\begin{thebibliography}{8}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
\newblock \emph{Deep learning}, volume~1.
\newblock MIT Press, 2016.

\bibitem[Keskar et~al.(2019)Keskar, McCann, Varshney, Xiong, and
  Socher]{Keskar2019CTRLAC}
N.~Keskar, Bryan McCann, L.~Varshney, Caiming Xiong, and R.~Socher.
\newblock Ctrl: A conditional transformer language model for controllable
  generation.
\newblock \emph{ArXiv}, abs/1909.05858, 2019.

\bibitem[OpenAI(2024)]{gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[Pfeiffer et~al.(2020)Pfeiffer, Kamath, Rücklé, Cho, and
  Gurevych]{Pfeiffer2020AdapterFusionNT}
Jonas Pfeiffer, Aishwarya Kamath, Andreas Rücklé, Kyunghyun Cho, and Iryna
  Gurevych.
\newblock Adapterfusion: Non-destructive task composition for transfer
  learning.
\newblock \emph{ArXiv}, abs/2005.00247, 2020.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Shen et~al.(2017)Shen, Lei, Barzilay, and Jaakkola]{Shen2017StyleTF}
T.~Shen, Tao Lei, R.~Barzilay, and T.~Jaakkola.
\newblock Style transfer from non-parallel text by cross-alignment.
\newblock \emph{ArXiv}, abs/1705.09655, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\end{thebibliography}

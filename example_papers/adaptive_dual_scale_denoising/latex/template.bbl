\begin{thebibliography}{9}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2020)Bai, Koltun, and Kolter]{Bai2020MultiscaleDE}
Shaojie Bai, V.~Koltun, and J.~Z. Kolter.
\newblock Multiscale deep equilibrium models.
\newblock \emph{ArXiv}, abs/2006.08656, 2020.

\bibitem[Hatamizadeh et~al.(2023)Hatamizadeh, Song, Liu, Kautz, and
  Vahdat]{Hatamizadeh2023DiffiTDV}
Ali Hatamizadeh, Jiaming Song, Guilin Liu, Jan Kautz, and Arash Vahdat.
\newblock Diffit: Diffusion vision transformers for image generation.
\newblock \emph{ArXiv}, abs/2312.02139, 2023.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  6840--6851. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}.

\bibitem[Ho et~al.(2021)Ho, Saharia, Chan, Fleet, Norouzi, and
  Salimans]{Ho2021CascadedDM}
Jonathan Ho, Chitwan Saharia, William Chan, David~J. Fleet, Mohammad Norouzi,
  and Tim Salimans.
\newblock Cascaded diffusion models for high fidelity image generation.
\newblock \emph{J. Mach. Learn. Res.}, 23:\penalty0 47:1--47:33, 2021.

\bibitem[Karras et~al.(2022{\natexlab{a}})Karras, Aittala, Aila, and
  Laine]{Karras2022ElucidatingTD}
Tero Karras, M.~Aittala, Timo Aila, and S.~Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{ArXiv}, abs/2206.00364, 2022{\natexlab{a}}.

\bibitem[Karras et~al.(2022{\natexlab{b}})Karras, Aittala, Aila, and
  Laine]{edm}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho
  (eds.), \emph{Advances in Neural Information Processing Systems},
  2022{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=k7FuTOWMOc7}.

\bibitem[Kotelnikov et~al.(2022)Kotelnikov, Baranchuk, Rubachev, and
  Babenko]{Kotelnikov2022TabDDPMMT}
Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko.
\newblock Tabddpm: Modelling tabular data with diffusion models.
\newblock \emph{ArXiv}, abs/2209.15421, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{pmlr-v37-sohl-dickstein15}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In Francis Bach and David Blei (eds.), \emph{Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37 of \emph{Proceedings
  of Machine Learning Research}, pp.\  2256--2265, Lille, France, 07--09 Jul
  2015. PMLR.

\bibitem[Yang et~al.(2023)Yang, Zhang, Song, Hong, Xu, Zhao, Zhang, Cui, and
  Yang]{yang2023diffusion}
Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao
  Zhang, Bin Cui, and Ming-Hsuan Yang.
\newblock Diffusion models: A comprehensive survey of methods and applications.
\newblock \emph{ACM Computing Surveys}, 56\penalty0 (4):\penalty0 1--39, 2023.

\end{thebibliography}

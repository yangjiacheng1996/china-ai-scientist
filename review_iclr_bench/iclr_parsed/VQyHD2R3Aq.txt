# SPIDE: A PURELY SPIKE-BASED METHOD FOR TRAINING FEEDBACK SPIKING NEURAL NETWORKS

**Anonymous authors**
Paper under double-blind review

ABSTRACT

Spiking neural networks (SNNs) with event-based computation are promising
brain-inspired models for energy-efficient applications on neuromorphic hardware. However, most high-performance supervised SNN training methods in machine learning research, such as conversion from artificial neural networks or direct training with surrogate gradients, require complex computation not supported
by spiking neurons, which hinders them from spike-based energy-efficient training. Among them, the recently proposed method, implicit differentiation on the
equilibrium state (IDE), for training feedback SNNs is a promising way possible for generalization to spike-based learning with flexible network structures. In
this paper, we study spike-based implicit differentiation on the equilibrium state
(SPIDE) that extends IDE for supervised local learning with spikes, which could
be possible for energy-efficient training on neuromorphic hardware. Specifically,
we first introduce ternary spiking neuron couples to realize ternary outputs with
the common neuron model, and prove that implicit differentiation can be solved by
spikes based on this design. With this approach, the whole training procedure can
be made as event-driven spike computation and weights are updated locally with
two-stage average firing rates. Then to reduce the approximation error of spikes
due to the finite simulation time steps, we propose to modify the resting membrane
potential. Based on it, the average firing rate, when viewed as a stochastic estimator, achieves an unbiased estimation of iterative solution for implicit differentiation and the variance of this estimator is reduced. With these key components, we
can train SNNs with either feedback or feedforward structures in a small number
of time steps. Further, the firing sparsity during training demonstrates the great potential for energy efficiency. Meanwhile, even with these constraints, our trained
models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100,
and CIFAR10-DVS. Our proposed method demonstrates the great potential for
energy-efficient training of SNNs on neuromorphic hardware.

1 INTRODUCTION

Spiking neural networks (SNNs) are brain-inspired models that transmit spikes between neurons for
event-driven energy-efficient computation. SNNs can be implemented with less energy on neuromorphic hardware (Akopyan et al., 2015; Davies et al., 2018; Pei et al., 2019; Roy et al., 2019),
which can remedy the defects of large energy consumption of artificial neural networks (ANNs).

Different from ANNs, however, directly supervised training of SNNs is a hard problem due to the
complex spiking neuron model which is discontinuous. To solve this problem, converting ANNs to
SNNs (Hunsberger & Eliasmith, 2015; Rueckauer et al., 2017; Sengupta et al., 2019; Rathi et al.,
2019; Deng & Gu, 2021; Yan et al., 2021), or many other direct SNN training methods (Wu et al.,
2018; Bellec et al., 2018; Jin et al., 2018; Shrestha & Orchard, 2018; Wu et al., 2019; Neftci et al.,
2019; Zhang & Li, 2019; Kim et al., 2020; Zheng et al., 2021; Bohte et al., 2002; Zhang & Li, 2020;
Kim et al., 2020; Xiao et al., 2021) have been proposed. While these methods could partly tackle
the problems of unsatisfactory performance or high latency, they require complex computation for
gradient calculation or approximation, which cannot be implemented by common spiking neurons
on neuromorphic hardware. They aim at training SNNs on commonly used computational units, e.g.
GPU, and deploying trained models for energy-efficient inference. However they do not consider
if the training procedure could leverage the same spike-based computation for gradient calculation
and training to reduce the large energy consumption during training as well.


-----

Table 1: Comparison of different supervised SNN training methods with respect to performance,
latency, structure flexibility, neuron model, spike-based or not, and neuromorphic plausibility.

Method High Perform. Low Latency Struc. Flexi. Common Neuron Model Spike-based Neuro. Plaus.

ANN-SNN ✓ _×_ _×_ ✓ _×_ Low
BPTT with Surrogate Gradients ✓ ✓ ✓ ✓ _×_ Low
DFA with Spikes _×_ ? _×_ ✓ ✓ High
SpikeGrad (Thiele et al., 2019a) ✓ ? _×_ _×_ ✓ Medium
IDE (Xiao et al., 2021) ✓ ✓ ✓ ✓ _×_ Low

**SPIDE (ours)** ✓ ✓ ✓ ✓ ✓ High

A few previous works try to train SNNs with spikes (Guerguiev et al., 2017; Neftci et al., 2017;
Samadi et al., 2017; O’Connor & Welling, 2016; Thiele et al., 2019b;a). They either are based
on direct feedback alignment (DFA) (Nøkland, 2016) and performs poorly, or require impractical
special neuron models (Thiele et al., 2019b;a). Besides, they only focus on feedforward network
structures imitated from ANNs, which ignores feedback connections that are ubiquitous in the human brain and enable neural networks to be shallower and more efficient (Kubilius et al., 2019; Xiao
et al., 2021). Actually, feedback structures suit SNNs more since SNNs will naturally compute with
multiple time steps, which could reuse representations and avoid uneconomical costs to unfold along
time that ANNs suffer from (Xiao et al., 2021). So training algorithms for feedback SNNs, which
may also degrade to feedforward structures by taking feedback as zero, is worth more exploration.

An ideal SNN training method should tackle the common problems, be suitable for flexible structures (feedforward or feedback) and be spike-based with high neuromorphic plausibility. The implicit differentiation on the equilibrium state (IDE) method (Xiao et al., 2021), which is recently
proposed to train feedback spiking neural networks (FSNNs), is a promising method that may generalize to spike-based learning for requirement. They derive that the forward computation of FSNNs
converges to an equilibrium state, which follows a fixed-point equation. Based on it, they propose
to train FSNNs by implicit differentiation on this equation, which tackles the common difficulties
for SNN training including non-differentiability and large memory costs, and has interesting local
update properties. In their method, however, they leverage general root-finding methods to solve
implicit differentiation, which requires complex computation on standard computation systems.

In this work, we extend the IDE method to spike-based IDE (SPIDE), which fulfills our requirements and has great potential for energy-efficient training of SNNs on neuromorphic hardware, by
introducing ternary spiking neuron couples and proposing to solve implicit differentiation by spikes
based on them. Our method is also applicable to feedforward structures by degrading the feedback
connection as zero. In practice, however, it may require long time steps to stabilize the training
with spikes due to approximation error for gradients. So we further dive into the approximation
error from the statistical perspective, and propose to simply adjust the resting potential of SNNs to
achieve an unbiased estimation of gradients and reduce the estimation variance of SNN computation. With these methods, we can train our models in a small number of time steps, which could
further improve the energy efficiency as well as the latency. Our contributions include:

1. We propose the SPIDE method that is the first to train high-performance SNNs by spikes
with common neuron models. Specifically, we propose ternary spiking neuron couples and
prove that implicit differentiation for gradient calculation can be solved by spikes based on
this design. Our method is applicable to both feedback and feedforward structures.

2. We theoretically analyze the approximation error of solving implicit differentiation by
spikes, and propose to modify the resting potential to remove the approximation bias and
reduce the estimation variance, which enables training in a small number of time steps.

3. Experiments show the low latency and firing sparsity during training, which demonstrates
the great potential for energy-efficient training of SNNs on neuromorphic hardware. The
performance on MNIST, CIFAR-10, CIFAR-100 and CIFAR10-DVS are also competitive.

2 RELATED WORK
Early works seek biologically inspired methods to train SNNs, e.g. spike-time dependent plasticity (STDP) (Diehl & Cook, 2015) or reward-modulated STDP (Legenstein et al., 2008). Since the
rise of successful ANNs, several works try to convert trained ANNs to SNNs to obtain high performance (Hunsberger & Eliasmith, 2015; Rueckauer et al., 2017; Sengupta et al., 2019; Rathi et al.,
2019; Deng & Gu, 2021; Yan et al., 2021). However, they suffer from extremely large time steps


-----

and their structures are limited in the scope of ANNs. Others try to directly train SNNs by imitating
backpropagation throught time (BPTT) and use surrogate derivative for discontinuous spiking functions (Lee et al., 2016; Wu et al., 2018; Bellec et al., 2018; Jin et al., 2018; Shrestha & Orchard, 2018;
Wu et al., 2019; Zhang & Li, 2019; Neftci et al., 2019; Zheng et al., 2021) or compute gradient with
respect to spiking times (Bohte et al., 2002; Zhang & Li, 2020; Kim et al., 2020). However, they suffer from approximation error and large memory costs. Xiao et al. (2021) propose the IDE method to
train feedback spiking neural networks, which decouples the forward and backward procedures and
avoids the common SNN training problems. However, all these methods require complex computation during training rather than spike-based. A few works focusing on training SNNs with spikes
either are based on feedback alignment and limited in simple datasets (Guerguiev et al., 2017; Neftci
et al., 2017; Samadi et al., 2017; O’Connor & Welling, 2016), or require impractical special neuron
models that require consideration of accumulated spikes for spike generation (Thiele et al., 2019b;a),
which is impractical on neuromorphic hardware. And they are only applicable to feedforward architectures. Instead, we are the first to leverage spikes with common neuron models to train SNNs with
feedback or feedforward structures. The comparison of different methods is illustrated in Table 1.
3 PRELIMINARIES

We first introduce preliminaries about spiking neurons and the IDE training method. The basic
thought of IDE (Xiao et al., 2021) is to identify the underlying equilibrium states of FSNN computation so that gradients can be calculated based on implicit differentiation on the equilibrium state.
We will briefly introduce the conclusion of equilibrium states in Section 3.2 and the IDE method in
Section 3.3. For more descriptions about the background please refer to Appendix A.

3.1 SPIKING NEURAL NETWORK MODELS
Spiking neurons draw inspirations from the human brain to communicate with each other by spikes.
Each neuron integrates information from input spike trains by maintaining a membrane potential
through a differential equation, and generates an output spike once the membrane potential exceeds
a threshold, following which the membrane potential is reset to the resting potential. We consider
the commonly used integrate and fire (IF) model and simple current model, whose discretized computational form is:

_ui [t + 0.5] = ui[t] +_ _wijsj[t] + b,_

 X


_j_

(1)

si[t + 1] = H(ui [t + 0.5] − _Vth),_

_ui[t + 1] = ui [t + 0.5] −_ (Vth − _urest)si[t + 1],_

where ui[t] is the membrane potential of neuron _i at time step t, si[t] is the binary output spike train_
of neuron i, wij is the connection weight from neuron j to neuron i, b is bias, H is the Heaviside step
function, Vth is the firing threshold, and urest is the resting potential. We use subtraction as the reset
operation. urest is usually taken as 0 in previous work, while we will reconsider it in Section 4.3.


3.2 EQUILIBRIUM STATES OF FEEDBACK SPIKING NEURAL NETWORKS

Xiao et al. (2021) derive that the (weighted) average rate of spikes during FSNN computation with
common neuron models would converge to an equilibrium state following a fixed-point equation
given convergent inputs. We focus on the conclusions with the discrete IF model under both singlelayer and multi-layer feedback structures. The single-layer structure has one hidden layer of neurons
with feedback connections on this layer. The update equation of membrane potentials is:
**u[t + 1] = u[t] + Ws[t] + Fx[t] + b** (Vth _urest)s[t + 1],_ (2)
_−_ _−_
where u[t] and s[t] are the vectors of membrane potentials and spikes of these neurons, x[t] is the
input at time step t, W is the feedback weight matrix, and F is the weight matrix from inputs to
these neurons. The average input and average firing rate are defined as x[t] = _t+11_ _tτ_ =0 **[x][[][τ]** []][ and]

**_α[t] =_** [1]t _tτ_ =1 **[s][[][τ]** []][, respectively. Define][ σ][(][x][) = min(1][,][ max(0][, x][))][.] P

The equilibrium state of the single-layer FSNN is described as (Xiao et al., 2021): If the averageP
inputs converge to an equilibrium point x[t] **x[∗], and there exists γ < 1 such that** **W** 2 _γVth,_
then the average firing rates of FSNN with discrete IF model will converge to an equilibrium point → _∥_ _∥_ _≤_
**_α[t] →_** **_α[∗], which satisfies the fixed-point equation α[∗]_** = σ _V1th_ [(][W][α][∗] [+][ Fx][∗] [+][ b][)] . Note that

they take urest = 0 in this conclusion, if we consider nonzero _urest, the constraint and the fixed-_
point equation should be ∥W∥2 ≤ _γ(Vth −_ _urest) and α[∗]_ = σ _Vth−1urest_ [(][W][α][∗] [+][ Fx][∗] [+][ b][)] .
 


-----

The multi-layer structure incorporates more non-linearity into the equilibrium fixed-point equation,
which has multiple layers with feedback connections from the last layer to the first layer. The update
equations of membrane potentials are expressed as:
**u[1][t + 1] = u[1][t] + W[1]s[N]** [t] + F[1]x[t] + b[1] (Vth _urest)s[1][t + 1],_
_−_ _−_ (3)
(u[l][t + 1] = u[l][t] + F[l]s[l][−][1][t + 1] + b[l] (Vth _urest)s[l][t + 1],_ _l = 2,_ _, N._

_−_ _−_ _· · ·_

The equilibrium state of the multi-layer FSNN with urest is described as (Xiao et al., 2021): If
the average inputs converge to an equilibrium point x[t] → **x[∗], and there exists γ < 1 such that**
**W[1]** 2 **F[N]** 2 **F[2]** 2 _γ(Vth_ _urest)[N]_, then the average firing rates of multi-layer FSNN
_∥_ _∥_ _∥_ _∥_ _· · · ∥_ _∥_ _≤_ _−_
with discrete IF model will converge to equilibrium points α[l][t] → **_α[l][∗], which satisfy the fixed-_**
point equations α[1][∗] = f1 _fN_ _f2(α[1][∗]), x[∗][]_ and α[l][+1][∗] = fl+1(α[l][∗]), where f1(α, x) =

_σ_ _Vth_ 1urest [(][W][1][α][ +][ F][1][x] [ +][ b] ◦· · · ◦[1][)] and fl(α) = σ _Vth_ 1urest [(][F][l][α][ +][ b][l][)] .

_−_ _−_

   

3.3 IDE TRAINING METHOD
Based on the equilibrium states in Section 3.2, we can train FSNNs by calculating gradients with
implicit differentiation (Xiao et al., 2021). Let α = fθ(α) denote the fixed-point equation of the
equilibrium state which is parameterized by θ, gθ(α) = fθ(α) **_α, and let_** (α[∗]) denote the
_−_ _L_
objective function with respect to the equilibrium state α[∗]. The implicit differentiation satisfies
_I_ _∂α[∗]_ ddαθ[∗] = _[∂f][θ]∂θ[(][α][∗][)]_ (Bai et al., 2019) (we follow the numerator layout convention for
_−_ _[∂f][θ][(][α][∗][)]_

derivatives). Therefore, the differentiation of  (α[∗]) for parameters can be calculated as:
_L_
_∂_ (α[∗])
_L∂θ_ = − _[∂][L]∂[(]α[α][∗][∗][)]_ _Jg[−]θ[1]_ _∂θ_ _,_ (4)

_[|][α][∗]_ [][ ∂f][θ][(][α][∗][)]

where Jg[−]θ[1] [evaluated at]  **_[ α][∗][. The calculation of inverse Jacobian can]_**
be avoided by solving an alternative linear system (Bai et al., 2019; 2020; Xiao et al., 2021):[|][α][∗] [is the inverse Jacobian of][ g][θ]
_∂_ (α∗) _⊤_
_Jg[⊤]θ_ _[|][α][∗]_ [] **_β +_** _L_ = 0. (5)

_∂α[∗]_

 

Note that a readout layer after the last layer of neurons will be constructed for output (Xiao et al., 
2021), which is equivalent to a linear transformation on the approximate equilibrium state, i.e. the
output would be o = W[o]α[∗], and the loss will be calculated between o and labels y with a common
criterion such as cross-entropy. Then the gradient on the equilibrium state could be calculated. For
the solution of implicit differentiation, Xiao et al. (2021) follow Bai et al. (2019; 2020) to leverage
root-finding methods, while we will solve it by spike dynamics, as will be derived in Section 4.
We treat the forward computation of average firing rates α[T ] of FSNNs at time step T roughly
reach the equilibrium state. Then by substituting α[∗] by α[T ] in the above equations, gradients for
the parameters can be calculated only with α[T ] and the equation, and we calculate them based on
spikes. With the gradients, first-order optimization methods such as SGD (Rumelhart et al., 1986)
and its variants can be applied to update parameters.

4 SPIKE-BASED IMPLICIT DIFFERENTIATION ON THE EQUILIBRIUM STATE

In this section, we present our SPIDE method that calculates the whole training procedure based on
spikes. We first introduce ternary spiking neuron couples in Section 4.1 and how to solve implicit
differentiation in Section 4.2. Then we theoretically analyze the approximation error and propose the
improvement in Section 4.3. Finally, a summary of the training pipeline is presented in Section 4.4.

4.1 TERNARY SPIKING NEURON COUPLES
The common spiking neuron model only generates spikes when the membrane potential exceeds a
positive threshold, which limits the firing rate from representing negative information. To enable
approximation of possible negative values for implicit differentiation calculation in Section 4.2, we
require negative spikes, whose expression could be:

1, _ui[t + 0.5] > Vth_

_si[t + 1] = T (ui[t + 0.5], Vth) =_ 0, _ui[t + 0.5]_ _Vth_ _,_ (6)

 _|_ _| ≤_
 1, _ui[t + 0.5] <_ _Vth_

_−_ _−_

and the reset is the same as usual: ui[t+1] = ui[t+0.5] (Vth _urest)si[t+1]. Direct realization of_

 _−_ _−_

such ternary output, however, may be not supported by common neuromorphic hardware for SNNs.


-----

We propose to leverage two coupled common neurons to realize
this computation. As illustrated in Figure 1, the two coupled neurons with the common IF model (Eq. (1)) receive opposite inputs
and output opposite spikes, which aim to deal with positive information and negative information with spikes, respectively. Theyshould share a reset operation in order to accord with Eq. (6), 𝑤= 𝑉𝑡ℎ [−𝑢]𝑟𝑒𝑠𝑡
which can be realized by the connection between them: as we usesubtraction as the reset operation, the connection whose weight 𝑤= 𝑉𝑡ℎ [−𝑢]𝑟𝑒𝑠𝑡
equalslently. To see how this works, consider the condition that the Vth − _urest enables one neuron to reset another equiva-_ spike 𝑠1 spike 𝑠2
accumulated membrane potential of neuron 1 reaches Vth, then 𝑠1 + −𝑠2
neuron 1 would generate a spike and reset, and the output is this
positive spike. At the same time, the membrane potential of neu
Input 𝑥

𝑥 −𝑥

𝑤= 𝑉𝑡ℎ [−𝑢]𝑟𝑒𝑠𝑡

1 2

𝑤= 𝑉𝑡ℎ [−𝑢]𝑟𝑒𝑠𝑡

spike 𝑠1 spike 𝑠2

𝑠1 + −𝑠2

output

ron 2 is −Vth and the neuron will not fire and reset, but the spike Figure 1: Illustration of ternary
from neuron 1 will reset it to −urest, which accords with our de- spiking neuron couples.
sired reset for ternary output. Similarly, if the inputs are negative,
neuron 2 will generate a spike which will be treated negative as output, and both neurons are reset.
For the operation of taking negative, one solution is to enable the reverse operation on hardware, another is to reconnect neuron 2 with other neurons while taking the weight negative to that of neuron
1. Therefore, such kind of coupled neurons with the common IF model could realize ternary output.

We note that the SpikeGrad algorithm (Thiele et al., 2019a) also requires neurons for ternary output.
However, they do not consider how such kind of operation can be implemented with the common
neuron model on neuromorphic hardware, and moreover, they propose another modified ternary
model in practice that requires consideration of accumulated spikes for spike generation, which is
further impractical on neuromorphic hardware. Differently, our method can be realized with the
common neuron model suitable for neuromorphic hardware.

4.2 SOLVING IMPLICIT DIFFERENTIATION WITH SPIKES
Based on the coupled neurons in Section 4.1, we can solve implicit differentiation with spikes. For
notation simplicity, we directly use Eq. (6) as a ternary neuron without detailing coupled neurons
below. Our main focus is on solving Eq. (5) with spikes. The brief outline for the derivation is:
we first derive the update equation of membrane potentials in SNN computation, then we derive the
equivalent equation of the rate of spikes with eliminating perturbation, finally, we could prove that
the rate of spikes converges to the solution of Eq. (5).

We first consider the single-layer condition. Let α[TF ] denote the average firing rate of these neurons after the forward computation with time steps TF as an approximate equilibrium state (we treat

the forward procedure as the first stage), g = _∂α∂[LTF ]_ _⊤_ denote the gradient of the loss function

on this approximate equilibrium state, and m = σ[′](α[TF ]), M = Diag(m) denote a mask indicator

1, 0 < x < 1
based on the firing condition in the first stage, where σ[′](x) = . We will have another
0, else


_TB time steps in the second backward stage to calculate implicit differentiation. We set the input to_
these neurons as g at all time steps, which can be viewed as input currents (Zhang & Li, 2020; Xiao
et al., 2021). Then along the inverse connections of neurons and with a mask on neurons or weights
and an output rescale, the computation of FSNN with ternary neurons is calculated as:

1
**u[t + 1] = u[t] +** (MW)[⊤]s[t] + g (Vth[b] _rest[)][s][[][t][ + 1]][,]_ (7)

_Vth_ _urest_ _−_ _[−]_ _[u][b]_
_−_

where Vth, urest and Vth[b] _[, u]rest[b]_ [are the threshold and resting potential during the first and second]
stage, respectively. Define the ‘average firing rate’ at this second stage as β[t] = [1]t _tτ_ =1 **[s][[][τ]** []][, and]

**u[0] = 0, s[0] = 0, then through summation, we have:**
P

1 _t_ 1
**_β[t + 1] =_** (MW)[⊤]β[t] + g _._ (8)

_Vth[b]_ _rest_ _t + 1_ _Vth_ _urest_ _−_ **[u]t[[][t] + 1[ + 1]]**

_[−]_ _[u][b]_  _−_ 

Since there could be at most t spikes during t time steps, β would be bounded in the
range of [ 1, 1]. The membrane potential ui[t] will maintain the exceeded terms, i.e. de_−_

fine vi[t] = _t+1t_ _Vth−1urest_ [(][MW][)][⊤][β][[][t][] +][ g] _i[, we can divide][ u][i][[][t][]][ as][ u]i[E][[][t][] +][ u]i[B][[][t][]][, where]_
 


-----

**u[E]i** [[][t][] = max] **vi[t] −** _Vth[b]_ _[,][ 0]_ + min **vi[t] + Vth[b]** _[,][ 0]_ is the exceeded term while u[B]i [[][t][]][ is a bounded]
term (Xiao et al., 2021) which is typically bounded in the range of [ _Vth[b]_ _[, V]th[ b]_ []][. Then, Eq. (8) turns]
      _−_
into:
1 _t_ 1
**_β[t + 1] = φ_** (MW)[⊤]β[t] + g _,_ (9)

_Vth[b]_ _rest_ _t + 1_ _Vth_ _urest_ _−_ **[u][B]t + 1[[][t][ + 1]]**

 _[−]_ _[u][b]_  _−_ 

where φ(x) = min(1, max(−1, x)). Note that if the input g and weight (MW)[⊤] are in an appropriate range, there would be no exceeded term and therefore φ will not take effect. Indeed we will
rescale the loss to control g in an appropriate range, as will be indicated in Section 4.3. With this
consideration, we could derive that the average firing rate β[t] converges to the solution of Eq. (5).
**Theorem 1. If there exists γ < 1 such that** (MW)[⊤] 2 _γ(Vth_ _urest)(Vth[b]_ _rest[)][, then the]_
_solution of Eq. (5).average firing rateand there exists λ < β 1[t such that] will converge to an equilibrium point ∥(MW)[⊤]∥ ∥∞_ _≤_ _λ(Vth∥ − ≤urest β)[ andt] → − ∥gβ∥[∗]∞. When≤_ 1 − V[−]λth[u][b], then[b][−] _[u] βrest[b]_ _[∗]_ _is the[= 1][,]_

The proof and discussion of assumptions are in Appendix B. With Theorem 1, we can solve Eq. (5)
by simulating this second stage of SNN computation to obtain the ‘firing rate’ β[TB] as the approximate solution. Plugging this solution to Eq. (4), the gradients can be calculated by: **W** =
1 1 1 _∇_ _L_

_Vth_ _urest_ **[M][β][[][T][B][]][α][[][T][F][ ]][⊤][,][ ∇][F][L][ =]** _Vth_ _urest_ **[M][β][[][T][B][]][x][[][T][F][ ]][⊤][,][ ∇][b][L][ =]** _Vth_ _urest_ **[M][β][[][T][B][]][.]**
_−_ _−_ _−_

Note that in practice, even if the data distribution is not properly in the range of φ, we can still view
_φ as a kind of clipping for improperly large numbers, which could be similar to empirical techniques_
like “gradient clipping” to stabilize the training.

Then we consider the extension to the multi-layer condition. Let α[l][TF ], l = 1, 2, · · ·, N denote

the average firing rate of neurons in layer l after the forward computation, g = _∂α[N]∂L[TF ]_ _⊤_ denote

the gradient of the loss function on the approximate equilibrium state of the last layer, and  **m[l]** =
_σ[′](α[l][TF ]), M[l]_ = Diag(m[l]) denote the mask indicators. Similarly, we will have another TB time
steps in the second stage to calculate implicit differentiation. We set the input to the last layer as
**g at all time steps. Then along the inverse connections of neurons and with a mask on neurons or**
weights and an output rescale, the computation of FSNN with ternary neurons is calculated as:

1
**u[N]** [t + 1] = u[N] [t] + _Vth_ _urest_ (M[1]W[1])[⊤]s[1][t] + g − (Vth[b] _[−]_ _[u]rest[b]_ [)][s][N] [[][t][ + 1]][,]

 _−_

1

u[l][t + 1] = u[l][t] + (M[l][+1]F[l][+1])[⊤]s[l][+1][t + 1] (Vth[b] _rest[)][s][l][[][t][ + 1]][,]_ _l = N_ 1, _, 1._

_Vth_ _urest_ _−_ _[−]_ _[u][b]_ _−_ _· · ·_
_−_ (10)

The ‘average firing rates’ **_β[l][t] are similarly defined for each layer, and the equivalent form can be_**
similarly derived as:

1 _t_ 1

**_β[N]_** [t + 1] = φ (M[1]W[1])[⊤]β[1][t] + g _,_

 _Vth[b]_ _rest_ _t + 1_ _Vth_ _urest_ _−_ **[u][N B]t + 1[[][t][ + 1]]** !!

_[−]_ _[u][b]_ _−_

β[l][t + 1] = φ 1 1 (M[l][+1]F[l][+1])[⊤]β[l][+1][t + 1] _._

_Vth[b]_ _rest_ _Vth_ _urest_ _−_ **[u][lB]t + 1[[][t][ + 1]]** !!

 _[−]_ _[u][b]_ _−_ (11)

The convergence of the ‘firing rate’ at the last layer to the solution of Eq. (5) can be similarly
derived as Theorem 1. However, we need to calculate gradients for each parameter as Eq. (4), which
is more complex than the single layer condition. Actually, we can derive that the ‘firing rates’ at
each layer converge to equilibrium points, based on which the gradients can be easily calculated
with information from the adjacent layers. Theorem 2 gives a formal description.
_γTheorem 2.(Vth_ _urest If there exists)[N]_ (Vth[b] _rest γ <[)]N_ _, then the average firing rates 1 such that ∥(M[1]W[1])[⊤]∥2∥ β(Ml[[N]t] will converge to equilibriumF[N]_ )[⊤]∥2 · · · ∥(M[2]F[2])[⊤]∥2 ≤
_points − β[l][t] →_ **_β[l][∗]. When[−]_** _[u][b]_ _Vth[b]_ _[−]_ _[u]rest[b]_ [= 1][, and there exists][ λ <][ 1][ such that][ ∥][(][M][1][W][1][)][⊤][∥][∞] _[≤]_
_λ(Vth −_ _urest), ∥(M[l]F[l])[⊤]∥∞_ _≤_ _λ(Vth −_ _urest), l = 2, · · ·, N and ∥g∥∞_ _≤_ 1 − _λ[N]_ _, then β[N][ ∗]_

_∂hN_ (α[N][ ∗]) _⊤_
_is the solution of Eq. (5), and β[l][∗]_ = _∂hl(α[N][ ∗])_ **_β[N][ ∗], l = N_** 1, _, 1, where hl(α[N][ ∗]) =_

_−_ _· · ·_

_fl_ _f2_ _f1(α[N][ ∗], x[∗])_ _, l = N,_ , 1. 
_◦· · · ◦_ _· · ·_
 


-----

The functions fl are defined in Section 3.2. For the proof please refer to Appendix C. With Theorem 2, by plugging the solutions explicitly into Eq. (4), the gradients can be calculated by **Fl** =
1 1 _∇_ _L_

_Vth_ _urest_ **[M][l][β][l][[][T][B][]][α][l][−][1][[][T][F][ ]][⊤][, l][ = 2][,][ · · ·][, N,][ ∇][F][1]** _[L][ =]_ _Vth_ _urest_ **[M][1][β][1][[][T][B][]][x][[][T][F][ ]][⊤][,][ ∇][W][1]** _[L][ =]_
_−1_ 1 _−_

_Vth_ _urest_ **[M][l][β][l][[][T][B][]][α][N]** [[][T][F][ ]][⊤][,][ ∇][b][l] _[L][ =]_ _Vth_ _urest_ **[M][l][β][l][[][T][B][]][.]**
_−_ _−_

Note that the gradient calculation shares an interesting local property, i.e. it is proportional to the
1
firing rates of the two neurons connected by it: ∇Fli,j _[L][ =]_ _Vth−urest_ **[m]i[l][β]i[l][α]j[l][−][1]. During calculation,**

since we will have the firing rate of the first stage before the second stage, this calculation can also
be carried out by event-based calculation triggered by the spikes in the second stage. So it would be
plausible on neuromorphic hardware as well.

Also, note that the theorems still hold if we degrade our feedback models to feedforward ones by
setting feedback connections as zero. In this setting, the dynamics and equilibriums degrade to direct
functional mappings, and the implicit differentiation degrades to the explicit gradient. We can still
approximate gradients with this computation.

In the following, we take Vth[b] _[−][u]rest[b]_ [= 1][ by default to fulfill the assumption of theorems (it may take]
other values if we correspondingly rescale the outputs and we set 1 for simplicity). Other techniques
like dropout can also be integrated into the calculation. Please refer to Appendix D for details.

4.3 REDUCING APPROXIMATION ERROR

Section 4.2 derives that we can solve implicit differentiation with spikes, as the average firing rate
will gradually converge to the solution. In practice, however, we will simulate SNNs for finite
time steps, and a smaller number of time steps is better for lower energy consumption. This will
introduce approximation error which may hamper training. In this subsection, we theoretically
study the approximation error and propose to adjust the resting potential to reduce it. Inspired by
the theoretical analysis on quantized gradients (Chen et al., 2020), we will analyze the error from
the statistical perspective.

For the ‘average firing rates’ β[l][t] in Eq. (8) and the multilayer counterparts, the approximation error
_e to the equilibrium states consists of three independent parts ee, er and ei: the first is u[lE][t + 1]_
that is the exceeded term due to the limitation of spike number, the second is u[lB][t + 1] which
can be viewed as a bounded random variable, and the third is the convergence error of the iterative
update scheme without u[l][t + 1], i.e. let b[l][t] denote the iterative sequences for solving β[l][∗] as
**b[l][t+1] =** _t+1t_ _Vth_ 1urest [(][M][l][+1][F][l][+1][)][⊤][b][l][[][t][]][, the convergence error is][ ∥][b][l][[][t][]][−][β][l][∗][∥][. The second part]

_−_
_er can be again decomposed into two independent components er = eq + es: eq is the quantization_
effect due to the precision of firing rates ( _T[1]_ [for][ T][ time steps) if we first assume the same average]

inputs at all time steps, and es is due to the random arrival of spikes rather than the average condition,
as there might be unexpected output spikes, e.g. the average input is 0 and the expected output
should be 0, but two large positive inputs followed by one larger negative input at the last time
would generate two positive spikes while only one negative spike. So the error is divided into:
_e = ee + eq + es + ei. Since the iterative formulation is certain for ei, we focus on ee, eq and es._

Firstly, the error eq due to the quantization effect is influenced by the input scale and time steps TB.
To enable proper input scale and smaller time steps, we will rescale the loss function by a factor
_sl, since the magnitude of gradients considering the direct cross-entropy loss function is relatively_
small. We scale the loss to an appropriate range so that information can be propagated by SNNs
in smaller time steps, and most signals are in the range of φ as analyzed in Section 4.2. The base
learning rate will be scaled by _s[1]l_ [correspondingly. This is also adopted by Thiele et al. (2019a).]

Then given the scale and number of time steps, eq, ee and es can be treated as random variables
from statistical perspective, and we view β[l][t] as stochastic estimators for the equilibrium states
with ei. For the stochastic optimization algorithms, the expectation and variance of the gradients are
important for convergence and convergence rate (Bottou, 2010), i.e. we hope an unbiased estimation
of gradients and smaller estimation variance. As for ee and es, they depends on the input data and
the expectations are E[ee] = 0, E[es] = 0 (the positive and negative parts have the same probability).
While for eq, it will depend on our hyperparameters Vth[b] [and][ u]rest[b] [. Since the remaining terms in]
**u[lB][t + 1] caused by the quantization effect is in the range of [u[b]rest[, V]th[ b]** []][ for positive terms while]

[−Vth[b] _[,][ −][u]rest[b]_ []][ for negative ones, given][ V][ b]th _[−]_ _[u]rest[b]_ [and considering the uniform distribution, only]


-----

when u[b]rest [=][ −][V][ b]th[, the expectation][ E][[][e][q][] = 0][ for both positive and negative terms. Therefore, we]
should adjust the resting potential from commonly used 0 (Wu et al., 2018; Sengupta et al., 2019;
Xiao et al., 2021) to −Vth[b] [for unbiased estimation, as described in Proposition 1.]

_−Proposition 1.Vth[b]_ _[,][ β][l][[][t][]][ are unbiased estimators for] For fixed Vth[b]_ _[−]_ _[u]rest[b]_ _[and uniformly distributed inputs and][ b][l][[][t][]][.]_ _[ e][q][, only when][ u]rest[b]_ [=]

Also, taking u[b]rest [=][ −][V][ b]th [achieves the smallest estimation variance for the quantization effect][ e][q][,]
considering the uniform distribution on [u[b]rest[, V]th[ b] []][ ∪] [[][−][V][ b]th[,][ −][u]rest[b] []][. Since the effects of][ e][e][,][ e][s] [and]
_ei are independent of eq and their variance is certain given inputs, it leads to Proposition 2._

**Proposition 2. Taking u[b]rest** [=][ −][V][ b]th _[reduces the variance of estimators][ β][l][[][t][]][.]_

With this analysis, we will take Vth[b] [= 0][.][5][, u]rest[b] [=][ −][0][.][5][ in the following to stabilize the training.]
For Vth and urest during the first forward stage, we will also take urest = −Vth.

4.4 DETAILS AND TRAINING PIPELINE
The original IDE method (Xiao et al., 2021) leverages other training techniques including modified batch normalization (BN) and restriction on weight spectral norm. Since the batch statistical
information might be hard to obtain for calculation on neuromorphic hardware and we seek for algorithms that could be possible on it, we drop the BN component in our SPIDE method. The restriction
on the weight norm, however, is necessary for the convergence of feedback models, as indicated in
theorems. We will adjust it for a more friendly calculation, please refer to Appendix D for details.

We summarize our training pipeline as follows (we also provide detailed pseudocodes in Appendix E). There are two stages for forward and backward procedures respectively. In the first stage,
SNNs will receive inputs and perform the calculation as Eq. (1,2,3) for TF time steps, after which
we get the output from the readout layer, and save the average inputs as well as the average firing
rates and masks of each layer for the second stage. In the second stage, the last layer of SNNs will
receive gradients for outputs and perform calculation along the inverse connections as Eq. (6,7,10)
for TB time steps, after which we get the ‘average firing rates’ of each layer. Based on the firing
rates from two stages, the gradients for parameters can be calculated as in Section 4.2 and then the
first-order optimization algorithm is applied to update the parameters.

5 EXPERIMENTS

In this section, we conduct experiments to demonstrate the effectiveness of our method and the great
potential for energy-efficient training. We simulate the computation on common computational
units. Please refer to Appendix D for implementation details and descriptions.

We first evaluate the effectiveness of our method in a small number of time steps. As shown in
Table 2, we can train high-performance models with low latency (TF = 30) in a very small number
time steps during training (e.g. TB = 50), which indicates the low latency and high energy efficiency. Note that the ANN-SNN methods usually require hundreds to thousands of time steps just
for satisfactory inference performance, and direct training methods show that relatively small time
steps are enough for inference, while we are the first to demonstrate that even training of SNNs can
be carried out with spikes in a very small number of time steps. This is due to our analysis and
improvement to reduce the approximation error, as illustrated in the ablation study in Appendix F.1.

Then we analyze the firing rate statistics to demonstrate the potential of energy efficiency. Since
the energy consumption on event-driven neuromorphic hardware is proportional to the number of
spikes, we present the average firing rates for forward and backward stages (for backward, both
positive and negative spikes are considered as firing) in Figure 2. It shows the firing sparsity of our
method, and spikes are sparser in the backward stage with around only 3%. Combined with the
small number of time steps, this demonstrates the great potential for the energy-efficient training of
SNNs based on our method on neuromorphic hardware.

Finally we evaluate the performance of our method on MNIST (LeCun et al., 1998), CIFAR-10 and
CIFAR-100 (Krizhevsky & Hinton, 2009). We compare our method to several ANN-SNN methods (Hunsberger & Eliasmith, 2015; Sengupta et al., 2019; Deng & Gu, 2021), direct SNN training
methods (Wu et al., 2018; Xiao et al., 2021), and SpikeGrad (Thiele et al., 2019a). As shown in
Table 3, we can train models with a small number of time steps and our trained models achieve


-----

competitive results on MNIST and CIFAR-10. Compared with the original IDE method (Xiao et al.,
2021), since we discard the BN component, our generalization performance is poorer (a detailed
discussion is in Appendix F.2). Compared with SpikeGrad (Thiele et al., 2019a), we can use fewer
neurons and parameters due to flexible network structure choices, and a small number of time steps
while they do not report this important feature. Besides, we use common neuron models while they
require impractical models, as indicated in Section 4.1. The results and discussion on CIFAR-100
and CIFAR10-DVS are in Appendix F.3 and F.4 due to the space limit, and our model could achieve
64.07% and 60.7% accuracy respectively. The result on CIFAR-100 is competitive for networks
without BN, though it is poorer than IDE with BN. And the result on CIFAR10-DVS is competitive
among results of common SNN models. It shows the effectiveness of our method even with constraints of purely spike-based training. Future work could seek normalization techniques friendly
for neuromorphic computation and our desired algorithm to further improve the performance.


Figure 2: The average firing rates for forward and backward stages during training. ‘A’ means AlexNet-F, ‘C’ means
CIFARNet-F, and T means time steps for the backward stage.


Table 2: Evaluation of
training with different time
steps in the backward stage.
Training is on CIFAR-10
with AlexNet-F structure and
_TF = 30. Results are based_
on 3 runs of experiments.


|50 100 250 500|88.41%±0.48% (89.07%) 89.17%±0.14% (89.35%) 89.61%±0.11% (89.70%) 89.57%±0.08% (89.67%)|
|---|---|


_TB_ Mean±Std (Best)

0.1 **A, T=50,**

**Forward**
**A, T=50,**

0.08 **BackwardA, T=100,**

**Forward**
**A, T=100,**

0.06 **BackwardA, T=250,**

**Forward**
**A, T=250,**

0.04 **BackwardA, T=500,**

**Forward**
**A, T=500,**

0.02 **BackwardC, T=250,**

**Forward**
**C, T=250,**

Average Firing Rates 0 **Backward**

1 11 21 31 41 51 61 71 81 91

Epochs

Table 3: Performance on MNIST and CIFAR-10. Results are based on 3 runs of experiments.

**MNIST**

Method Network structure _TF_ _TB_ Mean±Std (Best) Neurons Params

BP (Lee et al., 2016) 20C5-P2-50C5-P2-200 _>200_ / (99.31%) 33K 518K
STBP (Wu et al., 2018) 15C5-P2-40C5-P2-300 30 / (99.42%) 26K 607K
IDE (Xiao et al., 2021) 64C5 (F64C5) 30 / 99.53%±0.04% (99.59%) 13K 229K

SpikeGrad (Thiele et al., 2019a) 15C5-P2-40C5-P2-300 Unknown Unknown 99.38%±0.06% (99.52%) 26K 607K
**SPIDE (ours)** 64C5s-64C5s-64C5 (F64C3u) 30 100 99.34%±0.02% (99.37%) 20K 275K
**SPIDE (ours, degraded)** 15C5-P2-40C5-P2-300 30 100 99.44%±0.02% (99.47%) 26K 607K

**CIFAR-10**

Method Network structure _TF_ _TB_ Mean±Std (Best) Neurons Params

ANN-SNN (Hunsberger & Eliasmith, 2015) AlexNet 80 / (83.52%) 595K 21M
ANN-SNN Sengupta et al. (2019) VGG-16 2500 / (91.55%) 311K 15M
ANN-SNN (Deng & Gu, 2021) CIFARNet 400-600 / (90.61%) 726K 45M
STBP (Wu et al., 2019) AlexNet 12 / (85.24%) 595K 21M
STBP (w/o NeuNorm) (Wu et al., 2019) CIFARNet 12 / (89.83%) 726K 45M
STBP (Xiao et al., 2021) AlexNet-F 30 / (87.18%) 159K 3.7M
IDE (Xiao et al., 2021) AlexNet-F 30 / 91.74%±0.09% (91.92%) 159K 3.7M
IDE (Xiao et al., 2021) CIFARNet-F 30 / 92.08%±0.14% (92.23%) 232K 11.8M

SpikeGrad (Thiele et al., 2019a) CIFARNet Unknown Unknown 89.49%±0.28% (89.99%) 726K 45M
**SPIDE (ours)** AlexNet-F 30 250 89.61%±0.11% (89.70%) 159K 3.7M
**SPIDE (ours)** CIFARNet-F 30 250 89.94%±0.17% (90.13%) 232K 11.8M

6 CONCLUSION

In this work, we propose the SPIDE method that generalize the IDE method to enable the whole
training of SNNs with either feedback or degraded feedforward structures to be based on spikes
with common neuron models. We prove that the implicit differentiation can be solved with spikes
by our coupled neurons. We also analyze the approximation error due to finite time steps, and
propose to adjust the resting potential of SNNs. Experiments show that we could achieve competitive
performance with a small number of training time steps and sparse spikes, which demonstrates the
great potential of our method for energy-efficient training of SNNs on neuromorphic hardware.


-----

REFERENCES

Filipp Akopyan, Jun Sawada, Andrew Cassidy, Rodrigo Alvarez-Icaza, John Arthur, Paul Merolla,
Nabil Imam, Yutaka Nakamura, Pallab Datta, Gi-Joon Nam, et al. TrueNorth: Design and tool
flow of a 65 mw 1 million neuron programmable neurosynaptic chip. IEEE Transactions on
_Computer-Aided Design of Integrated Circuits and Systems, 34(10):1537–1557, 2015._

Shaojie Bai, J Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Advances in Neural
_Information Processing Systems, 2019._

Shaojie Bai, Vladlen Koltun, and J Zico Kolter. Multiscale deep equilibrium models. In Advances
_in Neural Information Processing Systems, 2020._

Shaojie Bai, Vladlen Koltun, and Zico Kolter. Stabilizing equilibrium models by jacobian regularization. In International Conference on Machine Learning, 2021.

Guillaume Bellec, Darjan Salaj, Anand Subramoney, Robert Legenstein, and Wolfgang Maass. Long
short-term memory and learning-to-learn in networks of spiking neurons. In Advances in Neural
_Information Processing Systems, 2018._

Sander M Bohte, Joost N Kok, and Han La Poutre. Error-backpropagation in temporally encoded
networks of spiking neurons. Neurocomputing, 48(1-4):17–37, 2002.

L´eon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
_COMPSTAT’2010. 2010._

Jianfei Chen, Yu Gai, Zhewei Yao, Michael W Mahoney, and Joseph E Gonzalez. A statistical
framework for low-bitwidth training of deep neural networks. In Advances in Neural Information
_Processing Systems, 2020._

Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao, Sri Harsha
Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain, et al. Loihi: A neuromorphic
manycore processor with on-chip learning. IEEE Micro, 38(1):82–99, 2018.

Shikuang Deng and Shi Gu. Optimal conversion of conventional artificial neural networks to spiking
neural networks. In International Conference on Learning Representations, 2021.

Peter U Diehl and Matthew Cook. Unsupervised learning of digit recognition using spike-timingdependent plasticity. Frontiers in Computational Neuroscience, 9:99, 2015.

Wei Fang, Zhaofei Yu, Yanqi Chen, Timoth´ee Masquelier, Tiejun Huang, and Yonghong Tian. Incorporating learnable membrane time constant to enhance learning of spiking neural networks. In
_Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021._

Jordan Guerguiev, Timothy P Lillicrap, and Blake A Richards. Towards deep learning with segregated dendrites. Elife, 6:e22901, 2017.

Eric Hunsberger and Chris Eliasmith. Spiking deep networks with LIF neurons. arXiv preprint
_arXiv:1510.08829, 2015._

Michael F Hutchinson. A stochastic estimator of the trace of the influence matrix for laplacian
smoothing splines. Communications in Statistics-Simulation and Computation, 18(3):1059–1076,
1989.

Yingyezhe Jin, Wenrui Zhang, and Peng Li. Hybrid macro/micro level backpropagation for training
deep spiking neural networks. In Advances in Neural Information Processing Systems, 2018.

Jinseok Kim, Kyungsu Kim, and Jae-Joon Kim. Unifying activation-and timing-based learning rules
for spiking neural networks. In Advances in Neural Information Processing Systems, 2020.

Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.


-----

Jonas Kubilius, Martin Schrimpf, Kohitij Kar, Rishi Rajalingham, Ha Hong, Najib Majaj, Elias Issa,
Pouya Bashivan, Jonathan Prescott-Roy, Kailyn Schmidt, et al. Brain-like object recognition with
high-performing shallow recurrent anns. In Advances in Neural Information Processing Systems,
2019.

Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

Jun Haeng Lee, Tobi Delbruck, and Michael Pfeiffer. Training deep spiking neural networks using
backpropagation. Frontiers in Neuroscience, 10:508, 2016.

Robert Legenstein, Dejan Pecevski, and Wolfgang Maass. A learning theory for reward-modulated
spike-timing-dependent plasticity with application to biofeedback. PLoS Comput Biol, 4(10):
e1000180, 2008.

Hongmin Li, Hanchao Liu, Xiangyang Ji, Guoqi Li, and Luping Shi. Cifar10-dvs: an event-stream
dataset for object classification. Frontiers in Neuroscience, 11:309, 2017.

Emre O Neftci, Charles Augustine, Somnath Paul, and Georgios Detorakis. Event-driven random
back-propagation: Enabling neuromorphic deep learning machines. Frontiers in neuroscience,
11:324, 2017.

Emre O Neftci, Hesham Mostafa, and Friedemann Zenke. Surrogate gradient learning in spiking
neural networks: Bringing the power of gradient-based optimization to spiking neural networks.
_IEEE Signal Processing Magazine, 36(6):51–63, 2019._

Arild Nøkland. Direct feedback alignment provides learning in deep neural networks. In Advances
_in Neural Information Processing Systems, 2016._

Peter O’Connor and Max Welling. Deep spiking networks. arXiv preprint arXiv:1602.08323, 2016.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, highperformance deep learning library. In Advances in Neural Information Processing Systems, 2019.

Jing Pei, Lei Deng, Sen Song, Mingguo Zhao, Youhui Zhang, Shuang Wu, Guanrui Wang, Zhe
Zou, Zhenzhi Wu, Wei He, et al. Towards artificial general intelligence with hybrid Tianjic chip
architecture. Nature, 572(7767):106–111, 2019.

Nitin Rathi, Gopalakrishnan Srinivasan, Priyadarshini Panda, and Kaushik Roy. Enabling deep
spiking neural networks with hybrid conversion and spike timing dependent backpropagation. In
_International Conference on Learning Representations, 2019._

Kaushik Roy, Akhilesh Jaiswal, and Priyadarshini Panda. Towards spike-based machine intelligence
with neuromorphic computing. Nature, 575(7784):607–617, 2019.

Bodo Rueckauer, Iulia-Alexandra Lungu, Yuhuang Hu, Michael Pfeiffer, and Shih-Chii Liu. Conversion of continuous-valued deep networks to efficient event-driven networks for image classification. Frontiers in Neuroscience, 11:682, 2017.

David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by backpropagating errors. Nature, 323(6088):533–536, 1986.

Arash Samadi, Timothy P Lillicrap, and Douglas B Tweed. Deep learning with dynamic spiking
neurons and fixed feedback weights. Neural Computation, 29(3):578–602, 2017.

Abhronil Sengupta, Yuting Ye, Robert Wang, Chiao Liu, and Kaushik Roy. Going deeper in spiking
neural networks: Vgg and residual architectures. Frontiers in Neuroscience, 13:95, 2019.

Sumit Bam Shrestha and Garrick Orchard. Slayer: spike layer error reassignment in time. In
_Advances in Neural Information Processing Systems, 2018._

Amos Sironi, Manuele Brambilla, Nicolas Bourdis, Xavier Lagorce, and Ryad Benosman. Hats:
Histograms of averaged time surfaces for robust event-based object classification. In Proceedings
_of the IEEE Conference on Computer Vision and Pattern Recognition, 2018._


-----

Johannes C Thiele, Olivier Bichler, and Antoine Dupret. Spikegrad: An ann-equivalent computation
model for implementing backpropagation with spikes. In International Conference on Learning
_Representations, 2019a._

Johannes C Thiele, Olivier Bichler, Antoine Dupret, Sergio Solinas, and Giacomo Indiveri. A spiking network for inference of relations trained with neuromorphic backpropagation. In 2019 Inter_national Joint Conference on Neural Networks (IJCNN), 2019b._

Jibin Wu, Yansong Chua, Malu Zhang, Guoqi Li, Haizhou Li, and Kay Chen Tan. A tandem learning
rule for effective training and rapid inference of deep spiking neural networks. IEEE Transactions
_on Neural Networks and Learning Systems, 2021._

Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, and Luping Shi. Spatio-temporal backpropagation for
training high-performance spiking neural networks. Frontiers in Neuroscience, 12:331, 2018.

Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, Yuan Xie, and Luping Shi. Direct training for spiking neural
networks: Faster, larger, better. In Proceedings of the AAAI Conference on Artificial Intelligence,
2019.

Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Yisen Wang, and Zhouchen Lin. Training feedback spiking neural networks by implicit differentiation on the equilibrium state. In Advances in
_Neural Information Processing Systems, 2021._

Zhanglu Yan, Jun Zhou, and Weng-Fai Wong. Near lossless transfer learning for spiking neural
networks. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021.

Wenrui Zhang and Peng Li. Spike-train level backpropagation for training deep recurrent spiking
neural networks. In Advances in Neural Information Processing Systems, 2019.

Wenrui Zhang and Peng Li. Temporal spike sequence learning via backpropagation for deep spiking
neural networks. In Advances in Neural Information Processing Systems, 2020.

Hanle Zheng, Yujie Wu, Lei Deng, Yifan Hu, and Guoqi Li. Going deeper with directly-trained
larger spiking neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence,
2021.


-----

A MORE BACKGROUND ABOUT THE IDE TRAINING METHOD

Due to the complex spiking neuron model which is discontinuous, directly supervised training
of SNNs is a hard problem, since the explicit computation is non-differentiable and therefore
backpropagation along the forward computational graph could be problematic. The IDE training
method (Xiao et al., 2021) considers another approach to calculating gradients that does not rely
on the exact reverse of the forward computation, which avoids the problem of non-differentiability
as well as large memory costs by BPTT-like methods with surrogate gradients. Specifically, the
IDE training method first derives that the (weighted) average firing rate of FSNN computation with
common neuron models would gradually evolve to an equilibrium state along time, which follows a
fixed-point equation. Then by viewing the forward computation of FSNN as a black-box solver for
this equation, and applying implicit differentiation on the equation, gradients can be calculated only
based on this equation and the (weighted) average firing rate during forward computation rather than
the exact forward procedure. Therefore, the forward and backward procedures are decoupled and
the non-differentiability is avoided.

As briefly introduced in Section 3.2, the IDE method defines the average firing rates of spikes during
forward computation, i.e. α[t]. Then IDE could derive an equivalent update equation for α[t], based
on the integrated update equations of membrane potentials Eq. (2,3). With the equivalent equation
for α[t], IDE proves that under certain conditions, α[t] converges to an equilibrium state following a
fixed-point equation. With the assumption that α[T ] after simulation of T time steps roughly follows
the fixed-point equation of the equilibrium state, gradients of the loss function for parameters can
be calculated by implicit differentiation, as introduced in Section 3.3. So the training pipeline for
the IDE method can be summarized as: first simulate FSNN computation for T time steps to obtain
the rate of spikes α[T ], then solve the implicit differentiation by root-finding methods for gradient
calculation based on α[T ] and the derived fixed-point equation of equilibrium states, finally apply
gradient-based optimizers to update parameters.

**Contribution of this work compared with IDE.** Compared with IDE, this work extends the
thought of equilibrium of spikes to solving implicit differentiation, which enables the whole training
procedure to be based on spike computation with common neuron models and provides the potential
for energy-efficient training of SNNs on neuromorphic hardware. IDE only derives the equilibrium
states of forward FSNN computation and requires general root-finding methods with complex computation to solve implicit differentiation for training. It remains unclear if it could be solved by
common spiking neuron models with only positive firing. This work design ternary spiking neuron
couples and prove that the equilibrium of spike computation can be leveraged to solve implicit differentiation based on the design, and we propose to modify the resting membrane potential to make
it practical in a relatively small number of time steps. This enables the proposed SPIDE method to be
the first to train high-performance SNNs with low latency and firing sparsity by spikes with common
neuron models, demonstrating the great potential for energy-efficient training of high-performance
SNNs on neuromorphic hardware.

B PROOF OF THEOREM 1

_Proof. We first prove the convergence of β[t]. Let Vu and Vu[b]_ [denote][ V][th] [and][ V][ b]th _rest_
respectively. Consider ∥β[t + 1] − **_β[t]∥, it satisfies:_** _[−]_ _[u][rest]_ _[−]_ _[u][b]_

_∥β[t + 1] −_ **_β[t]∥_**

1 _t_ 1
= _[φ]_ _Vu[b]_ _t + 1_ _Vu_ (MW)[⊤]β[t] + g − **[u][B]t + 1[[][t][ + 1]]**
  

1 _t_ 1 1
_φ_ _−_ (MW)[⊤]β[t 1] + g
_−_ _Vu[b]_ _t_ _Vu_ _−_ _−_ **[u][B]t[[][t][]]**
  

1 1 1 1
_≤_ _[φ]_ _Vu[b]_ _Vu_ (MW)[⊤]β[t] + g _−_ _φ_ _Vu[b]_ _Vu_ (MW)[⊤]β[t − 1] + g
     

1 _t_ 1 1 1
+ _[φ]_ _Vu[b]_ _t + 1_ _Vu_ (MW)[⊤]β[t] + g − **[u][B]t + 1[[][t][ + 1]]** _−_ _φ_ _Vu[b]_ _Vu_ (MW)[⊤]β[t] + g
     


-----

1 _t_ 1 1 1 1
+ _−_ (MW)[⊤]β[t 1] + g _φ_ (MW)[⊤]β[t 1] + g

_[φ]_ _Vu[b]_ _t_ _Vu_ _−_ _−_ **[u][B]t[[][t][]]** _−_ _Vu[b]_ _Vu_ _−_
     

1 1 1 1
_≤_ _[φ]_ _Vu[b]_ _Vu_ (MW)[⊤]β[t] + g _−_ _φ_ _Vu[b]_ _Vu_ (MW)[⊤]β[t − 1] + g
     

1 1 **u[B][t + 1]** 1 1 **u[B][t]**

+ [1] (MW)[⊤]β[t] (MW)[⊤]β[t 1] _._

_Vu[b]_ _t + 1_ _Vu_ [+] _t + 1_ [+] _t_ _Vu_ _−_ [+] _t_

 

(12)

As ∥(MW)[⊤]∥2≤ _γVuVu[b][, γ]_ _<_ 1, and |u[B]i [[][t][]][|][ is bounded,] we have ∥β[t + 1]∥ _≤_

_γ_ **_β[t]_** + _V1u_ **g** + **[u][B]t+1[[][t][+1]]** _γ_ **_β[t]_** + c, where c is a constant. Therefore **_β[t]_**
_∥_ _∥_ _∥_ _∥_ _≤_ _∥_ _∥_ _∥_ _∥_

is bounded. Then _∀ϵ > 0, ∃T1 such that when_ _t > T1, we have:_


1 **u[B][t + 1]**

(MW)[⊤]β[t] [+]
_Vu_ _t + 1_


1 **u[B][t]**

(MW)[⊤]β[t 1] [+]
_Vu_ _−_ _t_


_≤_ _[ϵ][(1][ −]2_ _[γ][)]_

(13)


_Vu[b]_


_t + 1_


And since ∥(MW)[⊤]∥2≤ _γVuVu[b][, we have:]_


1

_Vu[b]_




1 1

(MW)[⊤]β[t] + g _φ_
_Vu_ _−_ _Vu[b]_

  


1

(MW)[⊤]β[t 1] + g

 _Vu_ _−_  _[≤]_ _[γ][ ∥][β][[][t][]][ −]_ **_[β][[][t][ −]_** [1]][∥] _[.]_

(14)


Therefore, when t > T1, it holds that:


**_β[t + 1]_** **_β[t]_** _γ_ **_β[t]_** **_β[t_** 1] + _[ϵ][(1][ −]_ _[γ][)]_
_∥_ _−_ _∥≤_ _∥_ _−_ _−_ _∥_ 2


(15)


By iterating the above inequality, we haveϵ(12−γ) 1 + γ + · · · + γ[t][−][T][1][−][1][] _< γ[t][−][T][1]_ _∥β ∥[Tβ1[ + 1]t + 1] − −β[Tβ1[]t∥]∥≤+_ 2[ϵ] _[.][ There exists]γ[t][−][T][1]_ _∥β[T1 + 1][ T][2][ such that when] −_ **_β[T1]∥_** +

_t > T1 + T2, γ[t][−][T][1]_ **_β[T1 + 1]_** **_β[T1]_** 2 [, and therefore][ ∥][β][[][t][ + 1]][ −] **_[β][[][t][]][∥]_** _[< ϵ][. According]_

  _∥_ _−_ _∥≤_ _[ϵ]_

to Cauchy’s convergence test, the sequence {β[t]}i[∞]=0 [converges to][ β][∗][. Considering the limit, it]

satisfies β[∗] = φ _V1u[b]_ _V1u_ [(][MW][)][⊤][β][∗] [+][ g] .
  

When Vth[b] _rest_ [= 1][, and there exists][ λ <][ 1][ such that][ ∥][(][MW][)][⊤][∥][∞] _[≤]_ _[λ][(][V][th]_

_∥g∥∞_ _≤_ 1 −[−] _λ[u], the equation turns into[b]_ **_β[∗]_** = φ _V1u_ [(][MW][)][⊤][β][∗] [+][ g] . We have: _[−]_ _[u][rest][)][ and]_
 

1 1
**_β[∗]_** = (MW)[⊤]β[∗] + g (MW)[⊤]β[∗] + **g** _λ_ **_β[∗]_** + **g** _._
_∥_ _∥∞_ _Vu_ _≤_ _Vu_ _∥_ _∥∞_ _≤_ _∥_ _∥∞_ _∥_ _∥∞_
 ∞ _∞_

(16)

_[φ]_

Therefore, ∥β[∗]∥∞ _≤_ _[∥]1[g]−[∥]λ[∞]_ _[≤]_ [1][, and] _V[1]u_ [(][MW][)][⊤][β][∗] [+][ g] _∞_ _[≤]_ _V[1]u_ [(][MW][)][⊤][β][∗] _∞_ [+][ ∥][g][∥][∞] _[≤]_

_λ + (1 −_ _λ) = 1. It means β[∗]_ = φ _V1u_ [(][MW][)][⊤][β][∗] [+][ g] = _V1u_ [(][MW][)][⊤][β][∗] [+][ g][.]
 

Taking fθ(α[∗]) = _σ_ _Vth_ 1urest [(][W][α][∗] [+][ Fx][∗] [+][ b][)] (i.e. the fixed-point equation at the

_−_
equilibrium state as in Section 3.2) explicitly into Eq. (5), the linear equation turns into 

_V1u_ [(][MW][)][⊤] _[−]_ _[I]_ **_β + g = 0, where Vu, M, g are previously defined. Therefore, β[∗]_** satisfies

this equation. And since  (MW)[⊤] 2 _γVu, γ < 1, the equation has the unique solution β[∗]._
_∥_ _∥_ _≤_

**Remark 1.the assumption for the convergence is weaker than that for the convergence in the forward stage (in As for the assumptions in the theorem, firstly, when Vth[b]** _[−]_ _[u]rest[b]_ [= 1][ as we will take,]
_Section 3.2), because ∥(MW)[⊤]∥2 ≤∥W∥2 as M is a diagonal mask matrix. We will restrict the_


-----

_spectral norm of W following Xiao et al. (2021) to encourage the convergence of the forward stage_
_(in Appendix D), then this backward stage would converge as well._

_The assumptions for the consistency of the solution is a sufficient condition. In practice, the weight_
_norm will be partially restricted by weight decay and our restriction on Frobenius norm (in Ap-_
_pendix D), as well as the diagonal mask matrix M which would be sparse if the forward firing_
_events are sparse, and we will rescale the loss so that the input g is in an appropriate range, as_
_indicated in Section 4.3. Even if these assumptions are not satisfied, we can view φ as a kind of_
_empirical clipping techniques to stabilize the training, as indicated in Section 4.2. The discussion is_
_similar for the multi-layer condition (Theorem 2) in the next section._

C PROOF OF THEOREM 2

_Proof. We first prove the convergence of β[l][t]. Let Vu and Vu[b]_ [denote][ V][th] [and][ V][ b]th _rest_
respectively. Let gN[t][+1][(][β][,][ g][,][ u][B][) =][ φ] _V1u[b]_ _t+1t_ _V1u_ [(][M][1][W][1][)][⊤][β][ +][ g][ −] _t[u]+1[B][−]_ _[u][rest],_ _[−]_ _[u][b]_

_gl[t][(][β][,][ u][B][) =][ φ]_ _V1u[b]_ _V1u_ [(][M][l][+1][F][l][+1][)][⊤][β][ −] **[u]t[B]** _, l = 1, · · ·, N −_ 1, 

_gN_ (β, g) = φ V1u[b] [(][ 1]Vu [(][M][1][W][1][)][⊤][β][ +][ g][)] _,_ 

_gl(β) = φ_ _V1u[b]_ _V1u_ [(][M][l][+1][F][l][+1][)][⊤][β] _, l = 1, · · ·, N −_ 1.
  

Then β[N] [t + 1] = gN[t][+1] _g1[t]_ _· · · gN[t]_ _−1_ **_β[N]_** [t], u[N] _[−][1][B][t]_ _· · ·, u[1][B][t]_ _, g, u[N B][t + 1]_ .
     


We have:

**_β[N]_** [t + 1] − **_β[N]_** [t]

= _gN[t][+1]_ _g1[t]_ _· · · gN[t]_ _−1_ **_β[N]_** [t], u[N] _[−][1][B][t]_ _· · ·, u[1][B][t]_ _, g, u[N B][t + 1]_
     

_−gN[t]_ _g1[t][−][1]_ _· · · gN[t][−]−[1]1_ **_β[N]_** [t − 1], u[N] _[−][1][B][t −_ 1] _· · ·, u[1][B][t −_ 1] _, g, u[N B][t]_
     

_≤_ _gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t] _· · ·_ _, g_ _−_ _gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t − 1] _· · ·_ _, g_

+ _g N[t][+1] _ _g1[t]_ _· · · g N[t]_ _−1_ **_β[N]_** [t], u[N][−][1][B][t]   _· · · , u[1][B][t]_  , g, u[N B][t + 1]  _−gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t] _· · ·_ _, g_

+ _gN[t]_ _g1[t][−][1]_ _· · · gN[t][−]−[1]1_ **_β[N]_** [t − 1], u[N] _[−][1][B][t −_ 1] _· · ·, u[1][B][t −_ 1] _, g, u[N B][t ]_       
     

_−gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t − 1] _· · ·_ _, g_

_gN_  g1   _gN_ 1  β[N] [t] , g  _gN_ _g1_ _gN_ 1 **_β[N]_** [t 1] _, g_
_≤_ _· · ·_ _−_ _· · ·_ _−_ _· · ·_ _−_ _−_ _· · ·_

1 1

+ V[1]u [b]   _t + 1_ _Vu_ ( M[1]W[1])[⊤]g1[t] _· · ·_ _gN[t]_ _−1 _ **_β [N]_** [t], u[N] _[−] [1][B][t]_ _· · ·, u[1][B][t]_ 

    

1
+ _Vu_ (M[1]W[1])[⊤] []g1[t] _· · · gN[t]_ _−1_ **_β[N]_** [t], u[N] _[−][1][B][t]_ _· · ·, u[1][B][t]_ _−_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t] _· · ·_

         []
_A_

1 1
+ | _t_ _Vu_ (M[1]W[1])[⊤]g1[t][−][1] _· · · gN[t][−]−[1]1_ **_β[N]_** [t − 1], u{z[N] _[−][1][B][t −_ 1] _· · ·, u[1][B][t −_ 1] }

   

1
+ _Vu_ (M[1]W[1])[⊤] []g1[t][−][1] _· · · gN[t][−]−[1]1_ **_β[N]_** [t − 1], u[N] _[−][1][B][t −_ 1] _· · ·, u[1][B][t −_ 1] _−_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t − 1] _· · ·_

         []
_B_
| **u[N B][t + 1]** **u[N B][t]** {z }

+ _t + 1_ [+] _t_ _._ (17)

!


-----

For the term A and B, they are bounded by:

1 1
_A ≤_ _Vu[b]_ _Vu_ (M[1]W[1])[⊤] _V[1]u_ (M[N] **F[N]** )[⊤] []g2[t] _· · · gN[t]_ _−1_ **_β[N]_** [t], u[N] _[−][1][B][t]_ _· · ·, u[2][B][]_ _−_ _g2_ _· · · gN_ _−1_ **_β[N]_** [t] _· · ·_

         []

1

+ (M[1]W[1])[⊤] **[u][1][B][[][t][]]**

_Vu_ _t_ !


_≤_ _· · · · · ·_

1 1 1 1
_≤_ _Vu[b]_ _Vu_ (M[1]W[1])[⊤] **[u][1][B]t** [[][t][]] [+][ · · ·][ +] _Vu[b]N_ _−1_ _VuN_ _−1_ [(][M][1][W][1][)][⊤][(][M][N] **[F][N]** [)][⊤] _[· · ·][ (][M][3][F][3][)][⊤]_ **[u][N]** _[−]t[1][B][[][t][]]_

(18)
and B has the same form as A by substituting t with t − 1.

Since ∥(M[1]W[1])[⊤]∥2∥(M[N] **F[N]** )[⊤]∥2 · · · ∥(M[2]F[2])[⊤]∥2 ≤ _γVu[N]_ _[V][ b]u_ _N_, we have:
_gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t] _· · ·_ _, g_ _−_ _gN_ _g1_ _· · · gN_ _−1_ **_β[N]_** [t − 1] _· · ·_ _, g_

1 1
_≤_ _Vu[b]_  Vu ( M[1]W[1])[⊤] [ ]g1 _· · ·_ _gN−1_ β[N] [t]  · · ·   _−_ _g1_ _· · ·  gN_ _−1_ **_β[N][t −_** 1] _· · ·_

           

_≤_ _· · · · · ·_ (19)

1 1

_≤_ _Vu[b]N_ _Vu[N]_ (M[1]W[1])[⊤](M[N] **F[N]** )[⊤] _· · · (M[2]F[2])[⊤]_ [ ]β[N] [t] − **_β[N]_** [t − 1]



_≤_ _γ_ **_β[N]_** [t] − **_β[N]_** [t − 1] _._

_B_
And since u[l]i [t] is bounded, then _ϵ > 0,_ _T1 such that when t > T1, we have:_
_∀_ _∃_

**_β[N]_** [t + 1] **_β[N]_** [t] _γ_ **_β[N]_** [t] **_β[N]_** [t 1] + _[ϵ][(1][ −]_ _[γ][)]_ _._ (20)
_−_ _≤_ _−_ _−_ 2

Then ∥β[N] [t + 1] − **_β[N]_** [t]∥ _< γ[t][−][T][1]_ _∥β[N]_ [T1 + 1] − **_β[N]_** [T1]∥ + 2[ϵ] [, and there exists][ T][2][ such that]

when t > T1 + T2, ∥β[N] [t + 1] − **_β[N]_** [t]∥ _< ϵ. According to Cauchy’s convergence test, β[N]_ [t]

converges to β[N][ ∗], which satisfies β[N][ ∗] = gN _g1 ◦· · · ◦_ _gN_ _−1(β[N][ ∗]), g_ . Considering the limit,

**_β[l][t] converges to β[l][∗], which satisfies β[l][∗]_** = gl(β[l][+1][∗]). 


Whenurest) V, ∥(th[b]M[−][l]F[l][u])rest[b][⊤]∥∞ = 1≤ _λ(, and there existsVth −_ _urest), l = 2 λ <, · · ·, N 1 and such that ∥g∥∞_ _≤ ∥1( −M[1]λW[N]_, we have:[1])[⊤]∥∞ _≤_ _λ(Vth −_
1
**_β[N][ ∗]_** _∞_ [=] _gN_ g1 ◦· · · ◦ _gN_ _−1(β[N][ ∗]), g∞_ _[≤]_ _Vu_ (M[1]W[1])[⊤]g1 ◦· · · ◦ _gN_ _−1(β[N][ ∗])_ _∞_ + ∥g∥∞

_≤_ _λ_ _g1 ◦· · · ◦_ _gN_ _−1(β[N][ ∗])_ _∞_ [+][ ∥][g][∥][∞] _[≤· · · · · · ≤]_ _[λ][N]_ **_β[N][ ∗]_** _∞_ [+][ ∥][g][∥][∞] (21)

Therefore, **_β[N][ ∗]_** 1−λ[N][ ≤] [1][, and] _g˜N_ _−1(β[N][ ∗])_ **_β[N][ ∗]_**
_∞_ _[≤]_ _[∥][g][∥][∞]_ _∞_ _[≤]_ _[λ]_ _∞_ _[≤]_ _[λ,][ · · · · · ·][,]_

_g˜1 ◦· · · ◦_ _g˜N_ _−1(β[N][ ∗])_ _∞1_ _[≤]_ _[λ][N]_ _[−][1][,]_ _g˜N_ _g˜1 ◦· · · ◦_ _g˜N_ _−11(β[N][ ∗]), g_ _∞_ _[≤]_ _[λ][N][ + (1][ −]_ _[λ][N]_ [) =]

1, where ˜gN (β, g) = _Vu_ [(][M][1][W][1][)][⊤][β][ +][ g][,][ ˜]gl(β) = _Vu_ [(][M][l][+1][F][l][+1][)][⊤][β][, l][ = 1][,][ · · ·][, N][ −] [1][,]

(i.e. _g˜l is gl without the function φ)._ It means β[N][ ∗] = gN _g1_ _gN_ 1(β[N][ ∗]), g =
_◦· · · ◦_ _−_

_g˜N_ _g˜1 ◦· · · ◦_ _g˜N_ _−1(β[N][ ∗]), g_ and β[l][∗] = gl(β[l][+1][∗]) = ˜gl(β[l][+1][∗]).  
 

Taking α[1][∗] = f1 _fN_ _f2(α[1][∗]), x[∗][]_ and α[l][+1][∗] = fl+1(α[l][∗]) (i.e. the fixed-point equation at the equilibrium state as in Section 3.2) explicitly into Eq. (5), the linear equation turns ◦· · · ◦
 
_∥into(M ˜[1]gW1 ◦· · · ◦[1])[⊤]∥2∥g(˜MN_ _−[N]1F(β[N]) −)[⊤]∥β2 · · · ∥ + g( = 0M[2]F[2].)[⊤]Therefore,∥2 ≤_ _γV βu[N]_ _[, γ <][N][ ∗]_ satisfies this equation.[ 1][, the equation has the unique]And since


-----

_∂hl+1(α[N][ ∗])_ _⊤_
solution β[N][ ∗]. Further, because ˜gl(β) = _∂hl(α[N][ ∗])_ **_β, where hl(α[N][ ∗]) = fl_**

_◦· · · ◦_

 _∂hN_ (α[N][ ∗]) _⊤_

_f2_ _f1(α[N][ ∗], x[∗])_ _, l = N,_ _, 1, we have β[l][∗]_ = _∂hl(α[N][ ∗])_ **_β[N][ ∗], l = N_** 1, _, 1._
_· · ·_ _−_ _· · ·_
   

D TRAINING DETAILS

D.1 DROPOUT

Dropout is a commonly used technique to prevent over-fitting, and we follow Bai et al. (2019; 2020);
Xiao et al. (2021) to leverage variational dropout, i.e. the dropout of each layer is the same at different time steps. Since applying dropout on the output of neurons is a linear operation with a mask
and scaling factor, it can be integrated into the weight matrix without affecting the conclusions of
convergence. The detailed computation with dropout is illustrated in the pseudocode in Appendix E.

D.2 RESTRICTION ON WEIGHT NORM

As indicated in the theorems, a sufficient condition for the convergence to equilibrium states in
both forward and backward stages is the restriction on the weight spectral norm. Xiao et al. (2021)
leverages re-parameterization to restrict the spectral norm, i.e. they re-parameterize W as W =
_α_ _∥WW∥2_ [, where][ ∥][W][∥][2][ is computed as the implementation of Spectral Normalization and][ α][ is a]

learnable parameter to be clipped in the range of [−c, c] (c is a constant). However, the computation
of spectral norm and re-parameterization may be hard to realize on neuromorphic hardware. We
adjust it for a more friendly calculation as follows.

ternatively restrict the Frobenius norm which is easier to compute. Further, considering that con-First, the spectral norm is upper-bounded by the Frobenius norm: ∥W∥2 ≤∥W∥F . We can alnection weights may not be easy for readout compared with neuron outputs, we can approximate

**W** _F by_ **W** _F =_ tr(WW[⊤]) = Eϵ (0,Id) [ **_ϵ[⊤]W_** 2[]][, according to the Hutchinson esti-]
_∥_ _∥_ _∥_ _∥_ _∈N_ _∥_ _∥[2]_

mator (Hutchinson, 1989). It can be viewed as source neurons outputting noises and target neuronsp q
accumulating signals to estimate the Frobenius norm. We will estimate the norm based on the
Monte-Carlo estimation (we will take 64 samples), which is similarly adopted by Bai et al. (2021)
to estimate the norm of their Jacobian matrix. Then based on the estimation, we will restrict W
as W = α _∥WW∥F_ [where][ α][ = min(][c,][ ∥][W][∥][F][ )][,][ c][ is a constant for norm range. This estimation and]

calculation may correspond to large amounts of noises in our brains, and a feedback inhibition on
connection weights based on neuron outputs.

Following Xiao et al. (2021), we only restrict the norm of feedback connection weight W[1] for the
multi-layer structure, which works well in practice.

D.3 OTHER DETAILS

For SNN models with feedback structure, we set Vth = 1, urest = −1 in the forward stage to form
an equivalent equilibrium state as Xiao et al. (2021). The constant for restriction in Appendix D.2
is c = 2. Following Xiao et al. (2021), we train models by SGD with momentum for 100 epochs.
The momentum is 0.9, the batch size is 128, and the initial learning rate is 0.05. For MNIST, the
learning rate is decayed by 0.1 every 30 epochs, while for CIFAR-10 and CIFAR-100, it is decayed
by 0.1 at the 50th and 75th epoch. We apply linear warmup for the learning rate in the first 400
iterations for CIFAR-10 and CIFAR-100. We apply the weight decay with 5 × 10[−][4] and variational
dropout with rate 0.2 for AlexNet-F and 0.25 for CIFARNet-F. The initialization of weights follows
Wu et al. (2018), i.e. we sample weights from the standard uniform distribution and normalize them
on each output dimension. The scale for the loss function (as in Section 4.3) is 100 for MNIST, 400
for CIFAR-10, and 500 for CIFAR-100.

For SNN models with degraded feedforward structure, our hyperparameters mostly follow Thiele
et al. (2019a), i.e. we set Vth = 0.5, urest = −0.5, train models by SGD with momentum 0.9 for


-----

60 epochs, set batch size as 128, and the initial learning rate as 0.1 which is decayed by 0.1 every 20
epochs, and apply the variational dropout only on the first fully-connected layer with rate 0.5.

The notations for our structures mean: ‘64C5’ represents a convolution operation with 64 output
channels and kernel size 5, ‘s’ after ‘64C5’ means convolution with stride 2 (which downscales 2×)
while ‘u’ after that means a transposed convolution to upscale 2×, ‘P2’ means average pooling with
size 2, and ‘F’ means feedback layers. The network structures for CIFAR-10 are:

AlexNet (Wu et al., 2019): 96C3-256C3-P2-384C3-P2-384C3-256C3-1024-1024,

AlexNet-F (Xiao et al., 2021): 96C3s-256C3-384C3s-384C3-256C3 (F96C3u),

CIFARNet (Wu et al., 2019): 128C3-256C3-P2-512C3-P2-1024C3-512C3-1024-512,

CIFARNet-F (Xiao et al., 2021): 128C3s-256C3-512C3s-1024C3-512C3 (F128C3u).

We simulate the computation on commonly used computational units. The code implementation
is based on the PyTorch framework (Paszke et al., 2019), and experiments are carried out on one
NVIDIA GeForce RTX 3090 GPU.

E PSEUDOCODE OF THE SPIDE ALGORITHM

Our algorithm consists of two-stage SNN computation, as explained in Section 4.4. The detailed
computation for both stages are illustrated in Algorithm 1 and Algorithm 2 respectively.

**Algorithm 1 Forward procedure of SPIDE training - Stage 1.**

**Input: Network parameters F** [1], b[1], · · ·, F _[N]_ _, b[N]_ _, W_ [1], W _[o], b[o]; Input data x; Time steps TF ;_
Forward threshold Vth; Dropout rate r;
**Output: Output of the readout layer o.**

1: Initialize u[i][0] = 0, i = 1, 2, · · ·, N
2: If use dropout, randomly generate dropout masks D[i](i = 1, 2, · · ·, N ), D[f] with rate r //
_D[i], D[f]_ are saved for backward

3: for t = 1, 2, · · ·, TF do
4: **if t == 1 then**

5: _u[1][t] = u[1][t −_ 1] + D[1] _⊙_ (F [1]x[t] + b[1])

6: **else**

7: _u[1][t] = u[1][t −_ 1] + D[1] _⊙_ (F [1]x[t] + b[1]) + D[f] _⊙_ (W [1]s[N] [t − 1])

8: _s[1][t] = H(u[1][t]_ _Vth)_
_≥_

9: _u[1][t] = u[1][t] −_ 2Vths[1][t] // urest = −Vth, the same below

10: **for l = 2, 3, · · ·, N do**

11: _u[l][t] = u[l][t −_ 1] + D[l] _⊙_ (F _[l]s[l][−][1][t] + b[l])_

12: _s[l][t] = H(u[l][t]_ _Vth)_
_≥_

13: _u[l][t] = u[l][t]_ 2Vths[l][t]
_−_

14: _o = o+W_ _[o]s[N]_ [t]+b[o] // o can be accumulated here, or calculated later by o = W _[o]α[N]_ +b[o]

15: o = _T[o]_

_T_
_t=1_ _[s][i][[][t][]]_

16: α[i] = _T_ _, i = 1, 2,_ _, N_ // Save for backward, firing rate in Stage 1

P _· · ·_

17: m[i] = H(α[i] _> 0)_ _H(α[i]_ _< 1)_ // Save for backward, mask
_∧_ _T_

_t=1_ _[x][[][t][]]_

18: If x is not constant, save x = _T_ for backward

P

19: return o


F MORE EXPERIMENTAL COMPARISONS

F.1 ABLATION STUDY

In this section, we conduct ablation study on our improvement to reduce the approximation error
by setting the resting potential as negative threshold. To formulate equivalent equilibrium states, we


-----

**Algorithm 2 Backward procedure of SPIDE training - Stage 2.**

**Input: Network parameters F** [1], b[1], · · ·, F _[N]_ _, b[N]_ _, W_ [1], W _[o], b[o]; Forward output o; Label y; Time_
steps TB; Forward threshold Vth; Backward threshold Vth[b] [= 0][.][5][; Other hyperparameters and saved]
variables;
**Output: Trained network parameters F** [1], b[1], · · ·, F _[N]_ _, b[N]_ _, W_ [1], W _[o], b[o]._

1: Calculate g = _[∂L]∂o[(][o,y][)]_ // for CE loss, _[∂L]∂o[(][o,y][)]_ = softmax(o) _y, in practice we will scale the_

_−_
loss by a factor sl, then _[∂L]∂o[(][o,y][)]_ = sl (softmax(o) _y)_

_−_

2: Initialize u[i][0] = 0, i = 1, 2, · · ·, N
3: for t = 1, 2, · · ·, TB do
4: **if t == 1 then**

5: _u[N]_ [t] = u[N] [t − 1] + W _[o][⊤]g_

6: **else**

7: _u[N]_ [t] = u[N] [t − 1] + W _[o][⊤]g +_ 2V1th _[W][ 1][⊤][(][D][f][ ⊙]_ _[m][1][ ⊙]_ _[s][1][[][t][ −]_ [1])] // m[i] is the saved

mask in Stage 1


8: _s[N]_ [t] = T (u[N] [t], 0.5) // realized by two coupled neurons

9: _u[N]_ [t] = u[N] [t] − _s[N]_ [t] // realized by two coupled neurons

10:11: **for lu =[l][t N] = − u[l]1[t, N − −1] +2, · · ·2V1th,[F] 1[ l] do[⊤][(][D][l][ ⊙]** _[m][l][+1][ ⊙]_ _[s][l][+1][[][t][])]_ // m[i] is the saved mask in Stage 1

12: _s[l][t] = T_ (u[l][t], 0.5) // realized by two coupled neurons

13: _u[l][t] = u[l][t]_ _s[l][t]_ // realized by two coupled neurons

_T_ _−_
_t=1_ _[s][i][[][t][]]_

14: β[i] = _T_ _, i = 1, 2,_ _, N_ // “firing rate” in Stage 2

P _· · ·_

15: Calculate gradients:
16: (1) ∇F 1 _L =_ 2V1th [(][m][1][ ⊙] _[β][1][)][x][⊤]_ // m[i], x are the saved mask and average input in Stage 1

17: (2) ∇F i _L =_ 2V1th [(][m][i][ ⊙] _[β][i][)][α][i][−][1][⊤][, i][ = 2][,][ 3][,][ · · ·][, N]_ // m[i], α[i] are the saved mask and firing

rate in Stage 1

1
18: (3) ∇bi _L =_ 2Vth [(][m][i][ ⊙] _[β][i][)][, i][ = 1][,][ 2][,][ · · ·][, N]_

19: (4) ∇W 1 _L =_ 2V1th [(][m][1][ ⊙] _[β][1][)][α][N][ ⊤]_ // m[i], α[i] are the saved mask and firing rate in Stage 1

_∂L(o,y)_ _⊤_
20: (5) _W o_ = α[N][ ] _∂o_ // α[i] is the saved firing rate in Stage 1
_∇_ _L_

_∂L(o,y)_ _⊤_ 
21: (6) _bo_ = _∂o_
_∇_ _L_

22: Update F [1], b[1], · · ·, F _[N], b[N]_ _, W_ [1], W _[o], b[o]_ based on the gradient-based optimizer // SGD
learning rate η + momentum α & weight decay µ, the base learning rate is scaled by the factor
_sl of the loss, i.e. η =_ _s[η]l_

23: (1) Update the momentum Mθ = α ∗ _Mθ + (1 −_ _α) ∗∇θL, θ ∈{F_ _[i], b[i], W_ [1], W _[o], b[o]}_

24: (2) Update parameters θ = (1 _µ)_ _θ + η_ _Mθ, θ_ _F_ _[i], b[i], W_ [1], W _[o], b[o]_
_−_ _∗_ _∗_ _∈{_ _}_

25: (3) Restrict the norm of W [1]

26: return F [1], b[1], · · ·, F _[N]_ _, b[N]_ _, W_ [1], W _[o], b[o]_

take the samesettings: (1) both forward and backward stages apply our improvement, i.e. Vth − _urest = Vu and the same Vth[b]_ _[−]_ _[u]rest[b]_ [=][ V][ b]u [, and we consider the following] urest = −Vth, u[b]rest [=]
_−Vth[b]_ [; (2) remove the improvement on the backward stage, i.e.][ V][ b]th [=][ V][ b]u _[, u]rest[b]_ [= 0][; (3) remove the]
improvement on both forward and backward stages, i.e. Vth = Vu, urest = 0 and Vth[b] [=][ V][ b]u _[, u]rest[b]_ [=]
0. The latter two setting are denoted by “w/o B” and “w/o F&B” respectively.

The models are trained on CIFAR-10 with AlexNet-F structure and 30 forward time steps. The
training and testing curves under different settings and backward time steps are illustrated in Figure 3 and Figure 4 respectively. It demonstrates that without our improvement, the training can not
perform well within a small number of backward time steps, probably due to the bias and large
variance of the estimated gradients. When the backward time steps are large, the performance gap
is reduced since the bias of estimation is reduced. It shows the superiority of our improvement to
training SNNs within a small number of backward time steps.


-----

100

90

**T=50**

80 **w/o B, T=50**

**w/o F&B, T=50**

70 **T=100**

**w/o B, T=100**

60 **w/o F&B, T=100**

**T=250**

50 **w/o B, T=250**

**w/o F&B, T=250**

40 **T=500**

### Training Accuracy w/o B, T=500

30 **w/o F&B, T=500**

20

10

1 11 21 31 41 51 61 71 81 91

### Epochs

Figure 3: Comparison of training curves under different settings and backward time steps.



100

90

**T=50**

80

**w/o B, T=50**

**w/o F&B, T=50**

70

**T=100**

**w/o B, T=100**

60

**w/o F&B, T=100**

**T=250**

50

**w/o B, T=250**

**w/o F&B, T=250**

40

**T=500**

### Testing Accuracy

30 **w/o B, T=500**

**w/o F&B, T=500**

20

10

1 11 21 31 41 51 61 71 81 91

### Epochs

Figure 4: Comparison of testing curves under different settings and backward time steps.


-----

100

90 **IDE, train**

**IDE, test**

80 **SIDE, train**

70 **SIDE, test**

60

Accuracy 50

40

30

20

1 11 21 31 41 51 61 71 81 91

Epochs


Figure 5: Comparison of training and testing curves between IDE and SPIDE on CIFAR-10 with
AlexNet-F structure and TF = 30.

F.2 COMPARISON TO IDE

Table 3 in Section 5 shows that the SPIDE method performs poorer than the original IDE
method (Xiao et al., 2021). We further investigate the training and testing curves during optimization to analyze this phenomenon. As shown in Figure 5, the SPIDE method could achieve the same
training accuracy as the IDE method, while the generalization performance is poorer. Since the hyperparameters are the same for experiments, except that we drop the modified BN component (as
explained in Section 4.4), the performance gap may be caused by the implicit regularization effect
of BN. Therefore, the optimization ability of the SPIDE method should be similar to that of IDE,
while future work would be to investigate how to realize operations similar to BN with possible
computation that could be friendly on neuromorphic hardware.

Also, we note that models trained by the IDE method (Xiao et al., 2021) have sparser spikes, as their
forward average firing rates are only around 1% (Xiao et al., 2021), while ours are around 7% as
shown in Figure 2. It is again probably due to BN which would subtract the statistical mean value
of neuron inputs, therefore regularizing the weights so that neurons will generate sparser spikes. An
interesting future work is to further reduce the number of spikes considering this phenomenon.

F.3 RESULTS ON CIFAR-100

Table 4: Performance on CIFAR-100. Results are based on 3 runs of experiments.

Method Network structure BN _TF_ _TB_ Mean±Std (Best) Neurons Params

BP (Thiele et al., 2019a) CIFARNet _×_ Unknown / (64.69%) 726K 45M
IDE (Xiao et al., 2021) CIFARNet-F ✓ 30 / 71.56%±0.31% (72.10%) 232K 14.8M

SpikeGrad (Thiele et al., 2019a) CIFARNet _×_ Unknown Unknown (64.40%) 726K 45M
**SPIDE (ours)** CIFARNet-F _×_ 30 100 63.57%±0.30%(63.91%) 232K 14.8M
**SPIDE (ours)** CIFARNet-F _×_ 30 250 64.00%±0.11%(64.07%) 232K 14.8M

In this section, we present the results on CIFAR-100. As shown in Table 4, our model could achieve
64.07% accuracy. Compared with IDE, the performance is poorer, and the main reason is probably
again the absence of BN which could be important for alleviating overfitting on CIFAR-100 with
relatively small number of images per class. The training accuracy of SPIDE is similar to IDE
(around 93% v.s. around 94%) while the generalization performance is poorer. Despite this, the
performance of our model is competitive for networks without BN and our model is with fewer
neurons and parameters and a small number of time steps. Compared with SpikeGrad (Thiele et al.,
2019a), we can use fewer neurons and parameters due to flexible network structure choices, and
we leverage common neuron models while they require complex impractical models. Future work
could investigate more suitable structures and if there are normalization techniques friendly for
neuromorphic computation and our desired algorithm to further improve the performance.


-----

F.4 RESULTS ON CIFAR10-DVS

In this section, we supplement some results on the spiking dataset CIFAR10-DVS (Li et al., 2017).
The CIFAR10-DVS dataset is the neuromorphic version of the CIFAR-10 dataset converted by a
Dynamic Vision Sensor (DVS), which is composed of 10,000 samples, one-sixth of the original
CIFAR-10. It consists of spike trains with two channels corresponding to ON- and OFF-event spikes.
The pixel dimension is expanded to 128 × 128. Following the common practice, we split the dataset
into 9000 training samples and 1000 testing samples. As for the data pre-processing, we reduce
the time resolution by accumulating the spike events (Fang et al., 2021) into 30 time steps, and we
reduce the spatial resolution into 48 × 48 by interpolation. We apply the random crop augmentation
as CIFAR-10 to the input data. We leverage the network structure: 512C9s (F512C5), where the
notations follow Appendix D.3. We train the model by SGD with momentum for 70 epochs. The
momentum is 0.9, the batch size is 128, the weight-decay is 5 × 10[−][4], and the initial learning rate is
0.05 which is decayed by 0.1 at the 50th epoch. No dropout is applied. The initialization of weights
follows the widely used Kaiming initialization. The constant for restriction in Appendix D.2 is
_c = 10 due to the large channel size, and the scale for the loss function as well as the firing thresholds_
and resting potentials are the same as the CIFAR-10 experiment.

Table 5: Performance on CIFAR10-DVS.

Method Model _TF_ _TB_ Accuracy

Gabor-SNN (Sironi et al., 2018) Gabor-SNN / / 24.5%
HATS (Sironi et al., 2018) HATS / / 52.4%
STBP (Wu et al., 2019) Spiking CNN (LIF, w/o NeuNorm) 40 / 58.1%
STBP (Wu et al., 2019) Spiking CNN (LIF, w/ NeuNorm) 40 / 60.5%
Tandem Learning (Wu et al., 2021) Spiking CNN (IF) 20 / 58.65%
Spike-based BP (Fang et al., 2021) Spiking CNN (PLIF, w/ BN) 20 / 74.8%

**SPIDE (ours)** Spiking CNN (IF) 30 250 60.7%

As shown in Table 5, our model could achieve 60.7% accuracy, which is competitive among results of common SNN models, demonstrating the effectiveness of our method. Fang et al. (2021)
leverages many techniques such as learnable membrane time constant, batch normalization, and
max pooling to achieve better performance. We do not aim at outperforming the state-of-the-art
results, but demonstrate that a competitive performance could be achieved even with our constraints
of purely spike-based training in a relatively small number of time steps, verifying the effectiveness.


-----


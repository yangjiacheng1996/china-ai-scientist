# QUERY EMBEDDING
## ON HYPER-RELATIONAL KNOWLEDGE GRAPHS

**Dimitrios Alivanistos[1, 4], Max Berrendorf[2], Michael Cochez[1,4], and Mikhail Galkin[3]**

1 Vrije Universiteit Amsterdam, 2 LMU Munich, 3 Mila, McGill University,
4 Discovery Lab, Elsevier
d.alivanistos@vu.nl, berrendorf@dbs.ifi.lmu.de,
m.cochez@vu.nl, mikhail.galkin@mila.quebec

ABSTRACT

Multi-hop logical reasoning is an established problem in the field of representation
learning on knowledge graphs (KGs). It subsumes both one-hop link prediction
as well as other more complex types of logical queries. However, existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often
employ a hyper-relational modeling paradigm. In this paradigm, typed edges may
have several key-value pairs known as qualifiers that provide fine-grained context
for facts. In queries, this context modifies the meaning of relations, and usually
reduces the answer set. Hyper-relational queries are often observed in real-world
KG applications, and existing approaches for approximate query answering (QA)
cannot make use of qualifier pairs. In this work, we bridge this gap and extend the
multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new
type of complex queries. Building upon recent advancements in Graph Neural
Networks and query embedding techniques, we study how to embed and answer
hyper-relational conjunctive queries. Besides that, we propose a method to answer
such queries and demonstrate in our experiments that qualifiers improve QA on a
diverse set of query patterns.

1 INTRODUCTION

Query embedding (QE) on knowledge graphs (KGs) aims to answer logical queries using neural
reasoners instead of traditional databases and query languages. Traditionally, a KG is initially loaded
into a database that understands a particular query language, e.g., SPARQL. The logic of a query is
encoded into conjunctive graph patterns, variables, and common operators such as joins or unions.

On the other hand, QE bypasses the need for a database or query engine and performs reasoning
directly in a latent space by computing a similarity score between the query representation and entity
_representations[1]. A query representation is obtained by processing its equivalent logical formula_
where joins become intersections (∧), and variables are existentially quantified (∃). A flurry of
recent QE approaches (Hamilton et al., 2018; Ren et al., 2020; Ren & Leskovec, 2020; Kotnis et al.,
2020; Arakelyan et al., 2021) expand the range of supported logical operators and graph patterns.

However, all existing QE models work only on classical, triple-based KGs. In contrast, an increasing amount of publicly available (Vrandeˇci´c & Kr¨otzsch, 2014; Suchanek et al., 2007) and industrial
KGs adopt a hyper-relational modeling paradigm where typed edges may have additional attributes,
in the form of key-value pairs, known as qualifiers. Several standardization efforts embody this
paradigm, i.e., RDF* (Hartig, 2017) and Labeled Property Graphs (LPG)[2], with their query languages SPARQL* and GQL, respectively. Such hyper-relational queries involving qualifiers are
instances of higher-order logical queries, and so far, there has been no attempt to bring neural reasoners to this domain.

In this work, we bridge this gap and propose a neural framework to extend the QE problem to
hyper-relational KGs enabling answering more complex queries. Specifically, we focus on logical

1Existing QE approaches operate only on the entity level and cannot have relations as variables
[2https://www.iso.org/standard/76120.html](https://www.iso.org/standard/76120.html)


-----

Figure 1: Triple-based (left) and hyper-relational (right) queries. The answer set of the hyperrelational query is reduced with the addition of a qualifier pair, and the final query representation
moves closer to the narrowed down answer.

queries that use conjunctions (∧) and existential quantifiers (∃), where the function symbols are
parameterized with the qualifiers of the relation. This parameterization enables us (cf. Fig. 1) to
answer queries like What is the university U where the one who discovered the law of the photoelec_tric effect L got his/her BSc. degree?, which can be written as ?U : ∃P.discovered by(L, P_ ) ∧
`educated at{(degree:BSc)}(P, U` ).

Our contributions towards this problem are four-fold. First, as higher-order queries are intractable
at practical scale, we show how to express such queries in terms of a subset of first-order logic
(FOL) well-explored in the literature. Second, we build upon recent advancements in Graph Neural
Networks (GNNs) and propose a method to answer conjunctive hyper-relational queries in latent
space. Then, we validate our approach by demonstrating empirically that qualifiers significantly
improve query answering (QA) accuracy on a diverse set of query patterns. Finally, we show the
robustness of our hyper-relational QA model to a reification mechanism commonly used in graph
databases to store such graphs on a physical level.

2 RELATED WORK

**Query Embedding. The foundations of neural query answering and query embeddings laid in**
GQE (Hamilton et al., 2018) considered conjunctive (∧) queries with existential (∃) quantifiers
modeled as geometric operators based on Deep Sets (Zaheer et al., 2017). Its further extension,
QUERY2BOX (Ren et al., 2020), proposed to represent queries as hyper-rectangles instead of points
in a latent space. Geometrical operations on those rectangles allowed to answer queries with disjunction (∨) re-written in the Disjunctive Normal Form (DNF). Changing the query representation
form to beta distributions enabled BETAE (Ren & Leskovec, 2020) to tackle queries with negation
(¬). Another improvement over QUERY2BOX as to answering entailment queries was suggested in
EMQL (Sun et al., 2020) by using count-min sketches.

The other family of approaches represents queries as Directed Acyclic Graphs (DAGs).
MPQE (Daza & Cochez, 2020) assumes variables and targets as nodes in a query graph and applies an R-GCN (Schlichtkrull et al., 2018) encoder over it. It was shown that message passing
demonstrates promising generalization capabilities (i.e., when training only on 1-hop queries and
evaluating on more complex patterns). Additional gains are brought when the number of R-GCN
layers is equal to the graph diameter. Treating the query DAG as a fully-connected (clique) graph,
BIQE (Kotnis et al., 2020) applied a Transformer encoder (Vaswani et al., 2017) and allowed to
answer queries with multiple targets at different positions in a graph.

Finally, CQD (Arakelyan et al., 2021) showed that it is possible to answer complex queries without
an explicit query representation. Instead, CQD decomposes a query in a sequence of reasoning steps
and performs a beam search in a latent space of KG embeddings models pre-trained on a simple 1

-----

hop link prediction task. A particular novelty of this approach is that no end-to-end training on
complex queries is required, and any trained embedding model of the existing abundance (Ali et al.,
2020; Ji et al., 2020) can be employed as is.

Still, all of the described approaches are limited to triple-based KGs while we extend the QE problem
to the domain of hyper-relational KGs. As our approach is based on query graphs, we investigate
some of MPQE observations as to query diameter and generalization (see also Appendix G).

**Hyper-relational KG Embedding. Due to its novelty, embedding hyper-relational KG is a field of**
ongoing research. Most of the few existing models are end-to-end decoder-only CNNs (Rosso et al.,
2020; Guan et al., 2020) limited to 1-hop link prediction, i.e., embeddings of entities and relations
are stacked and passed through a CNN to score a statement. On the encoder side, we are only aware
of STARE (Galkin et al., 2020) to work in the hyper-relational setting. STARE extends the message
passing framework of CompGCN (Vashishth et al., 2020) by composing qualifiers and aggregating
their representations with the primary relation of a statement.

Inspired by the analysis of (Rosso et al., 2020), we take a closer look at comparing hyper-relational
queries against their reified counterparts (transformed into a triple-only form). We also adopt
STARE (Galkin et al., 2020) as a basic query graph encoder and further extend it with attentional
aggregators akin to GAT (Veliˇckovi´c et al., 2018).

3 HYPER-RELATIONAL KNOWLEDGE GRAPHS AND QUERIES

**Definition 3.1 (Hyper-relational Knowledge Graph). Given a finite set of entities E, and a finite set of**
_relations R, let Q = 2[(][R×E][)]. Then, we define a hyper-relational knowledge graph as G = (E, R, S),_
_where S ⊂_ (E × R × E × Q) is a set of (qualified) statements.

For a single statement s = (h, r, t, qp), we call h, t ∈E the head and tail entity, and r ∈R the
_(main) relation. This also indicates the direction of the relation from head to tail. The triple (h, r, t)_
is also called the main triple. qp = _q1, . . ._ = (qr1, qe1), . . . is the set of qualifier
_{_ _}_ _{_ _} ⊂R × E_
_pairs, where_ _qr1, qr2, . . ._ are the qualifier relations and _qe1, qe2, . . ._ the qualifier values.
_{_ _}_ _{_ _}_

Hyper-relational KGs extend traditional KGs by enabling to qualify triples. In this work, we
solely use hyper-relational KGs and hence use ”KG” to denote this variant. The qualifier pair set
provides additional information for the semantic interpretation of the main triple (h, r, t). For instance, consider the statement (AlbertEinstein, educated at, ETHZurich, {(degree, BSc)}).
Here, the qualifier pair (degree, BSc) gives additional context on the base triple
(AlbertEinstein, educated at, ETHZurich) (also illustrated on Fig. 1).

Note that this statement can equivalently be written in first order logic (FOL).
Specifically, we can write it as a statement with a parameterized predicate
`educated at{(degree:BSc)}(AlbertEinstein, ETHZurich).` Then, we note that Q is a finite
set, meaning that also the number of different parameterizations for the predicate is finite, which
means that this becomes a first order logic statement. In this formalism, the KG is the conjunction
of all FOL statements. Possible monotonicity concerns are discussed in Appendix E.

We define a hyper-relational query on a hyper-relational KG as follows:[3]

**Definition 3.2 (Hyper-relational Query). Let V be a set of variable symbols, and TAR ∈V a special**
_variable denoting the target of the query. Let E_ [+] = E ⊎V. Then, any subset Q of (E [+] _×R×E_ [+] _×Q)_
_is a valid query if its induced graph 1) is a directed acyclic graph, 2) has a topological ordering in_
_which all entities (in this context referred to as anchors) occur before all variables, and 3) TAR must_
_be last in the topological orderings.[4]_

The answers A (Q) to the query Q are the entities e that can be assigned to TAR, for which
_G_ _∈E_
there exist a variable assignment for all other variables occurring in the query graph, such that the
instantiated query graph is a subgraph of the complete graph G.

3The queries considered here are a subset of SPARQL* basic graph pattern queries.
4These requirements are common in the literature, and usually stated with formal logic, but not a strict
requirement for our approach. See Appendix F for more information.


-----

degree BSc

**qr** **qe**

_q_ 1

**hq** **_Wq_**

Photo

electric effect ?var educatedAt _φr_ **hr,q** _= φr(r,hq)_ ?target

**r** 2

4 **mh→t,r,q**

**_Win_**

_r_ **Σ**

3


Figure 2: StarE layer intuition: (1) aggregation γq of qualifiers into a single vector; (2) aggregation
_φr of a main relation with a qualifiers vector; (3) composition of an enriched relation with the head_
entity; (4) final message to the tail node.

**Problem Definition. Given the incomplete KG G (part of the not observable complete KG** _G[ˆ]) and a_
query Q. Rank all entities in G such that answers to the query, if it were asked in the context of the

Since the given KG is not complete, we cannot solve this problem directly as a graph matchings r o qr1 qv1 qr2 qv2 <PAD> <PAD>
problem as usually done in databases. Instead, we compute a latent representation of the query, suchP69 **P512** **Q849697P812** **Q853077Q206702**


|Col1|Col2|Col3|Col4|
|---|---|---|---|


**qr1**

**R** Pooling

|×|E|Col3|×|
|---|---|---|---|


|hy|p|er|-p|
|---|---|---|---|


|h|Col2|Col3|t,|
|---|---|---|---|


|Col1|Col2|Col3|Col4|
|---|---|---|---|


|ead, we s which, but ra Encoder e consid an be s a Com StarE ntities R ∈ two re uting “ t, i.e ← ce of S|compute are the V|Col3|Col4|Col5|
|---|---|---|---|---|
||||||
||||||
||||||
||||||
||ther. .w. ith||||
||er|a|qu|er|
||een as a pGCRN (||||
||||||
||an|d|th|e|
||2||R||×|d,|
||R ...||||
||pr|es|en|ta|
||forward” ., invers TARE la||||



[+]qv1

**qr2**

**qv2**

Pooling

_∈_

_G_

**P69** **P512** **Q849697P812** **Q853077Q206702**

that it is close to the embeddings of entities which are the correct answers to the query.r **qr1** **qv1** **qr2** **qv2** **o**

ODEL DϕqESCRIPTIONϕq

∑

tion 5.1). Hence, to describe our model, we consider a queryWq

γ

Our model learns representations for entities and the special symbols (ϕr

[+2)][×][d], and relation representationsWλ **R**

**(r)**

_h, r, t, qp) ∈_ _Q_ ∑
to compute “backward” messages from h

**s** **Q937** _←_

_Q ⊂_ (

Query Linearization

, where

Transformer

TAR}),

, and the other one


from **E[ˆ]** the necessary embeddings. These correspond to the ones for all entities in the query, VAR if
the query has internal variables, and TAR for targets. The embeddings are then put in E, which also
contains one copy of VAR for each unique variable encountered in Q.

we only describe mh→t,r,qp, the other direction works analogously.r **r**

_∈_

**qr1** **h**

_qeqr1i],_

**qv1**

_Eqv1_

For φr we experiment with a simple sum aggregation, and an attention mechanism.


FC


_φ_

**qr2**


_φqr2r(_


_→_

_,rqv2,qp_

**qv2**

_qri]),_

. Next, we aggregate

Pooling

_r],_ **hq**
_{_

using another composition

_→_ _→_ _←_


StarE Encoder

**mh**

_m(_ **mh**
_{_


_, R[′]_
and m

= γq(

_qei_
**hrTransformer,qp**

[h]

(h, r, t


-----

Figure 3: The hyper-relational formulas and their graphical structures. The qualifier pairs attached
to each edge may vary in 0..n; for brevity we represent them as a single pair. We also allow qualifiers
to exist only on certain edges of a query, i.e., not all edges necessarily contain them.

ing a message aggregation function φm, e.g., a (weighted) sum. Besides computing these message aggregates in each direction, we also compute a self-loop update ae,⟲ = W⟲γr(e, r⟲),
where W⟲, r⟲ are trainable parameters. The updated entity representation is then obtained as
the average over both directions and the self loop, with an additional activation σ applied to it:
1
**E[′][e] = σ** 3 [(][a][e][,][⟲] [+][ a][e][,][→] [+][ a][e][,][←][)] Finally, the relation representations are updated by a linear

transformation R[′][r] = WrR[r], where Wr is a layer specific trainable weight.

  

**Query Representation.** After applying multiple STARE layers, we obtain enriched node representations E[∗] for all nodes in the query graph. As final query representation xQ, we aggregate all node representations of the query graph, xQ = φq({E[∗][e] | e ∈E [+] _∧_ ((e, r, t, qp) ∈
_Q ∨_ (h, r, e, qp) ∈ _Q)}), with φq denoting an aggregation function, e.g., the sum. Alternatively,_
we only select the final representation of the unique target node, xQ = E[∗][TAR]. To score answer
entity candidates, we use the similarity of the query representation and the entity representation, i.e.,
_score(Q, e) = sim(xQ, E[∗][e]), such as the dot product, or cosine similarity._

We designate the described model as STARQE (Query Embedding for RDF Star Graphs) since
RDF* is one of the most widely adopted standards for hyper-relational KGs.

5 EXPERIMENTS

In this section, we empirically evaluate the performance of QA over hyper-relational KGs. We
design experiments to tackle the following research questions: RQ1) Does QA performance benefit
from the use of qualifiers? RQ2) What are the generalization capabilities of our hyper-relational QA
approach? RQ3) Does QA performance depend on the physical representation of a hyper-relational
KG, i.e., reification?

5.1 DATASET

Existing QE datasets based on Freebase (Toutanova & Chen, 2015) and NELL (Carlson et al., 2010)
are not applicable in our case since their underlying KGs are strictly triple-based. Thus, we design
a new hyper-relational QE dataset based on WD50K (Galkin et al., 2020)[5] comprised of Wikidata
statements, with varying numbers of qualifiers.

**WD50K-QE. We introduce hyper-relational variants of 7 query patterns commonly used in the**
related work (Hamilton et al., 2018; Ren et al., 2020; Sun et al., 2020; Arakelyan et al., 2021)
where each edge can have [0, n] qualifier pairs. The patterns contain projection queries (designated
with -p), intersection queries (designated with -i), and their combinations (cf. Fig. 3). Note that
the simplest 1p pattern corresponds to a well-studied link prediction task. Qualifiers allow more
flexibility in query construction, i.e., we further modify formulas by conditioning the existence of
qualifiers and their amount over a particular edge. We include dataset statistics and further details
as to dataset construction in Appendices B and D.

These patterns are then translated to the SPARQL* format (Hartig, 2017) and used to retrieve materialized query graphs from specific graph splits. Following existing work, we make sure that
validation and test queries contain at least one edge unseen in the training queries, such that evaluated models have to predict new links in addition to QA. As we are in the transductive setup where

5This dataset is available under CC BY 4.0.


-----

Figure 4: Example of a reification process: An original hr-2p query pattern (left) is reified through
_standard RDF reification (right). Note the change of the graph topology: the reified variant has two_
blank nodes, three new pre-defined relation types, and original edge types became nodes connected
via the rdf : predicate edge. The distance between the anchor and target increased, too.

all entities and relation types have to be seen in training, we also ensure this for all entity and relation
types appearing in qualifiers.

Due to the (current) lack of standardized data storage format for hyper-relational (RDF*) graphs
in graph databases, particular implementations of RDF* employ reification, i.e, transformation of
hyper-relational statements as defined in Section 3 to plain triples. Reification approaches (Frey
et al., 2019) introduce auxiliary virtual nodes, new relation types, turn relations into nodes, and
might dramatically change the original graph topology. An example of a standard RDF reifica_tion (Brickley et al., 2014) in Fig. 4 transforms an original hr-2p query with three nodes, two_
edges, and two qualifier pairs into a new graph with nine nodes and eight edges with rigidly defined
edge types. However, the logical interpretation of a query remains the same. Therefore, we want
hyper-relational QE models to be robust to the underlying graph topology. For this reason, we ship
dataset queries in both formats, i.e., hyper-relational RDF* and reified with triples, and study the
performance difference in a dedicated experiment.

5.2 EVALUATION PROTOCOL

In all experiments, we evaluate the model in the rank-based evaluation setting. Each query is encoded into a query embedding vectortween the query embedding and the entity representation for each entity xq ∈ R. We compute a similarity score e ∈E. The rank sim(xq, E r[ ∈e]) be-N[+]
of an entity is its position in the list of entities sorted decreasingly by score. We compute filtered
ranks (Bordes et al., 2013), i.e., while computing the rank of a correct entity, we ignore the scores
of other correct entities. We resolve exactly equal scores using the realistic rank (Berrendorf et al.,
2020), i.e., all entities with equal score obtain the rank of the average of the first and last position.

Given a set of individual ranks {ri}i[n]=1[, we aggregate them into a single-figure measure using several]
different aggregation measures: The Hits@k (H@k) metric measures the frequency of ranks at most
_k_ N[+], i.e., H@k = _n1_ I[ri _k], with I denoting the indicator function. H@k lies between_
zero and one, with larger values showing better performance. The Mean Reciprocal Rank (MRR) is ∈ _≤_
the (arithmetic) mean over the reciprocal ranks, i.e.,P _MRR =_ _n[1]_ _ri−1, with a value range of (0, 1],_

and larger values indicating better results. It can be equivalently interpreted as the inverse harmonic
mean over all ranks, and thus is stronger influenced by smaller ranks.P

Since the size of the answer set of queries varies greatly,[6] queries with large answer sets would
strongly influence the overall score compared to very specific queries with a single entity as answer. In contrast to rank-based evaluation in existing QE work, we propose to weight each rank
in the aforementioned averages by the inverse cardinality of the answer set to compensate for their
imbalance. Thereby, each query contributes an equal proportion to the final score.

5.3 HYPER-RELATIONAL QA

As we are the first to introduce the problem of hyper-relational QA, there is no established baseline
available at the time of writing. Hence, we compare our method to several alternative approaches.

6For, e.g., hr-2p we observe a maximum answer set cardinality of 1,351, while the upper quartile is 3.


-----

Table 1: QA performance of STARQE and the baselines when training on all hyper-relational query
patterns. We omit the hr- prefix for brevity. Best results (excluding the Oracle) are marked in bold.

Pattern 1p 2p 3p 2i 3i 2i-1p 1p-2i

Hits@10 (%)

StarQE 51.72 **51.20** **65.50** 77.78 92.64 **61.81** **81.60**
Triple-Only 45.04 12.76 24.66 69.74 91.74 16.77 40.67
Reification **55.17** 50.86 63.65 **81.25** **95.31** 61.05 80.49
Zero Layers 44.93 29.94 38.45 67.79 90.66 35.48 47.85

Oracle 81.03 24.11 38.47 95.54 99.67 32.74 76.96

MRR (%)

StarQE 30.98 **44.13** **52.96** **63.14** 83.78 **55.20** **71.52**
Triple-Only 22.25 6.73 14.05 48.01 74.52 8.16 22.23
Reification **34.78** 43.42 50.77 61.01 **85.17** 49.09 64.21
Zero Layers 27.55 19.10 21.25 50.27 80.62 24.49 30.04

Oracle 79.16 18.40 23.72 90.43 97.91 21.10 54.74

**Implementation. We implement STARQE[7]** and other baselines in PyTorch (Paszke et al., 2019)
(MIT License). We run a hyperparameter optimization (HPO) pipeline on a validation set for each
model and report the best setup in the Appendix J. All experiments are executed on machines with
single GTX 1080 Ti or RTX 2080 Ti GPU and 12 or 32 CPUs.

**Triple-Only For the first experiment, we remove all qualifiers from the hyper-relational statements**
in the query graph leaving the base triples (h, r, t). Thus, we isolate the effect of qualifiers in
answering the queries correctly. Note that in effect, this is similar to the MPQE approach, but with a
better GNN and aggregation. To do this, we have to retain the same queries as in other experiments,
but remove the qualifiers upon loading. The set of targets for these queries remains unchanged, e.g.,
in the hyper-relational query from Fig. 1 we would drop the (degree:BSc) qualifier but still have
only ETHZurich as a correct answer.

**Reification. For the second setting, we convert the hyper-relational query graph to plain triples via**
reification (see Section 5.1). The effects of such a transformation include the addition of two extra
nodes per triple in the query, to represent blank nodes and predicates (more details in Appendix A).
Here, we investigate whether STARQE is able to produce the same semantic interpretation of a topologically different query. Note that, while conceptually the default relation enrichment mechanism
of STARQE resembles singleton property reification (Frey et al., 2019), its semantic interpretation
is equivalent to standard RDF reification.

**Zero Layers. To measure the effect of message passing, we consider a model akin to bag-of-words,**
which trains entity and relation embeddings without message passing before graph aggregation.

**Oracle. If we take away the qualifier information, we could compare with several QE approaches**
(e.g. GQE, MPQE, Query2box, BetaE, EmQL, and CQD). The Oracle setup, is not just an upper
bound to these, but to all possible, non-hyper-relational QE models. It simulates the best possible
QE model that has perfect link prediction and ranking capabilities, but without the ability to use
qualifier information. Using this setting we investigate the impact of qualifier information on our
queries. More details are in Appendix I.

**Discussion. The results shown in Table 1 indicate that STARQE is able to tackle hyper-relational**
queries of varying complexity. That is, the performance on complex intersection and projection
queries is often higher than that of a simple link prediction (hr-1p). Particularly, queries with
intersections (−i) demonstrate outstanding accuracy, but it should be noted here that also the Oracle
setting performs very well in this case. Importantly, MRR values are relatively close to Hits@10
which means that more precise measures like Hits@3 and Hits@1 retain good performance (we
provide a detailed breakdown in Appendix J).

[7STARQE implementation: https://github.com/DimitrisAlivas/StarQE](https://github.com/DimitrisAlivas/StarQE)


-----

Table 2: Results for the generalization experiment. Colored cells denote training query patterns
for each style, e.g., in the EMQL-style we train only on 1p and 2i patterns and evaluate on all. The
hr- prefix is omitted for brevity.

Evaluation Style 1p 2p 3p 2i 3i 2i-1p 1p-2i

Hits@10 (%)

StarQE-like 51.72 **51.20** 65.50 77.78 92.64 **61.81** **81.60**
Q2B-like 55.44 51.10 **66.39** 78.79 94.20 57.49 80.49
EmQL-like 50.10 16.45 44.36 75.86 93.55 6.79 62.80
MPQE-like 48.48 12.57 34.19 83.04 96.32 14.75 61.02
MPQE-like + Reif **58.43** 12.02 31.14 **83.77** **97.22** 13.50 50.92

MRR (%)

StarQE-like 30.98 **44.13** **52.96** **63.14** 83.78 **55.20** **71.52**
Q2B-like 33.04 41.99 51.71 61.72 83.49 44.24 67.04
EmQL-like 32.01 10.09 27.94 61.45 **86.28** 3.73 53.58
MPQE-like 26.83 6.79 19.72 56.16 74.35 9.62 39.81
MPQE-like + Reif **36.36** 6.12 17.11 56.81 77.29 8.32 29.25

To investigate if this performance could be attributed to the impact of qualifiers, we run a Triple_Only and Oracle setup. These experiments show that for some query patterns, qualifiers play an_
important role. Without them, we would not be able to get good results for the 2p, 3p, 2i-1p and
1p-2i queries. The reason that the Oracle cannot answer these well is that despite its access to
the test set, the mistakes it makes accumulate when there are more hops akin to beam search (recall
that the Oracle does not have access to qualifiers and considers all edges with a given relation) . For
queries that only involve one reasoning step, we notice that the Oracle can, and hence a normal link
predictor might be able, to perform very well. When more paths intersect (2i and 3i), the chance of
making a mistake goes down. This observation is similar what can be seen in e.g., CQD (Arakelyan
et al., 2021), and can be ascribed to each of the different paths constraining the possible answer set,
while cancelling out mistakes. More experiments on qualifiers impact are reported in Appendix H.

We observe a comparative performance running the Reification baseline. It suggests that our QE
framework is robust to the underlying graph topology retaining the same logical interpretation of a
complex query. We believe it is a promising sign of enabling hyper-relational QA on a wide range
of physical graph implementations.

Finally, we find that message passing layers are essential for maintaining high accuracy as the Zero
_Layers baseline lags far behind GNN-enabled models. One explanation for this observation can_
be that without message passing, variable nodes do not receive any updates and are thus not ”resolved” properly. To some extent counter-intuitively, we also observed that it does not make a large
difference whether relation embeddings are included in the aggregation or not. Relatively high
performance on 1p, 2i, 3i queries can be explained by their very specific star-shaped query
pattern which is essentially 1-hop with multiple branches joining at the center node.

5.4 GENERALIZATION

Following the related work, we experiment with how well our approach can generalize to complex
query patterns if trained on simple ones. Note that below we understand all query patterns as hyperrelational, i.e., having the hr- prefix. There exist several styles for measuring generalization in the
literature that we include in the experiment:

**Q2B-like. The style is used by QUERY2BOX (Ren et al., 2020) and assumes training only on**
1p,2p,3p,2i,3i queries while evaluating on two additional patterns 2i-1p, 1p-2i.

**EmQL-like. The other approach proposed by EMQL (Sun et al., 2020) employs only 1p, 2i**
patterns for training, using five more complex ones for evaluation.


-----

**MPQE-like. The hardest generalization setup used in MPQE (Daza & Cochez, 2020) allows train-**
ing only on 1p queries, i.e., vanilla link prediction, while all evaluation queries include unseen
intersections and projections.

**MPQE-like + Reif. To measure the impact of reification on generalization, we also run the exper-**
iment on reified versions of all query patterns. Similarly to MPQE-like, this setup allows training
only on 1p reified pattern and evaluates the performance on other, more complex reified patterns.

**Discussion. Table 2 summarizes the generalization results. As reference, we include the STARQE**
results in the no-generalization setup when training and evaluating on all query patterns. Generally,
we observe that all setups generalise well on intersection queries (-i) even when training in the most
restricted (1p) mode. The Q2B-like regime demonstrates appealing generalization capabilities on
(2i-1p, 2p-1i), indicating that it is not necessary to train on all query types. However, moving
to a fine-grained study of most impactful patterns, we find that projection (-p) patterns are rather
important for generalization, as both EmQL and MPQE styles dramatically fall behind in accuracy,
especially in the MRR metric indicating that higher precision results are impaired the most.

The MPQE style is clearly the hardest when having only one training pattern. The higher results
on intersection (-i) patterns can be explained by a small cardinality of the answer set, i.e., qualifiers make a query very selective with very few possible answers. Finally, it appears that reification
(MPQE+ Reif ) impedes generalization capabilities and overall accuracy according to the MRR results. This can be explained by the graph topologies produced when reifying complex queries, and
training only on 1p is not sufficient.

6 LIMITATIONS & FUTURE WORK

In this section, we discuss limitations of the current work, and future research directions. The first
limitation of our work is that we do not allow literal values like numbers, text, and time in our graph.
This means that we cannot, for example, handle queries asking for people born in the year 1980.
These and more complex values can be incorporated as node features (Wilcke et al., 2020).

Secondly, more logical operators, such as negation (which could be included as a qualifier), disjunctions, cardinality constraints, etc. can be considered. In this work, we only allow variables in the
head and tail positions. Nonetheless, one can also formulate queries with variables in more diverse
positions, e.g., qualifier value or main relation.

Moreover, the current work allows for different query shapes compared to prior work because
queries are not limited to DAGs (see Appendix F for details). However, our work does not allow all
shapes. Specifically, it is currently unclear how queries with cycles would behave.

Another future direction can be found in the many operators which query languages like SPARQL
have. For example, queries including paths, aggregations, sub-queries, filters on literals, etc. Further
research work is required towards explainability. Currently, our system does not provide explanations to the answers. An initial direction is to analyse the intermediate values in variable positions
which can be used as explanations, but likely need to be explicitly trained to behave that way. Finally, an interesting research direction is the use of our approach for the creation of query plans.

7 CONCLUSION

In this work, we have studied and addressed the extension of the multi-hop logical reasoning problem
to hyper-relational KGs. We addressed the theoretical considerations of having qualifiers in the
context of QA and discussed the effects it can have on it, such as cardinality of the answer set.
We proposed the first hyper-relational QE model, STARQE, based on a GNN encoder to work in
this new setup. We introduced a new dataset, WD50K-QE, with hyper-relational variants of 7 well
studied query patterns and analysed the performance of our model on each of them. Our results
suggest that qualifiers help in obtaining more accurate answers compared to triple-only graphs. We
also demonstrate the robustness of our approach to structural changes involved in the process of
reification. Finally, we evaluate the generalisation capabilities of our model in all settings and find
that it is able to accurately answer unseen patterns.


-----

**Reproducibility Statement. The experimental setup and implementation details are described in**
Section 5. We elaborate on the dataset construction process in Appendices B and C. All hyperparameters are listed in Table 6. The complete source code is available for reviewers in the supplementary
material, and will be made available open source. More experimental evidence is provided in Appendix H and more detailed metrics per query pattern are listed in Appendix J.

**Ethics Statement. The assumption of our approach as well as related techniques is that the data**
used for training solely contains true facts. If this data is (intentionally) biased or erroneous to start
with, further biased or wrong information will be derived, which could lead to harmful conclusions
and decisions. Besides, even if the input data to the system is correct, the system could due to its
imperfections still derive incorrect answers to queries, which might, again lead to wrong conclusions. Hence, users of this technology must be made aware that answers to their queries are always
approximate, and this technology ought not to be used in a process where correctness is critical.

**Acknowledgements. This work has been funded by the Elsevier Discovery Lab and the German**
Federal Ministry of Education and Research (BMBF) under Grant No. 01IS18036A. The authors of
this work take full responsibilities for its content. For performing the experiments the authors made
use of the LISA system provided by SurfSara and the DAS cluster (Bal et al., 2016).

REFERENCES

Mehdi Ali, Max Berrendorf, Charles Tapley Hoyt, Laurent Vermue, Mikhail Galkin, Sahand Sharifzadeh, Asja Fischer, Volker Tresp, and Jens Lehmann. Bringing light into the dark: A largescale evaluation of knowledge graph embedding models under a unified framework. _CoRR,_
abs/2006.13365, 2020.

Erik Arakelyan, Daniel Daza, Pasquale Minervini, and Michael Cochez. Complex query answering
with neural link predictors. In International Conference on Learning Representations, 2021. URL
[https://openreview.net/forum?id=Mos9F9kDwkz.](https://openreview.net/forum?id=Mos9F9kDwkz)

H. Bal, D. Epema, C. de Laat, R. van Nieuwpoort, J. Romein, F. Seinstra, C. Snoek, and H. Wijshoff.
A medium-scale distributed system for computer science research: Infrastructure for the long
term. Computer, 49(05):54–63, may 2016. ISSN 1558-0814. doi: 10.1109/MC.2016.127.

Claude Berge. Hypergraphs: combinatorics of finite sets, volume 45. Elsevier, 1984.

Max Berrendorf, Evgeniy Faerman, Laurent Vermue, and Volker Tresp. Interpretable and fair
comparison of link prediction or entity alignment methods with adjusted mean rank. _CoRR,_
[abs/2002.06914, 2020. URL https://arxiv.org/abs/2002.06914.](https://arxiv.org/abs/2002.06914)

Antoine Bordes, Nicolas Usunier, Alberto Garc´ıa-Dur´an, Jason Weston, and Oksana Yakhnenko.
Translating embeddings for modeling multi-relational data. In Christopher J. C. Burges, L´eon
Bottou, Zoubin Ghahramani, and Kilian Q. Weinberger (eds.), Advances in Neural Information
_Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013._
_Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States, pp._
2787–2795, 2013.

Dan Brickley, Ramanathan V Guha, and Brian McBride. RDF schema 1.1. W3C recommendation,
25:2004–2014, 2014.

Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M.
Mitchell. Toward an architecture for never-ending language learning. In Maria Fox and David
Poole (eds.), Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI
_2010, Atlanta, Georgia, USA, July 11-15, 2010. AAAI Press, 2010._

Daniel Daza and Michael Cochez. Message passing query embedding. In ICML Workshop

_- Graph Representation Learning and Beyond, 2020._ [URL https://arxiv.org/abs/](https://arxiv.org/abs/2002.02406)
[2002.02406.](https://arxiv.org/abs/2002.02406)

Fredo Erxleben, Michael G¨unther, Markus Kr¨otzsch, Julian Mendez, and Denny Vrandecic. Introducing wikidata to the linked data web. In Peter Mika, Tania Tudorache, Abraham Bernstein, Chris Welty, Craig A. Knoblock, Denny Vrandecic, Paul Groth, Natasha F. Noy, Krzysztof


-----

Janowicz, and Carole A. Goble (eds.), The Semantic Web - ISWC 2014 - 13th International Se_mantic Web Conference, Riva del Garda, Italy, October 19-23, 2014. Proceedings, Part I, vol-_
ume 8796 of Lecture Notes in Computer Science, pp. 50–65. Springer, 2014. doi: 10.1007/
[978-3-319-11964-9\ 4. URL https://doi.org/10.1007/978-3-319-11964-9_4.](https://doi.org/10.1007/978-3-319-11964-9_4)

Johannes Frey, Kay M¨uller, Sebastian Hellmann, Erhard Rahm, and Maria-Esther Vidal. Evaluation
of metadata representations in RDF stores. Semantic Web, 10(2):205–229, 2019.

Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck, and Jens Lehmann. Message passing for hyper-relational knowledge graphs. In Bonnie Webber, Trevor Cohn, Yulan He,
and Yang Liu (eds.), Proceedings of the 2020 Conference on Empirical Methods in Natural Lan_guage Processing, EMNLP 2020, Online, November 16-20, 2020, pp. 7346–7359. Association_
for Computational Linguistics, 2020.

Saiping Guan, Xiaolong Jin, Jiafeng Guo, Yuanzhuo Wang, and Xueqi Cheng. Neuinfer: Knowledge inference on n-ary facts. In Proceedings of the 58th Annual Meeting of the Association for
_Computational Linguistics, pp. 6141–6151, 2020._

William L. Hamilton, Payal Bajaj, Marinka Zitnik, Dan Jurafsky, and Jure Leskovec. Embedding
logical queries on knowledge graphs. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle,
Kristen Grauman, Nicol`o Cesa-Bianchi, and Roman Garnett (eds.), Advances in Neural Informa_tion Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018,_
_NeurIPS 2018, December 3-8, 2018, Montr´eal, Canada, pp. 2030–2041, 2018._

Olaf Hartig. Foundations of RDF* and SPARQL*:(an alternative approach to statement-level metadata in RDF). In AMW 2017 11th Alberto Mendelzon International Workshop on Foundations
_of Data Management and the Web, Montevideo, Uruguay, June 7-9, 2017., volume 1912. Juan_
Reutter, Divesh Srivastava, 2017.

Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and Philip S. Yu. A survey on knowledge
graphs: Representation, acquisition and applications. CoRR, abs/2002.00388, 2020.

Bhushan Kotnis, Carolin Lawrence, and Mathias Niepert. Answering complex queries in knowledge
graphs with bidirectional sequence encoders. CoRR, abs/2004.02596, 2020.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K¨opf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance
deep learning library. In Advances in Neural Information Processing Systems 32: Annual Con_ference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019,_
_Vancouver, BC, Canada, pp. 8024–8035, 2019._

Hongyu Ren and Jure Leskovec. Beta embeddings for multi-hop logical reasoning in knowledge
graphs. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and
Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Con_ference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,_
_virtual, 2020._

Hongyu Ren, Weihua Hu, and Jure Leskovec. Query2box: Reasoning over knowledge graphs in
vector space using box embeddings. In 8th International Conference on Learning Represen_tations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL_
[https://openreview.net/forum?id=BJgr4kSFDS.](https://openreview.net/forum?id=BJgr4kSFDS)

Paolo Rosso, Dingqi Yang, and Philippe Cudr´e-Mauroux. Beyond triplets: hyper-relational knowledge graph embedding for link prediction. In Proceedings of The Web Conference 2020, pp.
1885–1896, 2020.

Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max
Welling. Modeling relational data with graph convolutional networks. In European semantic web
_conference, pp. 593–607. Springer, 2018._


-----

Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic knowledge.
In Proceedings of the 16th international conference on World Wide Web, pp. 697–706, 2007.

Haitian Sun, Andrew O. Arnold, Tania Bedrax-Weiss, Fernando Pereira, and William W. Cohen.
Faithful embeddings for knowledge base queries. In Hugo Larochelle, Marc’Aurelio Ranzato,
Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information
_Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020,_
_NeurIPS 2020, December 6-12, 2020, virtual, 2020._

Kristina Toutanova and Danqi Chen. Observed versus latent features for knowledge base and text
inference. In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their
_Compositionality, pp. 57–66, Beijing, China, July 2015. Association for Computational Lin-_
[guistics. doi: 10.18653/v1/W15-4007. URL https://www.aclweb.org/anthology/](https://www.aclweb.org/anthology/W15-4007)
[W15-4007.](https://www.aclweb.org/anthology/W15-4007)

Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and Partha P. Talukdar. Composition-based multirelational graph convolutional networks. In 8th International Conference on Learning Represen_tations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020._

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von
Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman
Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on
_Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp._
5998–6008, 2017.

Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li`o, and Yoshua
Bengio. Graph attention networks. In International Conference on Learning Representations,
[2018. URL https://openreview.net/forum?id=rJXMpikCZ.](https://openreview.net/forum?id=rJXMpikCZ)

Denny Vrandeˇci´c and Markus Kr¨otzsch. Wikidata: a free collaborative knowledgebase. Communi_cations of the ACM, 57(10):78–85, 2014._

W. X. Wilcke, P. Bloem, V. de Boer, R. H. van t Veer, and F. A. H. van Harmelen. End-to-end entity
classification on multimodal knowledge graphs, 2020.

Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov,
and Alexander J Smola. Deep sets. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30,
[pp. 3391–3401. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/](http://papers.nips.cc/paper/6931-deep-sets.pdf)
[6931-deep-sets.pdf.](http://papers.nips.cc/paper/6931-deep-sets.pdf)

APPENDIX

A TYPES OF GRAPHS

In this section, we discuss in further detail the different approaches to break free from the restriction
of pairwise relations. The intuition how those approaches are different is presented in Fig. 5.

**Hyper-relational Graphs** KGs used in our work are a subset of hyper-relational graphs. In general, hyper-relational graphs can also contain literal values, like integers and string values as qualifier
values. Labeled property graphs are another example of a subset of hyper-relation graphs, but they
typically only allow literals as qualifier values. The Wikidata model (Erxleben et al., 2014) and
RDF* (Hartig, 2017) allows for both literals and entities as values. Many implementations of RDF*
do make the monotonicity assumption, which we also made in the paper. Some will also merge
statements in case they have the same main triple. The resulting statement will have the same main
triple, but as qualifier information, the union of the sets of qualifier pairs of the original statements.


-----

Figure 5: The same query expressed in three different approaches. Hyper-relational (left), hypergraph (middle), and reified (right) graphs.

**Hypergraphs** Hypergraphs are another type of graphs, initially proposed by Berge (Berge, 1984),
where hyperedges link one or more vertices. These hyperedges group together sets of nodes in
a relation, but lose information of the particular roles that entities play in this relation. Besides,
each different composition of elements in the relation introduces a new hyperedge type, causing a
combinatorial explosion of these types.

**Reified Graphs** Hyper-relational and reified graphs have equivalent expressive power compared
to labelled directed graphs. The reason is that we can define a bijection between these graphs.
However, depending on the use case, the different graph types have benefits.

When we convert a hyper-relational graph to an RDF graph, we end up with what is called the
reified graph. There are multiple approaches on how to perform this conversion. In our work, we
use Standard RDF Reification[8]. It introduces new, so called blank nodes to represent statements
with all parts of a statement attached. This allows for all information to exist on the same level.
One of the disadvantages to this approach is the addition of auxiliary nodes, which heavily affect the
structure of the graph and quickly inflate the graph size.

B THE WD50K-QE DATASET

In this section, we describe the generation of the hyper-relational queries that we use for training, validation and testing of our models. We start with WD50K (Galkin et al., 2020), which is a
WikiData-based dataset created for hyper-relational link prediction. This dataset already provides
with train, validation and test splits, each containing a selection of hyper-relational triples. It is
publicly available by the authors, in CSV format. In order to utilise it for our work, we converted it
from CSV to RDF*.

The overall pipeline is presented on Fig. 6. To generate the queries, we hosted the converted dataset
on a graph database with support for hyper-relational data. For our use-case, we use anzograph[9].
We utilize 3 named graphs[10]: triple train, triple validation, and triple test, to prevent validation and
test set leakage. In the evaluation of approximate QA, it is common to have queries with at least
**one unseen edge from the test set, which is also applied upon our query generation process. We**
ensure that:

-  For the training set, all statements in a query come from the triple train set (only).

-  For the validation set, one statement comes from the triple validation and the other edge(s)
come from either triple train or triple validation, and

[8https://www.w3.org/TR/2014/REC-rdf11-mt-20140225/#reification](https://www.w3.org/TR/2014/REC-rdf11-mt-20140225/#reification)
[9https://www.cambridgesemantics.com/anzograph/](https://www.cambridgesemantics.com/anzograph/)
[10https://www.w3.org/TR/rdf11-concepts/#section-dataset](https://www.w3.org/TR/rdf11-concepts/#section-dataset)


-----

Figure 6: A diagram of the query generation process. On the far left, the chosen dataset (WD50K)
is uploaded in the RDF*-compatible triplestore (AnzoGraph). As a follow up, we translated the
hyper-relational query patterns to SPARQL* and executed them against the triplestore to retrieve
the desired splits.

Pattern 1p 2p 3p 2i 3i 2i-1p 1p-2i

train 24, 819 313, 088 5, 950, 990 48, 513 318, 735 306, 022 1, 088, 539
validation 4, 100 100, 706 2, 968, 315 15, 648 169, 195 169, 438 569, 957
test 7, 716 202, 045 6, 433, 476 38, 207 547, 272 445, 007 1, 267, 452

Table 3: The amount of queries for each of the different query patterns. We notice that for some
patterns there are many more queries than for others, which is also why we report results for the
patterns separately.

-  For the test set, one statement comes from triple test, and the other statement from any of
_triple train, triple validation, and triple test_

In order to generate the query data splits, we constructed SPARQL* queries that correspond to a
specific pattern. We call these higher order queries formulas. Using these formulas to generate
queries has several advantages compared to other approaches found in related work. In the related
work, we encounter sampling using techniques such as random walks to create queries which have
the shape according to the pattern. With our approach, we have more control over what the samples
are, and thus a finer control of the inputs to our experiments.

Moreover, we can also ensure that we do not sample with replacement, we are not biased towards
specific high degree nodes, and at the same time guarantee that we do not sample queries that are
isomorphic with each other. A final benefit is that with our approach, we can immediately retrieve
all answers for a query, instead of only one.

One final issue we encountered had to do with the nodes that have a high in-degree in our dataset.
Their existence causes a skewing of the distribution of correct answers to queries, and has to be
resolved. In Appendix C, we describe this issue and explain our approach to overcome it.

As a result of this procedure, we obtain all queries of the given shapes, and are guaranteed that there
are no duplicates nor isomorphism among the queries. The queries used in this paper are such that
every edge in the query has one qualifier, which means that, in the knowledge graph, the same edge
has at least one, but possibly more qualifiers. The amount of queries for the different patterns can
be found in Table 3.


-----

C ISSUES SAMPLING QUERIES WITH JOINS IN A GRAPH WITH HIGH
DEGREE NODES

In our query generation step, we exclude high in-degree nodes as a target for specific queries. In this
section, we explain why that choice was made. We will focus on the 3i pattern. The same argument
holds for other patterns with joins, like 2i, 2i-1p, 1p-2i.

The queries are randomly sampled from all possible queries that can be formed by matching the
pattern with the data graph. For the 3i pattern, a node with an in-degree of n, results in _n3_ different
queries, with that node as a target.
  

The problem is that if we randomly sample our queries, the answer would usually be one of the
highest degree nodes. Concretely, in our graph data, the highest observed in-degree is 4,424, which
would result in 14,421,138,424 possible queries with the corresponding node as an answer. If we
generated all possible queries, we would end up with 38,011,148,464 different ones. So, the node
with the highest in-degree is already responsible for 38% of the queries, meaning that system answering 3-i queries that are randomly sampled, would get 38% correct by always giving that answer.
Moreover, if we look at the Hits@10 metric, we would score 93%, by always predicting the same
ranking (the top 10 in descending frequency). Note that existing query embedding models have been
evaluated like this in the past, ignoring this data issue.

Hence, we decided to make the task harder by removing these high degree nodes for queries with
joins. That is, by putting the threshold at an in-degree of 50, we remove the 623 nodes with the
highest in-degree which would have represented 99.9% of the possible answers for the 3i queries
without this modification. After filtering, the baseline of always predicting the same ranking for the
randomly sampled queries, will result in a Hits@10 of 3% in the best case.

For other query shapes where a join is involved, the situation is similar, but less pronounced.

D SIZE OF THE ANSWER SET OF A QUERY WITH MORE QUALIFIERS

When we have a query with or without qualifiers, and we add more qualifiers, the number of answers
to this query can only become smaller. Intuitively, this happens because the query becomes more
specific. In this section we prove this intuition correct. Note that proving this requires monotonicity,
as we defined in the paper. Without this assumption - for example allowing non-monotonic qualifier
relations - would result in losing the guarantee that the answer set becomes smaller.

Given a query Q, and a query Q that is the same, except for one set of qualifier pairs of Q which can
have extra pairs, then the answers to Q are a subset of the answers to Q.

Formally:

**Theorem D.1.** _Given a KG G_ = (E, R, S), _where S_ _⊂_ (E × R × E × Q),
_a_ _query_ _Q_ = (h1, r1, t1, qp1), . . . (hn, rn, tn, qpn) _,_ _and_ _a_ _second_ _query_
_{_ _}_

_Q = {(h1, r1, t1, qp1), . . . (hn, rn, tn, qpn)}, where ∃!k : qpk ⊆_ _qpk and ∀x((x ∈_ [1, . . . n] ∧ _x ̸=_
_k)_ _qpx = qpx). Then, A_ (Q) _A_ (Q).
_→_ _G_ _⊆_ _G_

_Proof. Assuming symbols as defined in the theorem, we show that_ _a : a_ _A_ (Q) =
_∀_ _∈_ _G_ _⇒_
_a_ _A_ (Q). If a is an answer to Q, then its associated variable substitution v is such that
_∈_ _G_
(know thatv(hk), rk (, vv((thkk), qp), rkk, v) ∈G(tk). From monotonicty (see Appendix E), and given, qpk) . And hence, using the same variable substitution, qpk ⊆ _qpk we then a is an_
_∈G_
answer for Q.

**Corollary D.1. By induction, given a query Q, and a query Q that is the same, except for any set of**
_qualifier pairs of Q which can have extra pairs, then the answers to Q are a subset of the answers_
_to Q._

**Corollary D.2. As a special case, given a query Q, and a query Q that is the same, except that Q**
_does not have qualifiers, while Q can have qualifier pairs on its statements, then the answers to Q_
_are a subset of the answers to Q._


-----

_r2_ _r3_

_r2[−][1]_ _r3[−][1]_



_r1_

_e1_ TAR VAR1 _e3_


Figure 7: Visualization for Appendix F. Original query (black and red) violating the original definition of a valid query graph, and equivalently transformed query (black and blue) which fulfils the
properties becoming 1p-2i query.

E ON MONOTONICITY

In this work, we restrict the qualifiers to respect monotonicity in the KG in the following sense:

(h, r, t, qp) ∈G ∧ _qp[′]_ _⊆_ _qp =⇒_ (h, r, t, qp[′]) ∈G

This implies that if a qualified statement in the KG has a set of qualifier pairs, then the KG also
contains the qualified statement with any subset thereof. As a result, some types of qualifying
information cannot be used, e.g., a qualifier indicating that a relation does not hold (i.e., negation).
This breaks monotonicity since the existence of such a statement would further imply the existence
of that statement without the qualifier, leading to contradiction.

F RELAXING THE REQUIREMENTS ON QUERIES

In the paper, we limited our queries with the same limitations as done in prior work. Here we will
discuss why not all of these restrictions are needed for our work, and how our evaluation already
includes some of these more general cases.

As a reminder the definition of our queries is as follows:

**Definition F.1 (Hyper-relational Query). Let V be a set of variable symbols, and TAR ∈V a special**
_variable denoting the target of the query. Let E_ [+] = E ⊎V. Then, any subset Q of (E [+] _×R×E_ [+] _×Q)_
_is a valid query if its induced graph_

_1) is a directed acyclic graph,_

_2) has a topological ordering in which all entities (in this context referred to as anchors) occur_
_before all variables, and_

_3) TAR must be last in the topological orderings._

The main reason why we deal with more general queries is because our query encoder learns representation for both normal and inverse relations. We use r[−][1] to indicate the inverse of relation r.
When encoding a query with a (normal) relation r, then both representations R[r] and R[r[−][1]] are
used simultaneously. If we encounter a query using the inverse relation r[−][1], we can use that inverse
relation R[r[−][1]] and the inverse of the inverse R[ _r[−][1][][−][1]] = R[r], or in other words the normal_
relation representation of r. This means that even if we only ever train with the normal relation, we
 
have the ability to invert relations, and hence we can lift some limitations.

For example, let us look at the query

_Qnew pattern = {(e1, r1, TAR, {}), (TAR, r2, VAR1, {}), (VAR1, r3, e3, {})},_

as shown in Fig. 7. This query breaks two of the requirements. It has an entity e3 occurring after
variables VAR1 and TAR in the topological ordering. And, TAR is not in the last position.

However, using inverse relations, we can convert this query into:

_Qknown pattern =_ (e1, r1, TAR, {}), (VAR1, r2[−][1][,][ TAR][,][ {}][)][,][ (][e][3][, r]3[−][1][,][ VAR][1][,][ {}][)] _._



-----

This transformation converts the query into a 1p-2i query, which is a pattern among the evaluated
patterns in the paper. Because of this transformation, the pattern of Qnew pattern is indistinguishable
from the pattern of Qknown pattern from the perspective of the model. Besides the example illustrated
above, many other graphs can be converted into one of the patterns in the paper. Since we can
perform the conversion in both directions, all these possible patterns are also implicitly included in
our used datasets.

In principle, the encoder does also not assume that there are no cycles in the query graph. However,
the effect of cycles requires further investigation.

G NUMBER OF MESSAGE PASSING STEPS EQUAL TO THE DIAMETER

In Daza & Cochez (2020), the authors find that the best results are achieved when making the
number of message passing steps equal to the diameter of the query, defined as the longest shortest
path between 2 nodes in it. After these steps, they use the embedding of the target variable as
the embedding of the complete graph. Accordingly, we performed additional experiments with
this dynamic query embedding setting, and with a variant which uses an extra message passing
step. From these experiments we concluded that this approach did not lead to better results, which
contradicts with the findings in Daza & Cochez (2020).

H QUALIFIER IMPACT ON PERFORMANCE

For a more fine-grained analysis of qualifiers impact on query answering performance, for each
query pattern we ran an experiment measuring relative performance change in the presence and
absence of a given qualifier relation in a query. That is, the main results of StarQE in Table 1 assume
all qualifiers are enabled. Then, for each qualifier relation, we remove qualifier pairs containing this
relation from all queries in a given pattern and run a model forward pass to obtain new predictions.
We run such experiments 5 times for each relation, each metric, and each pattern to get an average
value with standard deviations. Finally, for each metric, we sort relations in the ascending order of
their performance increase.

Table 4 reports top-3 worst (i.e., first 3 relations in the sorted list) and top-3 best (last 3 relations in the
sorted list) qualifier relations that have the most impact along the metrics. For example, P1686 (for
work), a common qualifier of relation award received, increases Hits@10 performance in 1p2i queries by a large margin of 62% and MRR by 57% compared to queries without this qualifier.
The gains are consistent, although on a smaller scale, in other patterns, too. On the other hand, P453
(character role), a qualifier of cast member, seems to be the most confusing qualifier in
2p queries leading to lower scores across all metrics.

We note, however, that on a bigger picture (Fig. 8), where impact for all qualifier relations is visualized, total gains of having qualifiers outweigh negative effects from some of them.

metric = AMRI metric = H@10 metric = MRR

80%

60%

40%

20%

0%

Improvement

20%

40%

60%

1hop 1hop-2i 2hop 2i 2i-1hop 3hop 3i 1hop 1hop-2i 2hop 2i 2i-1hop 3hop 3i 1hop 1hop-2i 2hop 2i 2i-1hop 3hop 3i

pattern pattern pattern


Figure 8: A general overview of qualifiers impact on AMRI, Hits@10, and MRR. In all metrics,
higher deltas correspond to better prediction performance. Having qualifiers does, on average, lead
to better predictions.


-----

AMRI H@10 MRR
pattern relation improvement relation improvement relation improvement


1p [P1264P1346P518P453P805P17](https://www.wikidata.org/wiki/Property:P518) _−−−+ 2+ 2+ 4520......425308247502 ± ± ± ± ± ±_ 233200......580230097842 [P1264P1686P1346P2453P453P518](https://www.wikidata.org/wiki/Property:P1264) + 6+ 3+ 6+13+24+33......006484700403 ± ± ± ± ± ± 214134......507047198726 [P1264P1346P2453P518P453P17](https://www.wikidata.org/wiki/Property:P518) + 2+ 3+ 4+11+27+45......887812177882 ± ± ± ± ± ± 001243......869823300148

2p [P2241P1686P453P102P805P531](https://www.wikidata.org/wiki/Property:P453) _−−−+11+13+2464107......563504916214 ± ± ± ± ± ± 32 40 50 2326......263748796757_ [P1011P1686P459P453P122P837](https://www.wikidata.org/wiki/Property:P459) _−−−+45+47+47554......000049741555 ± ± ± ± ± ± 12 240052......003883762648_ [P3680P1552P1310P453P407P837](https://www.wikidata.org/wiki/Property:P453) _−−−+58+64+78200......384912053301 ± ± ± ± ± ±_ 771500......577750575559

3p [P2937P2241P102P453P805P92](https://www.wikidata.org/wiki/Property:P102) _−−+14+17−+16442......169577532365 ± ± ± ± ± ± 21 14 15 1222......845357787577_ [P1552P3823P155P812P937P122](https://www.wikidata.org/wiki/Property:P155) _−−+ 0+50+62+7200......006428854416 ± ± ± ± ± ± 11 420000......002700079932_ [P3680P1441P1310P3823P175P837](https://www.wikidata.org/wiki/Property:P3680) _−−−+65+76+76000......540771363002 ± ± ± ± ± ± 1071000......147165570446_

[P2715P4100P453](https://www.wikidata.org/wiki/Property:P2715) _−−_ 100...938567 ± ± 532...539006 [P3680P2614P291](https://www.wikidata.org/wiki/Property:P291) _−+ 0+ 00...000008 ± ±_ 000...000018 [P3680P291P459](https://www.wikidata.org/wiki/Property:P3680) _−−+ 000...090706 ± ±_ 110...111609

2i [P156P805P17](https://www.wikidata.org/wiki/Property:P156) _−+ 3+34+ 4...425608 ± ± ± ±_ 255...934346 [P1686P518P805](https://www.wikidata.org/wiki/Property:P518) +23+34+29...396449 ± ± ± ± 422...008232 [P1686P1264P805](https://www.wikidata.org/wiki/Property:P1686) +29+35+34...231953 ± ± ± ± 1611...986250

[P2241P4100P453](https://www.wikidata.org/wiki/Property:P453) _−−_ 210...183777 ± ± 451...010909 [P2241P4100P1534](https://www.wikidata.org/wiki/Property:P2241) _−−_ 300...443333 ± ± 411...477313 [P2241P3680P291](https://www.wikidata.org/wiki/Property:P2241) _−−_ 800...030100 ± ± 500...502700

3i [P1013P2842P805](https://www.wikidata.org/wiki/Property:P1013) _−+ 6+14+42...281344 ± ± ± ± 3642...063123_ [P3831P805P518](https://www.wikidata.org/wiki/Property:P805) _−+16+17+21...724994 ± ± ± ±_ 221...813542 [P1264P642P518](https://www.wikidata.org/wiki/Property:P642) _−+22+28+32...432688 ± ± ± ± 15 252...706804_

2i-1p [P2241P1686P459P805P366P131](https://www.wikidata.org/wiki/Property:P2241) _−−+24+10−+ 3510......583789298101 ± ± ± ± ± ±_ 654470......445781073002 [P1346P2453P1686P3680P837P39](https://www.wikidata.org/wiki/Property:P1346) _−−+56+62+ 0+5100......639800715305 ± ± ± ± ± ± 27 360000......735500911111_ [P3680P2453P1441P1686P837P39](https://www.wikidata.org/wiki/Property:P3680) _−+55+82+ 0+ 0+530......670340051132 ± ± ± ± ± ± 2302010......435860432031_

1p-2i [P2241P1013P453P654P805P17](https://www.wikidata.org/wiki/Property:P2241) _−−−+31+77+24332......249953563066 ± ± ± ± ± ± 46 10 21845......202348669126_ [P2241P1686P459P407P102P805](https://www.wikidata.org/wiki/Property:P459) _−−−+49+61+63663......046610633413 ± ± ± ± ± ± 12 14 14203......182038519140_ [P2241P1039P1686P805P837P92](https://www.wikidata.org/wiki/Property:P2241) _−−−+57+57+75830......303611573370 ± ± ± ± ± ±_ 103762......649891459465

Table 4: Top 3 worst and top 3 best impacting qualifier relations per pattern. In all metrics (AMRI,
H@10, MRR), positive value corresponds to better predictions. For some metrics, and given pat[terns we only see improvements in cases where qualifiers are included. The qualifier relation P453](https://www.wikidata.org/wiki/Property:P453)
(specific role played or filled by subject – as a “cast member” or “voice actor”) seems to confuse
[the model the most. On the other hand P805 (referring to an item that describes the relation identi-](https://www.wikidata.org/wiki/Property:P805)
_fied in the statement) often leads to the biggest improvements in the metrics. All relation names are_
clickable links to their Wikidata pages.


-----

I THE ORACLE SETUP

There are several QE methods we could compare our work with. However, these methods are
only able to answer queries utilising triple and not qualifier information. Besides, we see that new
methods are introduced regularly, each outperforming the previous method. Hence, we employ an
Oracle approach to compute the upper bound that triple only QE models can achieve on WD50KQE. This Oracle is simulating perfect link prediction and ranking capabilities but does not have
access to qualifier information.

To achieve this, the Oracle system has access to training, validation, as well as test data. Given the
access to the totality of the data, the system will return an optimal ordering, i.e., one that maximizes
our reported metrics. However, since the system cannot process qualifier information, the ordering
of the result set can only be based on the entities and relations in the query. This means that queries
that are the same when ignoring the qualifier information, will get the same list of answers. In effect,
the oracle will, despite its perfect information for a setting without qualifiers, not answer perfectly.
Using this setting we can hence investigate how much difference qualifier information makes for our
queries.

Finally, note that because multiple ordering can be considered optimal from the information the
Oracle has available, we report the expected value for these metrics.

J DETAILED RESULTS

We provide our chosen hyper-parameters after performing hyper-parameter optimisation in Table 6
and detailed results including standard deviation across five runs with different random seeds in Tables 7 and 8. We report Hits@k for k = 1, 3, 10, mean reciprocal rank (MRR), and adjusted mean
rank index (AMRI) (Berrendorf et al., 2020). For all metrics, larger values indicate better performance. We highlight the best result per column and metric in bold font.

For the Hits@k metric, we observe StarQE performing best across patterns, except for the most
simple ones, 1p (equivalent to plain link prediction), and 3i. Standard deviations are usually small
(around 1% point). The base triples baseline sometimes exhibits larger variances across multiple
random seeds. For MRR we make similar observations as for Hits@k, which is intuitive since it can
be seen as a soft version of H@k.

For AMRI, the picture differs slightly. AMRI is a linear transformation of the mean rank, which
normalizes the scores such that 0 corresponds to the performance of a random scoring model and
100% to the perfect score. Besides, AMRI preserves the linearity of mean rank, i.e., it is equally
influenced by improvements on any rank, not just at the top of the ranking. Across the board, we
observe values far beyond 50%, usually exceeding 90%. The general tendency of some patterns
being more difficult than others persists and is coherent with the other metrics. Comparing different
models, we can see that StarQE falls behind, e.g., reification and more simple baselines such as zerolayers, which do not use the graph structure. Since this behavior was not observed for the metrics
more focused on the top positions in ranking, the decrease in performance in this metric has to be
caused by entities that received large ranks in the first place.

Zooming in on the Oracle setup, we make several observations. First, it becomes increasingly harder
for the Oracle to produce good results for smaller values of k in the Hits@k metrics. Since this is an
upper bound to the Base triple setup, also that model shows similar behavior. The observation that
the intersection queries can still perform well is also visible in the more detailed results.

The very high AMRI for the Oracle is also expected. Since this model is designed as the best
possible ranking model, it will place all correct answers for the query (while ignoring qualifiers)
at the top of the ranking. This set of answers is a super set of the correct answers to the qualified
query (see Appendix D). Now, that set of answers is nearly always very small compared to the 50K
candidate entities in our dataset. So, relatively speaking the correct answers are still nearly always
ranked high, and hence we obtain a high AMRI score.


-----

K EVALUATING FAITHFULNESS

Following the idea of EmQL (Sun et al., 2020), we evaluate faithfulness of our hyper-relational
approach by evaluating its performance on the training set, that is, an ability to correctly answer
already seen queries. Evaluation on the training set is a suitable proxy for faithfulness since even
the union of training, validation and test queries (as done in the original work) is highly incomplete
considering the whole background graph (be in Freebase or Wikidata). To this end, we evaluate the
model trained in two regimes: StarQE-like trained on all query types and MPQE-like trained in the
hardest setting on only 1p link prediction queries. The results presented in Table 5 show that the
_StarQE-like model exhibits faithfulness saturating performance metrics to almost perfect results. As_
expected, training the model only on one query type inhibits faithfulness qualities.

Table 5: Full results for the faithfulness experiments, including standard deviation across five runs
with different random seeds. We report Hits@k for k = 1, 3, 10, mean reciprocal rank (MRR), and
adjusted mean rank index (AMRI) Berrendorf et al. (2020). For all metrics, larger values indicate
better performance.

Pattern 1p 2p 3p 2i 3i 2i-1p 1p-2i

Hits@1 (%)

StarQE-likeMPQE-like 7490..2743 ± ± 5 2..3010 948..5800 ± ± 1 0..8185 8919..9399 ± ± 2 2..2905 9487..2988 ± ± 1 1..6753 9992..3444 ± ± 0 1..2456 9613..0268 ± ± 1 0..4597 9965..0551 ± ± 0 2..4660

Hits@3 (%)

StarQE-likeMPQE-like 8496..0618 ± ± 4 1..6410 9814..1219 ± ± 0 1..4918 9632..5612 ± ± 0 2..8959 9797..4817 ± ± 1 0..1562 9999..8146 ± ± 0 0..1116 9818..7864 ± ± 0 1..5143 9985..8442 ± ± 0 1..0924

Hits@10 (%)

StarQE-likeMPQE-like 9098..9475 ± ± 4 0..1841 9922..3962 ± ± 0 1..1656 9847..9809 ± ± 0 3..3814 9999..1846 ± ± 0 0..6718 9999..9694 ± ± 0 0..0402 9923..6498 ± ± 0 1..2070 9994..9790 ± ± 0 0..0335

MRR (%)

StarQE-likeMPQE-like 8093..2358 ± ± 4 1..8552 9612..5188 ± ± 1 1..0906 9328..5088 ± ± 1 2..5136 9692..0970 ± ± 1 0..3294 9995..5993 ± ± 0 0..1781 9717..4736 ± ± 0 1..9523 9976..4554 ± ± 0 1..2774

AMRI (%)

StarQE-likeMPQE-like 10099..9700 ± ± 0 0..0300 9991..9977 ± ± 0 2..0029 9994..9964 ± ± 0 2..0059 100100..0000 ± ± 0 0..0000 100100..0000 ± ± 0 0..0000 10093..0097 ± ± 0 2..0009 10099..0099 ± ± 0 0..0000


-----

-----

-----

**87. 1** 29. 3 09. 5 40. 1 55. 1
_± ± ± ± ±_
**77.** 74.59 54.48 76.28 75.18
**65**

**73. 0** 88. 2 87. 0 58. 0 72. 0
_± ± ± ± ±_
**77.** 59.37 17.2 84.6 59.5
**51**

44. 1 46. 1 **63. 3** 23. 2 36. 1
_± ± ± ± ±_
58.78 36.77 **73.** 67.60 93.63
**81**

**26. 1** 45. 1 46. 3 49. 1 59. 0
_± ± ± ± ±_
**11.** 49.52 36.53 01.41 36.41
**55**

**81. 0** 98. 0 99. 4 59. 1 09. 2
_± ± ± ± ±_
**85.** 82.43 86.19 70.12 52.10
**45**

**27. 0** 65. 0 24. 2 38. 0 62. 0
_± ± ± ± ±_
**98.** 15.37 78.6 81.3 24.3
**39**

11. 1 70. 0 12. 1 48. 0 **36. 0**
_± ± ± ± ±_
91.20 63.21 06.23 53.16 **52.**
**25**
StarE-likeQ2B-likeemQL-likeMPQE-likeMPQE-like + Reif


**02. 1** 45. 2 31. 5 30. 1 60. 2
_± ± ± ± ±_
**35.** 20.71 96.55 88.44 31.32
**75**

**47. 0** 04. 3 05. 1 08. 1 59. 0
_± ± ± ± ±_
**89.** 99.46 80.3 08.10 56.8
**56**

74. 0 23. 1 87. 2 45. 1 **58. 0**
_± ± ± ± ±_
56.87 97.87 91.89 17.86 **07.**
**90**

93. 0 24. 1 18. 3 21. 1 **97. 0**
_± ± ± ± ±_
98.67 02.67 56.66 87.66 **14.**
**68**

**58. 0** 21. 1 37. 6 58. 2 69. 2
_± ± ± ± ±_
**34.** 41.55 47.30 48.21 25.18
**57**

**32. 0** 98. 0 23. 3 65. 0 82. 0
_± ± ± ± ±_
**41.** 75.43 73.10 15.7 34.6
**46**

82. 0 92. 0 11. 1 75. 0 **65. 0**
_± ± ± ± ±_
58.35 79.38 14.36 82.30 **26.**
**41**
StarE-likeQ2B-likeemQL-likeMPQE-likeMPQE-like + Reif


**60. 0** 92. 1 26. 5 70. 044. 3
_± ± ± ± ±_
**60.** 49.80 80.62 02.6192.50
**81**

**37. 0** 26. 2 13. 1 42. 181. 0
_± ± ± ± ±_
**81.** 49.57 79.6 75.1450.13
**61**

65. 0 86. 0 93. 1 77. 014. 0
_± ± ± ± ±_
64.92 20.94 55.93 32.9622.
**97**

53. 0 04. 1 45. 2 01. 147. 0
_± ± ± ± ±_
78.77 79.78 86.75 04.8377.
**83**

39. 0 **72. 1** 96. 4 78. 370. 2
_± ± ± ± ±_
50.65 **39.** 36.44 19.3414.31
**66**

**44. 0** 40. 1 56. 3 96. 012. 1
_± ± ± ± ±_
**20.** 10.51 45.16 57.1202.12
**51**

66. 0 35. 1 34. 1 59. 029. 0
_± ± ± ± ±_
72.51 44.55 10.50 48.4843.
**58**
StarE-likeQ2B-likeemQL-likeMPQE-likeMPQE-like + Reif


**37. 1** 70. 2 03. 5 20. 1 05. 2
_± ± ± ± ±_
**52.** 04.67 58.53 81.39 25.29
**71**

**52. 0** 73. 2 94. 0 85. 0 52. 0
_± ± ± ± ±_
**20.** 24.44 73.3 62.9 32.8
**55**

00. 1 24. 1 **11. 3** 70. 1 86. 0
_± ± ± ± ±_
78.83 49.83 **28.** 35.74 29.77
**86**

**97. 0** 18. 1 13. 3 30. 1 69. 0
_± ± ± ± ±_
**14.** 72.61 45.61 16.56 81.56
**63**

**61. 0** 18. 1 11. 5 23. 2 27. 2
_± ± ± ± ±_
**96.** 71.51 94.27 72.19 11.17
**52**

**28. 0** 88. 0 70. 2 56. 0 74. 0
_± ± ± ± ±_
**13.** 99.41 09.10 79.6 12.6
**44**

91. 0 84. 0 00. 1 53. 0 **38. 0**
_± ± ± ± ±_
98.30 04.33 01.32 83.26 **36.**
**36**
StarE-likeQ2B-likeemQL-likeMPQE-likeMPQE-like + Reif


61. 0 40. 0 45. 8 16. 006. 0
_± ± ± ± ±_
76.88 49.98 59.82 04.9925.
**99**
39. 2 08. 1 89. 22 86. 256. 1
_± ± ± ± ±_
14.73 24.83 80. 61.8554.
37 **86**

33. 0 03. 0 60. 1 01. 000. 0
_± ± ± ± ±_
65.98 93.99 79.97 96.9997.
**99**

81. 0 20. 0 62. 5 05. 002. 0
_± ± ± ± ±_
63.93 01.99 68.90 49.9957.
**99**
94. 2 **58. 0** 70. 10 04. 343. 1
_± ± ± ± ±_
62.74 **60.** 93. 00.9208.92
**95** 74
52. 2 **48. 1** 25. 13 61. 283. 1
_± ± ± ± ±_
11.68 **17.** 74. 25.8393.82
**87** 51
78. 1 45. 0 74. 11 09. 009. 0
_± ± ± ± ±_
44.78 69.88 20. 77.9368.
73 **95**
StarE-likeQ2B-likeemQL-likeMPQE-likeMPQE-like + Reif


-----


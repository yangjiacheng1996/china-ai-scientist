# FAST GENERIC INTERACTION DETECTION FOR MODEL INTERPRETABILITY AND COMPRESSION

**Tianjian Zhang[1][,][2], Feng Yin[1][,][2], Zhi-Quan Luo[1][,][2]**

1School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen
2Shenzhen Research Institute of Big Data
tianjianzhang@link.cuhk.edu.cn _{yinfeng,luozq}@cuhk.edu.cn_

ABSTRACT

The ability of discovering feature interactions in a black-box model is vital to
explainable deep learning. We propose a principled, global interaction detection
method by casting our target as a multi-arm bandits problem and solving it swiftly
with the UCB algorithm. This adaptive method is free of ad-hoc assumptions
and among the cutting-edge methods with outstanding detection accuracy and
stability. Based on the detection outcome, a lightweight and interpretable deep
learning model (called ParaACE) is further built using the alternating conditional
expectation (ACE) method. Our proposed ParaACE improves the prediction performance by 26% and reduces the model size by 100+ times as compared to
its Teacher model over various datasets. Furthermore, we show the great potential of our method for scientific discovery through interpreting various real
datasets in the economics and smart medicine sectors. The code is available at
[https://github.com/zhangtj1996/ParaACE.](https://github.com/zhangtj1996/ParaACE)

1 INTRODUCTION

Explainable machine learning is an active research field that focuses on providing interpretable models,
transparent explanations, and confident decisions to practical AI systems. Investigating feature
interaction is vital to model interpretability. Interaction detection should be able to reveal which
subset of features influence the output jointly, and what the corresponding nonlinear transformation is.
We aim to find the underlying interactions from data, such that we can interpret the model properly.
To go one step further, we hope that new models can be built with the aid of the detected interaction
knowledge economically to avoid heavy parameterization.

In this paper, we first restrict ourselves to interaction detection. A novel method is derived directly
from the most acknowledged definition of feature interaction (Friedman et al., 2008). We further
apply the obtained interaction knowledge to design a transparent and refined neural network (NN).
This approach fits well into the data science life cycle (Yu & Kumbier, 2019), which was applied, for
instance in Tsang et al. (2020a), successfully for interpretable recommender system design.

The main contributions of this paper include: 1) a fast and principled interaction detection method,
2) a lightweight and interpretable neural network model that can surpass its Teacher, 3) thorough
theoretical analysis and performance evaluations with real datasets. More details are given below.


1. We propose a generic interaction detection method based on a global statistical metric,
namely the expected Hessian, Hij := Ex _∂∂x[2]Fi∂x (xj)_ . Notably, our method is model-agnostic

and applicable to any pre-trained learning model,h i F (x), being for instance, a deep neural
network model or a tree model. It is also flexible to use for multi-way interaction detection.

2. To speed up the detection process, we evaluate the expected Hessian via adaptive sampling
using the Upper Confidence Bound (UCB) algorithm (Lai & Robbins, 1985), which can significantly reduce the computational complexity. Besides, thorough analysis of the proposed
interaction detection method are conducted.

3. Using the detected interaction pairs, we further design a compressed but interpretable
Student model which can surpass its Teacher by 26% in terms of data fitting performance


-----

averaged over various datasets. The compressed model reduces its size over 100 times
compared to the baseline fully-connected, over-parameterized neural network (OverparaFC).

4. We demonstrate the linkages between our compressed model and the classic alternating
conditional expectation (ACE) model (Breiman & Friedman, 1985).

5. We conduct large-scale performance evaluations and further explain the obtained model
interpretability with some real datasets.

The remainder of this paper is organized as follows. Section 2 introduces all related works. Our
proposed interaction detection method is introduced in Section 3. By exploiting the detection
outcome, a new variant of lightweight and interpretable deep learning model is introduced in Section 4.
Experimental results are given in Section 5. Finally, we conclude the paper in Section 6.

2 RELATED WORKS

**Interaction Detection: Early works adopt pure statistics for detecting feature interactions, and**
representatives include ANOVA and GUIDE (Wonnacott & Wonnacott, 1990; Fisher, 1992; Loh,
2002). These works have motivated a plethora of new methods with the aim to enhance the detection
accuracy and/or efficiency. The first class of methods centered around the GA[2]M and tree models, see
for instance Lou et al. (2013); Sorokina et al. (2008); Friedman et al. (2008); Lundberg et al. (2020).
The second class of methods were built on the so-called factorization machines (Rendle, 2010) as
well as its new variants (Xiao et al., 2017; Song et al., 2019) with attention mechanism. The third
class exploits the most recent advances in deep learning, including the Neural Interaction Detection
(NID) and some new variants (Tsang et al., 2018a;b; Cui et al., 2019): Persistence Interaction
Detection (PID) (Liu et al., 2020), Integrated Hessians (IH) (Janizek et al., 2020), Shapley interaction
(Zhang et al., 2020; Sundararajan et al., 2020), etc. Although we have witnessed well improved
interaction detection performance for many datasets over the decades, the above methods still lead to
inconsistent detection results for some other datasets. The reasons are twofold. Firstly, the interaction
strength is empirically defined, for instance, NID method computes the interaction strength via
summarizing the neural network weights. Secondly, a specific deep learning model is required, for
instance, an ℓ1-regularized ReLU network is required by the latest NID and PID methods to maintain
high accuracy. In contrast, our proposed method is derived directly from the definition of feature
interaction (Friedman et al., 2008) and moreover is not confined to any specific learning model.

**Model Interpretability: There are two categories of approaches to address model interpretability,**
namely the transparency-based and post-hoc approaches (Dosiloviˇ c et al., 2018).´ _Transparency-based_
_approaches require the model itself to be simple and interpretable, like linear models, decision_
trees, etc. One can directly read off the interpretations from their coefficients or decision rules. But
often, they are less accurate due to limited representation power. In contrast, post-hoc approaches
extract useful information from a pre-trained model, which is often complex and hard to interpret.
Well-known methods such as LIME (Ribeiro et al., 2016) and SHAP (Lundberg & Lee, 2017) fall
in this category, but they did not take feature interaction into account. Recently proposed symbolic
metamodel (Alaa & van der Schaar, 2019) captures nonlinear interactions by approximating the
black-box model with explicit symbolic expressions. There are also some other post-hoc approaches
based on sensitivity analysis (Cortez & Embrechts, 2013), which return a quantification of fea
(Roustant et al., 2014) by input perturbation. Our work aims to combine the strengths of the twoture importance νi = E[( _[∂F]∂x[ (]i[x][)]_ [)][2][]][ (Kucherenko et al., 2009) and interactions][ ν][ij][ =][ E][[][|][ ∂]∂x[2][F]i∂x[ (][x]j[)] _[|][2][]]_
categories. Concretely, we first extract the interaction knowledge by a post-hoc method, and then
build a transparent and interpretable learning model as illustrated in Figure 3.

**Model Compression and Knowledge Distillation (KD): Model compression (Bucilua et al., 2006)**
aims to learn a small compressed model (Student) from a large complex model (Teacher) with
augmented training data produced by the Teacher. Compared to the Teacher, the Student can make
similar or even better predictions. Knowledge distillation (Hinton et al., 2015) mainly deals with
multi-class classification problems and extracts “valuable information that defines a rich similarity
structure over the data”. Our work introduces a novel viewpoint of knowledge (the interacted
relationships) and targets a lightweight but more accurate Student model.


-----

3 PROPOSED INTERACTION DETECTION METHOD

Before diving into in-depth discussions of interaction detection, we need to formally define what
feature interaction is. The textbook definition according to Friedman et al. (2008) is given below.
**Definition 3.1 (Friedman & Popescu 2008). A function F : R[p]** _→_ R is said to exhibit an interaction
_between two of its variables xi and xj if the difference in the value of F_ (x) as a result of changing
_the value of xi depends on the value of xj._

Equivalently, if Ex _[∂]∂x[2][F]i∂x[ (][x]j[)]_ _> 0, namely the partial derivative w.r.t xj turns out to be dependent_
_|_ _[|][2][i]_

on xi, then we say xhi and xj are interacted. Otherwise, xi and xj have no interaction, if F (x) can be
expressed as the sum of two functions f _i and f_ _j (Sorokina et al., 2008), namely,_
_\_ _\_

_F_ (x) = f _i (x1, . . ., xi_ 1, xi+1, . . ., xp) + f _j (x1, . . ., xj_ 1, xj+1, . . ., xp),
_\_ _−_ _\_ _−_

where f _i(j) is irrespective to xi(j). Similarly, higher-order (multi-way) interaction can be defined._
_\_
In this paper, we mainly focus on pairwise interaction, while multi-way interaction is only briefly
discussed due to space limitations.

3.1 INTERACTION STRENGTH MEASURE


Motivated by the above definition of interaction, it is natural to take advantage of the Hessian matrix
_H :=_ **xx[F]** [(][x][)][. The magnitude of its entry][ |][ ∂]∂x[2][F]i∂x[ (][x]j[)]

curvature at a data point ∇[2] **x. Note that F** (x) is a regression function here, not a loss function. This[|][ contains rich information about the local]
idea was originally considered in the economics community (Ai & Norton, 2003) and rediscovered
for sensitivity analysis in Roustant et al. (2014). The goodness of F (x) as an approximator can
essentially influence the interaction detection performance, see our Theorem M.2 in the supplement.

We define g(x, i, j) := _[∂]∂x[2][F]i∂x[ (][x]j[)]_
_|_ _[|][2][ to measure the][ local interaction strength][ of the][ i][-th and][ j][-th]_

features at point x. We then use f (i, j) := Ex [g(x, i, j)] = Ex _[∂]∂x[2][F]i∂x[ (][x]j[)]_ as a measure of
_|_ _[|][2][i]_

the global interaction strength. If f (i, j) ≈ 0, we say feature xi andh _xj have weak interaction;_
otherwise, if f (i, j) is significantly larger than zero, then xi and xj have strong interaction. In this
**paper, we focus on the global interaction.**

3.2 INTERACTION STRENGTH EVALUATION


The above defined global interaction strength f (i, j) =

_Ex_ _[∂]∂x[2][F]i∂x[ (][x]j[)]_ is mostly unavailable due to the unknown in_|_ _[|][2][i]_

put distributionh **x** _P_ (x). The Monte Carlo method can be
_∼_
used to approximate it by computing the sample mean over the
training data(Roustant et al., 2014).

**Analytical Evaluation: The Hessian matrix ∇xx[2]** _[F]_ [(][x][)][ for neu-]
ral networks at a certain data point can be calculated analytically
and efficiently, by using the automatic differentiation (Paszke
et al., 2017). However, using this analytical solution is problematic for some learning models, such as the ReLU network,
Random Forest (RF), etc., see supplement A. For example, the
landscape of a ReLU network is piece-wise linear as shown in
Figure 1, thus the exact Hessian is a zero matrix at almost every
point. So, we turn to the following numerical evaluation for
broader horizons.


Figure 1: The landscape of a ReLU
network with two inputs (X1, X2).


**Numerical Evaluation: Finite difference method is a common way to approximate the Hessian on a**
given data point (Campolongo & Braddock, 1999), i.e.,


_∂[2]F_ (x)

_∂xi∂xj_



[F (x + eihi + ejhj) _F_ (x + eihi **ejhj)**
4hihj _−_ _−_ (1)

_F_ (x + ejhj **eihi) + F** (x **eihi** **ejhj)],**
_−_ _−_ _−_ _−_


-----

where ei is a one-hot vector with the i-th element being equal to one and the rest of elements being
zeros. We also note that if the computation of gradient _[∂F]∂x_ [is cheap (e.g.,][ F][ is a neural network), then]

_Hij can be approximated as_ 21h _∂F (x∂x+iej_ _h)_ _∂xi_ to reduce computation, which is similar

_−_ _[∂F][ (][x][−][e][j]_ _[h][)]_

to the feature interaction score defined in Greenside et al. (2018). The choice of perturbation sizeh i _hi_
or hj (abbr. hi(j)) is critical. Generally, we do not want hi(j) to be too small (incurring round-off
error) or too large (incurring truncation error) to get a good overall approximation of the derivative
(Jerrell, 1997; Baydin et al., 2018). For our problem, we particularly do not want hi(j) to be too small
so that the four evaluated points (shown in the numerator of Equation 1) lie on the same hyperplane
(e.g., region A in Figure 1), which makes the quantity in Equation 1 always zero. The following
theorem reveals that choosing a sufficiently small hi(j) is not necessary.

**Theorem 3.1. For any x and y, function F shows no interaction between them, i.e., it can be**
_decomposed as F_ (x, y) = a(x) + b(y) if and only if, for any h, k > 0, F (x + h, y + k) − _F_ (x +
_h, y −_ _k) −_ _F_ (x − _h, y + k) + F_ (x − _h, y −_ _k) = 0._

The magnitude of the numerator in Equation 1 tells us whether F is locally separable for variables xi
and xj at point x, see our proof in supplement B.

The main issue of the finite difference method lies in the computational complexity for approximating
the global interaction strength f (i, j), especially when the function evaluation itself is expensive.
Using all the training samples for finding just a few strongest interaction pairs can be a total waste of
computation resources. In general, for a dataset with N samples in p-dimensional feature spaces,
a total number of 4Np(p − 1)/2 arithmetic evaluations of the surrogate regression function F are
needed. If the Hessian happens to be sparse, that is, there are only a few interactions existing in the
ground truth function, massive evaluations on those feature pairs with zero interaction strength should
be avoided.

3.3 IDENTIFICATION OF THE k-STRONGEST PAIRWISE INTERACTIONS

In practice, we do not have to obtain the interaction strengths for all interaction pairs, because many
of them are simply too weak to have an impact on the output, and the top k strongest pairwise
interactions are well sufficient for data modeling and prediction. Finding the top k strongest pairwise
interactions fits perfectly into the best k-arms identification problem in the context of multi-armed
bandits.

Inspired by the recent work (Bagaria et al., 2018b), we can treat each entry of the Hessian Hij
as an arm Ar (see Figure 2). Since Hessian is a symmetric matrix, we only need to consider
_n = p(p −_ 1)/2 arms in the set {Ar : r ∈ [n]}. For example, if we choose to pull the arm for the
_i-th row and j-th column of the Hessian, we will evaluate the local interaction strength g(xξ, i, j)_
on a randomly selected training data point xξ. The strength g(xξ, i, j) can be regarded as a random
reward, where xξ is uniformly drawn from the training data {x1, . . ., xN _}. For ease of notation, we_
let f (r; ξ) := g(xξ, i, j) as the random reward of the arm r, and define µr := Eξ[f (r; ξ)] as the true
mean value. Our goal is to find the best k arms with the highest mean reward.

This reformulation is reasonable since the following three essential assumptions for multi-armed
bandits (Slivkins et al., 2019) are satisfied.

**a. Only the reward will be observed after each pull;**

**b. The reward for each arm is drawn independently and identically from its reward distribution;**

**c. The reward for each round is bounded. Since we only consider functions F** (x) defined on a
compact set, if F is a continuous function and twice differentiable, its first- and second-order
derivatives are bounded accordingly.

3.4 DETECTING THE k-STRONGEST PAIRWISE INTERACTIONS WITH UCB ALGORITHM

In this section, we briefly introduce the UCB algorithm (Lai & Robbins, 1985) for finding the
_k-strongest interactions. Here, we design a sequence of estimators_ _f[ˆ]ℓ(r)_ for the mean reward of
_{_ _}_
the arm Ar and construct confidence interval C(ℓ). We let _f[ˆ]ℓ(r) denote the estimator after ℓ_ pulls of
the arm _r. Several assumptions need to be made before we give out the primary outcome._
_A_


-----

**Algorithm 1 UCB ({Ar : r ∈** [n]}, m, k)

1: For each arm {Ar : r ∈ [n]}, compute an initial (1 − _δ) confidence interval by_
running log(n) steps of the estimator to obtain: [ˆµr(1) − _Cr(1), ˆµr(1) + Cr(1)]_

2: B = {} // Set of k best arms

**…** 3: S = {Ar : r ∈ [n]} // Set of arms under consideration

5: At iteration t, pick arm Ar that maximizes ˆµr(t − 1) + Cr(t − 1) among arms

6: **if arm Ar is evaluated less than m times then**

|Col1|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
||||||
||||||
|…|…|…|||
||…|…|||


**…** 7: Refine the confidence interval and mean estimate of the armestimator one more time. _Ar by updating the_

**…**

8: **else**

9: Set ˆµr(t) to be the current mean of the arm and set Cr(t) = 0.

10: **end if**

11: **if Arm Ar is such that ∀i ̸= r, ˆµi(t) + Ci(t) < ˆµr(t) −** _Cr(t) then_

12: Add Ar to B

13: Remove Ar from the set of arms under consideration, that is S = S −{Ar}.

14: **if the size of B, |B| = k, then**

15: **return B**

16: **end if**

18: end while

**…**


Figure 2: Top Left: The entries of the Hessian are treated as arms. Bottom Left: Illustration of the
notations used in Algorithm 1. This is a snapshot taken at iteration t, where the colored solid bar
and the red dashed bar are the true mean reward and the current estimate for each arm, respectively.
At each iteration, the arm with the highest UCB will be pulled. Right: Pseudo-code for the UCB
algorithm.


**Assumption 1. Finite m evaluations of one arm are sufficient to obtain an accurate reward.**

**Assumption 2. Estimators** _f[ˆ]ℓ(r) are σr-subgaussian._


Assumption 2 is satisfied because the reward is bounded (Hoeffding’s lemma, 1963). Here, σrs are
pre-defined parameters. In the following analysis, we will choose σ = maxr _σr_, such that all _f[ˆ]ℓ(r)_
_{_ _}_
are σ-subgaussian.

Let _f[ˆ]ℓ(r) :=_ [1]ℓ _ℓi=1_ _[f]_ [(][r][;][ ξ][i][)][, and we construct the][ 1][ −] _[δ][ confidence intervals (see supplement C) of]_

_fˆℓ(r) as,_
P

_C(ℓ) :=_ 2σ[2] logℓ _δ[2]_ if ℓ _≤_ _m_ _,_ (2)

( q0 if ℓ> m

_µr_ _fˆℓ(r)_ _C(ℓ),_ _f[ˆ]ℓ(r) + C(ℓ)_ _, w.p. 1_ _δ,_ (3)
_∈_ _−_ _−_

where µr denotes the true expectation. Increasing number of pulls of one arm, the uncertaintyh i
of the reward for that arm will decrease. When the number of pulls reaches m, we can remove
the uncertainty of the arm and set C(ℓ) = 0. Let ℓr(t) count the number of pulls of arm Ar till
iteration t. To simplify the notations, we let ˆµr(t) = f[ˆ]ℓr(t)(r) and Cr(t) = C(ℓr(t)) be the sample
means and confidence intervals at iteration t. Now, we formally introduce the complete procedure in
Algorithm 1.

The Algorithm 1 is initialized by evaluating all arms O(log(n)) times, then at each subsequent
iteration, it picks the arm with the highest UCB, i.e., maxj _µˆj(t)+_ _Cj(t)_, to evaluate (see Figure 2).
_{_ _}_
If one arm has been evaluated for m times, we will its true mean value and set the uncertainty to zero.
At the end of each iteration, if there exists one arm whose Lower Confidence Bound (LCB) is higher
than all the other’s UCB, we will put it into the set of k best arms.

In the following, we give a theoretical analysis on the complexity of this algorithm. We have to further
define ∆[(]i[k][)] := max(0, µi[∗]k _k_ [is the index for the][ k][-th best arm and][ ∆][(]i[k][)] indicates the
gap of true values between the top-[−] _[µ][i][)][, where]k arms and the rest.[ i][∗]_
**Theorem 3.2. With probability 1** _−_ Θ( _n[1][2][ )][, given maximal pulling times][ m][ for each arm, Algorithm 1]_

_returns the k-strongest interaction pairs in O_ _ni=1_ [log(][n][)] _σ[2](∆log([(]i[k][)]nm)[2]_ ) _∧_ _m_ _time, where (· ∧·)_
 

_is short for min(_ _,_ ). P

_·_ _·_


-----

**Remark 3.1. When k ≪** _n, the complexity of Algorithm 1 for finding the top k interactions is_
(n log(mn) log(n) + km log(n)) under some natural assumptions on the distribution of ∆i, being
_O_
_superior to the naive algorithm (every arm is pulled m times) with complexity O(nm)._
**Remark 3.2. For k = 1, namely the strongest interaction pair identification, it requires at most**
_n_ 8σ[2]
_i=1[((]_ (∆[(1)]i )[2][ log(][n][3][m][))][ ∧] _[m][)][ pulls. We leave the complete proof in supplement C.]_
P

3.5 EXTENSION TO MULTI-WAY INTERACTION

Similarly, the third-order derivatives _∂xi∂∂x[3]Fj_ _∂xk_ _[,][ ∀][(][i, j, k][)][, and even the higher-order ones can be]_

approximated by the finite difference method as well, but the computational complexity will increase
geometrically. For a remedy, one can detect higher-order interactions from the obtained pairwise
ones. For instance, based on the k-strongest pairwise interaction strengths, we can further construct
an undirected graph G, in which each node represents a feature. We develop Algorithm 2 to detect
the multi-way interactions through checking all the cliques in the graph G, and more details are given
in supplement G. Despite the computation complexity, our proposed algorithm is more advantageous
to use because the associated learning model is agnostic and the form of interaction is adaptive as
compared with some existing methods, such as Min et al. (2014), which relies on a logistic regression
model and multiplicative interactions of a particular form.

4 MODEL COMPRESSION WITH DETECTED INTERACTIONS

The detected interactions can be used for designing structured and more transparent models. A similar
idea was mentioned in Tsang et al. (2020b). But we propose a new architecture called Parametric
ACE (ParaACE), inspired by several seminal works on Generalized Additive Model (GAM) (Hastie,
2017) and (nonparametric) Alternating Conditional Expectation (ACE) method (Breiman & Friedman,
1985). The original ACE method is based on the following model,


_φk(Xk) + ϵ,_ (4)

_k=1_

X


_θ(Y ) =_


and solves for the optimal transformation functions _θ, φ1,_ _, φp_ nonparametrically in the Hilbert
_{_ _· · ·_ _}_
space. However, it only considers transformation of each single feature and is time consuming for
large feature dimension p. We build the ParaACE model with the detected interactions as


_βp+iri (x_ _i_ ; θri ), (5)
_I_
_i=1_

X


_h(x; {θsi_ _}, {θri_ _}, β) := β0 +_


_βisi (xi; θsi_ ) +
_i=1_

X


where {Ii}i[R]=1 [is a set of indices for the detected interaction pairs,][ s][i][ and][ r][i][ are the transformation]
functions for a single feature and interacting features with the corresponding parameters **_θsi_** and
_{_ _}_
**_θri_**, β is a weight vector for the output of all the transformation functions.
_{_ _}_

The new architecture is shown in Figure 3 with two meta
layers: the optimal feature transformation layer (Equa- **Main effects** **Identity**
tion 5, boxed in red and green) and an optional fix-up layer **Input**
(boxed in yellow). The optimal transformation layer gives
the transformation functions of both the main effects and
interacting features explicitly. The fix-up layer can be un- **…**
derstood as the inverse function for the optimal transformaAnother functionality of the fix-up layer is to alleviate thetion of the output, θ(Y ), in the original ACE (Equation 4). … … …
negative impacts of the wrongly detected interactions on **Optimal** **Optional**

|…|Col2|Col3|Col4|
|---|---|---|---|
||||… …|
|…||||

the output. More explanations are given in supplement H. **transformationlayer** **Candidateinteractions** **ResNet** **fix-up layer**

|Main effects Identity Input … … … … … … … Optimal transformation Candidate ResNet layer interactions|Identity … … … …|Outp|
|---|---|---|
|Optimal transformation layer||Optional fix-up layer|


We highlight the advantages of this model as follows: 1)

Figure 3: Parametric ACE model.

**interpretable, unlike many other models, ParaACE model**
gives explicit transformations of features, making it interpretable. 2) lightweight, this model can
significantly reduce the number of parameters from the original one, and unlike the pruning technique
(Han et al., 2015), it does not need extra memory to store the indices of the preserved weights.


-----

3) flexible, the structure of NN is modularized by blocks, which is easy to plug in/off for other
applications. The fix-up layer can be redesigned as block-wise subnetworks to capture high-level
interactions, end up in the shape of a hierarchical deep network.

5 EXPERIMENTS

5.1 EXPERIMENTAL SETUP

**Datasets: We generated 10 synthetic datasets (p = 10) as was used in Tsang et al. (2018a) to**
test the accuracy of different interaction detection methods. We added a scaled Gaussian noise
_η ∼_ 0.1 × N (0, 1) to get the noisy data. We also selected 5 real datasets, namely the Elevators for
controlling an F16 aircraft (Itorgo, 2019), Parkinsons for predicting the total UPDRS scores (Tsanas
et al., 2009), Skillcraft for game player behavior analysis (Thompson et al., 2013), Cal housing for
house price prediction (Pace & Barry, 1997), and Bike sharing for predicting hourly bike rental count
(Fanaee-T & Gama, 2014). The datasets are preprocessed, and details are shown in supplement D.

**Neural Network Configuration: For the baseline OverparaFC (Teacher), we used the architecture**
of p-5000-900-400-100-30-1 (indicating a deep neural network with p inputs, one output, and 5
hidden layers with 5000, 900, 400, 100, 30 neurons, respectively), which is a standard ReLU network
with the last hidden layer being linear. For the ParaACE model (Student), the size of the network
mainly depends on the number of candidate interactions we choose; more interactions imply more
blocks. However, the configuration for each subnetwork is fixed, the structure of which is 1-50-8-1
for main effects and 2-50-8-1 for pairwise interactions. These subnetworks are ReLU networks with
linear output. The fix-up layer is chosen as a single layer ResNet with the number of neurons equal to
15. All the above networks were initialized with Kaiming’s strategy (He et al., 2015).

**Optimizer Setup: We chose adam (Kingma & Ba, 2014) as the optimizer, with the default setup in**
MXNet (Chen et al., 2015), and the batch size is set to be 500 for all the datasets.

5.2 PAIRWISE INTERACTION DETECTION

We first test on 10 different synthetic datasets (p = 10) (Tsang et al., 2018a) to show the superiority
of our proposed method. Datasets with higher input dimensions (p = 50, 100) were compared as
well, see supplement F. To compare the detection performance of different methods, we adopt the
ROC-AUC metric (see supplement E). In Table 1, we compared our proposed method with various
existing methods, including ANOVA (Wonnacott & Wonnacott, 1990), AG (Sorokina et al., 2008),
IH (Janizek et al., 2020), NID (Tsang et al., 2018a), and PID (Liu et al., 2020). HierLasso (Bien et al.,
2013) and RuleFit (Friedman et al., 2008) have been omitted due to their weak performances. For
our method, we pick the same number of data samples n = 10000 for the training of OverparaFC
and run 5 independent Monte Carlo tests. In Algorithm 1, we pull each arm 3 times for initialization.
Each arm will be pulled at maximally m = 100 times, and we terminate when k = 20 strongest
interactions stand out. We take ˆµr(t) upon termination as the final scores for our method. In this
experiment, our proposed method needs around 1500 pulls of arms to pick out the top 20 interactions,
however, naively pulling each arm 100 times needs 100C10[2] [= 4500][ pulls in total.]

Table 1: Interaction detection methods in comparison. ROC-AUCs of pairwise interaction strengths
proposed by us (with hi(j) = 0.8) versus various baselines on a test suite of synthetic functions (see
Table 4 in the supplement).

1 Small standard deviation means high stability, a post-hoc method, b model agnostic method.

|Col1|ANOVAa,b AG IHa NIDa PIDa|Our methoda,b|
|---|---|---|
|F1(x) F2(x) F3(x) F4(x) F5(x) F6(x) F7(x) F8(x) F9(x) F10(x)|0.992 1 ± 0.0 0.989 0.970 ± 9.2e−3 0.986 ± 4.1e−3 0.468 0.88 ± 1.4e−2 0.968 0.79 ± 3.1e−2 0.804 ± 5.7e−2 0.657 1 ± 0.0 1 0.999 ± 2.0e−3 1 ± 0.0 0.563 0.999 ± 1.4e−3 1 0.85 ± 6.7e−2 0.935 ± 3.9e−2 0.544 0.67 ± 5.7e−2 1 1 ± 0.0 1 ± 0.0 0.780 0.64 ± 1.4e−2 0.932 0.98 ± 6.7e−2 1 ± 0.0 0.726 0.81 ± 4.9e−2 0.611 0.84 ± 1.7e−2 0.888 ± 2.8e−2 0.929 0.937 ± 1.4e−3 0.954 0.989 ± 4.4e−3 1 ± 0.0 0.783 0.808 ± 5.7e−3 0.831 0.83 ± 5.3e−2 0.972 ± 2.9e−2 0.765 1 ± 0.0 1 0.995 ± 9.5e−3 0.987 ± 3.5e−2|0.947 ± 2.5e−2 0.944 ± 3.2e−2 1 ± 0.0 0.997 ± 2.7e−3 0.988 ± 2.3e−2 0.925 ± 3.7e−2 0.714 ± 7.0e−2 0.984 ± 4.2e−3 0.948 ± 4.6e−2 1 ± 0.0|
|average Time (s)|0.721 0.87 ± 1.4e−2 0.931 0.92 ± 2.3e−2 0.957 ± 6.2e−2 - - 132 0.007 -|0.945 ± 5.6e−31 14.7|


-----

From the results, we can conclude the following: (1) PID outperforms all others; (2) our proposed
method is as competitive as the PID method; (3) while the average performance of our method is
only slightly worse than the PID method due to the poor result on dataset 7; this is due to the term
1

1+(x4x5x6x7x8)[2][ in][ F][7][(][x][)][ has little impact on the output, and such interactions are hard to detect.]
Apart from the above facts, both NID and PID work by analyzing the connectivity of NN, which
strongly relies on specific sparse ReLU networks and empirical interaction strength computations,
and thus are risky to generalize and may fail for some other datasets. For instance, for the function
_F11(x) = x[2]1[x][2][x][2]3[x][4]_ [+][ x][2]5[x][6][x][2]7[x][8][, the ROC-AUC of NID degrades to around 0.69, while our method]
maintains 1.0 robustly. Moreover, our method is model-agnostic and can be directly applied to any
pre-trained learning models, such as tree models, kernel regression models, etc., which is impossible
for other methods.

5.3 MODEL COMPRESSION WITH INTERACTION KNOWLEDGE

In this section, we construct a Student model with the learned interactions. With the interaction
knowledge extracted from the Teacher model, we first show that the Student model trained under the
same setup can achieve well-improved prediction accuracy (on average). We use normalized RMSE
(NRMSE), which is defined by _ymaxRMSE−ymin_ [to measure the performances of all competing models such]

that the comparison across different datasets is fair and convenient.

For synthetic data, we use 800 training samples and 200 test samples. The noise η is injected
as described earlier. We choose the top 20 pairwise interactions with our new detection method
to build the ParaACE model. We compared our proposed ParaACE with OverparaFC, KD for
regression (Chen et al., 2017), and two recent pruning methods known as Lottery Ticket Hypothesis
(LTH) (Frankle & Carbin, 2019) and SynFlow (Tanaka et al., 2020). The results are shown in
Table 2. As we expected, the KD method shows similar performance as the OverparaFC, because
the Student model tries hard to approximate its Teacher. However, our ParaACE model can improve
the performance of the OverparaFC by 26.0% on average, and the model compression ratio (CR :=
# parameters in the uncompressed model

# parameters in the compressed model [) is around 300. More details can be found in supplement L. We also]
found that the ParaACE model is sample efficient. To be concrete, the ParaACE trained on a small
training set can surpass the over-parameterized NN trained with substantially more data, see Figure 13
in supplement K.

Table 2: NRMSE of the baselines: OverparaFC, KD, and LTH versus our proposed ParaACE tested
on the synthetic datasets in Table 4. (The results were averaged over 5 folds.)

_F1_ _F2_ _F3_ _F4_ _F5_ _F6_ _F7_ _F8_ _F9_ _F10_ Average CR

OverparaFC 0.026 0.054 0.059 0.062 0.042 0.041 0.018 0.024 0.032 0.023 0.038 1
KD (student) 0.029 0.055 0.061 0.064 0.041 0.042 0.019 0.024 0.032 0.024 0.039 278
LTH 0.027 0.044 0.032 0.032 0.039 0.033 0.018 0.021 0.029 0.025 0.030 18
SynFlow 0.025 0.048 0.034 0.035 0.039 0.031 **0.015** **0.018** 0.026 0.022 0.029 280
**ParaACE** **0.025** **0.035** **0.031** **0.030** **0.038** **0.025** 0.016 0.019 **0.023** **0.021** **0.026** **283**

For real-world datasets, we built the ParaACE model with the top 50 pairwise interactions for
Elevators, Parkinsons, Skillcraft, Bike sharing, and the top 20 pairwise interactions for Cal housing
(since the number of features is smaller). For most datasets, the detected interactions can help improve
the predictive performance and significantly reduce the model size, see Table 3 for detailed results.
The comparison with KD is omitted as it is supposed to be close to the Teacher.

Table 3: Performance comparison between OverparaFC, LTH, SynFlow, and ParaACE on real-world
datasets. (The results were averaged over 5 folds.)

|Datasets N p|OverparaFC NRMSE Parameters|LTH NRMSE CR|SynFlow NRMSE CR|ParaACE NRMSE Parameters CR|
|---|---|---|---|---|
|Elevators 16599 18 Parkinsons 5875 20 Skillcraft 3338 19 Bike sharing 17379 15 Cal housing 20640 8|0.0483 4999461 0.0251 5009461 0.0937 5004461 0.0403 4984461 0.1059 4949461|0.0523 87 0.0180 87 0.1228 87 0.0404 87 0.1038 87|0.0479 120 0.0229 120 0.0968 120 0.0405 120 0.1026 120|0.0475 39848 125 0.0204 40946 122 0.0929 40397 124 0.0420 38201 130 0.1022 16388 302|



Due to space limitations, we give more results for classification tasks in supplement I. Furthermore,
we show the performance gain induced by interaction detection via ablation study in supplement N.


-----

5.4 MODEL INTERPRETATION

For synthetic data, we take F10(x) = sinh (x1 + x2) + arccos (tanh(x3 + x5 + x7)) + cos(x4 +
_x5) + sec(x7x9) as an example. Three dominant pairwise interactions_ _x1, x2_, _x4, x5_, _x7, x9_
_{_ _}_ _{_ _}_ _{_ _}_
have been detected successfully and visualized in Figure 4 (left). The ground truth transformations
are shown in the upper part of the figure. Besides, the transformations for the single features can
also be learned accurately. Taking F3(x) = exp _x1_ _x2_ + _x2x3_ (x[2]3[)][|][x][4][|][ + log(][x][2]4 [+][ x]5[2] [+][ x]7[2] [+]
_x[2]8[) +][ x][9]_ [+] 1+1x[2]10 [for example, wherein feature] |[ x][6] −[ is not involved,]| _|_ _| −[ x][9][ is linearly transformed, and]_

_x10 is transformed by an even function. All of them are correctly learned as shown in Figure 4 (right)._



0.120

0.115

0.110

0.105

0.100

0.095 1.6 0.8 0.0 0.8 1.6


0.3

0.2

0.1

0.0

0.1

1.6 0.8 0.0 0.8 1.6


_s6(x6)_ _s9(x9)_


1.5 1.0 0.5x10.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.521.01.510.00.07.52.55.05.02.57.5


0.000.750.250.500.500.250.751.00

1.5 1.0 0.5x40.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.551.01.5


20015010010050500

1.5 1.0 0.5x70.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.591.01.5





0.8

0.6

0.4

0.2

0.0

0.2

1.5 1.0 0.5x10.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.521.01.5


0.1

0.2

0.3

0.60.50.4

1.5 1.0 0.5x40.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.551.01.5


1.5 1.0 0.5x70.0 0.5 1.0 1.5 1.5 1.0 0.50.0x0.591.01.50.0000.0050.0100.0150.0050.0200.0250.0300.035


0.00

0.05

0.10

0.15

0.20 1.6 0.8 0.0 0.8 1.6


1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2 1.6 0.8 0.0 0.8 1.6


_s10(x10)_ ground truth s10( )

_·_


sinh(x1 + x2) cos(x4 + x5) sec(x7x9)


Figure 4: Visualization of the transformations in F10 (left) and F3 (right).

For real applications, we first take the Cal housing dataset for further analysis as less expert
knowledge is required. From Figure 5, we can easily recognize that {longitude, latitude} and
_{totalRooms,totalBedrooms} show strong interactions. This makes sense, because {longitude, lati-_
_tude} indicates the location, and {totalRooms,totalBedrooms} indicates the fraction of bedrooms._
Also in the Parkinsons dataset, we find {Age, Sex} are interacted, which is consistent with the result
that “age at onset (of Parkinson’s disease) was 2.1 years later in women than in men” in Haaxma
et al. (2007). Interaction detection may also have a significant impact on drug combination discovery
(Julkunen et al., 2020). We applied our interaction detection method on an RF model trained with the
Drug combination dataset. Among the top 34 detected drug-drug interactions, 15 pairwise interactions have been verified in the DrugBank database (Wishart et al., 2018) (see supplement J). These
results confirmed the effectiveness of our interaction detection method and strongly call for careful
investigation of the unexplored drug pairs, potentially of great value.

Cal housing

longitude

latitude

housingMedianAge

totalRooms

totalBedrooms

population

households

medianIncome

longitudehousingMedianAgelatitudetotalRoomstotalBedroomspopulationhouseholdsmedianIncome

Parkinsons

subject#

age
sex

test_time

Jitter(%)

Jitter(Abs)

Jitter:RAP

Jitter:PPQ5

Jitter:DDP

Shimmer

Shimmer(dB)

Shimmer:APQ3
Shimmer:APQ5

Shimmer:APQ11

Shimmer:DDA

NHR
HNR

RPDE

DFA

PPE

subject#agetest_timesexJitter(%)Jitter(Abs)Jitter:RAPJitter:PPQ5Jitter:DDPShimmer(dB)ShimmerShimmer:APQ3Shimmer:APQ5Shimmer:APQ11Shimmer:DDANHRHNRRPDEDFAPPE


Figure 5: Heat maps of interaction strengths for Cal housing, Parkinsons, and Drug combination data.
Note that darker color indicates stronger interaction.
6 CONCLUSION

This paper proposed a fast, generic, and model-agnostic interaction detection method. A thorough
analysis of the computational complexity of our adaptive method proved its superior efficacy. The
detected interaction knowledge can be further exploited to build a novel Student model, called
ParaACE, which is compact, more interpretable, and mostly more accurate than its Teacher and other
competing methods. We also showed experimentally that our ParaACE model is sample efficient
owing to its simple architecture. Its model-agnostic property enables tremendous applications in
different domains of finance, medicine, biology, wireless communication, where a significant number
of well-performed black-box models have been built but not interpreted yet.


-----

ACKNOWLEDGMENTS

This work was supported by Guangdong Provincial Key Laboratory of Big Data Computing and by
NSFC under Grant 61731018. The corresponding author is Feng Yin.

REFERENCES

Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana, and Geoffrey E Hinton. Neural
additive models: Interpretable machine learning with neural nets. arXiv preprint arXiv:2004.13912,
2020.

Chunrong Ai and Edward C Norton. Interaction terms in logit and probit models. Economics letters,
80(1):123–129, 2003.

Ahmed M Alaa and Mihaela van der Schaar. Demystifying black-box models with symbolic
metamodels. In NeurIPS, pp. 11301–11311, 2019.

Vivek Bagaria, Govinda Kamath, Vasilis Ntranos, Martin Zhang, and David Tse. Medoids in almostlinear time via multi-armed bandits. In Amos Storkey and Fernando Perez-Cruz (eds.), Proceedings
_of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84_
of Proceedings of Machine Learning Research, pp. 500–509, Playa Blanca, Lanzarote, Canary
Islands, 09–11 Apr 2018a. PMLR.

Vivek Bagaria, Govinda M. Kamath, and David N. Tse. Adaptive Monte-Carlo optimization, 2018b.

Pierre Baldi, Peter Sadowski, and Daniel Whiteson. Searching for exotic particles in high-energy
physics with deep learning. Nature communications, 5(1):1–9, 2014.

Atilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind.
Automatic differentiation in machine learning: a survey. Journal of machine learning research, 18
(153), 2018.

Jacob Bien, Jonathan Taylor, and Robert Tibshirani. A lasso for hierarchical interactions. Annals of
_statistics, 41(3):1111, 2013._

Leo Breiman and Jerome H Friedman. Estimating optimal transformations for multiple regression
and correlation. Journal of the American statistical Association, 80(391):580–598, 1985.

Cristian Bucilua, Rich Caruana, and Alexandru Niculescu-Mizil. Model compression. In Proceedings
_of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pp._
535–541. ACM, 2006.

Francesca Campolongo and Roger Braddock. The use of graph theory in the sensitivity analysis of
the model output: a second order screening method. Reliability Engineering & System Safety, 64
(1):1–12, 1999.

Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Manmohan Chandraker. Learning efficient
object detection models with knowledge distillation. In Advances in Neural Information Processing
_Systems, pp. 742–751, 2017._

Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu,
Chiyuan Zhang, and Zheng Zhang. MXNet: A flexible and efficient machine learning library for
heterogeneous distributed systems. arXiv preprint arXiv:1512.01274, 2015.

Paulo Cortez and Mark J Embrechts. Using sensitivity analysis and visualization techniques to open
black box data mining models. Information Sciences, 225:1–17, 2013.

Tianyu Cui, Pekka Marttinen, and Samuel Kaski. Learning pairwise interactions with Bayesian
neural networks, 2019.

Filip Karlo Dosiloviˇ c, Mario Br´ ciˇ c, and Nikica Hlupi´ c. Explainable artificial intelligence: A survey.´
In 2018 41st International convention on information and communication technology, electronics
_and microelectronics (MIPRO), pp. 0210–0215. IEEE, 2018._


-----

[Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.](http://archive.ics.uci.edu/ml)
[ics.uci.edu/ml.](http://archive.ics.uci.edu/ml)

Hadi Fanaee-T and Joao Gama. Event labeling combining ensemble detectors and background
knowledge. Progress in Artificial Intelligence, 2(2-3):113–127, 2014.

Ronald Aylmer Fisher. Statistical methods for research workers. In Breakthroughs in statistics, pp.
66–70. Springer, 1992.

Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural
networks. In International Conference on Learning Representations, 2019.

Jerome H Friedman, Bogdan E Popescu, et al. Predictive learning via rule ensembles. The Annals of
_Applied Statistics, 2(3):916–954, 2008._

Peyton Greenside, Tyler Shimko, Polly Fordyce, and Anshul Kundaje. Discovering epistatic feature
interactions from neural network models of regulatory DNA sequences. Bioinformatics, 34(17):
[i629–i637, 09 2018. ISSN 1367-4803. doi: 10.1093/bioinformatics/bty575. URL https:](https://doi.org/10.1093/bioinformatics/bty575)
[//doi.org/10.1093/bioinformatics/bty575.](https://doi.org/10.1093/bioinformatics/bty575)

Charlotte A Haaxma, Bastiaan R Bloem, George F Borm, Wim JG Oyen, Klaus L Leenders, Silvia
Eshuis, Jan Booij, Dean E Dluzen, and Martin WIM Horstink. Gender differences in parkinson’s
disease. Journal of Neurology, Neurosurgery & Psychiatry, 78(8):819–824, 2007.

Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.

Trevor J Hastie. Generalized additive models. In Statistical models in S, pp. 249–307. Routledge,
2017.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. In Proceedings of the IEEE international
_conference on computer vision, pp. 1026–1034, 2015._

Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv
_preprint arXiv:1503.02531, 2015._

Giles Hooker. Generalized functional anova diagnostics for high-dimensional functions of dependent
variables. Journal of Computational and Graphical Statistics, 16(3):709–732, 2007.

Kurt Hornik. Approximation capabilities of multilayer feedforward networks. Neural networks, 4(2):
251–257, 1991.

[Luis Itorgo. Regression datasets (accessed: February 12, 2020), 2019. URL https://www.dcc.](https://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html)
[fc.up.pt/˜ltorgo/Regression/DataSets.html.](https://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html)

Joseph D. Janizek, Pascal Sturmfels, and Su-In Lee. Explaining explanations: Axiomatic feature
interactions for deep networks, 2020.

Max E Jerrell. Automatic differentiation and interval arithmetic for estimation of disequilibrium
models. Computational Economics, 10(3):295–316, 1997.

Heli Julkunen, Anna Cichonska, Prson Gautam, Sandor Szedmak, Jane Douat, Tapio Pahikkala,
Tero Aittokallio, and Juho Rousu. Leveraging multi-way interactions for systematic prediction of
pre-clinical drug combination effects. Nature communications, 11(1):1–11, 2020.

Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
_arXiv:1412.6980, 2014._

S Kucherenko et al. Derivative based global sensitivity measures and their link with global sensitivity
indices. Mathematics and Computers in Simulation, 79(10):3009–3017, 2009.

Tze Leung Lai and Herbert Robbins. Asymptotically efficient adaptive allocation rules. Advances in
_applied mathematics, 6(1):4–22, 1985._


-----

Benjamin Lengerich, Sarah Tan, Chun-Hao Chang, Giles Hooker, and Rich Caruana. Purifying
interaction effects with the functional anova: An efficient algorithm for recovering identifiable
additive models. In International Conference on Artificial Intelligence and Statistics, pp. 2402–
2412. PMLR, 2020.

Zirui Liu, Qingquan Song, Kaixiong Zhou, Ting Hsiang Wang, Ying Shan, and Xia Hu. Towards interaction detection using topological analysis on neural networks. arXiv preprint arXiv:2010.13015,
2020.

Wei-Yin Loh. Regression trees with unbiased variable selection and interaction detection. Statistica
_sinica, pp. 361–386, 2002._

Yin Lou, Rich Caruana, Johannes Gehrke, and Giles Hooker. Accurate intelligible models with
pairwise interactions. In Proceedings of the 19th ACM SIGKDD international conference on
_Knowledge discovery and data mining, pp. 623–631. ACM, 2013._

Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances
_in Neural Information Processing Systems 30, pp. 4765–4774. Curran Associates, Inc., 2017._

Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit
Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. From local explanations to global
understanding with explainable AI for trees. Nature Machine Intelligence, 2(1):2522–5839, 2020.

Martin Renqiang Min, Xia Ning, Chao Cheng, and Mark Gerstein. Interpretable sparse high-order
boltzmann machines. In Artificial Intelligence and Statistics, pp. 614–622. PMLR, 2014.

Thomas Muehlenstaedt, Olivier Roustant, Laurent Carraro, and Sonja Kuhnt. Data-driven kriging
models based on fanova-decomposition. Statistics and Computing, 22(3):723–738, 2012.

R Kelley Pace and Ronald Barry. Sparse spatial autoregressions. Statistics & Probability Letters, 33
(3):291–297, 1997.

Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.

William JE Potts. Generalized additive neural networks. In Proceedings of the fifth ACM SIGKDD
_international conference on Knowledge discovery and data mining, pp. 194–200, 1999._

S. Rendle. Factorization machines. In 2010 IEEE International Conference on Data Mining, pp.
995–1000, 2010.

Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ” why should i trust you?” explaining the
predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference
_on knowledge discovery and data mining, pp. 1135–1144, 2016._

Olivier Roustant, Jana Fruth, Bertrand Iooss, and Sonja Kuhnt. Crossed-derivative based sensitivity
measures for interaction screening. Mathematics and Computers in Simulation, 105:105–118,
2014.

Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. Learning important features through
propagating activation differences. In Proceedings of the 34th International Conference on Machine
_Learning-Volume 70, pp. 3145–3153. JMLR. org, 2017._

Aleksandrs Slivkins et al. Introduction to multi-armed bandits. Foundations and Trends® in Machine
_Learning, 12(1-2):1–286, 2019._

Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang.
Autoint: Automatic feature interaction learning via self-attentive neural networks. In Proceedings
_of the 28th ACM International Conference on Information and Knowledge Management, CIKM_
’19, pp. 1161–1170, 2019.


-----

Daria Sorokina, Rich Caruana, Mirek Riedewald, and Daniel Fink. Detecting statistical interactions
with additive groves of trees. In Proceedings of the 25th international conference on Machine
_learning, pp. 1000–1007. ACM, 2008._

Mukund Sundararajan, Kedar Dhamdhere, and Ashish Agarwal. The shapley taylor interaction index.
In International Conference on Machine Learning, pp. 9259–9268. PMLR, 2020.

Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing
_Systems, 33, 2020._

Joseph J Thompson, Mark R Blair, Lihan Chen, and Andrew J Henrey. Video game telemetry as a
critical tool in the study of complex skill learning. PloS one, 8(9), 2013.

Athanasios Tsanas, Max A Little, Patrick E McSharry, and Lorraine O Ramig. Accurate telemonitoring of parkinson’s disease progression by noninvasive speech tests. IEEE transactions on
_Biomedical Engineering, 57(4):884–893, 2009._

Michael Tsang, Dehua Cheng, and Yan Liu. Detecting statistical interactions from neural network
weights. In International Conference on Learning Representations, 2018a.

Michael Tsang, Hanpeng Liu, Sanjay Purushotham, Pavankumar Murali, and Yan Liu. Neural
interaction transparency (NIT): Disentangling learned interactions for improved interpretability. In
_NeurIPS, pp. 5809–5818, 2018b._

Michael Tsang, Dehua Cheng, Hanpeng Liu, Xue Feng, Eric Zhou, and Yan Liu. Feature interaction
interpretability: A case for explaining ad-recommendation systems via neural interaction detection.
In International Conference on Learning Representations, 2020a.

Michael Tsang, Dehua Cheng, Hanpeng Liu, Xue Feng, Eric Zhou, and Yan Liu. Extracting
and leveraging feature interaction interpretations. In International Conference on Learning
_Representations, 2020b._

Peter D Turney. Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree
induction algorithm. Journal of artificial intelligence research, 2:369–409, 1994.

Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge University Press, 2019.

David S Wishart, Yannick D Feunang, An C Guo, Elvis J Lo, Ana Marcu, Jason R Grant, Tanvir Sajed,
Daniel Johnson, Carin Li, Zinat Sayeeda, et al. Drugbank 5.0: a major update to the drugbank
database for 2018. Nucleic acids research, 46(D1):D1074–D1082, 2018.

Thomas H Wonnacott and Ronald J Wonnacott. Introductory statistics, volume 5. Wiley New York,
1990.

Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. Attentional
factorization machines: Learning the weight of feature interactions via attention networks. In
_Proceedings of the 26th International Joint Conference on Artificial Intelligence, IJCAI’17, pp._
3119–3125, 2017.

Bin Yu and Karl Kumbier. Three principles of data science: predictability, computability, and stability
(PCS). arXiv preprint arXiv:1901.08152, 2019.

Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, and Quanshi Zhang. Interpreting multivariate
interactions in dnns. arXiv preprint arXiv:2010.05045, 2020.


-----

## Supplementary Document Fast Generic Interaction Detection for Model Interpretability and Compression

A PROBLEMS WITH ANALYTICAL EVALUATION

In this section, we first illustrate the conceptual difference between local and global interaction and
then state the problems of analytical evaluation.

**Illustration of Local vs. Global Interaction. A quick example showing the difference of lo-**
cal/global interaction is the MATLAB symbol[1] (Figure 6(a)). There is no local interaction inside the
flat region, but two input variables globally interact.

Analytical evaluation works for neural networks with differentiable activation functions, e.g.,
sigmoid, tanh, etc. However, it is problematic when we use neural networks with piece-wise
linear activation functions (PLNN), such as ReLU, Leaky ReLU, and so on. The Hessian will be
a zero matrix at every second-order differentiable point, and it will no longer provide information
about local interaction. Imagine the function landscape is joint with many facets, and the interaction
information is hidden in the boundary of those facets (the set of non-differentiable points).

A simple example is checkerboard-like function, e.g., XOR function F (x1, x2) = 1{x1x2 > 0},
wherehowever, the second-order derivatives x1, x2 are uniformly drawn from∂x [∂F1−∂x12, 1][will be zero for almost all sampled points. The]. In this case, x1 and x2 are clearly interacted,

interaction information is hidden at the line x1 = 0 and x2 = 0.

(a) origin function (b) approximated function

Figure 6: The MATLAB symbol. (a)Imagine the MATLAB symbol as the landscape of a function
_F_ (x1, x2), there is no interaction locally in the flat region, but x1 and x2 interact globally, i.e., there
is no global decomposition as F (x1, x2) = a(x1) + b(x2). (b) (Problems with analytical evaluation)
The function is approximated by a PLNN, and the landscape is spliced by flat facets. The Hessian
matrix is a zero matrix on almost every point (no local interaction), but x1 and x2 still interact
globally.

B PROOF OF THEOREM 3.1 AND DISCUSSION ON THE CHOICE OF h

**Theorem 3.1.** _For any x and y, function F shows no interaction between them, i.e., it can be_
_decomposed as F_ (x, y) = a(x) + b(y) if and only if, ∀ _h, k > 0, F_ (x + h, y + k) − _F_ (x + h, y −
_k) −_ _F_ (x − _h, y + k) + F_ (x − _h, y −_ _k) = 0._

_Proof. (⇒) is trivial. (⇐) We will directly have, ∀h, k > 0 and ∀x, y,_


_F_ (x + h, y + k) − _F_ (x + h, y − _k)_

_k_

_F_ (x + h, y + k) − _F_ (x − _h, y + k)_

_h_

1With permission of MathWorks.


= _[F]_ [(][x][ −] _[h, y][ +][ k][)][ −]_ _[F]_ [(][x][ −] _[h, y][ −]_ _[k][)]_

_k_

= _[F]_ [(][x][ +][ h, y][ −] _[k][)][ −]_ _[F]_ [(][x][ −] _[h, y][ −]_ _[k][)]_


-----

Let∂F _k →_ 0, we will have _[∂F]∂y_ [(][x][ +][ h, y][) =][ ∂F]∂y [(][x][ −] _[h, y][)][ for any positive][ h][; let][ h][ →]_ [0][, we will have]

_∂x_ [(][x, y][ +][ k][) =][ ∂F]∂x [(][x, y][ −] _[k][)][ for any positive][ k][. Thus,][ ∂F]∂y_ [is irrespective of][ x][ and][ ∂F]∂x [is irrespective]

of y.

**Remark B.1. Theorem 3.1 can be extended for higher-order interaction with the same machinery.**

Ave. AUC score versus hi on synthetic datasets


0.95

0.90

0.85

0.80

0.75


0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4

PID
NID
Our method

hi

Figure 7: Average ROC-AUC score versus hi(j) on synthetic datasets. The error bar represents one
standard deviation (5 folds).


**A guide for the choice of hi(j). We empirically test the sensitivity of hi(j), see Figure 7. For**
_standardized features, we suggest using hi(j)_ [0.6, 0.9] as the rule-of-thumb.
_∈_

**Further discussions on the choice of hi(j). People may argue that for the interaction detection task,**
a small number of evaluations for each feature pair are already enough to get pretty good results,
and the benefits of using the UCB algorithm is trivial. This is not always true. We address this
from two perspectives in the following. First, in many scenarios, the function can only be evaluated
sequentially, and the evaluation may be very expensive. The benefits of the UCB algorithm are
revealed then. Second, we empirically study the performance of evaluating each arm evenly under
different configurations (perturbation size hi(j), and the number of evaluations for each arm), see
Figure 8. The ROC-AUC scores were obtained from the OverparaFC model trained as described in
Section 5.2. We expect that given the fixed perturbation size h, the ROC-AUC scores will rise as the
number of evaluations increases. This is consistent with the observation that the bricks are brighter
from top to bottom. Also, we observed that with a properly chosen h ∈ [0.6, 0.9], the interactions
can be correctly detected with a relatively small number of evaluations (the bricks are brighter in the
middle, see dataset 3, 4, and 5). The corresponding reasons can be that (a) if h is too small, four
evaluated points lie in the same flat region with high probability, which is harmful to interaction
detection; (b) if h is too large, some evaluated points may be out of the distribution of the training
data, which makes the detected interaction strength less representative. Even though the suggestion
of using hi(j) [0.6, 0.9] is purely empirical, the plots here help us better understand the essence of
statistical interactions and their detection process. ∈

C PROOF OF THEOREM 3.2


Recall that we construct the 1 _δ confidence intervals of_ _f[ˆ]ℓ(r) as,_
_−_

_C(ℓ) =_ 2σ[2] logℓ _δ[2]_ if ℓ _m_ _,_

_≤_

( q0 if ℓ> m

_µr_ _fˆℓ(r)_ _C(ℓ),_ _f[ˆ]ℓ(r) + C(ℓ)_ _, w.p. 1_ _δ._
_∈_ _−_ _−_

This is derived from concentration inequality (Inequality 2.9 in Wainwright (2019)). We seth i _δ =_ _n[3]2m_ [,]

which is a small number and easy to analyze. We have,
**Lemma C.1 (high probability event/clean event). With probability (w.p.) 1** _n2[2][, all true values][ µ][r]_
_−_

_lie in the their confidence intervals during the run of the algorithm._


-----

Average AUC on the dataset 1


Average AUC on the dataset 2


0.9

0.8

0.7

1.0

0.9

0.8


0.9

0.8

0.7

1.0

0.8


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 3


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 4


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 5


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 6


1.0

0.8


0.8

0.6

0.9

0.8


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 7


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 8


0.7

0.6

0.9

0.8

0.7


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 9


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55

h

Average AUC on the dataset 10


1.0

0.9


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55


8

32
64

128
256

0.05 0.35 0.65 0.95 1.25 1.55


Figure 8: The ROC-AUC scores obtained for 10 synthetic datasets under different configurations of
perturbation size h (horizontal axis), and the number of evaluations on each interaction pair (vertical
axis). We expect that given the fixed perturbation size h, the ROC-AUC scores will rise as the number
of evaluations increases. This is consistent with the observation that the bricks are brighter from
top to bottom. Also, we observed that with a properly chosen h ∈ [0.6, 0.9], the interactions can be
correctly detected with a relatively small number of evaluations (the bricks are brighter in the middle,
see dataset 3, 4, and 5).

_Proof. It’s equivalent to proof:_


_P_ ( _t,_ _r_ [n], _µr_ _µˆr(t)_ _Cr(t)_ ) 1
_{ ∀_ _∀_ _∈_ _|_ _−_ _| ≤_ _}_ _≥_ _−_ _n[2][2]_

The opposite of this event is


_t and r, s.t.,_ _µr_ _µˆr(t)_ _> Cr(t)._
_∃_ _|_ _−_ _|_


Since we have,


_P_ ( _µr_ _µˆr(t)_ _> Cr(t)_ ) _δ =_
_{|_ _−_ _|_ _}_ _≤_ _n[3]m_ _[,]_

and we evaluate at most nm times (n arms, each arm is pulled m times),

_P_ ( _t and r, s.t.,_ _µr_ _µˆr(t)_ _> Cr(t)_ ) _δnm = [2]_ _(union bound)_
_{∃_ _|_ _−_ _|_ _}_ _≤_ _n[2]_


_P_ ( _t,_ _r_ [n], _µr_ _µˆr(t)_ _Cr(t)_ ) 1 _(clean event)_
_{ ∀_ _∀_ _∈_ _|_ _−_ _| ≤_ _}_ _≥_ _−_ _n[2][2]_


-----

Using Lemma C.1, we restate Theorem 3.2 as follows.

**Theorem C.2 (Restating Theorem 3.2). With probability 1 −** Θ( _n[1][2][ )][, Algorithm 1 returns the][ k][-]_

_strongest interactions with at most_


24σ2

log(nm) _m_
∆[2]i _∧_

 


_M ≤_


_i=1_


_local interaction strength evaluations. This takes O_ _ni=1_ [log(][n][)] _σ[2]_ log(∆[2]inm)
P 


_∧_ _m_ _time._



_Proof. We first analyze the running of algorithm till the first strongest interaction comes out. If we_
choose to update arm i ̸= i[∗]1 [at time][ t][, then we have]

_µˆi(t) + Ci(t) ≥_ _µˆi[∗]1_ [(][t][) +][ C][i]1[∗] [(][t][)][.] (6)

For equation 6 to occur, at least one of the following three events must occur:

_E1 =_ _µˆi[∗]1_ [(][t][)][ ≤] _[µ][i]1[∗]_ _[−]_ _[C][i]1[∗]_ [(][t][)] _,_

2 = µˆi(t) _µi + Ci(t)_ _,_
_E_ _{_ _≥_ _}_

3 = ∆[(1)]i = µi[∗]1 _._
_E_ _[−]_ _[µ][i][ ≤]_ [2][C][i][(][t][)]
n o


To see this, note that if none of E1, E2, E3 occurs, we have

([¬]E2) ([¬]E3)
_µˆi(t) + Ci(t)_ _<_ _µi + 2Ci(t)_ _<_ _µi[∗]1_


([¬]E1)
_<_ _µˆi[∗]1_ [+][ C][i]1[∗] [(][t][)][.]


From Lemma C.1, E1 and E2 do not occur during the run of the algorithm with probability 1 − _n2[2][,]_

because


w.p. 1
_−_ _n[2][2]_



: _µi_ _µˆi(t)_ _Ci(t),_ _i_ [n], _t._ (7)
_|_ _−_ _| ≤_ _∀_ _∈_ _∀_


It also implies w.p. 1 − Θ( _n[1][2][ )][, the algorithm does not stop pulling arm][ i][ until event][ E][3][ stops]_

occurring.

Let ζi[(][w][)] index the iteration in which Algorithm 1 evaluates arm _i for the last time before declaring_
_A_
it to be the w-th strongest interaction. Let’s first consider how many pulls are needed for each arm to

pick out the first strongest interaction. If Ci(ζi[(1)]) 2i for arm _i, then we can stop evaluating_
_≤_ [∆][(1)] _A_

arm _i, that is,_
_A_


∆[(1)]i


2σ[2] log n[3]m

or Ci(ζi[(1)]) = 0,
_Ti(ζi[(1)])_


8σ[2]
= _Ti(ζi[(1)])_ _i_ ) _m._
_⇒_ _≥_ (∆[(1)]i [)][2][ log(][n][3][m][)][ or][ T][i][(][ζ] [(1)] _≥_

Note thatmost 8σ T[2] _i(t) denotes for the number of pulls of arm Ai at iteration t. We will evaluate arm Ai at_

evaluations satisfying(∆[(1)]i )[2][ log(][n][3][m][)][ ∧] _[m][ times. To pick out the first strongest interaction, we need at most][ M]_


8σ[2]

(∆[(1)]i [)][2][ log(][n][3][m][)]


_M ≤_


_∧_ _m_


_i=1_


-----

This result can be extend to find all top k strongest interactions concretely,


8σ[2]

(∆[(]i[k][)])[2][ log(][n][3][m][)]

24σ[2] _√m)_

(∆[(]i[k][)])[2][ log(][n][ 3]


_M ≤_


_∧_ _m_

! _∧_ _m_

_∧_ _m!_


_i=1_

_n_

_i=1_

X


_n_

24σ[2]

_≤_ _i=1_ (∆[(]i[k][)])[2][ log(][nm][)]! _∧_ _m!_ _._

X

The Algorithm 1 takes O _ni=1_ [log(][n][)] _σ[2]_ log(∆[2]inm) _∧_ _m_ time, where O(log(n)) is the time

for maintaining a priority queue(to find the minimal LCB or maximal UCB) in each iteration.P   

**Theorem C.3c** [0, 1], then the expected pulls of arms (over randomness in (Remark 3.1). If we further assume that ∆i ∼N ∆(γ,i) satisfies 1), for some γ, and m = cn, for
_∈_

E[M ] ≤O(n log(nm) + km)

_with probability 1 −_ Θ( _n[1][2][ )][ over randomness in Algorithm 1. Thus, the expected running time is well]_

_bounded by O(n log(nm) log(n) + km log(n))._

_Proof. This follows directly from the Appendix 2 of Bagaria et al. (2018a)._

D DATASETS PRE-PROCESSING

D.1 SYNTHETIC TEST SUITE

To make our experimental results convincing, we follow the test suite ever used in Tsang et al. (2018a)
with the details given in Table 4. Among others, F1 is a widely used test function for interaction
detection, which can be generated as described in Sorokina et al. (2008). For all the other functions,
_i.i.d._
the input dimension is set to 10, and x1, . . ., x10 _U_ ( 1, 1).
_∼_ _−_

Table 4: Test suite of data-generating functions



|F (x) 1|πx1x2√ 2x 3 −sin−1(x 4) + log(x 3 + x 5) − xx 9 rx x7 −x 2x 7 10 8|
|---|---|
|F (x) 2|πx1x2p 2|x 3| −sin−1(0.5x 4) + log(|x 3 + x 5| + 1) + 1 +x |9 x 10|r 1 +x 7 |x 8| −x 2x 7|
|F (x) 3|+1 exp |x 1 −x 2| + |x 2x 3| −(x2 3)|x4| + log(x2 4 + x2 5 + x2 7 + x2 8) + x 9 + 1 x2 10|
|F (x) 4|+1 exp |x 1 −x 2| + |x 2x 3| −(x2 3)|x4| + (x 1x 4)2 + log(x2 4 + x2 5 + x2 7 + x2 8) + x 9 + 1 x2 10|
|F (x) 5|1 p 1 + x2 + x2 + x2 + exp(x 4 + x 5) + |x 6 + x 7| + x 8x 9x 10 1 2 3|
|F (x) 6|q exp (|x 1x 2| + 1) −exp(|x 3 + x 4| + 1) + cos(x 5 + x 6 −x 8) + x2 8 + x2 9 + x2 10|
|F (x) 7|(arctan(x 1) + arctan(x 2))2 + max(x 3x 4 + x 6, 0) − 1 + (x 4x 51 x 6x 7x 8)2 + 1 +|x 7 |x| 9|5 +X i1 =0 1x i|
|F (x) 8|x 1x + 2x3+x5+x6 + 2x3+x4+x5+x7 + sin(x sin(x + x 9)) + arccos(0.9x 10) 2 7 8|
|F (x) 9|tanh(x 1x 2 + x 3x 4)p |x 5| + exp(x 5 + x 6) + log (x 6x 7x 8)2 + 1+ x 9x 10 + 1 + 1 |x 10||
|F (x) 10|sinh (x + x 2) + arccos (tanh(x + x + x 7)) + cos(x + x 5) + sec(x 7x 9) 1 3 5 4|


D.2 REAL DATASETS


All the real datasets are publicly available. We preprocessed the datasets as follows. For Parkinsons
data, we remove the column motor UPDRS and predict the total UPDRS. For SkillCraft data, the


-----

target is set to be LeagueIndex. For the Bike sharing data, the feature weather is converted into a onehot representation. Before feeding the data into neural networks, we performed data normalization
first for all datasets.

The Drug combination dataset is processed as follows. There are 110 features extracted, among
which the first 50 features are the concentration of 50 unique FDA-approved drugs, and the last 60
features are the one-hot encodings for the cell lines.

E ROC-AUC FOR PAIRWISE INTERACTION DETECTION

We calculate the ROC-AUC scores for the synthetic datasets, where the ground truth interaction pairs
are known. To obtain the ROC-AUC value, two vectors are needed, namely the pairwise interaction
_score ∈_ R[45]+ [and][ ground truth][ ∈{][0][,][ 1][}][45][, both of them are of dimension][ p][(][p]2[−][1)] = 45. By setting

different thresholds for the pairwise interaction score ranking, different classifiers with False Positive
(FP) rate and True Positive (TP) rate can be obtained. The ROC-AUC value is approximated from
those (FP, TP) pairs by the trapezoidal rule.

F PAIRWISE INTERACTION DETECTION ON HIGH- DIMENSIONAL DATASETS

We created two new high-dimensional datasets by simply combining the 10 synthetic datasets
considered in the paper. The new datasets have either 50 (using F1-F5) or 100 features (using F1-F10).
The labels of the two datasets are the sum of the original labels in each dataset of input dimension
_p = 10. The training sample size is increased to 500,000 to mimic big data. We compared 5 different_
model architectures and our method consistently outperforms NID, see the Table 5 below for the
results.

Table 5: ROC-AUCs comparison for high-dimensional datasets

1 Big network: p-5000-900-400-100-30-1

|ROC-AUC score (NID/Ours)|data size: 500,000 * 100 data size: 500,000 * 50|
|---|---|
|Big network1 with main effect + L1reg|0.743/0.768 0.831/0.864|
|Big network without main effect + L1reg|0.699/0.700 0.803/0.855|
|Small network2 with main effect + L1reg|0.731/0.744 0.836/0.859|
|Small network without main effect + L1reg|0.701/0.742 0.796/0.840|
|Standard big network without main effect|0.646/0.653 0.583/0.793|

2 Small network: p-140-100-60-20-1

Here we also report the computational complexity of our UCB-based interaction detection method.
Due to the randomness of the UCB algorithm, the number of pulls fluctuates. Note that we select
top k = 200 interaction pairs for 100-dimensional case, and the total number of pulls is around
40000, while the naive approach needs 100 × 100 × 99/2 = 495000 pulls. We select top k = 100
interaction pairs for 50-dimensional case, and the total number of pulls is around 21000, while the
naive approach needs 100 × 50 × 49/2 = 122500 pulls.

**Discussion on High Dimensional Data: For high dimensional data, the Hessian matrix will be**
too huge to handle. One possible solution is to focus on the important features. We may first take
advantage of DeepLIFT(Shrikumar et al., 2017) or SHAP (Lundberg & Lee, 2017) to screen out the
most important features, and then apply our interaction detection method. If the number of important
features is still too large to handle, we may use ANOVA and F-test to select an affordable number of
interaction candidates to pull log(n) times, and explore the remaining pairs with a small probability,
say 5%, like the common strategy used in reinforcement learning..

G EXTENSION TO HIGHER-ORDER INTERACTIONS

We define three-way interaction as follows, and higher-order interactions can be defined similarly.


-----

**Definition G.1 (three-way interaction). A function F : R[p]** _→_ R is said to exhibit an interaction
_among three of its variables xi, xj and xk if,_


2
_> 0._



_∂[3]F_ (x)

_∂xi∂xj∂xk_


_Ex_


The naive method to detect higher-order interactions is quite similar to FANOVA graph (Muehlenstaedt et al., 2012). We give three examples of detecting higher-order interactions from the synthetic
data. We detect the pairwise interaction strength first, then build a weighted graph (the edge weight
corresponds to the interaction strength). By setting a proper number of clusters, higher-order interactions can be discovered correctly, see Figure 9.

(a) y = x0x1 + x2x3x4 + x5x6x7 + x8x9

(b) y = e[|][x][0][−][x][1][|] _x9 +_ _x2_ _x3_ _x[2]4[|][x][5][|]_ + (x6x7)[2] + x8
_∗_ _|_ _∗_ _| −_

(c) y = x0x1 + |x1 + x2x3| + x4x5 − (x[2]5[)][x][6][ −] _[e][x][7][+][x][8][x][9]_

5

8

6

9

7

1 2

3

0

4

8

3

2

1 0 4

9 6

7 5

6

4 5

9

2

7 8

3

1

0


(a) (b) (c)

Figure 9: The nodes (features) are clustered correctly. The color of edges indicates pairwise interaction
strength. Nodes with the same color belong to the same cluster.

**Algorithm 2 Hierarchical Higher-Order Interaction Detection**

**Require: The target number of i-way interactions {k[(][i][)]}i[p]=2[.]**

1: Detect top-k[(2)] pairwise interaction via UCB algorithm.
2: Construct an undirected graph G based on the detected pairwise interactions.
3: Enumerate all the cliques C in the graph G.
4: for i = 3, 4, · · ·, p do
5: **if C[(][i][)]** = ∅ **then**

6: **break**

7: **end if**

8: Find C[(]refine[i][)] [=][ {][C][ ∈] [C][(][i][)][ |][ every][ i][ −] [1][ complete subgraph of][ C][ admits a detected interaction][}]

9: Detect the top k[(][i][)]-strongest i-way interactions in C[(]refine[i][)] [via the UCB algorithm.]

10: end for
11: return All the detected interactions with their strengths.


One drawback of the above naive clustering method is that it doesn’t allow for the overlap of nodes,
i.e. one variable may appear in several interactions (F8 in the test suite). To address the above
problem, we propose the Algorithm 2, which detects the higher-order interactions hierarchically.
We first construct an undirected graph G from the detected pairwise interactions. To shrink our
search space for higher-order interactions, we restrict ourselves to the set of all cliques C of the
graph G, where a clique C ∈ C in a graph is a subset of vertices that are all joined by edges. We
use C[(][i][)] _⊆_ C to denote the collection of the i-cliques (the cliques with i vertices). For example,
to detect 3-way interactions, one only needs to search in the C[(3)], which contains the cliques with
three vertices. Furthermore, we can shrink the search space to C[(]refine[i][)] [for][ i][-way interactions, based]
on the detected (i − 1)-way interactions (see line 8 in Algorithm 2). For example, while detecting
4-way interactions, we put 4-clique {2, 3, 4, 6} into consideration only if all the 3-way interactions
_{3, 4, 6}, {2, 4, 6}, {2, 3, 6}, {3, 4, 6} exist. We then use the UCB algorithm to verify if the cliques_


-----

in Crefine[(][i][)] [admit the interaction relationship. In this way, we detect the][ i][-way interactions from the]
detected (i − 1)-way interactions information.

The 3-way interaction strength can be calculated from Equation 8. However, with the order of
interaction increasing, the number of function evaluations for one gradient computation increases
geometrically. We do not recommend detecting the interaction whose order is higher than four,
which is uneconomical to compute and hard to interpret. We found our proposed Algorithm 2 can
successfully detect the higher-order interactions for F8 in the test suite [2].


_∂[2]F_ (x)

_∂xi∂xj∂xk_


8h[3][ [+][F] [(][x][ +][ h][(][e][i][ +][ e][j][ +][ e][k][)) +][ F] [(][x][ +][ h][(][−][e][i][ −] **[e][j][ +][ e][k][))]**

+ F (x + h(ei − **ej −** **ek)) + F** (x + h(−ei + ej − **ek))**
_−_ _F_ (x + h(−ei + ej + ek)) − _F_ (x + h(ei − **ej + ek))**
_−_ _F_ (x + h(ei + ej − **ek)) −** _F_ (x + h(−ei − **ej −** **ek))]**


(8)


H MORE ON THE PARAMETRIC ACE

In section 4, we introduced a parametric ACE model based on the following generalized linear
additive model with main effects and pairwise feature interactions, namely,


_βp+iri (x_ _i_ ; θri ) + ϵ. (9)
_I_
_i=1_

X


_θ(Y ) =_


_βisi (xui_ ; θsi ) +
_i=1_

X


The consideration of interactions improves the model performance significantly, compare to Generalized Additive Neural Networks (GANN)(Potts, 1999; Agarwal et al., 2020)[3], see Table 6.

Table 6: NRMSE of the GANN versus our proposed ParaACE network on the synthetic datasets in
(Table 4). (The results were averaged over 5 folds.)

_F1_ _F2_ _F3_ _F4_ _F5_ _F6_ _F7_ _F8_ _F9_ _F10_ average CR

GANN 0.033 0.063 0.064 0.068 0.053 0.052 0.028 0.032 0.040 0.033 **0.046** **959**
ParaACE 0.025 0.035 0.031 0.030 0.038 0.025 0.016 0.019 0.023 0.021 **0.026** **283**

The idea behind the original nonparametric ACE algorithm (Breiman & Friedman, 1985) is to
alternate between an inner process for finding the optimal transformation functions of the inputs and
an outer process for finding the optimal transformation function of the output.

Here, we made several modifications. First, all the transformation functions are represented by small
subnetworks. Second, we reformulate the above regression equation approximately as


_Y ≈_ _θ[−][1]_


(10)


_βisi (xui_ ; θsi ) +
_i=1_

X


_βp+iri (x_ _i_ ; θri )
_I_
_i=1_

X


Therefore, the fix-up layer shown in Figure 3 can be understood as the inverse optimal transformation
of the output θ[−][1](·). To be more general, θ[−][1](·) takes all input transformations as individuals instead
of their high-level summary (weighted sum). Our parametric ACE then alternately tunes the fix-up
layer conditioned on the current optimal transformation layer (outer iteration) and tunes the optimal
transformation layer conditioned on the current fix-up layer until some convergence condition is met.

Another important function of the fix-up layer is to alleviate the negative impacts of wrongly detected
pairwise interactions and/or undetected higher-order interactions altogether on the output. For
this purpose, we could make this fix-up layer a network of small subnetworks, so that the whole
architecture is a network of small subnetworks. Each subnetwork can be regarded as a meta-neuron
that is expected to be more competent than any SOTA activation function. With such a nice structure,

[2A demo can be found at https://github.com/zhangtj1996/ParaACE.](https://github.com/zhangtj1996/ParaACE)
3GANN is a parametric version of GAM, which only considers the transformations of univariates (single
features).


-----

we have divided the hyper-parameters naturally into blocks and the whole network can hopefully be
made adaptive to new tasks more rapidly by tuning just a few blocks.

It is possible for ParaACE to learn “contradictory” models, which present the same function
(Lengerich et al., 2020). For example, the main effect might be absorbed into the interaction
effects. Thus the direct interpretation through subnetworks may not sound that convincing. Lengerich
et al. (2020) proposed an algorithm to purify the interaction effect by calculating the functional
ANOVA (Hooker, 2007), based on a piecewise-constant function _F[ˆ]. This algorithm is applicable_
to any function F by first constructing a piecewise-constant approximation _F[ˆ]. Particularly, for our_
ParaACE model, the overall computation will be much easier since we explicitly have the univariate
and bi-variate feature transformation. The number of bins required to approximate ParaACE with _F[ˆ]_
reduces significantly, and so does the complexity of the follow-up purifying algorithm.

I EXTENSION TO CLASSIFICATION TASK

We generated the datasets for binary classification from the synthetic regression datasets (1000
samples with injected noise). We choose the median of the target as a threshold to separate each
synthetic regression the dataset into two classes. The comparison between the baseline OverparaFC
and our proposed ParaACE in terms of classification accuracy is shown in Table 7. For real-world
datasets, we picked Higgs Boson (Baldi et al., 2014), Spambase (Dua & Graff, 2017), and Diabetes
(Turney, 1994).Both the classification accuracy and the compression ratio are reported in Table 8.

Table 7: Accuracy of the baseline OverparaFC versus our proposed ParaACE network on the synthetic
classification datasets. The results were averaged over 5 folds.

_F1_ _F2_ _F3_ _F4_ _F5_ _F6_ _F7_ _F8_ _F9_ _F10_ Average CR

OverparaFC 0.955 0.896 0.887 0.872 0.907 0.939 0.964 0.971 0.932 0.953 **0.927** **1**
ParaACE 0.949 0.908 0.94 0.946 0.916 0.94 0.96 0.935 0.919 0.942 **0.936** **283**

Table 8: Performance comparison between OverparaFC and ParaACE on various real-world classification datasets.

|Datasets N p|OverparaFC Accuracy Parameters|ParaACE Accuracy CR|
|---|---|---|
|Higgs Boson 98050 28 Spambase 4601 57 Diabetes 768 8|0.698 ± 3.0e −3 5049461 0.950 ± 8.0e −3 5194461 0.741 ± 2.5e −2 4949461|0.730 ± 2.8e −3 184 0.950 ± 7.9e −2 120 0.789 ± 1.7e −2 302|



J DETECTED PAIRWISE INTERACTIONS FOR SYNTHETIC AND REAL DATA

**Synthetic data: Figure 10 shows the pairwise interaction strength produced by our proposed method.**

**Real data: We provide the detected interactions for five real datasets in Figure 11. For the Cal**
housing dataset, we terminate the UCB algorithm when k = 20 interactions stood out; for the other
four datasets, we terminate at k = 50. The green, orange, and blue points represent the UCB,
estimated mean, and LCB respectively. For the drug combination dataset, the results are shown in
Figure 12.

K EMPIRICAL RESULT FOR SAMPLE EFFICIENCY

Figure 13 shows our proposed framework is sample efficient. The data are from the test suite (Table 4),
and noise η is injected. Increasing the training sample size, both over-parameterized neural nets and
our proposed ParaACE perform better. But ParaACE is less data-hungry since fewer training samples


-----

x1 x1 x1 x1 x1

x2 X x2 X x2 X x2 X x2 X

x3 X X x3 X X x3 X x3 X x3 X X

x4 x4 x4 X x4 X X x4

x5 X x5 X x5 X x5 X x5 X

x6 x6 x6 x6 x6

x7 X x7 X x7 X X x7 X X x7 X

x8 X x8 X x8 X X X x8 X X X x8

x9 X X x9 X X x9 x9 x9 X

x10 X X X x10 X X X x10 x10 x10 X X

x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10


_F1_ _F2_ _F3_ _F4_ _F5_

x1 x1 x1 x1 x1

x2 X x2 X x2 X x2 X x2 X

x3 x3 x3 x3 X X x3

x4 X x4 X x4 X x4 X X X x4

x5 x5 X x5 X X x5 X X X X x5 X X

x6 X x6 X X X x6 X X x6 X x6

x7 x7 X X X x7 X X X x7 X x7 X X

x8 X X x8 X X X X x8 x8 X X x8

x9 X x9 X x9 X x9 x9 X

x10 X X x10 x10 x10 X x10

x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10 x1 x2 x3 x4 x5 x6 x7 x8 x9x10


_F6_ _F7_ _F8_ _F9_ _F10_

Figure 10: Heat maps of pairwise interaction strength proposed by our method for functions F1-F10
(Table 4). Cross-marks indicate the ground truth interactions.

are needed for ParaACE to achieve a similar performance of the over-parameterized neural nets. The
experiments show that ParaACE still performs well, even if with small training samples.

L DETAILS ON THE COMPARISON WITH KD, LTH, AND SYNFLOW

L.1 COMPARISON WITH KD

KD is widely used for multi-class classification problems, which extracts knowledge from the ”soft
label” by controlling the temperature, but fewer KD methods are there for regression problems.
Currently, people mainly use the Teacher bounded regression loss (Chen et al., 2017) and the hint loss
to deal with the objective detection problem. Passing unlabeled data to the Teacher model to produce
pseudo labels can also help. In these ways, the Student is expected to have a similar performance to
the Teacher.

We let an over-parameterized FC (10-5000-900-400-100-30-1) be the Teacher, and a ReLU network
with architecture (10-70-70-70-70-30-1) be the Student. The Student is trained with 800 original
data and 4000 pseudo data (labeled by the Teacher). The loss function we adopted is L2 + Hint loss,
where the Hint loss is used on the layer with 30 neurons.

It shows that KD trained with pseudo data and carefully designed loss function achieves similar
performance as the Teacher, while ParaACE trained with original data and simple L2 loss achieves
significantly better performance.

L.2 COMPARISON WITH LTH

We used the pruning technique proposed in the lottery tickets hypothesis (LTH) paper (Frankle &
Carbin, 2019). We pruned the fully connected neural network after every 20 epochs. Every time 20
% weights were pruned in each layer except for the last layer. We trained 500 epochs, and set the
batch size to be 400. We report the best test performance in each round of pruning in Figure 14.

Figure 14 shows that, in most cases pruning the network properly can improve the model performance.
But if the network was over-pruned, the performance may drop.

L.3 COMPARISON WITH SYNFLOW

We implemented the single shot SynFlow for regression tasks based on the official code repository
[https://github.com/ganguli-lab/Synaptic-Flow (Tanaka et al., 2020). The sparsity is set to 10[−][2][.][447]](https://github.com/ganguli-lab/Synaptic-Flow)
for synthetic datasets, thus the neural network is compressed 280 times. For real-world datasets, we


-----

Elevators

climbRate

Sgz

p

q

curRoll

absRoll

diffClb

diffRollRate

diffDiffClb

SaTime1
SaTime2
SaTime3
SaTime4

diffSaTime1
diffSaTime2
diffSaTime3
diffSaTime4

Sa

climbRateSgzpcurRollq absRolldiffRollRatediffClbdiffDiffClb SaTime1SaTime2SaTime3diffSaTime1SaTime4diffSaTime2diffSaTime3diffSaTime4Sa


Confidence interval for each arm

0.5

0.4

0.3

0.2

0.1

0.0

0 20 40 60 80 100 120 140 160

Arms' index




Parkinsons

subject#

age
sex

test_time

Jitter(%)

Jitter(Abs)

Jitter:RAP

Jitter:PPQ5

Jitter:DDP

Shimmer

Shimmer(dB)

Shimmer:APQ3
Shimmer:APQ5

Shimmer:APQ11

Shimmer:DDA

NHR
HNR

RPDE

DFA

PPE

subject#agetest_timesexJitter(%)Jitter(Abs)Jitter:RAPJitter:PPQ5Jitter:DDPShimmer(dB)ShimmerShimmer:APQ3Shimmer:APQ5Shimmer:APQ11Shimmer:DDANHRHNRRPDEDFAPPE


Confidence interval for each arm

0.175

0.150

0.125

0.100

0.075

0.050

0.025

0.000

0 25 50 75 100 125 150 175 200

Arms' index


SkillCraft

ComplexAbilitiesUsedMinimapRightClicksComplexUnitsMadeTotalMapExploredGapBetweenPACsUniqueUnitsMadeAssignToHotkeysSelectByHotkeysMinimapAttacksNumberOfPACsUniqueHotkeysHoursPerWeekActionLatencyWorkersMadeActionsInPACTotalHoursAPMAgeid

HoursPerWeekSelectByHotkeysTotalHoursAssignToHotkeysidAgeUniqueHotkeysMinimapRightClicksMinimapAttacksAPMGapBetweenPACsNumberOfPACsActionLatencyTotalMapExploredActionsInPACUniqueUnitsMadeComplexUnitsMadeComplexAbilitiesUsedWorkersMade


Confidence interval for each arm

0.015

0.010

0.005

0.000

0.005

0.010

0.015

0 25 50 75 100 125 150 175

Arms' index



Bike sharing

season

yr

mnth

hr

holiday

weekday

workingday

temp

atemp

hum

windspeed

weathersit_1
weathersit_2
weathersit_3
weathersit_4

seasonyrmnthholidayhrweekdayworkingdaytempatempwindspeedweathersit_1humweathersit_2weathersit_3weathersit_4


Confidence interval for each arm

0.08

0.06

0.04

0.02

0.00

0.02

0 20 40 60 80 100

Arms' index


Cal housing

longitude

latitude

housingMedianAge

totalRooms

totalBedrooms

population

households

medianIncome

longitudehousingMedianAgelatitudetotalRoomstotalBedroomspopulationhouseholdsmedianIncome

Confidence interval for each arm

0.175

0.150

0.125

0.100

0.075

0.050

0.025

0.000

0.025

0 5 10 15 20 25

Arms' index

Figure 11: Left: Heat maps of pairwise interaction strengths on real datasets. Right: Confidence
interval for each interaction pair. The green, orange, blue points denote the UCB, estimated mean,
and LCB respectively.


-----

Amifostine; Cabazitaxel Vandetanib; Mitoxantrone
Estramustine phosphate sodium; Mitoxantrone Vismodegib; Cabazitaxel
Thioguanine; Gefitinib Megestrol acetate; Mitoxantrone
Thioguanine; Mitoxantrone Tamoxifen citrate; Cabazitaxel
Thioguanine; Cytarabine hydrochloride Quinacrine hydrochloride; Mitoxantrone
Thioguanine; Cabazitaxel Vincristine sulfate; Cabazitaxel
Thioguanine; Floxuridine Uracil mustard; Cytarabine hydrochloride
Gefitinib; Mitoxantrone Mitoxantrone; Cytarabine hydrochloride
Gefitinib; Cytarabine hydrochloride Mitoxantrone; Cabazitaxel
Gefitinib; Cabazitaxel Mitoxantrone; Floxuridine
Ruxolitinib; Vinorelbine tartrate Cytarabine hydrochloride; Arsenic trioxide
Teniposide; Cytarabine hydrochloride Cytarabine hydrochloride; Cabazitaxel
Teniposide; Cabazitaxel Cytarabine hydrochloride; Everolimus
Vinorelbine tartrate; Axitinib Cytarabine hydrochloride; Floxuridine
Vinorelbine tartrate; Vandetanib Cabazitaxel; Everolimus
Vinorelbine tartrate; Cytarabine hydrochloride Cabazitaxel; Floxuridine
Crizotinib; Mitoxantrone Everolimus; Floxuridine

50 FDA approved drugs 60 cell lines


Figure 12: Heat maps of pairwise interaction strengths for drug combination data. The top 34 detected
interactions are listed, among which 15 of them (marked in red) are verified in the DrugBank (Wishart
et al., 2018).

compressed the model by 120 times. And we retrained the neural network after the single-shot prune
(post-training). Note that we did not prune the biases here.

We set the hyper parameters for the post-training process as follows. The batch size is set to be 500,
and the number of epochs is 100. We use Adam as the optimizer with lr = 0.001, betas = (0.9, 0.99).

M ACCURATE APPROXIMATION FUNCTION BENEFITS INTERACTION
DETECTION

Suppose the underlying ground truth function is f (x), and our approximation function is
_gθ(x), we omit the θ in the following._ We show that the estimation error for Hessian
_Ex_ _∂x∂[2]ig∂x(x)j_ _Ex_ _∂x∂[2]fi∂x(xj)_ is bounded by o(ϵ), when _f_ (x) _g(x)_ _< ϵ for all x. This im-_

_−_ _|_ _−_ _|_

plies more accurate pre-trained model leads to better interaction detection accuracy. According to theh i h i
following theorem, deep neural networks are good surrogate functions due to the universal function
approximation capability (Hornik, 1991).

**Theorem M.1. Assume xi are uniformly drawn from [−1, 1] independently, if there exist an ϵ > 0,**
_such that |f_ (x) − _g(x)| ≤_ _ϵ for all x ∈_ R[p], then

2 2
_∂_ _g(x)_ _∂_ _f_ (x)

_Ex_ _Ex_ _ϵ._

_∂xi∂xj_ _−_ _∂xi∂xj_ _≤_

   


_Proof._


2
_∂_ _g(x)_

_∂xi∂xj_

 

_∂[2]g(x)_

_p(x)dx_
_∂xi∂xj_


_Ex_


_∂[2]g(x)_

_∂xi∂xj_ _p(xi, xj)p(x\ij)dx_

1 1

_∂[2]g(x)_

_p(x\ij)_ Z−1 Z−1 _∂xi∂xj_ _p(xi, xj)dxidxjdx\ij_

[where p(xi, xj) = 1/4]

1 1

_∂[2]g(x)_

Z _p(x\ij)_ Z−1 Z−1 _∂xi∂xj_ _dxidxjdx\ij,_


= [1]


-----

where
1 1

_∂[2]g(x)_

_dxidxj_

Z−1 Z−1 _∂xi∂xj_

1

_∂g(x_ _ij, xi = 1, xj)_ _∂g(x_ _ij, xi =_ 1, xj)

= _\_ _−_ _\_ _−_ _dxj_
Z−1 _∂xj_

= _g(x_ _ij, xi = 1, xj = 1)_ _g(x_ _ij, xi = 1, xj =_ 1)
_\_ _−_ _\_ _−_

(g(x _ij, xi =_ 1, xj = 1) _g(x_ _ij, xi =_ 1, xj = 1)).
_−_ _\_ _−_ _−_ _\_ _−_ _−_


We can derive Ex _∂x∂[2]fi∂x(xj)_
h


in a similar fashion. Thus,


2
_∂_ _g(x)_

_∂xi∂xj_




_∂2f_ (x)

_∂xi∂xj_




_Ex_


_Ex_
_−_


= [1]

4 _[E][x][\][ij]_ [[][g][(][x][\][ij][, x][i][ = 1][, x][j][ = 1)][ −] _[f]_ [(][x][\][ij][, x][i][ = 1][, x][j][ = 1)]


_g(x_ _ij, xi =_ 1, xj = 1) + f (x _ij, xi =_ 1, xj = 1)
_−_ _\_ _−_ _\_ _−_

_g(x_ _ij, xi = 1, xj =_ 1) + f (x _ij, xi = 1, xj =_ 1)
_−_ _\_ _−_ _\_ _−_

+ g(x _ij, xi =_ 1, xj = 1) _f_ (x _ij, xi =_ 1, xj = 1)]
_\_ _−_ _−_ _−_ _\_ _−_ _−_

_≤_ [1]4 _[E][x][\][ij]_ [[4][ϵ][]]


=ϵ.

**Theorem M.2. Assume xi are uniformly drawn from [−1, 1] independently, and further assume**

_∂x[∂][2][f]i∂x[(][x]j[)]_ _,_ _∂x[∂][2]i[g]∂x[(][x][)]j_ _M,_ (xi, xj). If there exist an ϵ > 0, such that _f_ (x) _g(x)_ _ϵ for all_

_≤_ _∀_ _|_ _−_ _| ≤_
**x** R[p], then
_∈_ 2[#] 2[#]

_∂[2]g(x)_ _∂[2]f_ (x)

_Ex_ _Ex_ 2Mϵ.

_∂xi∂xj_ _−_ _∂xi∂xj_ _≤_

" "


_Proof._


2[#]


2[#]


2[#] 2[#]

_∂[2]g(x)_ _∂[2]f_ (x)

_Ex_ _Ex_

_∂xi∂xj_ _−_ _∂xi∂xj_

" "

2 2[#]

_∂[2]g(x)_ _∂[2]f_ (x)

=Ex

_∂xi∂xj_ _−_ _∂xi∂xj_

"

2 2
_∂_ _g(x)_ _∂_ _g(x)_

=Ex + _[∂][2][f]_ [(][x][)]

_∂xi∂xj_ _−_ _∂x[∂][2][f]i∂x[(][x]j[)]_ _∂xi∂xj_ _∂xi∂xj_

   

2 2
_∂_ _g(x)_ _∂_ _g(x)_

+ _[∂][2][f]_ [(][x][)]

_≤_  _∂xi∂xj_ _−_ _∂x[∂][2][f]i∂x[(][x]j[)]_  _[·]_  _∂xi∂xj_ _∂xi∂xj_

_≤ϵ ·[E] 2[x]M_ (Using Theorem M.1) _[E][x]_


_∂[2]g(x)_

_∂xi∂xj_

_∂[2]g(x)_


_Ex_
_−_





Note that M can be interpreted as the magnitude of the strongest local interaction. For the functions
with strong interactions, higher approximation quality is desired.


-----

Table 9: Ablation study to show the effectiveness of interaction detection on the synthetic datasets in
(Table 4). (The results were averaged over 5 folds.)

_F1_ _F2_ _F3_ _F4_ _F5_ _F6_ _F7_ _F8_ _F9_ _F10_ average CR

ParaACE (with random interaction) 0.026 0.042 0.035 0.034 0.060 0.032 0.017 0.025 0.044 0.031 **0.035** **283**
ParaACE (with detected interaction) 0.025 0.035 0.031 0.030 0.038 0.025 0.016 0.019 0.023 0.021 **0.026** **283**

N ABLATION STUDY FOR THE EFFECTIVENESS OF INTERACTION DETECTION

To show how much performance gain we are able to obtain from the interaction detection procedure.
We conduct an experiment that input random pairwise interactions to ParaACE to compare with the
one with detected interactions on synthetic datasets, see Table 9.


-----

Synthetic dataset 1

0.023 OverparaFC

ParaACE

0.022

0.021

0.020

test NRMSE

0.019

0.018

400 600 800 1000 1200 1400 1600

number of training samples


Synthetic dataset 2

0.050 OverparaFC

ParaACE

0.045

0.040

0.035

test NRMSE

0.030

0.025

0.020

400 600 800 1000 1200 1400 1600

number of training samples


0.07

0.06

0.05

0.04

0.03

0.02

Synthetic dataset 5

0.050 OverparaFCParaACE

0.045

test NRMSE 0.0400.035

0.030

0.025

400 600 800 1000 1200 1400 1600

number of training samples


0.022

0.020

0.018

0.016

0.014

0.012

0.010


0.07

0.06

0.05

0.04

0.03

0.02

Synthetic dataset 6

0.045 OverparaFC

0.040 ParaACE

0.035

0.030

0.025

test NRMSE

0.020

0.015

0.010

400 600 800 1000 1200 1400 1600

number of training samples


0.018

0.016

0.014

0.012

0.010

0.008


|Synthetic dataset 3|Col2|Col3|
|---|---|---|
|OverparaFC ParaACE||OverparaFC ParaACE|
||||
||||


400 600 800 1000 1200 1400 1600

number of training samples

Synthetic dataset 5

OverparaFC
ParaACE

400 600 800 1000 1200 1400 1600

number of training samples


|Synthetic dataset 4|Col2|Col3|
|---|---|---|
|OverparaFC ParaACE||OverparaFC ParaACE|
||||
||||


400 600 800 1000 1200 1400 1600

number of training samples

Synthetic dataset 6

OverparaFC
ParaACE

400 600 800 1000 1200 1400 1600

number of training samples


|Synthetic dataset 7|Col2|Col3|
|---|---|---|
|OverparaFC ParaACE||OverparaFC ParaACE|
||||


400 600 800 1000 1200 1400 1600

number of training samples

Synthetic dataset 9


|Synthetic dataset 8|Col2|Col3|
|---|---|---|
|OverparaFC ParaACE||OverparaFC ParaACE|
||||


400 600 800 1000 1200 1400 1600

number of training samples

Synthetic dataset 10


0.024

0.022

0.020

0.018

0.016

0.014


0.0325

0.0300

0.0275

0.0250

0.0225

0.0200

0.0175

|OverparaFC ParaACE|Col2|OverparaFC ParaACE|
|---|---|---|

|OverparaFC ParaACE|Col2|OverparaFC ParaACE|
|---|---|---|


400 600 800 1000 1200 1400 1600

OverparaFC
ParaACE

number of training samples


400 600 800 1000 1200 1400 1600

OverparaFC
ParaACE

number of training samples


Figure 13: Performance comparison on synthetic datasets while reducing the number of training
samples. For each dataset, we tried different training data 5 times in one experiment, and the
performances (of ten experiments) were all tested on the same test set. The error bar shows the
maximal and minimal test NRMSE in 5 folds.


-----

Synthetic data Real data

Synthetic dataset 1, LTH Synthetic dataset 2, LTH Elevators, LTH

0.16 0.058

0.07

0.14 0.056

0.12 0.06 0.054

0.10

0.052

Test NRMSE 0.08 Test NRMSE 0.05 Test NRMSE

0.050

0.06

0.04 0.04 0.048

0.02 0.046

100 50 20 5 1 0.5 100 50 20 5 1 0.5 100 50 20 5 1 0.5

Percents of Weights Remaining Percents of Weights Remaining Percents of Weights Remaining

Synthetic dataset 3, LTH Synthetic dataset 4, LTH Parkinsons, LTH

0.18

0.16 0.16 0.08

0.14 0.14 0.07

0.12 0.12 0.06

0.10 0.10 0.05

Test NRMSE 0.08 Test NRMSE 0.08 Test NRMSE 0.04

0.03

0.06 0.06

0.02

0.04 0.04

0.01

100 50 20 5 1 0.5 100 50 20 5 1 0.5 100 50 20 5 1 0.5

Percents of Weights Remaining Percents of Weights Remaining Percents of Weights Remaining

Synthetic dataset 5, LTH Synthetic dataset 6, LTH Skillcraft, LTH

0.16 0.30

0.09

0.14

0.08 0.25

0.12

0.07

0.10 0.06 0.20

Test NRMSE 0.08 Test NRMSE 0.05 Test NRMSE 0.15

0.06 0.04

0.04 0.03 0.10

100 50 20 5 1 0.5 100 50 20 5 1 0.5 100 50 20 5 1 0.5

Percents of Weights Remaining Percents of Weights Remaining Percents of Weights Remaining

Synthetic dataset 7, LTH Synthetic dataset 8, LTH Bike sharing, LTH

0.09 0.09 0.048

0.08 0.08

0.046

0.07 0.07

0.06 0.06 0.044

Test NRMSE 0.05 Test NRMSE 0.05 Test NRMSE 0.042

0.04 0.04

0.03 0.03 0.040

0.02 0.02 0.038

100 50 20 5 1 0.5 100 50 20 5 1 0.5 100 50 20 5 1 0.5

Percents of Weights Remaining Percents of Weights Remaining Percents of Weights Remaining

Synthetic dataset 9, LTH Synthetic dataset 10, LTH Cal housing, LTH

0.14 0.114

0.038

0.12 0.112

0.036

0.10 0.110

0.034

0.108

0.08

Test NRMSE 0.032 Test NRMSE Test NRMSE 0.106

0.06

0.030 0.104

0.028 0.04 0.102

0.026 0.02

100 50 20 5 1 0.5 100 50 20 5 1 0.5 100 50 20 5 1 0.5

Percents of Weights Remaining Percents of Weights Remaining Percents of Weights Remaining

Figure 14: Performance comparison on both the synthetic and real datasets while reducing the percent
of weights retained by the LTH. The error bar shows the maximal and minimal test NRMSE in 5
folds.


-----


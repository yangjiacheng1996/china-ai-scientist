# ON THE GENERALIZATION OF WASSERSTEIN ROBUST FEDERATED LEARNING

**Anonymous authors**
Paper under double-blind review

ABSTRACT

In Federated Learning (FL), participating clients typically possess non-i.i.d. data,
posing a significant challenge to generalization to unseen distributions. To address
this, we propose a Wasserstein distributionally robust optimization scheme called
WAFL. Leveraging its duality, we frame WAFL as an empirical surrogate risk
minimization problem, and solve it using a novel local SGD-based algorithm with
convergence guarantees. We show that the robustness of WAFL is more general
than related approaches, and the generalization bound is robust to all adversarial
distributions inside the Wasserstein ball (ambiguity set). Since the center location and radius of the Wasserstein ball can be suitably modified, WAFL shows its
applicability not only in robustness but also in domain adaptation. Through empirical evaluation, we demonstrate that WAFL generalizes better than the vanilla
FedAvg in non-i.i.d. settings, and is more robust than other related methods in
distribution shift settings. Further, using benchmark datasets we show that WAFL
is capable of generalizing to unseen target domains.

1 INTRODUCTION

Federated Learning (FL) (Koneˇcn´y et al., 2016; McMahan et al., 2017) has emerged as a cuttingedge technique in distributed and privacy-preserving machine learning. The nature of highly nonindependent and identically distributed (non-i.i.d.) data in clients’ devices poses an important challenge to FL commonly called statistical heterogeneity. The global model trained on this data using
the de facto FedAvg algorithm (McMahan et al., 2017) has been shown to generalize poorly to
individual clients’ data, and further to unseen distributions on new clients as they enter the network.

Several solutions to data heterogeneity have been proposed. Personalized FL (Fallah et al., 2020;
Deng et al., 2020a; Dinh et al., 2021; Li et al., 2021) and multi-task FL (Smith et al., 2018) are
_client-adaptive approaches, where a personalized model is adapted to each client. From another_
perspective, distributionally robust FL trains a model using a worst-case objective over an ambiguity
_set (Mohri et al., 2019; Du et al., 2020; Reisizadeh et al., 2020; Deng et al., 2020b). This approach_
is client-uniform because a single global model is judiciously learned to deliver uniformly good
performance not only for all training clients but also for new/unseen clients with unknown data distributions. It is specifically useful when test distributions drift away from the training distributions.

A natural question when designing distributionally robust FL frameworks is generalization: how can
minimizing the training error also bound the test error (generalization bounds)? In FL, Mohri et al.
(2019) proposed agnostic FL where a model is designed to be robust against any ambiguity set as a
convex combination of the clients’ distributions. Reisizadeh et al. (2020) applied the general affine
covariate shift – used in the standard adversarial robust training – into FL training. In characterizing
the generalization bounds, while Mohri et al. (2019) relied on the standard Rademacher complexity,
Reisizadeh et al. (2020) use the margin-based technique developed by Bartlett et al. (2017).

In this work, we take a different approach called WAsserstein distributionally robust FL (WAFL for
short). The ambiguity set in WAFL is a Wasserstein ball of all adversarial distributions in close
proximity to the nominal data distribution at the center. Our main contributions are:

-  We propose a distributionally robust optimization problem to address statistical heterogeneity in FL. By controlling the center and radius of the Wasserstein ball, we show that WAFL
is robust to a wider range of adversarial distributions than is agnostic or adversarial FL.


-----

-  To make WAFL more amenable to distributed optimization, we transform the original problem into a minimization of the empirical surrogate risk. We propose a local SGD-based algorithm to solve this surrogate problem. With additional Lipschitz smoothness conditions,
standard techniques can be applied to find the convergence rate for the proposed algorithm.

-  We show how WAFL’s output can reduce the test error by bounding its excess risk. We call
this the robust generalization bound as it is applicable to all adversarial distributions inside
the Wasserstein ball. By scaling the Wasserstein radius based on local data sizes, we show
this bound is applicable to the true (unknown) data distribution among all clients.

-  We show WAFL’s extra flexibility in controlling the location of the Wasserstein ball by
adjusting the nominal distribution. This enables applications such as multi-source domain
adaptation and robustness to all clients’ unknown distributions with minimal Wasserstein
radius.

-  Experimentally, we discuss how to control this radius for a given center location by finetuning a robust hyperparameter. We show that WAFL generalizes better than FedAvg in
non-i.i.d. settings and further outperforms existing robust methods in distribution shift settings. We finally explore WAFL’s capability in transferring knowledge from multi-source
domains to related target domains with much less data and/or without labels.

2 RELATED WORK

**Federated Learning was introduced in response to three challenges of machine learning at scale:**
massive data quantities at the edge, communication-critical networks of participating devices, and
privacy-preserving learning without central data storage (Koneˇcn´y et al., 2016; McMahan et al.,
2017). The de facto federated optimization algorithm – FedAvg (McMahan et al., 2017) – is based
on local stochastic gradient descent (SGD) and averaging and is often considered a baseline in FL.

Most challenges of FL are categorized into systems heterogeneity and statistical heterogeneity. The
former focuses on communication problems such as connection loss and bandwidth minimization.
This motivated some prior works to design more communication-efficient methods (Koneˇcn´y et al.,
2016; 2017; Suresh et al., 2017). On the other hand, statitical heterogeneity is concerned with
clients’ non-i.i.d. data, which is the main cause behind aggregating very different models leading to
one which does not perform well on any data distribution. To address this, many ideas have been
introduced. Li et al. (2020) provided much theoretical analysis of FL non-i.i.d. settings. Zhao et al.
(2018) proposed an FL framework which globally shares a small subset of data among clients to train
the model with non-i.i.d. data. Smith et al. (2018) introduced a multi-task FL framework in which
each client individually learns its own data pattern while borrowing information from other clients.
Mansour et al. (2020) proposed three approaches to adapt the FL model to enable personalization, in
reponse to distribution shift. Several personalized FL models have also been developed, including
Fallah et al. (2020); Deng et al. (2020a); Dinh et al. (2021); Li et al. (2021).

**Wasserstein Distributionally Robust Optimization (WDRO) aims to lean a robust model against**
adversarially manipulated data. The unknown data distribution is assumed to lie within a Wasserstein
ball centered around the empirical distribution (Kuhn et al., 2019). WDRO has received attention as
a promising tool for training parametric models, both in centralized and federated learning settings.

In centralized learning, many studies have proposed solutions based on WDRO problems for certain machine learning tasks (Shafieezadeh Abadeh et al., 2015; Gao & Kleywegt, 2016; Esfahani
& Kuhn, 2017; Chen & Paschalidis, 2018; Sinha et al., 2020; Blanchet et al., 2019; ShafieezadehAbadeh et al., 2019; Gao et al., 2020). For instance, Shafieezadeh Abadeh et al. (2015) considered
a robust logistic regression model under the assumption that the probability distributions lie in a
Wasserstein ball. Chen & Paschalidis (2018); Blanchet et al. (2019); Gao et al. (2020) leveraged
WDRO to recover regularization formulations in classification and regression. Gao & Kleywegt
(2016) proposed a minimizer based on a tractable approximation of the local worst-case risk. Esfahani & Kuhn (2017) used WDRO to formulate the search for the largest perturbation range as an
optimization problem and solve its dual problem. Sinha et al. (2020) introduced a robustness certificate based on a Lagrangian relaxation of the loss function which provably robust against adversarial
input distributions within a Wasserstein ball centered around the original input distribution.


-----

In FL, only a few works have explored the Wasserstein distance (Reisizadeh et al., 2020; Diamandis
et al., 2021). Specially, Reisizadeh et al. (2020) proposed FedRobust based on adversarial robust
training to enhance robustness. Regarding distributionally robust learning, Deng et al. (2020b) proposed DRFA, a communication efficient distributed algorithm. Besides, based on the agnostic FL
framework suggested by Mohri et al. (2019), Du et al. (2020) introduced AgnosticFair, a two-player
adversarial minimax game between the learner and the adversary, to achieve fairness.

3 WASSERSTEIN ROBUST FEDERATED LEARNING

3.1 EXPECTED RISK AND EMPIRICAL RISK MINIMIZATION IN FEDERATED LEARNING

In a federated setting, there are m clients, and each client i ∈ [m] := {1, . . ., m} has its data generating distribution Pi supported on domain Zi := (Xi, Yi). Consider the parametrized hypothesis
class H = _hθ | θ ∈_ R[d], where each member hθ is a mapping from Xi to Yi parametrized by
_θ. With zi := (xi, yi)_ _i, we use ℓ(zi, hθ), shorthand for ℓ(yi, hθ(xi)), to represent the cost of_
 _∈Z_
predictingsquare loss h ℓθ((zxi, hi) when the ground-truth label isθ) = ℓ(yi, hθ(xi)) = (θ[T]xi _y yi)i[2]. For example, ifcan be considered. In FL, all clients collaborate hθ(xi) = θ[T]xi and yi ∈_ R, a
_−_
with a server to find a global model θ such that the following sum weighted risk is minimized:


_λiEZi∼Pi_ _ℓ(Zi, hθ)_ _,_ (1)
_i=1_

X  


min
_θ∈R[d]_


where EZi∼Pi _ℓ(Zi, hθ)_ is client i’s expected risk and λi ≥ 0 represents the relative “weight”
of client i and _i=1_ _[λ][i][ = 1][.]_ Therefore, λ := [λ1, . . ., λm][⊤] belongs to a simplex ∆:=
_λ ∈_ R[m] : λ ≽ 0 and λ[⊤]1m = 1 . Define by Pλ := _i=1_ _[λ][i][P][i][ the mixed clients’ distribution]_
over m domains [P] :=[m] 1, . . ., _m_ . We denote by Z _Pλ a random data point Z generated by_
 _Z_ _{Z_ _Z_ _}_ _∼_
_Pλ, which means that the domain of client i is chosen with probability[P][m]_ **P(Z = Zi) = λi first, then**
a data point zi ∈Zi is selected with probability P(Zi = zi), Zi ∼ _Pi._

While the underlying distributions[ni] _Pλ. We abuse the notation [ Pnii] are unknown, clients have access to finite observations to denote the set of client i’s both observable data points and zi ∈_
their indexes. Let ∼ _Pni :=_ _n1i_ _zi_ [ni] _[δ][z]i_ [be the empirical distribution of][ P][i][, where][ δ][z]i [is the Dirac]

_∈_
point mass at zi. In general, we use the notation for quantities that are dependent on the training

P

data. Define by _Pλ[b] :=_ _i=1_ _[λ][i][ b]Pni the mixed empirical distribution of n =_ _i=1_ _[n][i][ training data]_
from m clients. The empirical risk minimization (ERM) problem of (1) is as follows: b

_m_ _m_

[b] [P][m] _ni_ 1 [P][m]

_θmin∈R[d]EZ∼Pλ_ _ℓ(Z, hθ)_ = _i=1_ _λiEZi∼Pni_ _ℓ(Zi, hθ)_ = _i=1_ _n_  _ni_ _zi_ [ni] _ℓ(zi, hθ),_ (2)

b   X b   X X∈

where λi = ni/n is often chosen in ERM of the standard FL (McMahan et al., 2017).

3.2 WASSERSTEIN ROBUST RISK IN FEDERATED LEARNING


Models resulting from (2) have been shown to be vulnerable to adversarial attacks and to lack of
robustness to distribution shifts. We consider a robust variant of the ERM framework, involving the
worst-case risk with respect to the p-Wasserstein distance between two probability measures. Given
a set Z, define d : Z × Z → [0, ∞) to be the cost of “transportation” between its two points.[1]
Suppose P and Q are two distributions on Z. Let Π(P, Q) be the set of probability measures π on
_Z × Z whose marginals are P and Q, called their couplings. In other words, π(A, Z) = P_ (A) and
_π(Z, A) = Q(A), ∀A ⊂Z. The p-Wasserstein distance between P and Q is defined as_

1/p

_Wp(P, Q) =_ _π∈Π(infP,Q)_ **E(Z,Z′)∼π** _d[p](Z, Z_ _[′])_ _._ (3)

   

This distance represents the minimum cost of transporting one distribution to another, where the
cost of moving a unit point mass is determined by the ground metric on the space of uncertainty
realizations. In this work, we mainly work with p = 2. Let _p(P, ρ) :=_ _Q : Wp(P, Q)_ _ρ_
_B_ _{_ _≤_ _}_

1The function d must satisfy non-negativity, lower semi-continuity and d(z, z) = 0, ∀z ∈Z.


-----

denote the Wasserstein ball centered at P (i.e., nomimal distribution) and having radius ρ ≥ 0. We
modify (2) into the following Wasserstein robust risk minimization in FL problem:

WAFL: _θmin∈R[d]_ supQ∈B(Pλ,ρ) **[E][Z][′][∼][Q]** _ℓ(Z_ _[′], hθ)_ _._ (4)

There are several merits to this framework. First, then b _ambiguity set_ _p(Pλ[o], ρ) contains all (contin-_
_B_
uous or discrete) distributions Q that can be converted from the (discrete) nominal distribution _Pλ_
at a bounded transportation cost ρ. Second, Wasserstein distances can be approximated from the[b]
samples. Based on the non-asymptotic convergence results of Fournier & Guillin (2015), we can

[b]
specify a suitable value for ρ to probabilistically bound Wp(P, Q) by the distance between their
empirical distributions Wp(P, _Q) (e.g., for multi-source domain adaptation)._

In any robust optimization problem, the ambiguity set is a key ingredient to defining the level of
robustness. We will compare[b] WAFL[b] in (4) with other approaches in terms of their ambiguity set.

**Agnostic** **FL.** Using this approach, existing techniques (Mohri et al., 2019; Deng et al., 2020b) minimize the
worst-case loss
maxλ ∆ **[E][Z][∼]P[b]λ** _ℓ(Z, hθ)_ _,_
_∈_

hence its distributional ambiguity set is _Q_ ∆ := _Pλ : λ ∈_
∆ _. While Agnostic FL’s ambiguity set is the static convex_
hull of _Pni_ _i_ [m][,][ WAFL][’s ambiguity set][ B][(][ b]Pλ b, ρ) can be

_∈_
adjusted by controlling the robustness level ρ and by position
Figure 1: Example of four FL clients

ing the ball center using b _λ, which is useful for domain adapta-_

with data distributions P1, . . ., P4. The

tion. Therefore, B(Pλ, ρ) can cover Q∆ by using appropriate shaded area (Agnostic FL’s ambiguity
values for ρ and λ (see Fig. 1). set) is covered by the blue ball with ra
**Adversarial robust FL.[b]** Using this approach, Reisizadeh dius ρ and centered at _Pλ (Wasserstein_

ambiguity set). For domain adaptation

et al. (2020) combines a general affine covariate shift in stan
with Q as a target domain, the nom
dard adversarial robust training with FL. Most existing tech- [b]

inal distribution (multi-source domain)

niques using this approach (Goodfellow et al., 2015; Kurakin
et al., 2017; Carlini & Wagner, 2017; Madry et al., 2019; is shifted to _Pλ′ such that W2(Pλ′_ _, Q)_

is minimal.

Tram`er et al., 2020) define an adversarial perturbation u at

[b] [b]

a data point Z, and minimize the worst-case loss over all perturbations: maxu∈U EZ∼Pλ _ℓ(Z +_
_u, hθ)_, where the ambiguity set is := _u_ R[d][+1] : _u_ _ϵ_ . In Appendix A, we show that
_U_ _∈_ _∥_ _∥≤_ b 
the Wasserstein ambiguity set also contains the perturbation points induced by the solution to this
 
adversarial robust training problem.

3.3 WAFL: ALGORITHM DESIGN AND CONVERGENCE ANALYSIS


The original form of WAFL in (4) is not friendly for distributed algorithm design. Fortunately, the
_Wasserstein robust risk (or_ (Pλ, ρ)-worst-case risk) has its dual formulation as follows (Gao &
_B_
Kleywegt, 2016; Sinha et al., 2020)
_Q_ sup(Pλ,ρ) **EZ[′][b]∼Q** _ℓ(Z_ _[′], hθ)_ = infγ≥0 _γρ[2]_ + EZ∼Pλ _φγ(Z, θ)_ _,_ (5)
_∈B_
   b  

where φγ(zi, θ) := sup[b] _ζ_ _ℓ(ζ, hθ)_ _γd[2](ζ, zi)_, and d[2](z, z[′]) = _x_ _x[′]_ + κ _y_ _y[′]_ _, κ >_
_∈Z_ _−_ _∥_ _−_ _∥[2]_ _|_ _−_ _|[2]_
0. The crux of using the dual is that the inner supremum problem (finding φγ) is easily solvable
when its objective is well-conditioned: if _ℓ_ is L-smooth and _d is 1-strongly convex, setting γ > L_
ensures that ζ _ℓ(ζ, hθ)_ _γd[2](ζ, z) is strongly concave, and using gradient ascent for the inner_
_7→_ _−_
supremum problem (for finding φγ) ensures linear convergence. For each zi let zi[∗] [be the solution to]
supζ _ℓ(ζ, hθ)_ _γd[2](ζ, zi)_ . Then, _θφγ(zi, θ) =_ _θℓ(zi[∗][, h][θ][)][ (Sinha et al., 2020, Lemma 1).]_
_∈Z_ _−_ _∇_ _∇_

Rather than find the optimal _γ in (5), we consider γ as a control parameter, and instead solve the_
following client-decomposable problem, which is amenable to distributed algorithm design.

_m_

_θmin∈R[d]EZ∼Pλ_ _φγ(Z, θ)_ = _i=1_ _λiEZi∼Pni_ _φγ(Zi, θ)_ _._ (6)

b   X b  []


-----

**Algorithm 1: Local SGD for WAFL**

1: for t = 0, 1, ..., T − 1 do // Global rounds



[P] [P]

|2: 3: 4: 5: 6: 7: 8: 9:|Sample a subset of clients S ⊂m t for client i ∈S in parallel do t Set local parameters: θ(t,0) = θt // Communication i for k = 0, 1, ..., K −1 do // Local rounds Sample a mini-batch Di from client i’s dataset θ i(t,k+1) = θ i(t,k) − |Dη ziP ∈Di∇θφ(z i, θ i(t,k)) i| Send θ(t,K)to server // Communication i Server: update θ(t+1) =P λ θ(t,K)/P λ i∈St i i i∈St i|
|---|---|


This motivates the development of Algorithm 1 for solving (6). The structure of WAFL is similar
to FedAvg with T communication rounds. We further note three key components of Algorithm 1
common to FL methods. First, client sampling (line 2) refers to the partial participation of clients
in each global round. Second, each client performs K local steps (line 5) before sending its local
model to the server,. Finally, stochastic approximation of a client’s gradient using a mini-batch
(lines 6 and 7) is necessary when the data size is large. The main difference between WAFL and
FedAvg is that WAFL aims to minimize the risk with respect to the surrogate loss φγ, rather than ℓ.

We show that the convergence of WAFL can be similarly characterized as that of FedAvg, the de
facto FL algorithm based on local SGD updates (McMahan et al., 2017). In FedAvg optimization,
we seek to establish the convergence when using the original loss function ℓ. On the other hand, in
WAFL the convergence is with respect to the surrogate loss φγ, through which the local and global
risks are defined by Fi(θ) := EZi∼Pi _φγ(Zi, θ)_ and F (θ) := EZ∼Pλ _φγ(Z, θ)_, respectively.

We first make the following assumptions, common to analyses of Wasserstein-robust optimiza-   
tion (Sinha et al., 2020). Unless stated otherwise, all norms are the Euclidean norm.
**Assumption 1. The function d : Z × Z →** R+ is continuous, and d(·, z0) is 1-strongly convex,
_z0_ _._
_∀_ _∈Z_
**Assumption 2. The loss function ℓ** : Z × H → R is Lipschitz continuous as follows

(a) _ℓ(z, hθ)_ _ℓ(z[′], hθ)_ _Lz_ _z_ _z[′]_ _,_ (b) _ℓ(z, hθ)_ _ℓ(z, hθ′_ ) _Lθ_ _θ_ _θ[′]_ _._
_∥_ _−_ _∥≤_ _∥_ _−_ _∥_ _∥_ _−_ _∥≤_ _∥_ _−_ _∥_

**Assumption 3. The loss function ℓ** : Z × H 7→ R is Lipschitz smooth as follows

_θℓ(z, hθ)_ _θℓ(z, hθ′_ ) _Lθθ_ _θ_ _θ[′]_ _,_ _zℓ(z, hθ)_ _zℓ(z[′], hθ)_ _Lzz_ _z_ _z[′]_ _,_
_∥∇_ _−∇_ _∥≤_ _∥_ _−_ _∥_ _∥∇_ _−∇_ _∥≤_ _∥_ _−_ _∥_

_θℓ(z, hθ)_ _θℓ(z[′], hθ)_ _Lθz_ _z_ _z[′]_ _,_ _zℓ(z, hθ)_ _zℓ(z, hθ′_ ) _Lzθ_ _θ_ _θ[′]_ _._
_∥∇_ _−∇_ _∥≤_ _∥_ _−_ _∥_ _∥∇_ _−∇_ _∥≤_ _∥_ _−_ _∥_

Given Assumption 3, it has been shown that the mapping θ _φγ(_ _, θ) is L-smooth with L =_
_7→_ _·_
_Lθθ +_ _[L]γ[θz]L[L]zz[zθ]_ _[, γ > L][zz][ (Sinha et al., 2020) (more detail in Appendix Lemma 2). In addition, we]_

_−_
make the following assumptions common to FL analysis (Wang et al., 2021).
**Assumption 4. The unbiased stochastic approximation of** _Fi(θ), denoted by gφi_ (θ) :=
_∇_

_θφγ(zi, θ), zi_ _Pi, has σ[2]-uniformly bounded variance, i.e., E_ _gφi_ (θ) _Fi(θ)_ _σ[2]._
_∇_ _∼_ _∥_ _−∇_ _∥[2][i]_ _≤_

**Assumption 5. The difference between the local gradient ∇Fi(θh) and the global gradient ∇F** (θ)
_is Ω-uniformly bounded, i.e., maxi supθ_ _Fi(θ)_ _F_ (θ) Ω.
_∥∇_ _−∇_ _∥≤_

Assuming complete participation of clients in every round (St = m, ∀t), using standard techniques
in Wang et al. (2021), we have:
**Theorem 1 (WAFL’s convergence for convex loss function). Let Assumptions 1–5 hold and the**
_mapping θ_ _ℓ(z, hθ) be convex. Denote by_ _θ[¯][(][t,k][)]_ _the “shadow” sequence, defined as_ _θ[¯][(][t,k][)]_ =
_m_ _7→_
_i=1_ _[λ][i][θ]i[(][t,k][)]_ _and by θ[∗]_ _the optimal solution to minθ∈Rd F_ (θ). If the client learning rate satisfies

2 2

P 1 _D_ _D_ 3 _D_ 3

_η_ min _,_ 1 2 1 1 2 1 1 1 2 _,_
_≤_ 3L _[,]_ 2√KT Λσ 48 3 K 3 T 3 L 3 Ω[¯] 3 _[,]_ 40 3 KT 3 L 3 Ω[¯] 3
 

b


-----

_then we have_


1 _T −1_ _K−1_ _LD2_ _σDΛ_ 21 13 Ω[¯] 32 D 34 13 Ω[¯] 23 D
E _F_ (θ[¯][(][t,k][)]) _F_ (θ[∗]) + _[L]_ 1 2 + _[L]_ 2
 _KT_ _t=0_ _k=0_ _−_  _≤O_ _KT_ [+][ b]√KT _K_ 3 T 3 _T_ 3

X X

_σ[2]_
_where ˆσ[2]_ := _|Di|_ _[,][ D][ :=][ ∥][θ][(0)][ −]_ _[θ][∗][∥]_ _[and][ Λ :=][ P]i[m]=1_ _[λ]i[2][.]_

We provide a proof of Theorem 1 in Appendix C.


1

_KT_




_T −1_

_t=0_

X


(7)


4 ROBUST GENERALIZATION BOUNDS

We show the generalization and robustness properties of WAFL’s output by bounding its excess risk.
Denote the loss class by := ℓ := _z_ _ℓ(z, h), h_, where we use f (resp. fθ) to
_F_ _◦H_ _{_ _7→_ _∈H}_ _∈F_
represent a generic loss (resp. a loss function parametrized by θ).
**Definition 1. Denote the expected risk and surrogate of Wasserstein robust risk of an arbitrary f**,
respectively, as follows

L(Pλ, f ) := EZ∼Pλ _ℓ(Z, h)_ and L[γ]ρ[(][P][λ][, f] [) :=][ E][Z][∼][P]λ _φγ(Z, f_ ) + γρ[2].

Then their excess risks are defined respectively as follows  h i

E(Pλ, f ) := L(Pλ, f ) inf and E[γ]ρ[(][P][λ][, f] [) :=][ L]ρ[γ][(][P][λ][, f] [)][ −] [inf] _ρ[(][P][λ][, f][ ′][)][.]_
_−_ _f_ _[′]∈F_ [L][(][P][λ][, f][ ′][)] _f_ _[′]∈F_ [L][γ]

If a distribution Q is in the ambiguity set (Pλ, ρ), we can bound its excess risk E(Q, f ) as follows.
_B_
**Lemma 1. Let Assumption 2 (a) holds and γ ≥** _Lz/ρ. For all f ∈F and for all Q ∈B(Pλ, ρ),_

E[γ]ρ[(][P][λ][, f] [)][ −] _[g][(][ρ, γ][)][ ≤]_ [E][(][Q, f] [)][ ≤] [E]ρ[γ][(][P][λ][, f] [) +][ g][(][ρ, γ][)][,]

_where g(ρ, γ) := 2Lzρ + |γ −_ _γ[∗]|ρ[2], and γ[∗]_ := arg minγ′≥0 Lρ[γ][′] [(][P][λ][, f] [)][.]

We provide a proof of Lemma 1 in Appendix D.
**Remark 1. Lemma 1 shows that the lower and upper bounds for E(Q, f** ) can be analyzed using
E[γ]ρ[(][P][λ][, f] [)][ and a two-component error term][ g][(][ρ, γ][)][. The first component,][ 2][L][z][ρ][, says that when][ ρ]
is increased – to allow for larger Wasserstein distance between the nominal Pλ and any worst-case
distribution Q – the difference between the excess risks E(Q, f ) and E[γ]ρ[(][P][λ][, f] [)][ increases, and this]
error is amplified at most by the Lipschitz constant Lz of the mapping z 7→ _ℓ(z, ·). The second_
component, |γ − _γ[∗]|ρ[2], addresses the sub-optimality error of a chosen value of γ, which is amplified_
when γ is drifted away from the optimal γ[∗]. Note that L[γ]ρ[∗] [(][P][λ][, f] [)][ is the same as][ B][(][P][λ][, ρ][)][-worst-]
case risk thanks to the strong duality (5), which is obtained with ρ > 0.

Denote by _θ[ϵ]_ Θ an ε-minimizer to the surrogate ERM, i.e., EZ _Pλ_ _φγ(Z, fθ[ε]_ [)]
_∈_ _∼_ _≤_
inf _θ∈Θ EZ∼Pλ_ _φ(Z, fθ)_ + ε, where Θ ⊂ R[d] is a parameter class, we obtain the following result.b  b 

[b]

**Theorem 2 (Robust Generalization Bounds)b**   **. Let Assumptions 2 and 3 hold, γ** max _Lzz, Lz/ρ_ _,_
_≥_
_and_ _ℓ(z, h)_ _Mℓ. We have the following result for all Q_ (Pλ, ρ)
_|_ _| ≤_ _∈B_ 


48C(Θ)
+ 2Mℓ
_√ni_


2 log(2m/δ)

_ni_


E(Q, fθ[ε] [)][ ≤] _λi_ + 2Mℓ + ε + g(ρ, γ)

_i=1_ " _√ni_ s _ni_ #

b X

_with probability at least 1_ _δ, where C(Θ) := Lθ_ _∞0_ log (Θ, Θ, ϵ)dϵ and (Θ, Θ, ϵ)
_−_ _N_ _∥· ∥_ _N_ _∥· ∥_

_denotes the ϵ-covering number of Θ w.r.t a metric_ Θ as the norm on Θ.

R ∥· ∥p

We provide a proof of Theorem 2 in Appendix E. We sketch the proof as follows: first bound
E[γ]ρ[(][P][λ][, f]θ[b][ε] [)][ using standard excess risk decomposition and uniform convergence with Rademacher]
complexity. Then leverage the upper-bound of Lemma 1 to bound E(Q, f ), _Q_ (Pλ, ρ), based
_∀_ _∈B_
on the bound of E[γ]ρ[(][P][λ][, f]θ[b][ε] [)][. The result shows that using][ WAFL][ to minimize the surrogate of]
Wasserstein robust empirical risk also controls the robustness and generalization. As an example


-----

_H =_ _⟨θ, ·⟩_ _, θ ∈_ Θ with Θ = _θ ∈_ R[d] : ∥θ∥2 ≤ _C_ . The diameter of Θ is supθ,θ′∈Θ∥θ − _θ[′]∥_ =
2C, thus (Θ, 2, ϵ) = (1 + 2C/ϵ)[d], and C(Θ) 3CLθ√d/2 (Lee & Raginsky, 2018).
 _N_ _∥· ∥_  _≤_

Generally, the radius of Wasserstein ball ρ can be considered hyperparameter that needs fine-tuning
(e.g., through cross-validation). In principle, ρ should not be too large to become over-conservative,
which can hurt the empirical average performance, but also not too small to become similar to the
ERM, and thus can lack robustness. From a statistical standpoint, we are interested in learning how
to scale ρ w.r.t. the sample size ni, i [m], such that the generalization of the WAFL solution
_∈_
_θ[ε]_ w.r.t the true distribution Pλ is guaranteed, while still ensuring robustness w.r.t all distributions
inside the Wasserstein ball. Using the result from Fournier & Guillin (2015), which shows that _Pni_
converges in Wasserstein distance to the trueb _Pi at a specific rate, we obtain the following_

**Corollary 1. With all assumptions as in Theorem 2, defining ρn :=** _mi=1_ _[λ][i]ρ[b][δ/m]ni_ _[, we have]_ [b]

_m_

48C(Θ) 2 log(4m/δ) qP

E(Pλ, fθ[ε] [)][ ≤] _λi_ + 2Mℓ + g(ρn, γ) + ε

_i=1_ " _√ni_ s _ni_ #

b X min 2/d,1/2

log(c1/δ) _{_ _}_

_c2n_ _if n_ _c2_ _,_

_with probability at least 1 −_ _δ, where_ _ρ[δ]n_ [:=]   log(c1/δ) 1/α _≥_ [log(][c][1][/δ][)]

 _c2n_ _if n <_ [log(]c[c]2[1][/δ][)] _._

b  

We provide a proof of Corollary 1 in Appendix F.

5 CHOOSING λ: APPLICATIONS

We focus on two applications: multi-source domain adaptation and generalization to all client distributions. We provide insights about choosing the client weights λ for these applications.

**Multi-source domain adaptation: Consider the multi-source domain distribution Pλ (Mansour**
et al., 2021). Lee & Raginsky (2018) show that solving the minimax risk with the Wasserstein
ambiguity set can help transfer data/knowledge from the source domain Pλ to a different, but related,
target domain Q. They bound the distance Wp(Pλ, Q) using the triangle inequality

_Wp(Pλ, Q)_ _Wp(Pλ,_ _Pλ) + Wp(Pλ,_ _Q) + Wp(Q, Q),_ (8)
_≤_

where _Pλ and_ _Q are the empirical versions of Pλ and Q, respectively. While Wp(Pλ,_ _Pλ) and_

[b] [b] [b] [b]

_Wp(Q, Q) can be probabilistically bounded with a confidence parameter δ_ (0, 1) according to
_∈_
Fournier & Guillin (2015),[b] [b] _Wp(Pλ,_ _Q) can be deterministically computed using linear or convex[b]_
programming (Peyr´[b] e & Cuturi, 2019).
In FL context, in order to have a better bound for W2(Pλ, Q) similar to (8), it is straightforward to

[b] [b]
choose λ = arg minλ′∈∆ _W2(Pλ′_ _,_ _Q). To relax this problem into a form solvable using existing_
approaches, observe that W2(Pλ, Q) ≤ [P]i[m]=1 _[λ][i][W][2][(][ b]Pni_ _, Q) due to the convexity of Wasserstein_
distance. We then consider the following upper-bound to[b] [b] _m_ minλ∈∆ _W2(Pλ,_ _Q):_

[b]

_λmin∆_ _i=1_ _[λ][i][W][2][(][ b]Pni_ _,_ _Q) =: ρ[⋆],_ (9)
_∈_ [b] [b]

X

which is a linear program, considering each W2(Pni _,_ _Q) can be found by efficiently solving convex_

[b]

programs especially with entropic regularization and the Sinkhorn algorithm (Cuturi, 2013).
**Corollary 2. Denote the solution to (9) by λ[⋆], and assume that domain[b]** [b] _Q generates nQ i.i.d. data_
_points. With probability at least 1 −_ _δ, we have_

_m_

_W2(Pλ⋆_ _, Q) ≤_ _W2(Pλ⋆_ _,_ _Pλ⋆_ ) + W2(Pλ⋆ _,_ _Q) + W2(Q,_ _Q) ≤_ _i=1_ _[λ]i[⋆]ρ[δ/m]ni_ + ρ[⋆] + _ρ[δ/]nQ[2][.]_

rX

The proof of this corollary is similar to that of Corollary 3 in Appendix B.[b] [b] [b] [b] [b] b

**Covering all client distributions in the Wasserstein ball: Suppose we want to cover all client**
distributions inside a Wassertein ball so that the generalization and robustness result by WAFL in
Theorem 2 is applicable to all clients’ distributions. We show in Appendix B that this is a problem
of finding λ such that the Wasserstein distance between Pλ and Pj, ∀j, is as small as possible.


-----

6 EXPERIMENTS

We first show how to change the level of worst-case perturbations by varying the robust parameter
_γ. To show the generalizability and robustness of WAFL, we evaluate WAFL under non-i.i.d. and_
distribution shift settings. We compare WAFL with baseline robust methods and non-robust FedAvg.
Finally, in Appendix G.4, we show WAFL’s capability in domain adaptation.

**Experimental settings. We use two datasets in two non-i.i.d. settings. We distribute the first dataset**
– MNIST (Lecun et al., 1998) – to 100 clients and use a multinomial logistic regression model to
model a convex setting. For the second dataset – CIFAR-10 (Krizhevsky, 2009) – we use 20 clients
and a CNN model employed in McMahan et al. (2017) to model a non-convex setting. We set
_λi = ni/n as the client weights. In optimization, we randomly sample St = 10 clients to participate_
in training at each communication round. More detail can be found in Appendix G.1.


**Effect of γ on the worst-case risk perturbations.** We
first examine the relationship between the robust parameter γ
and the average worst-case perturbations ˆρ, defined as ˆρ[2] =
**EZ∼Pλ** _d[2](Z, Z)_, where _Z is the adversarial perturbation of_
_Z. As shown in Fig. 2, smaller values of γ correspond to larger_
b  
worst-case perturbations ˆρ on both the MNIST and CIFAR-10

[b] [b]
datasets. For the rest of the experiment, rather than control ˆρ directly, we set γ on the opposite direction to control the level of
robustness.


Average worst-case perturbation


1.50

1.25

1.00

0.75

0.50

0.00

10 1 10[0] 10[1] 10[2] 10[3] 10[4]

|Col1|Col2|Col3|Col4|Col5|Col6|Col7|
|---|---|---|---|---|---|---|
||||||||
||||||||
||||||||
||||||||
||||||||
||||||||
||||||WAFL: WAFL:|MNIST CIFAR-10|


1/

Figure 2: Varying ˆρ by γ.


**Generalization and robustness of WAFL. We consider** _Pλ and_ _Q as the empirical distribution of_
the training samples and test samples of all clients, respectively. By varying γ, we aim to train a
global model robust to any empirical test distribution _Q. To show the generalization and robustness[b]_ [b]
of WAFL, we train and evaluate it in two different scenarios. First, in the clean data scenario, the
global robust model is trained with different values of γ and then evaluated on given clients’ test data

[b]
(similar to traditional FL). Second, in the distribution shift setting, the training process is similar;
however, the global robust model is evaluated when there are distribution shifts at the clients’ test
data. To obtain these shifts, we use the common PGD attack method in Madry et al. (2019) under
_l_ -norm to generate an ϵ-level perturbation on clients’ test data. We choose the l -norm as it
_∞_ _∞_
shows benefits in adversaries and gives large perturbations. Following Madry et al. (2019), we fix
the number of gradient steps to generate adversarial examples with tavd = 40, ϵ = 0.3, α = 0.01
for MNIST and tavd = 10, ϵ = 8/255, α = 2/255 for CIFAR-10 with a batch size of 64. We note
that this setting is similar to the adversarial poisoning attacks and the main purpose of this setting is
to increase the Wasserstein distance between _Pλ and_ _Q, thereby verifying the robustness of WAFL._

The performance of WAFL in both scenarios on MNIST and CIFAR-10 is shown in Fig. 3. When
the clients’ data is clean, the Wasserstein distance between[b] [b] _Pλ and_ _Q is relatively small, and training_
WAFL with small γ (large ˆρ) gives the worse performance on the test set. With a sufficiently large γ,
WAFL is less robust and has the same generalization with FedAvg. By carefully fine-turning γ in the

[b] [b]
range [0.5, 1] for MNIST and [10, 20] for CIFAR-10, WAFL shows an improvement over FedAvg.
_γ in this scenario plays the same role as a regularization parameter to handle non-i.i.d. data._

By adding distribution shifts, we increase the Wasserstein distance between _Pλ and_ _Q. By vary-_
ing γ, we train a global robust model with different levels of worst-case perturbation to handle the
distribution shifts. Small values of γ generate larger ambiguity sets (Pλ, ˆρ) and increase the ro-[b] [b]
_B_
bustness of WAFL, thus increase the chance _Q lies inside_ (Pλ, ˆρ). In Fig. 3, WAFL shows better
_B_
performance with smaller γ values. However, as in mentioned in Sec. 4, when[b] ˆρ is much larger or
smaller than the level of distribution shifts (γ 0.01 or γ 1 for MNIST and γ 0.1 or γ > 10
_≤[b]_ _≥_ [b] _≤_
for CIFAR-10), WAFL performs inefficiently: too small γ hurts the empirical performance, while
too large γ makes WAFL lack robustness. For every scenario, γ needs to be tuned correspondingly.
In our experiments, by carefully choosing γ, WAFL not only handles distribution shifts or common data poisoning attacks but also provides better performance than FedAvg in non-i.i.d. data and
heterogeneous settings. Specifically, we set γ = 0.5 for MNIST and γ = 10 for CIFAR-10.

**Comparison with other robust methods.** We compare WAFL with three baselines: two
common robust methods in FL called FedPGM and FedFGSM, and one non-robust method Fe

-----

MNIST

0.01 0.05 0.1 0.5 1 5 10 50


MNIST

0.01 0.05 0.1 0.5 1 5 10 50


CIFAR

0.01 0.05 0.1 0.5 1 5 10 50


CIFAR

0.01 0.05 0.1 0.5 1 5 10 50


0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50


0.70

0.65

0.60

0.55

0.50

0.45

0.40


2.00

1.75

1.50

1.25

1.00

0.75

0.50

0.25


2.75

2.50

2.25

2.00

1.75

1.50

1.25

1.00


WAFL: Clean data FedAvg: Clean data WAFL: Distribution shifts FedAvg: Distribution shifts


Figure 3: Global accuracy and loss of with different values of γ on MNIST and CIFAR-10 under clean data
and distribution shifts (40% of clients are affected by PGD attack). The blue vertical line indicates the value of


MNIST


CIFAR


0.9

0.8

0.7

0.6

0.5

0.4


2.50

2.25

2.00

1.75

1.50

1.25

1.00

0.75

0.50


0.70

0.65

0.60

0.55

0.50

0.45

0.40

0.35

0.30


2.8

2.6

2.4

2.2

2.0

1.8

1.6

1.4

1.2

1.0

|D attack(γ = 0.05 for|Col2|Col3|Col4|
|---|---|---|---|
|MNIST||||
|||||
|||||
|||||

|0).|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
|CIF||AR|||
||||||
||||||
||||||


0.2 0.4 0.6 0.8 0 0.2 0.4 0.6 0.8

Proportion of attacked clients Proportion of attacked clients


0.2 0.4 0.6 0.8

Proportion of attacked clients

|Col1|Col2|Col3|Col4|
|---|---|---|---|
|||||
|0 0.2 0.4 0.6 0.8 Proportion of attacked clients||||


WAFL FedPGM FedFGSM FedAvg


Figure 4: Comparison with other robust methods on MNIST and CIFAR-10 at different proportion of attacked
clients (clients are affected by distribution shifts).

dAvg. FedPGM and FedFGSM are FedAvg with adversarial training using the projected gradient method PGD (Madry et al., 2019) and the fast-gradient method FGSM (Goodfellow et al.,
2015), respectively. In FedPGM and FedFGSM, in each local update, all clients solve δ[∗] =
arg max∥δ∥∞≤ϵ _ℓ(hθ(z + δ), y)_ using projection onto an l∞-norm to find the worst-case perturbation δ. While FedPGD uses tavd gradient steps to find δ[∗], FedFGSM uses only one gradient

step. We use the same values of ϵ and α from the distribution shifts setting for projection. For a
fair comparison, both WAFL and FedPGM have the same value tavd and all algorithms have the
same number of local updates K. We also train WAFL with the value of γ generating the same
level perturbation of ϵ in FedPGM and FedFGSM. We study different proportions of clients having
distribution shifts in Fig. 4. The robust accuracy of all methods decreases when the percentage of
clients having distribution shifts increases. Especially, the FedAvg’s performance drops dramatically when the percentage of attacked clients reaches 80%. For all scenarios, WAFL outperforms
all the baselines. Specifically, in the case of 80% attacked clients, the improvements in accuracy of
WAFL over FedPGM, FedFGSM, and FedAvg are 7%, 8%, and 33% for MNIST and 2.5%, 4.5%,
and 18% for CIFAR-10, respectively.


7 CONCLUSION

In this paper, we present WAFL, a Wasserstein distributionally robust optimization framework, to
tackle the issue of statistical heterogeneity in federated learning. We first remodel the duality of
the worst-case risk to an empirical surrogate risk minimization problem, then solve it using a local
SGD-based algorithm with convergence analysis. We show that WAFL is more general in terms
of robustness compared to related approaches, and obtains an explicit robust generalization bound
with respect to all unknown distributions in the Wasserstein ambiguity set. Through numerical
experiments, we demonstrate that WAFL generalizes better than the standard FedAvg baseline in
non-i.i.d. settings, and outperforms related methods with respect to robustness to distribution shifts.
Moreover, WAFL reveals its capability in generalizing to unseen data distributions.


-----

REFERENCES

Peter Bartlett, Dylan J. Foster, and Matus Telgarsky. Spectrally-normalized margin bounds for neural
[networks. arXiv:1706.08498 [cs, stat], December 2017. URL http://arxiv.org/abs/1706.08498.](http://arxiv.org/abs/1706.08498)
arXiv: 1706.08498.

Jose Blanchet, Yang Kang, and Karthyek Murthy. Robust Wasserstein Profile Inference and Applications to Machine Learning. Journal of Applied Probability, 56(3):830–857, September 2019.
[ISSN 0021-9002, 1475-6072. doi: 10.1017/jpr.2019.49. URL http://arxiv.org/abs/1610.05627.](http://arxiv.org/abs/1610.05627)
arXiv: 1610.05627.

Nicholas Carlini and David Wagner. Towards Evaluating the Robustness of Neural Networks.
_[arXiv:1608.04644 [cs], March 2017. URL http://arxiv.org/abs/1608.04644. arXiv: 1608.04644.](http://arxiv.org/abs/1608.04644)_

Ruidi Chen and Ioannis Ch Paschalidis. A Robust Learning Approach for Regression Models Based
on Distributionally Robust Optimization. Journal of Machine Learning Research, 19(13):1–48,
[2018. ISSN 1533-7928. URL http://jmlr.org/papers/v19/17-295.html.](http://jmlr.org/papers/v19/17-295.html)

Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Proceed_ings of the 26th International Conference on Neural Information Processing Systems - Volume_
_2, NIPS’13, pp. 2292–2300, Red Hook, NY, USA, 2013. Curran Associates Inc._

Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive Personalized Feder[ated Learning. arXiv:2003.13461 [cs, stat], November 2020a. URL http://arxiv.org/abs/2003.](http://arxiv.org/abs/2003.13461)
[13461. arXiv: 2003.13461.](http://arxiv.org/abs/2003.13461)

Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Distributionally Robust Federated Averaging. In Advances in Neural Information Processing Systems, volume 33, pp. 15111–
15122. Curran Associates, Inc., 2020b. [URL https://proceedings.neurips.cc/paper/2020/hash/](https://proceedings.neurips.cc/paper/2020/hash/ac450d10e166657ec8f93a1b65ca1b14-Abstract.html)
[ac450d10e166657ec8f93a1b65ca1b14-Abstract.html.](https://proceedings.neurips.cc/paper/2020/hash/ac450d10e166657ec8f93a1b65ca1b14-Abstract.html)

Theo Diamandis, Yonina C. Eldar, Alireza Fallah, Farzan Farnia, and Asuman Ozdaglar. A Wasserstein Minimax Framework for Mixed Linear Regression. arXiv:2106.07537 [cs, math, stat], June
[2021. URL http://arxiv.org/abs/2106.07537. arXiv: 2106.07537.](http://arxiv.org/abs/2106.07537)

Canh T. Dinh, Nguyen H. Tran, and Tuan Dung Nguyen. Personalized Federated Learning with
[Moreau Envelopes. arXiv:2006.08848 [cs, stat], March 2021. URL http://arxiv.org/abs/2006.](http://arxiv.org/abs/2006.08848)
[08848. arXiv: 2006.08848.](http://arxiv.org/abs/2006.08848)

Wei Du, Depeng Xu, Xintao Wu, and Hanghang Tong. Fairness-aware Agnostic Federated Learning.
_[arXiv:2010.05057 [cs], October 2020. URL http://arxiv.org/abs/2010.05057. arXiv: 2010.05057.](http://arxiv.org/abs/2010.05057)_

Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven Distributionally Robust Optimization Using the Wasserstein Metric: Performance Guarantees and Tractable Reformulations.
_arXiv:1505.05116 [math, stat], June 2017._ [URL http://arxiv.org/abs/1505.05116.](http://arxiv.org/abs/1505.05116) arXiv:
1505.05116.

Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach. In Advances in Neural Infor_[mation Processing Systems, volume 33, pp. 3557–3568. Curran Associates, Inc., 2020. URL https:](https://proceedings.neurips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html)_
[//proceedings.neurips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html.](https://proceedings.neurips.cc/paper/2020/hash/24389bfe4fe2eba8bf9aa9203a44cdad-Abstract.html)

Nicolas Fournier and Arnaud Guillin. On the rate of convergence in wasserstein distance of the
empirical measure. _Probability Theory and Related Fields, 162:707, 2015._ doi: 10.1007/
s00440-014-0583-7.

Yaroslav Ganin and Victor Lempitsky. Unsupervised Domain Adaptation by Backpropagation. In
_[International Conference on Machine Learning, pp. 1180–1189. PMLR, June 2015. URL https:](https://proceedings.mlr.press/v37/ganin15.html)_
[//proceedings.mlr.press/v37/ganin15.html. ISSN: 1938-7228.](https://proceedings.mlr.press/v37/ganin15.html)

Rui Gao and Anton J. Kleywegt. Distributionally Robust Stochastic Optimization with Wasserstein
[Distance. arXiv:1604.02199 [math], July 2016. URL http://arxiv.org/abs/1604.02199. arXiv:](http://arxiv.org/abs/1604.02199)
1604.02199.


-----

Rui Gao, Xi Chen, and Anton J. Kleywegt. Wasserstein Distributionally Robust Optimization and
[Variation Regularization. arXiv:1712.06050 [cs, math, stat], October 2020. URL http://arxiv.org/](http://arxiv.org/abs/1712.06050)
[abs/1712.06050. arXiv: 1712.06050.](http://arxiv.org/abs/1712.06050)

Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harnessing Adversarial
[Examples. arXiv:1412.6572 [cs, stat], March 2015. URL http://arxiv.org/abs/1412.6572. arXiv:](http://arxiv.org/abs/1412.6572)
1412.6572.

Jochen Gorski, Frank Pfeuffer, and Kathrin Klamroth. Biconvex sets and optimization with biconvex
functions: a survey and extensions. Mathematical Methods of Operations Research, 66(3):373–
[407, December 2007. ISSN 1432-5217. doi: 10.1007/s00186-007-0161-1. URL https://doi.org/](https://doi.org/10.1007/s00186-007-0161-1)
[10.1007/s00186-007-0161-1.](https://doi.org/10.1007/s00186-007-0161-1)

J.J. Hull. A database for handwritten text recognition research. _IEEE Transactions on Pattern_
_Analysis and Machine Intelligence, 16(5):550–554, May 1994. ISSN 1939-3539. doi: 10.1109/_
34.291440.

Jakub Koneˇcn´y, H. Brendan McMahan, Daniel Ramage, and Peter Richt´arik. Federated Optimization: Distributed Machine Learning for On-Device Intelligence. arXiv:1610.02527 [cs], October
[2016. URL http://arxiv.org/abs/1610.02527. arXiv: 1610.02527.](http://arxiv.org/abs/1610.02527)

Jakub Koneˇcn´y, H. Brendan McMahan, Felix X. Yu, Peter Richt´arik, Ananda Theertha Suresh,
and Dave Bacon. Federated Learning: Strategies for Improving Communication Efficiency.
_[arXiv:1610.05492 [cs], October 2017. URL http://arxiv.org/abs/1610.05492. arXiv: 1610.05492.](http://arxiv.org/abs/1610.05492)_

Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images. pp. 60, 2009.

Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh Shafieezadeh-Abadeh.
Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning. _arXiv:1908.08729 [cs, math, stat], August 2019._ [URL http://arxiv.org/abs/1908.08729.](http://arxiv.org/abs/1908.08729)
arXiv: 1908.08729.

Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial Machine Learning at Scale.
_arXiv:1611.01236 [cs, stat], February 2017._ [URL http://arxiv.org/abs/1611.01236.](http://arxiv.org/abs/1611.01236) arXiv:
1611.01236.

Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, November 1998. ISSN 1558-2256. doi:
10.1109/5.726791. Conference Name: Proceedings of the IEEE.

Jaeho Lee and Maxim Raginsky. Minimax Statistical Learning with Wasserstein distances. In
_Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018._
URL [https://papers.nips.cc/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.](https://papers.nips.cc/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html)
[html.](https://papers.nips.cc/paper/2018/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html)

Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and Robust Federated
[Learning Through Personalization. arXiv:2012.04221 [cs, stat], June 2021. URL http://arxiv.](http://arxiv.org/abs/2012.04221)
[org/abs/2012.04221. arXiv: 2012.04221.](http://arxiv.org/abs/2012.04221)

Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the Convergence of
[FedAvg on Non-IID Data. arXiv:1907.02189 [cs, math, stat], June 2020. URL http://arxiv.org/](http://arxiv.org/abs/1907.02189)
[abs/1907.02189. arXiv: 1907.02189.](http://arxiv.org/abs/1907.02189)

Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng. FedDG: Federated Domain
Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency
Space. arXiv:2103.06030 [cs], March 2021.

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards Deep Learning Models Resistant to Adversarial Attacks. arXiv:1706.06083 [cs, stat],
[September 2019. URL http://arxiv.org/abs/1706.06083. arXiv: 1706.06083.](http://arxiv.org/abs/1706.06083)

Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three Approaches for
Personalization with Applications to Federated Learning. arXiv:2002.10619 [cs, stat], July 2020.
[URL http://arxiv.org/abs/2002.10619. arXiv: 2002.10619.](http://arxiv.org/abs/2002.10619)


-----

Yishay Mansour, Mehryar Mohri, Jae Ro, Ananda Theertha Suresh, and Ke Wu. A Theory of
Multiple-Source Adaptation with Limited Target Labeled Data. In Proceedings of The 24th Inter_national Conference on Artificial Intelligence and Statistics, pp. 2332–2340. PMLR, March 2021._
[URL https://proceedings.mlr.press/v130/mansour21a.html. ISSN: 2640-3498.](https://proceedings.mlr.press/v130/mansour21a.html)

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag¨uera y
Arcas. Communication-Efficient Learning of Deep Networks from Decentralized Data.
_arXiv:1602.05629 [cs], February 2017._ [URL http://arxiv.org/abs/1602.05629.](http://arxiv.org/abs/1602.05629) arXiv:
1602.05629.

Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic Federated Learning.
_arXiv:1902.00146 [cs, stat], January 2019._ [URL http://arxiv.org/abs/1902.00146.](http://arxiv.org/abs/1902.00146) arXiv:
1902.00146.

Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram
Swami. The Limitations of Deep Learning in Adversarial Settings. arXiv:1511.07528 [cs, stat],
[November 2015. URL http://arxiv.org/abs/1511.07528. arXiv: 1511.07528.](http://arxiv.org/abs/1511.07528)

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance
Deep Learning Library. In Advances in Neural Information Processing Systems 32, Vancouver,
BC, Canada, 2019.

Xingchao Peng, Zijun Huang, Yizhe Zhu, and Kate Saenko. Federated Adversarial Domain Adaptation. arXiv:1911.02054 [cs], December 2019.

Gabriel Peyr´e and Marco Cuturi. Computational optimal transport: With applications to data science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019. ISSN 1935-8237.
[doi: 10.1561/2200000073. URL http://dx.doi.org/10.1561/2200000073.](http://dx.doi.org/10.1561/2200000073)

Amirhossein Reisizadeh, Farzan Farnia, Ramtin Pedarsani, and Ali Jadbabaie. Robust Federated
Learning: The Case of Affine Distribution Shifts. arXiv:2006.08907 [cs, math, stat], June 2020.
[URL http://arxiv.org/abs/2006.08907. arXiv: 2006.08907.](http://arxiv.org/abs/2006.08907)

Filippo Santambrogio. Optimal Transport for Applied Mathematicians: Calculus of Variations,
_PDEs, and Modeling._ Progress in Nonlinear Differential Equations and Their Applications.
Birkh¨auser Basel, 2015. ISBN 978-3-319-20827-5. doi: 10.1007/978-3-319-20828-2. URL
[https://www.springer.com/gp/book/9783319208275.](https://www.springer.com/gp/book/9783319208275)

Soroosh Shafieezadeh Abadeh, Peyman Mohajerin Mohajerin Esfahani, and Daniel Kuhn. Distributionally Robust Logistic Regression. In Advances in Neural Information Processing Sys_[tems, volume 28. Curran Associates, Inc., 2015. URL https://papers.nips.cc/paper/2015/hash/](https://papers.nips.cc/paper/2015/hash/cc1aa436277138f61cda703991069eaf-Abstract.html)_
[cc1aa436277138f61cda703991069eaf-Abstract.html.](https://papers.nips.cc/paper/2015/hash/cc1aa436277138f61cda703991069eaf-Abstract.html)

Soroosh Shafieezadeh-Abadeh, Daniel Kuhn, and Peyman Mohajerin Esfahani. Regularization via
[Mass Transportation. arXiv:1710.10016 [cs, math, stat], July 2019. URL http://arxiv.org/abs/](http://arxiv.org/abs/1710.10016)
[1710.10016. arXiv: 1710.10016.](http://arxiv.org/abs/1710.10016)

Shai Shalev-Shwartz and Shai Ben-David. _Understanding Machine Learning: From Theory to_
_Algorithms. Cambridge University Press, USA, 2014. ISBN 978-1-107-05713-5._

Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi. Certifying Some Distributional Robustness with Principled Adversarial Training. arXiv:1710.10571 [cs, stat], May 2020.
[URL http://arxiv.org/abs/1710.10571. arXiv: 1710.10571.](http://arxiv.org/abs/1710.10571)

Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated Multi-Task
[Learning. arXiv:1705.10467 [cs, stat], February 2018. URL http://arxiv.org/abs/1705.10467.](http://arxiv.org/abs/1705.10467)
arXiv: 1705.10467.

Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, and H. Brendan McMahan. Distributed Mean
[Estimation with Limited Communication. arXiv:1611.00429 [cs], September 2017. URL http:](http://arxiv.org/abs/1611.00429)
[//arxiv.org/abs/1611.00429. arXiv: 1611.00429.](http://arxiv.org/abs/1611.00429)


-----

Florian Tram`er, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. Ensemble Adversarial Training: Attacks and Defenses. arXiv:1705.07204 [cs, stat],
[April 2020. URL http://arxiv.org/abs/1705.07204. arXiv: 1705.07204.](http://arxiv.org/abs/1705.07204)

Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H. Brendan McMahan, Blaise Aguera y
Arcas, Maruan Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data,
[et al. A Field Guide to Federated Optimization. arXiv:2107.06917 [cs], July 2021. URL http:](http://arxiv.org/abs/2107.06917)
[//arxiv.org/abs/2107.06917. arXiv: 2107.06917.](http://arxiv.org/abs/2107.06917)

Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated
[Learning with Non-IID Data. arXiv:1806.00582 [cs, stat], June 2018. URL http://arxiv.org/abs/](http://arxiv.org/abs/1806.00582)
[1806.00582. arXiv: 1806.00582.](http://arxiv.org/abs/1806.00582)


-----

A ADVERSARIAL ROBUST FL’S AMBIGUITY SET V.S. WASSERTEIN BALL

We show that using the Wasserstein ambiguity set contains the perturbation points induced by the
solution to the Adversarial Robust FL approach. As we present in Sec. 3.2, existing techniques for
adversarial training robust models (Goodfellow et al., 2015; Papernot et al., 2015; Kurakin et al.,
2017; Carlini & Wagner, 2017; Madry et al., 2019; Tram`er et al., 2020) define an adversarial perturbation u at a data point Z, and minimize the following worst-case loss over all possible perturbations

maxu **[E][Z][∼]P[b]λ** _ℓ(Z + u, hθ)_ _,_ (10)
_∈U_

h i

where the ambiguity set U := _u ∈_ R[d][+1] : ∥u∥≤ _ϵ_ . To compare this approach with Wassersteinrobust FL, we relate the above problem to its counterpart defined in the probability space of input as

follows
max **E ˜Z** _Q_ _ℓ( Z, h[˜]_ _θ)_ _,_ (11)
_Q˜∈Q(ϵ)_ _∼_ [˜]
h i

where Q(ϵ) := _Q˜ : P_ _∥Z[˜] −_ _Z∥≤_ _ϵ_ = 1, Z ∼ _P[b]λ,_ _Z[˜] ∼_ _Q[˜]_ _. Considering u[∗]_ as a solution to

problem (10), we see that the distributionn   _Q[′]_ of perturbation points (i.e.,o _Z[˜] := (Z + u[∗])_ _Q[′])_
_∼_
in problem (10) belongs to the feasible set Q(ϵ) in problem (11) (If not, then P _∥u[∗]∥≤_ _ϵ_ _< 1, a_
contradiction). Next, consider an arbitrary distribution _Q[˜]_ (ϵ) in problem (11), with any _Z[˜]_ _Q_
_∈Q_   _∼_ [˜]
and Z _Pλ, we have_
_∼_ [b]

w.p.1
_∥Z[˜] −_ _Z∥_ _≤_ _ϵ =⇒_ **EZ∼Pλ,Z[˜]∼Q[˜]** _∥Z[˜] −_ _Z∥_ _≤_ _ϵ =⇒_ _π∈Π(infPλ,Q[˜])_ **E(Z,Z** _′)∼π_ _∥Z[˜] −_ _Z∥_ _≤_ _ϵ,_
b    

which implies that W1(Pλ, _Q[˜])_ _ϵ,_ _Q_ (ϵ), and thus (ϵ[b]) 1(Pλ, ϵ). We have shown
_≤_ _∀_ [˜] ∈Q _Q_ _⊂B_
that the Wasserstein ambiguity set contains the perturbation points induced by the solution to the
adversarial robust training problem (10).

[b] [b]

B CHOOSING λ: GENERALIZING TO ALL CLIENT DISTRIBUTIONS

We show that by calibrating appropriate λ value, our proposed algorithm will be capable of generalizing to all client distributions. Suppose we want to cover all client distributions inside a Wassertein
ball so that the generalization and robustness result by WAFL in Theorem 2 is applicable to all
clients’ distributions. This is the problem of finding λ such that the Wasserstein distance between
_Pλ and Pj, ∀j, is as small as possible. Instead of directly finding the minimum Wasserstein ra-_
dius that cover all client distributions, we will leverage the popular Wasserstein barycenter problem
(Peyr´e & Cuturi, 2019). Specifically, consider the problem

_λmin∈∆_ _[W][2][(][ b]Pλ, P_ [♥]) s.t. _P_ [♥] = arg minQ∈P _mi=1_ _[λ][i][W][2][(][ b]Pni_ _, Q),_ (12)

X

where P [♥] is the Wasserstein bary center w.r.t the solution λ[∗] to this problem. Even though the
solution is not straightforward, we propose to solve its tractable upper-bound:

_m_

_λ_ ∆min,Q _i=1_ _[λ][i][W][2][(][ b]Pni_ _, Q)._ (13)
_∈_ _∈P_

X

This is a bi-convex problem, which is convex w.r.t to λ (resp. Q) when fixing Q (resp. λ). Thus,
we can use alternative minimization (Gorski et al., 2007) to find a local solution to this problem.
Denoting _λ[˜] as the solution to (12) and (λ[∗], P_ _[∗]) as a local solution to (13), we obtain_

_m_
_W2(Pλ˜[, P][ ♥][)][ ≤]_ _[W][2][(][ b]Pλ∗_ _, P_ _[∗]) ≤_ _i=1_ _[λ]i[∗][W][2][(][ b]Pni_ _, P_ _[∗]) =: ρ[∗]._ (14)
X

**Corollary 3. For all client j** [m], with probability at least 1 _δ, we have_

[b] _∈_ _−_

_W2(Pλ∗_ _, Pj) ≤_ _W2(Pλ∗_ _,_ _Pλ∗_ ) + W2(Pλ∗ _, P_ _[∗]) + W2(P_ _[∗],_ _Pnj_ ) + W2(Pnj _, Pj)_

_m_

_≤_ _i=1_ _[λ][b]i[∗]ρ[δ/m]ni_ + ρ[∗][b]+ _λ[ρ][∗]j_ + _ρ[δ/]nj[2]_ [b] [b]

rX

[b] b


-----

_Proof. The first line is by triangle inequality._ The second line is by following facts: (i)

**P** _W2(Pλ∗_ _,_ _Pλ∗_ ) _≥_ _mi=1_ _[λ]i[∗]ρ[δ/m]ni_ _≤_ _δ/2 according to (37), (ii) W2(P_ _[∗],_ _Pnj_ ) =

_λjhW2(P_ _[∗],Pnj )_ _ρ[∗]_ i

union bound.λj [b] [b] _≤_ _λj_ [, and (iii)]qP **[ P]** _W[b]2(Pnj_ _, Pj) ≥_ _ρ[δ/]nj[2]_ _≤_ _δ/2 according to (35), and (iv) using[b]_
 

[b] b

C PROOF OF THEOREM 1

Our proof is based on the analysis of local SGD for FL presented in Wang et al. (2021).

Fix some zi. Define ϕ(ζ, θ; zi) := ℓ(ζ, hθ) _γd(ζ, zi). Since ℓ_ is Lzz-smooth and d is 1-strongly
_−_
convex, ϕ(ζ, θ; zi) is (γ _Lzz)-strongly concave with respect to ζ, given that γ > Lzz._
_−_
**Lemma 2. Let zi[∗]** [= arg max]ζ _[ϕ][(][ζ, θ][;][ z][i][)][. Therefore,][ φ][γ][(][θ][;][ z][i][) =][ ϕ][(][z]i[∗][, θ][;][ z][i][)][.][ Let][ ℓ]_ _[satisfy]_
_∈Z_
_Assumption 3. Then φγ is differentiable, and_

_φγ(zi, θ)_ _φγ(zi, θ[′])_ _L_ _θ_ _θ[′]_ _,_
_∥∇_ _−∇_ _∥≤_ _∥_ _−_ _∥_

_with L = Lθθ +_ _[L]γ[θz]−L[L]zz[zθ]_ _[when][ γ > L][zz][.]_


The proof can be found in (Sinha et al., 2020, Lemma 1). Lemma 2 implies that φγ is L-smooth.


Define gi(θ) := 1i _zi_ _i_

_|D_ _|_ _∈D_

_[∇][θ][ φ][γ][(][z][i][, θ][)][, then we have]_

2[i]

P

**E** _∥gi(θ) −∇Fi(θ)∥[2][i]_ = E [1]i _∇θ φγ(zi, θ) −∇Fi(θ)_
h h _|D_ _|_ _zXi∈Di_

1

_gφi_ (θ) _Fi(θ)_ _σ[2]_ (by Assumption 4.) (15)

_≤_ _i_ _−∇_ _≤_ _[σ][2]i_ [:=][ b]

_|D_ _|_ **[E]** _|D_ _|_
h

[2][i]

With the shadow sequence _θ[¯][(][t,k][)]_ = _i=1_ _[λ][i][θ]i[(][t,k][)], we have_

_m_ _m_ _m_

_θ¯[(][t,k][+1)]_ = _λiθi[(][t,k][+1)]_ = [P][m]λi _θi[(][t,k][)]_ _ηgi(θi[(][t,k][)])_ = θ[¯][(][t,k][)] _η_ _λigi(θi[(][t,k][)])._

_−_ _−_

_i=1_ _i=1_ _i=1_

X X    X


**Lemma 3. If the client learning rate satisfies η ≤** 31L _[, then]_

1 _K−1_ _m_ _m_ _K−1_ 1

_K_ _kX=0_ **EF** (θ[¯][(][t,k][)]) − _F_ (θ[∗]) _≤2ησˆ[2]_ Xi=1 _λ[2]i_ ! + L Xi=1 _λi_ _kX=0_ _K_ **[E]h∥θi[(][t,k][)]** _−_ _θ[¯][(][t,k][)]∥[2][i]_

1
+ _θ[(][t][)]_ _θ[∗]_ **E** _θ[(][t][+1)]_ _θ[∗]_ _._

2ηK _∥_ _−_ _∥[2]_ _−_ _∥_ _−_ _∥[2][i!]_

h

_Proof. Since_ _θ[¯][(][t,k][+1)]_ = θ[¯][(][t,k][)] _−_ _η_ _i=1_ _[λ][i][g][i][(][θ]i[(][t,k][)]), by parallelogram law_

_m_

_λi_ _gi(θi[(][t,k][)]),_ _θ[¯][(][t,k][+1)]_ _θ[∗][E]_ = [P][1][m] _θ[(][t,k][)]_ _θ[∗]_ _θ[(][t,k][+1)]_ _θ[(][t,k][)]_ _θ[(][t,k][+1)]_ _θ[∗]_
_−_ 2η _∥[¯]_ _−_ _∥[2]_ _−∥[¯]_ _−_ [¯] _∥[2]_ _−∥[¯]_ _−_ _∥[2][]_
_i=1_

X D 

(16)


Fact: Fi(θ) = EZi∼Pi _φγ(Zi, θ)_ is Lipschitz smooth with L = Lθθ + _[L]γ[θz]−L[L]zz[zθ]_ [when][ γ > L][zz][.]

With the assumption that θ _ℓ(z, hθ) is convex, we have θ_ _Fi(θ) is convex._

 _7→_  _7→_

Since Fi is convex and L-smooth,

_Fi(θ[¯][(][t,k][+1)]) ≤_ _Fi(θi[(][t,k][)]) +_ D∇Fi(θi[(][t,k][)]), _θ[¯][(][t,k][+1)]_ _−_ _θi[(][t,k][)]E_ + _[L]2_ _[∥]θ[¯][(][t,k][+1)]_ _−_ _θi[(][t,k][)]∥[2]_

_≤Fi(θ[∗]) +_ D∇Fi(θi[(][t,k][)]), _θ[¯][(][t,k][+1)]_ _−_ _θ[∗][E]_ + _[L]2_ _[∥]θ[¯][(][t,k][+1)]_ _−_ _θi[(][t,k][)]∥[2]_

_Fi(θ[∗]) +_ _Fi(θi[(][t,k][)]),_ _θ[¯][(][t,k][+1)]_ _θ[∗][E]_ + L _θ[(][t,k][+1)]_ _θ[(][t,k][)]_ + L _θi[(][t,k][)]_ _θ[(][t,k][)]_ _._ (17)
_≤_ _∇_ _−_ _∥[¯]_ _−_ [¯] _∥[2]_ _∥_ _−_ [¯] _∥[2]_
D


-----

From (16) and (17), we have


_F_ (θ[¯][(][t,k][+1)]) − _F_ (θ[∗]) =


_λi_ _Fi(θ[¯][(][t,k][+1)])_ _F_ (θ[∗])
_−_
_i=1_

X 


_m_ _m_

_λi_ _Fi(θi[(][t,k][)])_ _gi(θi[(][t,k][)]),_ _θ[¯][(][t,k][+1)]_ _θ[∗][E]_ + L _θ[(][t,k][+1)]_ _θ[(][t,k][)]_ + L _λi_ _θi[(][t,k][)]_ _θ[(][t,k][)]_

_≤_ _∇_ _−_ _−_ _∥[¯]_ _−_ [¯] _∥[2]_ _∥_ _−_ [¯] _∥[2]_

_i=1_ _i=1_

X D X

+ [1] _θ[(][t,k][)]_ _θ[∗]_ _θ[(][t,k][+1)]_ _θ[(][t,k][)]_ _θ[(][t,k][+1)]_ _θ[∗]_ _._ (18)

2η ∥[¯] _−_ _∥[2]_ _−∥[¯]_ _−_ [¯] _∥[2]_ _−∥[¯]_ _−_ _∥[2][]_

We have

_[m]_
**E** _λi_ _Fi(θi[(][t,k][)])_ _gi(θi[(][t,k][)]),_ _θ[¯][(][t,k][+1)]_ _θ[∗][Ei]_

_∇_ _−_ _−_
_i=1_

hX D

_[m]_
= E _λi_ _Fi(θi[(][t,k][)])_ _gi(θi[(][t,k][)]),_ _θ[¯][(][t,k][+1)]_ _θ[(][t,k][)][Ei]_ (since E _gi(θi[(][t,k][)])_ = _Fi(θi[(][t,k][)]) given_ _θ[¯][(][t,k][)], θ[∗])_

_∇_ _−_ _−_ [¯] _∇_
_i=1_

hX Dm  

_≤_ [3]2 _[η][ ·][ E]_ _∥_ _λi_ _∇Fi(θi[(][t,k][)]) −_ _gi(θi[(][t,k][)])_ _∥[2][i]_ + 6[1]η **[E]** _∥θ[¯][(][t,k][+1)]_ _−_ _θ[¯][(][t,k][)]∥[2][i]_ (by Peter Paul inequality)

_i=1_

h mX    h

_≤_ 2ησˆ[2] _λ[2]i_ + 6[1]η **[E]** _∥θ[¯][(][t,k][+1)]_ _−_ _θ[¯][(][t,k][)]∥[2][i],_ (19)
Xi=1  h


Plugging (19) back to the conditional expectation of (18), and noting that η ≤


1

3L [, we have]


_F_ (θ[¯][(][t,k][+1)]) _F_ (θ[∗]) + [1]
_−_ 2η
i


_∥θ[¯][(][t,k][+1)]_ _−_ _θ[∗]∥[2]_ _−∥θ[¯][(][t,k][)]_ _−_ _θ[∗]∥[2]_



_∥θ[¯][(][t,k][+1)]_ _−_ _θ[¯][(][t,k][)]∥[2]_ + L



_λi_ _θi[(][t,k][)]_ _θ[(][t,k][)]_
_∥_ _−_ [¯] _∥[2]_
_i=1_

X


_≤2ησˆ[2]_


_λ[2]i_
_i=1_

X


3η

_[−]_ _[L]_


2ησˆ[2][][ m] _λ[2]i_ + L
_≤_

_i=1_

X 


_λi_ _θi[(][t,k][)]_ _θ[(][t,k][)]_
_∥_ _−_ [¯] _∥[2]_
_i=1_

X


By convexity of F and telescoping k from 0 to K − 1, we have

1 _K−1_ _m_ _m_ _K−1_ 1

_K_ _kX=0_ **EF** (θ[¯][(][t,k][)]) − _F_ (θ[∗]) _≤2ησˆ[2]_ Xi=1 _λ[2]i_ ! + L Xi=1 _λi_ _kX=0_ _K_ **[E]h∥θi[(][t,k][)]** _−_ _θ[¯][(][t,k][)]∥[2][i]_

1
+ _θ[(][t,][0)]_ _θ[∗]_ **E** _θ[(][t,K][)]_ _θ[∗]_ _._

2ηK ∥[¯] _−_ _∥[2]_ _−_ h∥[¯] _−_ _∥[2][i]_

Since _θ[¯][(][t,][0)]_ = θ[(][t][)] and _θ[¯][(][t,K][)]_ = θ[(][t][+1)], we complete the proof.

**Lemma 4 (Bounded client drift). Assuming the client learning rate satisfies η ≤** 31L _[, we have]_

**E** _θi[(][t,k][)]_ _θ[(][t,k][)]_ _η[2](24K_ [2][ ¯]Ω[2] + 20KΩ[¯] [2]).
_∥_ _−_ [¯] _∥[2][i]_ _≤_
h

_where_ Ω[¯] [2] := max _σ[2], Ω[2]_ _._


_Proof._

b

2[]
**E** _θ1[(][t,k][+1)]_ _θ2[(][t,k][+1)]_ = E _θ1[(][t,k][)]_ _θ2[(][t,k][)]_ _η_ _g1(θ1[(][t,k][)])_ _g2(θ1[(][t,k][)])_
_−_ _−_ _−_ _−_
    

= _θ1[(][t,k][)]_ _θ2[(][t,k][)]_ 2η[2] _g1(θ1[(][t,k][)])_ _F1(θ1[(][t,k][)]), θ1[(][t,k][)]_ _θ2[(][t,k][)]_
_∥_ _−_ _∥[2]_ _−_ _−∇_ _−_
D E


2η _F2(θ1[(][t,k][)])_ _g2(θ2[(][t,k][)]), θ1[(][t,k][)]_ _θ2[(][t,k][)]_
_−_ _∇_ _−_ _−_
D E

2η _F1(θ1[(][t,k][)])_ _F2(θ2[(][t,k][)]), θ1[(][t,k][)]_ _θ2[(][t,k][)]_ + η[2] _g1(θ1[(][t,k][)])_ _g2(θ2[(][t,k][)])_ _._ (20)
_−_ _∇_ _−∇_ _−_ _∥_ _−_ _∥[2]_
D E


-----

The second term (and similarly for the third term) is bounded as follows

_g1(θ1[(][t,k][)])_ _F1(θ1[(][t,k][)]), θ1[(][t,k][)]_ _θ2[(][t,k][)]_
_−_ _−∇_ _−_
D 1 E

_≤_ 6ηK _θ1[(][t,k][)]_ _−_ _θ2[(][t,k][)]_ + [3][ηK]2 _g1(θ1[(][t,k][)]) −∇F1(θ1[(][t,k][)])_ (by Peter Paul inequality)

1
= 6ηK _θ1[(][t,k][)]_ _−_ _θ2[(][t,k][)]_ [2] + [3][ηK]2 _σ[2]_ (by (15)) [2]

Since maxi supθ _Fi(θ)_ [2]F (θ) bΩ (Assumption 5), the 4th-term is bounded as
_∥∇_ _−∇_ _∥≤_

_F1(θ1[(][t,k][)])_ _F2(θ2[(][t,k][)]), θ1[(][t,k][)]_ _θ2[(][t,k][)]_
_−_ _∇_ _−∇_ _−_
D E


_F_ (θ1[(][t,k][)]) _F_ (θ2[(][t,k][)]), θ1[(][t,k][)] _θ2[(][t,k][)]_ + 2Ω _θ1[(][t,k][)]_ _θ2[(][t,k][)]_
_≤−_ _∇_ _−∇_ _−_ _∥_ _−_ _∥_
D E

_≤−_ _L[1]_ _[∥∇][F]_ [(][θ]1[(][t,k][)]) −∇F (θ2[(][t,k][)])∥[2] + 2Ω∥θ1[(][t,k][)] _−_ _θ2[(][t,k][)]∥_ (by smoothness and convexity)

1

_≤−_ _L[1]_ _[∥∇][F]_ [(][θ]1[(][t,k][)]) −∇F (θ2[(][t,k][)])∥[2] + 6ηK 1 _−_ _θ2[(][t,k][)]∥[2]_ + 6ηKΩ[2] (by Young’s inequality)

_[∥][θ][(][t,k][)]_

The last term is bounded as follows


_g1(θ1[(][t,k][)])_ _g2(θ2[(][t,k][)])_
_∥_ _−_ _∥[2]_

5 _g1(θ1[(][t,k][)])_ _F1(θ1[(][t,k][)])_ + _F1(θ1[(][t,k][)])_ _F_ (θ1[(][t,k][)]) + _F_ (θ1[(][t,k][)]) _F_ (θ2[(][t,k][)])
_≤_ _−∇_ _∥∇_ _−∇_ _∥[2]_ _∥∇_ _−∇_ _∥[2]_


+ _F_ (θ2[(][t,k][)]) _F2(θ2[(][t,k][)])_ [2] + _g2(θ2[(][t,k][)])_ _F2(θ2[(][t,k][)])_
_∥∇_ _−∇_ _∥[2]_ _−∇_

5 _F_ (θ1[(][t,k][)]) _F_ (θ2[(][t,k][)]) + 10(σ[2] + Ω[2]) (by (15) and Assumption 5)[2][]
_≤_ _∥∇_ _−∇_ _∥[2]_

Substituting the above four bounds back to (20) gives (note thatb _η ≤_ 31L [)]

2

**Eh∥θ+ 61[(][t,k]η[+1)][2]K−σ[2]θ2[(]+ 12[t,k][+1)]η[2]∥K[2][i]Ω≤[2]** + 101 + ηK[2][1](σ[2]∥+ Ωθ1[(][t,k][2][)])− _θ2[(][t,k][)]∥[2]_ _−_ _η_ _L_ _[−]_ [5][η]∇F (θ1[(][t,k][)]) −∇F (θ2[(][t,k][)])

1 + [1] _θ1[(][t,k][)]_ _θ2[(][t,k][)]_ + 6η[2]Kσ[2] + 12η[2]KΩ[2] + 10η[2](σ[2] + Ω[2]).
_≤_ _Kb_ _∥_ _−_ _∥[2]_ b
 

Unrolling recursively, we obtain b b

_K_
1 + 1/K 1

**E** _θ1[(][t,k][+1)]_ _−_ _θ2[(][t,k][+1)]_ _≤_ 1/K _−_ 6η[2]Kσ[2] + 12η[2]KΩ[2] + 10η[2](σ[2] + Ω[2])

  

h h i

[2][i] _≤_ 12η[2]K [2]σ[2] + 24η[2]K [2]Ω[2]b+ 20η[2]K(σ[2] + Ω[2]) b

_≤_ _η[2](24K_ [2][ ¯]Ω[2] + 20KΩ[¯] [2]).

_K_ b b
where we use the fact that 1+11/K/K _−1_ _K(e_ 1) 2K, and Ω[¯] [2] := max _σ[2], Ω[2]_ .

_≤_ _−_ _≤_

  

By convexity, for any i, 

b

**E** _θi[(][t,k][+1)]_ _θ[(][t,k][+1)]_ _η[2](24K_ [2][ ¯]Ω[2] + 20KΩ[¯] [2]).
_∥_ _−_ [¯] _∥[2][i]_ _≤_
h

Substituting the result of Lemma 4 to Lemma 3, and telescoping over t, we obtain


1

_T_

h


_T −1_

_t=0_

X


_K−1_ _D[2]_

_F_ (θ[¯][(][t,k][)]) _F_ (θ[∗]) _σ[2]Λ + η[2]L(24K_ [2][ ¯]Ω[2] + 20KΩ[¯] [2]),
_−_ _≤_ 2ηKT [+ 2][η][ˆ]
_k=0_

X i


-----

where D := ∥θ[(0)] _−_ _θ[∗]∥, Λ :=_



[(0)] _−_ _θ[∗]∥, Λ :=_ _i=1_ _λ[2]i_ [. By optimizing][ η][ on the R.H.S, we obtain]

_K−1_ P _LD2_ _σDΛ_ 21 13 Ω[¯] 23 D 34 13 Ω[¯] 23 D

_F_ (θ[¯][(][t,k][)]) _F_ (θ[∗]) + _[L]_ 1 2 + _[L]_ 2
_kX=0_ _−_ i _≤O_ _KT_ [+][ b]√KT _K_ 3 T 3 _T_ 3


1

_KT_

h


_T −1_

_t=0_

X


when


_η = min_


3L _[,]_


1 2 1 1 2
48 3 K 3 T 3 L 3 Ω[¯] 3 _[,]_


1 1 1
40 3 KT 3 L 3 Ω[¯]


_KT_ Λσb


D PROOF OF LEMMA 1

We first prove the following fact:


**Fact 1:**
(a) L(Q, f ) ≤ L[γ]ρ[(][P][λ][, f] [)][,] _∀f ∈F, Q ∈B(Pλ, ρ)._

(b) inf _ρ[(][P][λ][, f][ ′][)][,]_ _Q_ (Pλ, ρ).
_f_ _[′]∈F_ [L][(][Q, f][ ′][)][ ≤] _f[inf][′]∈F_ [L][γ] _∀_ _∈B_

For (a), we have

L(Q, f ) ≤ _P_ _[′]∈Bsup(Pλ,ρ)L(P_ _[′], f_ ) = infγ[′]≥0nγ[′]ρ[2] + EZ∼Pλ hφγ(Z, f )io

_γρ[2]_ + EZ _Pλ_ _φγ(Z, f_ ) =: L[γ]ρ[(][P][λ][, f] [)][,]
_≤_ _∼_

where the equality is due to strong duality result by Gao & Kleywegt (2016).h i


For (b), defining fPλ := arg minf ′∈F Lρ[γ][(][P][λ][, f][ ′][)][, we have]

_finf[′]∈F_ [L][(][Q, f][ ′][)][ ≤] [L][(][Q, f][P][λ] [)][ ≤] _P_ _[′]∈Bsup(Pλ,ρ)L(P_ _[′], fPλ_ ) (21)

= infγ[′]≥0 _γ[′]ρ[2]_ + EZ∼Pλ _φγ(Z, fPλ_ ) (22)

n h io

_≤_ _γρ[2]_ + EZ∼Pλ _φγ(Z, fPλ_ ) (23)

= inf _ρ[(][P][λ][, f]h[ ′][)][.]_ i (24)
_f_ _[′]∈F_ [L][γ]

We next prove the second fact:


**Fact 2:**
(a) L[γ]ρ[(][P][λ][, f] [)][ ≤] [L][(][Q, f] [) + 2][L][z][ρ][ +][ |][γ][ −] _[γ][∗][|][ρ][2][,]_ _∀f ∈F, Q ∈B(Pλ, ρ)_

(b) inf _ρ[(][P][λ][, f][ ′][)][ ≤]_ [inf]
_f_ _[′]∈F_ [L][γ] _f_ _[′]∈F_ [L][(][Q, f][ ′][) + 2][L][z][ρ][ +][ |][γ][ −] _[γ][∗][|][ρ][2][.]_

For (a), we have:

L[γ]ρ[(][P][λ][, f] [) =] sup L(P _[′], f_ ) + L[γ]ρ[(][P][λ][, f] [)][ −] sup L(P _[′], f_ )
P _[′]∈B(Pλ,ρ)_  n _P_ _[′]∈B(Pλ,ρ)_ o

_≤_ L(Q, f ) + 2Lzρ + **EZ∼Pλ** [φγ(Z, f )] + ρ[2]γ − _γmin[′]_ 0 _ρ[2]γ[′]_ + EZ∼Pλ [φγ′ (Z, f )]
n o  _≥_ n o[]

_≤_ L(Q, f ) + 2Lzρ + ρ[2](γ − _γ[∗]) + EZ∼P_ _φγ(Z, f_ ) − _φγ∗_ (Z, f )
h i

= L(Q, f ) + 2Lzρ + ρ[2](γ − _γ[∗]) + EZ∼P_  _ζsup∈Z_ nℓ(ζ, h) − _γd(ζ, Z)o_ _−_ _ζsup∈Z_ nℓ(ζ, h) − _γ[∗]d[2](ζ, Z)o[]_

= L(Q, f ) + 2Lzρ + (γ − _γ[∗])_ _ρ[2]_ _−_ **EZ∼P** _ζsup∈Z_ _d[2](ζ, Z)_
 h i

L(Q, f ) + 2Lzρ + _γ_ _γ[∗]_ _ρ[2],_
_≤_ _|_ _−_ _|_


-----

where the first inequality is due to Proposition 1, and the last inequality is because we choose γ ≥
_Lz/ρ and that fact that γ[∗]_ _Lz/ρ by Lemma 1 of Lee & Raginsky (2018)._
_≤_

For (b), defining fQ := arg minf L(Q, f ), we have
_∈F_

inf _ρ[(][P][λ][, f][ ′][)][ ≤]_ [L][γ]ρ[(][P][λ][, f][Q][)] (25)
_f_ _[′]∈F_ [L][γ]

L(Q, fQ) + 2Lzρ + _γ_ _γ[∗]_ _ρ[2]_ (26)
_≤_ _|_ _−_ _|_

= inf (27)
_f_ _[′]∈F_ [L][(][Q, f][ ′][) + 2][L][z][ρ][ +][ |][γ][ −] _[γ][∗][|][ρ][2][,]_


where the second line is due to Fact 2(a).

Combining all facts, we complete the proof. Specifically, by adding two inequalities in Fact 1(a)
and Fact 2(b), we obtain the upperbound of Lemma 1. Similarly, adding two inequalities in Fact
**1(b) and Fact 2(a), we obtain the lowerbound of this lemma.**

Finally, we provide the proof of the following proposition that was used in proving Fact 2(a).

**Proposition 1. Let Assumption 2 (a) holds. For any f ∈F and for all Q ∈B(Pλ, ρ), we have**

sup L(P _, f_ ) L(Q, f ) + 2Lzρ.
_P_ _[′]∈B(Pλ,ρ)_ _[′]_ _≤_

_Proof. Denote P_ _[∗]_ := arg max L(P _[′], f_ ). We have
_P_ _[′]∈B(Pλ,ρ)_

_P_ _[′]∈Bsup(Pλ,ρ)L(P_ _[′], f_ ) = L(Q, f ) + _P_ _[′]∈Bsup(Pλ,ρ)L(P_ _[′], f_ ) − L(Q, f )

_≤_ L(Q, f ) + |L(P _[∗], f_ ) − L(Q, f )|,

_≤_ L(Q, f ) + Lz **EZ∼P ∗** []ℓ(Z, h)/Lz _−_ **EZ∼Q** _ℓ(Z, h)/Lz_

L(Q, f ) + LzW1(P _, Q)_
_≤_ _[∗]_   

L(Q, f ) + Lz _W2(P_ _, Pλ) + W2(Pλ, Q)_ (28)
_≤_ _[∗]_

L(Q, f ) + Lz2ρ,

 

_≤_


where the fourth line are due to Kantorovich-Rubinstein dual representation theorem, i.e.,


**EZ∼P** _h(Z)_ _−_ **EZ∼Q** _h(Z)_ : h(·) is 1-Lipschitz
   


_W1(P, Q) = sup_


and the fifth line is due to W1(P _, Q)_ _W2(P_ _, Q) and triangle inequality._

_[∗]_ _≤_ _[∗]_

E PROOF OF THEOREM 2

_Proof. To simplify notation, we denote Φ := φγ_ = _z_ _φγ(z, f_ ), f where = _fθ, θ_
_◦F_ _{_ _7→_ _∈F}_ _F_ _∈_
Θ R[d], which represents the composition of φγ with each of the loss function fθ parametrized
_⊂_ 
by θ belonging to the parameter class Θ.

Defining fPλ arg minf Lρ[γ][(][P][λ][, f] [)][ and][ b]θ[∗] argmin **EZ** _Pλ_ _φγ(Z, fθ)_ such that
_∈_ _∈F_ _∈_ _θ∈Θ_ _∼_

L[γ]ρ[(][ b]Pλ, fθ∗ ) = infθ Θ **EZ∼Pλ** _φγ(Z, fθ)_ + γρ[2][i], we decompose the excess risk as follows:b  
_∈_

h b  


-----

E[γ]ρ[(][P][λ][, f]θ[b][ε] [) =][ L]ρ[γ][(][P][λ][, f]θ[b][ε] [)][ −] [inf] _ρ[(][P][λ][, f]_ [)]
_f_ [L][γ]
_∈F_

= L[γ]ρ[(][P][λ][, f]θ[b][ε] [)][ −] [L]ρ[γ][(][P][λ][, f][P]λ [)]

= L[γ]ρ[(][P][λ][, f]θ[b][ε] [)][ −] [L]ρ[γ][(][ b]Pλ, fθ[ε] [)] + L[γ]ρ[(][ b]Pλ, fθ[ε] [)][ −] [L]ρ[γ][(][ b]Pλ, fθ[∗] [)]
h b i h b _ε_ b i

_≤_

+ L[γ]ρ[(][ b]Pλ, fθ[∗] [)][ −] [L]ρ[γ][(][ b]Pλ, fPλ ) |+ L[γ]ρ[(][ b]Pλ, fP{zλ ) − L[γ]ρ[(][P][λ][, f][P]}λ [)]
h b 0 i h i

_≤_

_≤_ 2 supφ|γ _∈Φ_ **EZ∼Pλ** [φ{zγ(Z, fθ)] − **EZ}∼Pλ** [[][φ][γ][(][Z, f][θ][)]] + ε

_m_ b

_≤_ 2 supφγ _∈Φ_ _i=1_ _λi_ **EZi∼Pi** [φγ(Zi, fθ)] − **EZi∼Pi** [[][φ][γ][(][Z][i][, f][θ][)]] + ε

_m_ X b

_≤_ 2 _i=1_ _λi supφγ_ _∈Φ_ **EZi∼Pi** [φγ(Zi, fθ)] − **EZi∼Pi** [[][φ][γ][(][Z][i][, f][θ][)]] + ε

X b

_m_

2 log(2m/δ)

_λi_ 4Ri(Φ) + 2Mℓ + ε with probability at least 1 _δ,_ (29)

_≤_ _i=1_  s _ni_  _−_

X

where the first inequality is due to optimization error and definition of _θ[∗]. The second inequality is_
due to the fact that |[P]i[m]=1 _[λ][i][a][i][| ≤]_ [P]i[m]=1 _[λ][i][|][a][i][|][,][ ∀][a][i][ ∈]_ [R][ and][ λ][i][ ≥] [0][. The third inequality is because]
pushing the sup inside increases the value. For the last inequality, using the facts that (i) _φγ(z, f_ )

[b] _|_ _| ≤_
_Mℓ_ due to _Mℓ_ _ℓ(z, h)_ _φγ(z, f_ ) supz _ℓ(z, h)_ _Mℓ_ and (ii) the Rademacher complexity
of the function class − _≤_ Φ defined by ≤ Ri(Φ) = ≤ **E[sup∈Z** _φγ_ Φ _n ≤1i_ _nk=1i_ _[σ][k][φ][γ][(][Z][k][, f][θ][)]][ where the expecta-]_
_∈_

i.i.d.
tion is w.r.t both Zk _Pi and i.i.d. Rademacher random variableP_ _σk independent of Zk,_ _k_ [ni],
_∼_ _∀_ _∈_
we have


2 log(2m/δ)

_φsupγ_ Φ **EZi∼Pi** [φγ(Zi, fθ)] − **EZi∼Pi** [[][φ][γ][(][Z][i][, f][θ][)]] _≥_ 2Ri(Φ) + Mℓs _ni_ (30)
_∈_

b

with probability ≤ _δ/m due to the standard symmetrization argument and McDiarmid’s inequal-_
ity (Shalev-Shwartz & Ben-David, 2014, Theorem 26.5). Multiplying λi to both sides of (30),
summing up the inequalities over all i ∈ [n], and using union bound, we obtain (29).

Define a stochastic process _Xφγ_ _φγ_ _∈Φ_

_ni_

   1

_Xφγ :=_ _σkφγ(Zk, fθ)_
_√ni_

_k=1_

X

which is zero-mean because E _Xφγ_ = 0 for all φγ Φ. To upper-bound Rn(Φ), we first show
_∈_
that _Xφγ_ _φγ_ _∈Φ_ [is a sub-Gaussian process with respect to the following pseudometric] 
   _φγ_ _φ[′]γ_ _φγ(z, fθ)_ _φγ(z, fθ[′]_ ) _._ (31)

_−_ _∞_ [:= sup]z _−_
_∈Z_

For any t ∈ R, using Hoeffding inequality with the fact that σk, k ∈ [n], are i.i.d. bounded random
variable with sub-Gaussian parameter 1, we have

_t_ _ni_

**E** exp _t_ _Xφγ −_ _Xφ′γ_ = E "exp _√ni_ _k=1_ _σk (φγ (Zk, fθ) −_ _φ (Zk, fθ′_ ))!#
h   i _t_ X _ni_

= **E** exp _σ1 (φγ (Z1, fθ)_ _φγ (Z1, fθ′_ ))
_√ni_ _−_
   

_t[2]_ _φγ_ _φ[′]γ_

exp _−_ _∞_ _._
_≤_ 2 !

[2]


-----

Then, invoking Dudley entropy integral, we have

_∞_
_√ni Ri(Φ) = E sup_ _Xφγ_ 12
_φγ_ Φ _≤_ 0
_∈_ Z


log (Φ, _, ϵ)dϵ_ (32)
_N_ _∥·∥∞_


We will show that when θ _ℓ(z, hθ) is Lθ-Lipschitz by Assumption 2, then θ_ _φγ(z, fθ) is also_
_7→_ _7→_
_Lθ-Lipschitz as follows._

_φγ(z, fθ)_ _φγ(z, fθ[′]_ ) = sup inf _ℓ(ζ, hθ)_ _γd(ζ, z)_ _ℓ(ζ_ _[′], hθ′_ ) + γd(ζ _[′], z)_
_−_ _ζ∈Z_ _ζ[′]∈Z_ _−_ _−_

n o

sup _ℓ(ζ, hθ)_ _ℓ(ζ, hθ′_ )
_≤_ _ζ∈Z_ _−_

n o

sup _ℓ(ζ, hθ)_ _ℓ(ζ, hθ[′]_ )
_≤_ _ζ∈Z_ _−_

_Lθ_ _θ_ _θ[′]_ _,_
_≤_ _∥_ _−_ _∥_

which implies
_φγ −_ _φ[′]γ_ _∞_ _[≤]_ _[L][θ][∥][θ][ −]_ _[θ][′][∥][.]_

Therefore, by contraction principle (Shalev-Shwartz & Ben-David, 2014), we have

_N (Φ, ∥·∥∞, ϵ) ≤N (Θ, ∥·∥, ϵ/Lθ) ._ (33)

Substituting (33) and (32) into (29), we obtain


48C(Θ)
+ 2Mℓ
_√ni_


2 log(2m/δ)

_ni_


48C(Θ) 2 log(2m/δ)

E[γ]ρ[(][P][λ][, f]θ[b][ε] [)][ ≤] _λi_ + 2Mℓ + ε, (34)

_i=1_ " _√ni_ s _ni_ #

X

which will be substituted into the upper-bound in Lemma 1 to complete the proof.


F PROOF OF CORROLARY 1

We now present how we adapt the result from Fournier & Guillin (2015) to prove Corollary 1
**Proposition 2 (Measure concentration (Fournier & Guillin, 2015, Theorem 2)). Let P be a probabil-**
_i.i.d._
_ity distribution on a bounded set Z. Let_ _Pn denote the empirical distribution of Z1, . . ., Zn_ _∼_ _P._
_Assuming that there exist constants a > 1 such that A := EZ∼P_ exp(∥Z∥[a]) _< ∞_ _(i.e., P is a_
_light-tail distribution). Then, for any ρ > 0,_

[b]  

_c1 exp_ _c2nρ[max][{][d/p,][2][}][]_ _if ρ_ 1
**P** _Wp(Pn, P_ ) ≥ _ρ_ _≤_ _c1 exp (−c2nρ[a])_ _if ρ > ≤ 1_
h i   −

_where c1, c2 are constants depending on[b]_ _a, A and d._


As a consequence of this proposition, for any δ > 0, we have


min 2/d,1/2

log(c1/δ) _{_ _}_

_c2n_ if n _c2_ _,_

1/α _≥_ [log(][c][1][/δ][)] (35)

log(c1/δ) 

_c2n_ if n < [log(]c[c]2[1][/δ][)] _._



_W2(Pn, P_ ) ≤ _ρ[δ]n_ _≥_ 1 − _δ where_ _ρ[δ]n_ [:=]
i

[b] b b


In Proposition 2, Fournier & Guillin (2015) show that the empirical distribution _Pn converges in_
Wasserstein distance to the true P at a specific rate. This implies that judiciously scaling the radius
of Wasserstein balls according to (35) provides natural confidence regions for the data-generating

[b]
distribution P .

By the duality of transport cost (Santambrogio, 2015, p.261), we have


_Wp[p][(][µ, ν][) =]_ sup
_ϕ(x)+ψ(y)≤d[p](x,y)_


_ϕ dµ + ψ dν =_ sup _Tf_ (µ, ν), _p_ 1,
_ϕ(x)+ψ(y)≤d[p](x,y)_ _∀_ _≥_


-----

which is the supremum of linear functionals Tf : P × P _7→_ R defined by Tf (µ, ν) =
_⟨(µ, ν), (ϕ, ψ)⟩; therefore, (µ, ν) 7→_ _Wp[p][(][µ, ν][)][ is convex. Thus we have]_

_[m]_ _m_
_W2[2][(][P][λ][,][ b]Pλ) = W2[2]_ _λi(Pni_ _, Pi)_ _≤_ _λiW2[2][(][ b]Pni_ _, Pi)._ (36)

_i=1_ _i=1_

X  X

Then, we have [b]

_m_

_m_

**P** _W2(Pλ,_ _Pλ) ≥_ _i=1_ _[λ][i]ρ[b][δ/m]ni_ = P _W2[2][(][P][λ][,][ b]Pλ) ≥_ _λiρ[δ/m]ni_

_i=1_

h rX i h _[m]_ X _m_ i

[b] b

_≤_ **P** _λiW2[2][(][ b]Pni_ _, Pi) ≥_ _λiρ[δ/m]ni_

_i=1_ _i=1_

_mhX_ X i

b

_≤_ **P** _W2[2][(][ b]Pni_ _, Pi) ≥_ _ρ[δ/m]ni_

_i=1_

Xm h i

b

= **P** _W2(Pni_ _, Pi)_ _ρ[δ/]ni[2][m]_

_≥_
_i=1_

Xm h i

_δ_ [b] b

(37)

_≤_ 2m [=][ δ]2 _[,]_

_i=1_

X

where the first inequality is due to (36), the second inequality is due to the union bound, and the last
inequality is due to Proposition 2 and (35).

1/2
According to (28), by setting ρ = _mi=1_ _[λ][i]ρ[b][δ/m]ni_ in Theorem 2 and using union bound, we
complete the proof. P 

G ADDITIONAL EXPERIMENTAL SETTINGS AND RESULTS

G.1 DATASETS

Table 1: Statistics of all datasets using in the experiments.

Total Num labels Samples / client
Dataset _m_
samples / client Mean Std

CIFAR-10 20 43,098 3 2154 593.8
MNIST 100 70,000 2 700 313.4
MNIST-M 100 70,000 2 700 322.4

We distribute all datasets to clients as follows:

-  MNIST: A handwritten digit dataset (Lecun et al., 1998) including 70, 000 instances belonged to 10 classes. We distribute dataset to m = 100 clients and each client has a different
local data size with only 2 of the 10 classes.

-  CIFAR-10: An object recognition dataset (Krizhevsky, 2009) including 60, 000 colored
images belonged to 10 classes. We partition the dataset to m = 20 clients and there are 3
labels per client. Each client has a different local data size.

-  Three handwritten digit: MNIST, MNIST-M (Ganin & Lempitsky, 2015), and USPS
(Hull, 1994). We distribute one dataset, for example, MNIST to 100 source clients, and
leave MNIST-M to the target client. Each source client has only 2 labels over 10 labels. As
the number of data samples in USPS is relatively small amount (9,298 samples), we only
use this dataset for the target client.

We standardize and randomly split all datasets with 75% and 25% for training and testing, respectively. In domain adaptation, the target client only has test data. The statistics of all datasets are
summarized in Tab. 1.


-----

MNIST: Clean Data

50 100 150 200


MNIST: Clean Data

50 100 150 200


MNIST: Under Distribution Shifts

0 50 100 150 200


MNIST: Under Distribution Shifts

0 50 100 150 200


1.8

1.6

1.4

1.2

1.0

0.8

0.6

2.2

2.0

1.8

1.6

1.4

1.2


0.8

0.7

0.6

0.5

0.4

0.55

0.50

0.45

0.40

0.35

0.30

0.25

0.20


0.6

0.5

0.4

0.3


3.0

2.5

2.0

1.5

2.2

2.1

2.0

1.9

1.8

1.7

1.6

1.5


CIFAR: Under Distribution Shifts

WAFL : = 0.05


0.45

0.40

0.35

0.30

Global Accuracy

0.25

0.20


CIFAR: Clean Data

50 100 150 200


CIFAR: Clean Data


CIFAR: Under Distribution Shifts

0 50 100 150 200


50 100 150 200

T


50 100 150 200


WAFL : = 0.5


Figure 5: Convergence of WAFL.


G.2 MODELS

The details of models for each dataset is provided as follows:



-  MNIST: We use a multinomial logistic regression model (MLR) with a cross-entropy loss
function and an L2-regularization term.

-  CIFAR-10: We use a CNN model employed in McMahan et al. (2017).



-  Set of three handwriten digits: We use a multinomial logistic regression model (MLR)
with a cross-entropy loss function and an L2-regularization term.

In all settings, we randomly sample 10 clients to participate in training the global robust model
in each communication round, and set the number of local epochs to K = 2 and the number of
communication rounds to T = 200. All experiments were conducted using PyTorch (Paszke et al.,
2019).


G.3 CONVERGENCE OF WAFL

We verify the convergence of WAFL under two cases: clean data (no attacked clients) and distri_bution shifts (where 40% of clients are attacked). In each case, we use two datasets: MNIST and_
CIFAR-10 and employ the same setup as in Sec. 6. Specifically, for MNIST, we distribute the dataset
to 100 clients and set γ = 0.05. For CIFAR-10, we use 20 clients and set γ = 0.5. We use T = 200
communication iterations.

To show WAFL’s convergence, we plot both the original loss (using the function ℓ) and global
accuracy in Fig. 5.


G.4 DOMAIN ADAPTATION.

We show that WAFL demonstrates its superior capability in domain adaptation by collaboratively
learning from a multi-source domain _Pλ, and applying it to an unseen, but related, target domain_
_Q. In federated domain adaptation (Peng et al., 2019; Liu et al., 2021), source domains often need_
access to the private data of target domains to find a common representation to aid training. However,[b]
this violates the data privacy assumption of FL. By contrast, the construction of the model inb WAFL
does not involve such private data.

Our experimental set up is as follows. We consider three datasets: MNIST (mt), MNIST-M (mm)
and USPS (up), which are widely used in domain adaptation. Among these datasets, we consider


-----

Table 2: Domain adaptation performance of WAFL and FedAvg as an accuracy on the target dataset.

Algorithm **_mt→mm_** **_mt→up_** **_mm→up_** **_mm→mt_** Average

WAFL **40.23** **66.94** **62.04** **79.27** **62.12**
FedAvg 37.71 66.08 58.60 75.80 59.55

one dataset as a source domain (distributed to 100 clients), and another dataset as a target domain
(assumed to be on one client). For example, if mt is used as the source and mm the domain, we
use mt→mm to denote this case. Specifically, the mm dataset is distributed to 100 clients to learn
a global model, then the model is tested on the mt dataset. We compare WAFL against the vanilla
FedAvg as a baseline, and report the accuracy on the target dataset in several scenarios in Tab. 2.

WAFL markedly improves from FedAvg in all cases. On average, the accuracy of WAFL is 2.5 percentage point higher than that of FedAvg. This indicates WAFL’s benefits in transferring knowledge
from multi-sourced, private client distributions to a new target distribution.


-----


# LEARNED INDEX WITH DYNAMIC ϵ

**Anonymous authors**
Paper under double-blind review

ABSTRACT

Index structure is a fundamental component in database and facilitates broad data
retrieval applications. Recent learned index methods show superior performance
by learning hidden yet useful data distribution with the help of machine learning,
and provide a guarantee that the prediction error is no more than a pre-defined
_ϵ. However, existing learned index methods adopt a fixed ϵ for all the learned_
segments, neglecting the diverse characteristics of different data localities. In
this paper, we propose a mathematically-grounded learned index framework with
dynamic ϵ, which is efficient and pluggable to existing learned index methods. We
theoretically analyze prediction error bounds that link ϵ with data characteristics
for an illustrative learned index method. Under the guidance of the derived bounds,
we learn how to vary ϵ and improve the index performance with a better space-time
trade-off. Experiments with real-world datasets and several state-of-the-art methods
demonstrate the efficiency, effectiveness and usability of the proposed framework.

1 INTRODUCTION

Data indexing (Graefe & Kuno, 2011; Wang et al., 2018; Luo & Carey, 2020; Zhou et al., 2020), which
stores keys and corresponding payloads with designed structures, supports efficient query operations
over data and benefits various data retrieval applications. Recently, Machine Learning (ML) models
have been incorporated into the design of index structure, leading to substantial improvements in
terms of both storage space and querying efficiency (Kipf et al., 2019; Ferragina & Vinciguerra, 2020a;
Mitzenmacher, 2018; Vaidya et al., 2021). The key insight behind this trending topic of “learned
index” is that the data to be indexed contain useful distribution information and such information can
be utilized by trainable ML models that map the keys to their stored positions. State-of-the-art learned
index methods (Galakatos et al., 2019; Kipf et al., 2020; Ferragina & Vinciguerra, 2020b; Ferragina
et al., 2020) adopt piece-wise linear segments to approximate the data distribution and introduce an
important pre-defined parameter ϵ. These methods ensure that the maximal prediction error of each
learned segment is no more than ϵ and provide a worst-case guarantee of querying efficiency.

By tuning ϵ, various space-time preferences from users can be met. For example, a relatively large ϵ
can result in a small index size while having large prediction errors, and on the other hand, a relatively
small ϵ provides with small prediction errors while having more learned segments and thus a large
index size. However, existing learned index methods implicitly assume that the whole dataset to be
indexed contains the same characteristics for different localities and thus adopt the same ϵ for all the
learned segments, leading to sub-optimal index performance. More importantly, the impact of ϵ on
index performance is intrinsically linked to data characteristics, which are not fully explored and
utilized by existing learned index methods.

Motivated by these, in this paper, we theoretically analyze the impact of ϵ on index performance,
and link the characteristics of data localities with the dynamic adjustments of ϵ. Based on the
derived theoretical results, we propose an efficient and pluggable learned index framework that
dynamically adjusts ϵ in a principled way. To be specific, under the setting of an illustrative learned
index method MET (Ferragina et al., 2020), we present novel analysis about the prediction error
bounds of each segment that link ϵ with the mean and variance of data localities. The segment-wise
prediction error embeds the space-error trade-off as it is the product of the number of covered keys
and mean absolute error, which determine the index size and preciseness respectively. The derived
mathematical relationships enable our framework to fully explore diverse data localities with an
_ϵ-learner module, which learns to predict the impact of ϵ on the index performance and adaptively_
choose a suitable ϵ to achieve a better space-time trade-off.


-----

We apply the proposed framework to several state-of-the-art (SOTA) learned index methods, and
conduct a series of experiments on three widely adopted real-world datasets. Comparing with
the original learned index methods with fixed ϵ, our dynamic ϵ versions achieve significant index
performance improvements with better space-time trade-offs. We also conduct various experiments
to verify the necessity and effectiveness of the proposed framework, and provide both ablation study
and case study to understand how the proposed framework works.

2 BACKGROUND

2.1 _ϵ-BOUNDED LEARNED INDEX_

Given a dataset D = {(x, y)|x ∈X _, y ∈Y}, X is the set of keys over a universe U such as reals or_
integers, and Y is the set of positions where the keys and corresponding payloads are stored. The
index such as B[+]-tree (Abel, 1984) aims to build a compact structure to support efficient query
operations over D. Typically, the keys are assumed to be sorted in ascending order to satisfy the
_key-position monotonicity, i.e., for any two keys, xi > xj iff their positions yi > yj, such that the_
range query ( [xlow, xhigh]) can be handled.
_X ∩_

Recently, learned index methods (Kraska et al., 2018; Li et al., 2019; Tang et al., 2020; Dai et al., 2020;
Crotty, 2021) leverage ML models to mine useful distribution information from D, and incorporate
such information to boost the index performance. To look up a given key x, the learned index first
predicts position ˆy using the learned models, and subsequently finds the stored true position y based
on ˆy with a binary search or exponential search. Thus the querying time consists of the inference
time of the learned models and the search time in O(log(|yˆ − _y|)). By modeling the data distribution_
information, learned indexes achieve faster query speed than traditional B[+]-tree index, meanwhile
using several orders-of-magnitude smaller storage space (Ding et al., 2020; Galakatos et al., 2019;
Ferragina & Vinciguerra, 2020b; Kipf et al., 2020; Marcus et al., 2020).

Many existing learned index methods adopt piece-wise linear segments to approximate the distribution
of D due to their effectiveness and low computing cost, and introduce the parameter ϵ to provides a
worst-case preciseness guarantee and a tunable knob to meet various space-time trade-off preferences.
Here we briefly introduce the SOTA ϵ-bounded learned index methods that are most closely to our
work, and refer to the review chapter of (Ferragina & Vinciguerra, 2020a) for details of other methods.
Specifically, Galakatos et al. (2019) greedily learn a set of piece-wise linear segments in a one-pass
manner. Ferragina & Vinciguerra (2020b) adopt another one-pass algorithm that achieves the optimal
number of learned segments. Kipf et al. (2020) introduce a radix structure to organize the learned
segments. Ferragina et al. (2020) adopt a fixed slope setting for all learned segments. Existing
methods constraint all learned segments with the same ϵ, i.e., the learning process ensures that the
maximum prediction error is within a pre-defined ϵ where ϵ ∈ Z>1. In this paper, we will discuss the
impact of ϵ in more depth and invistigate how to enhance existing learned index methods from a new
perspective: dynamic adjustment of ϵ considering the diversity of different data localities.

2.2 MEAN EXIT TIME (MET) ALGORITHM

Here we describe an illustrative learned index algorithm MET (Ferragina et al., 2020). Specifically,
for any two consecutive keys ofa random process {Gi}i∈N, where D G, suppose their key intervali is a positive independent and identically distributed (i.i.d.) (xi − _xi−1) is drawn according to_
random variable whose mean is µ and variance is σ[2]. The MET algorithm learns linear segments
**S = [S1, ..., Si, ..., SN** ] in one pass, where Si : y = aix + bi is the learnable linear segment and N is
the total number of learned segments. The learning process is as follows: The current linear segment
fixes the slope ai = 1/µ and goes through the first available data point, thus bi is also determined.
Then the segment covers as many data points as possible until a data point, say (x[′], y[′]) achieves the
prediction error larger than ϵ. The violation of ϵ triggers a new linear segment, and the data point
(x[′], y[′]) will be the first available data point, and the process repeats until no data point is available.
Although the MET algorithm adopts a simple learning mechanism, it makes the theoretical analysis
convenient by modeling the learning process as a random walk process. Other ϵ-bounded learned
index methods such as FITing-Tree (Galakatos et al., 2019), PGM (Ferragina & Vinciguerra, 2020b)
and Radix-Spline (Kipf et al., 2020) learn linear segments in a similar manner while having different
mechanisms to determine the parameters of _Si_ . Ferragina et al. (2020) reveal the relationship
_{_ _}_


-----

between ϵ and index size performance based on MET. In Section 3.3, we present novel analysis
about the impact of ϵ on not only the index size, but also the index preciseness and a comprehensive
_trade-off quantity, which facilitates the proposed dynamic ϵ adjustment._

3 LEARN TO VARY ϵ

3.1 PROBLEM FORMULATION AND MOTIVATION

Before introducing the proposed framework, we first formulate the task of learning index from
data with ϵ guarantee, and provide some discussions about why we need to vary ϵ. Given a dataset
_D to be indexed and an ϵ-bounded learned index algorithm A, we aim to learn segments S =_

[S1, ..., Si..., SN ] as index structure such that the size of S and _i=1_ _[MAE][(][D][i][|][S][i][)][ are both small,]_
where Si is the i-th learned linear segment with the parameter ϵi, MAE is the mean absolute prediction
error, andthe algorithm Di ⊂D A repeatedly checks whether the prediction error of new data point violates the given is the data whose keys are covered by Si. For the remaining data[P][N] _D \_ _j<i_ _[D][j][,]_

_ϵi, and outputs the learned segment Si that covers_ _i. When all the ϵis for i_ [N ] take the same[S]
_D_ _∈_
value, the problem becomes the one that existing learned index methods are dealing with.

Now let’s examine the effect of parameter ϵ. To query a specific data point, say (x, y), we first need to
find the specific segment S[′] that covers x, and then search its true position y based on the estimated
one ˆy = S[′](x). For the first step, we can find S[′] from S in O(log(N )); for the second step, the
search of y based on ˆy can be done in O(log(|yˆ − _y|)). In summary, we can find the true position of_
the queried data point in O(log(N ) + log(|yˆ − _y|))_ [1]. From here, we can see that the parameter ϵ
plays an important role to trade off two contradictory performance terms, i.e., the size of the learned
index N, and MAE of the whole data MAE(D|S). If we adopt a small ϵ, the maximal prediction error
constraint is more frequently violated, leading to a large N ; meanwhile, the preciseness of learned
index is improved, leading to a small MAE(D|S). On the other hand, with a large ϵ, we will get a
more compact learned index (i.e., a small N ) with larger prediction errors (i.e., a large MAE(D|S)).
Thus these two inversely changed terms jointly impact the querying efficiency.

Actually, the effect of ϵ on index performance is intrinsically linked to the characteristic of the
data to be indexed. For real-world datasets, an important observation is that the linearity degree
_varies in different data localities. Recall that we use piece-wise linear segments to fit the data, and_
_ϵ determines the partition and the fitness of the segments. By varying ϵ, we can adapt to the local_
variations of D and adjust the partition such that each learned segment fits the data better. Formally,
let’s consider the quantity SegErri that is defined as the total prediction error within a segment Si,
_i.e., SegErri =_ (x,y)∈Di

_Len(_ _i) and the mean absolute error[|][y][ −]_ _[S][i][(][x] MAE[)][|][, which is also the product of the number of covered keys](_ _i_ _Si). Note that a large Len(_ _i) leads to a small N_
_D_ _D_ _|_ _D_
since |D| = _i=1[P][Len][(][D][i][)][. From this view, the quantity][ SegErr][i][ internally reflects the space-error]_
trade-off. Later we will show how to leverage this quantity to dynamically adjust ϵ.

[P][N]

3.2 OVERALL FRAMEWORK

In practice, it is intractable to directly solve the problem formulated in Section 3.1. With a given ϵi,
the one-pass algorithm A determines Si and Di until the error bound ϵi is violated. In other words,
it is unknown what the data partition _i_ will be a priori, which makes it impossible to solve the
_{D_ _}_
problem by searching among all the possible _ϵi_ s and learning index with a set of given _ϵi_ .
_{_ _}_ _{_ _}_

In this paper, we investigate how to efficiently find an approximate solution to this problem via the
introduced ϵ-learner module. Instead of heuristically adjusting ϵ, the ϵ-learner learns to predict
the impact of ϵ on the index structure and adaptively adjusts ϵ in a principled way. Meanwhile, the
introducing of ϵ-learner should not sacrifice the efficiency of the original one-pass learned index
algorithms, which is important for real-world practical applications.

These two design considerations establish our dynamic ϵ framework as shown in Figure 1. The
_ϵ-learner is based on an estimation function SegErr = f_ (ϵ, µ, σ) that depicts the mathematical
relationships among ϵ, SegErri and the characteristics µ, σ of the data to be indexed. As a start, users
can provide an expected ˜ϵ that indicates various preferences under space-sensitive or time-sensitive
applications. To meet the user requirements, afterwards, we will internally transform the ˜ϵ into another

1In Appendix C, we link the absolute prediction error and specific searching algorithms in further details.


-----

|&−Learner * ", +,,|Expected,-&./00|Expected )(|
|---|---|---|



**User**


**: %-learner Inference**

**: %-learner Learning**

**: Index Learning**


**15** (

**10** '["], ((["], *["]) &−Learner

**Position** **5** **lookahead** -  ", +,,

**choose "$**

**0**

**10** **20** **Key** **30** **update**

**15** [,!, 2!]

**: Learned Segments: Data Points** **Position** **105** "$ **reward**,-./00((, *) !

**: M&'|) −+)|** **0** "+

**10** **20** **30**

**Key**


Figure 1: Dynamic ϵ framework with the ϵ-learner module.

proxy quantity _SegErr[^]_, which reflects the expected prediction error for each segment if we set ϵi = ˜ϵ.
This transformation also links the adjustment of ϵ and data characteristics together, which enables the
data-dependent adjustment of ϵ. Beginning with ˜ϵ, the ϵ-learner chooses a suitable ϵi according to
current data characteristics, then learn a segment Si using A, and finally enhance the ϵ-learner with
the rewarded ground-truth SegErri of each segment. To make the introduced adjustment efficient,
we propose to only sample a small Look-ahead data D[′] to estimate the characteristics (i.e., µ and σ)
of the following data locality. The learning and adjusting processes are repeatedly conducted and
also in an efficient one-pass manner.

Note that the proposed framework provides users the same interface as the ones used by original
learned index methods. That is, we add no any additional cost to the users’ experience, and users
can smoothly and painlessly use our framework with given ˜ϵ just as they use the original methods
with given ϵ. The ϵ is an intuitive, easy-to-set and method-agnostic quantity for users. On the one
hand, we can easily impose restrictions on the worst-case querying cases with ϵ as the data accessing
number in querying process is O(log(|yˆ − _y|)). On the other hand, ϵ is easier to estimate than the_
other quantities such as index size and querying time, which are dependent on specific algorithms,
data layouts, implementations and experimental platforms. Our pluggable framework retains the
benefits of existing learned index methods, such as the aforementioned usability of ϵ and the ability
to handle dynamic update case (Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b).

We have seen how ϵ determines index performance and how SegErri embeds the space-error tradeoff in Section 3.1. In Section 3.3, we will further theoretically analyze the relationship among ϵ,
_SegErri, and data characteristics µ, σ at different localities. Based on the analysis, we elaborate the_
details of ϵ-learner and the internal transformation between ϵ and SegErri in Section 3.4.


3.3 PREDICTION ERROR ESTIMATION

In this section, we will theoretically study the impact of ϵ on the prediction error SegErri of each
learned segment Si. Specifically, for the MET algorithm, we can prove the following theorem to
bound the expectation of SegErri with ϵ and the key interval distribution of the data to be indexed.
**Theorem 1. Given a dataset D to be indexed and an ϵ where ϵ ∈** Z>1, consider the setting of the
_MET algorithm (Ferragina et al., 2020), in which key intervals of D are drawn from a random process_
_consisting of positive i.i.d. random variables with mean µ and variance σ[2], and ϵ ≫_ _σ/µ. For a_
_learned segment Si and its covered data_ _i, denote SegErri =_ (x,y) _Di_
_D_ _∈_

_expectation of SegErri satisfies:_ _[|][y][ −]_ _[S][i][(][x][)][|][. Then the]_

1 _µ_ 2 3 [P]

4 ( _[µ]_

_π_ _σ [ϵ][2][ <][ E][[][SegErr][i][]][ <][ 2]3_ _π_ [(5]3 [)] _σ_ [)][2][ϵ][3][.]

r r

This theorem reveals that the prediction error SegErri depends on both ϵ and the data characteristics
(µ and σ). Recall that CV = σ/µ is the coefficient of variation, a classical statistical measure of
the relative dispersion of data points. In the context of the linear approximation, the data statistic
1/CV = µ/σ in our bounds intrinsically corresponds to the linearity degree of the data. With this, we
can find that when µ/σ is large, the data is easy-to-fit with linear segments, and thus we can choose a
small ϵ to achieve precise predictions. On the other hand, when µ/σ is small, it becomes harder to
fit the data using a linear segment, and thus ϵ should be increased to absorb some non-linear data
localities. In this way, we can make the total prediction error SegErri for different learned segments
consistent and achieve a better space-error trade-off. This analysis also confirms the motivation of


-----

varying ϵ: The local linearity degrees of the indexed data can be diverse, and we should adjust ϵ
according to the local characteristic of the data, such that the learned index can fit and leverage the
data distribution better. In the design of the ϵ-learner module (Section 3.4), we will take the derived
closed-form relationships among SegErri, ϵ and data statistic µ/σ into account.

In the rest of this section, we provide a proof sketch of this theorem due to the space limitation. For
detailed proof, please refer to our Appendix. The main idea is to model the learning process of linear
approximation with ϵ guarantee as a random walk process, and consider that the absolute prediction
error of each data point follows folded normal distributions. Specifically, given a learned segment
_Si : y = aix + bi, we can calculate the expectation of SegErri for this segment as:_

(j[∗]−1) _∞_ _n−1_

E[SegErri] = aiE _Zj_ = ai E _Zj_ Pr(j[∗] = n), (1)

 _|_ _|_  _|_ _|_

_j=0_ _n=1_ _j=0_

X X X

whereZj _ϵ/a Zj is thei_ is the random variable indicating the maximal position when the random walk is within j-th position of a transformed random walk  _{Zj}j∈N, j[∗]_ = max{j ∈ N| − _ϵ/ai ≤_
the strip of boundary ≤ _}_ _ϵ/ai, and the last equality is due to the definition of expectation._
_±_

Under the MET algorithm setting where ai = 1/µ and ϵ ≫ _σ/µ, we can show that the increments of_
the transformed random walk _Zj_ have zero mean and variance σ[2], and many steps are necessary to
_{_ _}_
reach the random walk boundary. With the Central Limit Theorem, we can assume the Zj follows
normal distribution with mean µzj = 0 and variance σzj[2] [=][ jσ][2][, and thus][ |][Z][j][|][ follows the folded]
normal distribution with expectation E(|Zj|) = 2/πσ[√]j. Thus Eq. (1) can be written as

_n_ 1 _n_ 1 _n_ 1

1 _∞_ _−_ _∞_ _−_ p 2 _∞_ _−_

E _Zj_ Pr(j[∗] = n) < [1] E [ _Zj_ ] Pr(j[∗] = n) = _[σ]_ _j Pr(j[∗]_ = n).

_µ_  _|_ _|_ _µ_ _|_ _|_ _µ_ _π_

_n=1_ _j=0_ _n=1_ _j=0_ r _n=1_ _j=0_

X X X X X X p

  _µ[4]_

Using E[j[∗]] = _[µ][2]_

_σ[2][ ϵ][2][ and][ V ar][[][j][∗][] = 2]3_ _σ[4][ ϵ][4][ as derived in (Ferragina et al., 2020), we get][ E][[(][j][∗][)][2][] =]_

5 _µ[4]_ _j=0_ _√j < 23_ _[n][√][n][ and][ E][[][X]_ 34 ] (E[X]) 34, we get the upper bound:
3 _σ[4][ ϵ][4][. With the inequality][ P][n][−][1]_ _≤_

E[SegErri] < [2] 2 _σ_ 32 ] 2 _σ_ E[(j[∗])[2]] [3]4 = [2] 2 43 ( _[µ]_

3 _π_ _µ_ [E][[(][j][∗][)] _≤_ 3[2] _π_ _µ_ 3 _π_ [(5]3 [)] _σ_ [)][2][ϵ][3][.]

r r r

For the lower bound, applying the triangle inequality into Eq. (1), we can get   E[SegErri] >
1 _∞_
_µ_ _n=1_ [E][ [][|][Z][|][] Pr(][j][∗] [=][ n][)][, where][ Z][ =][ P]j[n]=0[−][1] _[Z][j][, and][ Z][ follows the normal distribution since]_
_Zj_ _N_ (0, σzj[2] [)][. We can prove that][ |][Z][|][ follows the folded normal distribution whose expectation]
P ∼
E[|Z|] > σ(n − 1)/[√]π. Thus the lower bound is:

1 _∞_ 1 1

E[SegErri] > [σ] (n 1) Pr(j[∗] = n) = _[σ]_

_µ_ r _π_ _n=1_ _−_ _µ_ r _π_ [E][ [][j][∗] _[−]_ [1] =] r _π_ [(] _σ [µ]_ _[ϵ][2][ −]_ _[σ]µ_ [)][.]

X


Since ϵ ≫ _[σ]µ_ [, we can omit the right term] 1/π · σ/µ and finish the proof. Although the derivations

are based on the MET algorithm whose slope is the reciprocal of µ, we found that the mathematical

p

forms among ϵ, µ/σ and SegErri are still applicable to other ϵ-bounded methods, and further prove
that the learned segment slopes of other methods are close to the reciprocal of expected key intervals
in Appendix. We will empirically show the links between MET and other SOTA ϵ-bounded methods,
and how effectively the proposed framework works for them on real-world datasets (Section 4.2).

3.4 _ϵ-LEARNER_


Now given an ϵ, we have obtained the closed-form bounds of the SegErr in Theorem 1, and both
the upper and lower bounds are in the form of w1( _σ[µ]_ [)][w][2] _[ϵ][w][3]_ [, where][ w][1][,][2][,][3][ are some coefficients. As]

the concrete values of these coefficients can be different for different datasets and different methods,
we propose to learn the following trainable estimator to make the error prediction preciser:

_SegErr = f_ (ϵ, µ, σ) =w1( _[µ]_

_σ_ [)][w][2] _[ϵ][w][3]_ _[,]_

(2)

1 2 3

_s.t._ 4, 1 _w2_ 2, 2 _w3_ 3.

r _π_ _[≤]_ _[w][1][ ≤]_ 3[2] r _π_ [(5]3 [)] _≤_ _≤_ _≤_ _≤_


-----

With this learnable estimator, we feed data characteristic µ/σ of the look-ahead data and the trans
formed _SegErr^_ into it and find a suitable ϵ[∗] as _SegErr/w^_ 1( _σ[µ]_ [)][w][2] 1/w3. We will discuss the

look-ahead data and the transformed _SegErr[^]_ in the following paragraphs. Now let’s discuss the rea- 
sons for how this adjustment can achieve better index performance. Actually, the ϵ-learner proactively
plans the allocations of the total prediction error indicated by user (i.e., ˜ϵ · |D|) and calculates the
tolerated _SegErr[^]_ for the next segment. By adjusting current ϵ to ϵ[∗], the following learned segment
can fully utilize the distribution information of the data and achieve better performance in terms of
space-error trade-off. To be specific, when µ/σ is large, the local data has clear linearity, and thus we
can adjust ϵ to a relatively small value to gain precise predictions; although the number of data points
covered by this segment may decrease and then the number of total segments increases, such cost
paid in terms of space is not larger than the benefit we gain in terms of precise predictions. Similarly,
when µ/σ is small, ϵ should be adjusted to a relatively large value to lower the learning difficulty and
absorb some non-linear data localities; in this case, we gain in terms of space while paying some
costs in terms of prediction accuracy. The segment-wise adjustment of ϵ improves the overall index
performance by continually and data-dependently balancing the cost of space and preciseness.

**Look-ahead Data.** To make the training and inference of the ϵ-learner light-weight, we propose to
look ahead a few data D[′] to reflect the characteristics of the following data localities. Specifically,
we leverage a small subset _j<i_
_D[′]_ _⊂D \_ _[D][j][ to estimate the value][ µ/σ][ for the following data.]_

In practice, we set the size of to be 404 when learning the first segment as initialization, and

(i−11) _ij−=11_ _[Len][(][D][j][)]_ _· ρ for the other following segments. Here D[′]_ [S] _ρ is a pre-defined parameter_
indicating the percentage that is relative to the average number of covered keys for learned segments,

  P 

considering that the distribution of µ/σ can be quite different to various datasets. As for the first
segment, according to the literature (Kelley, 2007), the sample size 404 can provide a 90% confidence
intervals for a coefficient of variance σ/µ ≤ 0.2.

_SegErr^_ **and Optimization.** As aforementioned, taking the user-expected ˜ϵ as input, we aim to
reflect the impact of ˜ϵ with a transformed proxy quantity _SegErr[^]_ such that the ϵ-learner can choose
suitable ϵ[∗] to meet users’ preference while achieving better space-error trade-off. Specifically, we
make the value of _SegErr^_ updatable, and update it to be _SegErr^_ = w1(ˆµ/σˆ)[w][2] _ϵ˜[w][3]_ once a new
segment is learned, where ˆµ/σˆ is the mean value of all the processed data so far. This strategy enables
us to promptly incorporate both the user preference and the data distribution into the calculation of
_SegErr^_ . As for the optimization of the f (ϵ, µ, σ), we adopt the projected gradient descent (Calamai
& More, 1987; den Hertog & Roos, 1991) with the parameter constraints in Eq. (2). In this way,´
we only need to track a few statistics and learn the ϵ estimator in an efficient one-pass manner. The
overall adjustment algorithm is summarized in Appendix D.

4 EXPERIMENTS

4.1 EXPERIMENTAL SETTINGS

**Baselines.** We apply our framework into several SOTA ϵ-bounded learned index methods that use
different mechanisms to determine the parameters of segments _Si_ . Among them, MET (Ferragina
_{_ _}_
et al., 2020) fixes the segment slope as the reciprocal of the expected key interval. FITing-Tree
(Galakatos et al., 2019) and Radix-Spline (Kipf et al., 2020) adopt a greedy shrinking cone algorithm
and a spline interpolating algorithm respectively. PGM (Ferragina & Vinciguerra, 2020b) adopts
a convex hull based algorithm to achieve the minimum number of learned segments. Further
introduction and implementation details can be found in Appendix.

**Datasets.** We use several widely adopted datasets with differing data scales and distributions
(Kraska et al., 2018; Galakatos et al., 2019; Ferragina & Vinciguerra, 2020b; Li et al., 2021). Weblogs
and IoT contain about 715M log entries from a university web server and 26M event entries from
different IoT sensors respectively, in which the keys are both log timestamps. Map dataset contains
location coordinates that are collected around the world from the OpenStreetMap contributors (2017),
and the keys are longitude + 90 · latitude of about 1.8M places. Lognormal is a synthetic dataset
whose key intervals follow the lognormal distribution. We generate 20M keys with 40 partitions


-----

having different generation parameters to simulate the varied data characteristics among different
localities. More dataset details and visualization are presented in Appendix F.

**Evaluation Metrics.** We evaluate the index performance in terms of its size, prediction preciseness,
and the total querying time. Specifically, we report the number of learned segments N, the index size
in bytes, the MAE as _|D1_ _|_ (x,y)∈D _[|][y][ −]_ **[S][(][x][)][|][, and the total querying time per query in ns (][i.e.][, we]**

perform querying operations for all the indexed data, record the total time of getting the payloads

P

given the keys, and report the time that is averaged over all the queries). For a quantitative comparison
w.r.t. the trade-off improvements, we calculate the area under the space-error curve (AUSEC) where
the x-axis and y-axis indicate N and MAE respectively. For AUSEC metric, the smaller, the better.

4.2 OVERALL INDEX PERFORMANCE

**Space-Error Trade-off Improvements.** In Table 1, we summarize the AUSEC improvements in
percentage brought by the proposed framework of all the baseline methods on all the datasets. We
also illustrate the space-error trade-off curves for some cases in Figure 2, where the blue curves
indicate the results achieved by fixed ϵ version while the red curves are for dynamic ϵ. Other baselines
and datasets yield similar curves, which we include in Appendix due to the space limitation. From
these results, we can see that the dynamic ϵ versions of all the baseline methods achieve much better
error-space trade-off (−16.48% to −23.57% averaged improvements as smaller AUSEC indicates
better performance), demonstrating the effectiveness and the wide applicability of the proposed
framework. As discussed in previous sections, datasets usually have diverse key distributions at
different data localities, and the proposed framework can data-dependently adjust ϵ to fully utilize
the distribution information of data localities and thus achieve better index performance in terms
of space-error trade-off. Note that the Map dataset has significant non-linearity caused by spatial
characteristics, and it is hard to fit using linear segments (all baseline methods learn linear segments),
thus relatively small improvements are achieved.

Table 1: The AUSEC relative improvements for learned index methods with dynamic ϵ.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|MET FITing-Tr Radix-Spli PGM|-25.87% -7.66% -10.89% -21.48% -16.48% ee -31.18% -25.56% -9.30% -28.24% -23.57% ne -28.37% -24.59% -8.77% -31.32% -23.26% -22.42% -25.01% -7.18% -19.58% -18.55%|
|---|---|



Figure 2: The space-error trade-off curves for learned index methods.

Weblogs Dataset IoT Dataset

2520 𝜖̃=2 FITing-Tree, Dynamic ε 1,6001,4001,200 FITing-Tree, Dynamic ε

Index Size (KB) 1050 𝜖̃=4 𝜖̃=8 𝜖̃𝜖=16=8 𝜖=16 𝜖̃=32 𝜖=32 Index Size (KB) 6004002000 𝜖̃=32 𝜖̃=64𝜖=64𝜖̃=128 𝜖̃𝜖=256=128 𝜖=256

Figure 3: Improvements in terms of querying time for learned index methods with dynamic ϵ.

Weblogs Dataset

30 𝜖=2

FITing-Tree, Original

25

FITing-Tree, Dynamic ε

20 𝜖̃=2

15 𝜖=4

10

Index Size (KB) 50 𝜖̃=4 𝜖̃=8 𝜖̃𝜖=16=8 𝜖=16 𝜖̃=32 𝜖=32

600 700 800 900 1000 1100

Querying Time (ns)

IoT Dataset

2,0001,800 𝜖=16 FITing-Tree, Original
1,600
1,400 FITing-Tree, Dynamic ε
1,200
1,000800 𝜖̃=16 𝜖=32

Index Size (KB) 600400 𝜖̃=32 𝜖=64 𝜖=128

2000 𝜖̃=64 𝜖̃=128 𝜖̃=256 𝜖=256

1100 1200 1300 1400 1500 1600 1700 1800

Querying Time (ns)


**Querying Time Improvements.** Recall that the querying time of each data point is in O(log(N ) +

log(|y − _yˆ|) as we mentioned in Section 3.1, where N and |y −_ _yˆ| are inversely impacted by ϵ. To_
examine whether the performance improvements w.r.t. space-error trade-off (i.e., Table 1) can lead
to better querying efficiency in real-world systems, we show the averaged total querying time per


-----

query and the actual learned index size in bytes for two scenarios in Figure 3. We can observe that
the dynamic ϵ versions indeed gain faster querying speed, since we improve both the term N as well
as the term |y − _yˆ| via adaptive adjustment of ϵ. The similar conclusion can be drawn from other_
baselines and datasets, and we present their results in Appendix. Another thing to note is that, this
experiment also verifies the usability of our framework in which users can flexibly set the expected ˜ϵ
to meet various space-time preferences just as they set ϵ in the original learned index methods.

**Index Building Cost.** Comparing with the original learned index methods that adopt a fixed ϵ, our
framework introduces extra computation to dynamically adjust ϵ in the index building stage. Does
this affect the efficiency of original learned index methods? Here we report the relative increments of
building times in Table 2. From it, we can observe that the proposed dynamic ϵ framework achieves
comparable building times to all the original learned index methods on all the datasets, showing the
efficiency of our framework since it has the same complexity as the original methods (both in O(|D|)).
Also note that we only need to pay this extra cost once, i.e., building the index once, and then the
index structures can accelerate the frequent data querying operations for real-world applications.

Table 2: Building time increments in percentage for learned index methods with dynamic ϵ.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|MET FITing-Tree Radix-Spline PGM|10.54% 5.14% 7.55% 5.26% 7.12% 10.7% 1.88% 6.04% 5.23% 5.96% 10.19% 1.64% 3.56% 8.96% 6.09% 16.76% 2.2% 1.07% 21.29% 10.33%|
|---|---|



4.3 ABLATION STUDY OF DYNAMIC ϵ

To gain further insights about how the proposed dynamic ϵ framework works, we compare the
proposed one with three dynamic ϵ variants: (1) Random ϵ is a vanilla version that randomly choose
_ϵ from [0, 2˜ϵ] when learning each new segment; (2) Polynomial Learner differs our framework with_
another polynomial function SegErr(ϵ) = θ1ϵ[θ][2] where θ1 and θ2 are trainable parameters; (3) Least
_Square Learner differs our framework with an optimal (but very costly) strategy to learn f_ (ϵ, µ, σ)
with the least square regression.

Table 3: The AUSEC relative changes of dynamic ϵ variants compared to the proposed framework.

|Col1|Weblogs IoT Map Lognormal Average|
|---|---|


|Random ϵ Polynomial Learner Least Square Learner|+70.94% +68.19% +51.73% +73.38% +66.06% +49.32% +40.57% +7.29% +42.77% +34.99% +4.44% +9.32% +2.20% 17.63% 0.42% − −|
|---|---|



We summarize the AUSEC changes in percentage compared to the proposed framework in Table 3.
Here we only report the results for FITing-Tree due to the space limitation and similar results can
be observed for other methods. Recall that for AUSEC, the smaller, the better. From this table, we
have the following observations: (1) The Random ϵ version achieves much worse results than the
proposed dynamic ϵ framework, showing the necessity and effectiveness of learning the impact of
_ϵ. (2) The Polynomial Learner achieves better results than the Random ϵ version while still have a_
large performance gap compared to our proposed framework. This indicates the usefulness of the
derived theoretical results that link the index performance, the ϵ and the data characteristics together.
(3) For the Least Square Learner, we can see that it achieves similar AUSEC results compared with
the proposed framework. However, it has higher computational complexity and pays the cost of much
larger building times, e.g., 14× and 50× longer building times on IoT and Map respectively. These
results demonstrate the effectiveness and efficiency of the proposed framework that adjusts ϵ based
on the theoretical results, which will be validated next.

4.4 THEORETICAL RESULTS VALIDATION

We study the impact of ϵ on SegErri for the MET algorithm in Theorem 1, where the derivations
are based on the setting of the slope condition ai = 1/µ. To confirm that the proposed framework
also works well with other ϵ-bounded learned index methods, we analyze the learned slopes of other
_ϵ-bounded methods in Appendix. In summary, we prove that for a segment Si : y = aix + bi whose_


-----

**2**

**1**

**0**

|×103 Ma a= 1/µ|ap Dataset|
|---|---|
|ai = 1/µi FITing-T RadixSpli PGM|ree ne|
|||


**_ai = 1/µi_**
**FITing-Tree**
**RadixSpline**
**PGM**


**0** **1** **2** **3** **4**

**1/µi** **_×10[3]_**

Figure 4: Learned slopes.




**Lognormal µ = 1 σ = 0.5** **Lognormal µ = 1 σ = 1**

**45** **40**
**40** **MET Upper BoundMET** **PGMRadixSpline** **35** **MET Upper BoundMET** **PGMRadixSpline**
**35** **MET Lower Bound** **FITing-Tree** **30** **MET Lower Bound** **FITing-Tree**
**30** **25**
**25**

**20**

**20**

**Log(SegErr)** **1510** **Log(SegErr)** **1510**

**5** **5**
**0** **0**

**100** **200** **300** **400** **100** **200** **300** **400**

**_ϵ_** **_ϵ_**


Figure 5: Illustration of the derived bounds.


covered data is Di and the expected key interval of Di is µi, then ai concentrates on 1/µi within
2ϵ/(E[Len(Di)] − 1) relative deviations. Here we plot the learned slopes of baseline learned index
methods in Figure 4. We can see that the learned slopes of other methods indeed center along the line
_ai = 1/µi, showing the close connections among these methods and confirming that the proposed_
framework can work well with other ϵ-bounded learned index methods.

We further compare the theoretical bounds with the actual SegErri for all the adopted learned
index methods. In Figure 5, we only show the results on Lognormal dataset due to space limitation.
As expected, we can see that the MET method has the actual SegErri within the derived bounds,
verifying the correctness of the Theorem 1. Besides, the other ϵ-bounded methods show the same
trends with the MET method, providing the evidence that these methods have the same mathematical
forms as we derived, and thus the ϵ-learner also works well with them.

4.5 CASE STUDY


We visualize the partial learned segments for FITing-Tree with
fixed and dynamic ϵ on IoT dataset in Figure 6, where the N and
_SegErri indicates the number of learned segments and the_
total prediction error for the shown segments respectively. The
P
_−µ/σ−→ indicates the characteristics of covered data_ _i_ . We can
_{D_ _}_
see that our dynamic framework helps the learned index gain
both smaller space (7 v.s. 4) and smaller total prediction errors
(48017 v.s. 29854). Note that ϵs within _→[−]ϵi are diverse due to the_
diverse linearity of different data localities: For the data whose
positions are within about [30000, 30600] and [34700, 35000],
the proposed framework chooses large ϵs as their µ/σs are small,
and by doing so, it achieves smaller N than the fixed version by
absorbing these non-linear localities; For the data at the middle Figure 6: Visualization of the
part, they have clear linearity with large µ/σs, and thus the learned index (partial) on IoT for
proposed framework adjusts ϵ as 19 and 10 that are smaller than FITing-Tree with fixed ϵ = 32 and
32 to achieve better precision. These experimental observations dynamic version ( ˜ϵ = 32).
are consistent with our analysis in the paragraph under Eq. (2),
and clearly confirm that the proposed framework adaptively adjusts ϵ based on data characteristics.

5 CONCLUSIONS


Existing learned index methods introduce an important hyper-parameter ϵ to provide a worst-case
preciseness guarantee and meet various space-time user preferences. In this paper, we provide formal
analyses about the relationships among ϵ, data local characteristics and the introduced quantity
_SegErri for each learned segment, which is the product of the number of covered keys and MAE,_
and thus embeds the space-error trade-off. Based on the derived mathematical relationships, we
present a pluggable dynamic ϵ framework that leverages an ϵ-learner to data-dependently adjust ϵ and
achieve better index performance in terms of space-error trade-off. A series of experiments verify the
effectiveness, efficiency and usability of the proposed framework.

We believe that our work contributes a deeper understanding of how the ϵ impacts the index performance, and enlightens the exploration of fine-grained trade-off adjustments by considering data local
characteristics. Our study also opens several interesting future works. For example, we can apply the
proposed framework to other problems in which the piece-wise approximation algorithms with fixed
_ϵ are used while still requiring space-error trade-off, such as similarity search and lossy compression_
for time series data (Chen et al., 2007; Xie et al., 2014; Buragohain et al., 2007; O’Rourke, 1981).


-----

REPRODUCIBILITY STATEMENT

For the Theorem 1 presented in Section 3.3, we give a complete proof in Appendix A. We introduce
more implementation details of our method and baselines in Appendix E. More detailed description
of the adopted datasets is included in Appendix F. To facilitate the reproducibitlity, we share
downloadable source codes and IPython notebooks, and attach binary files of the public experimental
datasets in the anonymous link [2].

REFERENCES

David J Abel. A B+-tree structure for large quadtrees. Computer Vision, Graphics, and Image
_Processing, 27(1):19–31, 1984._

[Timo Bingmann. Stx b+ tree. https://panthema.net/2007/stx-btree/, 2013.](https://panthema.net/2007/stx-btree/)

Chiranjeeb Buragohain, Nisheeth Shrivastava, and Subhash Suri. Space efficient streaming algorithms
for the maximum error histogram. In IEEE 23rd International Conference on Data Engineering,
pp. 1026–1035, 2007.

Paul H Calamai and Jorge J More. Projected gradient methods for linearly constrained problems.´
_Mathematical programming, 39(1):93–116, 1987._

Qiuxia Chen, Lei Chen, Xiang Lian, Yunhao Liu, and Jeffrey Xu Yu. Indexable pla for efficient
similarity search. In Proceedings of the 33rd international conference on Very large data bases, pp.
435–446, 2007.

Andrew Crotty. Hist-tree: Those who ignore it are doomed to learn. In 11th Conference on Innovative
_Data Systems Research, 2021._

Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth, Andrea ArpaciDusseau, and Remzi Arpaci-Dusseau. From wisckey to bourbon: A learned index for log-structured
merge trees. In 14th USENIX Symposium on Operating Systems Design and Implementation, pp.
155–171, 2020.

Dick den Hertog and Cees Roos. A survey of search directions in interior point methods for linear
programming. Mathematical Programming, 52(1):481–509, 1991.

Jialin Ding, Umar Farooq Minhas, Hantian Zhang, Yinan Li, Chi Wang, Badrish Chandramouli,
Johannes Gehrke, Donald Kossmann, and David B. Lomet. Alex: An updatable adaptive learned
index. In Proceedings of the ACM SIGMOD International Conference on Management of Data,
pp. 969–984, 2020.

Paolo Ferragina and Giorgio Vinciguerra. Learned data structures. In Recent Trends in Learning
_From Data, pp. 5–41. 2020a. doi: 10.1007/978-3-030-43883-8 2._

Paolo Ferragina and Giorgio Vinciguerra. The PGM-Index: A fully-dynamic compressed learned
index with provable worst-case bounds. Proceedings of the VLDB Endowment, 13(8):1162–1175,
2020b. ISSN 2150-8097.

Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective? In
_International Conference on Machine Learning, pp. 3123–3132, 2020._

Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska. FITingTree: A data-aware index structure. In Proceedings of the International Conference on Management
_of Data, pp. 1189–1206, 2019._

Goetz Graefe and Harumi Kuno. Modern b-tree techniques. In 27th International Conference on
_Data Engineering, pp. 1370–1373, 2011._

2https://github.com/AnonyMLResearcher/AnonyCodesData/blob/main/Supplemental%20MaterialsICLR22-Paper997.zip


-----

Ken Kelley. Sample size planning for the coefficient of variation from the accuracy in parameter
estimation approach. Behavior Research Methods, 39(4):755–766, 2007.

Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A. Boncz, and Alfons Kemper.
Learned cardinalities: Estimating correlated joins with deep learning. In 9th Biennial Conference
_on Innovative Data Systems Research, 2019._

Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska,
and Thomas Neumann. Radixspline: A single-pass learned index. In Proceedings of the Third
_International Workshop on Exploiting Artificial Intelligence Techniques for Data Management,_
2020.

Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index
structures. In Proceedings of the International Conference on Management of Data, pp. 489–504,
2018.

Xin Li, Jingdong Li, and Xiaoling Wang. Aslm: Adaptive single layer model for learned index. In
_International Conference on Database Systems for Advanced Applications, pp. 80–95. Springer,_
2019.

Yaliang Li, Daoyuan Chen, Bolin Ding, Kai Zeng, and Jingren Zhou. A pluggable learned index
method via sampling and gap insertion. arXiv preprint arXiv:2101.00808, 2021.

Chen Luo and Michael J Carey. Lsm-based storage techniques: a survey. The VLDB Journal, 29(1):
393–418, 2020.

Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons Kemper,
Thomas Neumann, and Tim Kraska. Benchmarking learned indexes. Proceedings of the VLDB
_Endowment, 14(1):1–13, 2020._

Michael Mitzenmacher. A model for learned bloom filters, and optimizing by sandwiching. In
_Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp._
462–471, 2018.

OpenStreetMap contributors. Planet dump retrieved from https://planet.osm.org . https://www.
openstreetmap.org, 2017.

Joseph O’Rourke. An on-line algorithm for fitting straight lines between data ranges. Communications
_of the ACM, 24(9):574–578, 1981._

Jun Rao and Kenneth A. Ross. Cache conscious indexing for decision-support in main memory. In
_Proceedings of the 25th International Conference on Very Large Data Bases, pp. 78–89, 1999._

Chuzhe Tang, Youyun Wang, Zhiyuan Dong, Gansen Hu, Zhaoguo Wang, Minjie Wang, and Haibo
Chen. Xindex: a scalable learned index for multicore data storage. In Proceedings of the 25th
_ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 308–320,_
2020.

Kapil Vaidya, Eric Knorr, Michael Mitzenmacher, and Tim Kraska. Partitioned learned bloom filters.
In International Conference on Learning Representations, 2021.

Jingdong Wang, Ting Zhang, jingkuan song, Nicu Sebe, and Heng Tao Shen. A survey on learning to
hash. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4):769–790, 2018.

Qing Xie, Chaoyi Pang, Xiaofang Zhou, Xiangliang Zhang, and Ke Deng. Maximum error-bounded
piecewise linear representation for online stream approximation. The VLDB journal, 23(6):
915–937, 2014.

Xuanhe Zhou, Chengliang Chai, Guoliang Li, and Ji Sun. Database meets artificial intelligence: A
survey. IEEE Transactions on Knowledge and Data Engineering, 2020.


-----

APPENDICES FOR THE SUBMISSION: LEARNED INDEX WITH DYNAMIC ϵ

A PROOF OF THEOREM 1

Given a learned segment Si : y = aix + bi, denote ci as the stored position of the last covered data
for the (i − 1)-th segment (c1 = 0 for the first segment). We can write the expectation of SegErri
for the segment Si as the following form:

(j[∗]−1)

E[SegErri] = E _aiXj + bi_ (j + ci + 1) _,_

 _j=0_ _|_ _−_ _|_

X

 

where j[∗] indicates the length of the segment, and Xj indicates the j-th key covered by the segment
_Si. As studied in Ferragina et al. (2020), the linear-approximation problem with ϵ guarantee can_
be modeled as random walk processes. Specifically, Xj = X0 + _k=0_ _[G][k][ (for][ j][ ∈]_ [Z][>][0][) where]
_Gk is the key increment variable whose mean and variance is µ and σ[2]_ respectively. Denote the
when the random walk is within the strip of boundaryZandj = j[∗] X=j − maxj/a{ji ∈ + (Nb| −i −ϵ/aci −i ≤1)Z/aj ≤i as theϵ/ai j} as the random variable indicating the maximal position-th position of the transformed random walkϵ/ai. The expectation can be rewritten as[P][j] _{Zj}j∈N,_
_±_


(j[∗]−1)

_aiXj_ _j + (bi_ _ci_ 1) =aiE
_j=0_ _|_ _−_ _−_ _−_ _|_

X



=ai


(j[∗]−1)

_Zj_

 _|_ _|_

_j=0_

X




(3)


_∞_ _n−1_

=ai E _Zj_ Pr(j[∗] = n).

 _|_ _|_

_n=1_ _j=0_

X X

 

The last equality in Eq. (3) is due to the definition of expectation. Following the MET algorithm that
the Si goes through the point (X0, Y0 = ci + 1), we get bi = −aiX0 + ci + 1 and we can rewrite
_Zj as the following form:_


_j>0_
_Z0 = 0,_ _Zj_ = Xj − _X0 −_ _j/ai =_


_k=1_ _Gk −_ _j/ai =_

X


(Gk 1/ai) = (Wk),
_k=1_ _−_ _k=1_

X X


where Wk is the walk increment variable of Zj, E[Wk] = µ − 1/ai and V ar[Wk] = σ[2]. Under
the MET algorithm setting where ai = 1/µ and ε ≫ _σ/µ, the transformed random walk {Zj} has_
increments with zero mean and variance σ[2], and many steps are necessary to reach the random walk
boundary. With the Central Limit Theorem, we can assume that Zj follows the normal distribution
with mean µzj and variance σzj[2] [, and thus][ |][Z][j][|][ follows the folded normal distribution:]

_Zj_ (µ 1/ai)j, jσ[2][],
_∼N_ _−_

E(|Zj|) = µzj[1 − 2Φ( − _µzj /σzj)] + σzj_ 2/π exp(−µ[2]zj[/][2][σ]zj[2] [)][,]

where Φ is the normal cumulative distribution function. For the MET algorithm,p _ai = 1/µ and thus_
the µzj = 0, σzj = σ[√]j, and E(|Zj|) = 2/πσ[√]j. Then the Eq. (3) can be written as
p


_n−1_

_Zj_ Pr(j[∗] = n) < [1]
_|_ _|_ _µ_
_j=0_

X



= _[σ]_


_n−1_

E [|Zj|] Pr(j[∗] = n)
_j=0_

X


_n=1_


_n=1_


(4)


_∞_ _n−1_

_n=1_ _j=0_

X X


_j Pr(j[∗]_ = n).


For the inner sum term in Eq. (4), we have ([P][n]j=0[−][1] _√j) < 23_ _[n][√][n][ since]_

_n−1_ _j <_ _n−1_ _j +_ _√n_ _<_ _n_ _√x dx = 2_

_j=0_ _j=0_ 2 Z0 3 _[n][√][n,]_

X p X p


-----

then the result in Eq. (4) becomes


_∞_

_n[√]n Pr(j[∗]_ = n)

_n=1_

X


E[SegErri] < [2]

3

= [2]



[3]

= [2] 2 _σ_ 32 ] = [2] 2 _σ_ (j[∗])[2][][ 3]4 2 _σ_ E[(j[∗])[2]] 4,

3 _π_ _µ_ [E][[(][j][∗][)] 3 _π_ _µ_ [E] _≤_ 3[2] _π_ _µ_

r r r

h   

3 [i] 3
where the last inequality holds due to the Jensen inequality E[X 4 ] (E[X]) 4 . Using E[j[∗]] = _[µ][2]_
_≤_ _σ[2][ ϵ][2]_

_µ[4]_ _µ[4]_

and V ar[j[∗]] = [2]

3 _σ[4][ ϵ][4][ derived in MET algorithm Ferragina et al. (2020), we get][ E][[(][j][∗][)][2][] = 5]3_ _σ[4][ ϵ][4][,]_

which yields the following upper bound:


E[SegErri] < [2]


2 3

4 ( _[µ]_

_π_ [(5]3 [)] _σ_ [)][2][ϵ][3][.]


For the lower bound, applying the triangle inequality into the Eq. (3), we have


_n−1_

_Zj_ Pr(j[∗] = n) > [1]
_|_ _|_ _µ_
_j=0_

X



= [1]


_∞_ _n−1_

E _Zj_ Pr(j[∗] = n)

| _|_

_n=1_ _j=0_

X X

_∞_  

E [|Z|] Pr(j[∗] = n),
_n=1_

X


_n=1_


(5)


where Z = _j=0_ _[Z][j][. Since][ Z][j][ ∼]_ _[N]_ [(0][, σ]zj[2] [)][, the][ Z][ follows the normal distribution:]

_n−1_ _n−1_ _n−1_

[P][n][−][1]

_Z ∼_ N _µZ = 0, σZ[2]_ [=] _σzj[2]_ [+] _rjkσzjσzk_ _,_

_j=0_ _j=0_ _k=0,k=j_

 X X X̸ 

where rjk is the correlation between Zj and Zk. Since µZ = 0, the |Z| follows the folded normal
distribution with E[|Z|] = σZ 2/π. Since the random walk {Zj} is a process with i.i.d. increments,

the correlation rjk 0. With σzj = σ[√]j > 0 and rjk 0, we have
_≥_ p _≥_

2 _n−1_

E[|Z|] > _π_ _σzj > σ_ _n(n −_ 1)/π > [σ][(][n]√[ −]π [1)] _,_

r _j=0_

X p

and the result in Eq. (5) becomes:


_n−1_

E _Zj_ Pr(j[∗] = n)

| _|_

_j=0_

X

_∞_ 

(n − 1) Pr(j[∗] = n)
_n=1_

X


E[SegErri] > [1]

_µ_

_> [σ]_

_µ_

= _[σ]_

_µ_

Since ϵ ≫ _[σ]µ_ [, we can omit the right term]


_n=1_


1

_π_ [(] _σ [µ]_ _[ϵ][2][ −]_ _[σ]µ_ [)][.]


1

_π_ [E][ [][j][∗] _[−]_ [1] =]


_σ_
_µ_ [and finish the proof.]


B LEARNED SLOPES OF OTHER ϵ-BOUNDED METHODS

As shown in Theorem 1, we have known how ϵ impacts the SegErri of each segment learned by
the MET algorithm, where the theoretical derivations largely rely on the slope condition ai = 1/µ.
Here we prove that for other ϵ-bounded methods, the learned slope of each segment (i.e., ai of Si)
concentrates on the reciprocal of the expected key interval as shown in the following Theorem.


-----

**Theorem 2. Given an ϵ ∈** Z>1 and an ϵ-bounded learned index algorithm A. For a linear segment
_Si : y = aix + bi learned by A, denote its covered data and the number of covered keys as Di_
_and Len(Di) respectively. Assuming the expected key interval of Di is µi, the learned slope ai_
_concentrates on ˜a = 1/µi with bounded relative difference:_

2ϵ 2ϵ
(1 _a_ _E[ai]_ (1 + _a._
_−_ E[Len(Di)] − 1 [)˜] _≤_ _≤_ E[Len(Di)] − 1 [)˜]


_Proof. For the learned linear segment Si, denote its first predicted position and last predicted position_
as y0[′] [and][ y]n[′] [respectively, we have its slope][ a][i] [=][ y]xnn[′] _[−]−[y]x0[′]0_ [. Notice that][ y][0][ −] _[ϵ][ ≤]_ _[y]0[′]_ _[≤]_ _[y][0]_ [+][ ϵ][ and]

_yn_ _ϵ_ _yn[′]_ [+][ ϵ][ due to the][ ϵ][ guarantee, we have][ y][n] _n_ 0 [+ 2][ϵ][ and]
the expectation of − _≤_ _[≤]_ _[y][n] ai can be written as_ _[−]_ _[y][0]_ _[−]_ [2][ϵ][ ≤] _[y][′]_ _[−]_ _[y][′]_ _[≤]_ _[y][n]_ _[−]_ _[y][0]_

E[ _[y][n][ −]_ _[y][0][ + 2][ϵ]_ ] _E[ai] =_ _[y]n[′]_ _[−]_ _[y]0[′]_ E[ _[y][n][ −]_ _[y][0][ + 2][ϵ]_ ].

_xn_ _x0_ _≤_ _xn_ _x0_ _≤_ _xn_ _x0_
_−_ _−_ _−_

Note that for any learned segment Si whose first covered data is (x0, y0) and last covered data is
(xn, yn), we have E[ _[x]y[n]n[−][x]y0[0]_ [] =][ µ][i][ and thus the inequalities become]

_−_

1 2ϵ 1 2ϵ

] _E[ai]_ ].

_µ_ _xn_ _x0_ _≤_ _≤_ _µ_ [+][ E][[] _xn_ _x0_

_[−]_ [E][[] _−_ _−_

Since ˜a = 1/µi and E[xn − _x0] = (E[Len(Di)] −_ 1)µi, we finish the proof.


The Theorem 2 shows that the relative deviations between learned slope ai and ˜a are within
2ϵ/(E[Len(Di)] − 1). For the MET and PGM learned index methods, we have the following
corollary that depicts preciser deviations without the expectation term E[Len(Di)].

**Corollary 2.1. For the MET method Ferragina et al. (2020) and the optimal ϵ-bounded linear**
_approximation method that learns the largest segment length used in PGM Ferragina & Vinciguerra_
_(2020b), the slope relative differences are at O(1/ϵ)._

_Proof. We note that the segment length of a learned segment is at O(ϵ[2]) for the MET algorithm,_
which is proved in the Theorem 1 of Ferragina et al. (2020). Since PGM achieves the largest learned
segment length that is larger than the one of the MET algorithm, we finish the proof.

C CONNECTING PREDICTION ERROR WITH SEARCHING STRATEGY

As we mentioned in Section 3.1, we can find the true position of the queried data point in O(log(N )+
log(|yˆ − _y|)) where N is the number of learned segments and |yˆ −_ _y| is the absolute prediction error._
A binary search or exponential search can be used to finds the stored true position y based on ˆy. It is
worth noting out that the searching cost in terms of searching range |yˆ − _y| of binary search strategy_
corresponds to the maximum absolute prediction error ϵ, whereas the one of exponential search
corresponds to the mean absolute prediction error (MAE). In this paper, we decouple the quantity
_SegErri as the product of Len(Di) and MAE(Di|Si) in the derivation of Theorem 1. Built upon_
the theoretical analysis, we adopt exponential search in experiments to better leverage the predictive
models.

To clarify, let’s consider a learned segment Si with its covered data Di. Denote the absolute prediction
error of k-th data point covered by this segment as ˆyk _yk_, the maximum absolute prediction error
as ϵi where | ˆyk − _yk| ≤_ _ϵi for all k ∈_ [len(Di)]. _|_ _−_ _|_

-  The binary search is conducted within the searching range [ ˆyk _ϵi] for each data point_ [3],
thus the mean search range is _k=1_ _len(1Di)_ [2][ϵ][i][ =][ O][(][ϵ][i][)][, which is independent of the] ±

preciseness of the learned segment and an upper bound of MAE( _i_ _Si)._
_D_ _|_

3The lower bound and upper bounds of searching ranges should be constricted to[P][len][(][D][i][)] 0 and len(Di) respectively.
For brevity, we omit the corner cases when comparing these two searching strategies as they both need to handle
the out-of-bounds scenario.


-----

-  The exponential search first finds the searching range where the queried data may present by
centering around the ˆy, repeatedly doubling the range [yˆ ± 2[q]] where the integer q grows
from 0, and comparing the queried data with the data points at positions ˆy _±_ 2[q]. After finding
the specific range such that adata, an binary search is conducted to find the exact location. In this way, the mean search qk satisfies 2[log(][q][k][)][−][1] _≤| ˆyk −_ _yk| ≤_ 2[⌈][log(][q][k][)][⌉] for the k-th
range is _k=1_ _len(1_ _i)_ [(2][⌈][log(][q][k][)][⌉][+1][) =][ O] _MAE(_ _i_ _Si)_, which can be much smaller

_D_ _D_ _|_
than O(ϵi) especially for strong predictive models and the datasets having clear linearity.

[P][len][(][D][i][)]   

D THE ALGORITHM OF DYNAMIC ϵ ADJUSTMENT

**_Algorithm Dynamic ϵ Adjustment with Pluggable ϵ Learner_**

**_Input: D: Data to be indexed, A: Learned index algorithm, ˜ϵ: Expected ϵ, ρ: Length percentage_**
_for look-ahead data_

**_Output: S: Learned segments with varied ϵs_**

_1: initial parameters w1,2,3 of the learned function: f_ (ϵ, µ, σ) = w1( _σ[µ]_ [)][w][2] _ϵ[˜][w][3]_

_2: initial mean length of learned segments so far: Len(DS) ←_ 404
_3: S ←_ ∅, (ˆµ/σˆ) ← 0

_4: repeat_

_6:5:_ _ϵ(µ/σ[∗]_ _←) ←SegErr/w^lookahead1((σ[µ]D[)][w], Len[2]_ 1/w(D3 **_S) · ρ)_** _/* adjust ϵ based on the learner *//* get data statistic */_

_7:_ [Si, Di] ←A(D, ϵ[∗])  _/* learn new segment Si using adjusted ϵ[∗]_ _*/_

_8:_ **_S_** **_S_** _i_
_←_ _∪S_

_9:_ _D ←D \ Di, DS ←DS ∪Di_

_10:_ _Len(DS) ←_ _running-mean_ _Len(DS), Len(Di)_ _/* online update Len(DS) */_

_11:_ (ˆµ/σˆ) _running-mean_ (ˆµ/σˆ), (µ/σ)
_←_   

_12:_ _w1,2,3_ _optimize(f, Si, SegErri)_ _/* train the learner with ground-truth */_
_←_   

_13:_ _SegErr^_ _w1(ˆµ/σˆ)[w][2]_ _ϵ˜[w][3]_
_←_

_14: until D = ∅_

In Section 3.4, we provide detailed description about the initialization and adjustment sub-procedures.
The lookahead() and optimize() are in the Look-ahead Data and _SegErr^_ **and Optimization**
paragraph respectively.

E IMPLEMENTATION DETAILS

All the experiments are conducted on a Linux server with an Intel Xeon Platinum 8163 2.50GHz
CPU. We first introduce more details and the implementation of baseline learned index methods.
_MET (Ferragina et al., 2020) fixes the segment slope as the reciprocal of the expected key interval,_
and goes through the first available data point for each segment. FITing-Tree (Galakatos et al., 2019)
adopts a greedy shrinking cone algorithm and the learned segments are organized with a B[+]-tree.
Here we use the stx::btree (v0.9) implementation (Bingmann, 2013) and set the filling factors of
inner nodes and leaf nodes as 100%, i.e., we adopt the full-paged filling manner. Radix-Spline (Kipf
et al., 2020) adopts a greedy spline interpolating algorithm to learn spline points, and the learned
spline segments are organized with a flat radix table. We set the number of radix bits as r = 16 for
the Radix-Spline method, which means that the leveraged radix table contains 2[16] entries. PGM
(Ferragina & Vinciguerra, 2020b) adopts a convex hull based algorithm to achieve the minimum
number of learned segments, and the segments can be organized with the help of binary search,
CSS-Tree (Rao & Ross, 1999) and recursive structure. Here we implement the recursive version
since it beats the other two variants in terms of indexing performance.

We then describe a few additional details of the proposed framework in terms of the ϵ-learner
initialization and the hyper-parameter setting. For the w1,2,3 of the ϵ-learner shown in the Eq. (2), at
the beginning, we learn the first five segments with the ϵ sequence [ [1]4 _ϵ,[˜]_ 2[1] _ϵ,[˜]_ ˜ϵ, 2˜ϵ, 4˜ϵ], then track their

rewarded SegErri and update the parameters w1,2,3 using least square regression. We empirically


-----

found that this light-weight initialization leads to better index performance compared to the versions
with random parameter initialization, and it benefits the exploration of diverse ϵ[∗], i.e., leading to
the larger variance of the dynamic ϵ sequence [ϵ1, . . ., ϵi, . . ., ϵN ]. As for the hyper-parameter ρ
(described in the Section 3.4), we conduct grid search over ρ ∈ [0.1, 0.4, 0.7, 1.0] on Map an IoT
datasets. We found that all the ρs achieve better space-error trade-off (i.e., smaller AUSEC results)
than the fixed ϵ versions. Since the setting ρ = 0.4 achieves averagely best results on the two datasets,
we set ρ to be 0.4 for the other datasets.

F DATASET DETAILS


Our framework is verified on several widely adopted datasets having different data scales and
distributions. Weblogs Kraska et al. (2018); Galakatos et al. (2019); Ferragina & Vinciguerra (2020b)
contains about 715M log entries for the requests to a university web server and the keys are log
timestamps. IoT Galakatos et al. (2019); Ferragina & Vinciguerra (2020b) contains about 26M event
entries from different IoT sensors in a building and the keys are recording timestamps. Map dataset
Kraska et al. (2018); Galakatos et al. (2019); Ding et al. (2020); Ferragina & Vinciguerra (2020b); Li
et al. (2021) contains location coordinates of 1.8M places that are collected around the world from
the Open Street Map OpenStreetMap contributors (2017), and the keys are compound by coordinates
as longitude + 90 · latitude. Lognormal Ferragina & Vinciguerra (2020b) is a synthetic dataset
whose key intervals follow the lognormal distribution: ln(Gi) ∼N (µlg, σlg[2] [)][. To simulate the varied]
data characteristics among different localities. We generate 20M keys with 40 partitions by setting
_µlg = 1 and setting σlg with a random number within [0.1, 1] for each partition._

We normalize the positions of stored data into the range [0, 1], and thus the key-position distribution
can be modeled as Cumulative Distribution Function (CDF). We plot the CDFs and zoomed-in CDFs
of experimental datasets in Figure 7 and Figure 8 respectively, which intuitively illustrate the diversity
of the adopted datasets.


**Key** **_×10[9]_**

**Weblogs** **IoT** **Map** **Lognormal**

**1.0** **1.0** **1.0** **1.0**

**0.8** **0.8** **0.8** **0.8**

**CDF** **00..64** **CDF** **00..64** **CDF** **00..64** **CDF** **00..64**

**0.2** **0.2** **0.2** **0.2**

**0.0** **0.0** **0.0** **0.0**

**1.450 1.455 1.460 1.465 1.470 1.475 1.480** **1.485 1.490 1.495 1.500 1.505 1.510 1.515** **2000** **3000** **4000** **5000** **0** **1** **2** **3** **4** **5** **6**

**Key** **10[9]** **Key** **10[9]** **Key** **Key** **10[7]**


**Key** **_×10[9]_**


**Key** **_×10[9]_**


**Key**


**Key** **_×10[7]_**

**Key** **_×10[7]_**


Figure 7: CDFs of adopted datasets.


|Col1|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
||||||


**Zoomed-in Map** **Zoomed-in Lognormal**

**0.660** **0.660**

**0.655** **0.655**

**0.650** **CDF** **0.650**

**0.645** **0.645**

**0.640** **0.640**

**3250** **3260** **3270** **3280** **3290** **3300** **3.95** **4.00** **4.05** **4.10**

**Key** **Key** **10[7]**

Figure 8: Zoomed-in CDFs of adopted datasets.


**Zoomed-in Weblogs**

**0.660**

**0.655**

**0.650**

**0.645**

**0.640**

**1.4718** **1.4720** **1.4722** **1.4724**

**Key** **10[9]**


G ADDITIONAL EXPERIMENTAL RESULTS

**Overall Index Performance.** For the space-error trade-off improvements and the actual querying
efficiency improvements brought by the proposed framework, we illustrate more space-error tradeoff curves in Figure 9 and querying time results in Figure 10. Recall that the N -MAE trade-off
curve adequately reflects the index size and querying time: (1) the segment size in bytes and N are
only different by a constant factor, e.g., the size of a segment can be 128bit if it consists of two


-----

double-precision float parameters (slope and intercept); (2) the querying operation can be done in
_O(log(N_ ) + log(|y − _yˆ|) as we mentioned in Section 3.1, thus a better N_ -MAE trade-off indicates
a better querying efficiency. From these figures, we can see that the dynamic ϵ versions of all the
baseline methods achieve better space-error trade-off and better querying efficiency, verifying the
effectiveness and the wide applicability of the proposed framework.

Figure 9: The additional space-error trade-off curves for learned index methods.

**Ablation Study.** To examine the necessity and the effectiveness of the proposed framework, in
Section 4.3, we compare the proposed framework with three dynamic ϵ variants for the FITing-Tree
method. Here we demonstrate the AUSEC relative changes for the Radix-Spline method with the
same three variants in Table 4 and similar conclusions can be drawn.

Table 4: The AUSEC relative changes of dynamic ϵ variants compared to the Radix-Spline method
with the proposed framework.

|Col1|Weblogs IoT Map Lognormal|
|---|---|


|Random ϵ omial Learner Square Learner|+81.23% +74.78% +59.20% +83.16% +56.20% +53.28% +7.01% +55.01% -9.56% +9.81% +0.58% 11.23% −|
|---|---|



**Theoretical Validation.** In Section 4.4, we show that all the learned index baseline methods learn
similar segment slopes on the Map dataset. Here we illustrate the learned slope results on the IoT,
Weblogs and Lognormal datasets in Figure 11, which supports the Theorem 2 that the learned segment
slopes concentrate on the 1/µi with a bounded relative difference.


-----

Besides, for the comparison between the theoretical bounds and the actual SegErri of all the adopted
learned index methods, we show more results on another two datasets Gamma and Uniform in Figure
12, where the key intervals of the two datasets follow gamma distribution and uniform distribution
respectively. These results show that the MET method gains actual SegErri within the bounds,
verifying the correctness of the Theorem 1 again. Here all the learned index methods also achieve the
same trends, showing that these methods have the same mathematical forms w.r.t. the SegErri, ϵ
and µ/σ, and hence the ϵ-learner can effectively learn the estimator and adaptively choose suitable ϵ.

Weblogs Dataset 2,100 IoT Dataset

Index Size (KB) 544 𝜖̃=8 𝜖̃=16𝜖=8𝜖̃=32 𝜖=16𝜖=32 Index Size (KB) 700500300100 𝜖̃=32 𝜖̃=64 𝜖=64𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

Index Size (KB) 1801308030 𝜖̃=32 𝜖̃=64 𝜖̃=128𝜖=64𝜖=128𝜖̃=256 𝜖=256 Index Size (KB) 4003002001000 𝜖̃=32 𝜖=32𝜖̃=64 𝜖=64𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

1200 1250 1300 1350 1400 1250 1350 1450 1550 1650 1750

Weblogs Dataset IoT Dataset

1,001996 𝜖̃=2 𝜖=4 Radix-Spline, Dynamic ε 1,7001,500 𝜖̃=16 𝜖=32 Radix-Spline, Dynamic ε

500 600 700 800 900 1000 1100 700 900 1100 1300 1500 1700

Weblogs Dataset IoT Dataset

20 𝜖̃=64𝜖̃=128𝜖=64𝜖𝜖̃=128=256 𝜖=256 14040 𝜖̃=64 𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

Index Size (KB) 503010950 𝜖̃=32𝜖̃=128𝜖̃=641000 𝜖𝜖=128=641050 𝜖̃=256 1100𝜖=256 1150 Index Size (KB) 1015111000 𝜖̃=321100 𝜖̃=64𝜖=321200𝜖̃𝜖=128=641300 𝜖=1281400 𝜖̃=2561500𝜖=2561600

Querying Time (ns) Querying Time (ns)

Weblogs Dataset

204 𝜖̃=2 𝜖=2

154

104 𝜖̃=4 𝜖=4 MET, OriginalMET, Dynamic ε

Index Size (KB) 54 𝜖̃=8 𝜖=8 𝜖=16

4 𝜖̃=16 𝜖̃=32 𝜖=32

1000 1100 1200 1300 1400 1500 1600

Querying Time (ns)

Map Dataset

380 𝜖=16

330 𝜖̃=16

280 MET, Original

230 𝜖=32 MET, Dynamic ε

Index Size (KB) 180130 𝜖̃=32 𝜖=64

8030 𝜖̃=64 𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

1200 1250 1300 1350 1400

Querying Time (ns)

Weblogs Dataset

1,006 𝜖=2 Radix-Spline, Original

Radix-Spline, Dynamic ε

1,001 𝜖̃=2

996 𝜖=4

Index Size (KB) 991 𝜖̃=4 𝜖=8 𝜖=16 𝜖=32

986 𝜖̃=8 𝜖̃=16 𝜖̃=32

500 600 700 800 900 1000 1100

Querying Time (ns)

Weblogs Dataset

10 𝜖=16

𝜖̃=16

8 PGM, Original

6 PGM, Dynamic ε

𝜖=32

Index Size (KB) 4 𝜖̃=32

20 𝜖̃=64𝜖̃=128𝜖=64𝜖𝜖̃=128=256 𝜖=256

650 750 850 950 1050

Querying Time (ns)

Map Dataset

110 𝜖̃=16 𝜖=16

90 PGM, Original

70 𝜖=32 PGM, Dynamic ε

50 𝜖̃=32

Index Size (KB) 𝜖=64

30 𝜖̃=64

10 𝜖̃=128 𝜖=128 𝜖̃=256 𝜖=256

950 1000 1050 1100 1150

Querying Time (ns)

IoT Dataset

2,100
1,900 𝜖=16
1,700 𝜖̃=16 MET, Original
1,500 MET, Dynamic ε
1,300
1,100 𝜖=32

900

Index Size (KB) 700500 𝜖̃=32 𝜖=64 𝜖=128

300100 𝜖̃=64 𝜖̃=128 𝜖̃=256 𝜖=256

1400 1500 1600 1700 1800 1900

Querying Time (ns)

1,000900 𝜖=16 Lognormal Dataset

800 𝜖̃=16
700 MET, Original
600 MET, Dynamic ε
500
400300 𝜖=32

Index Size (KB) 2001000 𝜖̃=32 𝜖̃=64 𝜖=64𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

1250 1350 1450 1550 1650 1750

Querying Time (ns)

IoT Dataset

2,100

1,900 𝜖=16 Radix-Spline, Original

Radix-Spline, Dynamic ε

1,700

1,500 𝜖̃=16 𝜖=32

Index Size (KB) 1,3001,100 𝜖̃=32 𝜖=64 𝜖=128 𝜖=256

900 𝜖̃=64 𝜖̃=128 𝜖̃=256

700 900 1100 1300 1500 1700

Querying Time (ns)

Lognormal Dataset

𝜖=16

1,540 Radix-Spline, Original

1,440 𝜖̃=16 Radix-Spline, Dynamic ε

1,340

1,240

Index Size (KB) 1,140 𝜖=32

1,040 𝜖̃=32 𝜖=64 𝜖=128 𝜖=256

940 𝜖̃=64 𝜖̃=128 𝜖̃=256

700 800 900 1000 1100 1200 1300 1400 1500 1600

Querying Time (ns)

IoT Dataset

640 𝜖̃=16 𝜖=16

540

PGM, Original

440

340 𝜖=32 PGM, Dynamic ε

Index Size (KB) 240 𝜖̃=32 𝜖=64

14040 𝜖̃=64 𝜖̃=128 𝜖=128𝜖̃=256 𝜖=256

1200 1250 1300 1350 1400 1450 1500

Querying Time (ns)

Lognormal Dataset

𝜖=16

201 𝜖̃=16

PGM, Original

151 PGM, Dynamic ε

101 𝜖=32

Index Size (KB) 51 𝜖̃=32 𝜖=64

11000 1100 𝜖̃=641200𝜖̃=1281300 𝜖=1281400 𝜖̃=2561500𝜖=2561600

Querying Time (ns)


Figure 10: Improvements in terms of querying time for learned index methods with dynamic ϵ.


-----

**IoT Dataset** **Weblogs Dataset** **Lognormal Dataset**

**1.0** **_ai = 1/µi_** **1.00** **_ai = 1/µi_** **_ai = 1/µi_**

**FITing-Tree** **FITing-Tree** **0.35** **FITing-Tree**

**0.8** **RadixSpline** **RadixSpline** **RadixSpline**

**_ai_** **0.6** **PGM** **_ai_** **0.95** **PGM** **_ai_** **0.30** **PGM**

**0.90**

**0.4** **0.25**

**0.2** **0.85**

**0.2** **0.4** **0.6** **0.8** **1.0** **0.85** **0.90** **0.95** **1.00** **0.25** **0.30** **0.35**

**1/µi** **1/µi** **1/µi**


Figure 11: Learned slopes on the IoT, Weblogs and Lognormal datasets.





**Gamma, k = 1.0, θ = 1.0** **Gamma, k = 2.0, θ = 3.0** **Gamma, k = 3.0, θ = 6.0**

**40** **40** **40**

**MET Upper Bound** **PGM** **MET Upper Bound** **PGM** **MET Upper Bound** **PGM**

**35** **MET** **RadixSpline** **35** **MET** **RadixSpline** **35** **MET** **RadixSpline**

**MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree**

**30** **30** **30**

**25** **25** **25**

**20** **20** **20**

**15** **15** **15**

**Log(SegErr)** **Log(SegErr)** **Log(SegErr)**

**10** **10** **10**

**5** **5** **5**

**0** **0** **0**

**100** **200** **300** **400** **100** **200** **300** **400** **100** **200** **300** **400**

**_ϵ_** **_ϵ_** **_ϵ_**

**40** **Uniform, low = 0.0, high = 1.0** **40** **Uniform, low = 0.0, high = 10.0** **40Uniform, low = 10.0, high = 100.0**

**MET Upper Bound** **PGM** **MET Upper Bound** **PGM** **MET Upper Bound** **PGM**

**35** **MET** **RadixSpline** **35** **MET** **RadixSpline** **35** **MET** **RadixSpline**

**MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree** **MET Lower Bound** **FITing-Tree**

**30** **30** **30**

**25** **25** **25**

**20** **20** **20**

**15** **15** **15**

**Log(SegErr)** **Log(SegErr)** **Log(SegErr)**

**10** **10** **10**

**5** **5** **5**

**0** **0** **0**

**100** **200** **300** **400** **100** **200** **300** **400** **100** **200** **300** **400**

**_ϵ_** **_ϵ_** **_ϵ_**


Figure 12: Illustrations of the derived bounds on Gamma and Uniform datasets.


-----


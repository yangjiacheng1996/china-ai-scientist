# SPARSITY WINNING TWICE: BETTER ROBUST GEN## ERALIZATION FROM MORE EFFICIENT TRAINING

**Tianlong Chen[1*], Zhenyu Zhang[2*], Pengjun Wang[2*], Santosh Balachandra[1*],**
**Haoyu Ma[3*], Zehao Wang[2], Zhangyang Wang[1]**

1University of Texas at Austin, 2University of Science and Technology of China,
3University of California, Irvine
_{tianlong.chen,santoshb,atlaswang}@utexas.edu,_
_{zzy19969,wpj520,wangze}@mail.ustc.edu.cn, haoyum3@uci.edu_

ABSTRACT

Recent studies demonstrate that deep networks, even robustified by the state-ofthe-art adversarial training (AT), still suffer from large robust generalization gaps,
in addition to the much more expensive training costs than standard training. In
this paper, we investigate this intriguing problem from a new perspective, i.e., in_jecting appropriate forms of sparsity during adversarial training. We introduce_
two alternatives for sparse adversarial training: (i) static sparsity, by leveraging
recent results from the lottery ticket hypothesis to identify critical sparse subnetworks arising from the early training; (ii) dynamic sparsity, by allowing the
sparse subnetwork to adaptively adjust its connectivity pattern (while sticking to
the same sparsity ratio) throughout training. We find both static and dynamic
sparse methods to yield win-win: substantially shrinking the robust generalization
gap and alleviating the robust overfitting, meanwhile significantly saving training
and inference FLOPs. Extensive experiments validate our proposals with multiple network architectures on diverse datasets, including CIFAR-10/100 and TinyImageNet. For example, our methods reduce robust generalization gap and overfitting by 34.44% and 4.02%, with comparable robust/standard accuracy boosts and
87.83%/87.82% training/inference FLOPs savings on CIFAR-100 with ResNet18. Besides, our approaches can be organically combined with existing regulariz[ers, establishing new state-of-the-art results in AT. Codes are available in https:](https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization)
[//github.com/VITA-Group/Sparsity-Win-Robust-Generalization.](https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization)

1 INTRODUCTION


Deep neural networks (DNNs) are notoriously vulnerable to maliciously crafted adversarial attacks. To
conquer this fragility, numerous adversarial defense
mechanisms are proposed to establish robust neural networks (Schmidt et al., 2018; Sun et al., 2019;
Nakkiran, 2019; Raghunathan et al., 2019; Hu et al.,
2019; Chen et al., 2020c; 2021e; Jiang et al., 2020).
Among them, adversarial training (AT) based methods (Madry et al., 2017; Zhang et al., 2019) have
maintained the state-of-the-art robustness. However,
the AT training process usually comes with order-ofmagnitude higher computational costs than standard
training, since multiple attack iterations are needed to
construct strong adversarial examples (Madry et al.,
2018b). Moreover, AT was recently revealed to incur
severe robust generalization gaps (Rice et al., 2020),
between its training and testing accuracies, as shown
in Figure 1; and to require significantly more training
samples (Schmidt et al., 2018) to generalize robustly.

*Equal Contribution.


Figure 1: Robust train / test accuracy (Top / Bot_tom) on CIFAR-10 with ResNet-18 across var-_
ious sparsity levels from 0% (Dense) to 90%.
The dash-dot and solid lines represent the vanilla
PGD-AT dense baseline and our sparse proposals, respectively. As the sparsity increases, the
robust generalization gap between training and
testing accuracy is substantially narrowed.


-----

In response to those challenges, Schmidt et al. (2018); Lee et al. (2020); Song et al. (2019) investigate
the possibility of improving generalization by leveraging advanced data augmentation techniques,
which further amplifies the training cost of AT. Recent studies (Rice et al., 2020; Chen et al., 2021e)
found that early stopping, or several smoothness/flatness-aware regularizations (Chen et al., 2021e;
Stutz et al., 2021; Singla et al., 2021), can bring effective mitigation.

In this paper, a new perspective has been explored to tackle the above challenges by enforcing ap_propriate sparsity patterns during AT. The connection between robust generalization and sparsity_
is mainly inspired by two facts. On one hand, sparsity can effectively regularize the learning of
over-parameterized neural networks, hence potentially benefiting both standard and robust generalization (Balda et al., 2019). As demonstrated in Figure 1, with the increase of sparsity levels, the
robust generalization gap is indeed substantially shrunk while the robust overfitting is alleviated.
On the other hand, one key design philosophy that facilitates this consideration is the lottery ticket
hypothesis (LTH) (Frankle & Carbin, 2019). The LTH advocates the existence of highly sparse and
separately trainable subnetworks (a.k.a. winning tickets), which can be trained from the original
initialization to match or even surpass the corresponding dense networks’ test accuracies. These
facts point out a promising direction that utilizing proper sparsity is capable of boosting robust generalization while maintaining competitive standard and robust accuracy.

Although sparsity is beneficial, the current methods (Frankle & Carbin, 2019; Frankle et al., 2020;
Renda et al., 2020) often empirically locate sparse critical subnetworks by Iterative Magnitude Pruning (IMP). It demands excessive computational cost even for standard training due to the iterative
train-prune-retrain process. Recently, You et al. (2020) demonstrated that these intriguing subnetworks can be identified at the very early training stage using one-shot pruning, which they term as
_Early Bird (EB) tickets. We show the phenomenon also exists in the adversarial training scheme._
More importantly, we take one leap further to reveal that even in adversarial training, EB tickets can
be drawn from a cheap standard training stage, while still achieving solid robustness. In other words,
_the Early Bird is also a Robust Bird that yields an attractive win-win of efficiency and robustness -_
we name this finding as Robust Bird (RB) tickets.

Furthermore, we investigate the role of sparsity in a scene where the sparse connections of subnetworks change on the fly. Specifically, we initialize a subnetwork with random sparse connectivity
and then optimize its weights and sparse typologies simultaneously, while sticking to the fixed small
parameter budget. This training pipeline, called as Flying Bird (FB), is motivated by the latest
sparse training approaches (Evci et al., 2020b) to further reduce robust generalization gap in AT,
while ensuring low training costs. Moreover, an enhanced algorithm, i.e., Flying Bird+, is proposed
to dynamically adjust the network capacity (or sparsity) to pursue superior robust generalization, at
few extra prices of training efficiency. Our contributions can be summarized as follows:

-  We perform a thorough investigation to reveal that introducing appropriate sparsity into
AT is an appealing win-win, specifically: (1) substantially alleviating the robust generalization gap; (2) maintaining comparable or even better standard/robust accuracies; and (3)
enhancing the AT efficiency by training only compact subnetworks.

-  We explore two alternatives for sparse adversarial training: (i) the Robust Bird (RB) training
that leverages static sparsity, by mining the critical sparse subnetwork at the early training
stage, and using only the cheapest standard training; (ii) the Flying Bird (FB) training that
allows for dynamic sparsity, which jointly optimizes both network weights and their sparse
connectivity during AT, while sticking to the same sparsity level. We also discuss a FB
variant called Flying Bird+ that adaptively adjusts the sparsity level on demand during AT.

-  Extensive experiments are conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet with
diverse network architectures. Specifically, our proposals obtain 80.16% ∼ 87.83% training FLOPs and 80.16% ∼ 87.83% inference FLOPs savings, shrink robust generalization
from 28.00% ∼ 63.18% to 4.43% ∼ 34.44%, and boost the robust accuracy by up to
0.60% and the standard accuracy by up to 0.90%, across multiple datasets and architectures. Meanwhile, combining our sparse adversarial training frameworks with existing
regularizations establishes the new state-of-the-art results.

2 RELATED WORK

**Adversarial training and robust generalization/overfitting.** Deep neural networks present vulnerability to imperceivable adversarial perturbations. To deal with this drawback, numerous defense


-----

approaches have been proposed (Goodfellow et al., 2015; Kurakin et al., 2016; Madry et al., 2018a).
Although many methods (Liao et al., 2018; Guo et al., 2018a; Xu et al., 2017; Dziugaite et al., 2016;
Dhillon et al., 2018a; Xie et al., 2018; Jiang et al., 2020) were later found to result from obfuscated
gradients (Athalye et al., 2018), adversarial training (AT) (Madry et al., 2018a), together with some
of its variants (Zhang et al., 2019; Mosbach et al., 2018; Dong et al., 2018), remains as one of the
most effective yet costly approaches.

A pitfall of AT, i.e., the poor robust generalization, was spotted recently. Schmidt et al. (2018)
showed that AT intrinsically demands a larger sample complexity to identify well-generalizable robust solutions. Therefore, data augmentation (Lee et al., 2020; Song et al., 2019) is an effective remedy. Stutz et al. (2021); Singla et al. (2021) related robust generalization gap to curvature/flatness
of loss landscapes. They introduced weight perturbing approaches and smooth activation functions
to reshape the loss geometry and boost robust generalization ability. Meanwhile, the robust overfitting (Rice et al., 2020) in AT usually happens with or as a result of inferior generalization. Previous
studies (Rice et al., 2020; Chen et al., 2021e) demonstrated that conventional regularization-based
methods (e.g., weight decay and simple data augmentation) can not alleviate robust overfitting.
Then, numerous advanced algorithms (Zhang et al., 2020; 2021b; Zhou et al., 2021; Bunk et al.,
2021; Chen et al., 2021a; Dong et al., 2021; Zi et al., 2021; Tack et al., 2021; Zhang et al., 2021a)
arose in the last half year to tackle the overfitting, using data manipulation, smoothened training,
and else. Those methods work orthogonally to our proposal as evidenced in Section 4.

Another group of related literature lies in the field of sparse robust networks (Guo et al., 2018b).
These works either treat model compression as a defense mechanism (Wang et al., 2018; Gao
et al., 2017; Dhillon et al., 2018b) or pursue robust and efficient sub-models that can be deployed
in resource-limited platforms (Gui et al., 2019; Ye et al., 2019; Sehwag et al., 2019). Compared
to those inference-focused methods, our goal is fundamentally different: injecting sparsity during
training to reduce the robust generalization gap while improving training efficiency.

**Static pruning and dynamic sparse training.** Pruning (LeCun et al., 1990; Han et al., 2015a)
serves as a powerful technique to eliminate the weight redundancy in over-parameterized DNNs,
which aims to obtain storage and computational savings with almost undamaged performance. It
can roughly divided into two categories based on how to generate sparse patterns: (i) static prun_ing. It removes parameters (Han et al., 2015a; LeCun et al., 1990; Han et al., 2015b) or sub-_
structures (Liu et al., 2017; Zhou et al., 2016; He et al., 2017) based on optimized importance
scores (Zhang et al., 2018; He et al., 2017) or some heuristics like weight magnitude (Han et al.,
2015a), gradient (Molchanov et al., 2019), hessian (LeCun et al., 1990) statistics. The discarded
elements usually will not participate in the next round of training or pruning. Static pruning can be
flexibly applied prior to training, such as SNIP (Lee et al., 2019), GraSP (Wang et al., 2020) and
SynFlow (Tanaka et al., 2020); during training (Zhang et al., 2018; He et al., 2017); and post training (Han et al., 2015a) for different trade-off between training cost and pruned models’ quality. (ii)
_dynamic sparse training. It updates model parameters and sparse connectivities at the same time,_
starting from a randomly sparsified subnetwork (Molchanov et al., 2017). During the training, the
removed elements have chances to be grown back if they potentially benefit to predictions. Among
the huge family of sparse training (Mocanu et al., 2016; Evci et al., 2019; Mostafa & Wang, 2019;
Liu et al., 2021a; Dettmers & Zettlemoyer, 2019; Jayakumar et al., 2021; Raihan & Aamodt, 2020),
the recent methods Evci et al. (2020a); Liu et al. (2021b) lead to the state-of-the-art performance.

A special case of static pruning, Lottery tickets hypothesis (LTH) (Frankle & Carbin, 2019), demonstrates the existence of sparse subnetworks in DNNs, which are capable of training in isolation and
reach a comparable performance of their dense counterpart. The LTH indicates the great potential to
train a sparse network from scratch without sacrificing expressiveness and has recently drawn lots of
attention from diverse fields (Chen et al., 2020b;a; 2021g;f;d;c;b; 2022; Ding et al., 2022; Gan et al.,
2021) beyond image recognition (Zhang et al., 2021d; Frankle et al., 2020; Redman et al., 2021).

3 METHODOLOGY

3.1 PRELIMINARIES
**Adversarial training (AT).** As one of the widely adopted defense mechanisms, adversarial training (Madry et al., 2018b) effectively tackles the vulnerability to maliciously crafted adversarial
samples. As formulated in Equation 1, AT (specifically PGD-AT) replaces the original empirical
risk minimization into a min-max optimization problem:


-----

Figure 2: Overview of our proposed training frameworks including Robust Bird (RB), Flying Bird

Standard Training

PGD Adversarial Training

Non-robust Weights Robust Weights

Pruning Robust Bird (+) Flying Bird (+)

Identify Robust Bird PGD-AT for Robust Bird

Initial Sparse Model

**......**

Pruning & Grow Pruning & Grow

Jointly Identify and PGD-AT for Flying Bird

Initial Sparse Model
Overfitting Overfitting

**+** Underfitting Underfitting

**......** **+**

Pruning Less Pruning More

& Grow More & Grow Less

**+**

Jointly Identify and PGD-AT for Flying Bird+ / Dynamically Adjust Network Capacity based on Optimization Status

(FB), and Flying Bird (FB+). The length of cycles roughly indicates the number of training epochs.

min E(x,y) _f_ (x; θ), y = min E(x,y) max _f_ (x + δ; θ), y _,_ (1)
_θ_ _∈DL_ _⇒_ _θ_ _∈D_ _δ_ _p_ _ϵ_
_∥_ _∥_ _≤_ _[L]_

where f (x; θ) is a network with parameters   _θ. Input data x and its associated label _ _y from training set_
_D are used to first generate adversarial perturbations δ and then minimize the empirical classification_
loss L. To meet the imperceptible requirement, the ℓp norm of δ is constrained by a small constant
_ϵ. Projected Gradient Descent (PGD), i.e., δ[t][+1]_ = projP [δ[t] + α · sgn _∇xL(f_ (x + δ[t]; θ), y) ], is
usually utilized to produce the adversarial perturbations with step size α, which works in an iterative
  
manner leveraging the local first order information about the network (Madry et al., 2018b).

**Sparse subnetworks.** Following the routine notations in Frankle & Carbin (2019), f (x; m ⊙ _θ)_
donates a sparse subnetwork with a binary pruning mask m ∈{0, 1}[∥][θ][∥][0], where ⊙ is the elementwise product. Intuitively, it is a copy of dense network f (x; θ) with a portion of fixed zero weights.

3.2 ROBUST BIRD FOR ADVERSARIAL TRAINING

**Introducing Robust Bird.** The primary goal of Robust Bird is to find a high-quality sparse subnetwork efficiently. As shown in Figure 2, it locates subnetworks quickly by detecting critical network
structures arising in the early training, which later can be robustified with much less computation.

Specifically, for each epoch t during training, Robust Bird creates a sparsity mask mt by “masking
out” the p% lowest-magnitude weights; then, Robust Bird tracks the corresponding mask dynamics.
The key observation behind Robust Bird is that the sparsity mask mt does not change drastically
beyond the early epochs of training (You et al., 2020) because high-level network connectivity patterns are learned during the initial stages (Achille et al., 2019). This indicates that (i) winning tickets
emerge at a very early training stage, and (ii) that they can be identified efficiently.

_Robust Bird exploits this observation by comparing the Hamming distance between sparsity masks_
found in consecutive epochs. For each epoch, the last l sparsity masks are stored. If all the stored
masks are sufficiently close to each other, then the sparsity masks are not changing drastically over
time and network connectivity patterns have emerged; thus, a Robust Bird ticket (RB ticket) is
drawn. A detailed algorithmic implementation is provided in Algorithm 1 of Appendix A1. This is
the RB ticket used in the second stage of adversarial training.


-----

|000000.000 0.000 10.000 1000.000 100000.0 15 20 25 30 35|2nd PC: 19.17 % Flying Bird+|30 1000000 20 10000.000 100.000 10 .700.52.500 000887... 00 5500009 0.0 0 009.500 2.000 0 003.000 10 0 0 . 0 1 .5 41 . 6.0 5 0. 0 0500 00 10 000 00 00 .5 4. 3 20 .500 43 . 6 5 . 0 5 0 5 0 5 10|
|---|---|---|
|Ctr: a3j6e.9c4t o%ries. We compare the den1sset Pn|||


**Rationale of Robust Bird.** Recent studies (Zhang et al., 2021c) present theoretical analyses that

30 30

000.000

302010 3.500 3.0009.5009.0008.5008.0005.000 10000.0001000000.000 10000000.000 100000000.000 2010 100.000 10000.0001000000.00010000000.000 2010 2.0008.5007.0008.0007.5005.0002.5009.0009.500 100.00010000.0001000000.000 100000000.000

**Dense2nd PC: 19.56 %** 10200 0.5001.000 1.500 3.0002.000 2.5004.0003.5004.5005.5006.0007.0007.50010.000 6.50100.000 1000.000 100000.000 **Random Pruning2nd PC: 19.72 %** 10200 3.5003.0002.5002.5001.5005.0004.5003.0004.000 2.000 2.500 5.5009.5006.0003.5006.5007.0007.5008.0008.5009.00010.000 1000.000 100000.0 **Flying Bird+2nd PC: 19.17 %** 10200 4.0001.500 3.5001.0003.500 3.0004.5004.000 6.0005.5006.50010.000 1000.000 100000.000 10000000.000

5 0 5 10 15 20 25 30 35 5 0 5 10 15 20 25 30 35 5 0 5 10 15 20 25 30 35

Figure 3: Visualization of loss contours and training trajectories. We compare the dense network, randomly1st PC: 37.67 % 1st PC: 36.94 % 1st PC: 36.16 %
pruned sparse networks, and flying bird+ at 90% sparsity from ResNet-18 robustified on CIFAR-10.

identified sparse winning tickets enlarge the convex region near the good local minima, leading to
improved generalization. Our work also shows a related investigation in Figure A9 that, compared
with dense models and random pruned subnetworks, RB tickets found by the standard training have
much flatter loss landscapes, serving a high-quality starting point for further robustification. This
occurs because flatness of the loss surface is often believed to indicate the standard generalization.
Similarly, as advocated by Wu et al. (2020a); Hein & Andriushchenko (2017), a flatter adversarial
loss landscape also effectively shrinks the robustness generalization gap. This “flatness preference”
of adversarial robustness has been revealed by numerous empirical defense mechanisms, including
Hessian/curvature-based regularization (Moosavi-Dezfooli et al., 2019), learned weight and logits
smoothening (Chen et al., 2021e), gradient magnitude penalty (Wang & Zhang, 2019), smoothening
with random noise (Liu et al., 2018), or entropy regularization (Jagatap et al., 2020).

These observations make the main cornerstone for our proposal and provide possible interpretations
to the surprising finding that the RB tickets pruned from a non-robust model can be used for obtaining well-generalizable robust models in the followed robustification. Furthermore, unlike previous
costly flatness regularizers (Moosavi-Dezfooli et al., 2019), our methods not only offer a flatter
starting point but also obtain substantial computational savings due to the reduced model size.

3.3 FLYING BIRD FOR ADVERSARIAL TRAINING

**Introducing Flying Bird(+).** Since sparse subnetworks from static pruning are unable to regret
for removed elements, they may be too aggressive to capture the pivotal structural patterns. Thus,
we introduce Flying Bird (FB) to conduct a thorough exploration of dynamic sparsity, which allows
pruned parameters to be grown back and engages in the next round of training or pruning, as demonstrated in Figure 2. Specifically, it starts from a sparse subnetwork f (x; m⊙θ) with a random binary
mask m, and then jointly optimize model parameters and sparse connectivities simultaneously. In
other words, the subnetwork’s typologies are “on the fly”, decided dynamically based on current
training status. Specifically, we update Flying Bird’s sparse connectivity every ∆t epochs of adversarial training, which consists of two continually applied operations: pruning and growing. For the
pruning step, p% of model weights with the lowest magnitude will be eliminated, while g% weights
with the largest gradient will be added back in the growth step. Note that newly added connections
are not activated in the last sparse topology, and are initialized to zero since it establishes better performance as indicated in (Evci et al., 2020a; Liu et al., 2021b). Flying Bird maintains the sparsity
ratio unchanged during the full training by keeping both pruning and growing ratio p%, g% equal
_k% that decays with a cosine annealing schedule._

We further propose Flying Bird+, an enhanced variant of FB, capable of adaptively adjusting the
sparsity and learning the right parameterization level ”on demand” during training, as shown in
Figure 2. To be specific, we first record the robust generalization gap and robust validation loss at
each training epoch. An increasing generalization gap of the later training stage indicates a risk of
overfitting, while a plateau validation loss implies underfitting. Hence, we then analyze the fitting
status according to the upward/downward trend of those measurements. If most epochs (e.g., more
than 3 out of the past 5 epochs in our case) tend to see enlarged robust generalization gaps, we raise
the pruning ratio p% to further trim down the network capacity. Similarly, if the majority of epochs
present unchanged validation loss, we will increase the growing ratio q% to enrich the subnetwork
capacity. Detailed procedures are summarized in Algorithm 2 of Appendix A1.

**Rationale of Flying Bird(+).** As demonstrated in Evci et al. (2020a), allowing new connections
to grow yields improved flexibility in navigating the loss surfaces, which creates the opportunity to


-----

escape bad local minima and search for the optimal sparse connectivity Liu et al. (2021b). Flying
_Bird follows a similar design philosophy that excludes least important connections (Han et al.,_
2015a) while activating new connections with the highest potential to decrease the training loss
fastest. Recent works (Wu et al., 2020c; Liu et al., 2019) have also found enabling network (re)growth can turn a poor local minima into a saddle point that facilitates further loss decrease. Flying
_Bird+ empowers the flexibility further by adaptive sparsity level control._

The flatness of loss geometry provides another view to dissect the robust generalization gain (Chen
et al., 2021e; Stutz et al., 2021; Singla et al., 2021). Figure 3 compares the loss landscapes and training trajectories of dense, randomly pruned subnetworks, and Flying Brid+ robustified on CIFAR-10.
We observe that Flying Bird+ converges to a wider loss valley with improved flatness, which usually
suggests superior robust generalization (Wu et al., 2020a; Hein & Andriushchenko, 2017). Last but
not the least, our approaches also significantly trim down both the training memory overhead and
the computational complexity, enjoying extra bonus of efficient training and inference.

4 EXPERIMENT RESULTS

**Datasets and architectures.** Our experiments consider two popular architectures, ResNet-18 (He
et al., 2016), VGG-16 (Simonyan & Zisserman, 2014) on three representative datasets, CIFAR-10,
CIFAR-100 (Krizhevsky & Hinton, 2009) and Tiny-ImageNet (Deng et al., 2009). We randomly
split one-tenth of the training samples as the validation dataset, and the performance is reported on
the official testing dataset.

**Training and evaluation details.** We implement our experiments with the original PGD-based
adversarial trainig (Madry et al., 2018b), in which we train the network against ℓ adversary with
_∞_
maximum perturbations ϵ of 8/255. 10-steps PGD for training and 20-steps PGD for evaluation are
chosen with a step size α of 2/255, following Madry et al. (2018b); Chen et al. (2021e). In addition,
we also use Auto-Attack (Croce & Hein, 2020) and CW Attack (Carlini & Wagner, 2017) for a more
rigorous evaluation. More details are provided in Appendix A2. For each experiment, we train the
network for 200 epochs with an SGD optimizer, whose momentum and weight decay are kept to
0.9 and 5 × 10[−][4], respectively. The learning rate starts from 0.1 that decays by 10 times at 100,150
epoch and the batch size is 128, which follows Rice et al. (2020).

For Robust Bird, the threshold τ of mask distance is set as 0.1. In Flying Birds(+), we calculate the
layer-wise sparsity by Ideal Gas Quotas (IGQ) (Vysogorets & Kempe, 2021) and then apply random
pruning to initialize the sparse masks. FB updates the sparse connectivity per 2000 iterations of
AT, with an update ratio k that starts from 50% and decays by cosine annealing. More details are
referred to Appendix A2. Hyperparameters are either tuned by grid search or following Liu et al.
(2021b).

**Evaluation metrics.** In general, we care about both the accuracy and efficiency of obtained sparse
networks. To assess the accuracy, we consider both Robust Testing Accuracy (RA) and Standard
Testing Accuracy (SA) which are computed on the perturbed and the original test sets, together with
Robust Generalization Gap (RGG) (i.e., the gap of RA between train and test sets). Meantime,
we report the floating point operations (FLOPs) of the whole training process and single image
inference to measure the efficiency.

4.1 ROBUST BIRD IS A GOOD BIRD

In this section, we evaluate the effectiveness of static sparsity from diverse representative pruning
approaches, including: (i) Random Pruning (RP), by randomly eliminating model parameters to the
desired sparsity; (ii) One-shot Magnitude Pruning (OMP), which globally removes a certain ratio
of lowest-magnitude weights; (iii) Pruning at Initialization algorithms. Three advanced methods,
i.e., SNIP (Lee et al., 2019), GraSP (Wang et al., 2020) and SynFlow (Tanaka et al., 2020), are
considered, which identify the subnetworks at initialization respect to certain criterion of gradient
flow. (iv) Ideal Gas Quotas (IGS) (Vysogorets & Kempe, 2021). It adopts random pruning based
on pre-calculated layer-wise sparsity which draws intuitive analogies from physics. (v) Robust Bird
(RB), which can be regarded as an early stopped OMP. (vi) Small Dense. It is an important sanity
check via considering smaller dense networks with the same parameter counts as the ones of sparse
networks. Comprehensive results of these subnetworks at 80% and 90% sparsity are reported in
Table 1, where the chosen sparsity follows routine options (Evci et al., 2020a; Liu et al., 2021b).


-----

Table 1: Performance showing the appearance of poor robust generalization/robust overfitting, and the effectiveness of our sparse proposals with various comparisons to other sparsification methods on CFAIR-10 with
ResNet-18. The difference between best and final robust accuracy indicates degradation in performance during
training. We pick the best checkpoint by the best robust accuracy on the validation set. Bold numbers indicate
superior performance, and ↓ displays shrunk robust generalization gap compared to dense models. Note that
model picking criterion and the presentation style are consistent for all tables.

|Robust Accuracy Standard Accuracy Training Inference Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. FLOPs (×1017) FLOPs (×109) Generalization|Robust Accuracy|Standard Accuracy|Training Inference|Col5|
|---|---|---|---|---|
||Best Final Diff.|Best Final Diff.|FLOPs (×1017) FLOPs (×109)||
|0 Baseline|51.10 43.61 7.49|81.15 83.38 −2.23|772.41 260.07|38.82|
|Small Dense Random Pruning OMP SNIP GraSP 80 SynFlow IGQ Robust Bird Flying Bird Flying Bird+|49.04 44.18 4.86 49.32 43.97 5.35 50.16 45.02 5.14 50.46 46.44 4.02 50.16 45.31 4.85 51.17 46.91 4.26 51.12 46.74 4.38 50.18 46.10 4.08 51.62 46.37 5.25 51.70 47.51 4.19|76.64 80.77 −4.13 77.75 81.27 −3.52 79.80 82.39 −2.59 80.13 83.20 −3.07 78.38 82.42 −4.04 79.08 83.19 −4.11 79.73 83.26 −3.53 78.46 82.42 −3.96 80.55 83.17 −2.62 80.74 83.16 −2.42|69.54 23.41 154.40 51.99 966.63 65.39 241.85 81.43 187.11 63.00 256.09 86.23 239.39 80.60 209.54 64.64 239.38 80.60 120.04 40.42|21.68 ↓17.14 25.70 ↓13.12 28.38 ↓10.44 25.24 ↓13.58 26.28 ↓12.54 24.66 ↓14.16 25.41 ↓13.41 23.37 ↓15.45 28.90 ↓9.92 23.89 ↓14.93|
|Small Dense Random Pruning OMP SNIP GraSP 90 SynFlow IGQ Robust Bird Flying Bird Flying Bird+|46.81 45.48 1.33 47.09 44.97 2.12 49.31 46.11 3.20 49.49 47.85 1.64 48.56 46.80 1.76 50.08 48.02 2.06 49.74 48.05 1.69 49.09 46.56 2.53 50.97 48.10 2.87 50.88 49.27 1.61|77.13 78.54 −1.41 75.25 78.77 −3.52 77.99 81.00 −3.01 77.74 81.92 −4.18 79.02 81.39 −2.37 81.15 81.56 −0.41 81.06 81.84 −0.78 77.96 80.93. −2.97 79.62 82.93 −3.31 79.95 82.65 −2.70|24.31 8.19 77.16 25.98 877.76 35.47 154.35 51.97 113.38 38.18 156.74 52.77 141.10 47.51 133.42 39.01 141.10 47.51 66.67 22.45|13.86 ↓24.96 15.11 ↓23.71 19.05 ↓19.77 16.20 ↓22.62 16.80 ↓22.02 14.68 ↓24.14 15.95 ↓22.87 16.62 ↓22.20 20.07 ↓18.75 15.16 ↓23.66|



As shown in Table 1, we first observe the occurrence of poor robust generalization with 38.82% RA
gap and robust overfitting with 7.49% RA degradation, when training the dense network (Baseline).
Fortunately, coincided with our claims, injecting appropriate sparsity effectively tackle the issue. For
instance, RB greatly shrinks the RGG by 15.45%/22.20% at 80/90% sparsity, while also mitigates
robust overfitting by 2.53% ∼ 4.08%. Furthermore, comparing all static pruning methods, we find
that (1) Small Dense and RP behave the worst, which suggests the identified sparse typologies play
important roles rather than reduced network capacity only; (2) RB shows clear advantages to OMP
in terms of all measurements, especially for 78.32% ∼ 84.80% training FLOPs savings. It validates
our RB proposal that a few epochs of standard training are enough to learn a high-quality sparse
structure for further robustification, and thus there is no need to complete the full training in the
tickets finding stage like traditional OMP. (3) SynFlow and IGQ approaches have the best RA and
SA, while RB obtains the superior robust generalization among static pruning approaches.

Finally, we explore the influence of training regimes during the RB ticket finding on CIFAR-100
with ResNet-18. Table A6 demonstrates that RB tickets perform best when found with the cheapest
standard training. Specifically, at 90% and 95% sparsity, SGD RB tickets outperform both Fast
AT (Wong et al., 2020) and PGD-10 RB tickets with up to 1.27% higher RA and 1.86% narrower
RGG. Figure A7 offers a possible explanation for this phenomenon: the SGD training scheme more
quickly develops high-level network connections, during the early epochs of training (Achille et al.,
2019). As a result, RB Tickets pruned from the model trained with SGD achieve superior quality.

4.2 FLYING BIRD IS A BETTER BIRD

In this section, we discuss the advantages of dynamic sparsity and show that our Flying Bird(+) is
a superior bird. Table 1 examines the effectiveness of FB(+) on CIFAR-10 with ResNet-18, and
several consistent observations can be drawn:  FB(+) achieve 9.92% ∼ 23.66% RGG reduction,
2sparsity even pushes the RA.24% ∼ 5.88% decrease for robust overfitting, compared with the dense network. And FB+ at 0.60% higher.  Although the smaller dense network shows the leading 80%
performance w.r.t improving robust generalization, the robustness has been largely sacrificed, with
up to 4.29% RA degradation, suggesting that only reducing models’ parameter counts is insufficient
to keep satisfactory SA/RA.  FB and FB+ achieve superior performance of RA for both the best
and final checkpoints across all methods, including RB.  Regardless of small dense and random
pruning due to their poor robustness, FB+ reaches the most impressive robust generalization (rank #1
or #2) with the least training and inference costs. Precisely, FB+ obtains 84.46% ∼ 91.37% training
FLOPs and 84.46% ∼ 93.36% inference FLOPs saving, i.e., Flying Bird+ is SUPER light-weight.


-----

Table 2: Performance showing the effectiveness of our proposed approaches across different datasets with

|ResNet-18. The subnetworks at 80% sparsity are selected here.|ks at 80% sparsity are|selected here.|Col4|Col5|
|---|---|---|---|---|
|Robust Accuracy Standard Accuracy Training Inference Robust Dataset Settings Best Final Diff. Best Final Diff. FLOPs (×1017) FLOPs (×109) Generalization|Robust Accuracy|Standard Accuracy|Training Inference||
||Best Final Diff.|Best Final Diff.|FLOPs (×1017) FLOPs (×109)||
|Baseline Robust Bird CIFAR-10 Flying Bird Flying Bird+|51.10 43.61 7.49 50.18 46.10 4.08 51.62 46.37 5.25 51.70 47.51 4.19|81.15 83.38 −2.23 78.46 82.42 −3.96 80.55 83.17 −2.62 80.74 83.16 −2.42|772.41 260.07 209.54 64.64 239.38 80.60 120.04 40.42|38.82 23.37 ↓15.45 28.90 ↓9.92 23.89 ↓14.93|
|Baseline Robust Bird CIFAR-100 Flying Bird Flying Bird+|26.93 19.62 7.31 25.54 20.82 4.72 26.64 22.00 4.64 26.66 23.37 3.29|52.03 53.91 −1.88 48.79 53.33 −4.54 53.57 55.41 −1.84 52.29 55.23 −2.94|772.41 260.07 189.80 58.00 237.12 79.84 100.90 33.97|54.56 25.46 ↓29.10 27.46 ↓27.10 20.12 ↓34.44|
|Baseline Robust Bird Tiny-ImageNet Flying Bird Flying Bird+|20.84 15.76 5.08 19.58 16.45 3.13 20.34 19.00 1.34 20.36 19.11 1.25|43.57 46.64 −3.07 43.70 46.30 −2.60 45.95 46.86 −0.91 45.67 46.73 −1.06|6179.30 1040.29 1410.44 215.15 1884.01 317.17 1225.80 206.36|36.84 15.22 ↓21.62 14.93 ↓21.91 13.24 ↓23.60|



Table 3: Performance showing the effectiveness of our proposed approaches with other architectures, i.e.,

|VGG-16 on CIFAR-10/100. The subnetworks at 80% sparsity are selected here.|bnetworks at 80% sp|parsity are selected he|ere.|Col5|
|---|---|---|---|---|
|Robust Accuracy Standard Accuracy FLOPs Robust Architecture Dataset Settings Best Final Diff. Best Final Diff. Training Inference Generalization|Robust Accuracy|Standard Accuracy|FLOPs||
||Best Final Diff.|Best Final Diff.|Training Inference||
|Baseline Robust Bird VGG-16 CIFAR-10 Flying Bird Flying Bird+|48.33 42.73 5.60 47.69 41.66 6.03 48.43 44.65 3.78 48.25 45.24 3.01|76.84 79.73 −2.89 75.32 78.58 −3.26 77.53 79.72 −2.19 77.48 79.55 −2.07|574.69 193.50 165.95 51.48 173.56 58.44 94.63 31.86|28.00 23.57 ↓4.43 21.01 ↓6.99 17.75 ↓10.25|
|Baseline Robust Bird VGG-16 CIFAR-100 Flying Bird Flying Bird+|22.76 18.06 4.70 23.46 17.48 5.98 22.75 17.96 4.79 22.92 19.02 3.90|46.11 46.88 −0.77 46.33 47.59 −1.26 46.61 47.36 −0.75 47.01 48.11 −1.10|574.69 193.50 165.77 51.42 172.14 57.96 69.93 23.54|63.18 48.19 ↓14.99 48.11 ↓15.07 34.63 ↓28.55|



**Superior performance across datasets and architectures.** We further evaluate the performance
of FB(+) across various datasets (CIFAR-10, CIFAR-100 and Tiny-ImageNet) and architectures
(ResNet-18 and VGG-16). Table 2 and 3 display that both static and dynamic sparsity of our proposals serve effective remedies for improving robust generalization and mitigating robust overfitting,
with 4.43% ∼ 15.45%, 14.99% ∼ 34.44% and 21.62% ∼ 23.60% RGG reduction across different
architectures on CIFAR-10, CIFAR-100 and Tiny-ImageNet, respectively. Moveover, both RB and
FB(+) gain significant efficiency, with up to 87.83% training and inference FLOPs savings.

**Superior performance across improved attacks.** Additionally, we verify both RB and FB(+)
under improved attacks, i.e., Auto-Attack (Croce & Hein, 2020) and CW Attack (Carlini & Wagner, 2017). As shown in Table A8, our approaches shrink the robust generalization gap by up to
30.76% on CIFAR-10/100, and largely mitigate robust overfitting. This piece of evidence shows our
proposal’s effectiveness sustained across diverse attacks.


**Combining FB+ with existing start-of-the-art (SOTA) mitigation.**
Previous works (Chen et al., 2021e; Zhang et al., 2021a; Wu et al.,
2020b) point out that smoothening regularizations (e.g., KD (Hinton
et al., 2015) and SWA (Izmailov et al., 2018)) help robust generalization and lead to SOTA robust accuracies. We combine them with our
FB+ and collect the robust accuracy on CIFAR-10 with ResNet-18 in
Figure 4. The extra robustness gains from FB+ imply that they makes
complementary contributions.


Figure 4: Combination of

|53 (%) 52 Accuracy 51 Robust 50 K|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|
|---|---|---|---|---|---|---|---|---|---|
|||||Dense||||||
|||||FB+||||||
|||||||||||
|||||||||||
|||||||||||
|||||||||||
|||||||||||
|||||||||||
|||K||D|SW|A|SWA|&KD||

FB+ and previous SOTAs.


**Excluding obfuscated gradients.** A common “counterfeit” of robustness improvements is less
effective adversarial examples resulted from obfuscated gradients (Athalye et al., 2018). Table A7
demonstrates the maintained enhanced robustness under unseen transfer attacks, which excludes the
possibility of gradient masking. More are referred to Section A3.

4.3 ABLATION STUDY AND VISUALIZATION
**Different sparse initialization and update frequency.** As two major components in the dynamic
sparsity exploration (Evci et al., 2020a), we conduct thorough ablation studies in Table 4 and 5.
We found the performance of Flying Bird+ is more sensitive to different sparse initialization; using
SNIP to produce initial layer-wise sparsity and updating the connections per 2000 iterations serves
the superior configuration for FB+.


-----

Table 4: Ablation of different sparse initialization in
Flying Bird+. Subnetwroks at 80% initial sparsity are
chosen on CIFAR-10 with ResNet-18.


Table 5: Ablation of different update frequency in
Flying Bird+. Subnetworks at 80% initial sparsity
are chosen on CIFAR-10 with ResNet-18.



Initialization


|Robust Accuracy n Best Final Diff.|Standard Accuracy R Best Final Diff. Gener|
|---|---|
|49.09 46.96 2.13 7 50.57 47.70 2.87 7 51.30 49.17 2.13 7 50.76 47.88 2.88 7 50.56 48.75 1.81 7 50.88 49.27 1.61 7|8.32 80.32 −2.00 1 9.53 82.21 −2.68 1 9.86 82.28 −2.42 1 8.52 82.48 −3.96 1 8.51 82.17 −3.66 1 9.95 82.65 −2.70 1|

|Update Freque (iterations)|ncy Robust Accuracy Best Final Diff.|Standard Accuracy Ro Best Final Diff. Gener|bust alization|
|---|---|---|---|
|100 500 1000 2000 5000 10000|50.32 49.02 1.30 8 50.57 48.37 2.20 7 50.99 48.34 2.65 7 51.19 48.39 2.80 7 50.39 48.49 1.90 7 50.08 48.02 2.06 7|1.28 81.99 −0.71 13 9.76 82.73 −2.97 18 9.55 82.69 −3.14 19 9.80 83.00 −3.20 19 9.11 82.58 −3.47 17 9.25 82.50 −3.25 17|.36 .92 .85 .17 .95 .64|


2.00 2.00 2.00 2.00 2.00

1 .75 1 .75 1 .75 1 .75 1 .75

1 .50 1 .50 1 .50 1 .50 1 .50

1 .25 1 .25 1 .25 1 .25 1 .25

0.000.250.500.751 .00 0.000.250.500.751 .00 0.000.250.500.751 .00 0.000.250.500.751 .00 0.000.250.500.751 .00

1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00 1 .000.750.500.250.000.250.500.751 .00

**Dense** **Random Pruning** **SNIP** **Robust Bird** **Flying Bird** **Flying Bird +**


Figure 5: Loss landscape visualization of robusitified dense network and sparse networks (90% sparsity) from
different sparsification approaches on CIFAR-10 with ResNet-18.

**Final checkpoint loss landscapes.** From visualizations in Figure 5, FB and FB+ converge to much
flatter loss valleys, which evidences their effectiveness in closing robust generalization gaps.

**Attention and saliency maps.** To visually inspect the benefits of our proposal, here we provide
attention and saliency maps generated by Grad-GAM (Selvaraju et al., 2017) and tools in (Smilkov
et al., 2017). Comparing the dense model to our “talented birds” (e.g., FB+), Figure 6 shows that
our approaches have enhanced concentration on main objects, and are capable of capturing more
local feature information, aligning better with human perception.

|Col1|Col2|Col3|Col4|Col5|
|---|---|---|---|---|
|+|||||
||||||
||||||
||||||
||||||
||||||



Figure 6: (Left) Visualization of attention heatmaps on adversarial images based on Grad-Cam (Selvaraju

**Adversarial**

**Samples**

1 +

**Dense**

**Flying**

**Bird+**

**Flying**

**Bird**

**Robust**

**Bird**

**SNIP**

**Random**

**Pruning**

**Heatmap** **Saliency Map**

et al., 2017). (Right) Saliency map visualization on adversarial samples (Smilkov et al., 2017).

5 CONCLUSION

We show the adversarial training of dense DNNs incurs a severe robust generalization gap, which
can be effectively and efficiently resolved by injecting appropriate sparsity. Our proposed Robust
Bird and Flying Bird(+) with static and dynamic sparsity, significantly mitigate the robust generalization gap while retaining competitive standard/robust accuracy, besides substantially reduced
computation. Our future works plan to investigate channel- and block-wise sparse structures.


-----

REFERENCES

Alessandro Achille, Matteo Rovere, and Stefano Soatto. Critical learning periods in deep networks. In International Conference on Learning Representations, 2019. [URL https://](https://openreview.net/forum?id=BkeStsCcKQ)
[openreview.net/forum?id=BkeStsCcKQ.](https://openreview.net/forum?id=BkeStsCcKQ)

Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420,
2018.

Emilio Rafael Balda, Arash Behboodi, Niklas Koep, and Rudolf Mathar. Adversarial risk bounds
for neural networks through sparsity based compression. arXiv preprint arXiv:1906.00698, 2019.

Jason Bunk, Srinjoy Chattopadhyay, BS Manjunath, and Shivkumar Chandrasekaran. Adversarially
optimized mixup for robust classification. arXiv preprint arXiv:2103.11589, 2021.

Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
_ieee symposium on security and privacy (sp), pp. 39–57. IEEE, 2017._

Chen Chen, Jingfeng Zhang, Xilie Xu, Tianlei Hu, Gang Niu, Gang Chen, and Masashi Sugiyama.
Guided interpolation for adversarial training. arXiv preprint arXiv:2102.07327, 2021a.

Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Michael Carbin, and
Zhangyang Wang. The lottery tickets hypothesis for supervised and self-supervised pre-training
in computer vision models. arXiv preprint arXiv:2012.06908, 2020a.

Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Zhangyang Wang, and
Michael Carbin. The lottery ticket hypothesis for pre-trained bert networks. _arXiv preprint_
_arXiv:2007.12223, 2020b._

Tianlong Chen, Sijia Liu, Shiyu Chang, Yu Cheng, Lisa Amini, and Zhangyang Wang. Adversarial
robustness: From self-supervised pre-training to fine-tuning. In Proceedings of the IEEE/CVF
_Conference on Computer Vision and Pattern Recognition, pp. 699–708, 2020c._

Tianlong Chen, Yu Cheng, Zhe Gan, Jingjing Liu, and Zhangyang Wang. Ultra-data-efficient gan
training: Drawing a lottery ticket first, then training it toughly. arXiv preprint arXiv:2103.00397,
2021b.

Tianlong Chen, Yongduo Sui, Xuxi Chen, Aston Zhang, and Zhangyang Wang. A unified lottery
ticket hypothesis for graph neural networks, 2021c.

Tianlong Chen, Zhenyu Zhang, Sijia Liu, Shiyu Chang, and Zhangyang Wang. Long live the lottery:
The existence of winning tickets in lifelong learning. In International Conference on Learning
_[Representations, 2021d. URL https://openreview.net/forum?id=LXMSvPmsm0g.](https://openreview.net/forum?id=LXMSvPmsm0g)_

Tianlong Chen, Zhenyu Zhang, Sijia Liu, Shiyu Chang, and Zhangyang Wang. Robust overfitting
may be mitigated by properly learned smoothening. In International Conference on Learning
_[Representations, 2021e. URL https://openreview.net/forum?id=qZzy5urZw9.](https://openreview.net/forum?id=qZzy5urZw9)_

Tianlong Chen, Xuxi Chen, Xiaolong Ma, Yanzhi Wang, and Zhangyang Wang. Coarsening the
granularity: Towards structurally sparse lottery tickets. arXiv preprint arXiv:2202.04736, 2022.

Xuxi Chen, Tianlong Chen, Zhenyu Zhang, and Zhangyang Wang. You are caught stealing my winning lottery ticket! making a lottery ticket claim its ownership. Advances in Neural Information
_Processing Systems, 34, 2021f._

Xuxi Chen, Zhenyu Zhang, Yongduo Sui, and Tianlong Chen. Gans can play lottery tickets too. In
_[International Conference on Learning Representations, 2021g. URL https://openreview.](https://openreview.net/forum?id=1AoMhc_9jER)_
[net/forum?id=1AoMhc_9jER.](https://openreview.net/forum?id=1AoMhc_9jER)

Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble
of diverse parameter-free attacks. In International Conference on Machine Learning, pp. 2206–
2216. PMLR, 2020.


-----

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248–255. Ieee, 2009.

Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing
performance. arXiv preprint arXiv:1907.04840, 2019.

Guneet S. Dhillon, Kamyar Azizzadenesheli, Jeremy D. Bernstein, Jean Kossaifi, Aran Khanna,
Zachary C. Lipton, and Animashree Anandkumar. Stochastic activation pruning for robust
adversarial defense. In International Conference on Learning Representations, 2018a. URL
[https://openreview.net/forum?id=H1uR4GZRZ.](https://openreview.net/forum?id=H1uR4GZRZ)

Guneet S Dhillon, Kamyar Azizzadenesheli, Zachary C Lipton, Jeremy Bernstein, Jean Kossaifi,
Aran Khanna, and Anima Anandkumar. Stochastic activation pruning for robust adversarial defense. arXiv preprint arXiv:1803.01442, 2018b.

Shaojin Ding, Tianlong Chen, and Zhangyang Wang. Audio lottery: Speech recognition made
ultra-lightweight, noise-robust, and transferable. In International Conference on Learning Repre_[sentations, 2022. URL https://openreview.net/forum?id=9Nk6AJkVYB.](https://openreview.net/forum?id=9Nk6AJkVYB)_

Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial attacks with momentum. In Proceedings of the IEEE Conference on Computer
_Vision and Pattern Recognition, 2018._

Yinpeng Dong, Ke Xu, Xiao Yang, Tianyu Pang, Zhijie Deng, Hang Su, and Jun Zhu. Exploring
memorization in adversarial training. arXiv preprint arXiv:2106.01606, 2021.

Gintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M Roy. A study of the effect of jpg
compression on adversarial images. arXiv preprint arXiv:1608.00853, 2016.

Logan Engstrom, Andrew Ilyas, and Anish Athalye. Evaluating and understanding the robustness
of adversarial logit pairing. arXiv preprint arXiv:1807.10272, 2018.

Utku Evci, Fabian Pedregosa, Aidan Gomez, and Erich Elsen. The difficulty of training sparse
neural networks. arXiv preprint arXiv:1906.10732, 2019.

Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery:
Making all tickets winners. In International Conference on Machine Learning, pp. 2943–2952.
PMLR, 2020a.

Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery:
Making all tickets winners. In Hal Daum´e III and Aarti Singh (eds.), Proceedings of the 37th
_International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning_
_Research, pp. 2943–2952. PMLR, 13–18 Jul 2020b._ [URL http://proceedings.mlr.](http://proceedings.mlr.press/v119/evci20a.html)
[press/v119/evci20a.html.](http://proceedings.mlr.press/v119/evci20a.html)

Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural
[networks. In International Conference on Learning Representations, 2019. URL https://](https://openreview.net/forum?id=rJl-b3RcF7)
[openreview.net/forum?id=rJl-b3RcF7.](https://openreview.net/forum?id=rJl-b3RcF7)

Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, and Michael Carbin. Linear mode
connectivity and the lottery ticket hypothesis. In ICML, 2020.

Yonggan Fu, Qixuan Yu, Yang Zhang, Shang Wu, Xu Ouyang, David Daniel Cox, and Yingyan Lin.
Drawing robust scratch tickets: Subnetworks with inborn robustness are found within randomly
initialized networks. In Thirty-Fifth Conference on Neural Information Processing Systems, 2021.

Zhe Gan, Yen-Chun Chen, Linjie Li, Tianlong Chen, Yu Cheng, Shuohang Wang, and Jingjing Liu.
Playing lottery tickets with vision and language. arXiv preprint arXiv:2104.11832, 2021.

Ji Gao, Beilun Wang, Zeming Lin, Weilin Xu, and Yanjun Qi. Deepcloak: Masking deep neural
network models for robustness against adversarial samples. arXiv preprint arXiv:1702.06763,
2017.


-----

Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
[examples. In International Conference on Learning Representations, 2015. URL http://](http://arxiv.org/abs/1412.6572)
[arxiv.org/abs/1412.6572.](http://arxiv.org/abs/1412.6572)

Shupeng Gui, Haotao N Wang, Haichuan Yang, Chen Yu, Zhangyang Wang, and Ji Liu. Model
compression with adversarial robustness: A unified optimization framework. Advances in Neural
_Information Processing Systems, 32:1285–1296, 2019._

Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. Countering adversarial
images using input transformations. In International Conference on Learning Representations,
[2018a. URL https://openreview.net/forum?id=SyJ7ClWCb.](https://openreview.net/forum?id=SyJ7ClWCb)

Yiwen Guo, Chao Zhang, Changshui Zhang, and Yurong Chen. Sparse dnns with improved adversarial robustness. arXiv preprint arXiv:1810.09619, 2018b.

Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015a.

Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections for
efficient neural network. In Advances in neural information processing systems, pp. 1135–1143,
2015b.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pp. 770–778, 2016.

Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1389–1397,
2017.

Matthias Hein and Maksym Andriushchenko. Formal guarantees on the robustness of a classifier
against adversarial manipulation. In Advances in Neural Information Processing Systems, pp.
2266–2276, 2017.

Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv
_preprint arXiv:1503.02531, 2015._

Ting-Kuei Hu, Tianlong Chen, Haotao Wang, and Zhangyang Wang. Triple wins: Boosting accuracy, robustness and efficiency together by enabling input-adaptive inference. In International
_Conference on Learning Representations, 2019._

Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. _arXiv preprint_
_arXiv:1803.05407, 2018._

Gauri Jagatap, Animesh Basak Chowdhury, Siddharth Garg, and Chinmay Hegde. Adversarially
robust learning via entropic regularization. arXiv preprint arXiv:2008.12338, 2020.

Siddhant M Jayakumar, Razvan Pascanu, Jack W Rae, Simon Osindero, and Erich Elsen. Top-kast:
Top-k always sparse training. arXiv preprint arXiv:2106.03517, 2021.

Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang. Robust pre-training by adversarial
contrastive learning. arXiv preprint arXiv:2010.13337, 2020.

A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s
_thesis, Department of Computer Science, University of Toronto, 2009._

Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
_arXiv preprint arXiv:1607.02533, 2016._

Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural
_information processing systems, pp. 598–605, 1990._

Namhoon Lee, Thalaiyasingam Ajanthan, and Philip H. S. Torr. Snip: Single-shot network pruning
based on connection sensitivity, 2019.


-----

Saehyung Lee, Hyungyu Lee, and Sungroh Yoon. Adversarial vertex mixup: Toward better adversarially robust generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision
_and Pattern Recognition, pp. 272–281, 2020._

Bai Li, Shiqi Wang, Yunhan Jia, Yantao Lu, Zhenyu Zhong, Lawrence Carin, and Suman
Jana. Towards practical lottery ticket hypothesis for adversarial training. _arXiv preprint_
_arXiv:2003.05733, 2020._

F. Liao, M. Liang, Y. Dong, T. Pang, X. Hu, and J. Zhu. Defense against adversarial attacks using
high-level representation guided denoiser. In 2018 IEEE/CVF Conference on Computer Vision
_and Pattern Recognition, pp. 1778–1787, 2018._

Qiang Liu, Lemeng Wu, and Dilin Wang. Splitting steepest descent for growing neural architectures.
_arXiv preprint arXiv:1910.02366, 2019._

Shiwei Liu, Decebal Constantin Mocanu, Yulong Pei, and Mykola Pechenizkiy. Selfish sparse rnn
training. arXiv preprint arXiv:2101.09048, 2021a.

Shiwei Liu, Lu Yin, Decebal Constantin Mocanu, and Mykola Pechenizkiy. Do we actually need
dense over-parameterization? in-time over-parameterization in sparse training. arXiv preprint
_arXiv:2102.02887, 2021b._

Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. In Proceedings of the European Conference on Computer Vision (ECCV),
pp. 369–385, 2018.

Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE
_international conference on computer vision, pp. 2736–2744, 2017._

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learn_[ing Representations, 2018a. URL https://openreview.net/forum?id=rJzIBfZAb.](https://openreview.net/forum?id=rJzIBfZAb)_

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learn_[ing Representations, 2018b. URL https://openreview.net/forum?id=rJzIBfZAb.](https://openreview.net/forum?id=rJzIBfZAb)_

Decebal Constantin Mocanu, Elena Mocanu, Phuong H Nguyen, Madeleine Gibescu, and Antonio
Liotta. A topological insight into restricted boltzmann machines. Machine Learning, 104(2):
243–270, 2016.

Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural
networks. In International Conference on Machine Learning, pp. 2498–2507. PMLR, 2017.

Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation
for neural network pruning. In Proceedings of the IEEE Conference on Computer Vision and
_Pattern Recognition, pp. 11264–11272, 2019._

Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal Frossard. Robustness via curvature regularization, and vice versa. In Proceedings of the IEEE Conference on
_Computer Vision and Pattern Recognition, pp. 9078–9086, 2019._

Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein, and Dietrich Klakow.
Logit pairing methods can fool gradient-based attacks. arXiv preprint arXiv:1810.12042, 2018.

Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks
by dynamic sparse reparameterization. In International Conference on Machine Learning, pp.
4646–4655. PMLR, 2019.


-----

Preetum Nakkiran. Adversarial robustness may be at odds with simplicity. _arXiv preprint_
_arXiv:1901.00532, 2019._

Ozan Ozdenizci and Robert Legenstein. Training adversarially robust sparse networks via bayesian[¨]
connectivity sampling. In International Conference on Machine Learning, pp. 8314–8324.
PMLR, 2021.

Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, and Jun Zhu. Bag of tricks for adversarial
[training. In International Conference on Learning Representations, 2021. URL https://](https://openreview.net/forum?id=Xb8xvrtB8Ce)
[openreview.net/forum?id=Xb8xvrtB8Ce.](https://openreview.net/forum?id=Xb8xvrtB8Ce)

Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John C Duchi, and Percy Liang. Adversarial
training can hurt generalization. In ICMLW, 2019.

Md Aamir Raihan and Tor M Aamodt. Sparse weight activation training. _arXiv preprint_
_arXiv:2001.01969, 2020._

William T Redman, Tianlong Chen, Akshunna S Dogra, and Zhangyang Wang. Universality
of deep neural network lottery tickets: A renormalization group perspective. _arXiv preprint_
_arXiv:2110.03210, 2021._

Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural
network pruning. In International Conference on Learning Representations, 2020.

Leslie Rice, Eric Wong, and Zico Kolter. Overfitting in adversarially robust deep learning. In
Hal Daum´e III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Ma_chine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 8093–8104._
PMLR, 13–18 Jul 2020. [URL http://proceedings.mlr.press/v119/rice20a.](http://proceedings.mlr.press/v119/rice20a.html)
[html.](http://proceedings.mlr.press/v119/rice20a.html)

Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry. Adversarially robust generalization requires more data. In NeurIPS, pp. 5014–5026, 2018.

Vikash Sehwag, Shiqi Wang, Prateek Mittal, and Suman Jana. Towards compact and robust deep
neural networks. arXiv preprint arXiv:1906.06110, 2019.

Vikash Sehwag, Shiqi Wang, Prateek Mittal, and Suman Jana. Hydra: Pruning adversarially robust
neural networks. arXiv preprint arXiv:2002.10509, 2020.

Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh,
and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, pp. 618–626,
2017.

Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S
Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free! _arXiv preprint_
_arXiv:1904.12843, 2019._

Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.

Vasu Singla, Sahil Singla, David Jacobs, and Soheil Feizi. Low curvature activations reduce overfitting in adversarial training. arXiv preprint arXiv:2102.07861, 2021.

Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi´egas, and Martin Wattenberg. Smoothgrad:
removing noise by adding noise. arXiv preprint arXiv:1706.03825, 2017.

Chuanbiao Song, Kun He, Jiadong Lin, Liwei Wang, and John E Hopcroft. Robust local features
for improving the generalization of adversarial training. arXiv preprint arXiv:1909.10147, 2019.

David Stutz, Matthias Hein, and Bernt Schiele. Relating adversarially robust generalization to flat
minima. arXiv preprint arXiv:2104.04448, 2021.

Ke Sun, Zhanxing Zhu, and Zhouchen Lin. Towards understanding adversarial examples systematically: Exploring data size, task and model factors. arXiv preprint arXiv:1902.11019, 2019.


-----

Jihoon Tack, Sihyun Yu, Jongheon Jeong, Minseon Kim, Sung Ju Hwang, and Jinwoo Shin. Consistency regularization for adversarial robustness. arXiv preprint arXiv:2103.04623, 2021.

Hidenori Tanaka, Daniel Kunin, Daniel LK Yamins, and Surya Ganguli. Pruning neural networks
without any data by iteratively conserving synaptic flow. arXiv preprint arXiv:2006.05467, 2020.

Artem Vysogorets and Julia Kempe. Connectivity matters: Neural network pruning through the lens
of effective sparsity. arXiv preprint arXiv:2107.02306, 2021.

Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by
preserving gradient flow, 2020.

Jianyu Wang and Haichao Zhang. Bilateral adversarial training: Towards fast training of more
robust models against adversarial attacks. In Proceedings of the IEEE International Conference
_on Computer Vision, pp. 6629–6638, 2019._

Siyue Wang, Xiao Wang, Shaokai Ye, Pu Zhao, and Xue Lin. Defending dnn adversarial attacks with
pruning and logits augmentation. In 2018 IEEE Global Conference on Signal and Information
_Processing (GlobalSIP), pp. 1144–1148. IEEE, 2018._

Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better than free: Revisiting adversarial training. In
_[International Conference on Learning Representations, 2020. URL https://openreview.](https://openreview.net/forum?id=BJx040EFvH)_
[net/forum?id=BJx040EFvH.](https://openreview.net/forum?id=BJx040EFvH)

Dongxian Wu, Yisen Wang, and Shu-tao Xia. Revisiting loss landscape for adversarial robustness.
_arXiv preprint arXiv:2004.05884, 2020a._

Dongxian Wu, Shu-Tao Xia, and Yisen Wang. Adversarial weight perturbation helps robust generalization. In NeurIPS, 2020b.

Lemeng Wu, Mao Ye, Qi Lei, Jason D Lee, and Qiang Liu. Steepest descent neural architecture optimization: Escaping local optimum with signed neural splitting. arXiv preprint arXiv:2003.10392,
2020c.

Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. Mitigating adversarial
effects through randomization. In International Conference on Learning Representations, 2018.
[URL https://openreview.net/forum?id=Sk9yuql0Z.](https://openreview.net/forum?id=Sk9yuql0Z)

Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep
neural networks. arXiv preprint arXiv:1704.01155, 2017.

Dingqing Yang, Amin Ghasemazar, Xiaowei Ren, Maximilian Golub, Guy Lemieux, and Mieszko
Lis. Procrustes: a dataflow and accelerator for sparse deep neural network training. In 2020
_53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 711–724._
IEEE, 2020.

Shaokai Ye, Kaidi Xu, Sijia Liu, Hao Cheng, Jan-Henrik Lambrechts, Huan Zhang, Aojun Zhou,
Kaisheng Ma, Yanzhi Wang, and Xue Lin. Adversarial robustness vs. model compression, or
both? In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 111–
120, 2019.

Haoran You, Chaojian Li, Pengfei Xu, Yonggan Fu, Yue Wang, Xiaohan Chen, Richard G. Baraniuk,
Zhangyang Wang, and Yingyan Lin. Drawing early-bird tickets: Toward more efficient training of
[deep networks. In International Conference on Learning Representations, 2020. URL https:](https://openreview.net/forum?id=BJxsrgStvr)
[//openreview.net/forum?id=BJxsrgStvr.](https://openreview.net/forum?id=BJxsrgStvr)

Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
_on Machine Learning, pp. 7472–7482. PMLR, 2019._

Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, and Mohan Kankanhalli. Attacks which do not kill training make adversarial learning stronger. In International
_conference on machine learning, pp. 11278–11287. PMLR, 2020._


-----

Jingfeng Zhang, Xilie Xu, Bo Han, Tongliang Liu, Gang Niu, Lizhen Cui, and Masashi Sugiyama.
Noilin: Do noisy labels always hurt adversarial training? _arXiv preprint arXiv:2105.14676,_
2021a.

Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and Mohan Kankanhalli.
Geometry-aware instance-reweighted adversarial training. In International Conference on Learn_ing Representations, 2021b._

Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Why lottery ticket wins? a
[theoretical perspective of sample complexity on sparse neural networks, 2021c. URL https:](https://openreview.net/forum?id=8pz6GXZ3YT)
[//openreview.net/forum?id=8pz6GXZ3YT.](https://openreview.net/forum?id=8pz6GXZ3YT)

Tianyun Zhang, Kaiqi Zhang, Shaokai Ye, Jian Tang, Wujie Wen, Xue Lin, Makan Fardad, and
Yanzhi Wang. Adam-admm: A unified, systematic framework of structured weight pruning for
dnns. arXiv preprint arXiv:1807.11091, 2018.

Zhenyu Zhang, Xuxi Chen, Tianlong Chen, and Zhangyang Wang. Efficient lottery ticket finding:
Less data is more. In International Conference on Machine Learning, pp. 12380–12390. PMLR,
2021d.

Dawei Zhou, Nannan Wang, Xinbo Gao, Bo Han, Jun Yu, Xiaoyu Wang, and Tongliang Liu. Improving white-box robustness of pre-processing defenses via joint adversarial training. arXiv
_preprint arXiv:2106.05453, 2021._

Hao Zhou, Jose M Alvarez, and Fatih Porikli. Less is more: Towards compact cnns. In European
_Conference on Computer Vision, pp. 662–677. Springer, 2016._

Bojia Zi, Shihao Zhao, Xingjun Ma, and Yu-Gang Jiang. Revisiting adversarial robustness distillation: Robust soft labels make student better. arXiv preprint arXiv:2108.07969, 2021.


-----

A1 MORE TECHNIQUE DETAILS

**Algorithms of Robust Bird and Flying Bird(+).** Here we present the detailed procedure to identify robust bird and flying bird(+), as summarized in algorithm 1 and 2. Note that for the increasing
frequency on Line 10 and 11 in algorithm 2, we compare the measurements stored in the queue
between two consequent epochs and calculate the frequency of increasing.

**Algorithm 1: Finding a Robust Bird**
**Input: f** (x; θ0) w. initialization θ0, target sparsity s%, FIFO queue Q with length l, threshold τ
**Output: Robust bird f** (x; mt∗ _θT)_
_⊙_

**1 while t < tmax do**

**2** Update network parameters θt _θt_ 1 via standard training

**3** Apply static pruning towards target sparsity ← _−_ _s% and obtain the sparse mask mt_

**4** Calculate the Hamming distance δH(mt, mt−1), append result to Q

**5** _t ←_ _t + 1_

**6** **if max(Q) < τ then**

**7** _t[∗]_ _←_ _t_

**8** Rewind f (x; mt[∗] _θt[∗]_ ) _f_ (x; mt[∗] _θ0)_
_⊙_ _→_ _⊙_

**9** Training f (x; mt[∗] _θ0) via PGD-AT for T epochs_
_⊙_

**10** **return f** (x; mt∗ _θT)_
_⊙_

**11** **end**

**12 end**


**Algorithm 2: Finding a Flying Bird(+)**
**Input: Initialization parameters θ0, sparse masks m of sparsity s%, FIFO queue Qp andQg**
with length l, pruning and growth increasing ratio δp and δg, update threshold ϵ,
optimize interval ∆t, parameter update ratio k%, ratio update starting point tstart

**Output: Flying bird(+) f** (x; m ⊙ _θT)_

**1 while t < T do**

**2** Update network parameters θt _θt_ 1 via PGD-AT;

**3** # Record training statistics ← _−_

**4** Add robust generalization gap between train and validation set to Qp

**5** Add robust validation loss to Qg

**6** # Update sparse masks m

**7** **if (t mod ∆t) == 0 then**

**8** |---Optional for Flying Bird+---|

**9** # Update pruning and growth ratio p%, g%

**101112** **ifif|---Optional for Flying Bird+---| t > t t > tstartstart and increasing frequency of and increasing frequency of Q Qpg ≥ ≥** _ϵϵ:: p g = (1 + = (1 + δ δpg)) × × k k else else p g = = k k_

**13** _Prune p% parameters with smallest weight magnitude_

**14** _Grow g% parameters with largest gradient_

**15** Update sparse mask m accordingly

**16** **end**

**17 end**


A2 MORE IMPLEMENTATION DETAILS

A2.1 OTHER COMMON DETAILS

We select two checkpoints during training: best, which has the best RA values on the validation
set, and final, i.e., the last checkpoint. And we report both RA and SA of these two checkpoints
on test sets. Apart from the robust generalization gap, we also show the extent of robust overfitting
numerically by the difference of RA between best and final. Furthermore, we calculate the FLOPs


-----

at both training and inference stages to evaluate the prices of obtaining and exploiting the subnetworks respectively, in which we approximate the FLOPs of the back-propagation to be twice that of
forwarding propagation (Yang et al., 2020).

A2.2 MORE DETAILS ABOUT ROBUST BIRD


For the experiments of RB tickets finding, we comprehensively study three training regimes: standard training with stochastic gradient descent (SGD), adversarial training with PGD-10 AT (Madry
et al., 2018b), and Fast AT (Wong et al., 2020). Following Pang et al. (2021), we train the network
with an SGD optimizer of 0.9 momentum and 5 × 10[−][4] weight decay. We use a batch size of 128.
For the experiments of PGD-10 AT, we adopt the ℓ PGD attack with a maximum perturbation
_∞_
_ϵ = 8/255 and a step size α = 2/255. And the learning rate starts from 0.1, then decays by ten_
times at 50, 150 epoch. As for fast AT, we use a cyclic schedule with a maximum learning rate
equals 0.2.

A2.3 MORE DETAILS ABOUT FLYING BIRD(+)


For the experiments of Flying Bird+, the increasing ratio of pruning and growth δp, δq is kept default
to 0.4% and 0.05%, respectively.

A3 MORE EXPERIMENT RESULTS


A3.1 MORE RESULTS ABOUT ROBUST BIRD

**Accuracy during RB Tickets Finding** Figure A7 shows the curve of standard test accuracy during
the training phase of RB ticket finding. We can observe the SGD training scheme develops highlevel network connections much faster than the others, which provides a possible explanation for the
superior quality of RB tickets from SGD.


RB Ticket Finding Performance

10 15 20 25 30

|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|
|---|---|---|---|---|---|---|---|---|---|
|||||||||||
|||||||||||
|||||||||||
|||||||||||
||||||||PGD-10|||
||||||||SGD|||
||||||||FAST A|T||
|||||||||||


Epoch


80

70

60

50

40

30


Figure A7: Standard accuracy (SA) of PGD-10, SGD, and Fast AT during the RB ticket finding phase.

**Mask Similarity Visualization.** Figure A8 visualizes the dynamic similarity scores for each epoch
among masks found via SGD, Fast AT, and PGD-10. Specifically, the similarity scores (You et al.,
2020) reflect the Hamming distance between a pair of masks. We notice that masks found by SGD
and PGD-10 share more common structures. A possible reason is that Fast AT usually adopts a
cyclic learning rate schedule, while SGD and PGD use a multi-step decay schedule.


**Different training regimes for finding RB tickets.** We denote the subnetworks identified by standard training with SGD, adversarial training with Fast AT (Wong et al., 2020) and adversarial train

-----

20 40 60 80 100

Fast AT Mask


20 40 60 80 100

Fast AT Mask


20 40 60 80 100

PGD-10 Mask


20

40

60

80

100


20

40

60

80

100


20

40

60

80

100


0.50 0.55 0.60 0.65 0.70 0.75

Figure A8: Similarity scores by epoch among masks found via Fast AT, SGD, and PGD-10. A
brighter color denotes higher similarity.


Table A6: Comparison results of different training regimes for RB ticket finding on CIFAR-100 with


|ResNet-18. The subnetworks at 90% and 95% are selected here.|t 90% and 95% are select|ted here.|Col4|
|---|---|---|---|
|Roubst Accuarcy Standard Accuarcy Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. Generalization|Roubst Accuarcy|Standard Accuarcy||
||Best Final Diff.|Best Final Diff.||
|0 Baseline|26.93 19.62 7.31|52.03 53.91 −1.88|54.56|
|SGD tickets 90 Fast AT tickets PGD-10 tickets|25.83 23.40 2.43 25.15 22.88 2.27 25.34 22.96 2.38|49.35 53.51 −4.16 51.00 51.75 −0.75 52.01 53.27 −1.26|18.37 ↓36.19 20.23 ↓34.33 20.03 ↓34.53|
|SGD tickets 95 Fast AT tickets PGD-10 tickets|24.77 24.12 0.65 23.50 22.46 1.04 24.44 23.77 0.67|49.88 50.89 −1.01 41.67 43.19 −1.52 49.30 50.65 −1.35|9.18 ↓45.38 9.53 ↓45.03 9.86 ↓44.70|


ing with PGD-10 AT as SGD tickets, Fast AT tickets, and PGD-10 tickets, respectively. Table A6
demonstrate the SGD tickets has the best performance.

**Loss Landscape Visualization** We visualize the loss landscape of the dense network, random
pruned subnetwork, and robust bird tickets at 30% sparsity in Figure A9. Compared with the dense
model and random pruned subnetwork, RB tickets found by the standard training shows much flatter
loss landscapes, which provide a high-quality starting point for further robustification.

A3.2 MORE RESULTS ABOUT FLYING BIRD(+)


**Excluding Obfuscated Gradients.** To exclude this possibility of gradient masking, we show that
our methods maintain improved robustness under unseen transfer attacks. As shown in Table A7,
the left part represents the testing accuracy of perturbed test samples from an unseen robust model,
and the right part shows the transfer testing performance on an unseen robust model (here we use a
separately robustified ResNet-50 with PGD-10 on CIFAR-100).

**Performance under Improved Attacks.** We report the performance of both RB and FB(+) under
Auto-Attack (Croce & Hein, 2020) and CW Attack (Carlini & Wagner, 2017). For Auto-Attack,
we keep the default setting with ϵ = 2558 [. And for CW Attack we perform][ 1][ search step on C with]

an initial constant of 0.1. And we use 100 iterations for each search step with the learning rate of
0.01. As shown in Table A8, both RB and FB(+) outperform the dense counterpart in terms of robust
generalization. And FB+ achieves superior performance.

**More Datasets and Architectures** We report more results of different sparsification methods
across diverse datasets and architectures at Table A9, A10, A11 and A12, from which we observe
our approaches are capable of improving robust generalization and mitigating robust overfitting.


-----

Dense Models Random Pruning (30%) RB Tickets (30%)

Figure A9: Loss landscapes visualizations (Engstrom et al., 2018; Chen et al., 2021e) of the dense
model (unpruned), random pruned subnetwork at 30% sparsity, and Robust Bird (RB) tickets at
30% sparsity found by the standard training. The ResNet-18 backbone with the same original
_initialization on CIFAR-10 is adopted here. Results demonstrate that RB tickets offer a smoother_
and flatter starting point for further robustification in the second stage.

Table A7: Transfer attack performance from/on an unseen non-robust model, where the attacks are generated
by/applied to the non-robust model. The robust generalization gap is also calculated based on transfer attack
accuracies between train and test sets. We use ResNet-18 on CIFAR-10/100 and sub-networks at 80% sparsity.



|Transfer Attack from Unseen Model Transfer Attack on Unseen Model Dataset Settings Accuracy Robust Accuracy Robust Best Final Diff. Generalization Best Final Diff. Generalization|Transfer Attack from Unseen Model|Col3|Transfer Attack on Unseen Model|Col5|
|---|---|---|---|---|
||Accuracy||Accuracy||
||Best Final Diff.||Best Final Diff.||
|Baseline Robust Bird CIFAR-10 Flying Bird Flying Bird+|79.68 82.03 −2.35 77.33 81.04 −3.71 79.13 82.17 −3.04 79.47 81.90 −2.43|16.43 12.18 13.49 11.85|70.48 79.85 −9.37 73.17 77.03 −3.86 71.59 77.19 −5.60 70.43 76.00 −5.57|11.84 11.49 11.88 11.42|
|Baseline Robust Bird CIFAR-100 Flying Bird Flying Bird+|50.51 52.15 −1.64 47.25 51.74 −4.49 51.80 53.52 −1.72 50.72 53.56 −2.84|45.91 28.80 31.98 25.09|48.67 54.48 −5.81 47.47 50.90 −3.43 45.56 50.61 −5.05 47.04 49.43 −2.39|36.98 35.82 35.39 35.09|


**Distributions of Adopted Sparse Initialization.** We report the layer-wise sparsity of different
initial sparse masks. As shown in Figure A10, we observe that subnetworks generally have better
performance when the top layers remain most of the parameters.

**Training Curve of Flying Bird+.** Figure A11 shows the training curve of Flying Bird+, in which
the red dotted lines represent the time for increasing the pruning ratio and the green dotted lines for
growth ratio. The detailed training curve demonstrates the flexibility of flying bird+ for dynamically
adjusting the sparsity levels.

A4 EXTRA RESULTS AND DISCUSSION

We sincerely appreciate all anonymous reviewers’ and area chairs’ constructive discussions for improving this paper. Extra results and discussions are presented in this section.


-----

Table A8: Evaluation under improved attacks (i.e., Auto-Attack and CW-Attack) on CIFAR-10/100 with

|ResNet-18 at 80% sparsity. The robust generalization gap is computed under improved attacks.|The robust generalization gap is computed|Col3|under improved attacks.|Col5|
|---|---|---|---|---|
|Auto-Attack CW-Attack Dataset Settings Accuracy Robust Accuracy Robust Best Final Diff. Generalization Best Final Diff. Generalization|Auto-Attack||CW-Attack||
||Accuracy||Accuracy||
||Best Final Diff.||Best Final Diff.||
|Baseline Robust Bird CIFAR-10 Flying Bird Flying Bird+|47.41 41.59 5.82 45.90 42.45 3.45 47.55 43.57 3.98 47.06 44.09 3.17|35.30 21.58 ↓13.72 26.55 ↓8.75 21.73 ↓13.57|75.76 66.13 9.63 73.95 73.52 0.43 75.30 72.08 3.22 76.00 73.83 2.17|30.39 17.67 ↓12.72 21.77 ↓8.62 17.77 ↓12.62|
|Baseline Robust Bird CIFAR-100 Flying Bird Flying Bird+|23.16 17.68 5.48 21.29 18.00 3.29 22.74 19.44 3.30 22.90 20.31 2.59|49.73 21.72 ↓28.01 25.18 ↓24.55 19.05 ↓30.68|45.83 36.21 9.62 43.30 42.39 0.91 46.23 42.36 3.87 45.86 43.90 1.96|57.52 30.82 ↓26.70 35.50 ↓22.02 26.76 ↓30.76|



Table A9: More results of different sparcification methods on CIFAR-10 with ResNet-18.




|Robust Accuracy Standard Accuracy Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. Generalization|Robust Accuracy|Standard Accuracy|Col4|
|---|---|---|---|
||Best Final Diff.|Best Final Diff.||
|0 Baseline|51.10 43.61 7.49|81.15 83.38 −2.23|38.82|
|Small Dense Random Pruning OMP SNIP GraSP 95 SynFlow IGQ Robust Bird Flying Bird Flying Bird+|45.99 44.55 1.44 45.64 44.18 1.46 47.08 46.23 0.85 48.18 46.72 1.46 48.58 47.15 1.43 48.93 48.22 0.71 48.82 47.56 1.26 47.53 46.48 1.05 49.62 48.46 1.16 49.37 48.84 0.53|74.26 75.64 −1.38 75.20 75.20 0.00 78.77 79.36 −0.59 78.55 79.21 −0.66 78.95 79.44 −0.49 78.70 78.90 −0.20 79.44 79.76 −0.32 78.33 78.78 −0.45 78.12 81.43 −3.31 80.33 80.28 0.05|7.87 ↓30.95 7.96 ↓30.86 12.01 ↓26.81 9.58 ↓29.24 10.37 ↓28.45 8.25 ↓30.57 9.33 ↓29.49 9.20 ↓29.62 13.32 ↓25.52 9.27 ↓29.55|


1.0 Uniform

0.8 GraSP

0.6 SNIP

SynFlow

Sparsity 0.4 IGQ

0.2 ERK

0.0

conv1 layer1.0.conv1 layer1.0.conv2 layer1.1.conv1 layer1.1.conv2 layer2.0.conv1 layer2.0.conv2 layer2.0.shortcut.0 layer2.1.conv1 layer2.1.conv2 layer3.0.conv1 layer3.0.conv2 layer3.0.shortcut.0 layer3.1.conv1 layer3.1.conv2 layer4.0.conv1 layer4.0.conv2 layer4.0.shortcut.0 layer4.1.conv1 layer4.1.conv2 linear

Layer Name

Figure A10: Layer-wise sparisty of different initial sparse masks with ResNet-18


95


A4.1 MORE RESULTS OF DIFFERENT SPARSITY

We report more results of subnetworks with 40/60% sparsity on CIFAR-10/100 with ResNet-18
and VGG-16. As shown in Table A13, A14, A15 and A16, our flying bird(+) achieves consistent
improvement than baseline unpruned networks, in terms of 2.45 ∼ 19.81% narrower robust generalization gaps with comparable RA and SA performance.

A4.2 MORE RESULTS ON WIDERESNET

We further evaluate our flying bird(+) with WideResNet-34-10 on CIFAR-10 and report the results
on Table A17. We can observe that compared with the dense network, our methods significantly
shrink the robust generalization gap by up to 13.14% and maintain comparable RA/SA performance.


-----

Table A10: More results of different sparcification methods on CIFAR-10 with VGG-16.




|Robust Accuracy Standard Accuracy Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. Generalization|Robust Accuracy|Standard Accuracy|Col4|
|---|---|---|---|
||Best Final Diff.|Best Final Diff.||
|0 Baseline|48.33 42.73 5.60|76.84 79.73 −2.89|28.00|
|Random Pruning OMP SNIP GraSP SynFlow 80 IGQ Robust Bird Flying Bird Flying Bird+|46.14 40.33 5.81 47.90 43.19 4.71 48.03 43.17 4.86 47.91 42.34 5.57 48.47 45.32 3.15 48.57 44.25 4.32 47.69 41.66 6.03 48.43 44.65 3.78 48.25 45.24 3.01|74.42 76.68 −2.26 76.60 80.02 −3.42 76.68 80.08 −3.40 75.74 78.87 −3.13 77.62 79.09 −1.47 77.51 80.01 −2.50 75.32 78.58 −3.26 77.53 79.72 −2.19 77.48 79.55 −2.07|21.01 ↓6.99 24.97 ↓3.03 24.71 ↓3.29 23.65 ↓4.35 20.17 ↓7.83 22.79 ↓5.21 23.57 ↓4.43 21.01 ↓6.99 17.75 ↓10.25|
|Random Pruning OMP SNIP GraSP SynFlow 90 IGQ Robust Bird Flying Bird Flying Bird+|44.33 40.33 4.00 47.84 43.34 4.50 47.76 44.27 3.49 45.96 42.12 3.84 47.54 45.79 1.75 47.79 45.12 2.67 47.09 44.13 2.96 48.45 45.55 2.90 48.39 46.26 2.13|71.27 74.46 −3.19 75.60 79.10 −3.50 75.92 79.62 −3.70 75.19 77.03 −1.84 78.43 78.70 −0.27 74.87 79.19 −4.32 75.53 78.36 −2.83 75.82 79.21 −3.39 78.73 79.12 −0.39|15.48 ↓12.52 18.29 ↓9.71 17.85 ↓10.15 15.04 ↓12.96 14.40 ↓13.60 16.06 ↓11.94 16.57 ↓11.43 16.56 ↓11.44 12.47 ↓15.53|


Table A11: More results of different sparcification methods on CIFAR-100 with ResNet-18.


80

90





|Robust Accuracy Standard Accuracy Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. Generalization|Robust Accuracy|Standard Accuracy|Col4|
|---|---|---|---|
||Best Final Diff.|Best Final Diff.||
|0 Baseline|26.93 19.62 7.31|52.03 53.91 −1.88|54.56|
|Small Dense Random Pruning OMP SNIP GraSP 80 SynFlow IGQ Robust Bird Flying Bird Flying Bird+|24.40 21.83 2.57 25.92 20.83 5.09 25.12 20.18 4.94 26.61 23.55 3.06 25.37 20.79 4.58 26.31 23.52 2.79 26.87 23.07 3.80 25.54 20.82 4.72 26.64 22.00 4.64 26.66 23.37 3.29|51.87 51.64 0.23 48.16 51.31 −3.15 50.08 52.81 −2.73 49.47 54.79 −5.32 50.27 53.29 −3.02 48.33 54.49 −6.16 49.80 54.39 −4.59 48.79 53.33 −4.54 53.57 55.41 −1.84 52.29 55.23 −2.94|21.93 ↓32.63 34.04 ↓20.52 28.57 ↓26.00 23.69 ↓30.87 28.03 ↓26.53 20.29 ↓34.27 27.04 ↓27.52 25.46 ↓29.10 27.46 ↓27.10 20.12 ↓34.44|
|Small Dense Random Pruning OMP SNIP GraSP 90 SynFlow IGQ Robust Bird Flying Bird Flying Bird+|23.61 22.81 0.80 24.06 21.45 2.61 24.45 21.38 3.07 26.10 24.46 1.64 24.83 22.74 2.09 25.45 24.62 0.83 26.22 24.87 1.35 24.65 22.96 1.69 26.14 23.57 2.57 26.26 24.16 2.10|48.44 48.63 −0.19 47.06 49.73 −2.67 48.02 51.26 −3.24 52.35 52.88 −0.53 51.09 52.55 −1.46 51.03 51.96 −0.93 52.37 53.16 −0.79 46.16 51.87 −5.71 50.53 54.78 −4.25 51.16 53.97 −2.81|11.18 ↓43.38 18.04 ↓36.52 17.11 ↓37.45 11.54 ↓43.02 14.55 ↓40.01 10.38 ↓44.18 13.90 ↓40.66 16.14 ↓38.42 16.73 ↓37.83 11.44 ↓43.12|


A4.3 COMPARISON WITH EFFICIENT ADVERSARIAL TRAINING METHODS

To elaborate more about training efficiency, we compare our methods with two efficient training
methods. Shafahi et al. (2019) proposed Free Adversarial Training that improves training efficiency
by reusing the gradient information, which is orthogonal to our approaches and can be easily combined with our methods to pursue more efficiency by replacing the PGD-10 training with Free AT.


-----

Table A12: More results of different sparcification methods on CIFAR-100 with VGG-16.





|Robust Accuracy Standard Accuracy Robust Sparsity(%) Settings Best Final Diff. Best Final Diff. Generalization|Robust Accuracy|Standard Accuracy|Col4|
|---|---|---|---|
||Best Final Diff. Be|st Final Diff.||
|0 Baseline|22.76 18.06 4.70 46.|11 46.88 −0.77|63.18|
|Random Pruning OMP SNIP GraSP SynFlow 80 IGQ Robust Bird Flying Bird Flying Bird+|22.38 15.76 6.62 41. 22.98 16.32 6.66 45. 23.34 17.83 5.51 46. 23.05 16.50 6.55 43. 23.02 17.67 5.35 45. 23.60 17.44 6.16 45. 23.46 17.48 5.98 46. 22.75 17.96 4.79 46. 22.92 19.02 3.90 47.|79 44.85 −3.06 45 45.96 −0.51 58 48.55 −1.97 01 46.84 −3.83 55 47.33 −1.78 77 47.43 −1.66 33 47.59 −1.26 61 47.36 −0.75 01 48.11 −1.10|51.15 ↓12.03 53.59 ↓9.59 40.42 ↓22.76 49.71 ↓13.47 41.70 ↓21.48 48.18 ↓15.00 48.19 ↓15.00 48.11 ↓15.07 34.63 ↓28.55|
|Random Pruning OMP SNIP GraSP SynFlow 90 IGQ Robust Bird Flying Bird Flying Bird+|21.48 16.33 5.15 43. 22.18 17.38 4.80 44. 22.92 20.30 2.62 48. 22.17 17.60 4.57 44. 22.58 18.88 3.70 43. 22.55 18.56 3.99 44. 22.80 19.19 3.61 45. 23.59 18.86 4.73 46. 23.31 20.34 2.97 45.|10 44.93 −1.83 81 45.63 −0.82 50 49.05 −0.55 54 47.00 −2.46 62 46.73 −3.11 96 48.08 −3.12 78 48.61 −2.83 64 48.45 −1.81 51 48.13 −2.62|31.34 ↓31.84 38.91 ↓24.27 20.02 ↓43.16 29.76 ↓33.42 24.96 ↓38.22 27.91 ↓35.27 26.46 ↓36.72 34.05 ↓29.13 22.16 ↓41.02|


Sparsity: 80% Sparsity: 90%

Figure A11: Training curve of Flying Bird+ at 80%(Left) and 90%(Right) sparsity on CIFAR-10
with ResNet-18. The Red and Green dotted lines indicate the time for increasing the pruning and
growth ratio, respectively.

Table A13: Comparison results of the unpruned dense network and our flying birds at more sparsity levels.
Experiments are conducted on CIFAR-10 with ResNet-18 under PGD-10 adversarial training.




Robust Accuracy Standard Accuracy Robust

Sparsity% Settings

Best Final Diff. Best Final Diff. Generalization


|0 Baseline|51.10 43.61 7.49|81.15 83.38 2.23 −|38.82|
|---|---|---|---|


|40 Flying Bird+|51.25 43.45 7.80|81.51 82.94 1.43 −|34.38 ↓4.44|
|---|---|---|---|


|Flying Bird 60 Flying Bird+|51.20 43.58 7.62 51.23 44.95 6.28|81.27 83.35 2.08 − 81.35 83.19 1.84 −|35.65 ↓3.17 29.89 ↓8.93|
|---|---|---|---|


Additionally, Li et al. (2020) uses magnitude pruning to locate sparse structures, which is similar to
OMP reported in Table 1, except they use a smaller learning rate. Our methods achieve better performance and efficiency than OMP. Specifically, with 80% sparsity, our flying bird+ reaches a 4.49%
narrower robust generalization gap and 1.54% higher RA yet only requires 87.58% less training
FLOPs. Also, our methods can be easily combined with Fast AT for further training efficiency.


-----

Table A14: Comparison results of the unpruned dense network and our flying birds at more sparsity levels.
Experiments are conducted on CIFAR-100 with ResNet-18 under PGD-10 adversarial training.



Sparsity% Settings

|Robust Accuracy|Standard Accuracy|
|---|---|
|Best Final Diff.|Best Final Diff.|


Best Final Diff. Best Final Diff. Generalization


|0 Baseline|26.93 19.62 7.31|52.03 53.91 1.88 −|54.56|
|---|---|---|---|


|Flying Bird 40 Flying Bird+|26.63 19.80 6.83 27.35 20.48 6.87|53.44 54.46 1.02 − 52.34 54.76 2.42 −|48.66 ↓5.90 40.31 ↓14.25|
|---|---|---|---|


|Flying Bird 60 Flying Bird+|26.95 20.60 6.35 26.95 21.38 5.57|51.77 54.71 2.94 − 51.77 55.32 3.55 −|42.13 ↓12.43 34.75 ↓19.81|
|---|---|---|---|


Table A15: Comparison results of the unpruned dense network and our flying birds at more sparsity levels.
Experiments are conducted on CIFAR-10 with VGG-16 under PGD-10 adversarial training.



Sparsity% Settings

|Robust Accuracy|Standard Accuracy|
|---|---|
|Best Final Diff.|Best Final Diff.|


Best Final Diff. Best Final Diff. Generalization


|0 Baseline|48.33 42.73 5.60|76.84 79.73 2.89 −|28.00|
|---|---|---|---|


|Flying Bird 40 Flying Bird+|48.03 42.86 5.17 49.13 43.56 5.57|76.28 79.66 3.38 − 77.03 79.92 2.89 −|25.40 ↓2.60 23.19 ↓4.81|
|---|---|---|---|


|Flying Bird 60 Flying Bird+|48.06 43.69 4.37 48.41 44.64 3.77|78.31 80.11 1.80 − 76.45 80.03 3.58 −|25.55 ↓2.45 21.63 ↓6.37|
|---|---|---|---|


Table A16: Comparison results of the unpruned dense network and our flying birds at more sparsity levels.
Experiments are conducted on CIFAR-100 with VGG-16 under PGD-10 adversarial training.



Sparsity% Settings

|Robust Accuracy|Standard Accuracy|
|---|---|
|Best Final Diff.|Best Final Diff.|


Best Final Diff. Best Final Diff. Generalization


|0 Baseline|22.76 18.06 4.70|46.11 46.88 0.77 −|63.18|
|---|---|---|---|


|Flying Bird 40 Flying Bird+|23.22 18.20 5.02 23.21 17.90 5.31|45.20 46.95 1.75 − 45.20 47.13 1.93 −|59.19 ↓3.99 49.40 ↓13.78|
|---|---|---|---|


|Flying Bird 60 Flying Bird+|23.53 18.14 5.99 23.61 17.91 5.70|46.03 46.90 0.87 − 46.17 47.59 1.42 −|51.77 ↓11.41 49.78 ↓13.40|
|---|---|---|---|


Table A17: Comparison results of the unpruned dense network and our flying birds on CIFAR-10 with
WideResNet-34-10.

Sparsity% Settings

|Robust Accuracy|Standard Accuracy|
|---|---|
|Best Final Diff.|Best Final Diff.|


Best Final Diff. Best Final Diff. Generalization


|0 Baseline|54.73 46.83 7.90|84.08 85.84 1.76 −|52.60|
|---|---|---|---|


|Flying Bird 80 Flying Bird+|55.34 46.79 8.55 55.34 46.82 8.52|83.76 85.93 2.17 − 83.76 85.97 2.21 −|49.41 ↓3.19 46.73 ↓5.87|
|---|---|---|---|


|Flying Bird 90 Flying Bird+|54.27 46.16 8.11 54.24 46.91 7.33|85.44 86.01 0.57 − 85.52 85.93 0.41 −|45.41 ↓7.19 39.46 ↓13.14|
|---|---|---|---|


A4.4 COMPARISON WITH OTHER PRUNING AND SPARSE TRAINING METHODS

Compared with the recent work ( Ozdenizci & Legenstein, 2021), our flying bird(+) is different at[¨]
both levels of goal and methodologies. Firstly, Ozdenizci & Legenstein (2021) pursues a supe-[¨]
rior adversarial robust testing accuracy for sparsely connected networks. While we aim to investigate the relationship between sparsity and robust generalization, and demonstrate that introducing
appropriate sparsity (e.g., LTH-based static sparsity or dynamic sparsity) into adversarial training


-----

substantially alleviates the robust generalization gap and maintains comparable or even better standard/robust accuracies. Secondly, Ozdenizci & Legenstein (2021) samples network connectivity[¨]
from a learned posterior to form a sparse subnetwork. However, our flying bird first removes the
parameters with the lowest magnitude, which ensures a small term of the first-order Taylor approximation of the loss and thus limits the impact on the output of networks (Evci et al., 2020a). And
then, it allows new connectivity with the largest gradient to grow to reduce the loss quickly (Evci
et al., 2020a). Furthermore, we propose an enhanced variant of Flying Bird, i.e., Flying Bird+,
which not only learns the sparse topologies but also is capable of adaptively adjusting the network
capacity to determine the right parameterization level “on-demand” during training, while Ozdenizci[¨]
& Legenstein (2021) stick to a fixed parameter budget.

Another work, HYDRA (Sehwag et al., 2020) also has several differences from our robust birds.
Specifically, HYDRA starts from a robust pre-trained dense network, which requires at least hundreds of epochs for adversarial training. However, our robust bird’s pre-training only needs a few
epochs of standard training. Therefore, Sehwag et al. (2020) has significantly higher computational
costs, compared to ours. Then, Sehwag et al. (2020) adopt TRADES (Zhang et al., 2019) for adversarial training, which also requires auxiliary inputs of clean images, while our methods follow
the classical adversarial training (Madry et al., 2018b) and only take adversarial perturbed samples
as input. Moreover, for CIFAR-10 experiments, Sehwag et al. (2020) uses 500k additional pseudolabeled images from the Tiny-ImageNet dataset with a robust semi-supervised training approach.
However, all our methods and experiments do not leverage any external data.

Furthermore, one concurrent work (Fu et al., 2021) demonstrates that there exist subnetworks with
inborn robustness. Such randomly initialized networks have matching or even superior robust accuracy of adversarially trained networks with similar parameter counts. It’s interesting to utilize this
finding for further improvement of robust generalization, and we will investigate it in future works.


-----


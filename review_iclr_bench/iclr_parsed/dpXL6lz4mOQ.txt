# LEARNING GUARANTEES FOR GRAPH CONVOLU## TIONAL NETWORKS ON THE STOCHASTIC BLOCK
# MODEL

**Wei Lu**
Department of Mathematics
Brandeis University
Waltham, MA 02453, USA
luwei@brandeis.edu

ABSTRACT

An abundance of neural network models and algorithms for diverse tasks on
graphs have been developed in the past five years. However, very few provable
guarantees have been available for the performance of graph neural network models.
This state of affairs is in contrast with the steady progress on the theoretical
underpinnings of traditional dense and convolutional neural networks. In this paper
we present the first provable guarantees for one of the best-studied families of
graph neural network models, Graph Convolutional Networks (GCNs), for semisupervised community detection tasks. We show that with high probability over the
initialization and training data, a GCN will efficiently learn to detect communities
on graphs drawn from a stochastic block model. Our proof relies on a fine-grained
analysis of the training dynamics in order to overcome the complexity of a nonconvex optimization landscape with many poorly-performing local minima.

1 INTRODUCTION

There is presently a large gap between what can be accomplished in practice using deep learning, and
what can be satisfactorily explained and predicted by the theory of deep learning. Nevertheless, the
past several years have seen substantial developments in the theory of deep learning (Ge et al., 2017;
Brutzkus & Globerson, 2017; Zhang et al., 2019a; Goel et al., 2020; Chen et al., 2020a).

One factor contributing to the gap between the theory and practice of traditional NNs is that realworld data sets tend to have complex structure that is difficult to capture with formal definitions. For
example, popular image classification models are capable of memorizing arbitrary data (Zhang et al.,
2016), and yet they exhibit astonishing generalization performance on accurately-labeled natural
images. Hence, any rigorous proof of the observed generalization performance of deep learning
models on image classification tasks will necessarily require assumptions about the data that are
sharp enough to separate random inputs from natural images. Because of the difficulty of giving an
adequate characterization of real-world data, much of the recent progress in deep learning theory
has instead focused on proving results using very simple (e.g. Gaussian) input distributions or in
distribution-free settings (Ge et al., 2017; Brutzkus & Globerson, 2017; Zhang et al., 2019a; Vempala
& Wilmes, 2019).

Compared to traditional feed-forward (dense, convolutional, etc.) NNs, the theory of graph neural
networks (GNNs) is still in its infancy. On the other hand, it appears substantially easier to give
plausible descriptions of the combinatorial structure of real-world graph data sets than, e.g., to
characterize the distribution of natural images (Drobyshevskiy & Turdakov, 2019). We therefore
believe that GNNs offer a natural setting for developing provable guarantees that are able to capture
the power of deep learning on real-world datasets. In this paper, we contribute to that goal by giving
the first rigorous guarantees of efficient semi-supervised learning of stochastic block models via a
GNN.


-----

1.1 GRAPH NEURAL NETWORKS

Many natural datasets for diverse machine learning problems have a graph structure, including social
networks, molecular structures, and transit networks. In order to efficiently exploit such combinatorial
structure, a variety of GNN models have been proposed, tuned for different kinds of tasks. A number
of taxonomies of GNN models have been proposed (Zhou et al., 2018; Wu et al., 2021); one of the
most essential differences between different GNN models is whether they are meant to label the
graph as a whole, or to label individual components of the graph, particularly vertices.

From a theoretical perspective, the best understood tasks for GNNs concern labeling the graph as
a whole, for example for the task of classifying a graph by its isomorphism type (Sato, 2020). In
particular, it has been established that many GNN models are of comparable power to various versions
of the Weisfeiler-Leman hierarchy[1] (Xu et al., 2018; Morris et al., 2019).

Some progress has also been made on the theory of GNNs for vertex-labeling tasks. Recent works by
Sato et al. describe the representational power of certain GNN models for tasks such as computing
minimum vertex covers (Sato et al., 2019). Garg et al. also give bounds on the representational
power of GNN models, as well as using Rademacher bounds to estimate the generalization ability of
GNNs (Garg et al., 2020).

Our results concern the task of semi-supervised community detection. In this problem, each vertex
belongs to one community, and some subset of the vertices are labeled according to their community
membership. The task is to classify the community membership of the remaining vertices. This task
has been one of the most intensively studied problems in the GNN literature, but there have not yet
been any provable guarantees on the performance of proposed models.

We study (spatial-based) graph convolutional models similar to the GCN model proposed in Kipf
& Welling (2017). A single layer of such a model computes weights at each node by aggregating
the weights at neighboring nodes and applying an activation function with learned parameters, e.g.,
a linear map followed by a ReLU. Many variations on this theme, including various sophisticated
training regimes, have been proposed (Chen et al., 2017; Gao et al., 2018; Li et al., 2018; Zhang et al.,
2019b; Chen et al., 2018), but no provable guarantees have been available for the performance of
such models on natural data distributions, until the present work.

2 MAIN RESULTS

One motivation for GNNs as a target for progress in deep learning theory is that there are well-studied
graph distributions that plausibly capture some of the structure of real-world data (Drobyshevskiy &
Turdakov, 2019). For example, even fairly simple preferential attachment models plausibly capture
some of the essential structure of the web (Kumar et al., 2000). Other graph models naturally capture
community structures, the simplest of which is the Stochastic Block Model (SBM) (Holland et al.,
1983). A graph is sampled from a SBM by first partitioning vertices into communities (with fixed or
random sizes). Two vertices are connected with probability p if they belong to the same community
and probability q if they belong to different communities.

In this paper, we consider the case of an SBM with two equal-sized communities in which vertices
have label 0 and 1 respectively. We denote the label of vertex x by ℓ(x) ∈{0, 1}. The graphs
are parameterized as SBM(n, p, q) where n is the number of vertices, p is the probability of an
intra-community connection, and q is the probability of a cross-community connection. We allow
_n to vary (but will require it to be sufficiently large), while p and q are of the form p =_ _[a][ log]n[3][ n]_ and

_q =_ _[b][ log]n[3][ n]_ for some fixed constants a > b. In the semi-supervised setting, the community labels of

some portion of the labels are revealed. We assume the label of each vertex is revealed independently
with probability λ. The input-layer features at a vertex x is (0, 0) if its label is not revealed, (1, 0) if
its label is revealed to be 0, and (0, 1) if its label is revealed to be 1.

**Assumption 2.1 (Sparse Stochastic Block Model). The probabilities of intra and cross-community**
_connections are p =_ _[a][ log]n[3][ n]_ _and q =_ _[b][ log]n[3][ n]_ _, where a > b are constants._

1Weisfeiler-Leman hierarchy is a polynomial-time iterative algorithm which provides a necessary but
insufficient condition for graph isomorphism.


-----

We study the problem of recovering the communities from such graphs using GNN models. Of
course, recovering the communities of an SBM graph has been well-studied and its computational
complexity is fully understood in most cases (Abbe & Sandon, 2015; Kawamoto et al., 2019). SBM
models are therefore a natural test-case for understanding the power of GNN models for learning
community structure, and experimental studies have been done in this setting (Chen et al., 2020b;
Yadav et al., 2019). (Abbe et al., 2014) shows a sharp threshold in the task of community recovery:

_n_

([√]p − _[√]q)_ log n _[>]_ _√2. This threshold clearly holds for our case (at sufficiently large values of_

_n), since p =q_ _[a][ log]n[3][ n]_ _, q =_ _[b][ log]n[3][ n]_ and a > b. The contribution here is not to learn the community

models. Rather it’s showing that (multi-layer) GCNs solve the classification problem, which is very
much not trivial (it is non-convex, and the training loss curve is empirically non-monotonic).

Our GNN models will be trained on a graph or several graphs generated by the SBM(n, p, q) model,
and seek to understand their accuracy on arbitrary SBM(n, p, q) graphs not necessarily in the training
set but with the same parameters a, b determining p and q (with n allowed to vary).

In particular, we study spatial-based graph convolutional models along the lines of the Graph
Convolutional Networks (GCN) introduced in (Kipf & Welling, 2017). Each layer of the model
computes a feature vector at every vertex of an input graph based on features of nearby vertices in the
previous layer. A typical layer-wise update rule is of the form

_X_ [(][k][+1)] = ϕ ˆAX [(][k][)]W [(][k][)][],
where
 

-  _A[ˆ] is a suitably-normalized adjacency matrix of shape n × n where n is the number of_
vertices. Usually _A[ˆ] includes self-loops._

-  X [(][k][)] gives the feature vector in the k-th layer at each vertex as a matrix of shape n _mk,_
_×_
where mk is the number of features in layer k.

-  ϕ is an activation function, such as the ReLU.

-  W [(][k][)] are the trainable weights in the k-th layer, a matrix of shape mk _mk+1._
_×_

1
In our version of this model, we define _A[ˆ] =_ _n_ _A, where_ _A[˜] = A + I, A is the adjacency matrix_

2 [(][p][+][q][)][ ˜]
of a given graph, and I is the identity matrix. For the given SBM(n, p, q), a randomly selected vertex
has _[n]2_ [(][p][ +][ q][)][ neighbors in expectation, so][ ˆ]A is obtained by normalizing each row of A + I with

the average size of a neighborhood. Since very deep GCN models seem to provide little empirical
benefit (Li et al., 2018), we use a single hidden layer with a softmax output layer. Furthermore, we
introduce a bias term B at the second layer. So the model has the following form:

_f_ (X, A) = softmax ˆAϕ ˆAXW [(0)][]W [(1)] + B

4
= softmax    _Aϕ_ ˜AXW [(0)][]W [(1)] + B _,_ (1)

_n[2](p + q)[2][ ˜]_

 

where X is the input feature of the graph and W [(0)], W [(1)] and B are trainable parameters. Let h
denote the number of hidden features, which equals the number of columns of W [(0)] and the number
of rows of W [(1)].

We define the accuracy of the model as the probability of predicting correctly the label of a single
vertex in a randomly generated SBM(n, p, q) graph where the label of each vertex is revealed with
probability λ. We can now state our main result.
**Theorem 2.2. For any ϵ > 0 and δ > 0, given a GCN model with** [1]δ

_and with parameters initialized independently from N_ (0, 1), if training graphs are sampled from[≤] _[h][ ≤]_ _[n][ hidden features]_
_SBM(n, p, q) with n ≥_ max(Ω( [1]ϵ [)][2][,][ Ω(][ 1]δ [))][ and the label of each vertex revealed with probability][ λ][,]

_and if the model is trained by coordinate descent for k = O(log log_ [1]ϵ [)][ epochs, then with probability]

_≥_ 1 − _δ, the model achieves accuracy ≥_ 1 − 4ϵ.
_Remark. We treat λ as constants, so it is omitted in the big O and Ω_ notation in the sampling and
training complexity.

We emphasize that the novelty of this theorem is not in learning two-class SBM models as such;
this is a long-solved problem. Instead, this is the first proof of efficient learning for a GCN on
semi-supervised community detection tasks using a natural family of random graph models.


-----

3 PRELIMINARIES

In this section, we first introduce notations (a table of notations is also shown in the appendix for
readers’ convenience) and some interpretations. Then we introduce the structure of the paper. Given
a vertex y, denote the row of _AX[˜]_ corresponding to y as (t[y]0[, t]1[y][)][, so][ t][y]0 [and][ t]1[y] [give the numbers of]
neighbors of y (including perhaps y itself) with revealed labels in class 0 and class 1 respectively. Let

_β1_ _β1[′]_ _b0_ _b1_

_W_ [(0)] = _αα11[′]_ _αα22[′]_ _· · ·_ _ααhh[′]_ _, W_ [(1)] = β...2 _β...2[′]_  b...0 _b...1_
 _[· · ·]_ 

βh _βh[′]_  b0 _b1_
  _[, B][ =]_   _[.]_

Then αit[y]0 [+][ α]i[′][t][y]1[,][ 1][ ≤] _[i][ ≤]_ _[h][ gives][ h][ features of vertex][ y][ in the hidden layer. The inner product]_
of the y-th row of ϕ( AXW[˜] [(0)]) and the columns of W [(1)] gives weighted sums of features of
_y :_ _i=1_ _[β][i][ϕ][(][α][i][t]0[y]_ [+][ α]i[′][t][y]1[)][ and][ P][h]i=1 _[β]i[′][ϕ][(][α][i][t][y]0_ [+][ α]i[′][t][y]1[)][, where][ ϕ][ represents the ReLU function.]

Given a vertex x, the row of _Aϕ[ˆ]_ ( AXW[ˆ] [(0)])W [(1)] corresponding to x is denoted by (f0(x), f1(x))

[P][h]

and is of the form


_β1_ _β1[′]_
_β2_ _β2[′]_
. .
. .
. .
_βh_ _βh[′]_


_W_ [(0)] = _αα11[′]_ _αα22[′]_ _· · ·_ _ααhh[′]_
 _[· · ·]_


4 4

1[y _x]_ _βiϕ(αit[y]0[+][α]i[′][t][y]1[)][,]_ 1[y _x]_ _βi[′][ϕ][(][α][i][t][y]0[+][α]i[′][t][y]1[)]_ _,_

_n[2](p + q)[2]_ _∼_ _n[2](p + q)[2]_ _∼_

 _y_ _G_ _i=1_ _y_ _G_ _i=1_ 

X∈ X X∈ X

(2)
where 1[y ∼ _x] is equal to 1 if y and x are connected, 0 otherwise. Denote_

_f0[i][(][x][) :=]_ 4βi 1[y _x]ϕ(αit[y]0[+][α]i[′][t][y]1[)]_ _f1[i][(][x][) :=]_ 4βi[′] 1[y _x]ϕ(αit[y]0[+][α]i[′][t][y]1[)][,]_

_n[2](p + q)[2]_ _∼_ _n[2](p + q)[2]_ _∼_

_yX∈G_ _yX∈G_

so f0(x) = _i=1_ _[f][ i]0[(][x][)][ and][ f][1][(][x][) =][ P][h]i=1_ _[f][ i]1[(][x][)][.]_

Denote gj(x) := fj(x) + bj, j = 0, 1, where (g0(x), g1(x)) represents the logit of the model
corresponding to[P][h] _x. Denote ∆(x) := g0(x)_ _g1(x). In order to make correct predictions, we need_
_−_
∆(x) > 0 when ℓ(x) = 0 and ∆(x) < 0 when ℓ(x) = 1.

The bias term B is useful in our analysis because its derivative controls how imbalanced the current
loss is between the classes. In training we consider the cross-entropy loss denoted as L, and have


E[ _[∂L]_ ] = E[ _[∂L]_ ] =

_∂b0_ _−_ _∂b1_ _−_ 2[1] [(][E][[][Z][|][ℓ][(][x][) = 0]][ −] [E][[][Z][|][ℓ][(][x][) = 1])][,]

where Z = exp (exp (g0(xg))+exp (1−ℓ(x)(xg))1(x)) [.][ Z][ can be regarded as a measure of wrong prediction: the numerator]

is the exponential of the output corresponding to the wrong label and the denominator is a normalizer.
It is easy to see that Z > 12 [if the prediction is wrong;][ Z <] 12 [if prediction is correct. When]
E[ _∂b[∂L]0_ []] _≈_ 0, the model’s loss is balanced in the sense of that E[Z|ℓ(x) = 0] − E[Z|ℓ(x) = 1] _≈_ 0.

In order to have balanced performance in every epoch, we train the model through coordinate descent
instead of conventional gradient descent. Specifically, in each epoch we first update b0 and b1 until
E[ _∂b[∂L]0_ []] is smaller than some threshold. Then we update the other parameters.

In order to make a learning guarantee of the model, we need a high probability estimation of ∆(x).
In Section 4, we show that ∆(x) is concentrated at one of two values, denoted by µ0 and µ1, for
_ℓ(x) = 0 and 1 respectively. The proof depends on different parameter regimes of hidden neurons._
Furthermore, to avoid the overlap between the concentration range of ∆(x), we also show the
separation between µ0 and µ1. In Section 5, we analyze the dynamics of hidden neurons throughout
training to show that the concentration and separation improve at a controlled rate. Based on this
information, in Section 6 we prove the main theorem. Section 7 shows some experimental results to
verify our theory. The paper ends with future directions in Section 8.


4 CONCENTRATION AND SEPARATION OF OUTPUT

In this section we show that ∆(x) is concentrated at µ0 and µ1 and their separation. The difference
of the logits is


-----

∆(x) = g0(x) − _g1(x) = f0(x) −_ _f1(x) + b0 −_ _b1 =_


∆i(x) + b0 _b1,_
_i=1_ _−_

X


where


_i[)]_
∆i(x) = f0[i][(][x][)][ −] _[f][ i]1[(][x][) = 4(][β][i][ −]_ _[β][′]_

_n[2](p + q)[2]_


∆i(x) = f0[i][(][x][)][ −] _[f][ i]1[(][x][) = 4(][β][i][ −]_ _[β]i[′][)]_ 1[y _x]ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)][.]

_n[2](p + q)[2]_ _∼_

_yX∈G_

For brevity, we write ∆(x) as ∆ and ∆i(x) as ∆i. In order to estimate ∆, we need to estimate each
∆i, 1 _i_ _h._
_≤_ _≤_

We denote the high probability estimate of ∆ as µ0 and µ1 for ℓ(x) = 0 and 1 respectively. Our
fine-grained analysis of the dynamics of coordinate descent on GCNs relies on a classification of
neurons into three families based on the sign and scale of the parameters: “good type”, “bad type”
and “harmless type”. The names also indicate whether the neuron has positive contribution to the
value of µ0 _µ1. We show that “good type” neuron makes positive contribution; the contribution_
of “bad type” neuron is negative but lower bounded; “harmless type” neuron’s contribution is non −
negative (see Corollary A.4 and the remark following it). We will specifically describe parameter
regime of each type in the following subsections. We analyze the dynamics of these types throughout
coordinate descent in the next section. First we give some definitions.
**Definition 1. For 1 ≤** _i ≤_ _h, we call (αi, αi[′][, β][i][, β]i[′][)][ the][ i][-th neuron][ of the model, where][ (][α][i][, α]i[′][)][⊤]_

is the i-th column of W [(0)], (βi, βi[′][)][ is the][ i][-th row of][ W][ (1)][.]

**Definition 2.say it is order-misaligned We say that the.** _i-th neuron is order-aligned if (αi −_ _αi[′][)(][β][i][ −]_ _[β]i[′][)][ >][ 0][, otherwise we]_

4.1 CLASSIFICATION OF NEURON PARAMETER REGIMES

We say the i-th neuron is of “good type” if it satisfies either (G1) or (G2) below. (There is also the
symmetric case obtained by switching αi with αi[′] [and][ β][i][ with][ β]i[′][. For brevity, we only consider the]
cases that αi > αi[′][. This applies to the “bad” and “harmless” types below as well). Neurons in this]
type are order-aligned and both αi and αi[′] [are positive or the ratio between][ α][i][ and][ α]i[′] [is large enough.]
_αi > αi[′]_ _[>][ 0][ and][ β][i]_ _[> β]i[′]_ (G1)

_αi_
_αi > 0 > αi[′][,]_ _[>][ 1][ and][ β][i][ > β]i[′]_ (G2)
_αi[′]_

We say the i-th neuron is of “bad type” if it satisfies either (B1), (B2) or (B3). Neurons in this type
are order-misaligned and αi, αi[′] [are either both positive or have the opposite signs.]
_αi > αi[′]_ _[>][ 0][ and][ β][i]_ _[< β]i[′]_ (B1)

_αi > 0 > αi[′][,]_ _αi_ _[> q]_ 3 n) and βi < βi[′] (B2)
_αi[′]_ _p_ [(1 + log][−] [1]

_αi > 0 > αi[′][,]_ _αi_ 3 n) (B3)
_αi[′]_ _[≤]_ _p[q]_ [(1 + log][−] [1]

We say that the i-th neuron is of “harmless type” if it satisfies either (H1) or (H2):

_αi > 0 > αi[′][,]_ _ααii[′]_ _[∈]_ [(] _p[q]_ [(1 + log][−] 3[1] n), 1] and βi > βi[′] (H1)

_αi_ 0 and αi[′] (H2)
_≤_ _[≤]_ [0]

4.2 CONCENTRATION AND SEPARATION

**Theorem 4.1. If the i-th neuron is of “good type” satisfying (G1) or of “bad type” satisfying (B1),**
_then for ℓ(x) = 0:_


_αi_
_αi > 0 > αi[′][,]_
_αi[′]_


_αi_
_αi > 0 > αi[′][,]_
_αi[′]_


_i[)]_
P[ ∆i _i[]]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [(][p][2][ +][ q][2][)][α][i][ + 2][pqα][′]_ _≤_

1

(αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_ 1 _O_
_−_ _[−]_ _[β][′]_ _|_ _≥_ _−_ _n[2]_

 


-----

_for ℓ(x) = 1:_

_i[)]_
P[ ∆i _i[]]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [2][pqα][i][ + (][p][2][ +][ q][2][)][α][′]_ _≤_

1

(αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_ 1 _O_ _._
_−_ _[−]_ _[β][′]_ _|_ _≥_ _−_ _n[2]_

_Similar concentration hold for neurons satisfying (G2), (B2) and (B3), and for neurons of “harmless _ 
_type.”_

We apply the method of bounded differences to show the concentration. The details are shown in the
appendix.

Given the concentration of ∆i for each type of neurons, we estimate the concentration of the output
∆= _i=1_ [∆][i][ +][ b][0][ −] _[b][1][. For the][ i][-th neuron, we denote the high-probability estimate of][ ∆][i][ given in]_
the statement of Theorem 4.1 as m[i]0 [when][ ℓ][(][x][) = 0][ and][ m]1[i] [when][ ℓ][(][x][) = 1][. By union bound, we]
have the following corollary.

[P][h]
**Corollary 4.2. Given a vertex x ∈** _G with label unrevealed, we have_

P[ ∆ _µj_ _δ_ _ℓ(x) = j]_ 1 _O( [1]_ (3)
_|_ _−_ _| ≤_ _|_ _≥_ _−_ _n_ [)][,]

_where_


_αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) .
_i=1_ _|_ _−_ _[−]_ _[β][′]_

X


_m[i]j[) +][ b][0]_ _δ =_
_i=1_ _[−]_ _[b][1][, j][ = 0][,][ 1]_

X


_µj = (_


For any ϵ > 0, we require the probability of concentration in (3) to be at least 1 − _ϵ˜, where ˜ϵ = o(ϵ)._
If we choose ˜ϵ = ϵ[2], then we set 1 − _O(_ _n[1]_ [)][ ≥] [1][ −] _[ϵ][2][, i.e.][n][ ≥]_ [Ω(][ 1]ϵ [)][2][. Our following analysis will be]

based on this condition.

From Theorem 4.1, we have the following result about the value of m[i]0 _[−]_ _[m]1[i]_ [.]

**Corollary 4.3.** -  If the i-th neuron is of “good type” and satisfies (G1), then

2

_p_ _q_
_m[i]0_ 1 [=][ λ][|][α][i] _i[||][β][i]_ _i[|]_ _−_ _._

_[−]_ _[m][i]_ _[−]_ _[α][′]_ _[−]_ _[β][′]_ _p + q_
 



-  If the i-th neuron is of “bad type” and satisfies (B1), then

_p_ _q_
_m[i]0_ 1 [=][ −][λ][|][α][i] _i[||][β][i]_ _i[|]_ _−_

_[−]_ _[m][i]_ _[−]_ _[α][′]_ _[−]_ _[β][′]_ _p + q_



2




-  If the i-th neuron is of “harmless type” and satisfies (H1), then

_m[i]0_ 1 [=][ λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2][ .]

Similar results for neurons satisfying (G2),(B2),(B3) and (H1) are stated in the appendix, along with
the proof.
_Remark._ type” neurons, non-negative for “harmless type” neurons and may be negative (but lower• As we can see from Corollary 4.3, the value of m[i]0 _[−]_ _[m]1[i]_ [is positive for “good]
bounded) for “bad type” neurons. Since positive values ofmodel, this explains the names for the types of neurons. _m[i]0_ _[−]_ _[m]1[i]_ [decrease the loss of the]

-  m[i]0 1 [is proportional to][ |][α][i] _i[||][β][i][ −]_ _[β]i[′][|][. In the next section, we analyze the dynamics]_
of the parameters[−] _[m][i]_ _αi, αi[′][, β][i][, β]i[′][−][. Using our understanding of these dynamics, in Theorem][α][′]_
6.2 we present a refined result about the separation of output which only depends on the
initialization of parameters.

-  LetThe balanced loss guaranteed by the bias term and the coordinate descent scheme ensure c := µ0 − _µ1 =_ _i=1[(][m]0[i]_ _[−]_ _[m]1[i]_ [)][. By the two corollaries above, we have][ δ][ =][ o][(][|][c][|][)][.]
that µ0 = Ω(c) and µ1 = Ω(c). It then follows that if the loss is sufficiently small, both

[P][h]
_µ0 and µ1 have correct sign, i.e. µ0 > 0 > µ1. (Otherwise, due to concentration of the_
output, the model makes wrong prediction and the loss is large). So we will eventually have
_δ = o(µ0) and δ = o(_ _µ1_ ).
_|_ _|_


-----

5 DYNAMICS OF PARAMETERS

In this section, we describe the dynamics of each type of neurons through coordinate descent, which
can be visualized in the following figure in which the arrows indicate movement between types that
can happen with non-negligible probability.

good type

harmless type bad type


Figure 1: Dynamics of hidden neurons

There are two noteworthy points from this figure. First, “good type” parameters are preserved under
coordinate descent. Second, there are no arrows coming into “bad type” except from itself.

These dynamics are proved by estimating the gradient with respect to the loss function for each type
of neuron. Because of the non-linearity of the activation, we rely heavily on the concentration result
proved above to get tight estimates. Without these concentration results, even estimating the sign of
the gradient seems difficult. The proof and experiments about the dynamics of hidden neurons are
deferred to the appendix.

6 LEARNING GUARANTEE

In this section, we prove our main result which states that with high probability a trained GCN can
detect communities in SBM with any desired accuracy. The proof is based on the following theorem
which shows that if µ0 and µ1 are separated enough, then the model achieves high accuracy.
**Theorem 6.1.** _ϵ > 0, provided that the difference between µ0 and µ1 is large enough:_
_∀ϵ_ _ϵ_
_σ(−_ _[µ][0][−]2_ _[µ][1]_ ) < 2 _[, if]_ E[ _∂b[∂L]0_ []] _<_ 4 _[, then][ P][[∆]_ _[<][ 0][|][ℓ][(][x][) = 0]][ <][ 4][ϵ,][ P][[∆]_ _[>][ 0][|][ℓ][(][x][) = 1]][ <][ 4][ϵ][,]_

_where σ(x) := 1/(1 + exp (−x)) represents the sigmoid function._

Next we show that the model can achieve such separation between µ0 and µ1 through coordinate
descent. In order to make constant update of parameters at every epoch, we set an adaptive learning
rate ηk = E[Z1[(][k][)]] [where][ Z] [(][k][)][ is the value of][ Z][ at the][ k][-th epoch. We first refine Corollary 4.3 about]

the separation of output for each type of neuron (m[i]0 _[−]_ _[m]1[i]_ [) using the dynamics of parameters.]

**Theorem 6.2 (separation of output). Let m[i]0** _[and][ m]1[i]_ _[be defined as in Section 4, train the model for][ k]_
_epochs by the defined coordinate descent with adaptive learning rate ηk =_ E[Z1[(][k][)]] _[,]_



-  if the i-th neuron is of “good type”, then

_λ_ _p_ _q_
_m[i]0_ 1 _i_ _[B]i[(0)]_ _−_

_[−]_ _[m][i]_ _[≥]_ _[A][(0)]_ 2 _p + q_



-  if the i-th neuron is of “bad type”, then


2
1 +
 


_p −_ _q_

_p + q_




2 2k
 


2λ


2 2 _λp(p_ _q)_
_m[i]0_ _[−]_ _[m]1[i]_ _[≥−][k]_ _A[(0)]i_ + _Bi[(0)]_ (p + − q)[2][,]
       

-  if the i-th neuron is of “harmless type”, then

_m[i]0_ 1

_[−]_ _[m][i]_ _[≥]_ [0][,]


-----

_where A[(0)]i_ = αi[(0)] _αi[′][(0)], Bi[(0)]_ = βi[(0)] _βi[′][(0)]._
_−_ _−_

Next we present a result about initialization, which shows that with high probability, there are enough
“good type” neurons and parameters have appropriate scale.

**Lemma 6.3. Suppose all parameters in W** [(0)] _and W_ [(1)] _are initialized independently following_
_standard normal distribution. Then the number hg of neurons initialized as “good type” satisfies_
P[hg ≥ _[h]8_ []][ ≥] [1][ −] [exp (][−] 64[h] [)][. Furthermore,]


_h_ 1

(αi _αi[′][)][2][+(][β][i][−][β]i[′][)][2][ ≤]_ [5][h][]][ ≥] [1][−][O]
_−_ _h_
_i=1_

X  


1

_αi_ _αi[′][||][β][i][−][β]i[′][| ≥]_ _[h]_
_|_ _−_ 80 []][ ≥] [1][−][O] _h_

 


P[


P[

_the i-th neuron_
_initialized asX_
_“good type”_


Now we can prove the final result.

_Proof of Theorem 2.2. First we show that if the loss E[Z] is small enough, the model achieves desired_
accuracy. Indeed, if E[Z] < 2ϵ, since

E[Z] = E[Z pred is wrong]P[pred is wrong]+E[Z pred is correct]P[pred is correct]
_|_ _|_ _≥_ 2[1] [P][[][pred is wrong][]][,]

we have P[pred is wrong] ≤ 4ϵ, i.e., P[pred is correct] > 1 − 4ϵ.

Otherwise, E[Z] ≥ 2ϵ, since E[Z] = 2[1] [(][E][[][Z][|][ℓ][(][z][) = 0] +][ E][[][Z][|][ℓ][(][z][) = 1])][, we have][ E][[][Z][|][ℓ][(][z][) =]

0]+ E[Z|ℓ(z) = 1] ≥ 4ϵ. On the other hand, E[ _∂b[∂L]0_ []] _< ϵ implies that_ E[Z|ℓ(z) = 0] _−_ E[Z|ℓ(z) =

1] _< 2ϵ._

By Theorem 6.2,


_µ0_ _µ1 =_ (m[i]0 1[) =] (m[i]0 1[) +] (m[i]0 1[) +] (m[i]0 1[)]
_−_ Xi=1 _[−]_ _[m][i]_ _i∈X“good”_ _[−]_ _[m][i]_ _i∈X“bad”_ _[−]_ _[m][i]_ _i∈“harmless”X_ _[−]_ _[m][i]_

2 2 2k

_p_ _q_ _√2λ_ _p_ _q_ 2 2
_−_ 1 + _−_ _A[(0)]i_ _[B]i[(0)]_ _k [λp][(][p][ −]_ _[q][)]_ _A[(0)]i_ + _Bi[(0)]_

_≥_ _[λ]2_ _p + q_ 8 _p + q_ _−_ (p + q)[2]

      _i_ “good” _i_ “bad”

_∈X_ _∈X_        

By Lemma 6.3, with probability ≥ 1 − _O(_ _h[1]_ [)][,]

2 2

_A[(0)]i_ _[B]i[(0)]_ _A[(0)]i_ + _Bi[(0)]_ 5h.
_≥_ 80[h] _[,]_ _≤_
_i∈X“good”_ _i∈X“bad”_        

Since h ≥ [1]δ [, then with probability][ ≥] [1][ −] _[δ][,]_

2 2 2k

_λ_ _p_ _q_ _√2λ_ _p_ _q_
_µ0_ _µ1_ _h_ _−_ 1 + _−_ _k_ [5][λp][(][p][ −] _[q][)]_
_−_ _≥_ 160 _p + q_ 8 _p + q_ _−_ (p + q)[2]
       

_h(C1(1 + C2)[2][k]_ _C3k),_ (4)
_≥_ _−_
where C1, C2 and C3 are constants determined by p, q and λ.

By Theorem 6.1, if (4)≥ 2 log [2]ϵ [(then][ σ][(][−] _[µ][0][−]2_ _[µ][1]_ ) ≤ 2[ϵ] [), then the model achieves accuracy][ ≥] [1][ −] [4][ϵ][.]

It’s sufficient to have
_C1(1 + C2)[2][k]_ _C3k_ 2 log [2]
_−_ _≥_ _ϵ [,]_

i.e. k = O(log log [1]ϵ [)][.]

7 EXPERIMENTS

We show some experiments verifying Theorem 2.2. In particular, our experiments demonstrate that
accuracy increases with n, the probability of high-accuracy models increases with h, and coordinate
descent is able to recovery high-accuracy models in the sparse regime of Assumption 2.1. Additional
plots demonstrating the dynamics of hidden neurons with their ratios and differences can be seen in
the appendix.


-----

**Experiment 1 In this experiment, we plot the**
an estimate of the accuracy versus epoch for
varying n. The parameters p, q of SBM follow
Assumption 2.1, where we choose a = 1.0 and
_b = 0.7. We set h = 20, λ = 0.3 and run_
40 independent experiments for n = 250, 500
and 1000 respectively. In each experiment we
train the model for 100 epochs. The training
set has 40 randomly generated graphs from
SBM(n, p, q). We validate the performance by
the percentage of correct predictions on 200 random vertices, each from a randomly generated
graph. The result is shown Figure 2. The shaded
region for each n is obtained from the max, min
and mean percentage of the 40 experiments. The
result verifies Theorem 2.2 which shows that the
accuracy of the model increases with n.

**Experiment 2 In this experiment, we show the**
effect of the number of hidden neurons h. The
parameters of SBM are the same as Experiment
1. We set h = 2, 5, 20. For each pair of (n, h)
we run 40 independent experiments and show
the distribution of validation in Figure 3. From
the top row to the bottom, n increases from 250
to 1000. From the left column to the right, h increases from 2 to 20. In each plot, the x-axis represents the accuracy, while y-axis represents the
count of experiments. According to Theorem
2.2, the probability of achieving high accuracy
is 1 − _O(1/h) and the accuracy increases with_
_n. We can see that in each row of Figure 3, as h_
increases, we have lager probability to achieve
high accuracy; in each column, as n increases,
the model achieves higher accuracy. The results
verify our theory in the paper.

8 FUTURE DIRECTIONS


Figure 2: Display of accuracy versus epoch for
varying n. Accuracy is computed on vertices
drawn from random SBM graphs. The accuracy increases with epoch, and we also see that the lower
bound on the accuracy increases with n, as expected from our theory.


Figure 3: Display of accuracy for varying n and h.

8 FUTURE DIRECTIONS For each row, n is set to be 250 (top), 500 (middle),

1000 (bottom); for each column, h is set to be 2

Graph neural networks offer a promising setting (left), 5 (middle), 20 (right). Probability of failure
for progress on the more general theory of deep decreases as h increases, and accuracy increases
learning, because random graph models more with n.
plausibly capture the structure of real-world data
compared to, e.g., the Gaussian inputs often used to prove deep learning guarantees for traditional
feed-forward neural networks. This paper has initiated the project of proving training guarantees for
semi-supervised learning using GCNs on SBM models, but much more work remains to be done.
Arguably the sparsest SBM models (expected constant degree) are the most compelling from the
perspective of modeling real-world communities, so it would be interesting to extend these results
to that setting. Models with more than two blocks, or overlapping communities (Petti & Vempala,
2018) would be even closer to real-world structure. We hope this initial step spurs further interest in
provable guarantees for training neural networks using plausible models of real-world data as the
input distribution.


9 ACKNOWLEDGEMENT

This research was supported in part by NSF Grant 1849796. The author would like to thank Prof.
John Wilmes for guiding the research, and also thank Prof. Tyler Maunu and Prof. Pengyu Hong for
making the results more generalized and designing the experiments.


-----

REFERENCES

Emmanuel Abbe and Colin Sandon. Recovering communities in the general stochastic block model
without knowing the parameters. arXiv preprint arXiv:1506.03729, 2015.

Emmanuel Abbe, Afonso S. Bandeira, and Georgina Hall. Exact recovery in the stochastic block
model, 2014.

Alon Brutzkus and Amir Globerson. Globally optimal gradient descent for a convnet with gaussian
inputs. In International conference on machine learning, pp. 605–614. PMLR, 2017.

Jianfei Chen, Jun Zhu, and Le Song. Stochastic training of graph convolutional networks with
variance reduction. arXiv preprint arXiv:1710.10568, 2017.

Jie Chen, Tengfei Ma, and Cao Xiao. Fastgcn: fast learning with graph convolutional networks via
importance sampling. arXiv preprint arXiv:1801.10247, 2018.

Sitan Chen, Adam R. Klivans, and Raghu Meka. Learning deep relu networks is fixed-parameter
tractable, 2020a.

Zhengdao Chen, Xiang Li, and Joan Bruna. Supervised community detection with line graph neural
networks, 2020b.

Mikhail Drobyshevskiy and Denis Turdakov. Random graph modeling: A survey of the concepts.
_ACM Comput. Surv., 52(6):1–36, December 2019._

D.P. Dubhashi and A. Panconesi. _Concentration of Measure for the Analysis of Randomized_
_Algorithms._ Cambridge University Press, 2009. ISBN 9781139480994. [URL https:](https://books.google.com/books?id=UUohAwAAQBAJ)
[//books.google.com/books?id=UUohAwAAQBAJ.](https://books.google.com/books?id=UUohAwAAQBAJ)

Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. Large-scale learnable graph convolutional
networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
_Discovery & Data Mining, pp. 1416–1424, 2018._

Vikas Garg, Stefanie Jegelka, and Tommi Jaakkola. Generalization and representational limits of
graph neural networks. In International Conference on Machine Learning, pp. 3419–3430. PMLR,
2020.

Rong Ge, Jason D. Lee, and Tengyu Ma. Learning one-hidden-layer neural networks with landscape
design. CoRR, abs/1711.00501, 2017.

Surbhi Goel, Aravind Gollakota, Zhihan Jin, Sushrut Karmalkar, and Adam Klivans. Superpolynomial
lower bounds for learning one-layer neural networks using gradient descent. In International
_Conference on Machine Learning, pp. 3587–3596. PMLR, 2020._

Paul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First
steps. Social networks, 5(2):109–137, 1983.

Tatsuro Kawamoto, Masashi Tsubaki, and Tomoyuki Obuchi. Mean-field theory of graph neural
networks in graph partitioning. Journal of Statistical Mechanics: Theory and Experiment, 2019(12):
[124007, dec 2019. doi: 10.1088/1742-5468/ab3456. URL https://doi.org/10.1088/](https://doi.org/10.1088/1742-5468/ab3456)
[1742-5468/ab3456.](https://doi.org/10.1088/1742-5468/ab3456)

Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks,
2017.

R. Kumar, P. Raghavan, S. Rajagopalan, D. Sivakumar, A. Tomkins, and E. Upfal. Stochastic models
for the web graph. In Proceedings 41st Annual Symposium on Foundations of Computer Science,
pp. 57–65, 2000. doi: 10.1109/SFCS.2000.892065.

Qimai Li, Zhichao Han, and Xiao-Ming Wu. Deeper insights into graph convolutional networks
for semi-supervised learning. In Proceedings of the AAAI Conference on Artificial Intelligence,
volume 32, 2018.


-----

Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav
Rattan, and Martin Grohe. Weisfeiler and leman go neural: Higher-order graph neural networks. In
_Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 4602–4609, 2019._

Samantha Petti and Santosh S. Vempala. Approximating sparse graphs: The random overlapping
communities model, 2018.

Ryoma Sato. A survey on the expressive power of graph neural networks, 2020.

Ryoma Sato, Makoto Yamada, and Hisashi Kashima. Approximation ratios of graph neural networks
for combinatorial problems. arXiv preprint arXiv:1905.10261, 2019.

Santosh Vempala and John Wilmes. Gradient descent for one-hidden-layer neural networks: Polynomial convergence and sq lower bounds. In Conference on Learning Theory, pp. 3115–3117.
PMLR, 2019.

Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu. A comprehensive survey on graph neural
networks. IEEE Transactions on Neural Networks and Learning Systems, 32(1):4–24, 2021.

Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural
networks? arXiv preprint arXiv:1810.00826, 2018.

Prateek Yadav, Madhav Nimishakavi, Naganand Yadati, Shikhar Vashishth, Arun Rajkumar, and
Partha Talukdar. Lovasz convolutional networks. In The 22nd International Conference on
_Artificial Intelligence and Statistics, pp. 1978–1987. PMLR, 2019._

Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.

Xiao Zhang, Yaodong Yu, Lingxiao Wang, and Quanquan Gu. Learning one-hidden-layer relu
networks via gradient descent. In The 22nd International Conference on Artificial Intelligence and
_Statistics, pp. 1524–1534. PMLR, 2019a._

Yingxue Zhang, Soumyasundar Pal, Mark Coates, and Deniz Ustebay. Bayesian graph convolutional
neural networks for semi-supervised classification. Proceedings of the AAAI Conference on
_Artificial Intelligence, 33(01):5829–5836, 2019b._

Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,
and Maosong Sun. Graph neural networks: A review of methods and applications. arXiv preprint
_arXiv:1812.08434, 2018._

A CONCENTRATION AND SEPARATION OF OUTPUT

Let N (x, 0), N (x, 1) denote the neighborhood of vertex x with label 0 and 1 respectively, i.e.
_N_ (x, 0) = {y ∈ _G, y ∼_ _x, ℓ(y) = 0}, N_ (x, 1) = {y ∈ _G, y ∼_ _x, ℓ(y) = 1}. By the definition_
of SBM, both |N (x, 0)| and |N (x, 1)| are binomial random variables. For ℓ(x) = 0, |N (x, 0)| ∼
_B(_ _[n]2_ _[, p][)][,][ |][N]_ [(][x,][ 1)][| ∼] _[B][(][ n]2_ _[, q][)][ and for][ ℓ][(][x][) = 1][,][ |][N]_ [(][x,][ 0)][| ∼] _[B][(][ n]2_ _[, q][)][,][ |][N]_ [(][x,][ 1)][| ∼] _[B][(][ n]2_ _[, p][)][. More-]_

over,similarly for t[y]0 [and][ t] ℓ1[y](y[are also binomial random variables, for]) = 1. Our following analysis is based on the condition that[ ℓ][(][y][) = 0][, t]0[y] _[∼]_ _[B][(][ nλ]N2_ ([, p]x,[)] 0)[, t]1[y], _[∼]N_ ([B]x,[(][ nλ] 1)2 _[, q], t[)][x]0[,]_

_|_ _|_ _|_ _|_
and t[x]1 [are in their high probability range for all][ x][ ∈] _[G][. Specifically we require the condition that for]_
all ℓ(x) = 0, (similar conditions for ℓ(x) = 1 are omitted):

5 5
6, 6 ; (Cond)

2 2

_[≤]_ _[O][(][np][)]_ _[≤]_ _[O][(][nq][)]_

5 5

_[|][N]_ [(][x,][ 0)]0 _[| −]_ _[np]_ 6, _[|][N]1_ [(][x,][ 1)][| −] _[nq]_ 6 .

_[−]_ _[nλp]2_ _[≤]_ _[O][(][np][)]_ _[−]_ _[nλq]2_ _[≤]_ _[O][(][nq][)]_

By tail bound of binomial random variables and union bound, we have

_[t][x]_ _[t][x]_

P[(Cond)] 1
_≥_ _−_ _n[1][2][ .]_

Under this condition, we show the concentration of ∆i for each type.


-----

A.1 “GOOD TYPE” NEURONS


For convenience, according to the activation pattern of ϕ(αit[y]0 [+][ α]i[′][t][y]1[)][, we further divide (][G][2][)]
into subcases (G2,1), (G2,2) and (G2,3) by to the ratio of _[α]α[i][′]i_ . For example, in (G1) and (G2,1),

_ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)][ is active for both][ ℓ][(][y][) = 0][ and][ ℓ][(][y][) = 1][; in (][G][2][,][1][), it is only active for][ ℓ][(][y][) = 0][.]

_αi_ 3

_[> p]_ _n)_ (G2,1)

_αi[′]_ _q_ [(1 + log][−] [1]

1 < _αi_ _[< p]_ 3 n) (G2,2)
_αi[′]_ _q_ [(1][ −] [log][−] [1]

_p_ 3 _αi_ 3

_n)_ _n)_ (G2,3)

_q_ [(1][ −] [log][−] [1] _≤_ _αi[′]_ _[≤]_ _[p]q_ [(1 + log][−] [1]

We have the following estimation of ∆i in “good type”.
**Theorem A.1 (concentration of output from “good type” neurons). If the i-th neuron is of “good**
_type”, then_

-  in both (G1) and (G2,1):


P[ ∆i _i[)]_ _i[]]_ (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ [1]2 n) _ℓ(x) = 0]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [(][p][2][ +][ q][2][)][α][i][ + 2][pqα][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_

P[ ∆i _i[)]_ _i[]]_ (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ [1]2 n) _ℓ(x) = 1]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [2][pqα][i][ + (][p][2][ +][ q][2][)][α][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_



-  in (G2,2):

P[ ∆i _i[)][p]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_


P[ ∆i _i[)][q]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_



-  in (G2,3):

P[ ∆i _i[)][p]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_


P[ ∆i _i[)][q]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )][.]_


-----

0 [+][α]i[′] _[t][y]1_ [)]

_Proof. We have ∆i = (βi −_ _βi[′][)][ P]y∈G_ [1][[][y][ ∼] _[x][]][ 4][ϕ][(]n[α][2][i]([t]p[y]+q)[2]_ . We apply the method of averaged

bounded difference (Dubhashi & Panconesi, 2009) to estimate ∆i. In different parameter regimes,
_ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)][ has different activation patterns.]

In (G1) and (G2,1), ϕ(αit[y]0 [+][ α]i[′][t][y]1[)][ is active with probability][ 1][ −] _[O][(][ 1]n[2][ )][ for both][ ℓ][(][y][) = 0][ and]_

_ℓ(y) = 1. For ℓ(x) = 0, at first we estimate E[∆i]. By condition (Cond):_
_i[)]_

_i[]]_ _i[)(][β][i]_ _i[)][O][(log][−][1][ n][)][.]_
(p + q)[2][ [(][p][2][ +][ q][2][)][α][i][ + 2][pqα][′] _[≤]_ [(][α][i][ −] _[α][′]_ _[−]_ _[β][′]_

_yj_ _yj_
4ϕ(αit0 [+][α]i[′] _[t]1_ [)]
Let Yj =[E][[∆][i]n[]][ −][2](p+[λ]q[(])[β][2][i][ −], then[β][′] ∆i = (βi _βi[′][)][ P]j_ _[Y][j][.]_ Based on condition (Cond), _Yj_

2λ(pαi+qα[′]i[)] 2 _−_ _−_

_n(p+q)[2]_ (αi _αi[′][)][O][(log][−]_ [7] n) for ℓ(yj) = 0. For any ak, a[′]k[,]
_≤_ _−_

2

_k[]]_ _i[)][O][(log][−]_ [7] n).

_[≤]_ [(][α][i][ −] _[α][′]_

Moreover, when the number of vertices with revealed labels are fixed,

[E][[][Y][k][|][Y][1][,][ · · ·][, Y][k][−][1][, Y][k][ =][ a][k][]][ −] [E][[][Y][k][|][Y][1][,][ · · ·][, Y][k][−][1][, Y][k][ =][ a][′]

_k[]]_ _[≤]_ [(][α][i][ −] _[α]i[′][)][O][(log][−][6][ n][)][,]_

for j _k. By condition (Cond), there are at most O(log[3]_ _n) non-zero terms for Yk, 1_ _k_ _n. So_
_≥[E][[][Y][j][|][Y][1][,][ · · ·][, Y][k][−][1][, Y][k][ =][ a][k][]][ −]_ [E][[][Y][j][|][Y][1][,][ · · ·][, Y][k][−][1][, Y][k][ =][ a][′] _≤_ _≤_

_Yj_ _Y1,_ _, Yk_ 1, Yk = ak] E[ _Yj_ _Y1,_ _, Yk_ 1, Yk = a[′]k[]] _i[)][O][(log][−]_ [7]2 n),
_j_ _|_ _· · ·_ _−_ _−_ _j_ _|_ _· · ·_ _−_ _[≤]_ [(][α][i][ −] _[α][′]_

X X

for 1 _k_ _n. By the method of averaged bounded difference, we have_

[E][[] _≤_ _≤_

P[ ∆i _i[)]_ _i[]]_ (αi _αi[′][)(][β][i][−][β]i[′][)][O][(log][ n][)][−]_ 2[1] _ℓ(x) = 0]_ 1 _O( [1]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [(][p][2][+][q][2][)][α][i][+2][pqα][′]_ _≤_ _−_ _|_ _≥_ _−_ _n[2][ )][.]_

Other regimes can be proved similarly.

A.2 “BAD TYPE” NEURONS


For convenience of our analysis, we further divide (B2) into subcases (B2,1), (B2,2) and (B2,3)
according to the ratio of _α[α][′]i[i]_

_αi_ 3

_[> p]_ _n)_ (B2,1)

_αi[′]_ _q_ [(1 + log][−] [1]

_αi_ 3 3

_n), [p]_ _n)]_ (B2,2)

_αi[′]_ _[∈]_ [(] _p[q]_ [(1 + log][−] [1] _q_ [(1][ −] [log][−] [1]

_αi_ 3 3

_n), [p]_ _n)]_ (B2,3)

_αi[′]_ _[∈]_ [(] _[p]q_ [(1][ −] [log][−] [1] _q_ [(1 + log][−] [1]

We have the following estimation of ∆i in “bad type”.
**Theorem A.2 (concentration of output from “bad type” neurons). If the i-th neuron is of “bad type”,**
_we have:_

-  in (B1) and (B2,1):


_i[)]_ 2
P[ ∆i _i[]]_ _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ [1] n) _ℓ(x) = 0]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [(][p][2][ +][ q][2][)][α][i][ + 2][pqα][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_

P[ ∆i _i[)]_ _i[]]_ _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ [1]2 n) _ℓ(x) = 1]_
_−_ _[λ]([(]p[β] +[i][ −] q)[β][2][′][ [2][pqα][i][ + (][p][2][ +][ q][2][)][α][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_


-----

-  in (B2,2):

P[ ∆i _i[)][p]_ (pαi + qαi[′][)] _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_

P[ ∆i _i[)][q]_ (pαi + qαi[′][)] _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_



-  in (B2,3):

P[ ∆i _i[)][p]_ (pαi + qαi[′][)] _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_

P[ ∆i _i[)][q]_ (pαi + qαi[′][)] _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤|_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )][.]_



-  in (B3):

P[ ∆i _αi_ _αi[′][||][β][i]_ _i[|][O][(log][−]_ 2[1] n) _ℓ(x) = 0 or 1]_ 1 _O( [1]_
_≤|_ _−_ _[−]_ _[β][′]_ _|_ _≥_ _−_ _n[2][ )][.]_

_Proof. The proof is similar as Theorem A.1_


A.3 “HARMLESS TYPE” NEURONS

We have the following estimation of ∆i in “harmless type”.
**Theorem A.3 (concentration of output from “harmless type” neurons). If the i-th neuron is of**
_“harmless type”, we have:_

-  in (H1):

P[ ∆i _i[)][p]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_

P[ ∆i _i[)][q]_ (pαi + qαi[′][)] (αi _αi[′][)(][β][i]_ _i[)][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_
_−_ _[λ][(]([β]p[i] +[ −] q[β])[2][′]_ _≤_ _−_ _[−]_ _[β][′]_ _|_

1 _O( [1]_
_≥_ _−_ _n[2][ )]_



-  in (H2): ∆i = 0 for both ℓ(x) = 0 and 1.

A.4 SEPARATION OF OUTPUT

Previous subsections have shown the concentration of ∆i for each type of neurons. For the i-th
neuron, we write the concentrated value as m[i]0 [if][ ℓ][(][x][) = 0][ and][ m]1[i] [if][ ℓ][(][x][) = 1][. From Theorem]
A.1, A.2 and A.3, we have the following result about the value ofcomputation. _m[i]0_ _[−]_ _[m]1[i]_ [by straightforward]


-----

**Corollary A.4. We have the following result about m[i]0** _[−]_ _[m]1[i]_ _[for][ 1][ ≤]_ _[i][ ≤]_ _[h][:]_

-  if the i-the neuron is of “good type”:

2

_p_ _q_
_in (G1) and (G2,1) : m[i]0_ 1 [=][ λ][|][α][i] _i[||][β][i]_ _i[|]_ _−_

_[−]_ _[m][i]_ _[−]_ _[α][′]_ _[−]_ _[β][′]_ _p + q_
 

_in (G2,2) : m[i]0_ 1 [=][ λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2]

2

_i[||][β][i]_ _i[|]_ _p −_ _q_

_≥_ _[λ]2_ _[−]_ _[β][′]_ _p + q_

_[|][α][i][ −]_ _[α][′]_  

_in (G2,3) : m[i]0_ 1 [=][ λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2]


_λ_ _αi_ _αi[′][||][β][i]_ _i[|]_ [(][p][ −] _[q][)Λ][3]_
_≥_ _|_ _−_ _[−]_ _[β][′]_ (p + q)[2][,]


_where Λ3 =_ [(1][−][log][−] 3[1] n)p[2]−q[2]

(1 log[−] 3[1] n)p+q _[.]_
_−_



-  if the i-the neuron is of “bad type”:

2

_p_ _q_
_in (B1) and (B2,1) : m[i]0_ 1 [=][ −][λ][|][α][i] _i[||][β][i]_ _i[|]_ _−_

_[−]_ _[m][i]_ _[−]_ _[α][′]_ _[−]_ _[β][′]_ _p + q_
 

_in (B2,2) : m[i]0_ 1 [=][ −][λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2]


_λ_ _αi_ _αi[′][||][β][i]_ _i[|]_ [(][p][ −] _[q][)Λ][3]_
_≥−_ _|_ _−_ _[−]_ _[β][′]_ (p + q)[2]

_in (B2,3) : m[i]0_ 1 [=][ −][λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2]


_λ_ _αi_ _αi[′][||][β][i]_ _i[|]_ [(][p][ −] _[q][)Λ][1]_
_≥−_ _|_ _−_ _[−]_ _[β][′]_ (p + q)[2]

_in (B3) : m[i]0_ _[−]_ _[m]1[i]_ [= 0][,]

_where Λ1 =_ [(1+log][−] 3[1] n)p[2]−q[2] 3 n)p[2]−q[2]

(1+log[−] [1]3 n)p+q _[,][ Λ][3][ =][ (1](1[−][log]log[−][−][1]_ 3[1] n)p+q _[.]_

_−_



-  if the i-the neuron is of “harmless type”:

_in (H1) : m[i]0_ 1 [=][ λ][|][β][i] _i[||][pα][i]_ [+][ qα]i[′][|][ p][ −] _[q]_

_[−]_ _[m][i]_ _[−]_ _[β][′]_ (p + q)[2]


_λ_ _αi_ _αi[′][||][β][i]_ _i[|]_ [(][p][ −] _[q][)Λ][5]_
_≥_ _|_ _−_ _[−]_ _[β][′]_ (p + q)[2]

_in (H2) : m[i]0_ _[−]_ _[m]1[i]_ [= 0][,]

_pq log[−]_ 3[1]
_where Λ5 =_

_p+(1+log[−]_ 3[1] )q _[.]_


B DYNAMICS OF PARAMETERS

We consider the cross-entropy loss in training. The loss on a particular vertex x is

_L(x) =_ log Oℓ(x)(x),
_−_

where O0(x) and O1(x) are the first and second component of the output respectively, i.e.

exp(g0(x)) exp(g1(x))
_O0(x) =_

exp(g0(x)) + exp(g1(x)) _[, O][1][(][x][) =]_ exp(g0(x)) + exp(g1(x)) _[.]_


-----

For a given graph G generated by SBM, we set the objective function L(G) as the average loss over
all the vertices with revealed labels[2], i.e.


_L(G) =_


_L(x)._
_x:ℓ(x) revealed_

X


#{x ∈ _G : ℓ(x) is revealed}_


We first show the partial derivatives of parameters.

**Theorem B.1 (derivatives of parameters). For 1 ≤** _i ≤_ _h, let x be a vertex, ℓ(x) its true label,_
_L(x) =_ log Oℓ(x)(x), then
_−_

_∂L_ 4

= _i[)][Z][(][−][1)][1][−][ℓ][(][x][)][ X]_ 1[y _x]1[αit[y]0_ [+][ α]i[′][t][y]1 0
_∂αi_ _n[2](p + q)[2][ (][β][i][ −]_ _[β][′]_ _y_ _∼_ _[≥]_ [0]][t][y]

_∂L_ 4

= _i[)][Z][(][−][1)][1][−][ℓ][(][x][)][ X]_ 1[y _x]1[αit[y]0_ [+][ α]i[′][t][y]1 1
_∂αi[′]_ _n[2](p + q)[2][ (][β][i][ −]_ _[β][′]_ _y_ _∼_ _[≥]_ [0]][t][y]

_∂L_ 4

= 1[y _x]ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)]
_∂βi_ _n[2](p + q)[2][ Z][(][−][1)][1][−][ℓ][(][x][)][ X]_ _∼_

_y_

_∂L_ 4

= 1[y _x]ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)]
_∂βi[′]_ _−_ _n[2](p + q)[2][ Z][(][−][1)][1][−][ℓ][(][x][)][ X]y_ _∼_

_∂L_

= ( 1)[1][−][ℓ][(][x][)]Z
_∂b0_ _−_

_∂L_

= ( 1)[ℓ][(][x][)]Z,
_∂b1_ _−_


_where Z =_ exp(exp(g0(xg))+exp(1−ℓ(x)(xg))1(x)) _[, t]0[y]_ _[and][ t]1[y]_ _[are the numbers of neighbors of][ y][(including perhaps][ y]_

_itself) with revealed labels in class 0 and class 1 respectively._

_Proof. We compute_ _∂α[∂L]i_ _[,][ ∂L]∂βi_ [and][ ∂L]∂b0 [, others can be computed symmetrically. We have]


_L(x) =_ log Oℓ(x)(x) = log(exp(g0(x)) + exp(g1(x))) _gℓ(x)(x),_
_−_ _−_

since Oj(x) = exp(g0exp((x))+exp(gj (x))g1(x)) _[, j][ = 0][,][ 1][. So]_


_∂L_ = _e[g][0][(][x][)][ ∂g]∂α[0][(]i[x][)]_ + e[g][1][(][x][)][ ∂g]∂α[1][(]i[x][)]

_∂αi_ _e[g][0][(][x][)]_ + e[g][1][(][x][)] _−_ _[∂g][ℓ]∂α[(][x][)]i[(][x][)]_

_∂g0(x)_
= ( 1)[1][−][ℓ][(][x][)]Z _._
_−_ _∂αi_ _−_ _[∂g]∂α[1][(]i[x][)]_
  

Since gj(x) = fj(x) + bj, _[∂g]∂α[j]_ [(]i[x][)] = _[∂f]∂α[j]_ [(]i[x][)] _[, j][ = 0][,][ 1][. By (2)]_


_∂f0(x)_

_∂αi_

_∂f1(x)_

_∂αi_


1[y ∼ _x]βi1[αit[y]0_ [+][ α]i[′][t][y]1 _[≥]_ [0]][t]0[y]

1[y ∼ _x]βi[′][1][[][α][i][t][y]0_ [+][ α]i[′][t][y]1 _[≥]_ [0]][t]0[y][.]


_n[2](p + q)[2]_

4

_n[2](p + q)[2]_


Therefore


_∂L_

_∂αi_


4

_i[)]_
_n[2](p + q)[2][ (][−][1)][1][−][ℓ][(][x][)][Z][(][β][i][ −]_ _[β][′]_


1[y ∼ _x]1[αit[y]0_ [+][ α]i[′][t][y]1 _[≥]_ [0]][t]0[y][.]


2We abuse the notation L for L(x) and L(G), but the meaning is clear from the context.


-----

Next we compute _∂β[∂L]i_ [. Similar as above,][ ∂L]∂βi [= (][−][1)][1][−][ℓ][(][x][)][Z] _∂f∂β0(ix)_ _−_ _[∂f]∂β[1][(]i[x][)]_ . By (2)

_∂f0(x)_ = 4 1[y _x]ϕ (αit[y]0_ [+][ α]i[′][t][y]1[)] 

_∂βi_ _n[2](p + q)[2]_ _∼_

_y_

X


_∂f1(x)_

= 0.
_∂αi_

4
=

_n[2](p + q)[2][ (][−][1)][1][−][ℓ][(][x][)][Z]_


So
_∂L_

_∂βi_

Lastly,


1[y ∼ _x]ϕ(αit[y]0_ [+][ α]i[′][t][y]1[)][.]


_∂L_ _∂g0(x)_

= ( 1)[1][−][ℓ][(][x][)]Z
_∂b0_ _−_ _∂b0_ _−_ _[∂g]∂b[1][(]0[x][)]_


= (−1)[1][−][ℓ][(][x][)]Z,

since _[∂g]∂b[0][(]0[x][)]_ = 1, _[∂g]∂b[1][(]0[x][)]_ = 0.


In the following, we will use Theorem B.1 to analyze the dynamics of neurons of each type. As
we can see, all of _∂α[∂L]i_ _[,][ ∂L]∂α[′]i_ _[,][ ∂L]∂βi_ [and][ ∂L]∂βi[′] [have the form][ Y Z][. In order to estimate these derivatives,]

we show the concentration of Y and Z respectively. To estimate the concentration of Z, we need
the concentration of output obtained in Section 4. For any ϵ > 0, we require the probability of
concentration in (3) to be at least 1 − _ϵ˜, where ˜ϵ = o(ϵ). In particular, if we choose ˜ϵ = ϵ[2], then we_
set 1 − _O(_ _n[1]_ [)][ ≥] [1][ −] _[ϵ][2][, i.e.]_ 2

1
_n_ Ω _._ (5)
_≥_ _ϵ_
 

Our following analysis will be based on this condition.

Meanwhile in order to have balanced performance in each epoch of coordinate descent, we require
E[ _∂b[∂L]0_ []] _<_ 2ϵ[˜][. Since][ E][[][ ∂L]∂b0 [] =][ 1]2 [(][−][E][[][Z][|][ℓ][(][x][) = 0] +][ E][[][Z][|][ℓ][(][x][) = 1]))][, we have]

E[Z|ℓ(x) = 0] − E[Z|ℓ(x) = 1] _< ˜ϵ._ (6)

We have the following relation between µ0 and µ1. In the following, σ represents the sigmoid
function: σ(x) = 1+1e[−][x][ .]

**Proposition B.2. If** E[Z|ℓ(x) = 0] − E[Z|ℓ(x) = 1] _< ˜ϵ, then |σ(−µ0) −_ _σ(µ1)| ≤_ _σ[′](µ0 −_ _δ)δ +_
_σ[′](µ1 + δ)δ + 3˜ϵ, where δ is as shown in Corollary 4.2._

_Proof. We have_

_σ(_ ∆), _ℓ(x) = 0_
_Z =_ _−_
_σ(∆),_ _ℓ(x) = 1_


For ℓ(x) = 0, by Lagrange mean value theorem, _σ(_ _µ0)_ _Z_ = _σ(_ _µ0)_ _σ(_ ∆) = σ[′](ξ)(∆
_|_ _−_ _−_ _|_ _|_ _−_ _−_ _−_ _|_ _−_
_µ0), where ξ is between −µ0 and −∆. By Corollary 4.2 and the condition of n, |∆_ _−_ _µ0| ≤_ _δ with_
probability ≥ 1 − _ϵ˜. From the remark following Corollary A.4, we have σ[′](ξ) ≤_ _σ[′](−µ0 + δ) =_
_σ[′](µ0_ _δ),[3]_ with probability 1 _ϵ˜. Then we have_
_−_ _≥_ _−_

P[|σ(−µ0) − _Z| ≤_ _σ[′](µ0 −_ _δ)δ|ℓ(x) = 0] ≥_ 1 − _ϵ.˜_

Since

E[Z|ℓ(x) = 0] = E[Z||σ(−µ0) − _Z| ≤_ _σ[′](µ0 −_ _δ)δ]P[|σ(−µ0) −_ _Z| ≤_ _σ[′](µ0 −_ _δ)δ]_

+ E[Z||σ(−µ0) − _Z| > σ[′](µ0 −_ _δ)δ]P[|σ(−µ0) −_ _Z| > σ[′](µ0 −_ _δ)δ],_

3σ′(x) is even.


-----

then (note that 0 < Z < 1)

E[Z|ℓ(x) = 0] ≤ _σ(−µ0) + σ[′](µ0 −_ _δ)δ + ˜ϵ_

and
E[Z|ℓ(x) = 0] ≥ (σ(−µ0) − _σ[′](µ0 −_ _δ)δ)(1 −_ _ϵ˜),_
i.e.
E[Z|ℓ(x) = 0] − _σ(−µ0) ≤_ _σ[′](µ0 −_ _δ)δ + ˜ϵ_
and


E[Z|ℓ(x) = 0] − _σ(−µ0) ≥−σ[′](µ0 −_ _δ)δ −_ _ϵ˜(σ(−µ0) −_ _σ[′](µ0 −_ _δ)δ)_

= _σ[′](µ0_ _δ)δ(1_ _ϵ˜)_ _ϵσ˜_ ( _µ0)_
_−_ _−_ _−_ _−_ _−_

_σ[′](µ0_ _δ)δ_ _ϵ.˜_
_≥−_ _−_ _−_

So
E[Z|ℓ(x) = 0] − _σ(−µ0)_ _≤_ _σ[′](µ0 −_ _δ)δ + ˜ϵ._
Similarly
E[Z|ℓ(x) = 1] − _σ(µ1)_ _≤_ _σ[′](µ1 + δ)δ + ˜ϵ._
By triangle inequality,
_σ(−µ0) −_ _σ(µ1)_ _≤_ _σ(−µ0) −_ E[Z|ℓ(x) = 0] + E[Z|ℓ(x) = 0] − E[Z|ℓ(x) = 1]

+ E[Z|ℓ(x) = 1] − _σ(µ1)_

_≤_ _σ[′](µ0 −_ _δ)δ + σ[′](µ1 + δ)δ + 3˜ϵ._

From the proof above, we can directly obtain the following corollary about Z.
**Corollary B.3.**


P[ _Z −_ E[Z|ℓ(x) = 0] _≤_ 2σ[′](µ0 − _δ)δ + ˜ϵ|ℓ(x) = 0] ≥_ 1 − _ϵ˜_

P[ _Z −_ E[Z|ℓ(x) = 1] _≤_ 2σ[′](µ1 + δ)δ + ˜ϵ|ℓ(x) = 1] ≥ 1 − _ϵ.˜_

In order to obtain the concentration offollowing proposition is based on the condition that Z, we need to estimate |µ0 + µ σ1| ≥[′](µ0 −4δ. Ifδ)δ and |µ0 σ +[′]( µµ11 +| < δ 4)δδ. The, set
_cCorollary 4.2 can guarantee := µ0 −_ _µ1, we have µ0 > 12[c]_ _[−]ϵ accuracy of the model for any[2][δ][ and][ µ][1][ <][ −]_ 2[c] [+ 2][δ][. Then the concentration of output shown in] ϵ > 0. In fact, from ∆ _µ0_ _< δ,_

_−_ _|_ _−_ _|_
we have ∆ _> µ0_ _δ >_ 2[c]
_−_ _[−]_ [3][δ >][ 0][, due to][ δ][ =][ o][(][c][)][. So]

P[∆ _> 0|ℓ(x) = 0] ≥_ P[|∆ _−_ _µ0| < δ|ℓ(x) = 0] ≥_ 1 − _ϵ.˜_

Similarly,
P[∆ _< 0|ℓ(x) = 1] ≥_ P[|∆ _−_ _µ0| < δ|ℓ(x) = 1] ≥_ 1 − _ϵ.˜_
Since ˜ϵ = o(ϵ), the model achieves overall accuracy ≥ 1 − _ϵ._

**Proposition B.4. If |µ0 + µ1| ≥** 4δ, then σ[′](µ0 − _δ)δ = O(˜ϵ), σ[′](µ1 + δ)δ = O(˜ϵ)._

_Proof. First, we estimate the lower bound of_ _σ(_ _µ0)_ _σ(µ1)_ via the Fundamental Theorem of
_|_ _−_ _−_ _|_
Calculus. We have |σ(−µ0) − _σ(µ1)| =_ _−µ0_ _[σ][′][(][t][)][ dt]_ .

If _µ0 < µ1 < 0, since µ0 + µ1_ 4δ, we divide the interval [ _µ0, µ1] into [_ _µ0,_ _µ0 + 2δ]_

[increasing on− −µ0 + 2δ, µ (1 −−∞2δ, 0]] ∪, we have[µ1 − 2δ, µ ≥1] and estimate the lower bound of the integral. Since[R][ µ][1] _−_ _−_ _−_ _σ[′](x) is ∪_
_µ1_
Z−µ0 _σ[′](t) dt ≥_ _σ[′](−µ0) · 2δ + I1 + σ[′](µ1 −_ 2δ) · 2δ, (7)

where I1 = _µµ1−0+22δδ_ _[σ][′][(][t][)][ dt][. If][ µ][1][ <][ −][µ][0][ <][ 0][, similarly we have]_
_−_
_µ0_
R _−_

_µ1_ _σ[′](t) dt ≥_ _σ[′](µ1) · 2δ + I2 + σ[′](−µ0 −_ 2δ) · 2δ, (8)

Z


-----

_µ0_ 2δ
where I2 = _−µ1+2−δ_ _σ[′](t) dt. We have a uniform lower bound from (7) and (8):_

_µ1_

R

_σ[′](t) dt_ (9)

Z−µ0 _[≥]_ _[σ][′][(][−][µ][0][ −]_ [2][δ][)][ ·][ 2][δ][ +][ σ][′][(][µ][1][ −] [2][δ][)][ ·][ 2][δ][ +][ I,]

where I = min _I1, I2_ .
_{_ _}_

Furthermore, by Proposition B.2,

_|σ(−µ0) −_ _σ(µ1)| ≤_ _σ[′](µ0 −_ _δ)δ + σ[′](µ1 + δ)δ + 3˜ϵ._ (10)

Combine (9) and (10):

2σ[′](−µ0 − 2δ)δ + 2σ[′](µ1 − 2δ)δ ≤ _σ[′](−µ0 + δ)δ + σ[′](µ1 + δ)δ + 3˜ϵ._ (11)

By Lagrange mean value theorem,

_σ[′](−µ0 −_ 2δ) = σ[′](−µ0 + δ) − 3σ[′′](ξ0)δ

_σ[′](µ1 −_ 2δ) = σ[′](µ1 + δ) − 3σ[′′](ξ1)δ,

where ξ0 ∈ (−µ0 − 2δ, −µ0 + δ), ξ1 ∈ (µ1 − 2δ, µ1 + δ). Plug these into (11):

_σ[′](µ0 −_ _δ)δ + σ[′](µ1 + δ)δ −_ 6δ[2](σ[′′](ξ0) + σ[′′](ξ1)) ≤ 3˜ϵ.

Since δ[2](σ[′′](ξ0) + σ[′′](ξ1)) = o(σ[′](µ0 − _δ)δ) and o(σ[′](µ1 + δ)δ), we have_

_σ[′](µ0_ _δ)δ = O(˜ϵ)_
_−_

_σ[′](µ1 + δ)δ = O(˜ϵ)._


Combine Proposition B.4 and Corollary B.3, we have the following concentration of Z.
**Proposition B.5.**

P[ _Z −_ E[Z|ℓ(x) = 0] _≤_ _O(˜ϵ)|ℓ(x) = 0] ≥_ 1 − _ϵ˜_

P[ _Z −_ E[Z|ℓ(x) = 1] _≤_ _O(˜ϵ)|ℓ(x) = 1] ≥_ 1 − _ϵ.˜_

Under the condition of balanced performance, we have the following corollary about the concentration
of Z independent of the label of x.
**Corollary B.6. If** E[ _∂b[∂L]0_ []] _≤_ 2ϵ[˜][, then][ P][[] _Z −_ E[Z] _≤_ _O(˜ϵ)] ≥_ 1 − _ϵ˜._

_Proof. Since E[_ _∂b[∂L]0_ [] =][ 1]2 [(][E][[][Z][|][ℓ][(][x][) = 0]][ −] [E][[][Z][|][ℓ][(][x][) = 1])][, we have]

E[Z|ℓ(x) = 0] − E[Z|ℓ(x) = 1] _≤_ _ϵ.˜_

On the other hand,

E[Z] = [1] E[Z _ℓ(x) = 0] + E[Z_ _ℓ(x) = 1]_ _._

2 _|_ _|_

So we have E[Z] − E[Z|ℓ(x) = 0] _≤ _ 2ϵ[˜][. By Proposition B.5,][ P][[][|][Z][ −][E][[][Z][]][| ≤] _[O][(˜]ϵ)] ≥_ 1 − _ϵ˜._

Now we can derive the estimation of the derivatives.
**Theorem B.7 (concentration of derivatives). For loss on the whole graph L = L(G), with probability**
_≥_ 1 − _O(_ _n[1]_ [)][, we have][ 4]


_1. If αi > αi[′]_ _[>][ 0][ or][ α][i][ >][ 0][ > α]i[′][,][ |][ α]α[′]i[i]_ _q_ [(1 + log][−] 3[1] n), then

_[| ≥]_ _[p]_ 2

_∂L_ _p_ _q_

+ (βi _βi[′][)]_ _[λ]_ _−_ E[Z] _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) (12)
_∂αi_ _−_ 2  _p + q_  _[≤|][β][i][ −]_ _[β][′]_

2

_∂L_ _p_ _q_

(βi _βi[′][)]_ _[λ]_ _−_ E[Z] _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) (13)
_∂αi[′]_ _−_ _−_ 2  _p + q_  _[≤|][β][i][ −]_ _[β][′]_

2

_∂L_ _p_ _q_

+ (αi _αi[′][)]_ _[λ]_ _−_ E[Z] _i[|][E][[][Z][]][O][(log][−]_ 2[1] n). (14)

4Since ∂L∂βi[′] [=][ −] _∂β[∂L]i_ _∂β[(see Theorem B.1), we only need to estimate]i_ _−_ 2  _p + q_  _[≤|][α][ ∂L][i]∂β[ −]i_ [.][α][′]


-----

_2. Iflog α[−]i >3[1] n 0) − > α1], theni[′][,][ |][ α]α[i][′]i_ _[| ∈]_ [[][ q]p [(1 +][ γ][)][,][ p]q [(1][ −] [log][−] 3[1] n)], where γ ∈ [log[−] 3[1] n, ( _[p]q_ [)][2][(1][ −]

_∂L_

+ (βi _βi[′][)]_ _[λp][(][p][ −]_ _[q][)]_ _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) (15)
_∂αi_ _−_ 2(p + q)[2][ E][[][Z][]] _[≤|][β][i][ −]_ _[β][′]_

_∂L_

+ (βi _βi[′][)]_ _[λq][(][p][ −]_ _[q][)]_ _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) (16)
_∂αi[′]_ _−_ 2(p + q)[2][ E][[][Z][]] _[≤|][β][i][ −]_ _[β][′]_

_∂L_ + _[λ][(][p][ −]_ _[q][)(][pα][i][ +][ qα]i[′][)]_ E[Z] _i[|][E][[][Z][]][O][(log][−]_ 2[1] n). (17)

_∂βi_ 2(p + q)[2] _[≤|][α][i][ −]_ _[α][′]_

_3. If αi > 0 > αi[′][,][ |][ α]α[′]i[i]_ _q_ [(1][ −] [log][−] [1]3 n), _[p]q_ [(1 + log][−] 3[1] n)), then

_[| ∈]_ [(][ p]

_∂L_ [ (αi _αi[′][)][E][[][Z][]]_ _λ(p −_ _q)Λ1_ 2 n) _,_

_∂βi_ _∈_ _−_ _−_ 2(p + q)[2][ +][ O][(log][−] [1]
 

(αi _αi[′][)][E][[][Z][]]_ _λ(p −_ _q)(Λ3 −_ Λ2) _O(log[−]_ 2[1] n) ], (18)
_−_ _−_ 2(p + q)[2] _−_
 

_where Λ1 =_ [(1+log][−] 3[1] n)p[2]−q[2] _pq log[−]_ 3[1] n 3 n)p[2]−q[2]

(1+log[−] [1]3 n)p+q _[,][ Λ][2][ =]_ (1+log[−] 3[1] n)p+q _[and][ Λ][3][ =][ (1](1[−][log]log[−][−][1]_ 3[1] n)p+q _[;]_

_−_

-  if βi > βi[′][,]

_∂L_ _λp(p_ _q)_

[ (βi _βi[′][)][E][[][Z][]]_ _−_ 2 n) _,_
_∂αi_ _∈_ _−_ _−_ 2(p + q)[2][ +][ O][(log][−] [1]
 

2

_λ_ _p_ _q_
(βi _βi[′][)][E][[][Z][]]_ _−_ _O(log[−]_ 2[1] n) ] (19)
_−_ _−_ 2 _p + q_ _−_
   

_∂L_ _λq(p_ _q)_

2

[ (βi _βi[′][)][E][[][Z][]]_ _−_ _n)_ _,_
_∂αi[′]_ _∈_ _−_ _−_ 2(p + q)[2][ +][ O][(log][−] [1]
 

2

_λ_ _p_ _q_
(βi _βi[′][)][E][[][Z][]]_ _−_ + O(log[−] 2[1] n) ] (20)
_−_ 2 _p + q_
   

2

_∂L_ _p_ _q_

[ (βi _βi[′][)][E][[][Z][]]_ _λ_ _−_ + O(log[−] 2[1] n) _,_

_∂αi_ _−_ _∂α[∂L]i[′]_ _∈_ _−_ _−_ _p + q_

   

2

_λ_ _p_ _q_
(βi _βi[′][)][E][[][Z][]]_ _−_ _O(log[−]_ 2[1] n) ], (21)
_−_ _−_ 2 _p + q_ _−_
   

-  if βi ≤ _βi[′][,]_

2

_∂L_ _λ_ _p_ _q_

[ (βi _βi[′][)][E][[][Z][]]_ _−_ _O(log[−]_ 2[1] n) _,_
_∂αi_ _∈_ _−_ _−_ 2 _p + q_ _−_
   

_λp(p_ _q)_
(βi _βi[′][)][E][[][Z][]]_ _−_ 2 n) ] (22)
_−_ _−_ 2(p + q)[2][ +][ O][(log][−] [1]
 

2

_∂L_ _λ_ _p_ _q_

[ (βi _βi[′][)][E][[][Z][]]_ _−_ + O(log[−] 2[1] n) _,_
_∂αi[′]_ _∈_ _−_ _−_ 2 _p + q_
   

_λq(p_ _q)_
(βi _βi[′][)][E][[][Z][]]_ _−_ 2 n) ] (23)
_−_ 2(p + q)[2][ +][ O][(log][−] [1]
 

2

_∂L_ _λ_ _p_ _q_

[ (βi _βi[′][)][E][[][Z][]]_ _−_ _O(log[−]_ 2[1] n) _,_

_∂αi_ _−_ _∂α[∂L]i[′]_ _∈_ _−_ _−_ 2 _p + q_ _−_

   

2

_p_ _q_
(βi _βi[′][)][E][[][Z][]]_ _λ_ _−_ + O(log[−] 2[1] n) ] (24)
_−_ _−_ _p + q_
   


-----

_4. If αi > 0 > αi[′][,]_ _[α]α[i][′]i_ _≤_ _p[q]_ [(1 + log][−] 3[1] n), βi < βi[′][, then]

_∂L_

_βi_ _βi[′][|][O][(˜]ϵ)_ (25)

_∂αi_ _−_ _∂α[∂L]i[′]_ _≥−|_ _−_


_∂L_

_O(˜ϵ)._ (26)
_∂βi_ _≤_

_Proof. We show the proof for item 1, other items can be proved similarly. Since L(G) is the average_
of the losses over revealed vertices, we first show the concentration of _[∂L]∂α[(][x]i_ [)] [, then we show the]

concentration of _[∂L]∂α[(][G]i_ [)] using union bound. Since


1[y ∼ _x]1[αit[y]0_ [+][ α]i[′][t][y]1 _[≥]_ [0]][t]0[y]

_n[2](p + q)[2]_


_∂L(x)_

= ( 1)[1][−][ℓ][(][x][)]4(βi _βi[′][)][Z]_
_∂αi_ _−_ _−_


we first show the concentration of Y := ( 1)[1][−][ℓ][(][x][)][ P]y _x_ 41[αint[y]0[2]([+]p[α]+i[′]q[t])[y]1[2][≥][0]][t][y]0 using the
_−_ _∼_

method of averaged bounded difference. Similar as the proof of Theorem A.1, let Yj =

_yj_ _yj_ _yj_
0 [+][α]i[′] _[t]1_ 0 2λp
(−1)[1][−][ℓ][(][x][) 4][1][[][α][i][t]n[2](p+q)[2][≥][0]][t] . Based on Condition (Cond), for ℓ(x) = 0, |Yj + _n(p+q)[2][ | ≤]_

_O(log[−]_ 2[7] n) for ℓ(yj) = 0. Similar results hold for ℓ(yj) = 1, ℓ(x) = 1. So for any ak, a[′]k[,]

2

_Yj_ _Y1,_ _, Yk_ 1, Yk = ak] E[ _Yj_ _Y1,_ _, Yk_ 1, Yk = a[′]k[]] _i[)][O][(log][−]_ [7] n).
_j_ _|_ _· · ·_ _−_ _−_ _j_ _|_ _· · ·_ _−_ _[≤]_ [(][α][i][ −] _[α][′]_

X X

By method of averaged bounded difference, for[E][[] _ℓ(x) = 0,_


_p_ 2

2
_n)]_ 1 exp ( 2 log[3] _n)_ 1

_p + q_ _≥_ _−_ _−_ _≥_ _−_ _n[1][2][ .]_

_[≤]_ _[O][(log][−]_ [1]



P[


_Yj + λ_
_ℓ(yj_ )=0

X


Similarly

Hence


_q_ 2

P[ _Yj + λ_ 2 n)] 1

_p + q_ _≥_ _−_ _n[1][2][ .]_

_ℓ(yj_ )=1 _[≤]_ _[O][(log][−]_ [1]

X   

Hence

2

P[ _n)]_ 1

(p + q)[2] _≥_ _−_ _n[1][2][ .]_

_[≤]_ _[O][(log][−]_ [1]

By Corollary B.6, P[ _Z_ E[Z] _O(˜ϵ)]_ 1 _ϵ˜, so we have_
_|_ _−_ _[Y][ +]| ≤[ λ][(][p][2][ +] ≥[ q][2][)]_ _−_


_∂L(x)_
P[ + (βi _βi[′][)][λ p][2][ +][ q][2]_ _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) _ℓ(x) = 0]_ 1 _O( [1]_

_∂αi_ _−_ (p + q)[2][ E][[][Z][]] _[≤|][β][i][ −]_ _[β][′]_ _|_ _≥_ _−_ _n[2][ )][.]_

For ℓ(x) = 1, similarly we have

_∂L(x)_ 2pq
P[ (βi _βi[′][)][λ]_ _i[|][E][[][Z][]][O][(log][−]_ 2[1] n) _ℓ(x) = 1]_ 1 _O( [1]_

_∂αi_ _−_ _−_ (p + q)[2][ E][[][Z][]] _[≤|][β][i][ −]_ _[β][′]_ _|_ _≥_ _−_ _n[2][ )][.]_

By union bound, we have (12). (13) and (14) can be proved similarly.

Using Theorem B.7, we can analyze dynamics of neurons of each type. First, we introduce some
notations. Let ηk denote the learning rate at the k-th epoch, Z [(][k][)] be the value of Z at the k-th
epoch, αi[(][k][)] be the value of αi at the k-th epoch, similar for αi[′][(][k][)], βi[(][k][)] and βi[′][(][k][)]. In particular,
_αi[(0)][, α]i[′][(0)], βi[(0)]_ and βi[′][(0)] represent the values at initialization.


-----

B.1 “GOOD TYPE” NEURONS

In this section, we show that “good type” neurons stay in the “good type” regime throughout
coordinate descent (Theorem B.8) using Theorem B.7.

**Theorem B.8. “Good type” neurons are preserved in the “good type” throughout coordinate descent**
_with probability ≥_ 1 − _O(_ _n[1][2][ )][ over the SBM randomness.]_

_Proof. As shown in Section 4, “good type” regime is composed of (G1) and (G2), we show the_
dynamics of neurons in (G1) and (G2) respectively.

Assume that neuron (αi[(][k][)], αi[′][(][k][)], βi[(][k][)], βi[′][(][k][)]) is in (G1), we show that it either stays in (G1) or moves
into (G2) throughout coordinate descent. In fact, by (14), with probability ≥ 1 − _O(_ _n[1][2][ )][,]_ _∂β∂Li[(][k][)]_ _<_

0 < _∂β∂Li[′][(][k][)]_, so βi[(][k][+1)] _> βi[(][k][)], βi[′][(][k][+1)]_ _< βi[′][(][k][)]_ and hence βi[(][k][+1)] _−_ _βi[′][(][k][+1)]_ _> βi[(][k][)]_ _−_ _βi[′][(][k][)]_ _> 0. By_

(12) and (13), _∂α∂L[(][k][)]_ _< 0 <_ _∂α∂L[′][(][k][)]_, so αi[(][k][+1)] _> αi[(][k][)], αi[′][(][k][+1)]_ _< αi[′][(][k][)]. If αi[′][(][k][+1)]_ _> 0, this neuron_


stays in (G1). If αi[′][(][k][+1)] _< 0, since_

_αi[(][k][+1)]_

_αi[′][(][k][+1)]_

the neuron moves into (G2).


_αi[(][k][)]_ _−_ _ηk_ _∂α∂L[(]i[k][)]_

_αi[′][(][k][)]_ _−_ _ηk_ _∂α∂L[′]i[(][k][)]_



_[>][ 1][,]_


Assume that neuron is in (G2), we also show that it either moves into (G1) or stays in (G2). As
shown in section 3.2, (G2) = (G2,1) (G2,2) (G2,3). If the neuron is in (G2,1), again by (12), (13)
_∪_ _∪_

_[α]i[(][k][+1)]_
and (14), αi[(][k][+1)] _> αi[(][k][)]_ _> 0 > αi[′][(][k][)]_ _> αi[′][(][k][+1)],_ _αi[′][(][k][+1)]_ _> 1, βi[(][k][+1)]_ _> βi[(][k][)]_ _> βi[′][(][k][)]_ _> βi[′][(][k][+1)],_

so the neuron stays in G2,2. If the neuron is in G2,2, by (15), (16) and (17), _∂L_ _< 0 <_ _∂L_,

_∂βi[(][k][)]_ _∂βi[′][(][k][)]_

_∂L_ _∂L_ _[α]i[(][k][+1)]_ _[α]i[(][k][)]_
so βi[(][k][+1)] _> βi[′][(][k][+1)]. Also,_ _∂α[(]i[k][)]_ _<_ _∂α[′]i[(][k][)]_ _< 0, so αi[(][k][+1)]_ _> αi[′][(][k][+1)],_ _α[′]i[(][k][+1)]_ _>_ _αi[′][(][k][)]_ _> 1._

If αi[′][(][k][+1)] _< 0, the neuron stays in G2. If αi[′][(][k][+1)]_ _> 0, it moves into G1. If the neuron is in_
_G2,3, by (18) and (21),_ _∂β∂Li[(][k][)]_ _< 0 <_ _∂β∂Li[′][(][k][)]_ _,_ _∂α∂L[(]i[k][)]_ _−_ _∂α∂Li[′][(][k][)]_ _< 0, so βi[(][k][+1)]_ _> βi[(][k][)]_ _> βi[′][(][k][)]_ _>_

_βi[′][(][k][+1)], αi[(][k][+1)]_ _αi[′][(][k][+1)]_ _> αi[(][k][)]_ _αi[′][(][k][)]_ _> 0. By (19) and (20),_
_−_ _−_

2

_∂L_ _λ_ _p_ _q_

(βi _βi[′][)][E][[][Z][]]_ _−_ _O(log[−]_ 2[1] n) _,_
_∂αi_ _≤−_ _−_ 2 _p + q_ _−_
   

2

_∂L_ _λ_ _p_ _q_

(βi _βi[′][)][E][[][Z][]]_ _−_ + O(log[−] 2[1] n) _._
_∂αi[′]_ _≤_ _−_ 2 _p + q_
   


Similar as in (G2,2), if αi[′][(][k][+1)] _< 0, the neuron stays in (G2). If αi[′][(][k][+1)]_ _> 0, it moves into (G1)._

B.2 “BAD TYPE” NEURONS

As shown in Section 4, neurons of “bad type” consist of two cases: B1 and B2, where B2 = B2,1∪
_Bto worry if neurons move into this region. Neurons intype” regime and become “harmless” or “good” (if the neuron becomes order-aligned), which will do2,2 ∪_ _B2,3 ∪_ _B3. Since the output in B3 is concentrated at B1 ∪ 0B (see Theorem A.2), we don’t need2,1 ∪_ _B2,2 ∪_ _B2,3 might exit “bad_
no harm to the performance of the model. If they stay in B1 _B2,1_ _B2,2_ _B2,3, the following_
_∪_ _∪_ _∪_
A.4 shows thattheorem shows that the separation m[i]0 1 [is proportional to] m[i]0 _[−]_ _[m]1[i]_ _[ |][can be upper bounded by initialization. In fact, Theorem][α][i]_ _i[||][β][i][ −]_ _[β]i[′][|][. The next theorem shows that both]_
Theorem B.7 we see that the magnitude can only increase by a limited rate (we can see this more|ofα |i −αiα −i[′][|][ and]αi[′][|][ and][ |][β][i][ −][ |][β][β][i][ −][−]i[′][|][ shrink throughout coordinate descent. The worst situation is that the magnitude][m][β]i[′][i][|][ of neurons in][ B][3][ increase and move into][−] _[α][′]_ _[ B][1][ or][ B][2][ at certain epoch. From]_
explicitly in Theorem 6.2).


-----

**Theorem B.9. If (αi[(][k][)], αi[′][(][k][)], βi[(][k][)], βi[′][(][k][)]) is in B1** _B2,1_ _B2,2_ _B2,3 then with probability_
_∪_ _∪_ _∪_
_≥_ 1 − _O(_ _n[1][2][ )][ over the SBM randomness,]_ _αi[(][k][+1)]_ _−_ _αi[′][(][k][+1)]_ _≤_ _αi[(][k][)]_ _−_ _αi[′][(][k][)]_ _,_ _βi[(][k][+1)]_ _−_ _βi[′][(][k][+1)]_ _≤_

_βi[(][k][)]_ _βi[′][(][k][)]_ _._
_−_

_Proof. In B1 and B2,1, by (12) and (13),_ _∂α∂L[(]i[k][)]_ _> 0 >_ _∂α∂Li[′][(][k][)]_, then αi[(][k][+1)] _< αi[(][k][)], αi[′][(][k][+1)]_ _>_

_αi[′][(][k][)], so |αi[(][k][+1)]_ _−_ _αi[′][(][k][+1)]| ≤|αi[(][k][)]_ _−_ _αi[′][(][k][)]|. Similarly, by (14),_ _∂β∂Li[(][k][)]_ = − _∂β∂Li[′][(][k][)]_ _< 0, so_

_βi[(][k][+1)]_ _βi[′][(][k][+1)]_ _βi[(][k][)]_ _βi[′][(][k][)]_ (Note that αi[(][k][)] _> αi[′][(][k][)], βi[(][k][)]_ _< βi[′][(][k][)])._
_|_ _−_ _| ≤|_ _−_ _|_

In B2,2, from (15) and (16), we have _∂α∂L[(]i[k][)]_ _>_ _∂α∂L[′]i[(][k][)]_ _> 0, so |αi[(][k][+1)]_ _−_ _αi[′][(][k][+1)]| ≤|αi[(][k][)]_ _−_ _αi[′][(][k][)]|._

On the other hand, _∂β∂Li[(][k][)]_ _< 0 <_ _∂β∂Li[′][(][k][)]_, so βi[(][k][+1)] _> βi[(][k][)], βi[′][(][k][+1)]_ _< βi[′][(][k][)]_ and |βi[(][k][+1)] _−_ _βi[′][(][k][+1)]| ≤_

_|βi[(][k][)]_ _−_ _βi[′][(][k][)]|. In B2,3, by (24),_ _∂α∂L[(]i[k][)]_ _−_ _∂α∂L[′]i[(][k][)]_ _> 0, so |αi[(][k][+1)]_ _−_ _αi[′][(][k][+1)]| ≤|αi[(][k][)]_ _−_ _αi[′][(][k][)]|. By (18),_

_∂β∂Li[(][k][)]_ _< 0 <_ _∂β∂Li[′][(][k][)]_, so |βi[(][k][+1)] _−_ _βi[′][(][k][+1)]| ≤|βi[(][k][)]_ _−_ _βi[′][(][k][)]|._

B.3 “HARMLESS TYPE” NEURONS


Section 4 shows that there are two cases of “harmless type”: H1 and H2. For neurons in H1, the
derivatives of parameters are estimated in (15), (16) and (17) (same as in G2,2). We can have similar
analysis as in G2,2 and show that the inequality αi > 0 > αi[′][, β][i][ > β]i[′] [can be preserved. Moreover]

_[α]α[i][′]i_ increases. So the neurons either stay in H1 or become “good type” if _[α]α[i][′]i_ _> 1. In particular,_

neurons in H1 do no harm to the performance of the model.

For neurons innever updated. Meanwhile they don’t affect the performance of the model since H2, 1[αit[y]0 [+][ α]i[′][t][y]1 _[≥]_ [0] = 0][, so the derivatives are all equal to 0. Therefore they are] ϕ(αit[y]0 [+][ α]i[′][t][y]1[) = 0]
and ∆i = 0.

C LEARNING GUARANTEE

In this section, we prove Theorem 6.1, 6.2 and Lemma 6.3.

_Proof of Theorem 6.1. We prove by contradiction. Suppose_


P[∆ _< 0|ℓ(x) = 0] ≥_ 4ϵ, (27)


then


E[Z|ℓ(x) = 0] = E[Z|ℓ(x) = 0, ∆ _< 0]P[∆_ _< 0|ℓ(x) = 0]_
+ E[Z|ℓ(x) = 0, ∆ _≥_ 0]P[∆ _≥_ 0|ℓ(x) = 0]

(28)

_≥_ [1]2

_[·][ 4][ϵ][ = 2][ϵ.]_

Furthermore, we claim thatCorollary 4.2, and ∆ _µ0_ _µ0δ < δ0. In fact, if, we have_ _µ0 ≥_ _δ, since P[|∆_ _−_ _µ0| ≤_ _δ|ℓ(x) = 0] ≥_ 1 − _ϵ by_
_≥_ _−_ _≥_

P[∆ _≥_ 0|ℓ(x) = 0] ≥ P[|∆ _−_ _µ0| ≤_ _δ|ℓ(x) = 0] ≥_ 1 − _ϵ,_

i.e. P[∆ _< 0|ℓ(x) = 0] ≤_ _ϵ, which contradicts (27)._

with probabilityLet c := µ0 − _µ ≥1, then1 −_ _µϵ, we have1 = µ0 − Zc < δ = σ(∆) −_ _c < σ. Again, by Corollary 4.2, for(µ1 + δ) < σ(−c + 2δ). Then ℓ(x) = 1, ∆_ _< µ1 + δ_

E[Z|ℓ(x) = 1] = E[Z|ℓ(x) = 1, |∆ _−_ _µ1| < δ]P[|∆_ _−_ _µ1| < δ|ℓ(x) = 1]_
+ E[Z|ℓ(x) = 1, |∆ _−_ _µ1| ≥_ _δ]P[|∆_ _−_ _µ1| ≥_ _δ|ℓ(x) = 1]_
_< σ(−c + 2δ) · 1 + 1 · ϵ_

_< σ_ + ϵ.
  _−_ 2[c] 


-----

The last step is due to δ = o(c). Since σ(− 2[c] [)][ <][ ϵ]2 _[,][ E][[][Z][|][ℓ][(][x][) = 1]][ <][ 3]2[ϵ]_ [. Combine with (28),]

E[Z _ℓ(x) = 0]_ E[Z _ℓ(x) = 1]_ _> [ϵ]_
_|_ _−_ _|_ 2 _[.]_

On the other hand, E[ _∂b[∂L]0_ []] _<_ 4[ϵ] [implies]

E[Z _ℓ(x) = 0]_ E[Z _ℓ(x) = 1]_ _< [ϵ]_
_|_ _−_ _|_ 2 _[,]_

which is a contradiction. So P[∆ _< 0|ℓ(x) = 0] < 4ϵ. Similarly, P[∆_ _> 0|ℓ(x) = 1] < 4ϵ._

_Proof of Theorem 6.2. If the i-th neuron is of “good type”, from Corollary A.4, we find a uniform_
lower bound of m[i]0 _[−]_ _[m]1[i]_ [in “good type” regimes. We have][ min][{][ p][−]2 _[q]_ _[,][ Λ][3][}][ =][ p][−]2_ _[q]_ [. Next we estimate]

_αi −_ _αi[′]_ [and][ β][i][ −] _[β]i[′][. Let][ A][(]i[k][)]_ := αi[(][k][)] _−_ _αi[′][(][k][)], Bi[(][k][)]_ := βi[(][k][)] _−_ _βi[′][(][k][)]. We have_

_∂L_ _∂L_

_A[(]i[k][)]_ = αi[(][k][)] _αi[′][(][k][)]_ = αi[(][k][−][1)] _αi[′][(][k][−][1)]_ _ηk_
_−_ _−_ _−_  _∂αi[(][k][−][1)]_ _−_ _∂αi[′][(][k][−][1)]_ 

_∂L_ _∂L_

_Bi[(][k][)]_ = βi[(][k][)] _βi[′][(][k][)]_ = βi[(][k][−][1)] _βi[′][(][k][−][1)]_ _ηk_ _,_
_−_ _−_ _−_  _∂βi[(][k][−][1)]_ _−_ _∂βi[′][(][k][−][1)]_ 


By Theorem B.7, in G1 and G2,1, with probability ≥ 1 − _O(_ _n[1]_ [)][,]

2

_∂L_ _p_ _q_ _p_ _q_

2

(βi _βi[′][)][E][[][Z][]]_ _−_ _λ_ _O(log[−]_ [1] n)) (βi _βi[′][)][E][[][Z][]]_ _[λ]_ _−_

_∂αi_ _−_ _∂α[∂L]i[′]_ _≤−_ _−_ _p + q_ _−_ _≤−_ _−_ 2 _p + q_

   

2

_∂L_ _p_ _q_ _p_ _q_

2

(αi _αi[′][)][E][[][Z][]]_ _−_ _λ_ _O(log[−]_ [1] n) (αi _αi[′][)][E][[][Z][]]_ _[λ]_ _−_

_∂βi_ _−_ _∂β[∂L]i[′]_ _≤−_ _−_ _p + q_ _−_ _≤−_ _−_ 2 _p + q_

   

so

2

_∂L_ _∂L_ _p_ _q_

_A[(]i[k][)]_ = A[(]i[k][−][1)] _−_ _ηk_ _∂αi[(][k][−][1)]_ _−_ _∂αi[′][(][k][−][1)]_  _≥_ _A[(]i[k][−][1)]_ + ηkE[Z [(][k][)]] _[λ]2_  _p − + q_  _Bi[(][k][−][1)]_

2

_p_ _q_

= A[(]i[k][−][1)] + _[λ]2_ _p − + q_ _Bi[(][k][−][1)]_

 

2

_∂L_ _∂L_ _p_ _q_

_Bi[(][k][)]_ = Bi[(][k][−][1)] _−_ _ηk_ _∂βi[(][k][−][1)]_ _−_ _∂βi[′][(][k][−][1)]_  _≥_ _Bi[(][k][−][1)]_ + ηkE[Z [(][k][)]] _[λ]2_  _p + − q_  _A[(]i[k][−][1)]_

2

_p_ _q_

= Bi[(][k][−][1)] + _[λ]2_ _p − + q_ _A[(]i[k][−][1)]._

 


2


2



In matrix form:
_A[(]i[k][)]_
_Bi[(][k][)]_

Similarly, in G2,2:
_A[(]i[k][)]_
_Bi[(][k][)]_

in G2,3:
_A[(]i[k][)]_
_Bi[(][k][)]!_


_pp−+qq_ 2

1

  

_pp−+qq_ 2

1

  


_A[(]i[k][−][1)]_
_Bi[(][k][−][1)]!_

_A[(]i[k][−][1)]_
_Bi[(][k][−][1)]!_

_A[(]i[k][−][1)]_
! Bi[(][k][−][1)]


(29)

(30)

(31)


_pp−+qq_ 2
  

1

_pp−+qq_ 2
  


_pp−+qq_ 2

1

  


_i_ _λ(Λ3_ Λ2) _p_ _q_ 2 4 _p+q_ _i_ (31)
_Bi[(][k][)]!_ _⪰_ 2(p−q) _p−+q_   1  ! Bi[(][k][−][1)]!

_−_

where Λ2 = _pq log[−]_ 3[1] n 3 n )p[2]−q[2]

(1+log[−] 3[1] n)p+q [,][ Λ][3][ =][ (1](1[−][log]log[−][−][1] 3[1] n)p+q [. A uniform relation among (29), (30) and (31)]

_−_

can be given by (30). By eigenvalue decomposition, we have

2 2k

_√2λ_ _p_ _q_ 1 2

_A[(]i[k][)]Bi[(][k][)]_ _≥_ 4[1] 1 + 8 _p − + q_ 2[−] 8[1] A[(0)]i + 2 8 Bi[(0)]

   

  2 2k 

_√2λ_ _p_ _q_

_A[(0)]i_ _[B]i[(0)]_ 1 + _−_ _._
_≥_ 8 _p + q_

   


-----

Therefore we have a uniform lower bound of m[i]0 _[−]_ _[m]1[i]_ [at the][ k][-th epoch in “good type” regime:]

2 2 2k

_λ_ _p_ _q_ _√2λ_ _p_ _q_
_m[i]0_ 1 _i_ _[B]i[(0)]_ _−_ 1 + _−_ _._

_[−]_ _[m][i]_ _[≥]_ _[A][(0)]_ 2 _p + q_ 8 _p + q_

     

Next we consider the “bad type” regime. By Corollary A.4, we have lower bound ofBsince2 and Λ B1 >3 respectively. By Theorem B.9, in Λ3[5], we have a uniform lower bound of B1 and m B[i]0 2, |αi1 −[in][ B]αi[′][|][1][ and][and][ |][ B][β][i][ −][2][:] _[β]i[′][|][ shrink. Moreover,] m[i]0_ _[−]_ _[m]1[i]_ [in][ B][1][,]

_[−]_ _[m][i]_

_m[i]0_ 1 _A[(0)]i_ _[B]i[(0)]_ _A[(0)]i_ _[B]i[(0)]_

_[−]_ _[m][i]_ _[≥−]_ (p + q)[2] _≥−_ (p + q)[2][,]

since Λ1 = [(1+log](1+log[−][−]3[1] n3[1] n)p)p[2]−+qq[2] _≤_ [2]2[p]p[2][−]+q[q][2] _≤_ _[λ]p.[(][p][ −]_ _[q][)Λ][1]_ _[λp][(][p][ −]_ _[q][)]_

Theorem B.7, we haveNext we show that |αi − _αi[′][|][ and][ |][β][i][ −]_ _[β]i[′][|][ can only increase by a limited rate in][ B][3][. From item 4 of]_


_∂L_

_βi_ _βi[′][|][O][(˜]ϵ)_

_∂αi_ _−_ _∂α[∂L]i[′]_ _≥−|_ _−_

_∂L_

= 2 _[∂L]_ _O(˜ϵ)._

_∂βi_ _−_ _∂β[∂L]i[′]_ _∂βi_ _≤_


Therefore (note that βi < βi[′][)]


_A[(]i[k][)]_ _A[(]i[k][−][1)]_ + ηk _Bi[(][k][−][1)]_ _O(˜ϵ)_
_≤_ _|_ _|_

_Bi[(][k][)]_ _Bi[(][k][−][1)]_ + ηkO(˜ϵ).
_|_ _| ≤|_ _|_

Since E[Z [(][k][)]] ≥ Ω(ϵ)[6], and ˜ϵ = o(ϵ), ϵ[2] = O( _n[1]_ [)][, so][ η][k][O][(˜]ϵ) ≤ _ηkE[Z_ [(][k][)]] _n[1]_ [=] _n1_ [. Suppose]

_A[(]i[k][)]_ _O(1), otherwise, A[(]i[k][)]_ and _Bi[(][k][)]_ increase by an even smaller rate. So we have
_≥_ _|_ _|_
_|BAi[(]i[(][k][k][)][)]|!_ _⪯_  1n1 1n1  _|BAi[(]i[(][k][k][−][−][1)][1)]|!_ _._


By eigenvalue decomposition, we have

2 2 2

_|A[(]i[k][)]Bi[(][k][)]| ≤_ 2[1] [(1 + 1]n [)][2][k][ ]|A[(0)]i _[|][ +][ |][B]i[(0)]|_ _≤_ _k_ _A[(0)]i_ + _Bi[(0)]_ (n →∞).

        

We obtained the result for “harmless type” neurons directly from Corollary 4.3.


_Proof of Lemma 6.3. Since all parameters are independent standard normal random variables, we_
have

E[(α − _α[′])[2]] = E[(β −_ _β[′])[2]] = 2,_

Var[(α − _α[′])[2]] = Var[(β −_ _β[′])[2]] = 8._

By Chebyshev’s inequality we have


_h_ 1

(αi _αi[′][)][2][ + (][β][i]_ _i[)][2][ ≤]_ [5][h][]][ ≥] [1][ −] _[O]_
_i=1_ _−_ _[−]_ _[β][′]_ _h_

X  


P[


5 xpxp[2]−+qq[2] is monotonically increasing.

6Otherwise, the model already achieves high accuracy, see the proof of Theorem 2.2


-----

For neurons initialized as “good type”, we have

2
E[α − _α[′]|α > α[′], α + α[′]_ _> 0] =_ _√π_

Var[α _α[′]_ _α > α[′], α + α[′]_ _> 0] = 2_
_−_ _|_ _−_ 4[1]π

1
E[β − _β[′]|β > β[′]] =_ _√π_


Var[β − _β[′]|β > β[′]] = 2 −_ _π [1]_ _[.]_

Let ρ denote the probability that a neuron is initialized as “good type”. By G1, G2 and symmetry,
_ρ = 2P[α > α[′], α + α[′]_ _> 0, β > β[′]]. Since_

P[α > α[′], α + α[′]] = [1]

4 _[,][ P][[][β > β][′][] = 1]2_ _[,]_


we have ρ = [1]4 [. By Chernoff bound,][ P][[][h][g][ ≥] _[ρ]2_ _[h][]][ ≥]_ [1][−][exp (][−] _[ρ]4[2]_ _[h][)][, so][ P][[][h][g][ ≥]_ _[h]8_ []][ ≥] [1][−][exp (][−] 64[h] [)][.]

Also by Chebyshev’s inequality,


_αi_ _αi[′][||][β][i]_ _i[| ≥]_ _[h][g]_ 1 _hg_ 4π1 [2]
_|_ _−_ _[−]_ _[β][′]_ 2π _≥_ _[h]8 []][ ≥]_ [1][ −] [4][ −]hgk[2][ .]

_[−]_ _[k]_

  


P[

the i-th neuron
initialized asX
“good type”

1

10π [,]

P[


Set k =


1

_hg_
_≥_ _[h]8 []][ ≥]_ [1][ −] _[O] _ _h_


_αi_ _αi[′][||][β][i]_ _i[| ≥]_ _[h]_
_|_ _−_ _[−]_ _[β][′]_ 80


the i-th neuron
initialized as
“good type”

P[
X


So we have


_αi_ _αi[′][||][β][i]_ _i[| ≥]_ _[h]_
_|_ _−_ _[−]_ _[β][′]_ 80 []]


the i-th neuron
initialized as
“good type”


_αi_ _αi[′][||][β][i]_ _i[| ≥]_ _[h]_
_|_ _−_ _[−]_ _[β][′]_ 80


_hg_
_≥_ _[h]8 []][P][[][h][g][ ≥]_ _[h]8 []]_


_≥_ P[

the i-th neuron
initialized asX
“good type”


1
1 _O_
_≥_ _−_ _h_
  1 

1 _O_
_≥_ _−_ _h_
  


(1 exp
 _−_   _−_ 64[h]


D EXPERIMENTS ON DYNAMICS OF HIDDEN NEURONS

This experiment verifies our argument in Sections B.1, B.2, B.3 and Theorem 6.2 about the dynamics
of hidden neurons. We set h = 5, λ = 0.3 and train the model on graphs sampled from SBM with
_n = 1000, a = 1.0, b = 0.7. The plot of accuracy and its distribution can be seen in Section 7. Here_
we plot the dynamics of all the 5 hidden neurons in Figure 4, with each row corresponding to one
hidden neuron. In each plot, x-axis represents epoch and y-axis represents the value of neurons. The
first column depicts αi and αi[′][, the second column][ |][ α]α[i][′]i _i[|][, the fourth column]_

_βi, βi[′]_ [and the last column][ |][β][i][ −] _[β]i[′][|][. As shown in the figure, the first, second and fourth neurons are][|][, the third column][ |][α][i][ −]_ _[α][′]_
of “good" type satisfying (G2). Throughout training these neurons are preserved as “good" type:

All of these verify our argument in B.1. The third neuron is “harmless" satisfying (they’re order-aligned, | _[α]α[i][′]i_ _[|][ is lowered bounded by 1, and both][ |][α][i][ −]_ _[α]|[′][,][ |][β][i][ −]_ _[β]i[′][|][ keeps increasing.]H2). As shown_


-----

in B.3, this neuron isn’t updated and doesn’t make contribution to the output. The fifth neuron is of
“bad" type satisfying (second and fourth row (“good" neurons), they increase at a much smaller rate. This verifies our resultB2). Although |αi − _αi[′][|][ and][ |][β][i][ −]_ _[β]i[′][|][ increase, but by comparing with the first,]_
in Theorem 6.2.

Figure 4: Dynamics of neurons of different types. The 1st, 2nd and 4th row correspond to neurons of
“good" type satisfying (G2). The 3rd row corresponds to “harmless" satisfying (H2). The 5th row
corresponds to “bad" type satisfying (B2). Their dynamics verify our results in Sections B.1, B.2,
B.3 and Theorem 6.2.

E TABLE OF NOTATIONS

We list the notations used in this paper for readers’ convenience.


-----

Notation Definition

_n_ number of vertices in a graph

_p_ probability of intra-community connection

_q_ probability of cross-community connection

_a_ parameter for p with p = _[a][ log]n[3][ n]_

_b_ parameter for q with q = _[b][ log]n[3][ n]_

_λ_ probability of revealing the label of a vertex

_ℓ(x)_ label of vertex x

_A_ adjacency matrix of a graph

_Aˆ_ normalized adjacency matrix with self loop _A[ˆ] =_ _n(p2+q)_ [(][A][ +][ I][)]

_X_ input feature of a graph

_W_ [(0)] trainable weights in the first layer of GCN

_W_ [(1)] trainable weights in the second layer of GCN

_B_ bias matrix of GCN with each row of B being [b0, b1]

_b0_ bias in the first component

_b1_ bias in the second component

_h_ number of hidden features

_f0_ logit in the first component without bias

_f1_ logit in the second component without bias

_g0_ logit in the first component, g0 = f0 + b0

_g1_ logit in the second component, g1 = f1 + b1

∆ difference between logit, ∆= g0 − _g1 = f0 −_ _f1 + b0 −_ _b1_


-----


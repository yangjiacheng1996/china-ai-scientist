# ON THE IMPACT OF CLIENT SAMPLING ON FEDER## ATED LEARNING CONVERGENCE

**Anonymous authors**
Paper under double-blind review

ABSTRACT

While clients’ sampling is a central operation of current state-of-the-art federated learning (FL) approaches, the impact of this procedure on the convergence
and speed of FL remains under-investigated. In this work we introduce a novel
decomposition theorem for the convergence of FL, allowing to clearly quantify
the impact of client sampling on the global model update. Contrarily to previous convergence analyses, our theorem provides the exact decomposition of a
given convergence step, thus enabling accurate considerations about the role of
client sampling and heterogeneity. First, we provide a theoretical ground for previously reported experimental results on the relationship between FL convergence
and the variance of the aggregation weights. Second, we prove for the first time
that the quality of FL convergence is also impacted by the resulting covariance
between aggregation weights. Our theory is general, and is here applied to Multinomial Distribution (MD) and Uniform sampling, the two default client sampling
schemes of FL, and demonstrated through a series of experiments in non-iid and
unbalanced scenarios. Our results suggest that MD sampling should be used as
default sampling scheme, due to the resilience to the changes in data ratio during
the learning process, while Uniform sampling is superior only in the special case
when clients have the same amount of data.

1 INTRODUCTION

Federated Learning (FL) has gained popularity in the last years as it enables different clients to
jointly learn a global model without sharing their respective data. Among the different FL approaches, federated averaging (FedAvg) has emerged as the most popular optimization scheme
(McMahan et al., 2017). An optimization round of FedAvg requires data owners, also called clients,
to receive from the server the current global model which they update on a fixed amount of Stochastic Gradient Descent (SGD) steps before sending it back to the server. The new global model is then
created as the weighted average of the client updates, according to their data ratio.

FedAvg was first proven to converge experimentally (McMahan et al., 2017), before theoretical
guarantees were provided for any non-iid federated dataset (Wang et al., 2020a; Karimireddy et al.,
2020; Haddadpour & Mahdavi, 2019; Khaled et al., 2020). A drawback of naive implementations
of FedAvg consists in requiring the participation of all the clients at every optimization round. As
a consequence, the efficiency of the optimization is limited by the communication speed of the
slowest client, as well as by the server communication capabilities. To mitigate this issue, the
original FedAvg algorithm already contemplated the possibility of considering a random subset of
_m clients at each FL round. It has been subsequently shown that, to ensure the convergence of_
FL to its optimum, clients must be sampled such that in expectation the resulting global model
is identical to the one obtained when considering all the clients (Wang et al., 2020a; Cho et al.,
2020). Clients sampling schemes compliant with this requirement are thus called unbiased. Due
to its simplicity and flexibility, the current default unbiased sampling scheme consists in sampling
_m clients according to a Multinomial Distribution (MD), where the sampling probability depends_
on the respective data ratio (Li et al., 2020a; Wang et al., 2020a; Li et al., 2020c; Haddadpour
& Mahdavi, 2019; Li et al., 2020b; Wang & Joshi, 2018; Fraboni et al., 2021). Nevertheless, when
clients have identical amount of data, clients can also be sampled uniformly without replacement (Li
et al., 2020c; Karimireddy et al., 2020; Reddi et al., 2021; Rizk et al., 2020). In this case, Uniform
sampling has been experimentally shown to yield better results than MD sampling (Li et al., 2020c).


-----

In spite of the practical usage of sampling in FL, the impact of different unbiased client sampling
schemes on the convergence and speed of FL remains to date under-investigated. In (Fraboni et al.,
2021), MD sampling was extended to account for collections of sampling distributions with varying client sampling probability, to define clustered sampling. From a theoretical perspective, this
approach was proven to have identical convergence guarantees of MD sampling, with albeit experimental improvement justified by lower variance of the clients’ aggregation weights. Another study
investigated the convergence guarantees of FedAvg under different sampling schemes, through a
penalized optimization framework (Li et al., 2020c). These studies reflect the ongoing interest and
need for a theoretical framework to elucidate the impact of client sampling on FL convergence.

The main contribution of this work consists in deriving a decomposition theorem for the convergence
of FL, allowing to clearly quantify the impact of client sampling on the global model update at
any FL round. This contribution has important theoretical and practical implications. First, we
demonstrate the dependence of FL convergence on the variance of the aggregation weights. Second,
we prove for the first time that the convergence speed is also impacted through sampling by the
resulting covariance between aggregation weights. Contrarily to the convergence bound illustrated
in (Li et al., 2020c), our theorem provides the exact decomposition of a given convergence step,
thus enabling accurate quantification of the role of client sampling and heterogeneity in FL. From
a practical point of view, we establish both theoretically and experimentally that client sampling
schemes based on aggregation weights with sum different than 1 are less efficient. We also prove
that MD sampling is outperformed by Uniform sampling only when clients have identical data ratio.
Finally, we show that the comparison between different client sampling schemes is appropriate only
when considering a small number of clients. Our theory ultimately shows that MD sampling should
be used as default sampling scheme, due to the favorable statistical properties and to the resilience
to FL applications with varying data ratio and heterogeneity.

Our work is structured as follows. In Section 2, we provide formal definitions for FL, unbiased client
sampling, and for the server aggregation scheme. In Section 3, we introduce our decomposition
theorem (Theorem 1) relating the convergence of FL to the aggregation weight variance of the client
sampling scheme. Consistently with our theory, in Section 4, we experimentally demonstrate the
importance of the clients aggregation weights variance and covariance on the convergence speed,
and conclude by recommending Uniform sampling for FL applications with identical client ratio,
and MD sampling otherwise.

2 BACKGROUND

Before investigating in Section 3 the impact of client sampling on FL convergence, we recapitulate
in Section 2 the current theory behind FL aggregation schemes for clients local updates. We then
introduce a formalization for unbiased client sampling.

2.1 AGGREGATING CLIENTS LOCAL UPDATES

In FL, we consider a set I of n clients each respectively owning a dataset Di composed of ni
samples. FL aims at optimizing the average of each clients local loss function weighted by pi such
that _i=1_ _[p][i][ = 1][, i.e.]_

_n_

(θ) = _pi_ _i(θ),_ (1)

[P][n] _L_ _L_

_i=1_

X

where θ represents the model parameters. The weight pi can be interpreted as the importance given
by the server to client i in the federated optimization problem. While any combination of _pi_ is
_{_ _}_
possible, we note that in practice, either (a) every device has equal importance, i.e. pi = 1/n, or (b)
every data point is equally important, i.e. pi = ni/M with M = _i=1_ _[n][i][. Unless stated otherwise,]_
in the rest of this work, we consider to be in case (b), i.e. _i, pi_ = 1/n.
_∃_ _̸_

In this setting, to estimate a global model across clients, FedAvg (McMahan et al., 2017) is an[P][n]
iterative training strategy based on the aggregation of local model parameters. At each iteration step
_t, the server sends the current global model parameters θ[t]_ to the clients. Each client updates the
respective model by minimizing the local cost function _i(θ) through a fixed amount K of SGD_
_L_
steps initialized with θ[t]. Subsequently each client returns the updated local parameters θi[t][+1] to the


-----

server. The global model parameters θ[t][+1] at the iteration step t + 1 are then estimated as a weighted
average:


_θ[t][+1]_ =


_piθi[t][+1]._ (2)
_i=1_

X


To alleviate the clients workload and reduce the amount of overall communications, the server often
considers m ≤ _n clients at every iteration. In heterogeneous datasets containing many workers,_
the percentage of sampled clients m/n can be small, and thus induce important variability in the
new global model, as each FL optimization step necessarily leads to an improvement on the m
sampled clients to the detriment of the non-sampled ones. To solve this issue, Reddi et al. (2021);
Karimireddy et al. (2020); Wang et al. (2020b) propose considering an additional learning rate ηg
to better account for the clients update at a given iteration. We denote by ωi(St) the stochastic
aggregation weight of client i given the subset of sampled clients St at iteration t . The server
aggregation scheme can be written as:


_θ[t][+1]_ = θ[t] + ηg

2.2 UNBIASED CLIENTS SAMPLING


_ωi(St)(θi[t][+1]_ _θ[t])._ (3)
_−_
_i=1_

X


While FedAvg was originally based on the uniform sampling of clients (McMahan et al., 2017), this
scheme has been proven to be biased and converge to a suboptimal minima of problem (1) (Wang
et al., 2020a; Cho et al., 2020; Li et al., 2020c). This was the motivation for Li et al. (2020c) to
introduce the notion of unbiasedness, where clients are considered in expectation subject to their
importance pi, according to Definition 1 below. Unbiased sampling guarantees the optimization of
the original FL cost function, while minimizing the number of active clients per FL round. We note
that unbiased sampling is not necessarily related to the clients distribution, as this would require to
know beforehand the specificity of the clients’ datasets.

Unbiased sampling methods (Li et al., 2020a;c; Fraboni et al., 2021) are currently among the standard approaches to FL, as opposed to biased approaches, known to over- or under-represent clients
and lead to suboptimal convergence properties (McMahan et al., 2017; Nishio & Yonetani, 2019;
Jeon et al., 2020; Cho et al., 2020), or to methods requiring additional computation work from
clients (Chen et al., 2020a).
**Definition 1 (Unbiased Sampling). A client sampling scheme is said unbiased if the expected value**
_of the client aggregation is equal to the global deterministic aggregation obtained when considering_
_all the clients, i.e._

_n_ _n_

ESt _wi(St)θi[t]_ := _piθi[t][,]_ (4)

" _i=1_ # _i=1_
X X

_where wj(St) is the aggregation weight of client j for subset of clients St._

The sampling distribution uniquely defines the statistical properties of stochastic weights. In this
setting, unbiased sampling guarantees the equivalence between deterministic and stochastic weights
in expectation. Unbiased schemes of primary importance in FL are MD and Uniform sampling, for
which we can derive a close form formula for the aggregation weights :

**MD sampling. This scheme considers l1, ..., lm to be the m iid sampled clients from a Multinomial**
Distribution with support on {1, ..., m} satisfying P(lk = i) = pi (Wang et al., 2020a; Li et al.,
2020a;c; Haddadpour & Mahdavi, 2019; Li et al., 2020b; Wang & Joshi, 2018; Fraboni et al., 2021).
By definition, we have _i=1_ _[p][i][ = 1][, and the clients aggregation weights take the form:]_

_m_

[P][n] _ωi(St) = [1]_ I(lk = i). (5)

_m_

_k=1_

X

**Uniform sampling. This scheme samples m clients uniformly without replacement. Since in this**
case a client is sampled with probability p( _i_ _St_ ) = m/n, the requirement of Definition 1
_{_ _∈_ _}_
implies:
_ωi(St) = I(i_ _St)_ _[n]_ (6)
_∈_ _m_ _[p][i][.]_


-----

Table 1: Synthesis of statistical properties of different sampling schemes.

Sampling Var [ωi(St)] _α_ Var [[P][n]i=1 _[ω][i][(][S][t][)]]_

Full participation = 0 = 0 = 0
MD = _m_ _[p]i[2]_ [+][ 1]m _[p][i]_ = 1/m = 0

Uniform = − nm[1] _p[2]i_ = _mn(−n_ _m1)_ = _mn(−n_ _m1)_ [[][n][ P]i[n]=1 _[p]i[2]_

_[−]_ [1] _−_ _−_ _[−]_ [1]]

  

We note that this formulation for Uniform sampling is a generalization of the scheme previously
used for FL applications with identical client importance, i.e. pi = 1/n (Karimireddy et al., 2020;
Li et al., 2020c; Reddi et al., 2021; Rizk et al., 2020). We note that Var [[P][n]i=1 _[ω][i][(][S][t][)] = 0][ if and]_
only if pi = 1/n for all the clients as, indeed, _i=1_ _[ω][i][(][S][t][) =][ m][ n]m_ _n1_ [= 1]

With reference to equation (3), we note that by setting ηg = 1, and by imposing the condition
_∀St,_ _i=1_ _[ω][i][(][S][t][) = 1][, we retrieve equation (2). This condition is satisfied for example by MD][P][n]_
sampling and Uniform sampling for identical clients importance.

We finally note that the covariance of the aggregation weights for both MD and Uniform sam-[P][n]
pling is such that there exists an α such that _i_ = j, Cov [ωi(St), ωj(St)] = _αpipj._ We
_∀_ _̸_ _−_
provide in Table 1 the derivation of α and the resulting covariance for these two schemes with
calculus details in Appendix A. Furthermore, this property is common to a variety of sampling
schemes, for example based on Binomial or Poisson Binomial distributions (detailed derivations
can be found in Appendix A). Following this consideration, in addition to Definition 1, in the
rest of this work we assume the additional requirement for a client sampling scheme to satisfy
_α_ 0, _i_ = j, Cov [ωi(St), ωj(St)] = _αpipj._
_∃_ _≥_ _∀_ _̸_ _−_


3 CONVERGENCE GUARANTEES

Based on the assumptions introduced in Section 2, in what follows we elaborate a new theory relating
the convergence of FL to the statistical properties of client sampling schemes. In particular, Decomposition Theorem 1 describes the impact of client sampling on a single optimization step, while
Theorem 2 quantifies the asymptotic relationship between client sampling and FL convergence.

3.1 DECOMPOSITION THEOREM

**Assumption 1 (Unbiased Gradient and Bounded Variance). Every client stochastic gradient**
_gi(x_ _B) of a model x evaluated on batch B is an unbiased estimator of the local gradient. We_
_|_

_thus have EB [ξi(B)] = 0 and 0 ≤_ EB _∥ξi(B)∥[2][i]_ _≤_ _σ[2], with ξi(B) = gi(x|B) −∇Li(x)._
h

the following Decomposition Theorem highlights the impact of client sampling on a single FL optimization step. For any optimization round, it provides an explicit link between the statistical
properties of the sampling scheme (variance and covariance) and the expected distance between the
global model and the related optimum.

**Theorem 1 (Decomposition Theorem). We consider yi,k[t]** _[the local model of client][ i][ after][ k][ SGD]_
_steps initialized on model θ[t]. We consider the vector ξi[t]_ _[of the gradient noises][ ξ]i,k[t]_ [= [][g][i][(][y]i,k[t] [)][ −]

_∇Lscheme satisfying Definition 1, and such thati(yi,k[t]_ [)]][ satisfying Assumption 1, and][ ∆]i[t] Cov [[=][ P]ω[K]k=0i[−](S[1] _t[∇L]), ω[i]j[(]([y]Si,k[t]t)] =[)][. We consider a client sampling]αpipj. For any given opti-_
_−_
_mization round based on equation (3), the following equation holds:_


Et **_θ[t][+1]_** _−_ **_θ[∗]_** = **_θ[t]_** _−_ **_θ[∗]_** _−_ 2ηg ⟨
h

[2][i] [2]


_n_

_pi Et_ **_θi[t][+1]_** _−_ **_θ[t][]_** _, θ[∗]_ _−_ **_θ[t]⟩_**
_i=1_

X 

_Direction drift_
{z }


+ηg[2][η]l[2][Q][(][θ][t][)] (7)


-----

_with_


2[]




_n_

_νi_ Et **_ξi[t]_**
_i=1_

X _Gradient Estimator Noiseh_

=Ni(θ[t])[2][i]
| {z }


_n_

_γi Et_ **∆[t]i**
_i=1_

X _Local Model Drifth_

=Li(θ[t]) [2][i]
| {z }



[]

_Q(θ[t]) =_ _νi_ Et **_ξi[t]_** + _γi Et_ **∆[t]i** +(1 _α) Et_ _pi∆[t]i_ _,_ (8)

_−_ 

_i=1_ _i=1_ _i=1_

X _Gradient Estimator Noiseh_ X _Local Model Drifth_ X

=Ni(θ[t])[2][i] =Li(θ[t]) [2][i] Global Model Drift 
| {z } | {z } =G( _pi_ _,θ[t])_

_{_ _}_
| {z }

_where θ[∗]_ _is the optimum of the optimization problem (1), νi =_ Var [ωi(St)] + p[2]i _, γi =_
Var [ωi(St)] + αp[2]i _[, and][ E][t][ [][X][]][ is the expected value of][ X][ conditioned on][ θ][t][.]_
 

The Decomposition Theorem (proof in Appendix B) shows that FL convergence is impacted by a
client sampling through the quantities Var [ωi(St)] and α, which both depend on the clients aggregation weights. These variables modulate three quantities, Ni(θ[t]), Li(θ[t]) and G( _pi_ _, θ[t]), rep-_
_{_ _}_
resenting respectively the stochastic gradient estimator noise, and the local and global model drift
from the current initialization, which are independent from client sampling. In particular, the quality
of clients data impacts the convergence speed through Ni(θ[t]). The Decomposition Theorem also
provides a necessary condition for an optimization step to improve the current global model: the expected client contribution Et _ni=1_ _[p][i]_ **_θi[t][+1]_** **_θ[t][]_** needs to be collinear with the global direction
_−_
of the optimum θ[∗] **_θ[t]._**
_−_ P 

To further clarify the influence of client sampling on the FL convergence we introduce the following property (proof in Appendix A.1) introducing the quantity Var [[P][n]i=1 _[ω][i][(][S][t][)]][, the variance of]_
the sum of the aggregation weights, and showing its relationship with the variance of the clients
aggregation weights Var [ωi(St)], and with the covariance parameter α.
**Property 1. For any client sampling, we have 0 ≤** _α ≤_ 1 and

_n_ _n_ _n_

Var _ωi(St)_ = Var [ωi(St)] _α_ 1 _p[2]i_ _._ (9)

" _i=1_ # _i=1_ _−_ " _−_ _i=1_ #
X X X

Since 0 _α_ 1, the global model drift G( _pi_ _, θ[t]) contributes positively to equation (8), and the_
_≤_ _≤_ _{_ _}_
term Q(θ[t]) is always positive. This means that Q(θ[t]) is not negligible, and an appropriate sampling
scheme should be defined such that Q(θ[t]) is minimized. We note that the impact of a client sampling
can always be mitigated by considering a smaller local learning rate ηl. Indeed, the client drift is
proportional to ηl while Q(θ[t]) is proportional to ηl[2][.]

3.2 ASYMPTOTIC FL CONVERGENCE WITH RESPECT TO CLIENT SAMPLING

To prove FL convergence with client sampling, our work relies on the following two assumptions
(Wang et al., 2020a; Li et al., 2020a; Karimireddy et al., 2020; Haddadpour & Mahdavi, 2019; Wang
et al., 2019a;b):
**Assumption 2 (Smoothness). The clients local objective function is L-Lipschitz smooth, that is,**
_i_ 1, ..., n _,_ _i(x)_ _i(y)_ _L_ _x_ _y_ _._
_∀_ _∈{_ _}_ _∥∇L_ _−∇L_ _∥≤_ _∥_ _−_ _∥_
**Assumption 3 (Bounded Dissimilarity ). There exist constants β[2]** _≥_ 1 and κ[2] _≥_ 0 such that for ev_ery combination of positive weights_ _wi_ _such that_ _i=1_ _[w][i][ = 1][, we have][ P]i[n]=1_ _[w][i][ ∥∇L][i][(][x][)][∥][2][ ≤]_
_{_ _}_
_β[2]_ _∥∇L(x)∥[2]_ + κ[2]. If all the local loss functions are identical, then we have β[2] = 1 and κ[2] = 0.

[P][n]

We formalize in the following theorem the relationship between the statistical properties of the client
sampling scheme and the asymptotic convergence of FL (proof in Appendix C).
**Theorem 2 (FL convergence). Let us consider a client sampling scheme satisfying Definition 1 and**
_such that for i_ = j, Cov [ωi(St), ωj(St)] = _αpipj_ 0. Under Assumptions 1 to 3, and with
_sufficiently small local step size ̸_ _ηl, the following convergence bound holds: −_ _≤_


_Q(θ[t]) =_


+(1 − _α) Et_


_T −1_

E _∇L(θ[t])_ _≤O_
_t=0_

X h

[2][i]

+ O


+ _ηl[2][(][K][ −]_ [1)][σ][2][] + _ηl[2][K][(][K][ −]_ [1)][κ][2][]
_O_ _O_

_n_    

_p[2]i_ _σ[2]_ + _ηgηlγ_ (K 1)σ[2] + Kκ[2][] _, (10)_
_i=1_ # ! _O_ _−_

X   


_ηgηlKT_


_ηgηl_


Σ +


-----

_where K is the number of local SGD, and_


Var [ωi(St)] and γ =
_i=1_

X


_p[2]i_ _[.]_ (11)
_i=1_

X


Σ =


Var [ωi(St)] + α
_i=1_

X


We first observe that any client sampling scheme satisfying the assumptions of Theorem 2 converges
to its optimum. Through Σ and γ, equation (10) shows that our bound is proportional to the clients
aggregation weights through the quantities Var [ωi(St)] and α, which thus should be minimized.
These terms are non-negative and are minimized and equal to zero only with full participation of the
clients to every optimization round. Theorem 2 does not require the sum of the weights ωi(St) to be
equal to 1. Yet, for client sampling satisfying Var [[P][n]i=1 _[ω][i][(][S][t][)] = 0][, we get][ α][ ∝]_ [Σ][. Hence, choos-]
ing an optimal client sampling scheme amounts at choosing the client sampling with the smallest Σ.
This aspect has been already suggested in Fraboni et al. (2021).

The convergence guarantee proposed in Theorem 2 extends the work of Wang et al. (2020a) where,
in addition of considering FedAvg with clients performing K vanilla SGD, we include a server
learning rate ηg and integrate client sampling (equation (3)). With full client participation (Σ = γ =
0) and ηg = 1, we retrieve the convergence guarantees of Wang et al. (2020a). Furthermore, our
theoretical framework can be applied to any client sampling satisfying the conditions of Theorem
2. In turn, Theorem 2 holds for full client participation, MD sampling, Uniform sampling, as well
as for the other client sampling schemes detailed in Appendix A. Finally, the proof of Theorem
2 is general enough to account for FL regularization methods (Li et al., 2020a; 2019; Acar et al.,
2021), other SGD solvers (Kingma & Ba, 2015; Ward et al., 2019; Li & Orabona, 2019), and/or
gradient compression/quantization (Reisizadeh et al., 2020; Basu et al., 2019; Wang et al., 2018).
For all these applications, the conclusions drawn for client samplings satisfying the assumptions of
Theorem 2 still hold.

3.3 APPLICATION TO CURRENT CLIENT SAMPLING SCHEMES

**MD sampling. When using Table 1 to compute Σ and γ close-form we obtain:**


ΣMD = [1]


and γMD = [1] (12)

_m_ _[,]_


_p[2]i_
_i=1_

X


1 −


where we notice thatthan the ones of Theorem 2, independently from the amount of participating clients ΣMD ≤ _m[1]_ [=][ γ][MD][. Therefore, one can obtain looser convergence guarantees] n and set of

clients importance _pi_, while being inversely proportional to the amount of sampled clients m. The
_{_ _}_
resulting bound shows that FL with MD sampling converges to its optimum for any FL application.

**Uniform sampling. Contrarily to MD sampling, the stochastic aggregation weights of Uniform**
sampling do not sum to 1. As a result, we can provide FL scenarios diverging when coupled with
Uniform sampling. Indeed, using Table 1 to compute Σ and γ close-form we obtain

_n_ _n_ 1 _n_ _n_
ΣU = _p[2]i_ [and][ γ][U] [=] 1 + _p[2]i_ _[,]_ (13)

_m_ _n_ 1 _m_

h _[−]_ [1]i Xi=1  _−_  h _[−]_ [1]i Xi=1

where we notice that γU = 1 + _n1_ 1 ΣU . Considering that _i=1_ _[p]i[2]_ _m_

_−_ _[≤]_ [1][, we have][ Σ][U][ ≤] _[n]_ _[−]_ [1][,]

which goes to infinity for large cohorts of clients and thus prevents FL with Uniform sampling toh i
converge to its optimum. Indeed, the conditionof client importance {pi}, including the very heterogeneous ones. In the special case wherei=1 _[p]i[2]_ _[≤]_ [1][P][ accounts for every possible scenario][n] _pi =_
1/n, we have _i=1_ _[p]i[2]_ [= 1][/n][, such that][ Σ][U][ is inversely proportional to both][P][n] _[ n][ and][ m][. Such FL]_
applications converge to the optimum of equation (1) for any configuration of n, _pi_ and m.
_{_ _}_

Moreover, the comparison between the quantities[P][n] Σ and γ for MD and Uniform sampling shows that
Uniform sampling outperforms MD sampling when pi = 1/n. More generally, Corollary 1 provides
sufficient conditions with Theorem 2 for Uniform sampling to have better convergence guarantees
than MD sampling (proof in Appendix C.7).
**Corollary 1.ΣMD, and γU Uniform sampling has better convergence guarantees than MD sampling whenγMD which is equivalent to** ΣU ≤
_≤_ _n_


_p[2]i_
_i=1_ _[≤]_

X


1

(14)
_n_ _m + 1_ _[.]_
_−_


-----

Corollary 1 can be related to Var [[P][n]i=1 _[ω][i][(][S][t][)]][, the variance for the sum of the aggregation weights,]_
which is always null for MD sampling, and different of 0 for Uniform sampling except when pi =
1/n for all the clients.

A last point of interest for the comparison between MD and Uniform sampling concerns the respective time complexity for selecting clients. Sampling with a Multinomial Distribution has time
complexity O(n + m log(n)), where O(n) comes from building the probability density function
to sample clients indices (Tang, 2019). This makes MD sampling difficult to compute or even intractable for large cohorts of clients. On the contrary sampling m elements without replacement
from n states is a reservoir sampling problem and takes time complexity O(m(1 + log(n/m))(Li,
1994). In practice, clients either receive identical importance (pi = 1/n) or an importance proportional to their data ratio, for which we may assume computation pi = O( _n[1]_ [)][. As a result, for]

important amount n of participating clients, Uniform sampling should be used as the default client
sampling due to its lower time complexity. However, for small amount of clients and heterogeneous
client importance, MD sampling should be used by default.

Due to space constraints, we only consider in this manuscript applying Theorem 2 to Uniform and
MD sampling, which can also be applied to Binomial and Poisson Binomial sampling introduced
in Section A, and satisfying our covariance assumption. To the best of our knowledge, we could
only find clustered sampling introduced in Fraboni et al. (2021) not satisfying this assumption. Still,
with minor changes, we provide for this sampling scheme a similar bound to the one of Theorem 2
(Appendix C.6), ultimately proving that clustered sampling improves MD sampling.

4 EXPERIMENTS

In this section we provide an experimental demonstration of the two main theorems of Section
3, by quantifying the correctness of Decomposition Theorem 1, and by verifying the convergence
properties identified in Theorem 2.

4.1 SYNTHETIC EXPERIMENT

We consider a synthetic FL experiment where the clients models are defined by quadratic local loss
functions. This choice enables closed-form computation of the global optimum, as well as of the
expectation of the distance between global model and optimum during a single FL optimization step.

We consider n = 10 clients jointly learning a model with m = 5 of them sampled by the server
at each optimization step. Each client local loss function is _i(θ) =_ [1]2 _i_

**_θi[∗]_** _L_ _[∥][θ][ −]_ **_[θ][∗][∥][2][ with optimum]_**
global loss function of equation (1) is[∼] _[N]_ [(0][d][, I][d][)][, where][ d][ = 20][ is the number of parameters in the model. The optimum of the] θ[∗] = _i=1_ _[p][i][θ]i[∗][. We consider varying][ p][1][, the importance of]_
client 1, while giving identical importance to the remaining clients, i.e.

_p1 = r and pi = (1[P][n]_ _−_ _r)/(n −_ 1), i ̸= 1. (15)

By varying r between 0 and 1, we investigate scenarios with different level of heterogeneity for the
clients importance. We perform full gradient descents, which makes client sampling the only source
of randomness during optimization. Lastly, we only consider a single FL optimization step initialized with a global model θ[0] _N_ (0d, Id). We compare the average distance of 1000 simulations
_∼_
obtained after a single FL round to the theoretical one provided by the Decomposition Theorem 1
(see Appendix D for the closed form equation derived for the controlled example here proposed).
The scenario above is tested in two different experimental settings: an iid one, where θi[∗] [=][ θ]1[∗][, and]
a non-iid one, where every client local model is drawn independently.

The theoretical expected distance **_θ[1]_** _−_ **_θ[∗]_** is plotted for iid and non-iid case in Figure 1a and 1b.
The corresponding experimental distance resulting from the 1000 simulations is shown in Figure 1c
and 1d. We note that there is a close match between theoretical and experimental results, demon-[2]
strating the validity of Decomposition Theorem 1. Figure 1 highlights the following properties:

**Iid case (Figure 1a and 1c). In the iid setting the expected difference obtained with MD sampling**
is equivalent to the one obtained when all the clients are considered (Full). This demonstrates that
in the iid case the covariance parameter α does not affect FL convergence (Section 3). Moreover,
Uniform sampling leads to generally poor convergence results, thus confirming that the variance of


-----

|(|c)|
|---|---|
|||


0.0 0.5 1.0

p1


|(d|)|
|---|---|
|||


0.0 0.5 1.0

p1


4.0

3.5

3.0

2.5

2.0

1.5


4.0

3.5

3.0

2.5

2.0

1.5


4.0

3.5

3.0

2.5

2.0


4.0

3.5

3.0

2.5

2.0

1.5

1.0


1.0

|Col1|(a)|
|---|---|
|Full MD Uniform||


0.0 0.5 1.0

p1


1.5

|(|b)|
|---|---|
|||


0.0 0.5 1.0

p1


Figure 1: Illustration of the Decomposition Theorem 1 for the synthetic scenario described in Section
4.1 for n = 10 clients when sampling m = 5 of them. Panels (a) and (b) show the theoretical
distances between global model and FL optimum obtained with the Decomposition Theorem 1 in
respectively iid and non-iid settings. Panels (c) and (d) show the distances estimated experimentally
when averaging over 1000 simulations for iid and non-iid settings. We consider ηg = 1, ηl = 0.1,
and K = 10.

the sum of the clients stochastic weights, VarSt [[P]i[n]=1 _[ω][i][(][S][t][)]][, negatively impacts FL convergence.]_
More precisely, the only case where Uniform sampling is comparable to the other schemes is when
_p1 = 0.1, which indeed corresponds to the special scenario in which pi = 1/n, and thus the variance_
associated to Uniform sampling is zero (cfr. Table 1).

**Non iid case (Figure 1b and 1d). The conclusions drawn for the iid case still hold when the lo-**
cal optima are not identical across clients. Moreover, we can now appreciate the impact of the
covariance parameter α on the convergence speed. Independently from the choice for p1, the minimum distance is obtained when considering all the clients. In this case we have both α = 0 and
VarSt [[P]i[n]=1 _[ω][i][(][S][t][)] = 0][. When][ p][i][ = 1][/n][ = 0][.][1][, both MD and Uniform sampling have null vari-]_
ance VarSt [[P]i[n]=1 _[ω][i][(][S][t][)]][. In this case, the negative impact of the covariance through the parameter]_
_α penalizes MD sampling. The penalization of the covariance term on MD sampling is still relevant_
when p1 is close to the critical value of 0.1. Finally, for large enough values of p1, the variance term
outweights the effect of the covariance, making MD better than Uniform sampling.

**Diverging Uniform sampling. Consistently with Figure 1, in Appendix E we provide further ex-**
amples showing that Uniform sampling can diverge in simple FL setting with heterogeneous client
importance. We still consider n = 10 clients and sample m = 5 of them with p1 = r = 0.9. When
sampled, clients perform K = 1 SGD to show that the divergence does not come from the clients
local work K. Figure 4 of Appendix E shows that for this scenario, FL with MD sampling converges
while FL with Uniform sampling diverges both for iid and non-iid client data distribution.


4.2 EXPERIMENT ON REAL DATA

We study a LSTM model for next character prediction on the dataset of The complete Works of
_William Shakespeare (McMahan et al., 2017; Caldas et al., 2018). We use a two-layer LSTM_
classifier containing 100 hidden units with an 8 dimensional embedding layer. The model takes as
an input a sequence of 80 characters, embeds each of the characters into a learned 8-dimensional
space and outputs one character per training sample after 2 LSTM layers and a fully connected one.

When selected, a client performs K = 50 SGD steps on batches of size B = 64 with local
learning rate ηl = 1.5. The server considers the clients local work with ηg = 1. We consider
_n ∈{10, 20, 40, 80} clients, and sample half of them at each FL optimization step. While for sake_
of interpretability we do not apply a decay to local and global learning rates, we note that our theory
remains unchanged even in presence of a learning rate decay. In practice, for dataset with important
heterogeneity, considering ηg < 1 can speed-up FL with a more stable convergence.

**Clients have identical importance [pi = 1/n]. We note that Uniform sampling consistently out-**
performs MD sampling due to the lower covariance parameter, while the improvement between the
resulting convergence speed is inversely proportional to the number of participating clients n (Figure
2a). This result confirms the derivations of Section 3.


-----

(a) - pi = 1/n (b) - pi = ni/M

0.0

)U 0.15
( 0.1
)MD 0.10
( 0.05 0.2

0.00

0 100 200 300 400 500 0 100 200 300 400 500

# rounds # rounds

10 20 40 80


Figure 2: Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n ∈{10, 20, 40, 80} clients and sampling m = n/2 of them. In (a),
clients have identical importance, i.e. pi = 1/n. In (b), clients importance is proportional to their
amount of data, i.e. pi = ni/M . Differences in global losses are averaged across 30 FL experiments
with different model initialization (global losses are provided in Appendix E).

**Clients importance depends on the respective data ratio [pi = ni/M** ]. In this experimental
scenario the aggregation weights for Uniform sampling do not always sum to 1, thus leading to the
slow-down of FL convergence. Hence, we see in Figure 2b that MD always outperforms Uniform
sampling. This experiment shows that the impact on FL convergence of the variance of the sum of
the stochastic aggregation weights is more relevant than the one due to the covariance parameter α.
We also note that the slow-down induced by the variance is reduced when more clients do participate.
This is explained by the fact that the standard deviation of the clients data ratio is reduced with larger
clients participation, e.g. pi = 1/10 ± 0.13 for n = 10 and pi = 1/80 ± 0.017 for n = 80. We thus
conclude that the difference between the effects of MD and Uniform sampling is mitigated with a
large number of participating clients (Figure 2b).

Additional experiments on Shakespeare are provided in Appendix E. We show the influence of the
amount of sampled clients m (Figure 6) and amount of local work K (Figure 8) on the convergence
speed of MD and Uniform sampling.

Finally, additional experiments on CIFAR10 (Krizhevsky, 2009) are provided in Appendix E, where
we replicate the experimental scenario previously proposed in Fraboni et al. (2021). In these applications, 100 clients are partitioned using a Dirichlet distribution which provides federated scenarios
with different level of heterogeneity. For all the experimental scenarios considered, both results and
conclusions are in agreement with those here derived for the Shakespeare dataset.

5 CONCLUSION

In this work, we derive a novel Decomposition Theorem demonstrating the impact on FL convergence speed of any unbiased client sampling scheme following the assumptions of Section 2.
Moreover, Theorem 2 highlights the asymptotic impact of client sampling on FL, and shows that
the convergence speed is inversely proportional to both the sum of the variance of the stochastic
aggregation weights, and to their covariance parameter α. To the best of our knowledge, this work
is the first one accounting for schemes where the sum of the weights is different from 1.

Thanks to our theory, we investigated MD and Uniform sampling from both theoretical and experimental standpoints. We established that when clients have approximately identical importance, i.e
_pi = 1/n, Uniform outperforms MD sampling, due to the larger impact of the covariance term for_
the latter scheme. On the contrary, Uniform sampling is outperformed by MD sampling in more general cases, due to the slowdown induced by its stochastic aggregation weights not always summing
to 1. Yet, in practical scenario with very large number of clients, MD sampling may be unpractical,
and Uniform sampling could be preferred due to the more advantageous time complexity. Finally,
while the contribution of this work is in the study of the impact of clients sampling on the global optimization objective, further extensions may focus on the analysis of the impact of clients selection
method on individual users’ performance, especially in presence of heterogeneity.


-----

ETHICS STATEMENT

We read and acknowledged the ICLR Code of Ethics.

The experimental correctness of our method was evaluated on publicly available datasets. Datasets
were properly referenced and their construction can be found in the associated references.

This work investigates client sampling, an FL component already introduced in previous literature.
Our work does not change the FL framework and thus does not propose additional client exposure.

There is no conflict of interest. The arguments used in this work are either theoretically proven,
experimentally illustrated, or coming from peer-reviewed work.

Our method is centered around unbiased client sampling and thus does not induce bias in the global
model.

REPRODUCIBILITY STATEMENT

Every proposed theoretical result is carefully analyzed in Section 3 and proven in Appendix. Aggregation weight calculus can be found in Appendix A, Theorem 1 can be found in Appendix B, and
Theorem 2 can be found in Appendix C.

The settings of the different experiments are specified in the paper and the code is provided. Furthermore, we use public datasets without any preprocessing.

REFERENCES

Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and
Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Con_ference on Learning Representations, 2021._

Debraj Basu, Deepesh Data, Can Karakus, and Suhas Diggavi. Qsparse-local-sgd: Distributed
sgd with quantization, sparsification and local computations. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information
_Processing Systems, volume 32. Curran Associates, Inc., 2019._

Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Koneˇcn´y, H. Brendan McMahan, Virginia Smith, and Ameet Talwalkar. LEAF: A Benchmark for Federated Settings.
(NeurIPS):1–9, 2018.

Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal Client Sampling for Federated Learning. Workshop in NeurIPS: Privacy Preserving Machine Learning, 2020a.

Wenlin Chen, Samuel Horvath, and Peter Richtarik. Optimal client sampling for federated learning,
2020b.

Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies, 2020.

Yann Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi. Clustered sampling: Lowvariance and improved representativity for clients selection in federated learning. In Marina Meila
and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning,
volume 139 of Proceedings of Machine Learning Research, pp. 3407–3416. PMLR, 18–24 Jul
2021.

Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in federated learning, 2019.

Tzu Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data
distribution for federated visual classification. arXiv, 2019.

Joohyung Jeon, Soohyun Park, Minseok Choi, Joongheon Kim, Young-Bin Kwon, and Sungrae Cho.
Optimal user selection for high-performance and stabilized energy-efficient federated learning
platforms. Electronics, 9(9), 2020. ISSN 2079-9292. doi: 10.3390/electronics9091359.


-----

Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning.
In Hal Daum´e III and Aarti Singh (eds.), Proceedings of the 37th International Conference on
_Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 5132–5143._
PMLR, 13–18 Jul 2020.

Ahmed Khaled, Konstantin Mishchenko, and Peter Richtarik. Tighter theory for local sgd on identical and heterogeneous data. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings of the
_Twenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of_
_Proceedings of Machine Learning Research, pp. 4519–4529. PMLR, 26–28 Aug 2020._

Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR (Poster),
2015.

Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.

Kim-Hung Li. Reservoir-sampling algorithms of time complexity o(n(1 + log(n/n))). ACM Trans.
_Math. Softw., 20(4):481–493, December 1994. ISSN 0098-3500. doi: 10.1145/198429.198435._

Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smithy.
Feddane: A federated newton-type method. In 2019 53rd Asilomar Conference on Signals, Sys_tems, and Computers, pp. 1227–1231, 2019. doi: 10.1109/IEEECONF44664.2019.9049023._

Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In I. Dhillon, D. Papailiopoulos, and V. Sze
(eds.), Proceedings of Machine Learning and Systems, volume 2, pp. 429–450, 2020a.

Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation in federated
learning. In International Conference on Learning Representations, 2020b.

Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of
fedavg on non-iid data. In International Conference on Learning Representations, 2020c.

Xiaoyu Li and Francesco Orabona. On the convergence of stochastic gradient descent with adaptive
stepsizes. In Kamalika Chaudhuri and Masashi Sugiyama (eds.), Proceedings of the Twenty_Second International Conference on Artificial Intelligence and Statistics, volume 89 of Proceed-_
_ings of Machine Learning Research, pp. 983–992. PMLR, 16–18 Apr 2019._

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-Efficient Learning of Deep Networks from Decentralized Data. In Aarti Singh
and Jerry Zhu (eds.), Proceedings of the 20th International Conference on Artificial Intelligence
_and Statistics, volume 54 of Proceedings of Machine Learning Research, pp. 1273–1282. PMLR,_
20–22 Apr 2017.

Takayuki Nishio and Ryo Yonetani. Client selection for federated learning with heterogeneous
resources in mobile edge. In ICC 2019 - 2019 IEEE International Conference on Communications
_(ICC), pp. 1–7, 2019. doi: 10.1109/ICC.2019.8761315._

Sashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Koneˇcn´y,
Sanjiv Kumar, and Hugh Brendan McMahan. Adaptive federated optimization. In International
_Conference on Learning Representations, 2021._

Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani.
Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings of the Twenty Third Interna_tional Conference on Artificial Intelligence and Statistics, volume 108 of Proceedings of Machine_
_Learning Research, pp. 2021–2031. PMLR, 26–28 Aug 2020._

Elsa Rizk, Stefan Vlaski, and Ali H. Sayed. Dynamic federated learning. In 2020 IEEE 21st
_International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),_
pp. 1–5, 2020. doi: 10.1109/SPAWC48557.2020.9154327.

Daniel Tang. Efficient algorithms for modifying and sampling from a categorical distribution. CoRR,
abs/1906.11700, 2019.


-----

Hongyi Wang, Scott Sievert, Shengchao Liu, Zachary Charles, Dimitris Papailiopoulos, and Stephen
Wright. Atomo: Communication-efficient learning via atomic sparsification. In S. Bengio,
H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in
_Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018._

Jianyu Wang and Gauri Joshi. Cooperative SGD: A unified Framework for the Design and Analysis
of Communication-Efficient SGD Algorithms. 2018.

Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, and Soummya Kar. Matcha: Speeding up decentralized sgd via matching decomposition sampling. In 2019 Sixth Indian Control
_Conference (ICC), pp. 299–300, 2019a. doi: 10.1109/ICC47138.2019.9123209._

Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H. Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. In Hugo Larochelle, Marc’Aurelio
Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural In_formation Processing Systems 33: Annual Conference on Neural Information Processing Systems_
_2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020a._

Jianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat. Slowmo: Improving
communication-efficient distributed sgd with slow momentum. In International Conference on
_Learning Representations, 2020b._

Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive Federated Learning in Resource Constrained Edge Computing Systems.
_IEEE Journal on Selected Areas in Communications, 37(6):1205–1221, 2019b. ISSN 15580008._
doi: 10.1109/JSAC.2019.2904348.

Rachel Ward, Xiaoxia Wu, and Leon Bottou. AdaGrad stepsizes: Sharp convergence over nonconvex landscapes. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th
_International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning_
_Research, pp. 6677–6686. PMLR, 09–15 Jun 2019._


-----

A CLIENTS SAMPLING SCHEMES CALCULUS

In this section, we calculate for MD, Uniform, Poisson, and Binomial sampling the respective aggregation weight variance Var [ωi(St)], the covariance parameter α such that Cov [ωi(St)), ωj(St)] =
_−αpipj, and the variance of the sum of weights Var [[P][n]i=1_ _[ω][i][(][S][t][)]][. We also propose statistics for]_
the parameter N, i.e. the amount of clients the server communicates with at an iteration:


I(i ∈ _St)._ (16)
_i=1_

X


_N =_


A.1 PROOF OF PROPERTY 1

_Proof. Covariance parameter_

Cov [ωi(St), ωj(St)] = E [ωi(St)ωj(St)] − _pipj ≥−pipj_ (17)


**Aggregation Weights Sum**

_n_

Var _ωi(St)_

" _i=1_
X


Cov [ωi(St), ωj(St)] (18)
_i,jX≠_ _i_


Var [ωi(St)] +
_i=1_

X


_pipj_ (19)
_i,jX≠_ _i_


Var [ωi(St)] _α_
_−_
_i=1_

X


= [Var [ωi(St)] _αpi(1_ _pi)]_ (20)

_−_ _−_
_i=1_

X

_n_ _n_

= Var [ωi(St)] _α_ 1 _p[2]i_ _,_ (21)

_i=1_ _−_ " _−_ _i=1_ #

X X

where we use _i=1_ _[p][i][ = 1][, equation (1), for the third and fourth equality. Using equation (20), we]_
see that we can also get the following equality based on Decomposition Theorem 1:

[P][n] _n_ _n_

Var _ωi(St)_ = _γi_ _α._ (22)

" _i=1_ # _i=1_ _−_
X X


**Re-expressing α. Using equation (20), we get**

_n_ _n_

Var _ωi(St)_ = Var [ωi(St)] _α_

" _i=1_ # _i=1_ _−_
X X


_p[2]i_
_i=1_

X


(23)


1 −


which, with reordering, gives

_n_
_i=1_ [Var [][ω][i][(][S][t][)]][ −] [Var [][P]i[n]=1 _[ω][i][(][S][t][)]]_
_α =_ _._ (24)
P 1 − [P]i[n]=1 _[p]i[2]_

A.2 NO SAMPLING SCHEME

When every client participate at an optimization round, we have ωi(St) = pi which gives
VarSt [ωi(St)] = 0, α = 0, and N = n.

A.3 MD SAMPLING

We recall equation (5),


_ωi(St) = [1]_


I(lk = i), (25)
_k=1_

X


-----

which gives

E [ωi(St)ωj(St)] =


E [I(lk = i)I(ll = j)] + [1]

_m[2]_

_k,lX≠_ _k_


E [I(lk = i)I(lk = j)] (26)
_k=1_

X


_m[2]_

1

_m[2]_


_m_

1
= _pipj + [1]_ E [I(lk = i)I(lk = j)] (27)

_m[2]_ _m[2]_

_k,lX≠_ _k_ _kX=1_

= _[m][ −]_ [1] _pipj + [1]_ (28)

_m_ _m_ [E][ [][I][(][l][ =][ i][)][I][(][l][ =][ j][)]]


**Variance(i = j). We get E [I(l = i)I(l = j)] = E [I(l = i)] = pi, which gives:**

Var [ωi(St)] = _i_ [+ 1] (29)
_−_ _m[1]_ _[p][2]_ _m_ _[p][i]_


**Covariance(i ̸= j). We get E [I(l = i)I(l = j)] = 0, which gives:**

Cov [ωi(St), ωj(St)] = (30)
_−_ _m[1]_ _[p][i][p][j][,]_

and by definition we get


_α = [1]_

_m_

**Aggregation Weights Sum. Using equation (29)) and (31) with Property 1, we get**


(31)


_n_

_ωi(St)_

" _i=1_
X


= 0. (32)


Var


**Amount of clients. Considering that p(i ∈** _St) = 1 −_ _p(i /∈_ _St) = 1 −_ (1 − _pi)[m], we get:_


(1 _pi)[m]_ _m_ (33)
_−_ _≤_
_i=1_

X


E [N ] =


P(i ∈ _St) = n −_
_i=1_

X


A.4 SAMPLING CLIENTS UNIFORMLY WITHOUT REPLACEMENT


We recall equation (6),


_ωi(St) = I(i_ _St)_ _[n]_ (34)
_∈_ _m_ _[p][i][.]_


**Variance. We first calculate the probability for a client to be sampled, i.e.**


P(i _St) = 1_ P(i / _St) = 1_
_∈_ _−_ _∈_ _−_ _[n][ −]n_ [1]

Using equation (35), we have


_n_ _m_
_..._ _−_

_n −_ _m + 1 [= 1][ −]_ _[n][ −]n_ _[m]_


= _[m]n [.]_ (35)


2

_n_
VarSt [ωi(St)] = Var [I(i _St)] =_ _[n][2]_

_m_ _[p][i]_ _∈_ _m[2]_

h i


_m_

_i_ [= (][ n] _i_ (36)

_n_ [(1][ −] _[m]n_ [)][p][2] _m_

_[−]_ [1)][p][2]


**Covariance. We have**

P({i, j} ∈ _St) = P(i ∈_ _St) + P(j ∈_ _St) −_ P(i ∪ _j ∈_ _St)_ (37)
= P(i ∈ _St) + P(j ∈_ _St) −_ (1 − P({i, j} /∈ _St)),_ (38)

and

P( _i, j_ _/_ _St) =_ _[n][ −]_ [2] _..._ _[n][ −]_ _[m][ −]_ [1] _._ (39)
_{_ _}_ _∈_ _n_ _n_ _m + 1 [= (][n][ −]_ _[m]n([)(]n[n][ −]1)[m][ −]_ [1)]

_−_ _−_


-----

Substituting equation (35) and (39) in equation (38) gives

P( _i, j_ _St) = 2_ _[m]_ (40)
_{_ _} ∈_ _n_ _[−]_ [1 + (][n][ −] _[m]n([)(]n[n] −[ −]1)[m][ −]_ [1)]


1
= (41)

_n(n_ 1) [[2][m][(][n][ −] [1)][ −] _[n][(][n][ −]_ [1) + (][n][ −] _[m][)(][n][ −]_ _[m][ −]_ [1)]]
_−_

= _[m][(][m][ −]_ [1)] (42)

_n(n_ 1) _[.]_
_−_

Hence, we can express the aggregation weights covariance as


_m(m_ 1)

Cov [ωi(St), ωj(St)] = _[n][2]_ _−_ (43)

_m[2]_ _n(n_ 1) _[p][j][p][k][ −]_ _[p][j][p][k][,]_

_−_


which gives


_n_ _m_
_α =_ _−_ (44)

_m(n_ 1) _[.]_
_−_

**Aggregation Weights Sum. Combining equation (36) and (44) with Property 1 gives**


_n_

_ωi(St)_

" _i=1_
X


_n_ _n_ _m_
h _m_ _[−]_ [1]i _p[2]i_ _[−]_ _m( −n −_ 1)


_pi(1_ _pi)_ (45)
_−_
_i=1_

X

(46)


Var


_i=1_


_n_

_n_ _m_
= _m( −n −_ 1) "n _i=1_ _p[2]i_ _[−]_ [1]# _,_

X

where we retrieve Var [[P][n]i=1 _[ω][i][(][S][t][)] = 0][ for identical client importance, i.e.][ P]i[n]=1_ _[p]i[2]_ [=][ 1]n [.]

**Amount of Clients. N = m.**


A.5 POISSON BINOMIAL DISTRIBUTION

Clients are sampled according to a Bernoulli with a probability proportional to their importance pi,
i.e.

_ωi(St) = [1]_ (47)

_m_ [B][(][mp][i][)][.]


Hence, only m ≥ _p[−]max[1]_ [can be sampled and we retrieve][ E][ [][ω][i][(][S][t][)] =][ 1]m _[mp][i][ =][ p][i][.]_

**Variance.**


1

(48)

_m[2][ mp][i][(1][ −]_ _[mp][i][) = 1]m_ _[p][i][(1][ −]_ _[mp][i][)]_


VarSt [ωi(St)] =


**Covariance. Due to the independence of each stochastic weight, we also get:**

Cov [ωi(St), ωj(St)] = 0 (49)

**Aggregation Weights Sum. Using Property 1 we obtain**


_n_

_ωi(St)_

" _i=1_
X


= [1]

_m_

_[−]_


_p[2]i_ _[.]_ (50)
_i=1_

X


Var


**Amount of Clients.**


E [N ] = m and Var [N ] = m − _m[2]_


_p[2]i_ _[.]_ (51)
_i=1_

X


-----

A.6 BINOMIAL DISTRIBUTION

Clients are sampled according to a Bernoulli with identical sampling probability, i.e.

_ωi(St) =_ _[n]_ (52)

_m_ [B][(] _[m]n_ [)][p][i][.]


Hence, we retrieve E [ωi(St)] = _m[n]_


_m_

_n_ _[p][i][ =][ p][i][.]_


**Variance.**


VarSt [ωi(St)] = _[n][2]_

_m[2]_


_m_

_i_ [=][ n][ −] _[m]_

_n_ [(1][ −] _[m]n_ [)][p][2] _m_


_p[2]i_ _[.]_ (53)


**Covariance. Due to the independence of each stochastic weight, we have:**

Cov [ωi(St), ωj(St)] = 0. (54)

**Aggregation Weights Sum. Using Property 1 gives**

_n_ _n_

Var _ωi(St)_ = _[n][ −]_ _[m]_ _p[2]i_ _[.]_ (55)

_m_

" _i=1_ # _i=1_
X X


**Amount of Clients.**


E [N ] = m and Var [N ] = m − _[m]n [2]_ _[.]_ (56)


A.7 CLUSTERED SAMPLING

Clustered sampling (Fraboni et al., 2021) is a generalization of MD sampling where instead of
sampling m clients from the same distributions, m clients are sampled from m different distributions
_{Wk}k[m]=1_ [each of them privileging a different subset of clients. We denote by][ r][k,i][ the probability]
of client i to be sampled in distribution k. To satisfy Definition 1, the original work (Fraboni et al.,
2021) provides the conditions:


_rk,i = 1 and ∀i ∈{1, ..., n},_
_i=1_

X


_rk,i = mpi._ (57)
_k=1_

X


_∀k ∈{1, ..., m},_


The clients aggregation weights remain identical to the one of MD sampling, i.e.


_K_

_ωi(SCl) = [1]_ I(lk = i), (58)

_m_

_k=1_

X


where I(lk = i) are still independently distributed but not identically.

We have


E [I(lk = i)I(ll = j)] + [1]

_m[2]_

_k,lX≠_ _k_


E [ωi(St)ωj(St)] =


E [I(lk = i)I(lk = j)] (59)
_k=1_

X


_m[2]_

1

_m[2]_


_rk,irl,j + [1]_

_m[2]_

_k,lX≠_ _k_


E [I(lk = i)I(lk = j)] (60)
_k=1_

X


= pipj
_−_ _m[1][2]_


_m_

_rk,irk,j + [1]_

_m[2]_

_k=1_

X


E [I(lk = i)I(lk = j)], (61)
_k=1_

X


where we retrieve equation (28) when rk,i = pi.

**Variance (i = j). We get E [I(lk = i)I(lk = j)] = E [I(lk = i)] = rk,i, which gives:**


_m_

Var [ωi(SCl)] = m[1] _[p][i][ −]_ _m[1][2]_ _k=1_ _rk,i[2]_ _[≤]_ [Var [][ω][i][(][S][MD][)]][,] (62)

X


-----

where the inequality comes from using the Cauchy-Schwartz inequality with equality if and only if
all the m distributions are identical, i.e. rk,i = pi.

**Covariance (i ̸= j). We get E [I(lk = i)I(lk = j)] = 0, which gives:**


Cov [ωi(SCl), ωj(SCl)] =
_−_ _m[1][2]_


_rk,irk,j_ Cov [ωi(SMD), ωj(SMD)], (63)
_k=1_ _≤_

X


where the inequality comes from using the Cauchy-Schwartz inequality with equality if and only if
all the m distributions are identical, i.e. rk,i = pi.


**Aggregation Weights Sum**

A.8 OPTIMAL SAMPLING


_n_

_ωi(SCl)_

" _i=1_
X


= 0. (64)


Var


With optimal sampling (Chen et al., 2020b), clients are sampled according to a Bernoulli distribution
with probability qi, i.e.
_ωi(St) =_ _[p][i]_ B(qi). (65)

_qi_

Hence, we retrieve E [ωi(St)] = _[p]qi[i]_ _[q][i][ =][ p][i][.]_


**Variance.**
VarSt [ωi(St)] = [1][ −] _[q][i]_ _p[2]i_ _[.]_ (66)

_qi_

**Covariance. Due to the independence of each stochastic weight, we have:**

Cov [ωi(St), ωj(St)] = 0. (67)

**Aggregation Weights Sum. Using Property 1 gives**

_n_ _n_

1 _qi_

Var _ωi(St)_ = _−_ _p[2]i_ _[.]_ (68)

" _i=1_ # _i=1_ _qi_
X X

**Amount of Clients.**


E [N ] =


_qi and Var [N_ ] =
_i=1_

X


_qi(1_ _qi)._ (69)
_−_
_i=1_

X


-----

Table 2: Common Notation Summary.

Symbol Description

_n_ Number of clients.
_K_ Number of local SGD.
_ηl_ Local/Client learning rate.
_ηg_ Global/Server learning rate.
_η˜_ Effective learning rate, ˜η = ηlηg.
**_θ[t]_** Global model at server iteration t.
**_θ[∗]_** Optimum of the federated loss function, equation (1).
**_θi[t][+1]_** Local update of client i on model θ[t].
**_yi,k[t]_** Local model of client i after k SGD (yi,K[t] [=][ θ]i[t][+1] and yi,[t] 0 [=][ θ][t][).]
_pi_ Importance of client i in the federated loss function, equation (1).
_m_ Number of sampled clients .
_St_ Set of participating clients considered at iteration t.
_ωi(St)_ Aggregation weight for client i given St.
_α_ Covariance parameter.
_γi_ cf Section 3
Et [·] Expected value conditioned on θ[t].
_L(·)_ Federated loss function, equation 1
_i(_ ) Local loss function of client i.
_L_ _·_
_gi(·)_ SGD. We have Eξi [gi(·)] = ∇Li(·) with Assumption 1.
_ξi_ Random batch of samples from client i of size B.
_L_ Lipschitz smoothness parameter, Assumption 2.
_σ[2]_ Bound on the variance of the stochastic gradients, Assumption 1.
_β, κ_ Assumption 3 parameters on the clients gradient bounded dissimilarity.

B DECOMPOSITION THEOREM 1

In Table 2, we provide the definition of the different notations used in this work. We also propose in
Algorithm 1 the pseudo-code for FedAvg with aggregation scheme (3).

**Algorithm 1 Federated Learning based on equation (3)**


1: The server sends to the n clients the learning parameters (K, ηl, B).
2: for t ∈{0, ..., T − 1} do
3: Sample a set of clients St and get their aggregation weights di(t).

4: Send to clients in St the current global model θ[t].

5: Receive each sampled client contributions ci(t) = θi[t][+1] **_θ[t]._**

_n_ _−_
6: Creates the new global model θ[t][+1] = θ[t] + ηg _i=1_ _[d][i][(][t][)][c][i][(][t][)][.]_

7: end for

P

B.1 USEFUL LEMMA

We first introduce and prove the following useful lemma before introducing the proof of Theorem 1.

**Lemma 1. Let us consider n vectors xi, ..., xn and a client sampling satisfying ESt [ωi(St)] = pi**
_and Cov [ωi(St), ωj(St)] =_ _αpipj. We have:_
_−_

_n_ 2[] _n_ _n_ 2

ESt _ωi(St)xi_ = _γi_ **_xi_** + (1 _α)_ _pixi_ _,_ (70)

 _i=1_ _i=1_ _∥_ _∥[2]_ _−_ _i=1_

X X X

 

_where γi = VarSt [ωi(St)] + αp[2]i_ _[.]_


-----

_Proof._

ESt


2[]

 =


_n_

ESt _ωi(St)[2][]_ _∥xi∥[2]_ +
_i=1_

X 


ESt [ωi(St)ωj(St)] ⟨xi, xj⟩. (71)


_ωi(St)xi_
_i=1_

X


_i=1_


_j=1_
_j≠_ _i_


In addition, we have:

ESt [ωi(St)ωj(St)] = Cov [ωi(St), ωj(St)] + pipj = (−α + 1)pipj, (72)

where the last equality comes from the assumption on the client sampling covariance.

We also have:


_p[2]i_ (73)
_i=1_ _[∥][x][i][∥][2][,]_

X


_pixi, pjxj_ =
_⟨_ _⟩_

_j=1_

Xj≠ _i_


_pixi_
_i=1_

X


_i=1_


Substituting equation (72) and equation (73) in equation (71) gives:

_n_ 2[] _n_ _n_ 2

ESt _ωi(St)xi_ = ESt _ωi(St)[2][]_ ( _α + 1)p[2]i_ **_xi_** + ( _α + 1)_ _pixi_ _,_

 _−_ _−_ _∥_ _∥[2]_ _−_

_i=1_ _i=1_ _i=1_

X X    X

  (74)

Considering that we have ESt _ωi(St)[2][]_ = Var [ωi(St)] + p[2]i [, we have :]

ESt _ωi(St)[2][]_ + (α − 1)p[2]i [= Var][S]t [[][ω][i][(][S][t][)] +][ αp]i[2][,] (75)


Substituting equation (75) in equation (74) completes the proof.

B.2 PROOF OF THE DECOMPOSITION THEOREM 1


_Proof._

Et **_θ[t][+1]_** _−_ **_θ[∗]_** = Et (θ[t][+1] _−_ **_θ[t]) + (θ[t]_** _−_ **_θ[∗])_** (76)
h h

[2][i] = **_θ[t]_** **_θ[∗]_** + 2 Et **_θ[t][+1]_** **_θ[t][][2],[i] θ[t]_** **_θ[∗]_** + Et **_θ[t][+1]_** **_θ[t]_** _,_ (77)

_−_ _⟨_ _−_ _−_ _⟩_ _−_

_n_
By construction (equation (3)), we have[2] **_θ[t][+1]_** **_θ[t]_** = ηg _i=1_ _[ω][i][(][S][t][)(][θ]i[t][+1]h_ **_θ[t]). The sampling[2][i]_**
_−_ _n_ _−_
scheme follows Definition 1 which gives ESt **_θ[t][+1]_** **_θ[t][]_** = ηg _i=1_ _[p][i][(][θ]i[t][+1]_ **_θ[t]). Hence, we_**
_−_ P _−_
get:
 _n_ P

Et **_θ[t][+1]_** _−_ **_θ[∗]_** = **_θ[t]_** _−_ **_θ[∗]_** + 2ηg⟨ _pi Et_ **_θi[t][+1]_** _−_ **_θ[t][]_** _, θ[t]_ _−_ **_θ[∗]⟩_**

_i=1_

h [2][i] _n[2]_ X  2[]

+ ηg[2] [E][t]  _ωi(St)(θi[t][+1]_ _−_ **_θ[t])_** _._ (78)

_i=1_

X

 

=ηl[2][Q][(][θ][t][)]
| {z }

Using Lemma 1, we express Q(θ[t]) as follow:

_n_ _n_ 2[]

_ηl[2][Q][(][θ][t][) =]_ _γi Et_ **_θi[t][+1]_** **_θ[t]_** + (1 _α) Et_ _pi(θi[t][+1]_ **_θ[t])_** _._ (79)

_−_ _−_  _−_
_i=1_ _i=1_

X h X

[2][i]  

By construction, we have θi[t][+1] _−_ **_θ[t]_** = − [P][K]k=0[−][1] _[η][l][g][i][(][y]i,k[t]_ [)][. Considering Assumption 1 gives]

E **_θi[t][+1]_** **_θ[t]_** = ηl[2] E _ξi[t]_ + E ∆[t]i _._ (80)
_−_
h h h h

[2][i] [2][i] [2][ii]


-----

Similarly, by using twice Assumption 1 for the global model drift, we have

_n_ 2[] _n_ 2[] _n_ 2[]

_ηl[2]_ [E]  _pid[t]i_ = ηl[2] [E]  _piξi[t]_ + ηl[2] [E]  _pi∆[t]i_ (81)

_i=1_ _i=1_ _i=1_

X X X

  n   _n_ 2[]

= ηl[2]  _p[2]i_ [E] _ξi[t]_ + E  _pi∆[t]i_  _,_ (82)

_i=1_ _i=1_

X h X
 [2][i]  

where, for the last equality, Assumption 1 gives E _ξi[t][, ξ]j[t][⟩]_ = E [ξi[t][]][T][ E] _ξj[t]_ = 0.
_⟨_

Combining equation (80) with equation (82) gives   


_n_

_Q(θ[t]) =_ Var [ωi(St)] + p[2]i E _ξi[t]_

_i=1_

X   h

_n_ [2][i] _n_

+ _γi E_ ∆[t]i + (1 _α) E_ _pi∆[t]i_

_−_ 
_i=1_ _i=1_

X h X

[2][i] 

Substituting equation (83) in equation (78) completes the proof.

B.3 ADAPTATION TO CLUSTERED SAMPLING


2[]

 _._ (83)


Instead of Lemma 1 which requires Cov [ωi(St), ωj(St)] = _αpipj, we propose the following_
_−_
Lemma for clustered sampling expressed in function of MD sampling covariance parameter αMD
showing that a sufficient condition for MD sampling to perform as well as Clustered sampling is
that all xi are identical, or that all the distributions are identical, i.e. rk,i = pi.
**Lemma 2. Let us consider n vectors xi, ..., xn and a client sampling satisfying ESt [ωi(St)] = pi**
_and Cov [ωi(SCl), ωj(SCl)] =_ _αpipj. We have:_
_−_

_n_ 2[] _n_ _n_ 2

ESCl _ωi(SCl)xi_ _γi(MD)_ **_xi_** + (1 _αMD)_ _pixi_ _,_ (84)

 _≤_ _∥_ _∥[2]_ _−_

_i=1_ _i=1_ _i=1_

X X X

 

_where γi(MD) and αMD are the aggregation weights statistics of MD sampling. Equation (84) is_
_an equality if and only if_ _i=1_ _[r][k,i][x][i][ =][ P]j[n]=1_ _[r][k,j][x][j][.]_

_Proof. Substituting equation (62) in equation (71) gives[P][n]_

_n_ 2[] _n_ _n_ _n_

ESCl _ωi(SCl)xi_ = ESCl _ωi(SCl)[2][]_ **_xi_** + _pipj_ **_xi, xj_**

 _∥_ _∥[2]_ _⟨_ _⟩_

_i=1_ _i=1_ _i=1_ _j=1_

X X  X Xj=i

  _̸_

_m_ _n_ _n_

_rk,irk,j_ **_xi, xj_** _,_ (85)

_−_ _m[1][2]_ _⟨_ _⟩_

_k=1_ _i=1_ _j=1_

X X Xj≠ _i_

Substituting equation (73) in equation (71) gives:

_n_ 2[] _n_ _n_ 2 _n_

ESCl _ωi(SCl)xi_ = ESCl _ωi(SCl)[2][]_ **_xi_** + _pixi_ _p[2]i_

 _i=1_ _i=1_ _∥_ _∥[2]_ _i=1_ _−_ _i=1_ _[∥][x][i][∥][2]_

X X  X X

  _m_ _n_ 2 _n_

_−_ _m[1][2]_ _k=1_  _i=1_ _rk,ixi_ _−_ _i=1_ _rk,i[2]_ _[∥][x][i][∥][2]_ _._ (86)

X X X

 


-----

With rearrangements and using equation (57) we get:

_n_ 2[] _n_

ESCl _ωi(SCl)xi_ = Var [ωi(SCl)] + [1]

 _i=1_ _i=1_ " _m[2]_

X X

  _m_ _n_ 2

_rk,ixi_ _._

_−_ _m[1][2]_

_k=1_ _i=1_

X X


**_xi_** +
_∥_ _∥[2]_


_rk,i[2]_
_k=1_

X


_pixi_
_i=1_

X


(87)


Using the expression of clustered sampling variance for the first term (equation (63)), and using
Jensen’s inequality on the third term completes the proof. Jensen’s inequality is an equality if and
only if _i=1_ _[r][k,i][x][i][ =][ P]j[n]=1_ _[r][k,j][x][j][.]_

[P][n]


-----

C FL CONVERGENCE

Our work is based on the one of Wang et al. (2020a). We use the developed theoretical framework
there proposed to prove Theorem 2. The focus of our work (and Theorem 2) is on FedAvg. Yet, the
proof developed in this section, similarly to the one of Wang et al. (2020a), expresses ai in such a
way they can account for a wide-range of regularization method on FedAvg, or optimizers different
from Vanilla SGDone. This proof can easily be extended to account for different amount of local
work from the clients (Wang et al., 2020a).

Before developing the proof of Theorem 2 in Section C.5, we introduce the notation we use in
Section C.1, some useful lemmas in Section C.2 and Theorem 3 generalizing Theorem 2 in Section
C.3.

C.1 NOTATIONS

We define by yi,k[t] [the local model of client][ i][ after][ k][ SGD steps initialized on][ θ][t][, which enables us]
to also define the normalized stochastic gradients d[t]i [and the normalized gradient][ h]i[t] [defined as]


_K−1_

_ai,kgi(yi,k[t]_ [)][ and][ h]i[t] [= 1]

_ai_

_k=0_

X


_K−1_

_ai,k∇Li(yi,k[t]_ [)][,] (88)
_k=0_

X


**_d[t]i_** [= 1]

_ai_


where ai,k is an arbitrary scalar applied by the client to its kth gradient, ai = [ai,0, .., ai,K 1][T], and
_−_
_ai =_ **_ai_** 1. In the special case of FedAvg, we have ai = [1, ..., 1] and in the one of FedProx, we
_∥_ _∥_
have ai = [(1 − _µ)[K][−][1], ..., 1] where µ is the FedProx regularization parameter._

With the formalism of equation (88), we can express a client contribution as θi[t][+1] **_θ[t]_** = _ηlaid[t]i_
_−_ _−_
and rewrite the server aggregation scheme defined in equation (3) as


**_θ[t][+1]_** **_θ[t]_** = _ηgηl_
_−_ _−_


_ωiaid[t]i[,]_ (89)
_i=1_

X


which in expectation over the set of sampled clients St gives


ESt **_θ[t][+1]_** _−_ **_θ[t][]_** = −η˜


= −η˜


_piaid[t]i_ (90)
_i=1_

X


_n_ _n_

_piai_

= −η˜ _i=1_ _piai!_ _i=1_  _ni=1_ _[p][i][a][i]_  **_d[t]i[.]_** (91)

X X

_Keff_ P _wi_
| {z } | {z }

We define the surrogate objective _L[˜](x) =_ _i=1_ _[w][i][L][i][(][x][)][, where][ P]i[n]=1_ _[w][i][ = 1][.]_

In what follows, the norm used for ai can either be L1, 1, or L2, 2, For other variables,
the norm is always the euclidean one and[P][n] is used instead of ∥·∥ 2. Also, regarding the client ∥·∥
_∥·∥_ _∥·∥_
sampling metrics, for ease of writing, we use ωi instead of ωi(St) due to the independence of the
client sampling statistics with respect to the current optimization round.


C.2 USEFUL LEMMAS

**Lemma 3 (equation (87) in Wang et al. (2020a)). Under Assumptions 1 to 3, we can prove**

_n_ _n_

1 _ηl[2][L][2][σ][2]_

_wi E_ _i(θ[t])_ **_h[t]i_** _wi_ **_ai_** 2 _i,_ 1

2 Xi=1 h∇L _−_ _≤_ 2[1] 1 − _R_ Xi=1 ∥ _∥[2]_ _[−]_ _[a][2]_ _−_ 

[2][i] _Rβ[2]_ 2[] _Rκ[2]_

+ (θ[t]) + (92)

2(1 _R)_ [E] _∇L[˜]_ 2(1 _R)_ _[,]_
_−_  _−_

_with R = 2ηl[2][L][2][ max][i][{∥][a][i][∥]1_ [(][∥][a][i][∥]1 _[−]_ _[a][i,][−][1][)][}][ with a learning rate such that][ R <][ 1][.]_


-----

_Proof. The proof is in Section C.5 of Wang et al. (2020a)._


The bound here provided is slightly tighter in term of numerical constants than the one of Wang
et al. (2020a). Indeed, equation (70) in Wang et al. (2020a) uses the Jensen’s inequality ∥a + b∥[2] _≤_
2 ∥a∥[2] + 2 ∥b∥[2] which could instead be obtained with:

2[] 2[] 2[]

_k−1_ _k−1_ _k−1_

E _ai,sgi(yi,s[t]_ [)] = E _ai,s_ _gi(yi,s[t]_ [)][ −∇L][i][(][y]i,s[t] [)] +E _ai,s_ _i(yi,s[t]_ [)] _,_

   _∇L_

_s=0_ _s=0_ _s=0_

X X    X

     (93)

which uses Assumption 1, giving E _⟨[P]s[k]=0[−][1]_ _[a][i,s]_ _gi(yi,s[t]_ [)][ −∇L][i][(][y]i,s[t] _,_ _s=0_ _[a][i,s][∇L][i][(][y]i,s[t]_ _[⟩]_ = 0
with the same reasoning as for U in equation (111).h    [P][k][−][1] i

**Lemma 4. Under Assumptions 1 to 3, we can prove**

_n_ _n_

1
_γi E_ _aih[t]i_ _γi_ **_ai_** 2 _i,_ 1[)]

Xi=1 h _≤_ 1 − _R_ _[σ][2]_ Xi=1 ∥n _∥[2]_ _[−]_ [(][a][2] _−_ 

[2][i] _R_ 2[]

+ 2 1 _R_ [+ 1] _γia[2]i_ _β[2]_ E _∇L[˜](θ[t])_ + κ[2] _,_ (94)
 _−_  Xi=1 !   

_where R[′]_ = 2ηl[2][L][2][ max][i][{∥][a][i][∥]1[2][}][ <][ 1][.]

_Proof. Due to the definition of h[t]i[, we have:]_

2[]

_K−1_ 1

E _aih[t]i_ = a[2]i [E]  _ai_ _ai,k∇Li(yi,k[t]_ [)] (95)

_k=0_

h X

[2][i] _K_ 1 

_−_ 1

_a[2]i_ _ai,k E_ _i(yi,k[t]_ [)] _._ (96)
_≤_ _ai_ _∇L_

_k=0_

X h

[2][i]

Using Jensen inequality, we have

E _∇Li(yi,k[t]_ [)] _≤_ 2 E _∇Li(yi,k[t]_ [)][ −∇L][i][(][θ][t][)] + 2 E _∇Li(θ[t])_ (97)
h h h

[2][i] 2L[2] E **_yi,k[t]_** + 2 E [2][i] _i(θ[t])_ _,_ [2][i] (98)

_≤_ _[−]_ **_[θ][t]_** _∇L_

where the second equality comes from using Assumption 2.h h

[2][i] [2][i]

Also, Section C.5 of Wang et al. (2020a) proves


_K−1_

_k=0_ _ai,k E_ **_yi,k[t]_** _[−]_ **_[θ][t]_**

X h

[2][i]


1

_l_ _[σ][2][ ]_ **_ai_** 2 _i,_ 1[)] + [1]
1 _R_ _[η][2]_ _∥_ _∥[2]_ _[−]_ [(][a][2] _−_ _L[2]_
_−_ 


_R_

_i(θ[t])_ _._
1 _R_ [E] _∇L_
_−_
h (99)

[2][i]


_ai_


Plugging equation (98) and then equation (99) in equation (96), we get:

_K−1_ 1

E _aih[t]i_ _≤_ _a[2]i_ _k=0_ _ai_ _ai,k_ 2L[2] E **_yi,k[t]_** _[−]_ **_[θ][t]_** + 2 E _∇Li(θ[t])_ (100)
h X h h h

[2][i] _K−1_ 1 [2][i] [2][ii]

= 2L[2]a[2]i _k=0_ _ai_ _ai,k E_ **_yi,k[t]_** _[−]_ **_[θ][t]_** + 2a[2]i [E] _∇Li(θ[t])_ (101)

X h h

1 [2][i] _R_ [2][i]

2L[2]a[2]i _l_ _[σ][2][ ]_ **_ai_** 2 _i,_ 1[)] + [1] _i(θ[t])_
_≤_  1 − _R_ _[η][2]_ _∥_ _∥[2]_ _[−]_ [(][a][2] _−_  _L[2]_ 1 − _R_ [E] h∇L

+ 2a[2]i [E] _∇Li(θ[t])_ [2][i] (102)

_R[′]_ h _R_
_≤_ 1 − _R_ _[σ][2][ ]∥ai∥2[2]_ _[−][2][i][(][a]i,[2]_ _−1[)]_ + 2a[2]i  1 − _R_ [+ 1] E h∇Li(θ[t]) _._ (103)

[2][i]


-----

Summing over n gives

_n_ _n_

1
_γi E_ _aih[t]i_ 2L[2] _l_ _[σ][2]_ _γia[2]i_ **_ai_** 2 _i,_ 1[)]

Xi=1 h _≤_ 1 − _R_ _[η][2]_ Xin=1 ∥ _∥[2]_ _[−]_ [(][a][2] _−_ 

[2][i] _R_

+ 2 1 _R_ [+ 1] _γia[2]i_ [E] _∇Li(θ[t])_ _._ (104)
 _−_  _i=1_

X h

[2][i]


Using Assumption 3 in equation (104) and R[′] _< 1 completes the proof._

C.3 INTERMEDIARY THEOREM

**Theorem 3. The following inequality holds:**

_T_ 1

1 _−_ 2[] 1

E (θ[t]) ( _ηA[′]σ[2][ 1]_ _l_ _[σ][2][B][′][)]_

_T_ _t=0_ _∇L[˜]_ _≤O_ (1 Ω)˜η ([P][n]i=1 _[p][i][a][i][)][ T][ ) +][ O][(˜]_ _m_ [) +][ O][(][η][2]

X  _−_

+ O(ηl[2][C] _[′][κ][2][) +][ O][(˜]ηD[′]σ[2]) + O(˜ηE[′]κ[2]),_ (105)


_where quantities A-E are defined in the following proof from equation (122) to equation (126)._

_Proof. Clients local loss functions are L-Lipschitz smooth. Therefore,_ _L[˜] is also L-Lipschitz smooth_
which gives

E ˜(θ[t][+1]) (θ[t]) E (θ[t]), θ[t][+1] **_θ[t]_** + _[L]_ **_θ[t][+1]_** **_θ[t]_** _,_ (106)
_L_ _−_ _L[˜]_ _≤_ _⟨∇L[˜]_ _−_ _⟩_ 2 [E] _−_
h i h _T1_ i h _T2_

[2][i]

| {z } | {z }

where the expectation is taken over the subset of randomly sampled clients St and the clients gradient
estimator noises ξi[t][. Please note that we use the notation][ E][ [][·][]][ instead of][ E] _ξi[t][}][,S][t][ [][·][]][ for ease of]_
_{_
writing.


BOUNDING T1

By conditioning on {ξi[t][}][ and using equation (91), we get:]

_T1 = E_ _⟨∇L[˜](θ[t]), ESt_ **_θ[t][+1]_** _−_ **_θ[t][]⟩_** = −ηK˜ _eff E_
h  i


_⟨∇L[˜](θ[t]),_


_wih[t]i[⟩]_
_i=1_

X


(107)


which, using 2⟨a, b⟩ = ∥a∥[2] + ∥b∥[2] _−∥a −_ _b∥[2]_ can be rewritten as:


2[]

 _._ (108)


_T1 = −_ 2 [1] _ηK[˜]_ _eff E_


_∇L[˜](θ[t])_



_[∇]L[˜](θ[t]) −_


_wih[t]i_
_i=1_

X


_wih[t]i_
_i=1_

X


-----

BOUNDING T2

_T2|St = ˜η[2]_ E

= ˜η[2] E

= ˜η[2] E

+ 2˜η E


_ωiaid[t]i_
_i=1_

X


(109)

(110)

(111)


_St_
_|_


_ωiai_ **_d[t]i_** _i_
_i=1_ _[−]_ **_[h][t]_**

X  

_n_

_ωiai_ **_d[t]i_** _i_
_i=1_ _[−]_ **_[h][t]_**

X  


_ωiaih[t]i_
_i=1_

X


_St_
_|_ _n_

_ωiaih[t]i_
_i=1_

X


_St_ + ˜η[2] E
_|_ 

_n_ 

_ωiaih[t]i[⟩|][S][t]_
_i=1_

X


_St_
_|_


+ 2˜η E _ωiai_ **_d[t]i_** _i_ _,_ _ωiaih[t]i[⟩|][S][t]_ _._ (111)

"⟨ _i=1_ _[−]_ **_[h][t]_** _i=1_ #

X    X

_U_

Using Assumption 1, we have| E _d[t]i_ _i[, h]{z[t]j[⟩]_ = 0. Hence, we get} _U = 0 and can simplify T2 as:_
_⟨_ _[−]_ _[h][t]_

_n_   _n_ 2[]
_T2 = ˜η[2]_ _i=1_ E _ωi[2]_ _a[2]i_ [E] **_d[t]i_** _[−]_ **_[h]i[t]_** + ˜η[2] E  _i=1_ _ωiaih[t]i_ _._ (112)
X   h X

[2][i]  

Using Lemma 1 on the second term, we get:

_n_ _n_ _n_ 2[]
_T2 = ˜η[2]_ _i=1_ E _ωi[2]_ _a[2]i_ [E] **_d[t]i_** _[−]_ **_[h]i[t]_** + ˜η[2] _i=1_ _γi E_ _aih[t]i_ + ˜η[2](1 − _α) E_  _i=1_ _piaih[t]i_ _._
X   h X h X

[2][i] [2][i]  (113)

Finally, by bounding the first term using Assumption 1, and noting that piai = wiKeff for the
second term, we get:


_n_ _[K][−][1]_

E _ωi[2]_ _a[2]i,k_ [E] _gi(yi,k[t]_ [)][ −∇L][i][(][y]i,k[t] [)]
_i=1_ _k=0_

Xn   X h _n_ [2][i] 2[]

_γi E_ _aih[t]i_ + ˜η[2](1 − _α)Keff[2]_ [E]  _wih[t]i_
_i=1_ _i=1_

X h X

_n_ [2][i] _n_  

E _ωi[2]_ _∥ai∥2[2]_ _[σ][2][ + ˜]η[2]_ _γi E_ _aih[t]i_ + ˜η[2](1 − _α)Keff[2]_ [E]
_i=1_ _i=1_

X   X h

[2][i]


_T2 = ˜η[2]_

+ ˜η[2]

_≤_ _η˜[2]_


(114)

2[]

_._
(115)


_wih[t]i_
_i=1_

X

_n_

_wih[t]i_
_i=1_

X


GOING BACK TO EQUATION (106)

Substituting equation (108) and equation (115) back in equation (106), we get:

2

E _L˜(θ[t][+1]) −_ _L[˜](θ[t])_ _≤−_ [1]2 ηK[˜] _eff_ _∇L[˜](θ[t])_ + [1]2 ηK[˜] _eff E_  _L(θ[t]) −_
h i

n 2[]

_[∇]_ [˜]

_ηKeff [1_ _Lη˜(1_ _α)Keff_ ] E _wih[t]i_

_−_ 2 [1] [˜] _−_ _−_ 

_i=1_

X

 


2[]


_n_

_γi E_ _aih[t]i_ _,_ (116)
_i=1_

X h

[2][i]


+ _[L]2 η[˜][2]_


_n_

E _ωi[2]_ **_ai_** 2 _[σ][2][ +][ L]_ _η[2]_
_∥_ _∥[2]_ 2 [˜]
_i=1_

X  


-----

We consider the learning rate to satisfy 1 − _Lη˜(1 −_ _α)Keff > 0 such that we can simplify equation_
(116) as :


_n_ 2[]

2
_∇L[˜](θ[t])_ + [1]2 [E]  _L(θ[t]) −_ _i=1_ _wih[t]i_

X

_n_  _n_ 

1 1

E _ωi[2]_ **_ai_** 2[∇][σ][2][˜][ +][ L] _η_ _γi E_ _aih[t]i_ (117)

_Keff_ _∥_ _∥[2]_ 2 [˜]Keff

_i=1_ _i=1_

X   _n_ X h

2 [2][i]
(θ[t]) + [1] _wi E_ _i(θ[t])_ **_h[t]i_**
_∇L[˜]_ 2 _∇L_ _−_

_i=1_

_n_ X h _n_

1 1 [2][i]

E _ωi[2]_ **_ai_** 2 _[σ][2][ +][ L]_ _η_ _γi E_ _aih[t]i_ _, (118)_

_Keff_ _∥_ _∥[2]_ 2 [˜]Keff

_i=1_ _i=1_

X   X h

[2][i]


_L˜(θ[t][+1]) −_ _L[˜](θ[t])_
h _ηK˜_ _eff_ i _≤−_ 2[1]

+ _[L]2 η[˜]_

_≤−_ [1]2

+ _[L]_ _η_

2 [˜]


where the last inequality uses the definition of the surrogate loss function _L[˜] and the Jensen’s in-_
equality.

Using Lemma 4 and 3, we get:

E _L˜(θ[t][+1]) −_ _L[˜](θ[t])_ 2 _ηl[2][L][2][σ][2]_ _n_

(θ[t]) + [1] _wi_ **_ai_** 2 _i,_ 1

h _ηK˜_ _eff_ i _≤−_ 2[1] _∇L[˜]_ 2 1 − _R_ Xi=1 ∥ _∥[2]_ _[−]_ _[a][2]_ _−_ 

2[]

_Rβ[2]_ _Rκ[2]_
+ (θ[t]) +

2(1 _R)_ [E] _∇L[˜]_ 2(1 _R)_
_−_ _n_ _−_ _n_

1 1

+ _[L]_ _η_ E _ωi[2]_ **_ai_** 2 [+] _γi_ **_ai_** 2 _i,_ 1[)] _σ[2]_

2 [˜]Keff "Xi=1   _∥_ _∥n[2]_ 1 − _R_ Xi=1 ∥ _∥[2]_ _[−]_ [(][a][2] _−_ [#]

2[]

1 _R_
+ Lη˜Keff 1 _R_ [+ 1] _γia[2]i_ _β[2]_ E _∇L[˜](θ[t])_ + κ[2] _._

 _−_  Xi=1 !   

(119)


If we assume that1 _RR_ 2 [, and][ Rβ]1 _RR[2]_ _≤_ 22ββ[2]1[2]1+1+1[(1 +][, and considering that]2β1[2][ )][β][2][ =][ 1]2 [. We also define][ β][2][ ≥] [1][, then we have][ Ω=][ L]η[˜] _Keff1_ 1−132R _[≤]ni=1[1 +][γ][i]2[a]β1i[2][2][ ≤]β[2]_ 2[3] [,]

1− _[≤]_ [1] _−_ _[≤]_ _≤_
2 [. Substituting these terms in equation (119) gives]  P 


˜(θ[t][+1]) (θ[t]) 2 _n_
_L_ _−_ _L[˜]_

(θ[t]) + [3] _l_ _[L][2][σ][2]_ _wi_ **_ai_** 2 _i,_ 1

_ηK˜_ _eff_ i _≤−_ 4 [1] [[1][ −] [Ω]] _∇L[˜]_ 4 _[η][2]_ _i=1_ _∥_ _∥[2]_ _[−]_ _[a][2]_ _−_

X  

+ [3] _l_ _[L][2][ max]_

2 _[η][2]_ _i_ _n[{][a][i][(][a][i][ −]_ _[a][i,][−][1][)][}][κ][2]_ _n_

1

+ _[L]_ _η_ E _ωi[2]_ **_ai_** 2 [+ 3] _γi_ **_ai_** 2 _i,_ 1[)]

2 [˜]Keff " _i=1_ _∥_ _∥[2]_ 2 _i=1_ _∥_ _∥[2]_ _[−]_ [(][a][2] _−_

X   X  [#]


_σ[2]_


+ [3] _η_ 1

2 _[L][˜]Keff_


_γia[2]i_
_i=1_

X


_κ[2]._ (120)


-----

Averaging across all rounds, we get:


_T_ 1 _n_

1 Ω _−_ 2[] ˜(θ[0]) (θ[∗])
_−_ E (θ[t]) 4 _L_ _−_ _L[˜]_ + 3ηl[2][L][2][σ][2] _wi_ **_ai_** 2 _i,_ 1

_T_ _t=0_ _∇L[˜]_ _≤_ _ηK˜_ _eff_ _T_ _i=1_ _∥_ _∥[2]_ _[−]_ _[a][2]_ _−_

X  X  

+ 6ηl[2][L][2][ max]
_i_

_[{][a]n[i][(][a][i][ −]_ _[a][i,][−][1][)][}][κ][2]_ _n_

1
+ Lη˜ 2 E _ωi[2]_ **_ai_** 2 [+ 3] _γi_ **_ai_** 2 _i,_ 1[)]

_Keff_ " _i=1_ _∥_ _∥[2]_ _i=1_ _∥_ _∥[2]_ _[−]_ [(][a][2] _−_

X   X  [#]


_σ[2]_


_γia[2]i_
_i=1_

X


_κ[2]._ (121)


+ 6Lη˜

_Keff_


We define the following auxiliary variables


1
_i=1_ E _ωi[2]_ _∥ai∥2[2]_ [=][ m] _ni=1_ _[p][i][a][i]_

X  

P


Var [ωi] + p[2]i _∥ai∥2[2]_ _[,]_ (122)


_∥ai∥2[2]_ _[−]_ _[a]i,[2]_ _−1_ _,_ (123)
 


_A = m_


_Keff_


_i=1_


_n_ _n_

_piai_

_i=1_ _wi_ _∥ai∥2[2]_ _[−]_ _[a]i,[2]_ _−1_ = _i=1_ _nj=1_ _[p][j][a][j]_ _∥ai∥2[2]_ _[−]_ _[a]i,[2]_ _−1_ _,_ (123)

X   X  

P

_C = max_ (124)
_i_

_[{][a][i][(][a][i][ −]_ _[a][i,][−][1][)][}][,]_


_B =_


_p[2]i_
_i=1_

X

_n_

_p[2]i_
_i=1_

X


(125)

(126)


_γi =_ _n_
_i=1_ _i=1_ _[p][i][a][i]_

X

P


_D =_

_E =_


max
_Keff_ _i_

_[{][a][i][(][a][i][ −]_ _[a][i,][−][1][)][}]_


Var [ωi] + α
_i=1_

X

_n_

Var [ωi] + α
_i=1_

X


1 1
_E =_ max _i_ _γi_ = _n_ max _i_

_Keff_ _i_ _[{][a][2][}]_ _i=1_ ! _i=1_ _[p][i][a][i]_ _i_ _[{][a][2][}]_ _i=1_

X X

P

We define for A -E the respective quantities A[′]-E[′] such that X _[′]_ =


1

max _i_
_Keff_ _i_ _[{][a][2][}]_


1

1 Ω _[X][. We have:]_
_−_


_T_ 1
_−_ 2[] ˜(θ[0]) (θ[∗])

E (θ[t]) 4 _L_ _−_ _L[˜]_ _ηA[′]σ[2][ 1]_ _l_ _[L][2][σ][2][B][′]_
_t=0_ _∇L[˜]_ _≤_ (1 Ω)˜η ([P][n]i=1 _[p][i][a][i][)][ T][ + 2][L][˜]_ _m_ [+ 3][η][2]

X  _−_

+ 6ηl[2][L][2][C] _[′][κ][2][ + 3][L]ηDσ[˜]_ [2] + 6LηEκ˜ [2], (127)


C.4 SYNTHESIS OF LOCAL LEARNING RATE ηl CONDITIONS FOR THEOREM 3

A sufficient bound on the local learning rate ηl for constraints on R for Lemma 3 and equation (119),
and constraint on R[′] for Lemma 4 to be satisfied is:

2 2β[2] + 1 _ηl[2][L][2][ max]_ 1[}][ <][ 1][.] (128)
_i_

_[{∥][a][i][∥][2]_
 

Constraints on equation (116) can be simplified as

_Lηgηl(1 −_ _α)Keff < 1._ (129)

Constraints on Ω, equation (119), give


_β[2]_ _≤_ 1. (130)


_γia[2]i_
_i=1_

X


3Lηgηl


_Keff_


-----

C.5 THEOREM 2

_Proof. With FedAvg, every client performs vanilla SGD. As such, we have ai,k = 1 which gives_
_ai = K and ∥ai∥2 =_ _√K. In addition we consider a local learning rate ηl such that Ω_ _≤_ 2[1] [as such]

we can bound A[′]-E[′] as X _[′]_ _≤_ 2X.

Finally, considering that the variables A to E can be simplified as


Var [ωi] + p[2]i _,_ (131)



_A = m_


_i=1_

_B = (K −_ 1), (132)

_C = K(K −_ 1), (133)


_p[2]i_
_i=1_

X


(134)

(135)

(136)


_D = (K −_ 1)


Var [ωi] + α
_i=1_

X


and


_p[2]i_ _,_
_i=1_ !

X

_n_

Var [ωi] + p[2]i _σ[2]_

X


_E = K_


Var [ωi] + α
_i=1_

X


the convergence bound of Theorem 3 can be reduced to


1 _T −1_ 1 _n_

_T_ _t=0_ E _∇L(θ[t])_ _≤O_  _ηgηlKT_  + O _ηgηl_ _i=1_ Var [ωi] + p[2]i _σ[2]!_

X h X  

[2][i] + _ηl[2][(][K][ −]_ [1)][σ][2][] + _ηl[2][K][(][K][ −]_ [1)][κ][2][]

_O_ _O_

_n_ _n_

   

+ _ηgηl_ Var [ωi] + α _p[2]i_ (K 1)σ[2] + Kκ[2][]
_O_ _i=1_ _i=1_ ! _−_

X X 

which completes the proof.


Ω is proportional to _i=1_ _[γ][i][ =][ P]i[n]=1_ [Var [][ω][i][]+][α][ P]i[n]=1 _[p]i[2][. With full participation, we have][ Ω= 0][.]_
However, with client sampling, all the terms in equation (136) are proportional with 1 1Ω [. Yet, we]

_−_
provide a looser bound in equation (136) independent from[P][n] Ω as the conclusions drawn are identical.
Through Ω, _i=1_ [Var [][ω][i][]][ and][ α][ needs to be minimized. This fact is already visible by inspection]
of the quantities E and F .

We note that equation (136) depends on client sampling through[P][n] _σ[2], which is an indicator of the_
clients SGD quality, and κ[2], which depends on the clients data heterogeneity. In the special case
where clients have the same data distribution and perform full gradient descent, based on the arguments discussed in the previous paragraph, we can still provide the following bound showing the
influence of client sampling on the convergence speed, while highlighting the interest of minimizing
the quantities _i=1_ [Var [][ω][i][]][ and][ α][.]

1 _T −1_ 1

[P][n] E (θ[t]) _,_ (137)

_T_ _∇L_ _≤O_ (1 Ω)ηgηlKT

_t=0_  _−_ 

X h

[2][i]

When setting the server learning rate at 1, ηg = 1 with client full participation, i.e. Var [ωi] =
Var [[P][n]i=1 _[ω][i][] =][ α][ = 0][ and][ m][ =][ n][, we have][ E][ =][ F][ = 0][ and can simplify][ A][ to]_

_n_

_A = n_ _p[2]i_ _[.]_ (138)

_i=1_

X


-----

Therefore, the convergence guarantee we provide is _ηlKT1_ [+][η][l] _ni=1_ _[p]i[2][σ][2][+][η]l[2][(][K][−][1)][σ][2][+][η]l[2][K][(][K][−]_

1)κ[2], which is identical to the one of Wang et al. (2020a) (equation (97) in their work), where
_n_ P
_i=1_ _[p]i[2]_ [can be replaced by][ 1][/n][ when clients have identical importance, i.e.][ p][i][ = 1][/n][.]

In the special case, where we useP _ηl =_ _m/KT (Wang et al., 2020a), we retrieve their asymptotic_

convergence bound _√mKT1_ [+][ p][ m]KT pni=1 _[p]i[2][σ][2][ +][ m]T_ _[σ][2][ +][ m]T_ _[Kκ][2][.]_

P

C.6 APPLICATION TO CLUSTERED SAMPLING

We adapt Theorem 2 to clustered sampling. Fraboni et al. (2021) prove the convergence of FL with
clustered sampling by giving identical convergence guarantees to the one of FL with MD sampling.
As a result, their convergence bound does not depend of the clients selection probability in the
different clusters rk,i. The authors’ claim was that reducing the variance of the aggregation weights
provides faster FL convergence, albeit only providing experimental proofs was provided to support
this statement. Corollary 2 here proposed extends the theory of Fraboni et al. (2021) by theoretically
demonstrating the influence of clustered sampling on the convergence rate. For easing the notation,
Corollary 2 is adapted to FedAvg but can easily be extended to account for any local ai using the
proof of Theorem 3 in Section C.3.

**Corollary 2. Even with no α such that Cov [ωi(St), ωj(St)] = −αpipj, the bound of Theorem 2**
_still holds with B, C, and D defined as in Section C.3 and_


1

_m_ _m[2]_

_[−]_ [1]


_, E = [1]_ (139)

_m_ [(][K][ −] [1)][,][ and][ F][ = 1]m _[K,]_


_rk,i[2]_ [+]
_k=1_

X


_p[2]i_
_i=1_

X


_A = m_


_i=1_


_where E and F are identical to the one for MD sampling and A is smaller than the one for Clustered_
_sampling._

_Proof. The covariance property required for Theorem 3 is only used for Lemma 1. In the proof of_
Theorem 3, Lemma 1 is only used in equation (113). We can instead use Lemma 2 and keep the
rest of the proof as it is in Section C.3. Therefore, the bound of Theorem 3 remains unchanged for
clustered sampling where E and F use the aggregation weight statistics of MD sampling instead of
clustered sampling. Statistics for MD sampling can be found in Section A.3 and give


_n_

_ωi(SMD)_

" _i=1_
X


= 0 and αMD = [1] (140)

_m_ _[,]_


Var


while the ones of clustered sampling in Section A.7 give


_n_

Var [ωi(SCl)] = [1]

_m_ _m[2]_

Xi=1 _[−]_ [1]


_rk,i[2]_
_k=1_ _[≤]_

X


Var [ωi(SMD)] . (141)
_i=1_

X


_i=1_


C.7 PROOF OF COROLLARY 1

_Proof. Combining equation (29) with equation (36) gives_


_n_

_m_

 _[−]_ [1]


_−_ _m[1]_


_n_

_p[2]i_ [+ 1]

_m_

_i=1_ #

X

(n − _m + 1)_


_p[2]i_ (142)
_i=1_

X

(143)


ΣMD − ΣU =


=
_−_ _m[1]_


_p[2]i_
_i=1_ _[−]_ [1]

X


Therefore, we have


_p[2]i_
_i=1_ _[≤]_

X


1

(144)
_n_ _m + 1_ _[.]_
_−_


ΣMD ΣU
_≤_ _⇔_


-----

Combining equation (31), (32), (44), and (46) gives


_p[2]i_
_i=1_ _[−]_

X


_p[2]i_
_i=1_

X


(145)


_γMD −_ _γU =_


Var [ωi(SMD)] + αMD
_i=1_

X


Var [ωi(SU )] + αU
_i=1_

X


= [1] _n −_ _m_

_m_ _[−]_ _m(n −_ 1) _[n]_


_p[2]i_ _[.]_ (146)
_i=1_

X


Therefore, we have

Noting that


1 _n −_ 1

_n −_ _m_ _n_


_p[2]i_
_i=1_ _[≤]_

X


(147)


_γMD_ _γU_
_≤_ _⇔_


1 _n −_ 1

_n −_ _m_ _n_


_m + 1_
_−_ (148)

_n(n −_ _m)(n −_ _m + 1)_ _[≤]_ [0][,]


_n −_ _m + 1_ _[−]_

completes the proof.


-----

D QUADRATIC

_Proof. For every client, we consider local loss functions such that:_

_Li(θ) = 2[1]_ _i_ _[∥][2][,]_ (149)

_[∥][θ][ −]_ **_[θ][∗]_**

where θi[∗] [is client’s][ i][ local minimum. By taking the derivative of the global loss function, equation]
(1), with these clients local loss function, gives:


**_θ[∗]_** =


_piθi[∗][.]_ (150)
_i=1_

X


**_yi,k[t]_** [is the local model obtained for client][ i][ after][ k][ SGD and satisfies]

**_yi,k[t]_** +1 [=][ y]i,k[t] _[−]_ _[η][l][(][y]i,k[t]_ _[−]_ **_[θ]i[∗][) = (1][ −]_** _[η][l][)][y]i,k[t]_ [+][ η][l][θ]i[∗][,] (151)

which, by induction, gives


_K−1_

(1 − _ηl)[k]ηlθi[∗][.]_ (152)
_k=0_

X


**_θi[t][+1]_** = (1 _ηl)[K]θ[t]_ +
_−_


We note that _k=0_ [(1][ −] _[η][l][)][k][ = [1][ −]_ [(1][ −] _[η][l][)][K][]][/η][l][. By defining][ ϕ][ = 1][ −]_ [(1][ −] _[η][l][)][K][, we get:]_

**_θi[t][+1]_** **_θ[t]_** = (1 _ηl)[K]θ[t]_ + 1 (1 _ηl)[K][]_ **_θi[∗]_** _i_ (153)

[P][K][−][1]− _−_ _−_ _−_ _[−]_ **_[θ][t][ =][ ϕ][(][θ][∗]_** _[−]_ **_[θ][t][)][.]_**

Hence, we have 
_n_

_pi(θi[t][+1]_ **_θ[t]) = ϕ(θ[∗]_** **_θ[t])._** (154)
_−_ _−_
_i=1_

X

Using Decomposition Theorem 1 leads to

_n_

E **_θ[t][+1]_** **_θ[∗]_** = (1 2˜η) E **_θ[t]_** **_θ[∗]_** + ηg[2] _γiϕ[2]_ E **_θ[t]_** **_θi[∗]_**
_−_ _−_ _−_ _−_

_i=1_

h h X h

[2][i] [2][i] [2][i]

+ ηg[2][(1][ −] _[α][)][ϕ][2][ E]_ **_θ[t]_** **_θ[∗]_** _._ (155)
_−_
h

[2][i]


-----

DDITIONAL EXPERIMENTS

YNTHETIC EXPERIMENT

(a) (b)

8 8

Full
MD

2 6 6

Uniform

- 

4 4

1

2 2

0 0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

(c) (d)

8 8

2 6 6

- 

4 4

1

2 2

0 0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

p1 p1


Figure 3: Additional plots for Figure 1. Illustration of the Decomposition Theorem 1 for the synthetic scenario described in Section 4.1 for n = 10 clients when sampling m = 5 of them. Panels
(a) to (d) show the distances estimated experimentally when averaging over 1000 simulations for
iid (Panels (a) and (c)), and non-iid settings, (Panels (b) and (d)), and with the associated standard
deviation, (Panels (a) and (b)), and minimum and maximum distances, (Panels (c) and (d)). We
consider ηg = 1, ηl = 0.1, and K = 10.

10[23] 10[22]

2
- 10[9] Full 10[8]

MD

t 10 5 Uniform 10 6

10 19 10 20

0 200 400 600 800 1000 0 200 400 600 800 1000

t t


Figure 4: We consider the synthetic scenario described in Section 4.1 for n = 100 clients when
sampling m = 5 and r = 0.9. We show the distances estimated experimentally when averaging
over 1000 simulations for iid (Panel (a)), and non-iid settings (Panel (b)). We consider ηg = 1,
_ηl = 0.2, and K = 1. With K = 1, we show that the divergence does not come from asking too_
much work to the local clients. Uniform sampling divergence can be prevented by lowering the local
learning rate ηl (consistently with Theorem 2).


E.2 SHAKESPEARE DATASET

The client local learning rate ηl is selected in {0.1, 0.5, 1., 1.5, 2., 2.5} minimizing FedAvg with full
participation, and n = 80 training loss at the end of the learning process.


-----

1.5

1.0


1.5

1.0


0.5

1.5


0.5

2.0


1.5

1.0


1.0

1.5


1.5

1.0


1.0

2.0


2.0


1.5

1.0


1.5

|(a) - n|= 10|
|---|---|
|||
|0 100 200 (c) - n|300 400 500 = 40|
|||
|0 100 200 (e) - n|300 400 500 = 10|
|||
|0 100 200 (g) - n|300 400 500 = 40|
|||


|(b) -|n = 20|
|---|---|
|||
|0 100 200 (d) -|300 400 500 n = 80|
|||
|0 100 200 (f) -|300 400 500 n = 20|
|||
|0 100 200 (h) -|300 400 500 n = 80|
|||



100 200 300 400 500 0 100 200 300 400 500

# rounds # rounds

MD Uniform Clustered


Figure 5: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 10 ((a) and (e)), n = 20 ((b) and (f)), n = 40 ((c) and (g)), and n = 80 ((d) and
(h)), while sampling m = n/2 of them. In (a-d), clients have identical importance, i.e. pi = 1/n,
and, in (e-h), their importance is proportional to their amount of data, i.e. pi = ni/M . Global losses
are estimated on 30 different model initialization.

(a) - pi = 1/n (b) - pi = ni/M

0.075 0.0

)U 0.050 0.1
( 0.025 0.2
)(MD 0.000 0.3

0.025 0.4

0.050

0 100 200 300 400 500 0 100 200 300 400 500

# rounds m=4 m=8 m=40 # rounds


Figure 6: Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n = 80 clients and sampling m ∈{4, 8, 40} of them while clients
perform K = 50 SGD steps . In (a), clients have identical importance, i.e. pi = 1/n. In (b), clients
importance is proportional to their amount of data, i.e. pi = ni/M . Differences in global losses are
averaged across 15 FL experiments with different model initialization (global losses are provided in
Figure 7).


-----

2.0


2.0

1.8

1.6

1.4

1.2

1.0

2.0

1.8

1.6

1.4

1.2


1.8

1.6

1.4

1.2

1.0

2.0

1.8

1.6

1.4

1.2




|(a) -|m = 4|
|---|---|
|||
|0 200 400 (c) -|600 800 1000 m = 4|
|||


|(b) -|m = 8|
|---|---|
|||
|0 200 400 (d) -|600 800 1000 m = 8|
|||


0 200 400 600 800 1000 0 200 400 600 800 1000

# rounds # rounds

MD Uniform Clustered

Figure 7: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 80 clients while sampling m = 4 ((a) and (c)), and m = 8 ((b) and (d)) while
clients perform K = 50 SGD steps. In (a-b), clients have identical importance, i.e. pi = 1/n, and,
in (d-f), their importance is proportional to their amount of data, i.e. pi = ni/M . Global losses are
estimated on 15 different model initialization.


(a) - pi = 1/n (b) - pi = ni/M

0.04 0.02

0.00

)U
( 0.02 0.02
) 0.04
MD 0.00
( 0.06

0.02 0.08

0.10

1000 1250 1500 1750 2000 2250 2500 1000 1250 1500 1750 2000 2250 2500

# rounds m=8 m = 40 # rounds


Figure 8: Difference between the convergence of the global losses resulting from MD and Uniform
sampling when considering n = 80 clients and sampling m ∈{8, 40} of them while clients perform
_K = 1 SGD step. In (a), clients have identical importance, i.e. pi = 1/n. In (b), clients importance_
is proportional to their amount of data, i.e. pi = ni/M . Differences in global losses are averaged
across 15 FL experiments with different model initialization (global losses are provided in Figure
9).


-----

(a) - m = 8 (b) - m = 40

4 4

)t

(

3 3

2 2

0 500 1000 1500 2000 2500 0 500 1000 1500 2000 2500

(c) - m = 8 (d) - m = 40

4 4

)t
( 3 3

2 2

0 500 1000 1500 2000 2500 0 500 1000 1500 2000 2500

# rounds # rounds

MD Uniform


Figure 9: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 80 clients while sampling m = 4 ((a) and (d)), m = 8 ((b) and (e)), m = 40 ((c)
and (f)) while clients perform K = 1 SGD steps. In (a-c), clients have identical importance, i.e.
_pi = 1/n, and, in (d-f), their importance is proportional to their amount of data, i.e. pi = ni/M_ .
Global losses are estimated on 15 different model initialization.


-----

E.3 CIFAR10 DATASET

We consider the experimental scenario used to prove the experimental correctness of clustered sampling in (Fraboni et al., 2021) on CIFAR10 (Krizhevsky, 2009). The dataset is partitioned in n = 100
clients using a Dirichlet distribution with parameter α = 0.1 as proposed in Harry Hsu et al. (2019).
10, 30, 30, 20 and 10 clients have respectively 100, 250, 500, 750, and 1000 training samples, and
testing samples amounting to a fifth of their training size.

(a) - = 0.1

2.0

)t

(

1.5

1.0

0 200 400 600 800 1000

(b) - = 0.01

2.5

)t

(

2.0

1.5

0 200 400 600 800 1000

(c) - = 0.001

3.0

)t
( 2.5

2.0

1.5

0 200 400 600 800 1000

# rounds

MD Uniform Clustered


Figure 10: Convergence speed of the global loss with MD sampling and Uniform sampling when
considering n = 100 clients, while sampling m = 10 of them. Clients are partitioned using a
Dirichlet distribution with parameter α = 0.1 (a), α = 0.01 (b), and α = 0.001 (c). Global losses
are estimated on 30 different model initialization.


-----


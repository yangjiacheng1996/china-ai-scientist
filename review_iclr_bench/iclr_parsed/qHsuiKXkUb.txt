# HIGH PRECISION SCORE-BASED DIFFUSION MODELS

**Anonymous authors**
Paper under double-blind review

ABSTRACT

Recent advances in diffusion models bring the state-of-the art performance on
image generation tasks. However, image generation is still an arduous task in high
resolution, both theoretically and practically. From the theory side, the difficulty
arises in estimating the high precision diffusion because the data score goes to ∞
as t → 0 of the diffusion time. This paper resolves this difficulty by improving
the previous diffusion models from three aspects. First, we propose an alternative
parameterization for such an unbounded data score, which theoretically enables the
unbounded score estimation. Second, we provide a practical Soft Truncation trick
(ST-trick) to handle the extreme variation of the score scales. Third, we design
a Reciprocal Variance Exploding Stochastic Differential Equation (RVESDE) to
enable the sampling at the high precision of t. These three improvements are
applicable to the variations of both NCSN and DDPM, and our improved versions
are named as HNCSN and HDDPM, respectively. The experiments show that the
improvements result in the state-of-the-art performances in the high resolution
image generation, i.e. CelebA-HQ. Also, our ablation study empirically illustrates
that all of 1) alternative parameterization, 2) ST-trick, and 3) RVESDE contributes
to the performance enhancement.

1 INTRODUCTION

Recent advances in the generative models enable creating of highly realistic images. One direction of
such modeling is likelihood-free models (Karras et al., 2019) based on the minimax training. The other
direction is likelihood-based models, including VAE Vahdat and Kautz (2020), autoregressive models
(Parmar et al., 2018), and flow models (Grci´c et al., 2021). Diffusion models (Ho et al., 2020) are
one of the most successful likelihood-based models where the generative process is modeled by the
reverse diffusion process. The success of diffusion models achieves the state-of-the-art performance
in image generation (Dhariwal and Nichol, 2021; Song et al., 2020).

Despite of such success, the score-based diffusion models still struggle in generating realistic
images with high resolution (Jolicoeur-Martineau et al., 2021). Rather than improving the network
architecture, this paper focuses mostly on the theoretic and the optimization aspects of the diffusion
model to improve the sample quality. We first observe that the diffusion time acts in distinctive ways
on the sample generation: the diffusion process with the front diffusion time (t ≈ 0) influences
the local sample fidelity, and the end diffusion time (t ≈ _T_ ) shapes the sample global structure.
However, the unbounded data score at the front diffusion time results in the training instability, and
this instability yields the diffusion model with poor estimation limiting the local sample fidelity,
which prevents the advancement in the high resolution because of its locality. Hence, this paper
constructs a diffusion model capable of training both front time and end time, effectively.

We observe that the current score parametrization is incapable of estimating the data score that blows
up as t → 0, which requires a new theory-driven parametrization for the unbounded score network
to enable the successful score estimation near t ≈ 0. This parametrization is universally applicable
for any diffusion models including NCSN (Song and Ermon, 2019) and DDPM (Ho et al., 2020),
and we call this parametrization as High precision NCSN (HNCSN) and High precision DDPM
(HDDPM), respectively. Second, we propose a practical optimization method (ST-trick) to improve
the score estimation at the end of the diffusion time (t ≈ _T_ ). This ST-trick provides a distinctive
way to optimize the diffusion model parameters, and we argue that this trick successfully trains the
score network at the end diffusion time by its nature, which is likely to be ignored due to the minor
contribution to the diffusion loss near t ≈ _T in the previous studies. Like the new parametrization,_


-----

ST-trick fits to any diffusion model, including NCSN/HNCSN and DDPM/HDDPM. Finally, we
suggest a new SDE (RVESDE) that 1) mitigates the theoretic dilemma of VESDE that arises as t → 0
and 2) gives additional performance boost by reducing the Monte-Carlo variance for the diffusion
loss. We perform the ablation study on our three improvements, and we find that using 1) the new
parametrization, 2) ST-trick, and 3) RVESDE all together improves both density estimation and
sample fidelity on benchmark datasets. Although we proceed our arguments based on the continuous
diffusion models, we emphasize that both new parametrization and ST-trick are applicable for discrete
diffusion models, such as ADM (Dhariwal and Nichol, 2021) and CDM (Ho et al., 2021), as well.

2 PRELIMINARY


The diffusion model trains the network by minimizing the Negative Evidence Lower BOund (NELBO)

_T_

(NELBO) Epr(x0) log pθ(x0) (θ; λ = g[2]) = [1] _g[2](t)_ _t(θ) dt,_ (1)
_−_ _≤L_ 2 0 _L_

Z

where  
_Lt(θ) = Ext_ _∥sθ(xt, t) −∇xt log pt(xt)∥2[2]_ = Ex0,xt _∥sθ(xt, t) −∇xt log p0t(xt|x0)∥2[2]_ _,_
up to a constant. Here, λ is the weighting function for the diffusion loss of _t(θ) at each diffusion time,_
   _L_ 
_pt(xt) is the marginal distribution of the diffusion process of {xt}t[T]=0[, and][ p][0][t][(][x][t][|][x][0][)][ is the transition]_
probability defined by (xt; µ(t)x0, σ[2](t)I), where µ(t) and σ[2](t) are determined by the governing
_N_
diffusion process. Previous works suggest a couple of diffusion processes: 1) VESDE dxt = g(t) dωt
with g(t) = σmin( _[σ]σ[max]min_ [)][t][q]2 log ( _[σ]σ[max]min_ [)][, and 2) VPSDE][ d][x][t][ =][ −] 2[1] _[β][(][t][)][x][t][ d][t][ +]_ _β(t) dωt with_

_βσ[2](t() =t) = β σmin[2]min + ((_ _[σ]σ[max]minβmax[)][2][t] −[ −]_ [1]βmin, and VPSDE has)t. With these diffusion schemes, VESDE has µ1 ( tt) = e[−] [1]2 R t0 _[β][(][s][) d][s]_ with σ[2](t) = 1 µp −(t)e ≡[−] R t0 1[β] with[(][s][) d][s].

We observe that the transformation of1 _t_   **yt = e** 2 0 _[β][(][s][) d][s]xt reduces VPSDE to VESDE of dyt =_
_e_ 2 0 _[β][(][s][) d][s][p]β(t) dωt by the Ito’s lemma (Oksendal, 2013), so VPSDE and VESDE are indeedR_

equivalent representations of the linear diffusion. Given their equivalence under the suggestedR
transformation, we build our model based on VESDE as a default diffusion otherwise stated.


10[0]

10[−][1]

10[−][2]

10[−][3]

10[−][4]

10[−][5]

10[−][6]

10[−][7]



2.1 EFFECT OF DIFFUSION TIME ON DIFFUSION MODEL


**Density Estimation In practice, previous diffusion models truncate**
the diffusion time from [0, T ] to [ϵ, T ] to stabilize the training. Figure
1 emphasizes the loss contribution to the NELBO at t → 0, which
signifies lowering ϵ in the practice. Moreover, Figure 2 shows the
cumulative loss of Figure 1 integrated over [σ, σmax] by changing
the integrating variable from t to σ in Eq. 2, and the high precision
(i.e., σ ≈ 0 or t ≈ 0) has significant portion on the NELBO. σmax

(θ; g[2]) = [1] _v_ _σ−1(v)(θ) dv._ (2)
_L_ 2 0 _L_

Z

Therefore, lowering σmin = σ(ϵ) guarantees the tighter NELBO
given its large portion at t = ϵ. Empirically, NCSN++ (Song et al.,
2020) performs 3.45 for NELBO trained with σmin = 10[−][2] on
CIFAR-10, but this NELBO is tightened up to 3.04 by lowering
_σmin to 10[−][3]_ in our experiments.

|Col1|Col2|Col3|1 g2(t)(θ)|
|---|---|---|---|
||||12g2(t)Lt(θ)|
|||||
|||||
|||||
|||||
|||||
|||||


0.0 0.2 0.4 0.6 0.8 1.0

Diffusion time

Figure 1: Loss contribution to
NELBO by diffusion time.



16

14

12

10

|1 �σmax|Col2|Col3|Col4|
|---|---|---|---|
|12Rσσmaxv|Lσ−1(v)(θ)dv|||
|||||
|||||
|||||
|||||
|||||
|||||
|||||


12 R σσ _max_ _vLσ−1(v)(θ)dv_


10[−][3] 10[−][2] 10[−][1] 10[0] 10[1]

Diffusion level σ (log)


_σmin to 10[−][3]_ in our experiments. Figure 2: NELBO by diffu
sion level.

**Sample Generation While we discussed the value of the loss at**
_t →_ 0, both fron and end diffusion time contribute to the sample quality in two distinctive ways.𝑡𝑡= 𝑇𝑇 Diffusion Time Horizon 𝑡𝑡= 0

_End Time (t_ _T_ _) : The diffusion model creates a fake_
_→_ Good
sample by reverting the diffusion process with the score
estimation. Figure 3 shows two contrastive image genera- Not
tions: the realistic image at the first row, and the unrealistic Good
image at the second row with curly hair on its forehead. Generative Process

𝑡𝑡= 𝑇𝑇 Diffusion Time Horizon 𝑡𝑡= 0

Good

Not
Good

Generative Process

This unwanted hair is synthesized at the early steps of the Figure 3: Generative process.
reverse diffusion, which correspond to the end time of the forward diffusion. Therefore, Figure 3
implies that the overall sample quality is determined on the range of the end diffusion time.


-----

_Front Time (t →_ 0) : The sample generation
in Figure 4 shows that the local fidelity heavily depends upon the denoising process at the
front of the diffusion time. This intuitive result is grounded by theory: observe that the

Figure 4: Generated images from CelebA-HQ

random variable **xt** **x0** 2[/σ][2][(][t][)][ follows the]
_χ[2]-distribution of degree ∥_ _−_ _d∥, where[2]_ _d is the data_ 256 × 256. Image quality (NIQE (Mittal et al.,

2012)) improves as the denoising proceeds.

dimension. If the score network exactly estimates the data score, the generated image at time t would follow xt, and the average distance between
the real sample (x0) with the fake sample (xϵ) becomes Epr(x0)Ep0ϵ(xϵ **x0)[** **xϵ** **x0** 2[] =][ σ]min[2] _[d][.]_
Therefore, even if the score network perfectly estimates the data score, this leads that minimizing| _∥_ _−_ _∥[2]_
_σmin acts in a crucial way for the pixel-wise precision._

From these observations, we identified that the front diffusion time is critical in generating the high
resolution image for the pixel-wise details, and we also acknowledge that the end diffusion time
contributes to the overall image structure. Now, our question becomes whether the existing models
can learn the data score at both front and end diffusion time.

WITH2.2 HPROBLEMS OFIGH PRECISION TRAINING THE DIFFUSION MODEL 2∥x p)(tt2 65××1010[6][6]


**Unbounded Score Figure 5 presents that the data score is unbounded**
as the diffusion level, σ[2](t), diminishes. This requires the score
parametrization to handle this unboundedness. For instance, the
parametrization of sθ(xt, σ(t)) yields the failure of the score estimation at t = 10[−][4] on the toy example in Figure 6.


2∥x p)(tt2 65××1010[6][6]
logxt 4×10[6]
_∥∇3×10[6]_

2×10[6]

1×10[6]

Data score 0×10[6]

10[−][3] 10[−][2] 10[−][1] 10[0] 10[1]

Diffusion level σ (log)


Figure 5: Unbounded score.


Theoretically, Lemma 1 states that the score estimation with sθ(xt, t) (DDPM) or sθ(xt, σ(t))
(NCSN) fails if the data score is unbounded. See Appendix A for the proof.

**Lemma 1. Let H[0,T ] = {s : R[d]** _× [0, T_ ] → R[d], s is locally Lipschitz}. Suppose a continuous
_vector field v defined on a subset U of a compact manifold M (i.e., v : U ⊂_ _M →_ R[d]) is unbounded,
_then there exists no s_ [0,T ] such that limt 0 s(x, t) = v(x) a.e. on U _._
_∈H_ _→_


The score network, sθ, is an element in H[0,T ] for any Data samples Data score Estimated score by NCSN++ Estimated score by HNCSN++
neural architecture as long as we put t in the network, so
Lemma 1 indicates that the vanilla score network cannot
estimate an unbounded data score.

Data samples Data score Estimated score by NCSN++ Estimated score by HNCSN++

Figure 6: Score estimation of NCSN and

**Training Instability Training the diffusion time on the** HNCSN on a toy dataset.
front range is advantageous on the creation of high-quality
samples. However, training the diffusion model with lowered σmin induces the numerical instability,
which eventually harms the overall sample quality.


3000

2500

2000

1500

1000

500


To analyze the logic of the training instability, Figure 7 illustrates
the Monte-Carlo samples of the diffusion loss, which blows up as
_t →_ 0 (or σ → 0). This leads that the diffusion loss is dominated
by the diffusion time with the front range in practice, and the loss at
the end diffusion time is barely counted in the gradient signal. This
imbalanced loss brings the immatured score estimation at the end
diffusion time, which ruins the overall sample shape.

**Limitation of Diffusion Process Continuous VESDE has its dif-**
fusion variance to be σ[2](t) = σmin[2] ( _[σ]σ[max]min_ [)][2][t][ −] [1] . As introduced

in Song and Ermon (2020), VESDE has been suggested in its orig
 

inal discrete version based on the geometric property for its smooth
transition of the distributional shift. Mathematically, the variance is
geometric if _dt[d]_ [log][ σ][2][(][t][)][ is a constant, but the continuous VESDE]

breaks this geometric progression as in Figure 8.

To make it geometric, Song et al. (2020) approximates the VESDE
diffusion process by the transition probability of p0t(xt **x0) =**
_|_

|Col1|Col2|Col3|τ = σ τ = σ|−1(0.001) −1(0.01)|
|---|---|---|---|---|
||||τ = σ|−1(0.1) 1|
||||τ = σ|−(1.0)|
||||||
||||||
||||||
||||||


10[−][3] 10[−][2] 10[−][1] 10[0] 10[1]

Diffusion level σ (log)

Figure 7: Imbalanced MonteCarlo losses.


60000

40000

20000

|Col1|Col2|Col3|Col4|ddt log σ2(t) ddt log σ2(1/t|of VESDE ) of RVESDE|
|---|---|---|---|---|---|
|||||||
|||||||
|||||||
|||||||


10[−][5] 10[−][4] 10[−][3] 10[−][2] 10[−][1] 10[0]


Diffusion time (log)

Figure 8: VESDE violates the
geometric progression.


-----

_N_ **xt; x0, σmin[2]** [(][ σ]σ[max]min [)][2][t][I], so this approximate diffusion process satisfies the geometric progres
sion. However, this approximation leads that xt is not converging to x0 in distribution because

  

_σmin[2]_ [(][ σ]σ[max]min [)][2][t][ →] _[σ]min[2]_ _[>][ 0][ as][ t][ →]_ [0][.]

**Proposition 1. There is no SDE that has the stochastic process {xt}t∈[0,T ], defined by a transition**
_probability p0t(xt|x0) = N_ (xt; x0, σmin[2] [(][ σ]σ[max]min [)][2][t][I][)][, as the solution.]

Proposition 1 indicates that if we approximate the diffusion process by p0t(xt **x0)** =
_|_
_N_ **xt; x0, σmin[2]** [(][ σ]σ[max]min [)][2][t][I], then the reverse diffusion cannot be modeled by a reverse SDE. There
fore, VESDE loses its theoretic ground on the continuation of the discrete Markov chain.

  

3 HIGH PRECISION SCORE-BASED DIFFUSION MODELS

Given the three problems of unbounded score, training instability, and limited diffusion process, this
section improves the diffusion model in three corresponding aspects. Section 3.1 introduces the
theory-driven new parametrization, called HNCSN and HDDPM, that enables the successful score
estimation for the diffusion model with small σmin. Section 3.2 proposes the practical technique,
ST-trick, which could estimate the score network at the end of the diffusion time without being
dominated by the front diffusion. Section 3.3 suggests the new SDE, RVESDE, which develops the
VESDE suitable for small σmin.

3.1 PARAMETRIZATION MODEL FOR UNBOUNDED SCORE

As presented in Lemma 1, the score estimation of baseline models (NCSN/DDPM) fails because the
locally Lipschitz with respect to the time argument does not hold anymore at t = 0. From this, we
make the time argument extendable to the infinity at t = 0. To proceed, let us define η : t 7→ R as a
function that satisfies η(t) or as t 0. Then, the parametrization of sθ(xt, η(t)) would
_→∞_ _−∞_ _→_
successfully estimate the data score by Proposition 2.

**Proposition 2. Let** [1, ) = **s : R[d]** [1, ) R[d], s is locally Lipschitz _. Suppose a continuous_
_H_ _∞_ _{_ _×_ _∞_ _→_ _}_
_vector field v defined on a d-dimensional open subset U of a compact manifold M is unbounded,_
_and the projection of v on each axis is locally integrable. Then, there exists s_ [1, ) such that
_∈H_ _∞_
limη→∞ **s(x, η) = v(x) a.e. on U** _._

Table 1: Instantiation of the unbounded

Proposition 2 becomes the foundation of the un- parametrization from Proposition 1. See Apbounded parametrization, and the introduction pendix B for the choice of c1, c2, σ0.
of η is the key to enable the estimation of the Model _η(t)_
unbounded data score. Therefore, we introduce the new parametrization for the high pre-cision score network as sθ(xt, η(t)), rather than HNCSN _η(t) :=_  log− _σ[c] σ([1]t()t)[+][ c][2]_ ifif σ σ((tt)) < σ ≥ _σ00_
**sθ(xt, t) (DDPM) or sθ(xt, σ(t)) (NCSN).** HDDPM _η(t) :=_ _σg[2][2]((tt))_ [d][t]

R

Table 1 presents example parametrizations following Proposition 2. We suggest HNCSN with η(t)
as the mixture of log σ(t) at the end diffusion time and _σ(1t)_ [at the front diffusion time, in which the]

inverse function is beneficial on estimating the rapidly blowing data score by orders of _σ[1]_ [. Note that]

Song and Ermon (2020) proposed the score parametrization of **[s][θ]σ[(]([x]t)[t][)]** [, and Jolicoeur-Martineau et al.]

(2020) showed that the optimal score function becomesz ∼N (0, I). Therefore, we suggest HNCSN to put _σ(1t)_ [in place of] s[∗](xt, t) =[ log]E[ σ]x0[(]|[t]xσ[)]t[ at the front time.][2][(xt0)]−xt _≈_ _σ(zt)_ [, where]

Before we choose optimal η for DDPM, observe that DDPM with the importance sampling has _σ[g][2][2][(]([t]t[)])_

as the importance weight, and this weight forces the sampled diffusion time highly concentrated on
_t_ _ϵ. Since a small difference between two diffusion times near t1, t2_ _ϵ results in a large deviation_
of two data scores in their scales, DDPM cannot approximate this extreme scale deviation with the ≈ _≈_
vanilla parametrization of sθ(xt, t) by Proposition 2.

We propose HDDPM with η(t) = _gσ2[2]((tt))_ [d][t][ as the antiderivative of the importance weight. For]

_g2(t)_ _t_
instance, HDDPM with VPSDE has its antiderivative asR _σ[2](t)_ [d][t][ = log (1][ −] _[e][−]_ 0 _[β][(][s][) d][s]) +_
R R


-----

_t_
0 _[β][(][s][) d][s][. This antiderivative diverges to][ −∞]_ [as][ t][ →] [0][ for both VPSDE and subVPSDE, so]
it satisfies the condition of Proposition 2.
R 1.0 DDPM

The choice of suchmation near t _ϵ because the input of η(t) for HDDPM helps the enhanced score esti- η(t) is distributed uniformly_ 00..86 HDDPM
_≈_
when we draw samples from the importance weight. Concretely,when the sampling distribution on the diffusion time is given by 00..42

Cumulative density function

_pcomes(t) ∝ pσ[g]([2][2]η[(]([t])t[)]) ∝[, the]1[ η], which is depicted in Figure 9. Therefore, this[-distribution from the importance sampling be-]_ 0.0 0.0 Normalized second input (0.2 0.4 0.6 _η(t) or t0.)8_ 1.0

|DDPM HDDP|M|Col3|Col4|Col5|Col6|Col7|
|---|---|---|---|---|---|---|
||||||||
||||||||
||||||||
||||||||


uniform distribution on η(t) in HDDPM guarantees the high preci- Figure 9: Cumulative density
sion to the score estimation. function of t and η.

3.2 SOFT TRUNCATION TRICK FOR PRACTICAL SCORE ESTIMATION


While the unbounded parametrization suggested in Section 3.1 provides the theoretic guarantee of the
score estimation, this section proposes a practical optimization method for the high precision score
estimation. In order to successfully train the score network without sacrificing the global fidelity, we
detour the training instability by introducing the Soft Truncation (ST) trick that is taking a distinctive
diffusion truncation for every mini-batch. In formula,

_LST (θ; λ, P) = EP(τ_ )[L(θ; λ, τ )],


where P(τ ) is the prior distribution for the diffusion truncation. In every mini-batch update, we
optimize L(θ; λ, τ ) with the sampled τ ∼ P(τ ) from the prior. Figure 7 illustrates four cases: blue
dots with τ = ϵ, green dots with τ = σ[−][1](0.01), etc. With ST-trick, a mini-batch with high truncation
of τ = σ[−][1](1) (purple) focuses on the score estimation at large t, and mini-batches with medium
_τ = σ[−][1](0.1) (green) and = σ[−][1](0.01) (red) focus on the middle region of [ϵ, T_ ]. In consequence,
ST-trick trains the diffusion model by partitioning its diffusion time for each mini-batch update.

The ST-trick with P(τ ) = δϵ(τ ) unconditionally Table 2: Example pairs of (P, λP).
selects ϵ for every batch update, so it is equiva- _λ_ _k_ P _λP_
Although it is free to chooselent with the original optimization of P, we find that the L(θ; λ, ϵ). RVE _λλ((tt))_ 2∞ _δτ1ϵ[2]([ 1]τ[[])[ϵ,T][ ]][(][τ]_ [)] (1λ( −t) _[ϵ]t_ [)][λ][(][t][)]
reciprocal functions work best in practice. Ob-serving that _τ1[k][ 1][[][ϵ,T][ ]][(][τ]_ [)][/Z][ →] _[δ][ϵ][(][τ]_ [)][ as][ k][ →∞] VP _λλ((tt))_ 1∞ _δτ1ϵ[1](τ[[][ϵ,T])_ [ ]][(][τ] [)] (1λ( −t) logϵ (t))λ(t)

where Z is the normalizing constant, the reciprocal functions are connected to the original optimization. We enumerate few examples of k = 2 and
_k = 1 in Table 2 for RVESDE and VPSDE, respectively. Note that ST-trick is independent to the_
choice on the weighting function λ for the batch-wise optimization loss, L(θ; λ, τ ).

**Theoretic Analysis of ST-trick The ST-loss reduces the original diffusion loss to** _ST (θ; λ, P) =_
_t_ _L_
_L(θ; λP, ϵ) with λP(t) :=_ 0 [P][(][τ] [) d][τ] _λ(t) in expectation by the Fubini theorem (Stein and_
Shakarchi, 2009). While the ST-loss in average is identical to the original diffusion loss, the
major difference lies on that 1)  R L(θ; λP, ϵ) optimizes the diffusion loss in its averaged form and 2)
_LST (θ; λ, P) with ST-trick optimizes the diffusion loss with the Monte-Carlo sampled truncation, τ_ .

To inspect how soft truncation affects to the optimization, let us assume λ(t) = g[2](t). Then, we
observe that the theoretic analysis previously suggested in Song et al. (2021) is directly extendable to
any τ ∈ (0, T ] by simply switching the positive truncation time, τ, in place of the zero time:

Epτ (xτ ) log pθ,τ (xτ ) (θ; g[2], τ ),
_−_ _≤L_

where pθ,τ is the marginal probability distribution at time  _τ of the reverse (generative) process that_
starts from the prior distribution and flows backwards in time, and pτ is the marginal probability
density at time τ of the forward diffusion process. Then, the above inequality is equivalent to

_DKL(pτ_ _pθ,τ_ ) (θ; g[2], τ ),
_∥_ _≤L_

after omitting constants independent of θ for the above two inequalities. This KL bound means that
our ST-trick simply ignores the time range beneath τ, and optimizes the proxy of the KL divergence
between the forward and the reverse diffusion at time τ . On the other hand, no such interpretation
can be applied to the diffusion loss without ST-trick, L(θ; λP, ϵ).


-----

3.3 RECIPROCAL VARIANCE EXPLODING SDE FOR SMALL TRUNCATION

This section introduces RVESDE whose variance, σ[2](t), is geometric by its nature. RVESDE is
defined as the form of dxt = g(t) dwt with


_σmax_ _σσmaxmin_ [)]

0

 


2ϵ log ( _[σmax]_

_σmin_ [)]


if t > 0,
if t = 0.[1]


_g(t) :=_


2ϵ

The transition probability of RVESDE becomes p0t(xt|x0) = _N_ **xt; x0, σmax[2]** [(][ σ]σmax[min] [)] _t I_ .

Recall that VESDE assumes g(t) = _σmin(_ _[σ]σ[max]min_ [)][t][q]2 log ( _[σ]σ[max]min _ [)][ and][ p][0][t][(][x][t][|][x][0][)] =

_N_ **xt; x0, σmin[2]** ( _[σ]σ[max]min_ [)][2][t][ −] [1] **I** . As presented in Figure 8, RVESDE attains the geometric property

at the expense of having reciprocated time, 1/t. We could successfully model the forward diffusion

    

process with RVESDE without any approximation, and this exact modeling of the forward process
enables applying the stochastic calculus to compute the log-likelihood or to generate new samples.

It is common to apply the importance sampling (Song et al., 2021) in order to minimize the MonteCarlo variance on the diffusion loss as illustrated in Figure 13 (c). RVESDE is advantageous on
VE/VPSDEs that the importance sampling is easy to implement: the diffusion loss with RVESDE
becomes

_T_ _σmax_ 1ϵ

(θ; g[2], ϵ) = [1] _g[2](t)_ _t(θ) dt = ϵ log_ _σ[2](s[−][1])_ _s−1_ (θ) ds,
_L_ 2 _ϵ_ _L_ _σmin_ _T1_ _L_

Z   [Z]

by substituting the integrating variable into the reciprocated time. Therefore, the importance sampling
for RVESDE is equivalent to drawing the diffusion time uniformly on a reciprocated interval, [ _T[1]_ _[,][ 1]ϵ_ []][.]

4 EXPERIMENTS

This section empirically studies our suggestions on benchmark datasets, including CIFAR-10
(Krizhevsky et al., 2009), STL-10 (Coates et al., 2011)[2] CelebA (Liu et al., 2015) 64×64, CelebA-HQ
(Karras et al., 2017) 256 × 256, LSUN (Yu et al., 2015) Bedroom/Church 256 × 256, and FFHQ
(Karras et al., 2019). We compute bits-per-dim, proportional to NLL, by applying the Instantaneous
Change of Variable Chen et al. (2018); Song et al. (2020) to the probability flow (Song et al., 2020)
with the uniform dequantization (Theis et al., 2015; Hoogeboom et al., 2020), rather than the variational dequantization (Ho et al., 2019) in order to sidestep the need of training an auxiliary flow
network. Also, we use the clean-FID introduced in Parmar et al. (2021) for computing the FID
(Heusel et al., 2017) score with the predictor-corrector sampler (Song et al., 2020). Training and
evaluation details are available in Appendix B.

4.1 QUANTITATIVE RESULTS

Table 3 compares HNCSN++ (RVE) with ST-trick against the current best generative models, and
Table 3 shows that our model establishes the state-of-the-art performances. On CIFAR-10, we observe
that our model improves NCSN++ (VE) in NLL and IS at the expense of sacrificing FID slightly. In
particular, our model surpasses the previous best IS performance (StyleGAN2-ADA+Tuning (Karras
et al., 2020)) by performing 10.11 on CIFAR-10. HNCSN++ trained on CelebA is the best performer
in terms of the FID performance, but CR-NVAE (Sinha and Dieng, 2021) outperforms our model
in NLL. However, we emphasize that HDDPM++ in Table 6 with ST-trick (1.52) outperforms CRNVAE (1.86) in NLL by far. In particular, HNCSN++ with high-dimensional CelebA-HQ 256 × 256
performs the state-of-the-art in FID out of the baselines in the diffusion models (NCSN++) and
the GAN models (PGGAN (Karras et al., 2017)). Finally, HNCSN++ on STL-10 dataset largely
outperforms the baselines by improving the state-of-the-art FID from 15.17 (Park and Kim, 2021) to
7.71, and IS from 11.01 (Park and Kim, 2021) to 13.43.

In Table 3, when computing the Inception Score (IS) (Salimans et al., 2016), there is a minor
discrepancy between likelihood-based models and likelihood-free models. IS-50k in diffusion models

1The existence and uniqueness of solution for RVESDE is guaranteed by Theorem 5.2.1 in Oksendal (2013).
2We downsize the dataset from 96 × 96 to 48 × 48 following Jiang et al. (2021); Park and Kim (2021).


-----

Table 3: Performance comparisons on benchmark datasets. The boldfaced numbers present the best
performance, and the underlined numbers present the second-best performance.

CIFAR10 CelebA CelebA-HQ STL-10
Model NLL (↓) 32FID ( × 32↓) IS (↑) NLL64 × 64FID 256 × 256FID (8-bits) FID48 × 48IS

HNCSN++ (RVE) + ST 3.04 2.33 **10.11** 1.93 **1.92** **7.16** **7.71** **13.43**

**Likelihood-based Models**
CR-NVAE (Sinha and Dieng, 2021) **2.51** -  -  **1.86** -  -  -  - 
LSGM (FID) (Vahdat et al., 2021) 3.43 **2.10** -  -  -  -  -  - 
DenseFlow-74-10 (Grci´c et al., 2021) 2.98 -  -  1.99 -  -  -  - 
Gamma Distribution DDIM (Nachmani et al., 2021) -  -  -  -  2.92 -  -  - 
VDM (Kingma et al., 2021) 2.65 -  -  -  -  -  -  - 
NCSN++ cont. (deep, VE) (Song et al., 2020) 3.45 2.20 9.89 2.39 3.95 7.23 -  - 
DDPM++ cont. (deep, sub-VP) (Song et al., 2020) 2.99 2.41 9.57 -  -  -  -  - 
ScoreFlow (cont. norm. flow) (Song et al., 2021) 2.74 5.70 -  -  -  -  -  - 
Improved DDPM (Lsimple) (Nichol and Dhariwal, 2021) 3.37 2.90 -  -  -  -  -  - 
**Likelihood-free Models**
StyleGAN2-ADA+Tuning (Karras et al., 2020) -  2.92 10.02 -  -  -  -  - 
Styleformer (Park and Kim, 2021) -  2.82 9.94 -  3.66 -  15.17 11.01

PGGAN (Karras et al., 2017) -  -  8.8 -  -  8.03 -  - 
TransGAN (Jiang et al., 2021) -  9.26 9.02 -  5.01 -  18.28 10.43


(Song et al., 2020; Ho et al., 2020) computes the score with 50k generated images once, while
IS-5k in GAN models (Karras et al., 2020; Park and Kim, 2021) computes the score 10 trials with
independently generated 5k samples and report the performance as the average of scores. We report
IS-50k following Song et al. (2020), but we note that IS-5k performs almost identical to IS-50k by
performing 10.07 on CIFAR-10 and 13.34 on STL-10 in terms of IS-5k.

One particular observation in Table 3 is the IS performance (13.34) of STL-10 that exceeds the number
of classes (10) of the dataset. We follow Park and Kim (2021), the current state-of-the-art model on
STL-10, to train STL-10 with 105k images by aggregating the labeled (5k) and the unlabeled (100k)
images (Jiang et al., 2021). Although the labeled images have 10 classes, the unlabeled images are
sampled from a broader distribution of images, so the unlabeled dataset contains the other types of
animals such as bears or rabbits, whose classes are different from the labeled classes. Therefore, a
well-trained model with 105k images would perform IS that exceeds the number of labeled classes.

4.2 ABLATION STUDY


Throughout the ablation study, we train the model on CelebA as default otherwise stated.


Table 4: Ablation study for the
new parametrization.

CelebA
Model _σmin_ NLL FID

NCSN++ (VE) 10[−][2] 2.39 3.95
NCSN++ (VE) 10[−][3] 1.96 3.59
HNCSN++ (VE) 10[−][3] 1.97 3.54
HNCSN++ (RVE) 10[−][3] 1.97 3.36

DDPM++ (VP, IS) 10[−][3] 1.53 5.31
HDDPM++ (VP, IS) 10[−][3] 1.64 4.65


**High Precision Parametrization Table 4 presents the model**
performances after 0.5M of training iterations. First, NCSN++
with lowered σmin effectively reduces the performances on both
NLL and FID, as anticipated in Section 2. Second, the new
parametrization of HNCSN gives a slight performance gain
compared to the original parametrization of NCSN. This performance gain comes from the better estimation for the data score,
evidenced by Figure 13 (a). Third, the new parametrization of
HDDPM largely improves the sample quality at the expense of
slight NLL degradation.


**Soft Truncation Figure 10 compares the diffusion model**
with/without ST-trick in terms of the sample fidelity by trainingiteration. To compare in a fair setting, we train the model in a pairof comparative settings: first, we train the model with vanilla diffu-sion loss of L(θ; λP, ϵ) with λP(t) = (1 − _[ϵ]t_ [)][g][2][(][t][)][; and second, we] FID-1k 24222018 _LL(STθ; (1(θ; g −[2]([ϵ]tt[)])[g],_ [2]τ[1][(][2][t][1][)][[][, ϵ][ϵ,T][)][]][(][τ] [))]

train according to the same loss with ST-trick of λ(t) = g[2](t) and

|Col1|Col2|Col3|Col4|(θ; (1|ϵ )g2(t), ϵ)|
|---|---|---|---|---|---|
|||||L(θ; (1 − ST(θ; g2|ϵt)g2(t), ϵ) (t), 121[ϵ,T](τ))|
|||||L|τ|
|||||||
|||||||

P(τ ) _τ1[2][ . At the initial stage of training, the sample fidelity with]_ 20000 40000Training iteration60000 80000 100000
_∝_

ST-trick is worse than that without ST-trick because the model with

Figure 10: ST-trick improves

ST-trick learns the data score of small diffusion slower. However,

the sample generation.

ST-trick effectively updates the score network as training proceeds,
and Figure 10 shows that the model with ST-trick surpasses the model without ST-trick after the
training.


-----

Table 5: Ablation study for ST-trick trained on
HNCSN++ (RVE).

Optimization CelebA
P(τ ) Loss ST NLL FID

_δϵ(τ_ ) _L(θ; g[2], ϵ)_  1.97 3.36
_δτϵ1[2]([ 1]τ_ [[])[ϵ,T][ ]][(][τ] [)] _L(LθST; (1 ( −θ; g[ϵ]t_ [2][)][g], P[2])[, ϵ][)]  1.981.93 3.181.92


Table 5 presents the performances after 0.5M of
training steps. It compares the diffusion models
with an identical weighting function, (1 − _[ϵ]t_ [)][g][2][,]

with/without ST-trick, and it shows that ST-trick
improves NLL from 1.98 to 1.93 and FID from 3.18
to 1.92, where 1.92 beats the current state-of-the-art
FID (2.92) by far.


Table 6: Ablation study for ST-trick.

CelebA
Model _λ_ ST
NLL FID

 2.39 3.95
NCSN++ (VE) _σ[2]_  2.41 2.68

 1.97 3.36
HNCSN++ (RVE) _g[2]_  1.93 1.92


Table 6 compares our ST-trick with the vanilla optimization
of the hard truncation on weighting functions of λ(t) =
_g[2](t) and λ(t) = σ[2](t). Table 6 shows that ST-trick is_
effective on both sample generation and density estimation.
In particular, for any model settings, we conclude that STtrick is a highly effective method that significantly enhances
the sample quality without any of model modification.


 1.79 3.03

**RVESDE Table 4 shows the efficacy of RVESDE on** DDPM++ (VP) _σ[2]_  1.75 2.88
HNCSN++. Applying RVESDE improves the FID score  1.78 3.23
while preserving the NLL performance, compared to HDDPM++ (VP) _σ[2]_  1.73 **2.22**
VESDE on HNCSN++. To analyze the performance, recall  1.53 5.31
that Proposition 2 implies that the inequality of NELBO in 1 DDPM++ (VP, IS) _g[2]_  **1.52** 4.50
does not hold anymore, so the NLL performance of VESDEloses its theoretic ground on bounding the log-likelihood. HDDPM++ (VP, IS) _g[2]_  1.641.52 4.654.45
However, our RVESDE allows the inequality of NELBO, so
the NLL performance in Table 4 is theoretically grounded. In addition, the experiments in Table 6
shows that RVESDE harmonizes with ST-trick better than VESDE.

Table 7: Ablation study

**Optimal Precisionharm the sample quality due to the training instability. We find that Table 7 finds that lowering σmin too small might** forHNCSN++ (RVE).σmin trained on
_σmin = 10[−][3]_ is a sweet spot for the optimal sample quality. This
tendency maintains even when we apply the training stabilization method,such as ST-trick. ST _σmin_ NLLCIFAR-10FID-10k

10[−][3] 2.96 7.04

The reasoning of such opposite trend could be partially explained by  10[−][4] 2.97 8.17
how the data is saved. When we save the data, it is 8-bit quantized in 10[−][5] 2.97 8.29
order to downsize the file size, so it is enough to downscalethan 1/256 to fit the model distribution to the data distribution, which is σmin less  101010[−][−][−][3][4][5] 2.992.972.96 5.095.545.98
approximately 0.004. Therefore, lowering σmin too small incurs severe
numerical instability without gaining additional performance enhancement.


Empirical result in Figure 11 indicates that σmin of 10[−][3] is indeed
enough to create high precision images on high-dimensional FFHQ
256 × 256 dataset. Figure 11 illustrates the histogram of the image-byimage quality metric, evaluated by Natural Image Quality Evaluator
(NIQE) (Mittal et al., 2012), with 5k samples. Figure 11 implies
that the denoised images up to the diffusion levels of 0.1 or 0.01 are
not satisfactory in terms of this image-by-image metric. In fact, this
discrepancy of the image-to-image quality metric explains the gain
in FID when we lower σmin in Table 4, where FID is a distributional
metric for sample quality.


Real
Generated (σ =0.1)
Generated (σ =0.01)
Generated (σ =0.001)

Natural Image Quality Evaluator (NIQE)


Figure 11: Optimal precision on FFHQ 256 × 256.


**High Dimensions To clarify the modeling effect on high dimensional** NCSN++
datasets, we train HNCSN++ (RVE) with ST-trick for σmin = 10[−][3] (σmin = 10[−][2])
on datasets of 256 × 256 resolutions. After the training of 3.3M
iterations, we draw 5k samples by stopping the reverse process at

|Col1|Real HNCSN++ (σmin = 10−3) NCSN++ (σmin = 10−2)|
|---|---|

_σ = 10[−][1]/10[−][2]/10[−][3]. When we denoise up to σ = 10[−][2], Table 8_ Natural Image Quality Evaluator (NIQE)
shows that our model largely improves the sample quality: HNCSN++

Figure 12: Image-by-image

outperforms by reporting 13.52 and 14.20 in FID-5k compared to the

quality histogram on

NCSN++ of 16.42 and 29.14 on FFHQ 256 256 and LSUN Church
_×_ CelebA-HQ 256 256.
256 256, respectively. Such a huge discrepancy on high-dimensional _×_
_×_
datasets is attributed to the poorly synthesized images from NCSN++, which is evidenced by the right


-----

1.75 _×10_

1.50

1.25

1.00

0.75

0.50

0.25

0.00




2000

1000

0

|Col1|Col2|Col3|Col4|H P|ard Trunc (τ) = δϵ(τ|ation )|
|---|---|---|---|---|---|---|
|||||S P|oft Trunca (τ) 11|tion (τ)|
||||||∝τ 2|[ϵ,T]|
||||||||
||||||||
||||||||



0.0000 0.0005 0.0010 0.0015 0.0020 0.0025 0.0030

|×109|9|Col3|Col4|Col5|Col6|Col7|
|---|---|---|---|---|---|---|
|||||||HNCSN+|
|||||||NCSN++|
||||||||
||||||||
||||||||
||||||||
||||||||


10[−][3] 10[−][2] 10[−][1] 10[0] 10[1] 10

Diffusion level σ (log)

(a) Estimated Score


Density

(b) Loss Density


Monte-Carlo Variance

-  VESDE: 121

-  RVESDE: 84


(c) Loss Variance


Figure 13: Qualitative experimental results for (a) score estimation, (b) Monte-Carlo loss density of
ST-trick, (c) Monte-Carlo loss variance without ST-trick.

Figure 14: Generated images from FFHQ (1st column) / FFHQ 256 (2,3th columns) / CelebAHQ
(4,5th columns) / LSUN Bedroom (6,7th columns) / LSUN Church (8,9th columns)


heavy tail in Figure 12. Also, as we denoise further from 10[−][2] to 10[−][3], the sample quality improves
from 13.52 to 10.35 on FFHQ 256 × 256 and 14.20 to 13.75 on LSUN Church 256 × 256.

Table 8: Ablation study for

4.3 QUALITATIVE RESULTS denoising effect on high
dimensional datasets.

This section presents the qualitative experimental results for the

FFHQ Church

proposed methods. Figure 13 (a) compares the score estimation Model _σ_ FID-5k FID-5k
for HNCSN++ and NCSN++ on CelebA. HNCSN++ succeeds in

10[−][1] 60.56 48.06

estimating the unbounded score, whereas NCSN++ shows poor (RVE) + STHNCSN++ 10[−][2] 13.52 14.20
estimation at the front diffusion time (or small diffusion level). 10[−][3] 10.35 13.75
Figure 13 (b) compares the diffusion model with/without ST-trick NCSN++ 10[−][2] 16.42 29.14
in terms of the Monte-Carlo loss density. As expected, the density
is bimodal for the model without ST-trick, but it turns out that this heavy tail is largely improved
by ST-trick. Figure 13 (c) illustrates that the Monte-Carlo loss variance is reduced with RVESDE,
compared to VESDE. We attribute this variance reduction to the exact modeling of the diffusion
process.

Figure 14 shows the generated images from various benchmark datasets. We find that our model
succeeds generating realistic images on high-dimensional datasets with resolution greater or equal to
256 × 256. See Appendix C for the full image generation results.

5 CONCLUSION


This paper tackles the problem of exploding data score with three points: 1) we provide a theorydriven parametrization for the high precision estimation; 2) we introduce a practical optimization
method of the diffusion model parameters; and 3) we suggest a new type of SDE that enables to apply
the stochastic calculus on small diffusion level. Applying the three improvements to NCSN/DDPM,
we presented the high precision version of NCSN and DDPM, which excels in generating the high
resolution images.


-----

6 ETHICS STATEMENT

Potential risk from this work is the negative usage of the deep generative models, such as deepfake images. Our contribution enables the creation of the high resolution virtual images, and we
acknowledge that there is any chance of misuse for malicious purposes.

7 REPRODUCIBILITY STATEMENT

Complete proofs of the theoretic analyses in the main paper are provided in Appendix A. The code
for the experiments would be released to the reviewers at the discussion phase through an anonymous
repository for the reproducibility. Most of our code is built based on the released code of the previous
work (Song et al., 2020) including the network structure and hyperparameters, as explained in
Appendix B.

REFERENCES

Anokhin, I., Demochkin, K., Khakhulin, T., Sterkin, G., Lempitsky, V., and Korzhenkov, D. (2020).
Image generators with conditionally-independent pixel synthesis. arXiv preprint arXiv:2011.13775.

Chen, R. T., Rubanova, Y., Bettencourt, J., and Duvenaud, D. (2018). Neural ordinary differential
equations. arXiv preprint arXiv:1806.07366.

Coates, A., Ng, A., and Lee, H. (2011). An analysis of single-layer networks in unsupervised feature
learning. In Proceedings of the fourteenth international conference on artificial intelligence and
_statistics, pages 215–223. JMLR Workshop and Conference Proceedings._

Dhariwal, P. and Nichol, A. (2021). Diffusion models beat gans on image synthesis. arXiv preprint
_arXiv:2105.05233._

Evans, L. C. (1998). Partial differential equations. Graduate studies in mathematics, 19(2).

Grci´c, M., Grubiši´c, I., and Šegvi´c, S. (2021). Densely connected normalizing flows. arXiv preprint
_arXiv:2106.04627._

Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S. (2017). Gans trained by a
two time-scale update rule converge to a local nash equilibrium. Advances in neural information
_processing systems, 30._

Ho, J., Chen, X., Srinivas, A., Duan, Y., and Abbeel, P. (2019). Flow++: Improving flow-based
generative models with variational dequantization and architecture design. In International
_Conference on Machine Learning, pages 2722–2730. PMLR._

Ho, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. arXiv preprint
_arXiv:2006.11239._

Ho, J., Saharia, C., Chan, W., Fleet, D. J., Norouzi, M., and Salimans, T. (2021). Cascaded diffusion
models for high fidelity image generation. arXiv preprint arXiv:2106.15282.

Hoogeboom, E., Cohen, T. S., and Tomczak, J. M. (2020). Learning discrete distributions by
dequantization. arXiv preprint arXiv:2001.11235.

Jiang, Y., Chang, S., and Wang, Z. (2021). Transgan: Two transformers can make one strong gan.
_arXiv preprint arXiv:2102.07074._

Jolicoeur-Martineau, A., Li, K., Piché-Taillefer, R., Kachman, T., and Mitliagkas, I. (2021). Gotta go
fast when generating data with score-based models. arXiv preprint arXiv:2105.14080.

Jolicoeur-Martineau, A., Piché-Taillefer, R., Combes, R. T. d., and Mitliagkas, I. (2020). Adversarial
score matching and improved sampling for image generation. arXiv preprint arXiv:2009.05475.

Karras, T., Aila, T., Laine, S., and Lehtinen, J. (2017). Progressive growing of gans for improved
quality, stability, and variation. arXiv preprint arXiv:1710.10196.


-----

Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., and Aila, T. (2020). Training generative
adversarial networks with limited data. arXiv preprint arXiv:2006.06676.

Karras, T., Laine, S., and Aila, T. (2019). A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
_Pattern Recognition, pages 4401–4410._

Kingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint
_arXiv:1412.6980._

Kingma, D. P., Salimans, T., Poole, B., and Ho, J. (2021). Variational diffusion models. arXiv
_preprint arXiv:2107.00630._

Krizhevsky, A., Hinton, G., et al. (2009). Learning multiple layers of features from tiny images.

Lin, C. H., Chang, C.-C., Chen, Y.-S., Juan, D.-C., Wei, W., and Chen, H.-T. (2019). Coco-gan:
Generation by parts via conditional coordinating. In Proceedings of the IEEE/CVF International
_Conference on Computer Vision, pages 4512–4521._

Lin, J., Zhang, R., Ganz, F., Han, S., and Zhu, J.-Y. (2021). Anycost gans for interactive image
synthesis and editing. arXiv preprint arXiv:2103.03243.

Liu, Z., Luo, P., Wang, X., and Tang, X. (2015). Deep learning face attributes in the wild. In
_Proceedings of the IEEE international conference on computer vision, pages 3730–3738._

Mittal, A., Soundararajan, R., and Bovik, A. C. (2012). Making a “completely blind” image quality
analyzer. IEEE Signal processing letters, 20(3):209–212.

Nachmani, E., Roman, R. S., and Wolf, L. (2021). Non gaussian denoising diffusion models. arXiv
_preprint arXiv:2106.07582._

Nichol, A. and Dhariwal, P. (2021). Improved denoising diffusion probabilistic models. arXiv
_preprint arXiv:2102.09672._

Oksendal, B. (2013). Stochastic differential equations: an introduction with applications. Springer
Science & Business Media.

Park, J. and Kim, Y. (2021). Styleformer: Transformer based generative adversarial networks with
style vector. arXiv preprint arXiv:2106.07023.

Parmar, G., Zhang, R., and Zhu, J.-Y. (2021). On buggy resizing libraries and surprising subtleties in
fid calculation. arXiv preprint arXiv:2104.11222.

Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, L., Shazeer, N., Ku, A., and Tran, D. (2018). Image
transformer. In International Conference on Machine Learning, pages 4055–4064. PMLR.

Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X. (2016). Improved
techniques for training gans. Advances in neural information processing systems, 29:2234–2242.

Schonfeld, E., Schiele, B., and Khoreva, A. (2020). A u-net based discriminator for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
_Pattern Recognition, pages 8207–8216._

Sinha, S. and Dieng, A. B. (2021). Consistency regularization for variational auto-encoders. arXiv
_preprint arXiv:2105.14859._

Skorokhodov, I., Ignatyev, S., and Elhoseiny, M. (2020). Adversarial generation of continuous images.
_arXiv preprint arXiv:2011.12026._

Song, Y., Durkan, C., Murray, I., and Ermon, S. (2021). Maximum likelihood training of score-based
diffusion models. arXiv e-prints, pages arXiv–2101.

Song, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution.
_arXiv preprint arXiv:1907.05600._


-----

Song, Y. and Ermon, S. (2020). Improved techniques for training score-based generative models.
_arXiv preprint arXiv:2006.09011._

Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2020). Score-based
generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: a
simple way to prevent neural networks from overfitting. The journal of machine learning research,
15(1):1929–1958.

Stein, E. M. and Shakarchi, R. (2009). Real analysis: measure theory, integration, and Hilbert spaces.
Princeton University Press.

Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. (2016). Rethinking the inception
architecture for computer vision. In Proceedings of the IEEE conference on computer vision and
_pattern recognition, pages 2818–2826._

Theis, L., Oord, A. v. d., and Bethge, M. (2015). A note on the evaluation of generative models.
_arXiv preprint arXiv:1511.01844._

Vahdat, A. and Kautz, J. (2020). Nvae: A deep hierarchical variational autoencoder. arXiv preprint
_arXiv:2007.03898._

Vahdat, A., Kreis, K., and Kautz, J. (2021). Score-based generative modeling in latent space. arXiv
_preprint arXiv:2106.05931._

Welling, M. and Teh, Y. W. (2011). Bayesian learning via stochastic gradient langevin dynamics. In
_Proceedings of the 28th international conference on machine learning (ICML-11), pages 681–688._
Citeseer.

Yang, C., Shen, Y., Xu, Y., and Zhou, B. (2021). Data-efficient instance generation from instance
discrimination. arXiv preprint arXiv:2106.04566.

Yu, F., Seff, A., Zhang, Y., Song, S., Funkhouser, T., and Xiao, J. (2015). Lsun: Construction
of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint
_arXiv:1506.03365._


-----

A PROOFS OF LEMMA 1, PROPOSITION 1, AND PROPOSITION 2

**Lemma 1. Let H[0,T ] = {s : R[d]** _× [0, T_ ] → R[d], s is locally Lipschitz}. Suppose a continuous
_vector field v defined on a subset U of a compact manifold M (i.e., v : U ⊂_ _M →_ R[d]) is unbounded,
_then there exists no s_ [0,T ] such that limt 0 s(x, t) = v(x) a.e. on U _._
_∈H_ _→_

_Proof. Since U is an open subset of a compact manifold M_, **x1** **x2** diam(M ) for all
**x1, x2** _U_ . Also, if t1, t2 [0, T ], _t1_ _t2_ is bounded. Hence, the local Lipschitzness of ∥ _−_ _∥≤_ **s implies**
that there exists a positive ∈ _∈ K > 0 such that |_ _−_ _|_ _s(x1, t1)_ _s(x2, t2)_ _K(_ **x1** **x2** + _t1_ _t2_ )
for any x1, x2 _U and t1, t2_ [0, T ]. Therefore, for any ∥ _− s_ [0,T∥≤ ], there exists∥ _− C >∥_ 0 | such that − _|_
_∈_ _∈_ _∈H_
_∥s(x, t)∥_ _< C for all x ∈_ _U and t ∈_ [0, T ], which leads no s that satisfies s(x, t) → _v(x) a.e. on U_
as t → 0.

**Proposition 2. Let** [1, ) = **s : R[d]** [1, ) R[d], s is locally Lipschitz _. Suppose a continuous_
_H_ _∞_ _{_ _×_ _∞_ _→_ _}_
_vector field v defined on a d-dimensional open subset U of a compact manifold M is unbounded,_
_and the projection of v on each axis is locally integrable. Then, there exists s_ [1, ) such that
_∈H_ _∞_
limη→∞ **s(x, η) = v(x) a.e. on U** _._

_Proof.to v a.e. on Let h U be a standard mollifier function. If as t →_ 0 (Theorem 7-(ii) of Appendix C in Evans (1998)). Therefore, if we define ht(x) = t[−][n]h(x/t), then vt := ht ∗ _v converges_
_s(x, η) := v1/η(x) on the domain of v1/η(x) and s(x, η) := 0 elsewhere, then s(x, η) = v1/η(x)_
_→_
_v(x) a.e. on U as η →∞._

Now, to show that s(x, η) is locally Lipschitz, let _M[˜] ×[η, η] be a compact subset of R[n]×[1, ∞). From_
**s(x1, η1)** **s(x2, η2)** = _v1/η1_ (x1) _v1/η2_ (x2) _v1/η1_ (x1) _v1/η1_ (x2) + _v1/η1_ (x2)
_∥_ _−_ _∥_ _∥_ _−_ _∥≤∥_ _−_ _∥_ _∥_ _−_
_v1/η2_ (x2), if there exists K1, K2 > 0 such that _v1/η1_ (x1) _v1/η1_ (x2) _K1_ **x1** **x2** and
_∥_ _∥_ _−_ _∥≤_ _∥_ _−_ _∥_
_v1/η1_ (x1) _v1/η2_ (x1) _K2_ _η1_ _η2_ for all x1, x2 _M and η1, η2_ [η, η], then s(x, η) =
_∥_ _−_ _∥≤_ _|_ _−_ _|_ _∈_ [˜] _∈_
_v1/η(x) is Lipschitz on_ _M[˜]_ [η, η].
_×_

First, since v1/η is infinitely differentiable on its domain (Theorem 7-(i) of Appendix C in Evans
(1998)) andSecond, the mollifier satisfies the uniform convergence on any compact subset of η ∈ [η, η], there exists K1 > 0 such that ∥v1/η(x1) − _v1/η(x2)∥≤ UK (Theorem 7-1∥x1 −_ **x2∥.**
(iii) of Appendix C in Evans (1998)), which leads that _v1/η1_ (x) _v1/η2_ (x) _K2_ _η[1]1_ _η12_
_∥_ _−_ _∥≤_ _|_

_η1_ _η2_ _[−]_ _[|][ =]_
_K2_ _|_ _η1−η2_ _|_ _≤_ _K3|η1 −_ _η2| for some K2, K3 > 0. Therefore, s becomes an element of H[1,∞)._

B IMPLEMENTATION DETAILS

Since the major contribution of this paper is developing the diffusion model in perspectives of theory
and optimization method, we use the same model architecture introduced in Song et al. (2020).

B.1 EXPERIMENTAL DETAILS

**Training Throughout the experiments, we train our model with a learning rate of 0.0002, warmup**
of 5000 iterations, gradient clipping by 1. On the experiments for HNCSN++ with σmin = 10[−][3],
we train the diffusion model by truncating σmin to 10[−][2] at the initial stage of training, and after the
saturation in terms of the FID score, we begin to train the score network with the whole range of

[σmin, σmax]. We find this way of training works best in practice for the training stability. We follow
the convention of Song et al. (2020) to choose σmax. Also, for DDPM-style model training, we use
_βmin = 0.1 and βmax = 20. For all experiments, we set ϵ = 10[−][5]_ and T = 1.

We stabilize the training by the Exponential Moving Average (EMA) (Song et al., 2020) with the rate
of 0.999 on NCSN++/HNCSN++ and 0.9999 on DDPM++/HDDPM++. In addition, we stabilize the
training by applying the dropout (Srivastava et al., 2014) with 0.1 rate. For the optimizer, we use the
Adam optimizer (Kingma and Ba, 2014) with (β1, β2) = (0.9, 0.999).

On datasets of resolution 32 × 32, we use the batch size of 128, which consumes about 48Gb GPU
memory. On STL-10 with resolution 48 × 48, we use the batch size of 192, and on datasets of
resolution 64 × 64, we experiment with 128 batch size. The batch size for the datasets of resolution


-----

256×256 is 40, which takes nearly 120Gb of GPU memory. On the dataset of 1024×1024 resolution,
we use the batch size of 16, which takes around 120Gb of GPU memory. We use five NVIDIA RTX3090 GPU machines to train the model exceeding 48Gb, and we use a pair of NVIDIA RTX-3090
GPU machines to train the model that consumes less than 48Gb.

**Evaluation We apply the EMA with rate of 0.999 on NCSN++/HNCSN++ and 0.9999 on**
DDPM++/HDDPM++. For the density estimation, we obtain the NLL performance by the Instantaneous Change of Variable (Song et al., 2020; Chen et al., 2018). For the sampling, we apply
the Predictor-Corrector (PC) algorithm introduced in Song et al. (2020). We set the signal-to-noise
ratio as 0.16 on 32 × 32 datasets, 0.17 on 48 × 48 and 64 × 64 datasets, 0.075 on 256×256 sized
datasets, and 0.15 on 1024 × 1024. On datasets less than 256 × 256 resolution, we iterate 1,000 steps
for the PC sampler, while we apply 2,000 steps on the other high-dimensional datasets. Throughout
the experiments, we use the reverse diffusion (Song et al., 2020) for the predictor algorithm and the
annealed Langevin dynamics (Welling and Teh, 2011) for the corrector algorithm.

We compute the FID score (Song et al., 2020) based on the modified Inception V1 network[3] using
the tensorflow-gan package for CIFAR-10 dataset, and we use the clean-FID (Parmar et al., 2021)
based on the Inception V3 network (Szegedy et al., 2016) for the remaining datasets. We note that
FID computed by Parmar et al. (2021) reports a higher FID score compared to the original FID
calculation[4].

B.2 CHOICE OF η(t)

**HNCSN As described in Section 3.1, HNCSN assumes the score parametrization of sθ(xt, η(t))**
with η(t) being the mixture of log σ(t) and _σ(1t)_ [. Despite of the clear advantage of][ log][ σ][(][t][)][ that the]

distribution of p(σ) is uniform in VE/RVESDEs, the drastic scale variation at t 0 prevents the
1 _≈_
enhanced score estimation. We empirically find that the reciprocal function of _σ(t)_ [works best on the]

estimation at the front diffusion time, and we combine these two functions to create a continuously
differentiable η(t) by

_η(t) :=_ log σ(t) if σ(t) ≥ _σ0_

_σ(t)_ [+][ c][2] if σ(t) < σ0,

 _−_ _[c][1]_

where c1, c2 and σ0 are the hyperparameters. By acknowledging the parametrization of log σ(t) introduced in Song et al. (2020), we choose σ0 as 0.01. Also, to satisfy the continuously differentiability
of η(t), the choice of two hyperparameters c1 and c2 satisfies a system of equations with degree 2, so
_c1 and c2 are fully determined with this system of equations._

_g2(t)_ _t_ _t_
**HDDPM Looking at the antiderivative** _σ[2](t)_ [d][t][ = log (1][ −] _[e][−]_ 0 _[β][(][s][) d][s]) +_ 0 _[β][(][s][) d][s][ =]_

_t_ R _t_
log σ[2](t)+ 0 _[β][(][s][) d][s][, the unbounded function reduces to]R_ _[ η][(][t][) = 2 log][ σ][(][t][)+]_ 0 _[β][(][s][) d]R_ _[s][. Therefore,]_
HDDPM resembles the temporal parametrization of log σ(t) (Song et al., 2020) at t 0 because the
R _t_ R _≈_
second term, 0 _[β][(][s][) d][s][, is nearly zero at][ t][ ≈]_ [0][.]
R

C ADDITIONAL EXPERIMENTAL RESULTS

Figure 15 shows how images are created from the trained model on 256-dimensional datasets, and
Figures from 16 to 21 present randomly generated samples of the trained model. Also, Tables 9
and 10 present the additional experimental results in terms of FID on LSUN Bedroom and FFHQ
256 × 256.

[3https://tfhub.dev/tensorflow/tfgan/eval/inception/1](https://tfhub.dev/tensorflow/tfgan/eval/inception/1)
[4See https://github.com/GaParmar/clean-fid for the detailed experimental results.](https://github.com/GaParmar/clean-fid)


-----

Figure 15: Image generation by denoising via predictor-corrector sampler.


Table 9: LSUN Bedroom

Bedroom
Model 256 × 256
FID

UDM (RVE) + ST 4.57


Table 10: FFHQ

FFHQ
Model 256 × 256
FID

UDM (RVE) + ST 5.54

**Likelihood-free Models**
InsGen Yang et al. (2021) **3.31**
Anycost GAN Lin et al. (2021) 3.35
StyleGAN2 ADA+bCR Karras et al. (2020) 3.62
CIPS Anokhin et al. (2020) 4.38
U-Net GAN Schonfeld et al. (2020) 7.48
BigGAN Schonfeld et al. (2020) 11.48


**Likelihood-based Models**
ADM Dhariwal and Nichol (2021) **1.90**
DDPM Ho et al. (2020) 4.90

**Likelihood-free Models**
StyleGAN Karras et al. (2019) 2.65
INR-GAN-bil Skorokhodov et al. (2020) 4.95
COCO-GAN Lin et al. (2019) 6.95


-----

Figure 16: Random samples on CIFAR10.


-----

Figure 17: Random samples on LSUN Bedroom.


-----

Figure 18: Random samples on LSUN Church.


-----

Figure 19: Random samples on FFHQ 256.


-----

Figure 20: Random samples on CelebA-HQ 256.


-----

Figure 21: Random samples on FFHQ 1024


-----


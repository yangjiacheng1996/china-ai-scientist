# COMPRESSED-VFL: COMMUNICATION-EFFICIENT LEARNING WITH VERTICALLY PARTITIONED DATA

**Anonymous authors**
Paper under double-blind review

ABSTRACT

We propose Compressed Vertical Federated Learning (C-VFL) for
communication-efficient training on vertically partitioned data. In C-VFL,
a server and multiple parties collaboratively train a model on their respective
features utilizing several local iterations and sharing compressed intermediate
results periodically. Our work provides the first theoretical analysis of the effect
message compression has on distributed training over vertically partitioned data.
We prove convergence of non-convex objectives to a fixed point at a rate of
_O(_ _√[1]T_ [)][ when the compression error is bounded over the course of training. We]

provide specific requirements for convergence with common compression techniques, such as quantization and top-k sparsification. Finally, we experimentally
show compression can reduce communication by over 90% without a significant
decrease in accuracy over VFL without compression.

1 INTRODUCTION

Federated Learning (McMahan et al., 2017) is a distributed machine learning approach that has
become of much interest in both theory (Li et al., 2020; Wang et al., 2019; Liu et al., 2020) and
practice (Bonawitz et al., 2019; Rieke et al., 2020; Lim et al., 2020) in recent years. Naive distributed
learning algorithms may require frequent exchanges of large amounts of data, which can lead to
slow training performance (Lin et al., 2020). Further, participants may be globally distributed, with
high latency network connections. To mitigate these factors, Federated Learning algorithms aim
to be communication-efficient by design. Methods such as local updates (Moritz et al., 2016; Liu
et al., 2019), where parties train local parameters for multiple iterations without communication, and
message compression (Stich et al., 2018; Wen et al., 2017; Karimireddy et al., 2019) reduce message
frequency and size, respectively, with little impact on training performance.

Federated Learning methods often target the case where the data among parties is distributed horizontally: each party’s data shares the same features but parties hold data corresponding to different
sample IDs. This is known as Horizontal Federated Learning (HFL) (Yang et al., 2019). However,
there are several application areas where data is partitioned in a vertical manner: the parties store
data on the same sample IDs but different feature spaces.

An example of a vertically partitioned setting includes a hospital, bank, and insurance company
seeking to train a model to predict something of mutual interest, such as customer credit score.
Each of these institutions may have data on the same individuals but store medical history, financial transactions, and vehicle accident reports, respectively. These features must remain local to the
institutions due to privacy concerns, rules and regulations (e.g., GDPR, HIPAA), and/or communication network limitations. In such a scenario, Vertical Federated Learning (VFL) methods must be
employed. Although VFL is less well-studied than HFL, there has been a growing interest in VFL
algorithms recently (Hu et al., 2019; Gu et al., 2021; Cha et al., 2021), and VFL algorithms have
important applications including risk prediction, smart manufacturing, and discovery of pharmaceuticals (Kairouz et al., 2021).

Typically in VFL, each party trains a local embedding function that maps raw data features to a
meaningful vector representation, or embedding, for prediction tasks. For example, a neural network
can be an embedding function for mapping the text of an online article to a vector space for classification (Koehrsen, 2018). Referring to Figure 1a, suppose Party 1 is a hospital with medical data


-----

(a) Example of a global model. (b) Local view of a global model.

Figure 1: Example global model with neural networks and its local view. a) To obtain a ˆy prediction
for a data sample x, each party m feeds the local features of x, xm, into a neural network. The output
of this neural network is the embedding hm(θm; xm). All embeddings are then fed into the server
model neural network with parameters θ0. b) When running C-VFL, Party 1 (in green) only has a
compressed snapshot of the other parties embeddings and the server model. To calculate ˆy, Party 1
uses its own embedding calculated at iteration t, and the embeddings and server model calculated at
time t0, the latest communication iteration, and compressed with _m._
_C_

features x1. The hospital computes its embedding h1(θ1; x1) for the features by feeding x1 through
a neural network. The other parties (the bank and insurance company), compute embeddings for
their features, then all parties share the embeddings in a private manner (e.g., homomorphic encryption, secure multi-party computation, or secure aggregation). The embeddings are then combined in
a server model θ0 to determine the final loss of the global model. A server model (or fusion network)
captures the complicated interactions of embeddings and is often a complex, non-linear model (Gu
et al., 2019; Nie et al., 2021; Han et al., 2021). Embeddings can be very large, in practice, sometimes
requiring terabytes of communication over the course of training.

Motivated by this, we propose Compressed Vertical Federated Learning (C-VFL), a general framework for communication-efficient Federated Learning over vertically partitioned data. In our algorithm, parties communicate compressed embeddings periodically, and the parties and the server each
run block-coordinate descent for multiple local iterations, in parallel, using stochastic gradients to
update their local parameters.

C-VFL is the first theoretically verified VFL algorithm that applies embedding compression. Unlike
in HFL algorithms, C-VFL compresses embeddings rather than gradients. Previous work has proven
convergence for HFL algorithms with gradient compression (Stich et al., 2018; Wen et al., 2017;
Karimireddy et al., 2019). However, no previous work analyzes the convergence requirements for
VFL algorithms that use embedding compression. Embeddings are parameters in the partial derivatives calculated at each party. The effect of compression error on the resulting partial derivatives may
be complex; therefore, the analysis in previous work on gradient compression in HFL does not apply
to compression in VFL. In our work, we prove that, under a diminishing compression error, C-VFL
converges at a rate of O( _√[1]T_ [)][, which is comparable to previous VFL algorithms that do not employ]

compression. We also analyze common compressors, such as quantization and sparsification, in
C-VFL and provide bounds on their compression parameters to ensure convergence.

C-VFL also generalizes previous work by supporting an arbitrary server model. Previous work in
VFL has either only analyzed an arbitrary server model without local updates (Chen et al., 2020),
or analyzed local updates with a linear server model (Liu et al., 2019; Zhang et al., 2020; Das &
Patterson, 2021). C-VFL is designed with an arbitrary server model, allowing support for more
complex prediction tasks than those supported by previous VFL algorithms.

We summarize our main contributions in this work.

1. We introduce C-VFL with an arbitrary compression scheme. Our algorithm generalizes previous
work in VFL by including both an arbitrary server model and multiple local iterations.

2. We prove convergence of C-VFL to a fixed point on non-convex objectives at a rate of O( _√[1]T_ [)][ for]

a fixed step size when the compression error is bounded over the course of training. We also prove
that the algorithm convergence error goes to zero for a diminishing step size if the compression error
diminishes as well. Our work provides novel analysis for the effect of compressing embeddings on


-----

convergence in a VFL algorithm. Our analysis also applies to Split Learning when uploads to the
server are compressed.

3. We provide convergence bounds on parameters in common compressors that can be used in CVFL. In particular, we examine scalar quantization (Bennett, 1948), lattice vector quantization (Zamir & Feder, 1996), and top-k sparsification (Lin et al., 2018).

4. We evaluate our algorithm by training LSTMs on the MIMIC-III dataset and CNNs on the ModelNet10 dataset. We empirically show how C-VFL can reduce the number of bits sent by over 90%
compared to VFL with no compression without a significant loss in accuracy of the final model.

**Related Work.** Richt´arik & Tak´ac (2016); Hardy et al. (2017) were the first works to propose
Federated Learning algorithms for vertically partitioned data. Chen et al. (2020); Romanini et al.
(2021) propose the inclusion of an arbitrary server model in a VFL algorithm. However, these works
do not consider multiple local iterations, and thus communicate at every iteration. Liu et al. (2019),
Feng & Yu (2020), and Das & Patterson (2021) all propose different VFL algorithms with local
iterations for vertically partitioned data but do not consider an arbitrary server model. In contrast to
previous works, our work addresses a vertical scenario, an arbitrary server model, local iterations,
and message compression.

Message compression is a common topic in HFL scenarios, where participants exchange gradients determined by their local datasets. Methods of gradient compression in HFL include scalar
quantization (Bernstein et al., 2018), vector quantization (Shlezinger et al., 2021), and top-k sparsification (Shi et al., 2019). In C-VFL, compressed embeddings are shared, rather than compressed
gradients. Analysis in previous work on gradient compression in HFL does not apply to compression in VFL, as the effect of embedding compression error on each party’s partial derivatives may
be complex. No prior work has analyzed the impact of compression on convergence in VFL.

**Outline.** In Section 2, we provide the problem formulation and our assumptions. Section 3
presents the details of C-VFL. In Section 4, we present our main theoretical results. Our experimental results are given in Section 5. Finally, we conclude in Section 6.

2 PROBLEM FORMULATION

We present our problem formulation and notation to be used in the rest of the paper. We let ∥a∥ be
the 2-norm of a vector a, and let ∥A∥F be the Frobenius norm of a matrix A.

We consider a set of M parties {1, . . ., M _} and a server. The dataset X ∈_ R[N] _[×][D]_ is vertically
partitioned a priori across the M parties, where N is the number of data samples and D is the
number of features. The i-th row of X corresponds to a data sample x[i]. For each sample x[i], a party
_m holds a disjoint subset of the features, denoted x[i]m[, so that][ x][i][ = [][x][i]1[, . . ., x][i]M_ []][. For each][ x][i][, there]
is a corresponding labelbe the local dataset of a party y[i]. Let m y ∈, where theR[N] _[×][1]_ be the vector of all sample labels. We let i-th row correspond to data features x X[i]mm[. We assume] ∈ R[N] _[×][D][m]_
that the server and all parties have a copy of the labels y. For scenarios where the labels are private
and only present at a single party, the label holder can provide enough information for the parties to
compute gradients for some classes of model architectures (Liu et al., 2019).

Each party m holds a set of model parameters θm as well as a local embedding function hm(·). The
server holds a set of parameters θ0 called the server model and a loss function l(·) that combines the
_embeddings hm(θm; x[i]m[)][ from all parties. Our objective is as follows:]_


minimize _F_ (Θ; X; y) := [1]


_l(θ0, h1(θ1; x[i]1[)][, . . ., h][M]_ [(][θ][M] [;][ x][i]M [);][ y][i][)] (1)
_i=1_

X


where Θ = [θ0[T] _[, . . ., θ]M[T]_ []][T][ is the][ global model][. An example of a global model][ Θ][ is in Figure 1a.]

For simplicity, we let m = 0 refer to the server, and define h0(θ0; x[i]) := _θ0 for_
all x[i], where h0(·) is equivalent to the identity function. Let hm(θm; x[i]m[)] _∈_ R[P][m] for
_m1_ =N 0, . . ., M, where Pm is the size of the m-th embedding. Let ∇mF (Θ; X; y) :=

_N_ _i=1_ 1[)][, . . ., h][M] [(][θ][M] [;][ x][i]M [);][ y][i][)][ be the partial derivatives for parameters][ θ][m][.]

_[∇][θ][m]_ _[l][(][θ][0][, h][1][(][θ][1][;][ x][i]_
P


-----

Let X[B] and y[B] be the set of samples and labels corresponding to a randomly sampled mini-batch
**B of size B. We let the stochastic partial derivatives for parameters θm be** _mFB(Θ; X; y) :=_
1 _∇_

_B_ _x[i],y[i]∈X[B],y[B][ ∇][θ]m[l][(][θ][0][, h][1][(][θ][1][;][ x][i]1[)][, . . ., h][M]_ [(][θ][M] [;][ x][i]M [);][ y][)][. We may drop][ X][ and][ y][ from][ F] [(][·][)][ and]

_FBP(·). With a minor abuse of notation, we let hm(θm; X[B]m[) :=][ {][h][m][(][θ][m][;][ x][B]m[1]_ [)][, . . ., h][m][(][θ][m][;][ x]m[B][B] [)][}]
be the set of all party m embeddings associated with mini-batch B, where B[i] is the i-th sample in
the mini-batch B. We let ∇mFB(Θ) and ∇mFB(θ0, h1(θ1; X[B]1 [)][, . . ., h][M] [(][θ][M] [;][ X][B]M [))][ be equivalent,]
and use them interchangeably.

**Assumption 1. Smoothness:** _There exists positive constants L < ∞_ _and Lm < ∞, for_
_m = 0, . . ., M_ _, such that for all Θ1, Θ2, the objective function satisfies_ _F_ (Θ1) _F_ (Θ2)
_∥∇_ _−∇_ _∥≤_
_L ∥Θ1 −_ Θ2∥ _and ∥∇mFB(Θ1) −∇mFB(Θ2)∥≤_ _Lm ∥Θ1 −_ Θ2∥.

**Assumption 2. Unbiased gradients: For m = 0, . . ., M** _, for a randomly selected mini-batch B, the_
_stochastic partial derivatives are unbiased, i.e., EB∇mFB(Θ) = ∇mF_ (Θ).

**Assumption 3. Bounded variance: For m = 0, . . ., M** _, there exists constants σm < ∞_ _such that_
_the variance of the stochastic partial derivatives are bounded as:σm[2]_ EB∥∇mF (Θ) −∇mFB(Θ)∥[2] _≤_

_B_ _[for a randomly selected mini-batch][ B][ of size][ B][.]_

Assumption 1 bounds how fast the gradient and stochastic partial derivatives can change. Assumptions 2 and 3 require that the stochastic partial derivatives are unbiased estimators of the true partial
derivatives with bounded variance. Assumptions 1–3 are common assumptions in convergence analysis of gradient-based algorithms (Tsitsiklis et al., 1986; Nguyen et al., 2018; Bottou et al., 2018).
We note Assumptions 2–3 are similar to the IID assumptions in HFL convergence analysis. However, in VFL settings, all parties store identical sample IDs but different subsets of features. Hence,
there is no equivalent notion of a non-IID distribution in VFL.

**Assumption 4. Bounded Hessian:** _There exists positive constants Hm for m = 0, . . ., M_
_such that for all Θ, the second partial derivatives of FB with respect to hm(θm; X[B]m[)][ satisfy:]_
_∥∇h[2]_ _m(θm;X[B]m[)][F][B][(Θ)][∥][F][ ≤]_ _[H][m][ for any mini-batch][ B][.]_

**Assumption 5. Bounded Embedding Gradients:** _There exists positive constants Gm for_
_m = 0, . . ., M such that for all θm, the stochastic embedding gradients are bounded by:_
_θm_ _hm(θm; X[B]m[)][∥][F]_ _[for any mini-batch][ B][.]_
_∥∇_ _[≤]_ _[G][m]_

Since we are assuming a Lipschitz-continuous loss function (Assumption 1), we know the Hessian
of F is bounded. Assumption 4 strengthens this assumption slightly to also bound the Hessian
over any mini-batch. Assumption 5 bounds the magnitude of the partial derivatives with respect to
embeddings. This embedding gradient bound is necessary to ensure convergence in the presence of
embedding compression error (see appendix for details).

3 ALGORITHM

We now present C-VFL, a communication-efficient method for training a global model with vertically partitioned data. In each global round, a mini-batch B is chosen randomly from all samples and
parties share necessary information for local training on this mini-batch. Each party, in parallel, runs
block-coordinate stochastic gradient descent on its local model parameters θm for Q local iterations.
C-VFL runs for a total of R global rounds, and thus runs for T = RQ total local iterations.

For party m to compute the stochastic gradient with respect to its features, it must receive embeddings from all parties. We reduce communication cost by only sharing embeddings every global
round. Further, each party compresses their embeddings before sharing. We define a set of general
compressors for compressing party embeddings and the server model: Cm(·) : R[P][m] _→_ R[P][m] for
_m = 0, . . ., M_ . To calculate the gradient for data sample x[i], party m receives Cj(hj(θj; x[i]j[))][ from]
all parties j ̸= m. With this information, a party m can compute ∇mFB and update its parameters
_θm for multiple local iterations. Note that each party uses a stale view of the global model to com-_
pute its gradient during these local iterations, as it is reusing the embeddings it receives at the start of
the round. In Section 4, we show that C-VFL converges even though parties use stale information.
An example view a party has of the global model during training is in Figure 1b. Here, t is the
current iteration and t0 is the start of the most recent global round, when embeddings were shared.


-----

**Algorithm 1 Compressed Vertical Federated Learning**

1: Initialize: θm[0] [for all parties][ m][ and server model][ θ]0[0]

2: for t ← 0, . . ., T − 1 do
3: **if t mod Q = 0 then**

4: Randomly sample B[t] _∈{X, y}_

5: **for m ←** 1, . . ., M in parallel do

6: Send _m(hm(θm[t]_ [;][ X]m[B][t] [))][ to server]
_C_

7: **end for**

8: Server sends {C0(θ0), C1(h1(θ1[t] [;][ X]1[B][t] [))][, . . .,][ C][M] [(][h][M] [(][θ]M[t] [;][ X]M[B][t] [))][}][ to all parties]

9: **end if**

10: **for m ←** 0, . . ., M in parallel do

11: Φˆ _[t]m_ _[←{C][0][(][θ]0[t][0]_ [)][,][ C][1][(][h][1][(][θ]1[t][0] [;][ X]1[B][t][0] )), . . ., hm(θm[t] [;][ X][B]m[t][0] [)][, . . .,][ C][M] [(][h][M] [(][θ]M[t][0] [;][ X]M[B][t][0] [))][}]

12: _θm[t][+1]_ _θm[t]_ Φ[t]m[;][ y][B][t][0][ )]

13: **end for** _←_ _[−]_ _[η][t][0]_ _[∇][m][F][B][(ˆ]_

14: end for


Algorithm 1 details the procedure of C-VFL. In each global round, when t mod Q = 0, a minibatch B is randomly sampled from X and the parties exchange the associated embeddings, compressed using _m(_ ), via the server (lines 3-9). Each party m completes Q local iterations, using the
_C_ _·_
compressed embeddings it received in iteration t0 and its own m-th uncompressed embedding set
_hm(θm[t]_ _[,][ X]m[B][t][0]_ [)][. We denote the set of embeddings that party][ m][ uses as:]

Φˆ _[t]m_ [:=][ {C][0][(][θ]0[t][0] [)][,][ C][1][(][h][1][(][θ]1[t][0] [;][ X]1[B][t][0] )), . . ., hm(θm[t] [;][ X]m[B][t][0] [)][, . . .,][ C][M] [(][h][M] [(][θ]M[t][0] [;][ X]M[B][t][0] [))][}][.] (2)

For each local iteration, each party m updates θm by computing the stochastic partial derivatives
_mFB(Φ[ˆ]_ _[t]m[;][ y][B][t][0][ )][ and applying a gradient step with step size][ η][t][0][ (lines 13-16).]_
_∇_

A key difference here from previous VFL algorithms is that C-VFL shares the server model with
all parties in order to support multiple local gradient updates with a non-linear server model. Also
note that the same mini-batch is used for all Q local iterations, thus communication is only required
every Q iterations. Therefore, without any compression, the total communication cost is O(R · M ·
(B · _Pm +_ _|θ0|)) for R global rounds. Our compression technique replaces Pm and |θ0| with smaller_
values based on the compression factor. For cases where embeddings, the batch size, and the server
model are large, this reduction can greatly decrease the communication cost.

**Privacy.** We now discuss privacy-preserving mechanisms for C-VFL. In HFL settings, model update or gradient information is shared in messages. It has been shown that gradients can leak information about the raw data (Phong et al., 2018; Geiping et al., 2020). However in C-VFL, parties only
share embeddings and can only calculate the partial derivatives associated with the server model and
their local models. Commonly proposed HFL gradient attacks cannot be performed on C-VFL. Embeddings may be vulnerable to model inversion attacks (Mahendran & Vedaldi, 2015), which are
methods by which an attacker can recover raw input to a model using the embedding output and
black-box access to the model. One can protect against such an attack using homomorphic encryption (Cheng et al., 2019; Hardy et al., 2017) or secure multi-party computation (Gu et al., 2021).
An efficient implementation of encryption for embeddings in VFL has been provided in the FATE
open-source project (FederatedAI, 2021). Alternatively, if the input to the server model is the sum
of party embeddings, then secure aggregation methods (Bonawitz et al., 2016) can be applied.

Note that C-VFL assumes all parties have access to the labels. For low-risk scenarios, such as
predicting credit score, labels may not need to be private among the parties. In cases where labels
are private, one can augment C-VFL to apply the method in Liu et al. (2019) for gradient calculation
without the need for sharing labels. Our analysis in Section 4 would still hold in this case, and the
additional communication is reduced by the use of message compression.

4 ANALYSIS

In this section, we discuss our analytical approach and present our theoretical results. We first define
the compression error associated with _m(_ ):
_C_ _·_


-----

**Definition 1. Compression Error: Let vectors ϵ[x]m[i]** _[for][ m][ = 0][, . . ., M]_ _[, be the compression errors of]_
_m(_ ) on a data sample x[i]: ϵ[x]m[i] [:=][ C][m][(][h][m][(][θ][m][;][ x][i][))][ −] _[h][m][(][θ][m][;][ x][i][)][.][ Let][ ϵ]m[t][0]_ _[be the][ P][m]_
_C_ _·_ _[×][ B][ matrix]_
_with ϵ[x]m[i]_ _[for all data samples][ x][i][ in mini-batch][ B][t][0][ as the columns. We denote the expected squared]_
_message compression error from party m at round t0 as Em[t][0]_ [:=][ E][ ∥][ϵ]m[t][0] _[∥][2]F_ _[.]_

Let **G[ˆ]** _t = [(∇0FB(ˆΦ[t]0[;][ y][B][t][0][ ))][T][, . . .,][ (][∇][M]_ _[F][B][(ˆ]Φ[t]M_ [;][ y][B][t][0][ ))][T][ ]][T][ . The model][ Θ][ evolves as:]

_t_
Θ[t][+1] = Θ[t] _−_ _η[t][0][ ˆ]G_ _._ (3)

We note the reuse of the mini-batch of B[t][0] for Q iterations in this recursion. This indicates that the
stochastic gradients are not unbiased during local iterations t0 +1 _t_ _t0_ +Q 1. However, using
_≤_ _≤_ _−_
conditional expectation, we can apply Assumption 2 to the gradient calculated at iteration t0 when
there is no compression error. We define Φ[t]m [to be the set of embeddings that would be received by]
party m if no compression error were applied:

Φ[t]m [=][ {][θ]0[t][0] _[, h][1][(][θ]1[t][0]_ [;][ X]1[B][t][0] ), . . ., hm(θm[t] [;][ X]m[B][t][0] [)][, . . ., h][M] [(][θ]M[t][0] [;][ X]M[B][t][0] [)][}][.] (4)

Then, if we take expectation over B[t][0] conditioned on previous global models Θ[t] up to t0:

EBt0 [∇mFB(Φ[t]m[0] [)][ | {][Θ][τ] _[}][t]τ[0]=0[] =][ ∇][m][F]_ [(Φ]m[t][0] [)][.] (5)

With the help of (5), we can prove convergence by bounding the difference between the gradient at
the start of each global round and those calculated during local iterations (see the proof of Lemma 2
in the appendix for details).

To account for compression error, using the chain rule and Taylor series expansion, we obtain:
**Lemma 1. Under Assumptions 4-5, the norm of the difference between the objective function value**
_with compressed and uncompressed embeddings is bounded as:_

E∥∇mFB(Φ[ˆ] _[t]m[)][ −∇][m][F][B][(Φ]m[t]_ [)][∥][2][ ≤] _[H]m[2]_ _[G]m[2]_ _Mj=0,j≠_ _m[E]j[t][0]_ _[.]_ (6)
P

The proof of Lemma 1 is given in the appendix. Using Lemma 1, we can bound the effect of
compression error on convergence.

We present our main theoretical results. All proofs are provided in the appendix.
**Theorem 1. Convergence with fixed step size: Under Assumptions 1-5, if η[t][0]** = η for all iterations
_and satisfies η[t][0]_ 16Q max _L,1maxm Lm_
_≤_ _{_ _}_ _[, then the average squared gradient over][ R][ global rounds]_

_of Algorithm 1 is bounded by:_


_R−1_ _F_ (Θ[0]) E _F_ (Θ[T] ) _M_ _σm[2]_

E _F_ (Θ[t][0] ) _−_ + 4ηQL
_∇_ _≤_ [2] _ηT_ _B_
_t0=0_    _m=0_

X h X

[2][i] _M_

+ [68]R[Q][2] _Hm[2]_ _[G][2]m_

_m=0_

X


_R−1_

_t0=0_

X


_Ej[t][0]_ _[.]_ (7)
_j=0X,j≠_ _m_


The first term in (7) is based on the difference between the initial model and final model of the
algorithm. The second term is the error associated with the variance of the stochastic gradients and
the Lipschitz constants L and Lm’s. The third term relates to the average compression error over
all iterations. The larger the error introduced by a compressor, the larger the convergence error is.
We note that setting _j_ = 0 for all parties and iterations provides an error bound on VFL without
_E_ _[t][0]_
compression and is an improvement over the bound in Liu et al. (2019) in terms of Q, M, and B.
The second and third terms include a coefficient relating to local iterations. As the number of local
iterations Q increases, the convergence error increases. However, increasing Q also has the effect of
reducing the number of communication rounds. Thus, it may be beneficial to have Q > 1 in practice.
We explore this more in experiments in Section 5. The second and third terms scale with M, the
number of parties. However, VFL scenarios typically have a small number of parties (Kairouz et al.,
2021), and thus M plays a small role in convergence error. We note that when M = 1 and Q = 1,
Theorem 1 applies to Split Learning (Gupta & Raskar, 2018) when only uploads to the server are
compressed.


-----

Table 1: Choice of common compressor parameters to achieve a convergence rate of O(1/√T ). Pm

is the size of the m-th embedding. In scalar quantization, we let there be 2[q] quantization levels, and
let hmax and hmin be respectively the maximum and minimum components in hm(θm[t] [;][ x][i]m[)][ for all]
iterations t, parties m, and x[i]m[. We let][ V][ be the size of the lattice cell in vector quantization. We let]
_k be the number of parameters sent in an embedding after top-k sparsification, and (∥h∥[2])max be_
the maximum value of ∥hm(θm[t] [;][ x][i]m[)][∥][2][ for all iterations][ t][, parties][ m][, and][ x][i]m[.]


**Uniform Scalar Quantizer** **Lattice Quantization** **Top-k Sparsification**

**Parameter choice** _q = Ω_ log2 _BPm(hmax −_ _hmin)[2][√]T_ _V = O_ _BPm1_ _√T_ _k = Ω_ _Pm −_ _B(∥h∥P[2])mmax√T_

**Compression error** _Em[t][0]_ _[≤][BP]m_ (hmax−12hmin)[2] 2[−][2][q] = O( _√1T[)]_ _Em[t][0]_ _[≤]_ _[V BP]24[m]_ = O( _√1T_ [)] _Em[t][0]_ _[≤]_ _[B][(1][ −]_ _Pkm_ [)(][∥][h][∥][2][)][max][ =][ O][(]


_T_ [)]


**Remark 1.independent of Let T E, then =** _RR1[1]_ PRtRt00−−=0=011[E]P∥∇Mm=0F[E](Θm[t][0][t][. If][0] )∥[ η][2][][t]=[0][ =] O(√√1[1]TT [+][for all global rounds][E][)][. This indicates that if][ t][0][, for][ E][ =][ Q][ O][ and][(][ 1]√[ B]T [)]

then we can achieve a convergence rate ofP  _O(_ _√[1]T_ [)][. Informally, this means that C-VFL can afford]

compression error and not worsen asymptotic convergence when this condition is satisfied. We
discuss how this affects commonly used compressors in practice later in the section.

We consider a diminishing step size in the following theorem.
**Theorem 2. Convergence with diminishing step size: Under Assumptions 1-5, if 0 < η[t][0]** _< 1_
_satisfies η[t][0]_ 16Q max _L,1maxm Lm_
_≤_ _{_ _}_ _[, then the minimum squared gradient over][ R][ global rounds of]_

_Algorithm 1 is bounded by:_

1 _Rt0−=01_ [(][η][t][0] [)][2] _Rt0−=01_ _Mm=0_ _[η][t][0]_ _[E]m[t][0]_

_t0=0min,...,R−1_ [E] _∇F_ (Θ[t][0] ) = O _tR0−=01_ _[η][t][0][ +]_ P _tT=0 −1_ _[η][t][0]_ + P PtR0−=01 _[η][t][0]_ ! _._
h _M_

_If η[t][0]_ _and Em[t][0]_ _[satisfy][ P]t[∞]0=0_ _[η][2][t][0][i][ =][ ∞][,][ P]Pt[∞]0=0[(][η][t][0]_ [)][2][ <]P[ ∞][, and][ P][∞]t0=0 _mP=0_ _[η][t][0]_ _[E]m[t][0]_ _[<][ ∞][, then]_

mint0=0,...,R−1 E _∥∇F_ (Θ[t][0] )∥[2][i] _→_ 0 as R →∞. P
h

According to Theorem 2, the product of the step size and the compression error must be summable
over all iterations. In the next subsection, we discuss how to choose common compressor parameters
to ensure this property is satisified. We also see in Section 5 that good results can be achieved
empirically without diminishing the step size or compression error.

**Common Compressors.** In this section, we show how to choose common compressor parameters
to achieve a convergence rate of O( _√[1]T_ [)][ in the context of Theorem 1, and guarantee convergence in]

the context of Theorem 2. We analyze three common compressors: a uniform scalar quantizer (Bennett, 1948), a 2-dimensional hexagonal lattice quantizer (Zamir & Feder, 1996), and top-k sparsification (Lin et al., 2018). For uniform scalar quantizer, we let there be 2[q] quantization levels. For the
lattice vector quantizer, we let V be the volume of each lattice cell. For top-k sparsification, we let
_k be the number of embedding components sent in a message. In Table 1, we present the choice of_
compressor parameters in order to achieve a convergence rate of O( _√[1]T_ [)][ in the context of Theorem 1.]

We show how we calculate these bounds in the appendix and provide some implementation details
for their use. We can also use Table 1 to choose compressor parameters to ensure convergence in
the context of Theorem 2. Let η[t][0] = O( _t[1]0_ [)][, where][ t][0][ is the current round. Then setting][ T][ =][ t][0]

in Table 1 provides a choice of compression parameters at each iteration to ensure the compression
error diminishes at a rate of O( _√1t0 ), guaranteeing convergence. Diminishing compression error can_
be achieved by increasing the number of quantization levels, decreasing the volume of each lattice
cell, or increasing the number of components sent in messages.

5 EXPERIMENTS

We present experiments to examine the performance of C-VFL in practice. The goal of our experiments is to examine the effects different compression techniques have on training, and investigate
the accuracy/communication trade-off empirically.

Unless otherwise specified, our experimental setup consists of four parties and a server. Most realworld VFL settings include collaboration between a few institutions (Kairouz et al., 2021), so we


-----

(a) MIMIC by epochs (b) MIMIC by cost (c) ModelNet by epochs (d) ModelNet by cost

Figure 2: C-VFL when compressing to 2 bits per component. We show test F1-Score on MIMIC-III
dataset and test accuracy on ModelNet10 dataset, plotted by epochs and communication cost (MB).

expect the number of parties to be small. We train our system with two datasets: the MIMICIII dataset (Johnson et al., 2016) and the ModelNet10 dataset (Wu et al., 2015). MIMIC-III is an
anonymized hospital patient time series dataset, while ModelNet10 are CAD photos of objects,
each with 12 different views. For MIMIC-III, the task is binary classification to predict in-hospital
mortality. Each party trains on 19 of the 76 features with an LSTM and the server model consists
of two fully-connected layers. For ModelNet10, the task is classification of images into 10 object
classes. Each party trains on three views with three convolutional layers and the server model
consists of a fully-connected layer. We use a fixed step size of 0.01 for the MIMIC-III dataset and
0.001 for the ModelNet10 dataset. For MIMIC-III, we use a batch size of 1000, and for ModelNet10,
we use a batch size of 16. We train on the MIMIC-III dataset for 1000 epochs and the ModelNet10
dataset for 50 epochs, where an epoch consists of all iterations to fully iterate over the dataset. More
details on the datasets and training procedure can be found in the appendix.

We consider the three compressors discussed in Section 4: a uniform scalar quantizer, a 2dimensional hexagonal lattice quantizer, and top-k sparsification. For both quantizers, the embedding values need to be bounded. In the case of MIMIC-III’s LSTM, the embedding values are the
output of a tanh activation function and have a bounded range of [−1, 1]. For ModelNet10, the
embeddings are the output of a ReLU activation function, and may be unbounded. We scale embedding values for ModelNet10 to the range [0, 1]. We apply subtractive dithering to both the scalar
quantizer (Wannamaker, 1997) and vector quantizer (Shlezinger et al., 2021).

In our experiments, each embedding component is a 32-bit float. Let b be the bits per component
we compress to. For the scalar quantizer, this means there are 2[b] quantization levels. For the 2-D
vector quantizer, this means there are 2[2][b] vectors in the codebook. The volume V of the vector
quantizer is a function of the number of codebook vectors. For top-k sparsification, k = Pm 32[b] [as]

we are using 32-bit components. We train using C-VFL and consider cases where b = 2, 3, and
4. We compare with a case where b = 32. This corresponds to a standard VFL algorithm without
embedding compression, acting as a baseline for accuracy.

In Figure 2, we plot the test F1-Score and test accuracy for MIMIC-III and ModelNet10, respectively, when training with b = 2. We use F1-Score for MIMIC-III as the in-hospital mortality
prediction task is highly skewed; most people in the dataset did not die in the hospital. The solid
line in each plot represents the average loss over five runs, while the shaded regions represent the
standard deviation. In Figures 2a and 2c, we plot by the number of training epochs. We can see in all
cases, although convergence can be a bit slower, training with compressed embeddings still reaches
similar accuracy to no compression. In Figures 2b and 2d, we plot by the communication cost in
MB. The cost of communication includes both the upload of (compressed) embeddings to the server
and download of embeddings and server model to all parties. We can see that by compressing embeddings, we can reach higher accuracy with significantly less communication cost. In both datasets,
the compressors reach similar accuracy to each other, though top-k sparsification performs slightly
worse than the others on MIMIC-III, while scalar quantization performs worse on ModelNet10.

In Table 2, we show the maximum test accuracy reached during training and the communication cost
to reach a target accuracy for both datasets. We show results for all three compressors with b = 2,
3, and 4 bits per component, as well as the baseline of b = 32. For the MIMIC-III dataset, we show
the maximum test F1-score reached and the total communication cost of reaching an F1-Score of
0.4. The maximum F1-score for each case is within a standard deviation of each other. However,
the cost to reach target score is much smaller as the value of b decreases for all compressors. We can
see that when b = 2, we can achieve over 90% communication cost reduction over no compression
to reach a target F1-score.

For the ModelNet10 dataset, Table 2 shows the maximum test accuracy reached and the total communication cost of reaching an accuracy of 75%. We can see similar results as for the MIMIC-III


-----

Table 2: Maximum F1-Score and test accuracy reached during training, and communication cost to
reach a target accuracy. For MIMIC-III, the target test F1-Score is 0.4, For ModelNet10, the target
test accuracy is 75%. In these experiments, Q = 10 and M = 4.

**Compressor** **MIMIC-III dataset** **ModelNet10 dataset**

Max F1-Score Cost (MB) Max Accuracy Cost (MB)
Reached Target = 0.4 Reached Target = 75%

None b = 32 0.448 ± 0.010 3830.0 ± 558.2 83.81% ± 0.54% 9715.9 ± 2819.3

Top-VectorScalark b b b = 2 = 2 = 2 0.4310.4510.441 ± ± ± 0.016 0.021 0.018 236.1309.8233.1 ± ± ± 93.6 17.9 28.7 83.92%81.98%79.63% ± ± ± 0.66% 0.43% 1.74% 620.2594.3374.7 ± ± ± 194.2 259.7 48.3

VectorTop-Scalark b b b = 3 = 3 = 3 0.4550.4350.446 ± ± ± 0.020 0.030 0.011 470.7343.1330.5 ± ± ± 116.8 10.6 18.8 79.47%83.85%82.64% ± ± ± 1.58% 0.65% 0.41% 581.4930.2833.3 ± ± ± 106.1 264.3 355.2

Top-VectorScalark b b b = 4 = 4 = 4 0.4530.4460.451 ± ± ± 0.014 0.017 0.020 519.1446.5456.0 ± ± ± 150.4 21.3 87.8 83.83%79.41%83.17% ± ± ± 0.62% 0.74% 2.23% 1240.31137.0749.4 ± ± ± 352.4 450.5 96.7


Table 3: MIMIC-III time in seconds to reach
a target F1-Score for different local iterations
_Q and communication latency tc with vector_
quantization and b = 3.

_tc_ **Time to Reach Target F1-Score 0.45**
_Q = 1_ _Q = 10_ _Q = 25_

11050200 13259.141262.783788.32694.53 ± ± ± ± 150.75 274.10 822.30 2878.04 1398.60512.82699.30470.86 ± ± ± ± 235.35 256.32 349.53 699.05 445.21461.17532.12798.19 ± ± ± ± 51.44 53.29 61.49 92.23


(a) Parties M = 4 (b) Parties M = 12

Figure 3: Communication cost of training on
ModelNet10 with vector quantization.


dataset with the exception of scalar quantization. Scalar quantization achieves the target accuracy
with much lower communication cost, but the maximum test accuracy is significantly lower than the
other cases. This can be due to scalar quantization always quantizing embedding components to the
same values when nearing convergence. Vector quantization benefits from considering components
jointly, and thus can have better reconstruction quality than scalar quantization (Woods, 2006).

In Table 3, we consider the communication/computation tradeoff of local iterations. We show how
the number of local iterations affects the time to reach a target F1-score in the MIMIC-III dataset.
We train C-VFL with vector quantization b = 3 and set the local iterations Q to 1, 10, and 25. We
simulate a scenario where computation time for training a mini-batch of data at each party takes
10 ms, and communication of embeddings takes a total of 1, 10, 50, and 200 ms roundtrip. These
different communication latencies correspond to the distance between the parties and the server:
within the same cluster, on the same local network, within the same region, and across the globe.
According to Theorem 1, increasing the number of local iterations Q increases convergence error.
However, the target test accuracy is reached within less time when Q increases. The improvement
over Q = 1 local iterations increases as the communication latency increases. In systems where
communication latency is high, it may be beneficial to increase the number of local iterations. The
choice of Q will depend on the accuracy requirements of the given prediction task and the time
constraints on the prediction problem.

Finally, in Figure 3, we plot the test accuracy of ModelNet10 against the communication cost when
using vector quantization with b = 2, 3, 4, and 32. We include plots for 4 and 12 parties. In the 12
party setup, each party stores one view for each CAD model. We note that changing the number of
parties changes the global model structure Θ as well. We can see in both cases that smaller values of
_b reach higher test accuracies at lower communication cost. The total communication cost is larger_
with 12 parties, but the impact of increasing compression is similar for both M = 4 and M = 12.

6 CONCLUSION

We proposed C-VFL, a distributed communication-efficient algorithm for training a model over
vertically partitioned data. We proved convergence of the algorithm to a fixed point at a rate of
_O(_ _√[1]T_ [)][, and we showed experimentally that communication could be reduced by over][ 90%][ without a]

significant decrease in accuracy. For future work, we seek to relax our bounded gradient assumption
and explore the effect of adaptive compressors.


-----

REFERENCES

W. R. Bennett. Spectra of quantized signals. Bell System Technical Journal, 1948.

Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree Anandkumar.
SIGNSGD: compressed optimisation for non-convex problems. In Proceedings of the 35th In_ternational Conference on Machine Learning, 2018._

Kallista A. Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan,
Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for federated learning on user-held data. arXiv, 2016.

Kallista A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman,
Vladimir Ivanov, Chlo´e Kiddon, Jakub Koneˇcn´y, Stefano Mazzocchi, Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, and Jason Roselander. Towards federated
learning at scale: System design. In Proceedings of Machine Learning and Systems, 2019.

L´eon Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine
learning. Siam Review, 2018.

Dongchul Cha, MinDong Sung, and Yu-Rang Park. Implementing vertical federated learning using
autoencoders: Practical application, generalizability, and utility study. JMIR Medical Informatics,
2021.

Tianyi Chen, Xiao Jin, Yuejiao Sun, and Wotao Yin. VAFL: a method of vertical asynchronous
federated learning. arXiv, 2020.

Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, and Qiang Yang. Secureboost: A
lossless federated learning framework. arXiv, 2019.

Anirban Das and Stacy Patterson. Multi-tier federated learning for vertically partitioned data. In
_IEEE International Conference on Acoustics, Speech and Signal Processing, 2021._

FederatedAI. Fate. https://github.com/FederatedAI/FATE, 2021.

Siwei Feng and Han Yu. Multi-participant multi-class vertical federated learning. arXiv, 2020.

Jonas Geiping, Hartmut Bauermeister, Hannah Dr¨oge, and Michael Moeller. Inverting gradients

-  how easy is it to break privacy in federated learning? In Advances in Neural Information
_Processing Systems, 2020._

Bin Gu, An Xu, Zhouyuan Huo, Cheng Deng, and Heng Huang. Privacy-preserving asynchronous
vertical federated learning algorithms for multiparty collaborative learning. IEEE Transactions
_on Neural Networks and Learning Systems, 2021._

Yue Gu, Xinyu Lyu, Weijia Sun, Weitian Li, Shuhong Chen, Xinyu Li, and Ivan Marsic. Mutual
correlation attentive factors in dyadic fusion networks for speech emotion recognition. In Pro_ceedings of the 27th ACM International Conference on Multimedia, 2019._

Otkrist Gupta and Ramesh Raskar. Distributed learning of deep neural network over multiple agents.
_Journal of Network and Computer Applications, 2018._

Wei Han, Hui Chen, and Soujanya Poria. Improving multimodal fusion with hierarchical mutual information maximization for multimodal sentiment analysis. Proceedings of the 2020 Conference
_on Empirical Methods in Natural Language Processing, 2021._

Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume
Smith, and Brian Thorne. Private federated learning on vertically partitioned data via entity
resolution and additively homomorphic encryption. arXiv, 2017.

Yaochen Hu, Di Niu, Jianming Yang, and Shengping Zhou. FDML: A collaborative machine
learning framework for distributed features. In 25th ACM SIGKDD International Conference
_on Knowledge Discovery & Data Mining, 2019._


-----

Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling Feng, Mohammad
Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. Mimic-iii,
a freely accessible critical care database. Nature, 2016.

Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur´elien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista A. Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael
G. L. D’Oliveira, Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri`a Gasc´on, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Za¨ıd Harchaoui, Chaoyang
He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi,
Mikhail Khodak, Jakub Koneˇcn´y, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo,
Tancr`ede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Ozg¨[¨] ur, Rasmus
Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song, Weikang Song,
Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram`er, Praneeth Vepakomma,
Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances
and open problems in federated learning. Foundations and Trends in Machine Learning, 2021.

Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian U. Stich, and Martin Jaggi. Error feedback
fixes signsgd and other gradient compression schemes. In Proceedings of the 36th International
_Conference on Machine Learning, 2019._

Will Koehrsen. Book recommendation system. https://github.com/WillKoehrsen/wikipedia-datascience/blob/master/notebooks/Book2018.

Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In Proceedings of Machine Learning and
_Systems, 2020._

Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang Liang,
Qiang Yang, Dusit Niyato, and Chunyan Miao. Federated learning in mobile edge networks: A
comprehensive survey. IEEE Communication Surveys and Tutorials, 2020.

Tao Lin, Sebastian U. Stich, Kumar Kshitij Patel, and Martin Jaggi. Don’t use large mini-batches,
use local SGD. In 8th International Conference on Learning Representations, 2020.

Yujun Lin, Song Han, Huizi Mao, Yu Wang, and Bill Dally. Deep gradient compression: Reducing the communication bandwidth for distributed training. In 6th International Conference on
_Learning Representations, 2018._

Lumin Liu, Jun Zhang, Shenghui Song, and Khaled B. Letaief. Client-edge-cloud hierarchical
federated learning. In IEEE International Conference on Communications, 2020.

Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian Chen, Mingyi Hong, and
Qiang Yang. A communication efficient vertical federated learning framework. NeurIPS Work_shop on Federated Learning for Data Privacy and Confidentiality, 2019._

Aravindh Mahendran and Andrea Vedaldi. Understanding deep image representations by inverting
them. In IEEE Conference on Computer Vision and Pattern Recognition, 2015.

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag¨uera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Proceedings of
_the 20th International Conference on Artificial Intelligence, 2017._

Philipp Moritz, Robert Nishihara, Ion Stoica, and Michael I. Jordan. Sparknet: Training deep networks in spark. 2016.

Lam M. Nguyen, Phuong Ha Nguyen, Marten van Dijk, Peter Richt´arik, Katya Scheinberg, and
Martin Tak´ac. SGD and hogwild! convergence without the bounded gradients assumption. In
_Proceedings of the 35th International Conference on Machine Learning, 2018._

Weizhi Nie, Qi Liang, Yixin Wang, Xing Wei, and Yuting Su. MMFN: multimodal information
fusion networks for 3d model classification and retrieval. ACM Transactions on Multimedia Com_puting, Communications, and Applications, 2021._


-----

Le Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai. Privacypreserving deep learning via additively homomorphic encryption. IEEE Transactions on Infor_mation Forensics and Security, 2018._

Peter Richt´arik and Martin Tak´ac. Parallel coordinate descent methods for big data optimization.
_Mathematical Programming, 2016._

Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletar`ı, Holger R. Roth, Shadi Albarqouni, Spyridon Bakas, Mathieu N. Galtier, Bennett A. Landman, Klaus Maier-Hein, S´ebastien Ourselin,
Micah Sheller, Ronald M. Summers, Andrew Trask, Daguang Xu, Maximilian Baust, and
M. Jorge Cardoso. Digital Medicine, 2020.

Daniele Romanini, Adam James Hall, Pavlos Papadopoulos, Tom Titcombe, Abbas Ismail, Tudor
Cebere, Robert Sandmann, Robin Roehm, and Michael A. Hoeh. Pyvertical: A vertical federated learning framework for multi-headed splitnn. ICLR Workshop on Distributed and Private
_Machine Learning, 2021._

Shaohuai Shi, Kaiyong Zhao, Qiang Wang, Zhenheng Tang, and Xiaowen Chu. A convergence
analysis of distributed SGD with communication-efficient gradient sparsification. In Proceedings
_of the 28th International Joint Conference on Artificial Intelligence, 2019._

Nir Shlezinger, Mingzhe Chen, Yonina C. Eldar, H. Vincent Poor, and Shuguang Cui. Uveqfed:
Universal vector quantization for federated learning. IEEE Transactions on Signal Processing,
2021.

Sebastian U. Stich, Jean-Baptiste Cordonnier, and Martin Jaggi. Sparsified SGD with memory. In
_Advances in Neural Information Processing Systems, 2018._

John Tsitsiklis, Dimitri Bertsekas, and Michael Athans. Distributed asynchronous deterministic and
stochastic gradient optimization algorithms. IEEE transactions on automatic control, 1986.

Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian Makaya, Ting He, and
Kevin Chan. Adaptive federated learning in resource constrained edge computing systems. IEEE
_Journal on Selected Areas in Communications, 2019._

Robert Alexander Wannamaker. The Theory of Dithered Quantization. PhD thesis, 1997.

Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Terngrad:
Ternary gradients to reduce communication in distributed deep learning. In Advances in Neural
_Information Processing Systems, 2017._

John W Woods. Multidimensional signal, image, and video processing and coding. Elsevier, 2006.

Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong
Xiao. 3d shapenets: A deep representation for volumetric shapes. In Conference on Computer
_Vision and Pattern Recognition, 2015._

Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept
and applications. ACM Transactions on Intelligent Systems and Technology, 2019.

Ram Zamir and Meir Feder. On lattice quantization noise. _IEEE Transactions on Information_
_Theory, 1996._

Xinwei Zhang, Wotao Yin, Mingyi Hong, and Tianyi Chen. Hybrid federated learning: Algorithms
and implementation. arXiv, 2020.


-----

A APPENDIX

A.1 PROOFS OF THEOREMS 1 AND 2

In this section, we provide the proofs for Theorems 1 and 2.

A.1.1 ADDITIONAL NOTATION

Before starting the proofs, we define some additional notation to be used throughout. At each
iteration t, each party m trains with the embeddings Φ[ˆ] _[t]m[. This is equivalent to the party training]_
directly with the models θm[t] [and][ θ]j[t][0] [for all][ j][ ̸][=][ m][, where][ t][0][ is the last communication iteration]
when party m received the embeddings. We define:

_γm,j[t]_ [=] _θjt_ _m = j_ (A.1)
_θj[t][0]_ otherwise


to represent party m’s view of party j’s model at iteration t. We define the column vector
Γ[t]m [= [(][γ]m,[t] 0[)][T][ ;][ . . .][ ; (][γ]m,M[t] [)][T][ ]][T][ to be party][ m][’s view of the global model at iteration][ t][.]

We introduce some notation to help with bounding the error introduced by compression. We define
_FˆB(Γ[t]m[)][ to be the stochastic loss with compression error for a randomly selected mini-batch][ B]_
calculated by party m at iteration t:

_FˆB(Γ[t]m[) :=][ F][B]_ _θ0[t][0]_ [+][ ϵ]0[t][0] _[, h][1][(][θ]1[t][0]_ [;][ X]1[B][t][0] ) + ϵ[t]1[0] _[, . . ., h][m][(][θ]m[t]_ [;][ X]m[B][t][0] [)][, . . ., h][M] [(][θ]M[t][0] [;][ X]M[B][t][0] [) +][ ϵ]M[t][0] _._
 (A.2)

Recall the recursion over the global model Θ:

_t_
Θ[t][+1] = Θ[t] _−_ _η[t][0][ ˆ]G_ _._ (A.3)

We can equivalently define **G[ˆ]** _t as follows:_

**Gˆ** _t =_ ( 0F[ˆ]B(Γ[t]0[))][T][, . . .,][ (][∇][M] _F[ˆ]B(Γ[t]M_ [))][T][ i][T] _._ (A.4)
_∇_
h

Note that the compression error in _F[ˆ](·) is applied to the embeddings, and not the model parameters._
Thus, F (·) and _F[ˆ](·) are different functions. In several parts of the proof, we need to bound the_
compression error in ∇mF[ˆ]B(Γ[t]m[)][.]

For our analysis, we redefine the set of embeddings for a mini-batch B of size B from party m as a
matrix:

_hm(θm; X[B]m[) :=]_ _hm(θm; x[B]m[1]_ [)][, . . ., h][m][(][θ][m][;][ x]m[B][B] [)] _._ (A.5)
h i

_hm(θm; X[B]m[)][ is a matrix with dimensions][ P][m]_
_m for a single sample in the mini-batch._ _[×][ B][ where each column is the embedding from party]_

Let P = _m=0_ _[P][m][ be the sum of the sizes of all embeddings. We redefine the set of embeddings]_
used by a party m to calculate its gradient without compression error as a matrix:

[P][M]

Φˆ _[t]m_ [=] (θ0[t][0] [)][T][,][ (][h][1][(][θ]1[t][0] [;][ X]1[B][t][0] ))[T] _, . . ., (hm(θm[t]_ [;][ X][B]m[t][0] [))][T][, . . .,][ (][h][M] [(][θ]M[t][0] [;][ X][B]M[t][0] [))][T][ i][T] _._ (A.6)
h

Φˆ _[t]m_ [is a matrix with dimensions][ P][ ×][ B][ where each column is the concatenation of embeddings for]
all parties for a single sample in the mini-batch.

Recall the set of compression error vectors for a mini-batch B of size B from party m is the matrix:

_ϵ[t]m[0]_ [:=] _ϵ[B]m[1]_ _[, . . ., ϵ]m[B][B]_ _._ (A.7)
h i

_ϵ[t]m[0]_ [is a matrix of dimensions][ P][m]
for a single sample in the mini-batch.[×][ B][ where each column is the compression error from party][ m]


-----

We define the compression error on each embedding used in party m’s gradient calculation at iteration t:

_Em[t][0]_ [=] (ϵ[t]0[0] [)][T][, . . .,][ (][ϵ]m[t][0] 1[)][T][,][ 0][T][,][ (][ϵ][t]m[0] 1[)][T][, . . .,][ (][ϵ][t]M[0] [)][T][ i][T] _._ (A.8)
_−_ _−_
h

_Em[t][0]_ [is a matrix with dimensions][ P][ ×][ B][ where each column is the concatenation of compression]
error on embeddings for all parties for a single sample in the mini-batch.

With some abuse of notation, we define:

_∇mFB(Φ[t]m_ [+][ E]m[t][0] [) :=][ ∇][m]F[ˆ]B(Γ[t]m[)][.] (A.9)

Note that we can apply the chain rule to ∇mF[ˆ]B(Γ[t]m[)][:]

_∇mF[ˆ]B(Γ[t]m[) =][ ∇][θ]m[h][m][(][θ]m[t]_ [)][∇]hm(θm)[F][B][(Φ][t]m [+][ E]m[t][0] [)][.] (A.10)

With this expansion, we can now apply Taylor series expansion to ∇hm(θm)FB(Φ[t]m [+][ E]m[t][0] [)][ around]
the point Φ[t]m[:]

_∇hm(θm)FB(Φ[t]m_ [+][ E]m[t][0] [) =][ ∇]hm(θm)[F][B][(Φ][t]m[) +][ ∇][2]hm(θm)[F][B][(Φ]m[t] [)][t][E]m[t][0] [+][ . . .] (A.11)

We let the infinite sum of all terms in this Taylor series from the second partial derivatives and up be
denoted as R0[m][:]

_R0[m][(Φ]m[t]_ [+][ E]m[t][0] [) :=][ ∇][2]hm(θm)[F][B][(Φ]m[t] [)][T][ E]m[t][0] [+][ . . .] (A.12)

Note that all compression error is in R0[m][(Φ]m[t] [+][ E]m[t][0] [)][.] Presented in Section A.1.2, the proof
of Lemma 1’ shows how we can bound R0[m][(Φ]m[t] [+][ E]m[t][0] [)][, bounding the compression error in]
_∇mF[ˆ]B(Γ[t]m[)][.]_

Let E[t][0] = EBt0 [ Θ[τ] _τ_ =0[]][. Note that by Assumption 2,][ E][t][0][ ]G[t][0] [] = _F_ (Θ[t][0] ) as when there is
_· | {_ _}[t][0]_ _∇_
no compression error in the gradients G, they are equal to the full-batch gradient in expectation when
conditioned on the model parameters up to the iteration t0. However, this is not true for iterations
_t0 + 1 ≤_ _t ≤_ _t0 + Q −_ 1, as we reuse the mini-batch B[t][0] in these local iterations. We upper bound
the error introduced by stochastic gradients calculated during local iterations in Lemma 2.

A.1.2 SUPPORTING LEMMAS

Next, we provide supporting lemmas and their proofs.

We restate Lemma 1 here:
**Lemma 1. Under Assumptions 4-5, the norm of the difference between the objective function value**
_with and without error is bounded by:_

_M_

2
E _∇mFB(Φ[ˆ]_ _[t]m[)][ −∇][m][F][B][(Φ][t]m[)]_ _≤_ _Hm[2]_ _[G][2]m_ _Ej[t][0]_ _[.]_ (A.13)

_j=0X,j≠_ _m_

To prove Lemma 1, we first prove the following lemma:
**Lemma 1’. Under Assumptions 4-5, the squared norm of the partial derivatives for party m’s**
_embedding multiplied by the Taylor series terms R0[m][(Φ]m[t]_ [+][ E]m[t][0] [)][ is bounded by:]
_∇θmhm(θm[t]_ [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)] _≤_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ _[.]_ (A.14)

_Proof._ [2]

_∇θm_ _hm(θm[t]_ [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)] _≤_ _∇θmhm(θm[t]_ [)] _F_ _R0[m][(Φ]m[t]_ [+][ E]m[t][0] [)] _F_ (A.15)

_Hm[2]_ _θm_ _hm(θm[t]_ [)] _Em[t][0]_ (A.16)

[2] _≤_ _∇_ [2] _F_ _F_ [2]

where (A.16) follows from Assumption 4 and the following property of the Taylor series approxi
[2] [2]

mation error:
_R0[m][(Φ]m[t]_ [+][ E]m[t][0] [)] _Em[t][0]_ _[.]_ (A.17)
_F_ _[≤]_ _[H][m]_ _F_


-----

Applying Assumption 5, we have:

_∇θmhm(θm[t]_ [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)] _≤_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ _[.]_ (A.18)

[2] [2]

We now prove Lemma 1.

_Proof. Recall that:_

_∇mF[ˆ]B(Γ[t]m[) =][ ∇][m][F][B][(Φ][t]m_ [+][ E]m[t][0] [)] (A.19)

= ∇θmhm(θm[t] [)][∇]hm(θm)[F][B][(Φ][t]m [+][ E]m[t][0] [)][.] (A.20)

Next we apply Taylor series expansion as in (A.11):


_∇mF[ˆ]B(Γ[t]m[) =][ ∇][θ]m_ _[h][m][(][θ]m[t]_ [)] _∇hm(θm)FB(Φ[t]m[) +][ R]0[m][(Φ]m[t]_ [+][ E]m[t][0] [)] (A.21)

= _mFB(Γ[t]m[) +] [ ∇][θ]m_ _[h][m][(][θ]m[t]_ [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)]  (A.22)
_∇_

Rearranging and applying expectation and the squared 2-norm, we can bound further:

2
E _∇mF[ˆ]B(Γ[t]m[)][ −∇][m][F][B][(Γ]m[t]_ [)] = E _∇θm_ _hm(θm[t]_ [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)] (A.23)

_Hm[2]_ _[G]m[2]_ [E] _Em[t][0]_ [2] (A.24)
_≤_ _F_

= Hm[2] _[G]m[2]_ E _ϵ[t]j[0]_ (A.25)

_jX≠_ _m_ [2] _F_

[2]

= Hm[2] _[G]m[2]_ _j_ (A.26)

_E_ _[t][0]_
_jX≠_ _m_


where (A.24) follows from Lemma 1’, (A.25) follows from the definition of Em[t][0] [, and (A.26) follows]
from Definition 1.

**Lemma 2.pected squared norm difference of gradients If η[t][0]** _≤_ 4Q max1 _m Lm_ _[, then under Assumptions 1-5 we can bound the conditional ex-] G[t][0]_ _and_ **_G[ˆ]_** _t for iterations t0 to t0 + Q −_ 1 as follows:


_t0+Q−1_ E[t][0] **_Gt_** **_Gt0_** 2[] 16Q[3](η[t][0] )[2] _M_ _L[2]m_ _mF_ (Θ[t][0] )

_−_ _≤_ _∇_
_t=t0_ _m=0_

X  X

_M_

[ˆ] + 16Q[3](η[t][0] )[2] _L[2]m_ _σBm[2]_

_m=0_

X


+ 64Q[3]


_Hm[2]_ _[G][2]m_ _Em[t][0]_ _[.]_ (A.27)
_m=0_ _F_

X

[2]


-----

_Proof._

_M_

E[t][0] **Gt** **Gt0** 2[] = E[t][0] _mF[ˆ]B(Γ[t]m[)][ −∇][m][F][B][(Γ][t]m[0]_ [)] 2[] (A.28)
_−_ _∇_

_m=0_

 X 

_M_

[ˆ] 2[]

= E[t][0] _∇mF[ˆ]B(Γ[t]m[)][ −]_ _F[ˆ]B(Γ[t]m[−][1][) +][ ∇][m]F[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)] (A.29)

_m=0_

X 

_M_

2[]

_≤_ (1 + n) E[t][0] _∇mF[ˆ]B(Γ[t]m[)][ −∇][m]F[ˆ]B(Γ[t]m[−][1][)]_

_m=0_

X 

_M_

2[]

+ 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)] (A.30)

_n_ _∇_

  _mX=0_ 

_M_

_≤_ 2 (1 + n) E[t][0][ h]∇mFB(Γ[t]m[)][ −∇][m][F][B][(Γ][t]m[−][1][)]

_m=0_

X

_M_ [2][i]

+ 2 (1 + n) E[t][0][ h]∇θmhm(θm[t] [)][R]0[m][(Φ]m[t] [+][ E]m[t][0] [)][ −∇][θ]m[h][m][(][θ]m[t][−][1][)][R]0[m][(Φ]m[t][−][1] + Em[t][−][1][)]

_m=0_

X

_M_ 2[] [2][i]

+ 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)] (A.31)

_n_ _∇_

  _mX=0_ 

_M_

_≤_ 2 (1 + n) E[t][0][ h]∇mFB(Γ[t]m[)][ −∇][m][F][B][(Γ]m[t][−][1][)]

_m=0_

X

_M_ [2][i]

+ 8 (1 + n) _Hm[2]_ _[G]m[2]_ _Em[t][0]_

_m=0_

X

_M_ [2] 2[]

+ 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)] (A.32)

_n_ _∇_

  _mX=0_ 

where (A.30) follows from the fact that (X + Y )[2] _≤_ (1 + n)X [2] + (1 + _n[1]_ [)][Y][ 2][ for some positive][ n]

and (A.32) follows from Lemma 1’.


Applying Assumption 1 to the first term in (A.30) we have:


_M_

E[t][0] **Gt** **Gt0** 2[] 2 (1 + n) _L[2]m[E][t][0][ h]Γ[t]m_ _m_
_−_ _≤_ _m=0_ _[−]_ [Γ][t][−][1]
 X

[ˆ] _M_ [2][i] 2[]

+ 2 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_n_ _∇_

  _mX=0_ 

_M_

+ 8 (1 + n) _Hm[2]_ _[G][2]m_ _Em[t][0]_ (A.33)

_m=0_

X

_M_ [2] 2[]

= 2(η[t][0] )[2] (1 + n) _L[2]m[E][t][0]_ _∇mF[ˆ]B(Γ[t]m[−][1][)]_

_m=0_

X 

_M_

2[]

+ 2 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_n_ _∇_

  _mX=0_ 

_M_

+ 8 (1 + n) _Hm[2]_ _[G][2]m_ _Em[t][0]_ (A.34)

_m=0_

X

[2]

where (A.34) follows from the update rule Γ[t]m [= Γ]m[t][−][1] _−_ _η[t][0]_ _∇mF[ˆ]B(Γ[t]m[−][1][)][.]_


-----

Bounding further:

E[t][0] **Gt** **Gt0** 2[]
_−_
 _M_

2[]

[ˆ]

_≤_ 2(η[t][0] )[2] (1 + n) _L[2]m[E][t][0]_ _∇mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [) +][ ∇][m][F][B][(Γ][t]m[0] [)]

_m=0_

X 

_M_

2[]

+ 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_n_ _∇_

  _mX=0_ 

_M_

+ 8 (1 + n) _Hm[2]_ _[G][2]m_ _Em[t][0]_ (A.35)

_m=0_

X

_M_ [2] 2[]

_≤_ 4(η[t][0] )[2] (1 + n) _L[2]m[E][t][0]_ _∇mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_m=0_

X 

_M_

+ 4(η[t][0] )[2] (1 + n) _L[2]m[E][t][0][ h]_ _mFB(Γ[t]m[0]_ [)]

_∇_
_m=0_

X

_M_ [2][i] 2[]

+ 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_n_ _∇_

  _mX=0_ 

_M_

+ 8 (1 + n) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ (A.36)

_m=0_

X

_M_ [2] 2[]

= 4(η[t][0] )[2] (1 + n) L[2]m [+] 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_n_ _∇_

_mX=0_    

_M_

+ 4(η[t][0] )[2] (1 + n) _L[2]m[E][t][0][ h]_ _mFB(Γ[t]m[0]_ [)]

_∇_
_m=0_

X

_M_ [2][i]

+ 8 (1 + n) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ _._ (A.37)

_m=0_

X

[2]


Let n = Q. We simplify (A.37) further:

E[t][0] **Gt** **Gt0** 2[]
_−_
 _M_

2[]

[ˆ]

4(η[t][0] )[2] (1 + Q) L[2]m [+] 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_≤_ _Q_ _∇_

_mX=0_    

_M_

+ 4(η[t][0] )[2] (1 + Q) _L[2]m[E][t][0][ h]∇mFB(Γ[t]m[0]_ [)]

_m=0_

X

_M_ [2][i]

+ 8 (1 + Q) _Hm[2]_ _[G][2]m_ _Em[t][0]_ _[.]_ (A.38)

_m=0_ _F_

X

[2]


-----

Let η[t][0] _≤_ 4Q max1 _m Lm_ [. We bound (A.38) as follows:]

_M_

E[t][0] **Gt** **Gt0** 2[] (1 + Q) + 1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)] 2[]
_−_ _≤_ 4Q[2] _Q_ _∇_
    _mX=0_ 

_M_

[ˆ]

+ 4(η[t][0] )[2] (1 + Q) _L[2]m[E][t][0][ h]∇mFB(Γ[t]m[0]_ [)]

_m=0_

X

_M_ [2][i]

+ 8(1 + Q) _m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ (A.39)

X

1 _M_ [2] 2[]

1 + [1] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]

_≤_ 2Q [+] _Q_ _∇_
   _mX=0_ 

_M_

+ 4(η[t][0] )[2] (1 + Q) _L[2]m[E][t][0][ h]∇mFB(Γ[t]m[0]_ [)]

_m=0_

X

_M_ [2][i]

+ 8(1 + Q) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ (A.40)

_m=0_ _F_

X

_M_ [2] 2[]

1 + [2] E[t][0] _mF[ˆ]B(Γ[t]m[−][1][)][ −∇][m][F][B][(Γ]m[t][0]_ [)]
_≤_ _Q_ _∇_
  _mX=0_ 

_M_

+ 4(η[t][0] )[2] (1 + Q) _L[2]m[E][t][0][ h]_ _mFB(Γ[t]m[0]_ [)]

_∇_
_m=0_

X

_M_ [2][i]

+ 8(1 + Q) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ _[.]_ (A.41)

_m=0_ _F_

X

[2]

We define the following notation for simplicity:

_M_

2[]

_A[t]_ := E[t][0] _∇mF[ˆ]B(Γ[t]m[)][ −∇][m][F][B][(Γ]m[t][0]_ [)] (A.42)

_m=0_

X 

_M_

_B0 := 4(η[t][0]_ )[2] (1 + Q) _L[2]m[E][t][0][ h]_ _mFB(Γ[t]m[0]_ [)] (A.43)

_∇_
_m=0_

X

_M_ [2][i]

_B1 := 8(1 + Q)_ _Hm[2]_ _[G]m[2]_ _Em[t][0]_ (A.44)

_m=0_ _F_

X

[2]

_C :=_ 1 + [2] _._ (A.45)
 


Note that we have shown that A[t] _≤_ _CA[t][−][1]_ + B0 + B1. Therefore:

_A[t][0][+1]_ _≤_ _CA[t][0]_ + (B0 + B1) (A.46)

_A[t][0][+2]_ _≤_ _C_ [2]A[t][0] + C(B0 + B1) + (B0 + B1) (A.47)

_A[t][0][+3]_ _≤_ _C_ [3]A[t][0] + C [2](B0 + B1) + C(B0 + B1) + (B0 + B1) (A.48)
.
.
. (A.49)

_t−t0−2_

_A[t]_ _≤_ _C_ _[t][−][t][0][−][1]A[t][0]_ + (B0 + B1) _C_ _[k]_ (A.50)

_k=0_

X

= C _[t][−][t][0][−][1]A[t][0]_ + (B0 + B1) _[C]_ _[t][−][t][0][−][1][ −]_ [1] _._ (A.51)

_C −_ 1


-----

We bound the first term in (A.51) by applying Lemma 1:

_M_

2[]

_A[t][0]_ = E[t][0] _∇mF[ˆ]B(Γ[t]m[0]_ [)][ −∇][m][F][B][(Γ][t]m[0] [)] (A.52)

_m=0_

X 

_M_

_≤_ _m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ _[.]_ (A.53)

X

Summing over the set of local iterations t0, . . ., t[+]0 [, where][2] _[ t]0[+]_ [:=][ t][0][ +][ Q][ −] [1][:]

_t[+]0_ _t[+]0_


_C_ _[t][−][t][0][−][1]A[t][0]_ = A[t][0]

_t=t0_

X


_C_ _[t][−][t][0][−][1]_ (A.54)
_t=t0_

X


= A[t][0][ C] _[Q][ −]_ [1] (A.55)

_C −_ 1 _Q_

1 + _Q[2]_ 1

_−_

= A[t][0] (A.56)

 

1 + _Q[2]_ 1

_−_

  _Q_

1 + _Q[2]_ 1

_−_

= QA[t][0] (A.57)

 2

_QA[t][0][ e][2][ −]_ [1] (A.58)
_≤_ 2

_≤_ 4QA[t][0] (A.59)

_M_

_≤_ 4Q _m=0_ _Hm[2]_ _[G]m[2]_ _Em[t][0]_ _F_ _[.]_ (A.60)

X

[2]

It is left to bound the second term in (A.51) over the set of local iterations t0, . . ., t0 + Q − 1.

_t[+]0_ _t[+]0_

(B0 + B1) _[C]_ _[t][−][t][0][−][1][ −]_ [1] (B0 + B1) _[C]_ _[t][−][t][0][−][1][ −]_ [1] (A.61)

_C_ 1 _≤_ _C_ 1

_t=t0_ _−_ _t=t0_ _−_

X X


= [(][B][0][ +][ B][1][)] _t[+]0_ _C_ _[t][−][t][0][−][1]_ _Q_ (A.62)

_C_ 1  _−_ 
_−_ _t=t0_

X

= [(][B][0][ +][ B][1][)] C _Q −_ 1  (A.63)

_C_ 1 _C_ 1
_−_  _−_ _[−]_ _[Q]_

_Q_

(B0 + B1) 1 + _Q[2]_ _−_ 1
= _Q_ (A.64)
1 + _Q[2]_ 1   1 + _Q[2]_ 1 _−_ 

_−_ _−_

 

     _Q_ 

_Q_ 1 + _Q[2]_ 1

_−_

= _[Q][(][B][0][ +][ B][1][)]_     _Q_ (A.65)

2 2 _−_

 
 
 _Q_ 

1 + _Q[2]_ 1

_−_

= _[Q][2][(][B][0][ +][ B][1][)]_ 1 (A.66)

2   2 _−_ 

 
e2 1 

_−_ 1 (A.67)

_≤_ _[Q][2][(][B][0]2[ +][ B][1][)]_ 2 _−_

 

_≤_ 2Q[2](B0 + B1) (A.68)
(A.69)


-----

Plugging the values for B0 and B1:


_t[+]0_

(B0 + B1) _[C]_ _[t][−][t][0][−][1][ −]_ [1] 8Q[2](η[t][0] )[2] (1 + Q)

_C_ 1 _≤_

_t=t0_ _−_

X


_M_

_Q)_ _L[2]m[E][t][0][ h]∇mFB(Γ[t]m[0]_ [)]

_m=0_

X

_M_ [2][i]

_m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ (A.70)

X

[2]


+ 16Q[2](1 + Q)


Applying Assumption 3 and adding in the first term in (A.51):

_t[+]0_ _M_

_A[t]_ 8Q[2](η[t][0] )[2] (1 + Q) _L[2]m_ _mF_ (Θ[t][0] )
_≤_ _∇_
_t=t0_ _m=0_

X X

_M_ [2]

+ 8Q[2](η[t][0] )[2] (1 + Q) _L[2]m_ _σBm[2]_

_m=0_

X

_M_

+ 4(4Q[2](1 + Q) + Q) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ (A.71)

_m=0_ _F_

X

_M_ [2]
16Q[3](η[t][0] )[2] _L[2]m_ _mF_ (Θ[t][0] )
_≤_ _∇_

_m=0_

X

_M_ [2]
+ 16Q[3](η[t][0] )[2] _L[2]m_ _σBm[2]_

_m=0_

X


_Hm[2]_ _[G]m[2]_ _Em[t][0]_ _[.]_ (A.72)
_m=0_ _F_

X

[2]


+ 64Q[3]


A.1.3 PROOF OF THEOREMS 1 AND 2

Let t[+]0 [:=][ t][0][ +][ Q][ −] [1][. By Assumption 1:]

2

_F_ (Θ[t]0[+] ) _F_ (Θ[t][0] ) _F_ (Θ[t][0] ), Θ[t]0[+] Θ[t][0] [E] + _[L]_ Θ[t]0[+] Θ[t][0] (A.73)
_−_ _≤_ _∇_ _−_ 2 _−_
D 2

_t[+]0_ _t[+]0_

_t_ _t_

= _F_ (Θ[t][0] ), _η[t][0][ ˆ]G_ + _[L]_ _η[t][0][ ˆ]G_ (A.74)
_−_ *∇ _t=t0_ + 2 _t=t0_

X X

_t[+]0_ _t[E]_ _t[+]0_ _t_ 2

_η[t][0][ D]_ _F_ (Θ[t][0] ), **G[ˆ]** + _[LQ]_ (η[t][0] )[2] **G** (A.75)

_≤−_ _∇_ 2

_t=t0_ _t=t0_

X X

[ˆ]


where (A.75) follows from fact that ([P][N]n=1 _[x][n][)][2][ ≤]_ _[N][ P]n[N]=1_ _[x]n[2]_ [.]


-----

We bound further:

_t[+]0_ _t[+]0_

_F_ (Θ[t]0[+] ) _F_ (Θ[t][0] ) _η[t][0][ D]_ _F_ (Θ[t][0] ), **G[ˆ]** _t_ **Gt0** [E] _η[t][0]_ _F_ (Θ[t][0] ), G[t][0]
_−_ _≤−_ _∇_ _−_ _−_ _∇_

_t=t0_ _t=t0_

X X

+ _[LQ]_ _t[+]0_ (η[t][0] )[2] **Gt** **Gt0 + Gt0** 2 (A.76)

2 _−_

_t=t0_

X

_t[+]0_ [ˆ] _t[+]0_

_t_ _t0_ [E]

_≤−_ _η[t][0][ D]∇F_ (Θ[t][0] ), **G[ˆ]** _−_ **G** _−_ _η[t][0]_ _∇F_ (Θ[t][0] ), G[t][0]

_t=t0_ _t=t0_

X X

+ LQ _t[+]0_ (η[t][0] )[2] **Gt** **Gt0** 2 + LQ _t[+]0_ (η[t][0] )[2] **G[t][0]** (A.77)

_−_
_t=t0_ _t=t0_

X X

_t[+]0_ [ˆ] _t[+]0_ [2]

_t[E]_

= _η[t][0][ D]−∇F_ (Θ[t][0] ), G[t][0] _−G[ˆ]_ _−_ _η[t][0]_ _∇F_ (Θ[t][0] ), G[t][0]

_t=t0_ _t=t0_

X X

+ LQ _t[+]0_ (η[t][0] )[2] **Gt** **Gt0** 2 + LQ _t[+]0_ (η[t][0] )[2] **G[t][0]** _._ (A.78)

_−_
_t=t0_ _t=t0_

X X

_t[+]0_ [ˆ] [2]

_η[t][0]_ _F_ (Θ[t][0] )

_≤_ 2[1] _∇_

_t=t0_

X

_t[+]0_ _t_ _t0[2]_ 2 _t[+]0_

+ [1] _η[t][0]_ **G** **G** _η[t][0]_ _F_ (Θ[t][0] ), G[t][0]

2 _−_ _−_ _∇_

_t=t0_ _t=t0_

X X

+ LQ _t[+]0_ (η[t][0][ˆ])[2] **Gt** **Gt0** 2 + LQ _t[+]0_ (η[t][0] )[2] **G[t][0]** (A.79)

_−_
_t=t0_ _t=t0_

X X

[ˆ] [2]

where (A.79) follows from the fact that A · B = 2[1] _[A][2][ +][ 1]2_ _[B][2][ −]_ [1]2 [(][A][ −] _[B][)][2][.]_

We apply the expectation E[t][0] to both sides of (A.79):


_t[+]0_ _η[t][0]_ _F_ (Θ[t][0] ) + [1] _t[+]0_ _η[t][0]_ (1 + LQη[t][0] )E[t][0] **Gt** **Gt0** 2[]

_∇_ 2 _−_
_t=t0_ _t=t0_

X X 

[2] _t[+]0_ [ˆ]

+ LQ (η[t][0] )[2]E[t][0][ h]G[t][0] (A.80)

_t=t0_

X

_t[+]0_ [2][i]


E[t][0][ h]F (Θ[t]0[+] ) _F_ (Θ[t][0] )
_−_ _≤−_ [1]2
i

_≤−_ 2[1]

+ [1]


_η[t][0]_ (1 − _LQη[t][0]_ ) _∇F_ (Θ[t][0] )
_t=t0_

X

_t[+]0_ _η[t][0]_ (1 + LQη[t][0] )E[t][0] **Gt** **G[2]t0** 2[] + LQ

_−_
_t=t0_

X 

[ˆ]


_t[+]0_

(η[t][0] )[2]

_t=t0_

X

(A.81)

_M_

_σm[2]_


_σm[2]_


_m=0_


= _F_ (Θ[t][0] )
_−_ _[Q]2_ _[η][t][0]_ [(1][ −] _[LQη][t][0]_ [)] _∇_

_t[+]0_ _t[2]_ _t0_ 2[]

+ [1] _η[t][0]_ (1 + LQη[t][0] )E[t][0] **G** **G** + LQ[2](η[t][0] )[2]

2 _−_

_t=t0_

X 

[ˆ]


_m=0_


(A.82)


-----

where (A.80) follows from applying Assumption 2 and noting that E[t][0][ ]G[t][0] [] = _F_ (Θ[t][0] ), and
_∇_
(A.82) follows from Assumption 3.

Applying Lemma 2 to (A.82):

E[t][0][ h]F (Θ[t]0[+] ) _F_ (Θ[t][0] ) _F_ (Θ[t][0] )
_−_ _≤−_ _[Q]2_ _[η][t][0]_ [(1][ −] _[LQη][t][0]_ [)] _∇_
i _M_

[2]

+ 8Q[3](η[t][0] )[3](1 + LQη[t][0] ) _L[2]m_ _∇mF_ (Θ[t]m[0] [)]

_m=0_

X

_M_ [2]

+ 8Q[3](η[t][0] )[3](1 + LQη[t][0] ) _L[2]m_ _σBm[2]_

_m=0_

X


_Hm[2]_ _[G][2]m_ _Em[t][0]_
_m=0_

X


+ 32Q[3]η[t][0] (1 + LQη[t][0] )


_σ[2]_


+ LQ[2](η[t][0] )[2]


(A.83)


_m=0_

_M_

_η[t][0]_ (1 − _LQη[t][0]_ _−_ 16Q[2]L[2]m[(][η][t][0] [)][2][ −] [16][Q][3][L]m[2] _[L][(][η][t][0]_ [)][3][))] _∇mF_ (Θ[t][0] )
_m=0_

X

_M_

+ (LQ[2](η[t][0] )[2] + 8Q[3]L[2]m[(][η][t][0] [)][3][ + 8][Q][4][LL]m[2] [(][η][t][0] [)][4][)] _σm[2]_

X


_≤−_ _[Q]2_


_m=0_

_M_

_Hm[2]_ _[G]m[2]_ _Em[t][0]_ _[.]_ (A.84)
_m=0_ _F_

X

[2]


+ 32Q[3]η[t][0] (1 + LQη[t][0] )


Let η[t][0] _≤_


1

16Q max{L,maxm Lm} [. Then we bound (A.84) further:]


_M_

1

E[t][0][ h]F (Θ[t]0[+] ) _F_ (Θ[t][0] ) _η[t][0]_ (1 _mF_ (Θ[t][0] )
_−_ _≤−_ _[Q]2_ _−_ 16[1] 16 16[2][ ))] _∇_

_m=0_

i X _[−]_ [1] _[−]_

+ (LQ[2](η[t][0] )[2] + 8Q[3]L[2]m[(][η][t][0] [)][3][ + 8][Q][4][LL][2]m[(][η][t][0] [)][4][)]


_σm[2]_


_m=0_

_M_

_m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ (A.85)

X

[2]


+ 16Q[3]η[t][0] (1 + LQη[t][0] )


_F_ (Θ[t][0] )

_≤−_ _[Q]2_ _[η][t][0]_ _∇_

[2]

+ (LQ[2](η[t][0] )[2] + 8Q[3]L[2]m[(][η][t][0] [)][3][ + 8][Q][4][LL][2]m[(][η][t][0] [)][4][)]


_σm[2]_


_m=0_

_M_

_m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ (A.86)

X

[2]


+ 32Q[3]η[t][0] (1 + LQη[t][0] )


-----

After some rearranging of terms:

2 _F_ (Θ[t][0] ) − E[t][0] _F_ (Θ[t]0[+] )
_η[t][0]_ _F_ (Θ[t][0] )
_∇_ _≤_ h _Q_ h ii

[2]

+ 2(LQ(η[t][0] )[2] + 8Q[2]L[2]m[(][η][t][0] [)][3][ + 8][Q][3][LL]m[2] [(][η][t][0] [)][4][)]


_σm[2]_


_m=0_

_M_

_m=0_ _Hm[2]_ _[G][2]m_ _Em[t][0]_ _F_ (A.87)

X

[2]


+ 64Q[2]η[t][0] (1 + LQη[t][0] )


Summing over all communication rounds t0 = 0, . . ., R − 1 and taking total expectation:


_R−1_ _η[t][0]_ E _F_ (Θ[t][0] ) _F_ (Θ[0]) − E _F_ (Θ[T] )

_∇_ _≤_ [2] _Q_
_t0=0_   

X h

_R_ 1 [2][i]
_−_

+ 2 (LQ(η[t][0] )[2] + 8Q[2]L[2]m[(][η][t][0] [)][3][ + 8][Q][3][LL]m[2] [(][η][t][0] [)][4][)]

_t0=0_

X


_σm[2]_


_m=0_


+ 64Q[2]η[t][0] (1 + LQη[t][0] ) _Hm[2]_ _[G]m[2]_ _Em[t][0]_ (A.88)

_m=0_ _F_

X

_F_ (Θ[0]) − E _F_ (Θ[T] ) [2]
_≤_ [2] _QR_
  

+ 2 _R−1(QL(η[t][0]_ )[2] + 8Q[2]L[2]m[(][η][t][0] [)][3][ + 8][Q][3][LL]m[2] [(][η][t][0] [)][4][)] _M_ _σm[2]_

_B_

_t0=0_ _m=0_

X X


_R−1_
+ 64Q[2] _η[t][0]_ (1 + LQη[t][0] )

_t0=0_

X


_Hm[2]_ _[G]m[2]_ [E] _Em[t][0]_
_m=0_

X h


(A.89)

(A.90)


Note that:

_M_

_Hm[2]_ _[G]m[2]_ [E] _Em[t][0]_
_m=0_

X h

where (A.91) follows from Definition 1.

Plugging this into (A.89)


_j=m_ E _ϵ[t]j[0]_ _F_ (A.90)

X̸ h i

[2]

_j_ (A.91)
_E_ _[t][0]_
_jX≠_ _m_


_Hm[2]_ _[G][2]_
_m=0_

X

_M_

_Hm[2]_ _[G][2]m_
_m=0_

X


_R−1_ _η[t][0]_ E _F_ (Θ[t][0] ) _F_ (Θ[0]) − E _F_ (Θ[T] )

_∇_ _≤_ [2] _QR_
_t0=0_   

X h

_R_ 1 [2][i]
_−_

+ 2 (QL(η[t][0] )[2] + 8Q[2]L[2]m[(][η][t][0] [)][3][ + 8][Q][3][LL][2]m[(][η][t][0] [)][4][)]

_t0=0_

X


_σm[2]_


_m=0_


_R−1_
+ 64Q[2] _η[t][0]_ (1 + LQη[t][0] )

_t0=0_

X


_Ej[t][0]_ _[.]_ (A.92)
_jX≠_ _m_


_Hm[2]_ _[G][2]m_
_m=0_

X


-----

Suppose that η[t][0] = η for all communication rounds t0. Then, averaging over R communication
rounds, we have:

1 _R−1_ _F_ (Θ[0]) E _F_ (Θ[T] ) _M_ _m_

E _F_ (Θ[t][0] ) _−_ + 2 (QLη + 8Q[2]L[2]m[η][2][ + 8][Q][3][LL][2]m[η][3][)] _[σ][2]_

_R_ _∇_ _≤_ [2] _QRη_ _B_

_t0=0_    _m=0_

X h X

[2][i] _R_ 1 _M_

_−_

+ [64][Q][2] (1 + LQη) _Hm[2]_ _[G][2]m_ _j_ _[.]_ (A.93)

_R_ _E_ _[t][0]_

_tX0=0_ _mX=0_ _jX≠_ _m_

_F_ (Θ[0]) E _F_ (Θ[T] ) _M_ _m_
_−_ + 4 _QLη [σ][2]_
_≤_ [2] _QRη_ _B_
   _m=0_

X


_R−1_

_t0=0_

X


+ [68][Q][2]


+ [68][Q] _Hm[2]_ _[G][2]m_ _j_ _[.]_ (A.94)

_R_ _E_ _[t][0]_

_tX0=0_ _mX=0_ _jX≠_ _m_

where (A.94) follows from our assumption that η[t][0] 16Q max _L,1maxm Lm_
_≤_ _{_ _}_ [. This completes the]

proof of Theorem 1.

We continue our analysis to prove Theorem 2. Starting from (A.92), we bound the left-hand side
with the minimum over all iterations:

_F_ (Θ[0]) E[t][0][ ]F (Θ[T] )
min _F_ (Θ[t][0] ) _−_
_t0=0,...,R−1_ [E] _∇_ _≤_ [2]  _Q_ _t0=0_ _[η][t][0]_ 

+ 2 _QL_ PhRt0Rt−=00−=01 [(]1[η][η][t][0][t][0][)][2] + 8[2][i]Q[2]L[2]m PRt0Rt−=00−=01[P][(]1[η][R][η][t][0][t][−][0][)][1][3] + 8Q[3]LL[2]m PRt0tR−=00−=01 [(]1[η][η][t][0][t][0][)][4] ! _mM=0_ _σBm[2]_

X

_MP_ _tR0−=01_ _[η][t][0][ P]j=Pm_ _j_ _M_ P _tR0−=01_ [(][η][t][0] [)][2][ P]j=m _j_
+ 64Q[2] _Hm[2]_ _[G]m[2]_ _R−1_ _̸_ _[E]_ _[t][0]_ + 64LQ[3] _Hm[2]_ _[G]m[2]_ _R−1_ _̸_ _[E]_ _[t][0]_

_m=0_ P _t0=0_ _[η][t][0]_ _m=0_ P _t0=0_ _[η][t][0]_

X X

(A.95)

P P

As R, if _t0=0_ _[η][t][0][ =][ ∞][,][ P]t[R]0[−]=0[1]_ [(][η][t][0] [)][2][ <][ ∞][, and][ P]t[R]0[−]=0[1] _[η][t][0][ P]j=m_ _j_ _<_, then
_→∞_ _̸_ _[E]_ _[t][0]_ _∞_

mint0=0,...,R−1 E _∥∇F_ (Θ[t][0] )∥[2][i] _→_ 0. This completes the proof of Theorem 2.

[P][R][−][1]

h

A.2 COMMON COMPRESSORS

In this section, we calculate the compression error and parameter bounds for uniform scalar quantization, lattice vector quantization and top-k sparsification, as well as discuss implementation details
of these compressors in C-VFL.

We first consider a uniform scalar quantizer (Bennett, 1948) with a set of 2[q] quantization levels,
where q is the number of bits to represent compressed values. We define the range of values
that quantize to the same quantization level as the quantization bin. In C-VFL, a scalar quantizer quantizes each individual component of embeddings. The error in each embedding of a batch
**B in scalar quantization is** _Pm_ [∆]12[2] [=][ P][m] (hmax−12hmin)[2] 2[−][2][q] where ∆ the size of a quantiza_≤_

tion bin, Pm is the size of the m-th embedding, hmax and hmin are respectively the maximum
and minimum value hm(θm[t] [;][ x][i]m[)][ can be for all iterations][ t][, parties][ m][, and][ x][i]m[. We note that if]
_hmax or hmin are unbounded, then the error is unbounded as well. By Theorem 1, we know that_

_R1_ _Rt0−=01_ _Mm=0_ _[E]m[t][0]_ [=][ O][(][ 1]√T [)][ to obtain a convergence rate of][ O][(][ 1]√T [)][. If we use the same][ q][ for]

all parties and iterations, we can solve for q to find that the value q must be lower bounded by

P P

_q = Ω(log2(Pm(hmax −_ _hmin)[2][√]T_ )) to reach a convergence rate of O( _√[1]T_ [)][. For a diminishing]

compression error, required by Theorem 2, we let T = t0 in this bound, indicating that q, the number
of quantization bins, must increase as training continues.

A vector quantizer creates a set of d-dimensional vectors called a codebook (Zamir & Feder, 1996).
A vector is quantized by dividing the components into sub-vectors of size d, then quantizing each
sub-vector to the nearest codebook vector in Euclidean distance. A cell in vector quantization is


_Hm[2]_ _[G][2]_
_m=0_

X


-----

defined as all points in d-space that quantizes to a single codeword. The volume of these cells are determined by how closely packed codewords are. We consider the commonly applied 2-dimensional
hexagonal lattice quantizer (Shlezinger et al., 2021). In C-VFL, each embedding is divided into
sub-vectors of size two, scaled to the unit square, then quantized to the nearest vector by Euclidean
distance in the codebook. The error in this vector quantizer is 24 where V is the volume of a
_≤_ _[V P][m]_

lattice cell. The more bits available for quantization, the smaller the volume of the cells, the smaller
the compression error. We can calculate an upper bound on V based on Theorem 1: V = O( _Pm1√T_ [)][.]

If a diminishing compression error is required, we can set T = t0 in this bound, indicating that V
must decrease at a rate of O( _Pm1√t0 ). As the number of iterations increases, the smaller V must be,_

and thus the more bits that must be communicated.

In top-k sparsification (Lin et al., 2018), when used in distributed SGD algorithms, the k largest
magnitude components of the gradient are sent while the rest are set to zero. In the case of embeddings in C-VFL, a large element may be as important as an input to the server model as a small
one. We can instead select the k embedding elements to send with the largest magnitude partial
derivatives in _θm_ _hm(θm[t]_ [)][. Since a party][ m][ cannot calculate][ ∇][θ]m[h][m][(][θ]m[t] [)][ until all parties send]
_∇_
their embeddings, party m can use the embedding gradient calculated in the previous iteration,
and thus do not change too rapidly. The error of sparsification is∇θmhm(θm[t][−][1][)][. This is an intuitive method, as we assume our gradients are Lipschitz continuous,] ≤ (1 − _Pkm_ [)(][∥][h][∥][2][)][max][ where]

(∥h∥[2])max is the maximum value of ∥hm(θm[t] [;][ x][i]m[)][∥][2][ for all iterations][ t][, parties][ m][, and][ x][i]m[. Note]
that ifk: k = Ω( (∥h∥P[2]m)max − is unbounded, then the error is unbounded. We can calculate a lower bound on(∥h∥[2]P)maxm _√T_ [)][. Note that the larger][ (][∥][h][∥][2][)][max][, the larger][ k][ must be. More com-]

ponents must be sent if embedding magnitude is large in order to achieve a convergence rate of
_O(_ _√[1]T_ [)][. When considering a diminishing compression error, we set][ T][ =][ t][0][, showing that][ k][ must]

increase over the course of training.

A.3 EXPERIMENTAL DETAILS

For our experiments, we used an internal cluster of 40 compute nodes running CentOS 7 each with
2× 20-core 2.5 GHz Intel Xeon Gold 6248 CPUs, 8× NVIDIA Tesla V100 GPUs with 32 GB
HBM, and 768 GB of RAM.

A.3.1 MIMIC-III

[The MIMIC-III dataset can be found at: mimic.physionet.org. The dataset consists of time-series](https://mimic.physionet.org/)
data from ∼60,000 intensive care unit admissions. The data includes many features about each
patient, such as demographic, vital signs, medications, and more. All the data is anonymized. In
order to gain access to the dataset, one must take the short online course provided on their website.

Our code for training with the MIMIC-III dataset can be found in in the folder titled “mimic3”.
[This is an extension of the MIMIC-III benchmarks repo found at: github.com/YerevaNN/mimic3-](https://github.com/YerevaNN/mimic3-benchmarks)
[benchmarks. The original code preprocesses the MIMIC-III dataset and provides starter code for](https://github.com/YerevaNN/mimic3-benchmarks)
training LSTMs using centralized SGD. Our code has updated their existing code to TensorFlow 2.
The new file of interest in our code base is “mimic3models/in hospital mortality/quant.py” which
runs C-VFL. Both our code base and the original are under the MIT License. More details on
installation, dependencies, and running our experiments can be found in “README.md”. Each
experiment took approximately six hours to run on a node in our cluster.

The benchmarking preprocessing code splits the data up into different prediction cases. Our experiments train models to predict for in-hospital mortality. For in-hospital mortality, there are 14,681
training samples, and 3,236 test samples. In our experiments, we use a step size of 0.01, as is
standard for training an LSTM on the MIMIC-III dataset.

A.3.2 MODELNET10

Details on the ModelNet10 dataset can be found at: [modelnet.cs.princeton.edu/.](https://modelnet.cs.princeton.edu/) The
specific link we downloaded the dataset from is the following Google Drive link:
[https://drive.google.com/file/d/0B4v2jR3WsindMUE3N2xiLVpyLW8/view. The dataset consists of](https://drive.google.com/file/d/0B4v2jR3WsindMUE3N2xiLVpyLW8/view)
3D CAD models of different common objects in the world. For each CAD model, there are 12 views


-----

from different angles saved as PNG files. We only trained our models on the following 10 classes:
bathtub, bed, chair, desk, dresser, monitor, night stand, sofa, table, toilet. We used a subset of the
data with 1,008 training samples and 918 test samples. In our experiments, we use a step size of
0.001, as is standard for training a CNN on the ModelNet10 dataset.

Our code for learning on the ModelNet10 dataset is in the folder “MVCNN Pytorch” and is an
[extension of the MVCNN-PyTorch repo: github.com/RBirkeland/MVCNN-PyTorch. The file of](https://github.com/RBirkeland/MVCNN-PyTorch)
interest in our code base is “quant.py” which runs C-VFL. Both our code base and the original are
under the MIT License. Details on how to run our experiments can be found in the “README.md”.
Each experiment took approximately six hours to run on a node in our cluster.

A.4 ADDITIONAL EXPERIMENTS

In this section we provide some additional experiments to test the scalability of C-VFL for a larger
number of parties and larger datasets.

First, we run C-VFL using the same parameters as described in Section 5, now with 48 parties and a
server with the ModelNet10 dataset. Each 3D CAD model in the ModelNet10 dataset has 12 views,
so we assign every four parties the same view, and have each store a different quadrant of the image.

(a) Plotted by epochs (b) Plotted by cost (c) Vector quantization

Figure A.1: Test accuracy on ModelNet10 dataset with the number of parties M = 48. In the first
two plots, the compressors have b = 2, where b is the number of bits used to represent embedding
components. In the third plot, b = 32 indicates there is no compression. The results show little
variation between compressors and no compression, leading to a large benefit in communication
cost versus test accuracy.

In Figure A.1, we plot the test accuracy for the ModelNet10 dataset. The test accuracy is overall
lower than when running with 4 and 12 parties. This is expected, as each party has less information
individually, making the prediction task more difficult. Figure A.1a shows the test accuracy plotted
by epochs. There is very little variation between compressors and no compression here. This leads
to a very large benefit for compression when plotting by communication cost, seen in Figure A.1b.
In Figure A.1c, we plot the test accuracy of C-VFL using vector quantization for different values of
_b, the number of bits to represent compressed values. Similar to previous results, lower b tends to_
improve test accuracy reached with the same amount of communication cost. We can also see that
the total cost of communication has increased compared to the case of 4 and 12 parties in Figure 3.
This is expected, as there are more embeddings being exchanged in each global round.

We also run C-VFL on CIFAR-10, a large dataset of 60,000 images with 10 classes of objects
and animals. To simulate a VFL scenario with the CIFAR-10 dataset, we split the images into 4
quadrants and run C-VFL with 4 parties and a server. Each party trains ResNet-18 locally, and the
server model is a single fully-connected layer.


-----

(a) Plotted by epochs (b) Plotted by cost (c) Vector quantization

Figure A.2: Test accuracy on CIFAR-10 dataset with the number of parties M = 4. In the first
two plots, the compressors have b = 2, where b is the number of bits used to represent embedding
components. In the third plot, b = 32 indicates there is no compression. The results show vector
quantization performs the best our of the compressors, and all compressors show improvement over
no compression in terms of communication cost to reach target test accuracies.

In Figure A.2, we plot the test accuracy for the CIFAR-10 dataset. The test accuracy is fairly
low compared to typical baseline accuracies, which is expected, as learning object classification
from only a quadrant of a 32 × 32 pixel image is difficult. Figure A.2a shows the test accuracy
plotted by epochs. We can see that vector quantization performs almost as well as no compression
in the CIFAR-10 dataset. When plotting by communication cost, seen in Figure A.2b, we can
see that vector quantization performs the best, though scalar quantization and top-k sparsification
show communication savings as well. In Figure A.2c, we plot the test accuracy of C-VFL using
vector quantization for different values of b, the number of bits to represent compressed values.
Similar to previous results, lower b tends to improve test accuracy reached with the same amount of
communication cost.

A.5 ADDITIONAL PLOTS

In this section, we include additional plots using the results from the experiments introduced in
Section 5 of the main paper. The setup for the experiments is described in the main paper. These
plots provide some additional insight into the effect of each compressor on convergence in both
datasets. As with the plots in the main paper, the solid lines in each plot are the average of five runs
and the shaded regions represent the standard deviation.

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.3: Training loss on MIMIC-III dataset. One can see that, with the exception of top-k
sparsification, allowing more bits for compression moves the training loss closer to the baseline of
no compression. Top-k appears to be more unstable in the MIMIC-III dataset.


-----

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.4: Test F1-Score on MIMIC-III dataset. Scalar and vector quantization achieve similar
test F1-score even when only using 2 bits in quantization. On the other hand, top-k sparsification
performs worse than the other compressors in the MIMIC-III dataset.

Figures A.3 and A.4 plot the training loss and test F1-Score for training on the MIMIC-III dataset
for different levels of compression. We can see that scalar and vector quantization perform similarly
to no compression and improve as the number of bits available increase. We can also see that top-k
sparsification has high variability on the MIMIC-III dataset and generally performs worse than the
other compressors.

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.5: Test F1-Score on MIMIC-III dataset plotted by communication cost. We can see that
all compressors reach higher F1-scores with lower communication cost than no compression. We
can see that the standard deviation for each compressor decreases as the number of bits available
increases. Top-k sparsification generally performs worse than the other compressors on the MIMICIII-dataset.

(a) Scalar quantization (b) Vector quantization (c) Top-k sparsification

Figure A.6: Test F1-Score on MIMIC-III dataset plotted by communication cost. We can see that
all compressors reach higher F1-scores with lower communication cost than no compression. We
can see that the standard deviation for each compressor decreases as the number of bits available
increases. Top-k sparsification generally performs worse than the other compressors on the MIMICIII-dataset.

Figures A.5 and A.6 plot the test F1-Score for training on the MIMIC-III dataset plotted against the
communication cost. The plots in Figure A.5 include all compression techniques for a given level of


-----

compression, while the plots in Figure A.6 include all levels of compression for a given compression
technique. We can see that all compressors reach higher F1-scores with lower communication cost
than no compression. It is interesting to note that increasing the number of bits per parameter reduces
the variability in all compressors.

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.7: Training loss on ModelNet10 dataset. Vector quantization and top-k sparsification perform similarly to no compression, even when only 2 bits are available. Scalar quantization converges
to a higher loss and has high variability on the ModelNet10 dataset.

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.8: Test accuracy on ModelNet10 dataset. Vector quantization and top-k sparsification perform similarly to no compression, even when only 2 bits are available. Scalar quantization converges
to a lower test accuracy, and has high variability on the ModelNet10 dataset.

Figures A.7 and A.8 plot the training loss and test accuracy for training on the ModelNet10 dataset.
Vector quantization and top-k sparsification perform similarly to no compression in both training
loss and test accuracy, even when only 2 bits are available. We can see that scalar quantization has
high variability on the ModelNet10 dataset.

(a) 2 bits per parameter (b) 3 bits per parameter (c) 4 bits per parameter

Figure A.9: Test accuracy on ModelNet10 dataset plotted by communication cost. We can see that
all compressors reach higher accuracies with lower communication cost than no compression. Scalar
quantization generally performs worse than the other compressors on the ModelNet10 dataset.


-----

(a) Scalar quantization (b) Vector quantization (c) Top-k sparsification

Figure A.10: Test accuracy on ModelNet10 dataset plotted by communication cost. We can see that
all compressors reach higher accuracies with lower communication cost than no compression. We
can see that when less bits are used in each compressor, higher test accuracies are reached at lower
communication costs. Scalar quantization generally performs worse than the other compressors on
the ModelNet10 dataset.

Figures A.9 and A.10 plot the test accuracy for training on the ModelNet10 dataset against the communication cost. The plots in Figure A.9 include all compression techniques for a given level of
compression, while the plots in Figure A.10 include all levels of compression for a given compression technique. We can see that all compressors reach higher accuracies with lower communication
cost than no compression. Scalar quantization generally performs worse than the other compressors
on the ModelNet10 dataset. From Figure A.10, we also see that when fewer bits are used in each
compressor, higher test accuracies are reached at lower communication costs.


-----


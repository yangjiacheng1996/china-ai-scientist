# FEDERATED LEARNING FRAMEWORK BASED ON
## TRIMMED MEAN AGGREGATION RULES

**Anonymous authors**
Paper under double-blind review

ABSTRACT

This paper studies the problem of information security in the distributed learning framework. In particular, we consider the clients will always be attacked
by Byzantine nodes and poisoning in the federated learning. Typically, aggregation rules are utilized to protect the model from the attacks in federated learning.
However, classical aggregation methods such as Krum(·) and Mean(·) are not
capable enough to deal with Byzantine attacks in which general deviations and
multiple clients are attacked at the same time. We propose new aggregation rules,
Tmean(·), to the federated learning algorithm, and propose a federated learning
framework based on Byzantine resilient aggregation algorithm. Our Tmean(·)
rules are derived from Mean(·) by appropriately trimming some of the values
before averaging them. Theoretically, we provide theoretical analysis and understanding of Tmean(·). Extensive experiments validate the effectiveness of our
approaches.

1 INTRODUCTION

As one special case of distributed machine learning, federated learning (FL) draws increasing research attention recently. FL has become one promising approach to enable clients collaboratively
to learn a shared model with the decentralized and private data on each client node. Thus it is of
central importance to keep the node information secured in FL. Unfortunately, FL is very vulnerable to software/hardware errors and adversarial attacks; especially Byzantine attack from distributed
systems has arose to be a key node attack sample for federated learning.

To ensure the FL model resistance to Byzantine attack, research focuses are made on how to intro_duce aggregation rules into the gradient information iteration process, and how to ensure that this_
_aggregation rule can make the data robust. In particular, classical approaches to avoid the Byzan-_
tine failures would employ the state machine replication strategy (Alistarh et al., 2018), which can
be roughly categorized into two ways in distributed machine learning: (1) the processes agree on a
sample of data based on which the clients update their local parameter vectors; (2) the clients agree
on how the parameter vector should be updated (Blanchard et al., 2017). The former ones demand
transmitting data samples to each individual node, resulting in high costs. The latter ways are not reliable neither, as we cannot detect whether clients are trustworthy or not, from the mixed Byzantine
vectors. The attacker can know any information about the process of FL, and can use any vectors to
initiate the attack during the node’s information transmission (Yin et al., 2018). More specifically,
the data between machines can be replaced by any value. This problem is not fully addressed in
previous works.

When facing the attacks from Byzantine nodes, the FL models have to rely on robust aggregation
rules to minimize the influence of the Byzantine attack on the data model (Bottou, 2010). For instance, Krum(·) is a strong aggregation rule designed to identify an honest node such that it can
effectively prevent Byzantine attacks in most cases (Blanchard et al., 2017). However, if the Byzantine node attack is changed from the original single miner node attack to multiple server attacks,
Krum(·) is not able to ensure the learning process robustness to noisy data. As another class of
aggregation rules, simple mean-based aggregation rules can maintain learning robustness if it is not
attacked by Byzantine nodes. However, the Byzantine attack will make the update direction of node
gradient information largely deviate from the original function by using simple mean-based aggregation rules. Some variants of mean-based aggregation rules, such as geometric median (Blanchard


-----

(a) Federated learning gradient update iteration (b) SGD gradient update

Figure 1: (a) is the procession of FL gradient updating. It consists of four parts: master server, master
server distributed network, miner servers and miner network. (b) represents the schematic diagram
of the gradient update direction: blue dashed lines represent the estimated gradients of miner nodes;
red dashed lines represent the Byzantine update gradients under the attack of the Byzantine nodes;
black solid line represents the ideal gradient.

et al., 2017), marginal median (Alistarh et al., 2018), are the classical methods to solve the Byzantine
node attack problem. But they are not much more robust than simple mean-based aggregation rules
in the case of some large deviation Byzantine attacks. The main difficulty that prevents mean-based
aggregation rules from robust is the unstable distribution of data (Jin et al., 2020). We find that the
difficulty can be tackled, if the data is averaged by trimming a part of the data and then imported
into the aggregation rules. This motivates our work in this paper.

Most of FL approaches are built upon the Stochastic Gradient Descent (SGD) algorithm (Castro
et al., 1999) or its variants, and the statistical properties of SGD such as convergence are well
developed. Our approach also employs the SGD; and the typical iterative process of SGD algorithm
in distributed system is represented by Figure 1. First, a client, known as a miner node, estimates
the gradient of the node, makes an estimate of the deviation between the estimated information and
the ideal gradient information (El-Mhamdi et al., 2020), then passes this information to the server
node in the network, and finally update the gradient there. So the miner node network transmits the
information to the master server, and the master server then passes the gradient update information
through a series of aggregation operations. When the aggregation conditions are met, the server
transmits the information to the distribution network, and then transmitted to the miner nodes. This is
a cyclic process, such that the gradient information is continuously updated in the entire network (Li
et al., 2014).

In this paper, we mainly propose new aggregation rules, Tmean(·), by trimming part of the data
before the average operation. We provide theoretical understandings of our aggregation rules, especially, why they are robust to the Byzantine attack. Through attack experiments and mathematical
proofs, we have concluded that appropriately trimming the original data and averaging can make the
model more robust from the decentralized data.

Specifically, in section 3 we introduce the federated learning Byzantine distributed system model,
briefly describes the working principle of SGD, and summarizes the update iteration rules based
on aggregation rules. Then, we present the concept of Byzantine resilience, and the conditions to
satisfy the aggregation rules of Byzantine resilience. We provide concept of trimmed mean and
the rigorous theoretical proof and understanding of Tmean(·) based aggregation rules in section 4.
Then, we prove the convergence of the proposed federated learning aggregation rules in section 5.
In section 6, we conduct experiments by Gaussian attack, omniscient attack and multiple servers
attack. Under these attacks, Tmean(·)-based FL aggregation rules can still maintain robustness.
These experiments thus validate the effectiveness of our approaches.


-----

**Contributions:** (1) We present new aggregation rules, Tmean(·), to the Byzantine resilient federated learning algorithm, and propose federated learning frameworks based on aggregation algorithm.
Our proposed approaches are shown to be robust to Byzantine attacks.

(2) We provide rigorous theoretical proof and understanding of our approaches and aggregation
rules. To the best of our knowledge, these theorems and theoretical understandings are for the first
time contributed to the community. Critically, we make convergence certificates and prove that
Tmean(·) can converge in the general convex optimization setting.

(3) Empirically, we demonstrate that the effectiveness of our approaches can make the FL model
robust to Byzantine attack.

2 RELATED WORK

**Federated Learning.** Federated learning has become a prominent distributed learning paradigm.
In (Jin et al., 2020), the authors proposed Stochastic-Sign SGD, a parameter estimation method
with convergence guarantees. It uses a gradient compressor based on random symbols to unify that
the gradient is updated in the framework. The FedAvg algorithm was first proposed by (Koneˇcn`y
et al., 2016), and many scholars subsequently improved it based on this algorithm. (Karimireddy
et al., 2020) pointed out that FedAvg can be improved by adding one additional parameters control
variables to correct the client drift, and proved that FedAvg may be seriously affected by the gradient
difference of different clients, and may even be slower than SGD.

**Byzantine attack in FL.** To make the secure transmission of the master server node, the FL models have to deal with the Byzantine attack. (Yin et al., 2018) showed that certain aggregation rules
in the master server node can ensure the robustness of the data. (Blanchard et al., 2017) pointed out
that Krum(·) can be used to make the robustness of data by computing the local sum of squared
Euclidean distance to the other candidates, and outputting the one with minimal sum. When the gradient is updated to the saddle point, there is no guarantee that the SGD algorithm converges to the
global optimum. Some scholars have proposed ByzantinePGD (Yin et al., 2019), which can escape
saddle points and false local minimums, and can converge to an approximate true local minimum
with low iteration complexity. Later, in the strong anti-Byzantine model, some scholars carried out
poisoning attacks on Byzantine robust data, from the original data collection process to the subsequent information exchange process, and at the same time, these attacks were defended accordingly,
in (Zhao et al., 2021). The research on the Byzantine structure model of federated learning has been
expanded once again (Zhao et al., 2021).

**Attack and Defence.** In the framework of federated learning, miner nodes are usually attacked,
such as Byzantine node attacks, poisoning attacks (Zhao et al., 2021), gradient leakage (Wei et al.,
2020), etc. There exist various defense methods also, such as robust aggregation, secure aggregation,
encryption, etc. Our paper mainly studies Byzantine node attacks. Byzantine node attacks can
usually be summarized into two types: (1) To update gradient information of nodes, nodes are
replaced by Byzantine nodes, and normal worker nodes cannot make judgments so that the gradient
estimates deviate from the actual gradient update direction. (2) During the gradient process, the local
node suffering from the interference of the Byzantine node, cannot reach a consensus with the master
node, making the entire process unable to proceed normally (Lamport et al., 2019). Krum(·) is a
popular aggregation rule to deal with these node attacks. We shall propose Tmean(·) as alternative
aggregation rules.

3 PRELIMINARY AND PROBLEM SETUP

3.1 FEDERATED LEARNING SETTING

Federated learning was first proposed in (Koneˇcn`y et al., 2016), where the prevalent asynchronous
SGD is used to update a global model in a distributed fashion. A pioneering work in this field
proposed the currently most widely used algorithm, FedAvg (McMahan et al., 2017), which is also
the first synchronous algorithm dedicated to federated setting. Recent studies attempt to expand
federated learning with the aim of providing learning in more diverse and practical environments


-----

**Algorithm 1: Distributed synchronous SGD with robust aggregation server.**

**Server:**
Initialize x0 `rand();`
**for t = 0, 1, ← . . ., T do**

Broadcast x[(][t][)] to all the workers;
Wait until all the gradients ˜v1[(][t][)][,][ ˜]v2[(][t][)][,][ . . .][,][ ˜]vm[(][t][)] [arrive;]
Compute G[(][t][)] = Aggr(˜v1[(][t][)][,][ ˜]v2[(][t][)][, . . .,][ ˜]vm[(][t][)][)][;]
Update the parameter x[(][t][+1)] _←_ _x[(][t][)]_ _−_ _γ[(][t][)]G[(][t][)];_
**end**

**Worker:**
**for t = 0, 1, . . ., T do**

Receive x[(][t][)] from the server;
Compute and send the local randomized gradient v[(][t][)] = _F_ (x[(][t][)], ξk) to the server;
_∇_
**end**


such as multi-task learning, generative models, continual learning, and data with noisy labels. However, these algorithms may obtain suboptimal performance when miners participating in FL have
non-independently and identical distributions (non-i.i.d.) (Zhao et al., 2018).

While the convergence of FedAvg on such settings was initially shown by experiments in (McMahan
et al., 2017), it does not guarantee performance as good as that in an i.i.d. setting. These algorithms
pointed out the issue have major limitations, such as privacy violation by partial global sharing of
local data (Zhao et al., 2018) or no indication of improvement over baseline algorithms such as
FedAvg (Hsieh et al., 2020). Our paper focuses on a general federated setting.

In order to better study the problem of aggregation in federated learning, we consider the following
optimization problem:
min (1)
_x_ R[d][ F] [(][x][)][,]
_∈_

where F (x) = Eξ∼D[f (x; ξ)] is a smooth convex function, ξ is sampled from some unknown distribution D. Ideally, the problem (1) can be solved by the gradient descent method as

_x[(][t][+1)]_ _←_ _x[(][t][)]_ _−_ _γ[(][t][)]∇F_ (x[(][t][)]), (2)

where γ[(][t][)] is the learning rate at t-th round. We assume that there exists at least one minimizer of
_F_ (x), denoted by x[∗], that satisfies ∇F (x[∗]) = 0.

The problem (1) is solved in a distributed manner with m miner nodes, and up to q of them may
be Byzantine nodes. The detailed algorithm of distributed synchronous SGD with aggregation rule
Aggr(·) is shown in Algorithm 1. In each iteration, each miner samples n i.i.d. data points from the
distribution D, and computes the gradient of the local empirical loss. Using a certain aggregation
rule Aggr(·), the server collects and aggregates the gradients sent by the miners, and estimate the
gradient through _F_ (x[(][t][)]) Aggr(v1, v2, . . ., vm). Without Byzantine failures, the k-th worker
_∇_ _≈_
calculates vk[(][t][)] _G[(][t][)], where G[(][t][)]_ = _f_ (x[(][t][)], ξ). When there exist Byzantine faults, vk[(][t][)] can be
_∼_ _∇_
replaced by any arbitrary value ˜vk[(][t][)][, and hence]

_F_ (x[(][t][)]) Aggr(˜v1, ˜v2, . . ., ˜vm). (3)
_∇_ _≈_

3.2 BYZANTINE RESILIENCE

In the following we introduce the concept of Byzantine resilience. Suppose that in a specific iteration, the correct vectors v1, v2, . . ., vm are i.i.d. samples drawn from the random variable
_G =_ _f_ (x; ξk), where E[G] = g is an unbiased estimator of the gradient based on the current
_∇_
parameter x. Thus, E[vk] = E[G] = g for k 1, 2, . . ., m . We simplify the notations by omitting
_∈{_ _}_
the index of iteration t. The following Definition 1 defines the concept of ∆-Byzantine resilience.
For simplicity, we sometimes use Byzantine resilient in short when the concrete value of ∆ is either
clear from the context or not important.


-----

**Definition 1 (Byzantine Resilience). Suppose that 0 ≤** _q ≤_ _m, and ∆_ _is a given positive number._
_Letv˜m be v1 attacked, v2, . . ., copies of vm be i.i.d. random vectors in vk’s, such that at least R m[d] −, whereq of which are equal to the corresponding vk ∼_ _G with E[G] = g. Let ˜v1, ˜v2, v . . .k’s,_
_while the rest are arbitrary vectors in R[d]. An aggregation rule Aggr(·) is said to be ∆-Byzantine_
resilient if
E Aggr(˜v1, ˜v2, . . ., ˜vm) _g_ ∆.
_∥_ _−_ _∥[2][]_ _≤_


4 FL FRAMEWORK WITH ROBUST AGGREGATION

Nowadays, the aggregation rules based on the FL framework are mainly based on Krum(·) and
Mean(·). They are usually used in the defense of Byzantine node attacks. However, the aggregation
rules based on Mean(·) often cannot exhibit strong robustness, if it is affected by Byzantine nodes.
The attack makes the gradient estimation direction deviate too far from the actual gradient update
direction; and it cannot guarantee the robustness of the data. Thus we shall propose trimmed meanbased aggregation rules to resolve this issue.

4.1 KRUM

The Krum rule is a strong aggregation rule that attempts to identify an honest computing node, and
discards the data of other computing nodes. The data from the identified honest computing node is
used in the next round of algorithm. The selection strategy is to find one whose data is closest to that
on other computing nodes. In other words, it computes the local sum of squared Euclidean distances
to the other candidates, and outputs the one with minimal sum. A notable property of Krum(·) is
shown in Lemma 1.
_vLemma 1k ∼_ _G with ((Blanchard et al., 2017)) E[G] = g and E_ _∥G −_ _g. Let∥[2]] ≤ v1V, . Let . . ., v ˜vm1, ∈ ˜v2,R . . .[d]_ _be any i.i.d. random vectors such that, ˜vm be attacked copies of vk’s, where_
_up to q of them are Byzantine. If 2q + 2 < m, then Krum(_ ) is ∆0-Byzantine resilient, where
 _·_

∆0 = 6m 6q + [4][q][(][m][ −] _[q][ −]_ [2) + 4][q][2][(][m][ −] _[q][ −]_ [1)] _V._
_−_ _m_ 2q 2
 _−_ _−_ 

4.2 MEAN-BASED AGGREGATION RULES


An important class of aggregation rules is mean-based aggregation rules. Mathematically, an aggregation rule Aggr( ) is a mean-based one if Aggr(v1, v2, . . ., vm) is guaranteed to be a convex

_·_
combination of v1, v2, . . ., vm. Roughly speaking, a mean-based rule produces an averaged value
of the input data. For instance, the arithmetic mean Mean(v1, v2, . . ., vm) = _m1_ _mk=1_ _[v][k][ is the]_

simplest mean-based aggregation rule. However, simple mean-based aggregation rules are in general not robust under Byzantine attacks, in the sense that they do not satisfy Byzantine resilienceP
conditions (Yin et al., 2018).

In the following, we show that by carefully handling the data, certain mean-based rules can satisfy
Byzantine resilience conditions. We first introduce the concept of b-trimmed means based on order
statistics as in Definition 2. This concept is closely related to the coordinate-wise trimmed mean
defined in (Yin et al., 2018).
**Definition 2. Let u1, u2, . . ., um be scalars whose order statistics is**

_u(1)_ _u(2)_ _u(m)._
_≤_ _≤· · · ≤_

_For an integer b with 0 ≤_ _b < m/2, the b-trimmed mean of u1, u2, . . ., um is defined as_

1 _m−b_
Tmeanb(u1, u2, . . ., um) = _m_ 2b _u(k)._

_−_ _k=b+1_

X


_in the component-wise sense, i.e.,For d-vectors v1, v2, . . ., vm ∈_ R[d], the b-trimmed mean Tmeanb(v1, v2, . . ., vm) ∈ R[d] _is defined_


Tmeanb(v1, v2, . . ., vm) =


_ei_ Tmeanb _v1, ei_ _,_ _v2, ei_ _, . . .,_ _vm, ei_
_i=1_ _·_ _⟨_ _⟩_ _⟨_ _⟩_ _⟨_ _⟩_

X  


-----

_where ei is the i-th column of the d × d identity matrix._

Intuitively, aggregation rules using b-trimmed means have opportunities to discard abnormal values
from the input data. Lemma 2 shows that b-trimmed means are usually within a meaningful range
under mild assumptions.
**Lemma 2. Let u1, u2, . . ., um be scalars whose order statistics is**

_u(1)_ _u(2)_ _u(m),_
_≤_ _≤· · · ≤_

_and ˜u1, ˜u2, . . ., ˜um be attacked copies of u1, u2, . . ., um with up to q Byzantine elements. If the_
_order statistics of ˜uk’s is_
_u˜(1)_ _u˜(2)_ _u˜(m),_
_≤_ _≤· · · ≤_

_then for q ≤_ _b < m/2, we have_

_u(k−b) ≤_ _u(k−q) ≤_ _u˜(k) ≤_ _u(k+q) ≤_ _u(k+b),_ (b + 1 ≤ _k ≤_ _m −_ _b)._

_Proof. Let ˜u(k0) be the largest non-Byzantine element in {u˜(1), ˜u(2) . . ., ˜u(k)}. Since the number of_
Byzantine elements is less than or equal to q, we have ˜u(k) _u˜(k0)_ _u(k_ _q)_ _u(k_ _b) if k_ _b_ +1.
The proof of ˜u(k) ≤ _u(k+q) ≤_ _u(k+b) for k ≤_ _m −_ _b is similar. ≥_ _≥_ _−_ _≥_ _−_ _≥_

With the help of Lemma 2, we can prove that Tmeanb( ) is Byzantine resilient when b is greater or

_·_
equal to the number of Byzantine nodes. The result is formulated as Theorem 1.
**Theorem 1.E[G −** _g][2]_ _≤ LetV . Let v1, ˜ . . .v1, ˜,v v2, . . .m ∈, ˜vRm[d] be attacked copies ofbe i.i.d. random vectors such that vk’s, where up to vk ∼ q of them are Byzantine.G with E[G] = g and_
_If q_ _b < m/2, then Tmeanb(_ ) is ∆1-Byzantine resilient, where
_≤_ _·_

_mV_
∆1 =

(m _b)[2][ .]_
_−_

_Proof. See the Appendix._

The exact time complexity for evaluating Tmeanb(˜v1, ˜v2, . . ., ˜vm) has no closed-form expression in
terms of (m, b, d). However, by sorting in each dimension, we can evaluate Tmeanb(˜v1, ˜v2, . . ., ˜vm)
using O(dm log m) operations. The cost is almost linear in practice, and is not much more expensive
than evaluating Mean(·). Hence, Tmean(·) improves the robustness with only negligible overhead
compared to Mean(·).

5 CONVERGENCE ANALYSIS

In this section, we conduct a convergence analysis for SGD using a Byzantine resilient aggregation
rule, such as Krum(·) and Tmean(·). Since a general convex optimization setting is used, we quote
some classic convex analysis theories (see, e.g., (Bubeck, 2014)), as shown in Lemma 3.
**Lemma 3. Let F : R[d]** _→_ R be a µ-strongly convex and L-smooth function. Then for x, y ∈ R[d] _and_
_α ∈_ [0, 1], one has

_F_ (x) _F_ (y), x _y_ _αµ_ _x_ _y_ + [1][ −] _[α]_ _F_ (x) _F_ (y) _._
_⟨∇_ _−∇_ _−_ _⟩≥_ _∥_ _−_ _∥[2]_ _L_ _∥∇_ _−∇_ _∥[2]_

_Proof. The µ-strong convexity and L-smoothness of F_ (x) implies


_⟨∇F_ (x) −∇F (y), x − _y⟩≥_ _µ∥x −_ _y∥[2],_

_F_ (x) _F_ (y), x _y_
_⟨∇_ _−∇_ _−_ _⟩≥_ _L[1]_ _[∥∇][F]_ [(][x][)][ −∇][F] [(][y][)][∥][2][.]

The conclusion is a simple convex combination of these inequalities.

Using Lemma 3 we establish the convergence of SGD as shown in Theorem 2. The expected error
bound consists of a linear convergence term similar to that for usual gradient descent methods, and a
term caused by randomness. The theorem also suggests theoretically the largest step size: γ = L[−][1].


-----

|Col1|Table 1: Structure of MLP.|
|---|---|
|Layer type|Flatten->fc1->relu1->fc2->relu2->fc3->softmax|
|Parameters|Null->#output128->null>#output128->null->#output10->null|
|Previous Layer|data->flatten->fc1->relu1->fc2->relu2->fc3|


Table 2: Experiment Summary.

data set #train #test #rounds _γ_ Batch size Evaluation metric

MNIST 60,000 10,000 600 0.1 32 Top-1 accuracy
CIFAR10 50,000 10,000 3,000 5 × 10[−][4] 128 Top-3 accuracy

**Theorem 2. Suppose that the SGD method with (3) is adopted to solve problem (1), where**
_F : R[d]_ _→_ R is a µ-strongly convex and L-smooth function. Let v1[(][t][)][,][ . . .][,][ v]m[(][t][)] _[be local gradi-]_
_ents at t-th iteration, and ˜v1[(][t][)][,][ . . .][,][ ˜]vm[(][t][)]_ _[be the corresponding attacked copies. If the aggregation]_
_rule Aggr(·) is ∆-Byzantine resilient, and the step size γ satisfies γ ≤_ _L[−][1], then_

E _x[(][t][)]_ _x[∗]_ _η[t]_ _x[(0)]_ _x[∗]_ + [1 +][ √][1][ −] _[γµ]_ _√∆,_
_∥_ _−_ _∥_ _≤_ _∥_ _−_ _∥_ _µ_
 


_where x[∗]_ _is the exact solution, and_

_Proof. See the Appendix._


1
_−_ _L[µ]_ _[.]_


_η =_


1 − _γµ ≥_


We remark that if we allow a general α ∈ [0, 1] in the proof of Theorem 2 and adjust the corresponding step size as γ ≤ 2(1 − _α)L[−][1], the decay ratio η is then bounded through_

_η =_ 1 2αγµ 1 4α(1 _α)_ _[µ]_ 1

_−_ _≥_ _−_ _−_ _L_ _−_ _L [µ]_ _[.]_
r _[≥]_ r

p

The optimal lower bound is achieved when α = 1/2 and γ = L[−][1].

6 EXPERIMENTS

In this section we verify the robustness and convergence of Tmean aggregation rules by experiments. We use a multi-layer perceptron with two hidden layers to handwritten digits classification
on the MNIST data set, in m = 20 worker processes, we repeat each experiment for ten times and
take the average value. Table 1 shows the detailed network structures of the MLP used in our experiments. Then, we conduct recognition on convolutional neural network in the Cifar10 dataset,
repeat each experiment for ten times and report the averaged value. In our experiments, we use
Mean(·) without Byzantine attack as a reference. We use top-1 or top-3 accuracy on testing sets as
the evaluation metrics. Table 2 lists the details of the data set and the default hyper-parameters for
the corresponding model. Our experiments are implemented by Python 3.7.4 with packages TensorFlow 2.4.1 and NumPy 1.19.2, on a physical node Intel i7-9700 CPU with 32 GB of memory and
two NVIDIA GeForce RTX 1080 Ti.

6.1 EXPERIMENT SETTING

In our experiment setting, 6 out of the 20 vectors are Byzantine vectors (i.e., m = 20, q = 6),
different values of b will affect different convergence performance. For the MNIST dataset, we take
_b = 6 and b = 8 to train the experiment; and we take b = 8 on the Cifar10 dataset to conduct_
recognition task.

6.2 GAUSSIAN ATTACK

In Gaussian attack experiment, We use the Gaussian random vector with zero mean and isotopic
covariance matrix with standard deviation 200 instead of some correct gradient vectors.


-----

From Table 3 for the MNIST dataset, we find that compared with Mean(·) without Byzantine,
Tmeanb( ) works well, and is more robust when b = 8. However, without trimming the data,

_·_
Mean(·) is not robust under Byzantine attack. The method of Krum(·) is also robust, while it is
relatively weaker than Tmean(·).

For the Cifar10 dataset, we set b = 8. From Table 4, the aggregation rule based on the Mean(·) is
not as robust as other aggregation rules, but after trimming the Mean(·), the output is more robust
than before.

Table 3: Accuracy of different aggregations under Gaussian attack in MLP.

|Aggregation rule|Number of iterations 100 150 200 250 300 350 400 450 500 550 600|
|---|---|
|Mean without Byzantine Krum Mean Tmean(b = 6) Tmean(b = 8)|0.87 0.88 0.89 0.89 0.90 0.90 0.91 0.91 0.92 0.92 0.93 0.71 0.82 0.85 0.86 0.87 0.87 0.88 0.89 0.88 0.89 0.89 0.63 0.62 0.62 0.63 0.64 0.64 0.64 0.65 0.65 0.65 0.66 0.80 0.82 0.83 0.84 0.84 0.85 0.85 0.86 0.86 0.86 0.87 0.82 0.85 0.88 0.89 0.89 0.91 0.89 0.90 0.91 0.91 0.92|



Table 4: Accuracy of different aggregations under Gaussian attack in Cifar10.

|Aggregation rule|Number of iterations 500 1000 1500 2000 2500 3000|
|---|---|
|Mean without Byzantine Krum Mean Tmean(b = 8)|0.63 0.71 0.73 0.75 0.77 0.79 0.62 0.70 0.72 0.75 0.76 0.78 0.51 0.55 0.56 0.57 0.57 0.58 0.62 0.71 0.73 0.74 0.76 0.77|



6.3 OMNISCIENT ATTACK

Assuming that the attackers (Byzantine nodes) know all the correct gradients information. For each
Byzantine gradient vector, all correct gradients of the gradient are replaced by their negative sum.
In other words, this attack attempts to make the parameter server go into the opposite direction.

For the MNIST dataset, we see from Table 5 that when the Byzantine node makes the gradient
update direction deviate from the maximum actual update direction, Mean(·) cannot be robust. On
the contrary, Krum(·) is more robust, while Tmean(·) shows only weak robustness. Because trim
is a part of the data intercepted from the mean value for aggregation, it removes the head and tail
parts of the entire data set; such that it does not decrease much compared to the overall set mean
accuracy when it is attacked by Byzantine.

For the Cifar10 dataset, Table 6 shows that Krum(·) is more robust than others. Mean-based aggregation behaved badly in data robustness under omniscient attack. If we trim Mean(·), it can be
clearly seen that, the output becomes more robust. However, under this attack, Tmean(·) is not as
robust as Krum(·).


Table 5: Accuracy of different aggregations under omniscient attack in MLP.

|Aggregation rule|Number of iterations 100 150 200 250 300 350 400 450 500 550 600|
|---|---|
|Mean without Byzantine Krum Mean Tmean(b = 6) Tmean(b = 8)|0.82 0.83 0.84 0.84 0.85 0.85 0.86 0.86 0.87 0.87 0.88 0.79 0.81 0.82 0.83 0.83 0.84 0.85 0.85 0.86 0.87 0.87 0.26 0.26 0.27 0.27 0.28 0.29 0.29 0.30 0.31 0.31 0.32 0.23 0.28 0.32 0.38 0.47 0.55 0.61 0.66 0.70 0.73 0.75 0.50 0.52 0.57 0.61 0.64 0.67 0.70 0.72 0.74 0.77 0.79|



Table 6: Accuracy of different aggregations under omniscient attack in Cifar10.

|Aggregation rule|Number of iterations 500 1000 1500 2000 2500 3000|
|---|---|
|Mean without Byzantine Krum Mean Tmean(b = 8)|0.62 0.71 0.74 0.76 0.78 0.79 0.64 0.72 0.73 0.74 0.76 0.78 0.31 0.31 0.32 0.32 0.32 0.33 0.42 0.43 0.45 0.45 0.46 0.48|


-----

6.4 GENERAL ATTACK WITH MULTIPLE SERVERS

We evaluate the robust aggregation rules under a more general and realistic type of attack. It is very
popular to partition the parameters into disjoint subsets, and use multiple server nodes to store and
aggregate them. We assume that the parameters are evenly partitioned and assigned to the server
nodes. The attacker picks one server, and manipulates any floating number by multiplying −10[20]
with probability of 0.05%. Because the attacker randomly manipulates the values, with the goal that
in some iterations the assumptions/prerequisites of the robust aggregation rules are broken, which
crashes the training. Such an attack requires less global information, and can be concentrated on
one single server, which makes it more realistic and easier to implement.

For the MNIST dataset, in Table 7 we evaluate the performance of all robust aggregation rules
under multiple serves attack. The number of servers is 20. For Krum(·) and Mean(·), we set the
estimated Byzantine number q = 6. We find that Krum(·) and not passed. The intercepted Mean(·)
aggregation rules cannot be robust. In this case, they cannot converge to the global optimum. On
the other hand, for Tmean(·), different values of b will affect different convergence performance.
And if we take b = 6, it can also behave robustly.

For the Cifar10 dataset in Table 8, we can find the advantage of the Tmean(·). Neither Krum(·)
nor Mean(·) is robust, while Tmean(·) can make the learning robust.

|Table 7: Accuracy|of different aggregations under multiple server attack in MLP.|
|---|---|
|Aggregation rule|Number of iterations 100 150 200 250 300 350 400 450 500 550 600|
|Mean without Byzantine Krum Mean Tmean(b = 6) Tmean(b = 8)|0.83 0.83 0.84 0.84 0.85 0.85 0.86 0.86 0.87 0.87 0.87 0.28 0.20 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.10 0.80 0.81 0.81 0.82 0.82 0.83 0.83 0.84 0.84 0.84 0.85 0.81 0.82 0.82 0.83 0.83 0.83 0.84 0.84 0.85 0.86 0.86|



Table 8: Accuracy of different aggregations under multiple server attack in Cifar10.

|Aggregation rule|Number of iterations 500 1000 1500 2000 2500 3000|
|---|---|
|Mean without Byzantine Krum Mean Tmean(b = 8)|0.65 0.70 0.73 0.75 0.77 0.78 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.30 0.64 0.69 0.73 0.74 0.76 0.77|



6.5 EXPERIMENT CONCLUSION

From the above experiments, we find that it is difficult for Mean(·) to ensure the robustness of the
data when it is attacked by any Byzantine node. When multiple server nodes are used at the same
time, Krum(·) also becomes vulnerable. However, after the data is properly trimmed, Tmean(·)
can maintain data robustness. Under omniscient attacks, Tmean(·) is not as robust as Krum(·).But
Tmean(·) still improves a lot compared to Mean(·) in this case. The data robustness of Tmean(·)
is also related to the value of b. We find that when the value of b is closer to m/2, it can achieve
stronger robustness.

7 CONCLUSIONS

We analyzed the aggregation rules of Tmean(·). We demonstrated that the effectiveness of our
approaches can make the FL model robust to Byzantine attacks. We used three different Byzantine node attacks to show that the original data set can be more robustly handled after partial data
trimming and averaging operations.

This work focuses on Tmean(·). In future work we plan to refine the trimming range of Tmean(·)
and prove its convergence in a non-convex environment. At the same time, we will add momentum
on the basis of Tmean(·), or add some constraints to strengthen its robustness.


-----

REFERENCES

Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li. Byzantine stochastic gradient descent. arXiv preprint
_arXiv:1803.08917, 2018._

Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Byzantine-tolerant
machine learning. In Conference and Workshop on Neural Information Processing Systems, pp.
118–128, 2017.

L´eon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
_COMPSTAT, pp. 177–186. Springer, 2010._

S´ebastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R in
_Machine Learning, 2014._

Miguel Castro, Barbara Liskov, et al. Practical Byzantine fault tolerance. In OSDI, volume 99, pp.
173–186, 1999.

El-Mahdi El-Mhamdi, Rachid Guerraoui, Arsany Guirguis, Lˆe Nguyˆen Hoang, and S´ebastien
Rouault. Genuinely distributed Byzantine machine learning. In Proceedings of the 39th Sym_posium on Principles of Distributed Computing, pp. 355–364, 2020._

Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons. The non-iid data quagmire of
decentralized machine learning. In International Conference on Machine Learning, pp. 4387–
4398. PMLR, 2020.

Richeng Jin, Yufan Huang, Xiaofan He, Tianfu Wu, and Huaiyu Dai. Stochastic-sign SGD for
federated learning with theoretical guarantees. arXiv preprint arXiv:2002.10940, 2020.

Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
_International Conference on Machine Learning, pp. 5132–5143. PMLR, 2020._

Jakub Koneˇcn`y, H. Brendan McMahan, Felix X. Yu, Peter Richt´arik, Ananda Theertha Suresh,
and Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv
_preprint arXiv:1610.05492, 2016._

Leslie Lamport, Robert Shostak, and Marshall Pease. The Byzantine generals problem. In Concur_rency: the Works of Leslie Lamport, pp. 203–226, 2019._

Mu Li, David G. Andersen, Alexander J. Smola, and Kai Yu. Communication efficient distributed
machine learning with the parameter server. Advances in Neural Information Processing Systems,
27:19–27, 2014.

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial intelli_gence and statistics, pp. 1273–1282. PMLR, 2017._

Wenqi Wei, Ling Liu, Margaret Loper, Ka-Ho Chow, Mehmet Emre Gursoy, Stacey Truex, and
Yanzhao Wu. A framework for evaluating gradient leakage attacks in federated learning. arXiv
_preprint arXiv:2004.10397, 2020._

Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed
learning: Towards optimal statistical rates. In International Conference on Machine Learning,
pp. 5650–5659. PMLR, 2018.

Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Defending against saddle point
attack in Byzantine-robust distributed learning. In International Conference on Machine Learn_ing, pp. 7074–7084. PMLR, 2019._

Bo Zhao, Peng Sun, Liming Fang, Tao Wang, and Keyu Jiang. FedCom: A Byzantine-robust local
model aggregation rule using data commitment for federated learning. USENIX Security Sympo_sium, 2021._

Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated
learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018.


-----

APPENDIX

_Proof of Theorem 1. We first assume that vk’s, ˜vk’s, and g are all scalars (i.e., d = 1), with variance_
_Vstatistics of = σ[2]. Let v1 v, v(1)2, . . . ≤, vv(2)m and ≤· · · ≤ ˜v1, ˜v2, . . .v(m,) and ˜vm. Notice that ˜v(1) ≤_ _v˜(2) ≤· · · ≤_ _v˜(m), respectively, be order_

_m_ 2b _m_ 2b

1 _−_ 2[] 1 _−_
E _m −_ 2b _kX=1_ _v(k) −_ _g_ = (m − 2b)[2][ E] mkX=1 (v(k) − _g)[2]_

1
_≤_ (m − 2b)[2][ E]k=1(v(k) − _g)[2]_

_mX_

1
= (vi _g)[2]_

(m − 2b)[2][ E]k=1 _−_ 
X

_mσ[2]_
=

(m 2b)[2][ .]
_−_

Similarly, we have

_m_

2[]

1 _mσ[2]_
E _m −_ 2b _k=2Xb+1_ _v(k) −_ _g_ = (m − 2b)[2][ .]

It follows from Lemma 2 that


_m−2b_

_v(k)_ _g_ Tmeanb(˜v1, ˜v2, . . ., ˜vm) _g_
_k=1_ _−_ _≤_ _−_ _≤_

X


_v(k)_ _g._
_k=2b+1_ _−_

X


_m −_ 2b

Therefore


_m −_ 2b


E (Tmeanb(˜v1, ˜v2, . . ., ˜vm) _g)[2][]_
_−_

_m_ 2b _m_

 1 _−_ 2[] 1 2[]

_≤_ maxE _m −_ 2b _kX=1_ _v(k) −_ _g_ _, E_ _m −_ 2b _k=2Xb+1_ _v(k) −_ _g_

_mσ[2]_
_≤_ (m 2b)[2][ .]

_−_

Now we consider the general case—vk’s, ˜vk’s, and g are d-vectors, with variance V = _i=1_ _[σ]i[2][,]_
where
E _⟨G −_ _g, ei⟩[2][]_ _≤_ _σi[2][.]_ [P][d]
Using the result for the scalar case, we have



Tmeanb(˜v1, ˜v2, . . ., ˜vm) _g, ei_
_⟨_ _−_ _⟩[2][]_


_mσi[2]_

(m 2b)[2][ .]
_−_


_i=1_


Thus we conclude that


Tmeanb(˜v1, ˜v2, . . ., ˜vm) _g_
∥ _−_ _∥[2][]_


_mσi[2]_ _mV_

(m 2b)[2][ =] (m 2b)[2][ .]
_−_ _−_


_i=1_


_Proof of Theorem 2. Let g[(][t][)]_ = Aggr(˜v1[(][t][)][, . . .,][ ˜]vm[(][t][)][)][. Then]

_∥x[(][t][+1)]_ _−_ _x[∗]∥_ = ∥x[(][t][)] _−_ _γg[(][t][)]_ _−_ _x[∗]∥≤∥x[(][t][)]_ _−_ _x[∗]_ _−_ _γ∇F_ (x[(][t][)])∥ + γ∥∇F (x[(][t][)]) − _g[(][t][)]∥._ (4)

It follows from Lemma 3 that

_F_ (x[(][t][)]), x[(][t][)] _x[∗]_
_∇_ _−_ _≥_ _[µ]2_ 2L _[∥∇][F]_ [(][x][(][t][)][)][∥][2][.]

_[∥][x][(][t][)][ −]_ _[x][∗][∥][2][ + 1]_

Then we obtain


_∥x[(][t][)]_ _−_ _x[∗]_ _−_ _γ∇F_ (x[(][t][)])∥[2]


-----

= ∥x[(][t][)] _−_ _x[∗]∥[2]_ + γ[2]∥∇F (x[(][t][)])∥[2] _−_ 2γ _x[(][t][)]_ _−_ _x[∗], ∇F_ (x[(][t][)])

_x[(][t][)]_ _x[∗]_ + γ[2] _F_ (x[(][t][)]) 2γ _αµ_ _x[(][t][)]_ _x[∗]_ + [1][ −] _[α]_
_≤∥_ _−_ _∥[2]_ _∥∇_ _∥[2]_ _−_ _∥_ _−_ _∥[2]_ _L_



_∥∇F_ (x[(][t][)])∥[2][]


= (1 2αγµ) _x[(][t][)]_ _x[∗]_ + γ _γ_
_−_ _∥_ _−_ _∥[2]_ _−_ [2(1][ −]L _[α][)]_


Taking α = 1/2 yields


_∥∇F_ (x[(][t][)])∥[2].


_∥x[(][t][)]_ _−_ _x[∗]_ _−_ _γ∇F_ (x[(][t][)])∥≤

The estimate (4) simplifies to


1 − _γµ ∥x[(][t][)]_ _−_ _x[∗]∥_ = η∥x[(][t][)] _−_ _x[∗]∥._


_∥x[(][t][+1)]_ _−_ _x[∗]∥≤_ _η∥x[(][t][)]_ _−_ _x[∗]∥_ + γ∥∇F (x[(][t][)]) − _g[(][t][)]∥._

By taking the expectation on both sides, we obtain

E _∥x[t][+1]_ _−_ _x[∗]∥_ _≤_ _η E_ _∥x[(][t][)]_ _−_ _x[∗]∥_ + γ E _∥∇F_ (x[(][t][)]) − _g[(][t][)]∥_
  _≤_ _η E∥x[(][t][)]_ _−_ _x[∗]∥_ + γ E _∥∇F_ (x[(][t][)]) − _g[(][t][)]∥[2][]_

_≤_ _η E∥x[(][t][)]_ _−_ _x[∗]∥_ + γ√q∆.

It can then be easily verified that  


_t−1_

_η[i]_

_i=0_

X


_∥x[(][t][)]_ _−_ _x[∗]∥_ _≤_ _η[t]∥x[(0)]_ _−_ _x[∗]∥_ + γ


_≤_ _η[t]∥x[(0)]_ _−_ _x[∗]∥_ + γ


_≤_ _η[t]∥x[(0)]_ _−_ _x[∗]∥_ + γ√∆ _η[i]_

_i=0_

X

= η[t] _x[(0)]_ _x[∗]_ + [1 +][ √][1][ −] _[γµ]_
_∥_ _−_ _∥_ _µ_


∆.


Finally, the decay ratio η can be bounded through


1
_−_ _L[µ]_ _[.]_


_η =_


1 − _γµ ≥_


-----


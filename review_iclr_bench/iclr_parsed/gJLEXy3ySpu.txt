# ALMOST TIGHT L0-NORM CERTIFIED ROBUSTNESS OF TOP-k PREDICTIONS AGAINST ADVERSARIAL PERTUR## BATIONS


**Jinyuan Jia**
Duke University
jinyuan.jia@duke.edu

**Hongbin Liu**
Duke University
hongbin.liu@duke.edu


**Binghui Wang**
Illinois Institute of Technology
bwang70@iit.edu


**Xiaoyu Cao**
Duke University
xiaoyu.cao@duke.edu


**Neil Zhenqiang Gong**
Duke University
neil.gong@duke.edu

ABSTRACT


Top-k predictions are used in many real-world applications such as machine learning as a service, recommender systems, and web searches. ℓ0-norm adversarial
perturbation characterizes an attack that arbitrarily modifies some features of an
input such that a classifier makes an incorrect prediction for the perturbed input.
_ℓ0-norm adversarial perturbation is easy to interpret and can be implemented in_
the physical world. Therefore, certifying robustness of top-k predictions against
_ℓ0-norm adversarial perturbation is important. However, existing studies either_
focused on certifying ℓ0-norm robustness of top-1 predictions or ℓ2-norm robustness of top-k predictions. In this work, we aim to bridge the gap. Our approach is
based on randomized smoothing, which builds a provably robust classifier from an
arbitrary classifier via randomizing an input. Our major theoretical contribution is
an almost tight ℓ0-norm certified robustness guarantee for top-k predictions. We
empirically evaluate our method on CIFAR10 and ImageNet. For instance, our
method can build a classifier that achieves a certified top-3 accuracy of 69.2% on
ImageNet when an attacker can arbitrarily perturb 5 pixels of a testing image.

1 INTRODUCTION

Adversarial example is a well-known severe security vulnerability of classifiers. Specifically, given a
classifier f and a testing input x, an attacker can carefully craft a human-imperceptible perturbation
_δ such that f_ (x) ̸= f (x + δ). The perturbation δ is called adversarial perturbation, while the input
_x + δ is called an adversarial example. Many empirical defenses (Goodfellow et al., 2015; Na et al.,_
2018; Metzen et al., 2017; Svoboda et al., 2019; Buckman et al., 2018; Ma et al., 2018; Guo et al.,
2018; Dhillon et al., 2018; Xie et al., 2018; Song et al., 2018) have been developed to defend against
adversarial examples in the past several years. However, these empirical defenses were often soon
broken by strong adaptive adversaries (Carlini & Wagner, 2017; Athalye et al., 2018; Uesato et al.,
2018; Athalye & Carlini, 2018). To end this cat-and-mouse game, many certified defenses (Scheibler
et al., 2015; Carlini et al., 2017; Ehlers, 2017; Katz et al., 2017; Cheng et al., 2017; Lomuscio &
Maganti, 2017; Fischetti & Jo, 2018; Bunel et al., 2018; Wong & Kolter, 2018; Wong et al., 2018;
Raghunathan et al., 2018a;b; Dvijotham et al., 2018a;b; Gehr et al., 2018; Mirman et al., 2018; Singh
et al., 2018; Weng et al., 2018; Zhang et al., 2018; Gowal et al., 2018; Wang et al., 2018; Lecuyer
et al., 2019; Li et al., 2019; Cohen et al., 2019; Lee et al., 2019; Salman et al., 2019; Wang et al.,
2020; Jia et al., 2020; Zhai et al., 2020) have been proposed. In particular, a classifier f is said to be
certifiably robust for an input x if it provably predicts the same top-1 label (i.e.,f (x) = f (x + δ))
when the adversarial perturbation δ is bounded, e.g., the ℓp-norm of δ is smaller than a threshold. The
threshold is also called certified radius. In this work, we focus on ℓ0-norm adversarial perturbation,
which arbitrarily manipulates some features of a testing input and can be implemented in the physical
world.


-----

However, most existing certified defenses focus on top-1 predictions. In many applications, top-k
predictions that return the k most likely labels are more relevant. For instance, when a classifier
is deployed as a cloud service (also called machine learning as a service) (Google Cloud Vision;
Microsoft; Amazon AWS; Clarifai), top-k labels for a testing input are often returned to a customer
for more informed decisions; in recommender systems and web searches, top-k items/webpages are
recommended to a user. Despite the importance and relevance of top-k predictions, their certified
robustness against adversarial perturbations is largely unexplored. One exception is the recent work
from Jia et al. (2020), which derived a tight ℓ2-norm certified robustness for top-k predictions. Such
_ℓ2-norm certified robustness can be transformed to ℓ0-norm certified robustness via employing the_
inequality between ℓ0-norm and ℓ2-norm. However, the ℓ0-norm certified robustness derived from
such transformations is suboptimal.

**Our work: We aim to develop ℓ0-norm certified robustness of top-k predictions. Our approach**
is based on randomized smoothing (Cao & Gong, 2017; Liu et al., 2018; Lecuyer et al., 2019; Li
et al., 2019; Cohen et al., 2019; Lee et al., 2019; Jia et al., 2020; Levine & Feizi, 2019), which can
build a certifiably robust classifier from any base classifier via randomizing the input. We adopt
randomized smoothing because it is applicable to any classifier and scalable to large neural networks.
In particular, we use a randomized smoothing method called randomized ablation (Levine & Feizi,
2019), which achieves state-of-the-art ℓ0-norm certified robustness for top-1 predictions. Unlike other
randomized smoothing methods (Cao & Gong, 2017; Lecuyer et al., 2019; Li et al., 2019; Cohen
et al., 2019) that randomize an input via adding additive noise (e.g., Gaussian, Laplacian, or discrete
noise) to it, randomized ablation randomizes an input via subsampling its features. Specifically, given
an arbitrary classifier (called base classifier) and a testing input x, randomized ablation creates an
_ablated input via retaining some randomly selected features in x and setting the remaining features_
to a special value, e.g., median of the feature value, mean of the feature value, or a special symbol.
When the testing input is an image, the features are the image’s pixels. Then, we feed the ablated
input to the base classifier. Since the ablated input is random, the output of the base classifier is also
random. Specifically, we denote by pj the probability that the base classifier outputs a label j for the
random ablated input. The original randomized ablation method builds a smoothed classifier that
outputs the label with the largest label probability pj for a testing input x. In our work, the smoothed
classifier returns the k labels with the largest label probabilities for x.

Our major theoretical contribution is an almost tight ℓ0-norm certified robustness guarantee of top-k
predictions for the smoothed classifier constructed by randomized ablation. Specifically, we first
derive an ℓ0-norm certified robustness guarantee of top-k predictions for the smoothed classifier. Our
results show that a label l is provably among the top-k labels predicted by the smoothed classifier for a
testing input x when the attacker arbitrarily perturbs at most rl features of x, where rl is the ℓ0-norm
certified radius. Moreover, we prove that our certified radius is tight when k = 1 and is almost tight
when k > 1. In particular, if no assumptions on the base classifier are made, it is impossible to derive
a certified radius that is larger than rl + I(k ̸= 1). In other words, when an attacker manipulates
at least rl + 1 + I(k ̸= 1) features of a testing input, there exists a base classifier from which the
smoothed classifier’s top-k predicted labels do not include l or there exist ties.

Our work has several technical differences with Levine & Feizi (2019). First, we derive the ℓ0-norm
certified radius of top-k predictions for randomized ablation, while Levine & Feizi (2019) only
derived the certified radius of top-1 predictions. Second, our certified radius is the same as or
larger than that in Levine & Feizi (2019) for top-1 predictions, because we leverage the discrete
property of the label probabilities to derive our certified radius. Third, we prove the (almost) tightness
of the certified radius, while Levine & Feizi (2019) didn’t. Our work also has several technical
differences with Jia et al. (2020), which derived a tight ℓ2-norm certified radius of top-k predictions
for randomized smoothing with Gaussian additive noise. Since they add additive Gaussian noise to a
testing input, the space of randomized inputs is continuous. However, our space of ablated inputs is
discrete, as we randomize a testing input via subsampling its features. As a result, Jia et al. and our
work use substantially different techniques to derive the ℓ2/ℓ0-norm certified radiuses and prove their
(almost) tightness. In particular, when deriving the ℓ2/ℓ0-norm certified radiuses, our work needs
to construct different regions in the discrete space of ablated inputs such that the Neyman-Pearson
Lemma (Neyman & Pearson, 1933) can be applied. When proving the (almost) tightness, we use
a completely different approach from Jia et al.. First, Jia et al. relies on the Intermediate Value
Theorem, which is not applicable to our discrete data. Second, since Gaussian noise is not uniform,
Jia et al. need to prove the results via Mathematical Induction. However, Mathematical Induction is


-----

unnecessary in our case because the ablated inputs that can be derived from an input are uniformly
distributed in the space of ablated inputs.

We evaluate our method on CIFAR10 and ImageNet. Our results show that our method substantially
outperforms state-of-the-art for top-k predictions. For instance, our method achieves a certified top-3
accuracy of 69.2% on ImageNet when an attacker arbitrarily perturbs 5 pixels of a testing image.
Under the same setting, Jia et al. (2020) achieves a certified top-3 accuracy of only 9.0%, when
transforming their ℓ2-norm certified robustness to ℓ0-norm certified robustness.

Our contributions can be summarized as follows:

-  We derive an ℓ0-norm certified radius of top-k predictions for randomized ablation.

-  We prove that our certified radius is tight when k = 1 and almost tight when k > 1.

-  We empirically evaluate our method on CIFAR10 and ImageNet.

2 THEORETICAL RESULTS

In this section, we show our core theoretical contributions.

2.1 BUILDING A SMOOTHED CLASSIFIER VIA RANDOMIZED ABLATION

Suppose we have a base classifier f, which classifies a testing input x to one of c classes {1, 2, · · ·, c}
deterministically. For simplicity, we assume x is an image with d pixels. Given an input x, randomized
ablation (Levine & Feizi, 2019) creates an ablated input as follows: we first randomly subsample e
pixels from x without replacement and keep their values. Then, we set the remaining pixel values
in the ablated input to a special value, e.g., median of the pixel value, mean of the pixel value, or a
special symbol. When the image is a color image, we set the values of the three channels of each
pixel separately. Note that an ablated input has the same size with x. We use h(x, e) to denote the
randomly ablated input for simplicity. Given h(x, e) as input, the output of the base classifier f is also
random. We use pj to denote the probability that the base classifier f predicts class j when taking
_h(x, e) as input, i.e., pj = Pr(f_ (h(x, e)) = j). Note that pj is an integer multiple of 1d

(e[)] [, which we]

will leverage to derive a tighter certified robustness guarantee. We build a smoothed classifier g that
outputs the k labels with the largest label probabilities pj’s for x. Moreover, we denote by gk(x) the
set of k labels predicted for x.

2.2 DERIVING THE CERTIFIED RADIUS FOR THE SMOOTHED CLASSIFIER


**Defining two random variables: Suppose an attacker adds a perturbation δ to an input x, where**
_∥δ∥0 is the number of pixels perturbed by the attacker. We define the following two random variables:_

_U = h(x, e), V = h(x + δ, e),_ (1)

where the random variables U and V denote the ablated inputs derived from x and its perturbed
version x + δ, respectively. We use S to denote the joint space of U and V, i.e., S is the set of ablated
inputs that can be derived from x or x + δ. Given the definition of U and V, Pr(f (U ) = j) and
Pr(f (V ) = j) respectively represent the label probabilities of the input x and its perturbed version
**x + δ predicted by the smoothed classifier.**

**Derivation goal: Intuitively, an ablated input h(x, e) is very likely to not include any perturbed pixel**
if ∥δ∥0 is bounded and e is relatively small, and thus the predicted labels of the smoothed classifier
are not influenced by the perturbation. Formally, our goal is to show that a label l ∈{1, 2, · · ·, c}
is provably in the top-k labels predicted by the smoothed classifier for an input x when the number
of perturbed pixels is no larger than a threshold. In other words, we aim to show that l _gk(x + δ)_
_∈_
when _δ_ 0 _rl, where rl is the certified radius. Our key idea to derive the certified radius is to_
guarantee that, when taking ∥ _∥_ _≤_ _V as input, the label probability for label l is larger than the smallest one_
among the label probabilities of any k labels from all labels except l. We let Γ = {1, 2, · · ·, c} \ {l},
i.e., Γ denotes the set of all labels except l. We use Γk to denote a set of k labels in Γ. Then, we aim
to find a maximum certified radius rl such that:

Pr(f (V ) = l) > max (2)
Γk⊂Γ _j[min]∈Γk_ [Pr][(][f] [(][V][ ) =][ j][)][.]


-----

Roughly speaking, the above equation means that: to ensure l exists in the set of top-k labels,
Pr(f (V ) = l) should be larger than the minimum probability observed by taking any set of k labels
Γk excluding l. To reach the goal, we derive a lower bound of Pr(f (V ) = l) and an upper bound of
maxΓk⊂Γ minj∈Γk Pr(f (V ) = j). In particular, we derive a lower bound and an upper bound using
the probabilities that V is in certain regions of the discrete space S, and such probabilities can be
efficiently computed for ∀∥δ∥0 = r. Then, we can leverage binary search to find the maximum r
such that the lower bound is larger than the upper bound and treat the maximum r as the certified
radius rl. Next, we respectively introduce how to derive lower and upper bounds and use them to
compute certified radius.

**Deriving a lower bound of Pr(f** (V ) = l) and an upper bound of maxΓk⊂Γ minj∈Γk Pr(f (V ) =
_j): We show our intuition to derive the upper and lower bounds. Our formal analysis is shown in the_
proof of Theorem 1. Our idea to derive the bounds is to divide the discrete space S in an innovative
way such that we can leverage the Neyman-Pearson Lemma (Neyman & Pearson, 1933). Suppose for
the random variable U, we have a lower bound of the label probability for l and an upper bound of
the label probability for every other label. Formally, we have pl, p1 _pl_ 1, pl, _, pc that satisfy_
the following: _· · ·_ _−_ _· · ·_
_pl_ Pr(f (U ) = l), pj Pr(f (U ) = j), _j_ = l, (3)
_≤_ _≥_ _∀_ _̸_
where p and p denote the lower and upper bounds of p, respectively. Multiplying each term in
Equation (3) by _de_, we have pl _de_ Pr(f (U ) = l) _de_ _, pj_ _de_ Pr(f (U ) = j) _de_ _,_ _j_ = l. Since
_pl and pj(∀j ̸= l ) are integer multiples of_ _· _  _≤_ (1de[)] [, we have]·  _[ ⌈][p][l][ ·]· de_ ⌉≤≥ Pr(f (U ) = l)· ·  de _∀, ⌊ ̸pj ·_ _de_ _⌋≥_

Pr(f (U ) = j) _de_ _,_ _j_ = l. Therefore, we have the following:        
_·_ _∀_ _̸_

_d_ _d_

   _e_ _e_

_p[′]l_ [≜] _[⌈][p][l][ ·]d_ _⌉_ _≤_ Pr(f (U ) = l), p[′]j [≜] _[⌊][p][j][ ·]d_ _⌋_ _≥_ Pr(f (U ) = j), ∀j ̸= l. (4)
_e _  _e _ 

Letare broken uniformly at random. We denote pak ≥ _pak−1 · · · ≥ _ pa1 be the k largest ones among Υt = {a 1, a {2p, · · ·1, · · ·, a, pt}l as the set of−1, pl+1, · · ·, p t labels with thec}, where ties
smallest label probability upper bounds in the k largest ones and denote by p[′]Υt [=][ P]j Υt _[p]j[′]_ [the sum]

_∈_
of the t label probability bounds, where t = 1, 2, · · ·, k.

We define regions A, B, and C in S as the sets of ablated inputs that can be derived only from x,
only from x + δ, and from both x and x + δ, respectively. In particular, the region A is a set of
ablated inputs that can only be obtained via sampling e features (pixels) from x. The region B is
a set of ablated inputs that can only be obtained via sampling e features from the perturbed x + δ,
and the region C is a set of ablated inputs that can be obtained via sampling e features from both
**x and x + δ. Then, we can find a region A[′]** _⊆C such that Pr(U ∈A[′]_ _∪A) = p[′]l[. Note that we]_
assume we can find such a region A[′] since we aim to find sufficient condition. Similarly, we can
findLemma (Neyman & Pearson, 1933) to derive a lower bound of HΥt ∈C such that we have Pr(U ∈HΥt ) = p[′]Υt[. Then, we can apply the Neyman-Pearson] Pr(f (V ) = l) and an upper bound
of maxΓk⊂Γ minj∈Γk Pr(f (V ) = j) by leveraging the probabilities of V in regions A[′] _∪A and_
Υt . Formally, we have the following:
_H_ Pr ∪B(f (V ) = l) ≥ Pr(V ∈A[′] _∪A), maxΓk⊂Γ_ _j[min]∈Γk_ [Pr][(][f] [(][V][ ) =][ j][)][ ≤] mint=1k Pr(V ∈Ht Υt ∪B) _._ (5)

**Computing certified radius: Given the lower and upper bounds, we can find the maximum r =** _δ_ 0
Pr(V Υt ) ∥ _∥_
such that the lower bound Pr(V ) is larger than the upper bound min[k]t=1 _∈Ht_ _∪B_ . The
_∈A[′]_ _∪A_

maximum r is the certified radius. Formally, we have the following theorem:
**Theorem 1 (ℓ0-norm Certified Radius for Top-k Predictions). Suppose we have an input x with d**
_features, a deterministic base classifier f_ _, an integer e, a smoothed classifier g where gk(x) is a set_
_of k labels predicted for x, an arbitrary label l_ 1, 2, _, c_ _, pl, p1,_ _, pl_ 1, pl+1, _, pc that_
_∈{_ _· · ·_ _}_ _· · ·_ _−_ _· · ·_
_satisfy Equation (3), and p[′]l[,][ p]j[′]_ [(][∀][j][ ̸][=][ l][)][ that are defined in Equation (4). If the following optimization]
_problem has a solution rl:_


_d−e_ _r[)]_
_p[′]Υt_ [+ (1][ −] [(](de[) )]


_d_ _r_
_−de_ ) > mint=1k
  _e_ 

  


_rl = arg max_ _r_ _s.t. p[′]l_
_r≥0_ _[−]_ [(1][ −]


(6)


-----

_Then, we have the following:_

_Proof. Please refer to Appendix A._


_l_ _gk(x + δ),_ _δ_ 0 _rl._ (7)
_∈_ _∀∥_ _∥_ _≤_


Next, we show that our derived certified radius is (almost) tight. In particular, when using randomized
ablation and no further assumptions are made on the base classifier, it is impossible to certify an
_ℓ0-norm radius that is larger than rl + I(k ̸= 1) for top-k predictions._

**Theorem 2 (Almost Tightness of our Certified Radius). Assuming we have** _d−e−rl1−2_ _≥_ 1, p[′]l [+]

_j∈Υk_ _[p]j[′]_ _[≤]_ [1][, and][ p]l[′] [+][ P]j≠ _l_ _[p]j[′]_ _[≥]_ [1][. If no assumption on the base classifier is made, then, for any]  

_perturbationP_ _∥δ∥0 > rl + I(k ̸= 1), there exists a base classifier f_ _[∗]_ _consistent with Equation (3) but_
_we have l /_ _gk(x + δ) or there exist ties._
_∈_

_Proof. Please refer to Appendix B._


**Comparing with Levine & Feizi (2019) when k = 1: Our certified radius reduces to the maximum**

_d−e_ _r[)]_
_r that satisfies p[′]l_ _[−]_ _[p]a[′]_ 1 _[>][ 2][ ·][ (1][ −]_ [(](de[) )][ when][ k][ = 1][. In contrast, the certified radius in Levine]d−e _r[)]_

& Feizi (2019) is the maximum r that satisfies pl − _pa1 > 2 · (1 −_ [(](de[) )][. Since][ p]l[′] _[≥]_ _[p][l][ and]_

_p[′]ak_ _ak_ [, our certified radius is the same as or larger than that in Levine & Feizi (2019). Note]
that the method by Levine & Feizi (2019) cannot be extended in a straightforward way to derive the[≤] _[p]_
certified robustness for top-k predictions. The reason is that they consider each label independently
in their derivation. In particular, they use the probability that the base classifier predicts label i for an
ablated clean input (i.e., Pr(f (U ) = i)) to bound the probability that the base classifier predicts label
_i for an ablated adversarial input (i.e., Pr(f_ (V ) = i)). However, to derive the certified robustness for
top-k predictions, we need to jointly derive the bounds for multiple label probabilities (i.e., Equation
(5)). Moreover, because of the difference in deriving label-probability bounds, our techniques are
significantly different. In particular, Levine & Feizi only need the law of total probability while we
leverage Neyman-Pearson Lemma. Moreover, Levine & Feizi (2019) did not analyze the tightness of
the certified radius for top-1 predictions.

**Comparing with Jia et al. (2020): Jia et al. (2020) proved the exact tightness of their ℓ2-norm**
certified radius for randomized smoothing with Gaussian noise. We highlight that our techniques
to prove our almost tightness are substantially different from those in Jia et al.. First, they proved
the existence of a region via the Intermediate Value Theorem, which relies on the continuity of
Gaussian noise. However, our space of ablated inputs is discrete. Therefore, given a probability
upper/lower bound, it is challenging to find a region whose probability measure exactly equals to the
given value, since the Intermediate Value Theorem is not applicable. As a result, we cannot prove
the exact tightness of the ℓ0-norm certified radius when k > 1. To address the challenge, we find a
region whose probability measure is slightly smaller than the given upper bound, which enables us to
prove the almost tightness of our certified radius. Second, since Gaussian noise is not uniform, they
need to iteratively construct regions via leveraging Mathematical Induction. However, Mathematical
Induction is unnecessary in our case because the ablated inputs that can be derived from an input are
uniformly distributed in the space of ablated inputs.

**Computing rl in practice:** When applying our Theorem 1 to calculate the certified radius rl
in practice, we need the probability bounds p[′]l [and][ p]Υ[′] _t_ [and solve the optimization problem in]
Equation (6). We can leverage a Monte Carlo method developed by Jia et al. (2020) to estimate
the probability bounds (pl and pj, ∀j ̸= l) with probabilistic guarantees. Then, we can use them to
estimate p[′]l [and][ p]Υ[′] _t_ [. Moreover, given the probability bounds][ p]l[′] [and][ p]Υ[′] _t_ [, we can use binary search to]
solve Equation (6) to find the certified radius rl.

Specifically, the probabilities p1, p2, · · ·, pc can be viewed as a multinomial distribution over the
label set {1, 2, · · ·, c}. Given h(x, e) as input, f (h(x, e)) can be viewed as a sample from the
multinomial distribution. Therefore, estimating pl and pi for i ̸= l is essentially a one-sided
_simultaneous confidence interval estimation problem. In particular, we leverage the simultaneous_


-----

confidence interval estimation method called SimuEM (Jia et al., 2020) to estimate these bounds
with a confidence level at least 1 − _α. Specifically, given an input x and parameter e, we randomly_
create n ablated inputs, i.e., ϵ[1], ϵ[2], · · ·, ϵ[n]. We denote by nj the frequency of the label j predicted
by the base classifier for the n ablated inputs. Formally, we have nj = _i=1_ [I][(][f] [(][ϵ][i][) =][ j][)][, where]
_j ∈{1, 2, · · ·, c} and I is the indicator function. According to Jia et al. (2020), we have the following_
probability bounds with a confidence level at least 1 _α:_
_−_ [P][n]

_α_
_pl = B_ _, pj = B(1_ (8)

_c_ [;][ n][l][, n][ −] _[n][l][ + 1]_ _−_ _[α]c_ [;][ n][j][ + 1][, n][ −] _[n][j][)][,][ ∀][j][ ̸][=][ l,]_

 

where B(q; ξ, ζ) is the qth quantile of a beta distribution with shape parameters ξ and ζ. Then,
we can compute p[′]l [and][ p]j[′] _[,][ ∀][j][ ̸][=][ l][ based on Equation (4). Finally, we estimate][ p][′]Υt_ [as][ p]Υ[′] _t_ [=]
min([P]j Υt _[p]j[′]_ _[,][ 1][ −]_ _[p][′]l[)][.]_

_∈_

3 EVALUATION

3.1 EXPERIMENTAL SETUP

**Datasets and models: We use CIFAR10 (Krizhevsky et al., 2009) and ImageNet (Deng et al., 2009)**
for evaluation. We normalize pixel values to be in the range [0,1]. We use the publicly available
implementation[1] of randomized ablation to train our models. In particular, we use ResNet-110 and
RestNet-50 as the base classifiers for CIFAR10 and ImageNet, respectively. Moreover, as in Lee
et al. (2019), we use 500 testing examples for both CIFAR10 and ImageNet.

**Parameter setting: Unless otherwise mentioned, we adopt the following default parameters. We**
set e = 50 and e = 1, 000 for CIFAR10 and ImageNet, respectively. We set k = 3, n = 100, 000,
and α = 0.001. We will study the impact of each parameter while fixing the remaining ones to their
default values.

**Evaluation metric: We use the certified top-k accuracy as an evaluation metric. Specifically, given**
a number of perturbed pixels, certified top-k accuracy is the fraction of testing images, whose true
labels have ℓ0-norm certified radiuses for top-k predictions that are no smaller than the given number
of perturbed pixels. Note that our ℓ0-norm certified radius corresponds to the maximum number of
pixels that can be perturbed by an attacker.

**Compared methods: We compare six randomized smoothing based methods. The first four are only**
applicable for top-1 predictions, while the latter two are applicable for top-k predictions.

-  Cohen et al. (2019). This method adds Gaussian noise to a testing image and derives a
tight ℓ2-norm certified radius for top-1 predictions. In particular, considering the three color
channels and each pixel value is normalized to be in the range [0,1], an ℓ0-norm certified
number of perturbed pixels rl can be obtained from an ℓ2-norm certified radius 3rl.

_[√]_

-  Lee et al. (2019). This method derives an ℓ0-norm certified radius for top-1 predictions. This
method is applicable to discrete features. Like Lee et al. (2019), we treat the pixel values
as discrete in the domain 0, 1/256, 2/256, _, 255/256_ . Since their ℓ0-norm certified
_{_ _· · ·_ _}_
radius is for pixel channels (each pixel has 3 color channels), a certified number of perturbed
pixels rl can be obtained from their ℓ0-norm certified radius 3rl.

-  Levine & Feizi (2019). This method derives an ℓ0-norm certified number of perturbed
pixels for top-1 predictions in randomized ablation. This method requires a lower bound of
the largest label probability and an upper bound of the second largest label probability to
calculate the certified number of perturbed pixels. They estimated the lower bound using
the Monte Carlo method in Cohen et al. (2019) and the upper bound as 1 - the lower bound.
Note that our certified radius is theoretically no smaller than that in Levine & Feizi (2019)
when k = 1. Therefore, we use our derived certified radius when evaluating this method.
We also found that the top-1 certified accuracies based on our derived certified radius and
their derived certified radius have negligible differences on CIFAR10 and ImageNet, and
thus we do not show the differences for simplicity.

1https://github.com/alevine0/randomizedAblation/


-----

**Table 1: Certified top-k accuracies of the compared methods on CIFAR10.**

|#Perturbed pixels|Col2|1|2|3|4|5|
|---|---|---|---|---|---|---|
|Certified top-1 accuracy|Cohen et al. (2019)|0.118|0.056|0.018|0.0|0.0|
||Lee et al. (2019)|0.188|0.018|0.004|0.002|0.0|
||Levine & Feizi (2019)|0.704|0.680|0.670|0.646|0.610|
||Levine & Feizi (2019) + SimuEM (Jia et al., 2020)|0.746|0.718|0.690|0.660|0.636|
||Our method|0.746|0.718|0.690|0.660|0.636|
|Certified top-3 accuracy|Jia et al. (2020)|0.244|0.124|0.070|0.028|0.004|
||Our method|0.886|0.860|0.838|0.814|0.780|


#Perturbed pixels 1 2 3 4 5

Cohen et al. (2019) 0.118 0.056 0.018 0.0 0.0

Lee et al. (2019) 0.188 0.018 0.004 0.002 0.0

Levine & Feizi (2019) 0.704 0.680 0.670 0.646 0.610

Certified top-1 accuracy

**Levine & Feizi (2019)**
**0.746** **0.718** **0.690** **0.660** **0.636**
**+ SimuEM (Jia et al., 2020)**

**Our method** **0.746** **0.718** **0.690** **0.660** **0.636**

Jia et al. (2020) 0.244 0.124 0.070 0.028 0.004
Certified top-3 accuracy

**Our method** **0.886** **0.860** **0.838** **0.814** **0.780**


**Table 2: Certified top-k accuracies of the compared methods on ImageNet.**

|#Perturbed pixels|Col2|1|2|3|4|5|
|---|---|---|---|---|---|---|
|Certified top-1 accuracy|Cohen et al. (2019)|0.226|0.152|0.120|0.088|0.0|
||Lee et al. (2019)|0.338|0.196|0.104|0.092|0.070|
||Levine & Feizi (2019)|0.602|0.600|0.596|0.588|0.586|
||Levine & Feizi (2019) + SimuEM (Jia et al., 2020)|0.634|0.628|0.618|0.616|0.608|
||Our method|0.634|0.628|0.618|0.616|0.608|
|Certified top-3 accuracy|Jia et al. (2020)|0.326|0.232|0.160|0.120|0.090|
||Our method|0.740|0.730|0.712|0.698|0.692|


#Perturbed pixels 1 2 3 4 5

Cohen et al. (2019) 0.226 0.152 0.120 0.088 0.0

Lee et al. (2019) 0.338 0.196 0.104 0.092 0.070

Levine & Feizi (2019) 0.602 0.600 0.596 0.588 0.586

Certified top-1 accuracy

**Levine & Feizi (2019)**
**0.634** **0.628** **0.618** **0.616** **0.608**
**+ SimuEM (Jia et al., 2020)**

**Our method** **0.634** **0.628** **0.618** **0.616** **0.608**

Jia et al. (2020) 0.326 0.232 0.160 0.120 0.090
Certified top-3 accuracy

**Our method** **0.740** **0.730** **0.712** **0.698** **0.692**


-  Levine & Feizi (2019) + SimuEM (Jia et al., 2020). This is the Levine & Feizi (2019)
method with the lower/upper bounds of label probabilities estimated using the simultaneous
confidence interval estimation method called SimuEM. Again, we use our derived certified
radius for top-1 predictions in this method.

-  Jia et al. (2020). This work extends Cohen et al. (2019) from top-1 predictions to top-k
predictions. In detail, they derive a tight ℓ2-norm certified radius of top-k predictions for
randomized smoothing with Gaussian noise. An ℓ0-norm certified number of perturbed
pixels rl for top-k predictions can be obtained from an ℓ2-norm certified radius 3rl.

_[√]_

-  Our method. Our method produces an almost tight ℓ0-norm certified number of perturbed
pixels of top-k predictions.

Note that we compare with Cohen et al. (2019) and Jia et al. (2020) because we aim to show that it is
suboptimal to derive ℓ0-norm certified robustness for top-k predictions by leveraging the relationship
between ℓ2-norm and ℓ0-norm.

3.2 EXPERIMENTAL RESULTS

**Comparison results: Table 1 and 2 respectively show the certified top-k accuracies of the compared**
methods on CIFAR10 and ImageNet when an attacker perturbs a certain number of pixels. The
Gaussian noise in Cohen et al. (2019) and Jia et al. (2020) has mean 0 and standard deviation σ. We
obtain the certified top-k accuracies for different σ, i.e., we explored σ = 0.1, 0.12, 0.25, 0.5, 1.0.
Lee et al. (2019) has a noise parameter β. We obtain the certified top-1 accuracies for different β. In
particular, we explored β = 0.1, 0.2, 0.3, 0.4, 0.5, which were also used by Lee et al. (2019). Then,
we report the largest certified top-k accuracies of Cohen et al. (2019), Lee et al. (2019), and Jia et al.
(2020) for each given number of perturbed pixels. We use the default values of e for Levine & Feizi
(2019) and our method.

We have two observations from Table 1 and 2. First, our method substantially outperforms Jia et al.
(2020) for top-k predictions, while Levine & Feizi (2019) substantially outperforms Cohen et al.
(2019) and Lee et al. (2019) for top-1 predictions. Since our method and Levine & Feizi (2019) use
randomized ablation, while the remaining methods use additive noise (Gaussian or discrete noise)
to randomize a testing input, our results indicate that randomized ablation is superior to additive
noise at certifying ℓ0-norm robustness. Second, Levine & Feizi (2019) + SimuEM (Jia et al., 2020)


-----

1.0 1.0

0.8 k=1k=2 0.8 k=1k=3

0.6 k=3 0.6 k=5k=10

0.4 0.4

0.2 0.2

Certified Top-k Accuracy Certified Top-k Accuracy

0.0 0.0

0 5 10 15 20 25 30 0 25 50 75 100 125 150

Number of Perturbed Pixels Number of Perturbed Pixels


(a) CIFAR10


(b) ImageNet


**Figure 1: Impact of k on certified top-k accuracy.**


1.0 1.0

0.8 e=50 0.8 e=500

e=100 e=1,000

0.6 e=200 0.6 e=2,000

0.4 0.4

0.2 0.2

Certified Top-k Accuracy Certified Top-k Accuracy

0.0 0.0

0 5 10 15 20 25 30 0 25 50 75 100 125 150

Number of Perturbed Pixels Number of Perturbed Pixels


(a) CIFAR10


(b) ImageNet


**Figure 2: Impact of e on certified top-3 accuracy.**


1.0 1.0

0.8 n=10[3] 0.8 n=10[3]

n=10[4] n=10[4]

0.6 n=10[5] 0.6 n=10[5]

0.4 0.4

0.2 0.2

Certified Top-k Accuracy Certified Top-k Accuracy

0.0 0.0

0 5 10 15 20 25 30 0 25 50 75 100 125 150

Number of Perturbed Pixels Number of Perturbed Pixels


(a) CIFAR10


(b) ImageNet


**Figure 3: Impact of n on certified top-3 accuracy.**


1.0 1.0

0.8 _α=0.01_ 0.8 _α=0.01_

_α=0.001_ _α=0.001_

0.6 _α=0.0001_ 0.6 _α=0.0001_

0.4 0.4

0.2 0.2

Certified Top-k Accuracy Certified Top-k Accuracy

0.0 0.0

0 5 10 15 20 25 30 0 25 50 75 100 125 150

Number of Perturbed Pixels Number of Perturbed Pixels


(a) CIFAR10


(b) ImageNet


**Figure 4: Impact of α on certified top-3 accuracy.**

outperforms Levine & Feizi (2019). This is because SimuEM can more accurately estimate the label
probability bounds via simultaneous confidence interval estimations.

**Impact of k, e, n, and α: Figure 1, 2, 3 and 4 show the certified top-k accuracy of our method**
vs. number of perturbed pixels for different k, e, n, and α, respectively. Naturally, the certified
top-k accuracy increases as k increases. For instance, when 5 pixels are perturbed, the certified
top-1 and top-3 accuracies are 63.6% and 78.0% on CIFAR10, respectively. We observe that e
provides a tradeoff between accuracy under no attacks and robustness. Specifically, when e is larger,
the accuracy under no attacks (i.e., certified accuracy with 0 perturbed pixels) is higher, while the
certified accuracy decreases to 0 more quickly as the number of perturbed pixels increases. As n
becomes larger, the curve of the certified accuracy may become higher. The reason is that a larger
_n makes the estimated label probability bounds pl and pΥt tighter and thus the ℓ0-norm certified_
radius may be larger, which result in a larger certified accuracy. Theoretically, as the confidence level
1 − _α decreases, the curve of the certified accuracy may become higher. This is because a smaller_
confidence level leads to tighter estimated label probability boundsaccuracy may be larger. However, we observe the differences between different confidence levels are pl and pΥt, and thus the certified
negligible when the confidence levels are high enough (i.e., α is small enough).


-----

4 RELATED WORK

Many certified defenses have been proposed to defend against adversarial perturbations. These
defenses leverage various techniques including satisfiability modulo theories (Scheibler et al., 2015;
Carlini et al., 2017; Ehlers, 2017; Katz et al., 2017), interval analysis (Wang et al., 2018), linear
programming (Cheng et al., 2017; Lomuscio & Maganti, 2017; Fischetti & Jo, 2018; Bunel et al.,
2018; Wong & Kolter, 2018; Wong et al., 2018), semidefinite programming (Raghunathan et al.,
2018a;b), dual optimization (Dvijotham et al., 2018a;b), abstract interpretation (Gehr et al., 2018;
Mirman et al., 2018; Singh et al., 2018), and layer-wise relaxation (Weng et al., 2018; Zhang et al.,
2018; Gowal et al., 2018; Chiang et al., 2020). However, these defenses suffer from one or two
limitations: 1) they are not scalable to large neural networks and/or 2) they are only applicable to
specific neural network architectures. Randomized smoothing addresses the two limitations. Next,
we review randomized smoothing based methods for certifying non-ℓ0-norm and ℓ0-norm robustness.
**Randomized smoothing for non-ℓ0-norm robustness: Randomized smoothing was first proposed**
as an empirical defense (Cao & Gong, 2017; Liu et al., 2018). In particular, Cao & Gong (2017)
proposed to use uniform random noise from a hypercube centered at a testing example to smooth its
predicted label. Lee et al. (2019) derived certified robustness for such uniform random noise. Lecuyer
et al. (2019) was the first to derive formal ℓ2 and ℓ -norm robustness guarantee of randomized
_∞_
smoothing with Gaussian or Laplacian noise via differential privacy techniques. Subsequently, Li
et al. (2019) leveraged information theory to derive a tighter ℓ2-norm robustness guarantee. Cohen
et al. (2019) leveraged the Neyman-Pearson Lemma (Neyman & Pearson, 1933) to obtain a tight
_ℓ2-norm certified robustness guarantee for randomized smoothing with Gaussian noise. Other studies_
include Pinot et al. (2019); Carmon et al. (2019); Salman et al. (2019); Zhai et al. (2020); Dvijotham
et al. (2019); Blum et al. (2020); Levine & Feizi (2020); Kumar et al. (2020); Yang et al. (2020);
Zhang et al. (2020); Salman et al. (2020); Zheng et al. (2020). All these studies focused on top-1
predictions. Jia et al. (2020) derived the first ℓ2-norm certified robustness of top-k predictions against
adversarial perturbations for randomized smoothing with Gaussian noise and proved its tightness.
**Randomized smoothing for ℓ0-norm robustness: All the above randomized smoothing based**
provable defenses were not (specifically) designed to certify ℓ0-norm robustness. They can be
transformed to ℓ0-norm robustness via leveraging the relationship between ℓp norms. However, such
transformations lead to suboptimal ℓ0-norm certified robustness. In response, multiple studies (Lee
et al., 2019; Levine & Feizi, 2019; Dvijotham et al., 2019; Bojchevski et al., 2020; Jia et al., 2020;
Zhang et al., 2021; Wang et al., 2021; Liu et al., 2021) proposed new randomized smoothing schemes
to certify ℓ0-norm robustness. For instance, Lee et al. (2019) derived an ℓ0-norm certified robustness
for classifiers with discrete features using randomized smoothing. In particular, for each feature,
they keep its value with a certain probability and change it to a random value in the feature domain
with an equal probability. Levine & Feizi (2019) proposed randomized ablation, which achieves
state-of-the-art ℓ0-norm certified robustness. However, their work focused on top-1 predictions and
they did not analyze the tightness of the certified robustness guarantee for top-1 predictions. We
derive an almost tight ℓ0-norm certified robustness guarantee of top-k predictions for randomized
ablation.

5 CONCLUSION

In this work, we derive an almost tight ℓ0-norm certified robustness guarantee of top-k predictions
against adversarial perturbations for randomized ablation. We show that a label l is provably among
the top-k labels predicted by a classifier smoothed by randomized ablation for a testing input when an
attacker arbitrarily modifies a bounded number of features of the testing input. Moreover, we prove
our derived bound is almost tight. Our empirical results show that our ℓ0-norm certified robustness is
substantially better than those transformed from ℓ2-norm certified robustness. Interesting future works
include exploring other noise to certify ℓ0-norm robustness for top-k predictions and incorporating
the information of the base classifier to derive larger certified radiuses.

ACKNOWLEDGMENTS

We thank the anonymous reviewers for insightful reviews. This work was supported by the National
Science Foundation under Grants No. 1937786 and 2125977, as well as the Army Research Office
under Grant No. W911NF2110182.


-----

REFERENCES

[Amazon AWS. https://aws.amazon.com/rekognition/. April 2021.](https://aws.amazon.com/rekognition/)

Anish Athalye and Nicholas Carlini. On the robustness of the cvpr 2018 white-box adversarial
example defenses. arXiv, 2018.

Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In ICML, 2018.

Avrim Blum, Travis Dick, Naren Manoj, and Hongyang Zhang. Random smoothing might be unable
to certify ℓ robustness for high-dimensional images. arXiv preprint arXiv:2002.03517, 2020.
_∞_

Aleksandar Bojchevski, Johannes Klicpera, and Stephan Gunnemann. Efficient robustness certificates¨
for discrete data: Sparsity-aware randomized smoothing for graphs, images and more. In ICML,
2020.

Jacob Buckman, Aurko Roy, Colin Raffel, and Ian Goodfellow. Thermometer encoding: One hot
way to resist adversarial examples. In ICLR, 2018.

Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A unified
view of piecewise linear neural network verification. In NeurIPS, 2018.

Xiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion attacks to deep neural networks via
region-based classification. In ACSAC, 2017.

Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods. In AISec, 2017.

Nicholas Carlini, Guy Katz, Clark Barrett, and David L Dill. Provably minimally-distorted adversarial
examples. arXiv, 2017.

Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Unlabeled
data improves adversarial robustness. In Advances in Neural Information Processing Systems, pp.
11192–11203, 2019.

Chih-Hong Cheng, Georg Nuhrenberg, and Harald Ruess. Maximum resilience of artificial neural¨
networks. In ATVA, 2017.

Ping-yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studer, and Tom Goldstein.
Certified defenses for adversarial patches. arXiv preprint arXiv:2003.06693, 2020.

[Clarifai. https://www.clarifai.com/demo. April 2021.](https://www.clarifai.com/demo)

Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. Certified adversarial robustness via randomized
smoothing. In ICML, 2019.

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale
hierarchical image database. In CVPR, 2009.

Guneet S Dhillon, Kamyar Azizzadenesheli, Zachary C Lipton, Jeremy Bernstein, Jean Kossaifi, Aran
Khanna, and Anima Anandkumar. Stochastic activation pruning for robust adversarial defense. In
_ICLR, 2018._

Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan O’Donoghue,
Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned verifiers. arXiv,
2018a.

Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A Mann, and Pushmeet Kohli. A
dual approach to scalable verification of deep networks. In UAI, 2018b.

Krishnamurthy Dj Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gyorgy,
Kai Xiao, Sven Gowal, and Pushmeet Kohli. A framework for robustness certification of smoothed
classifiers using f-divergences. In International Conference on Learning Representations, 2019.


-----

Ruediger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. In ATVA,
2017.

Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Con_straints, 2018._

Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin
Vechev. Ai2: Safety and robustness certification of neural networks with abstract interpretation. In
_IEEE S & P, 2018._

Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In ICLR, 2015.

[Google Cloud Vision. https://cloud.google.com/vision/. April 2021.](https://cloud.google.com/vision/)

Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation
for training verifiably robust models. arXiv, 2018.

Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten. Countering adversarial
images using input transformations. In ICLR, 2018.

Jinyuan Jia, Binghui Wang, Xiaoyu Cao, and Neil Zhenqiang Gong. Certified robustness of community detection against adversarial structural perturbation via randomized smoothing. In WWW,
2020.

Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An efficient
smt solver for verifying deep neural networks. In CAV, 2017.

Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.

Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certifiable robustness. In ICML, 2020.

Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In IEEE S & P, 2019.

Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S Jaakkola. Tight certificates of adversarial
robustness for randomly smoothed classifiers. In NeurIPS, 2019.

Alexander Levine and Soheil Feizi. Robustness certificates for sparse adversarial attacks by randomized ablation. arXiv preprint arXiv:1911.09272, 2019.

Alexander Levine and Soheil Feizi. Wasserstein smoothing: Certified robustness against wasserstein
adversarial attacks. In International Conference on Artificial Intelligence and Statistics, pp.
3938–3947. PMLR, 2020.

Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. In NeurIPS, 2019.

Hongbin Liu, Jinyuan Jia, and Neil Zhenqiang Gong. Pointguard: Provably robust 3d point cloud
classification. In CVPR, 2021.

Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. In ECCV, 2018.

Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu
neural networks. arXiv, 2017.

Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Grant Schoenebeck,
Dawn Song, Michael E Houle, and James Bailey. Characterizing adversarial subspaces using local
intrinsic dimensionality. In ICLR, 2018.


-----

Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff. On detecting adversarial
perturbations. In ICLR, 2017.

[Microsoft. https://aidemos.microsoft.com/computer-vision. April 2021.](https://aidemos.microsoft.com/computer-vision)

Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for provably
robust neural networks. In ICML, 2018.

Taesik Na, Jong Hwan Ko, and Saibal Mukhopadhyay. Cascade adversarial machine learning
regularized with a unified embedding. In ICLR, 2018.

Jerzy Neyman and Egon Sharpe Pearson. Ix. on the problem of the most efficient tests of statistical
hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing
_Papers of a Mathematical or Physical Character, 231(694-706):289–337, 1933._

Rafael Pinot, Laurent Meunier, Alexandre Araujo, Hisashi Kashima, Florian Yger, Cedric Gouy-´
Pailler, and Jamal Atif. Theoretical evidence for adversarial robustness through randomization. In
_NeurIPS, 2019._

Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets
for 3d classification and segmentation. In Proceedings of the IEEE conference on computer vision
_and pattern recognition, pp. 652–660, 2017._

Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial
examples. In ICLR, 2018a.

Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang. Semidefinite relaxations for certifying
robustness to adversarial examples. In NeurIPS, 2018b.

Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classifiers. In
_NeurIPS, 2019._

Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor, and J Zico Kolter. Black-box smoothing: A
provable defense for pretrained classifiers. arXiv preprint arXiv:2003.01908, 2020.

Karsten Scheibler, Leonore Winterer, Ralf Wimmer, and Bernd Becker. Towards verification of
artificial neural networks. In MBMV, 2015.

Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus Puschel, and Martin Vechev. Fast and¨
effective robustness certification. In NeurIPS, 2018.

Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. Pixeldefend:
Leveraging generative models to understand and defend against adversarial examples. In ICLR,
2018.

Jan Svoboda, Jonathan Masci, et al. Peernets: Exploiting peer wisdom against adversarial attacks. In
_ICLR, 2019._

Jonathan Uesato, Brendan O’Donoghue, Pushmeet Kohli, and Aaron Oord. Adversarial risk and the
dangers of evaluating against weak attacks. In ICML, 2018.

Binghui Wang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong, et al. On certifying robustness against
backdoor attacks via randomized smoothing. CVPR 2020 Workshop on Adversarial Machine
_Learning in Computer Vision, 2020._

Binghui Wang, Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang Gong. Certified robustness of graph
neural networks against adversarial structural perturbation. In KDD, 2021.

Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis
of neural networks using symbolic intervals. In USENIX Security Symposium, 2018.

Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning, Inderjit S
Dhillon, and Luca Daniel. Towards fast computation of certified robustness for relu networks. In
_ICML, 2018._


-----

Eric Wong and J Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In ICML, 2018.

Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial
defenses. In NeurIPS, 2018.

Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong
Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE
_conference on computer vision and pattern recognition, pp. 1912–1920, 2015._

Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. Mitigating adversarial effects
through randomization. In ICLR, 2018.

Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. In ICML, 2020.

Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh,
and Liwei Wang. Macer: Attack-free and scalable robust training via maximizing certified radius.
In ICLR, 2020.

Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu. Black-box certification with randomized smoothing: A functional optimization based framework. arXiv preprint
_arXiv:2002.09169, 2020._

Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural network
robustness certification with general activation functions. In NeurIPS, 2018.

Zaixi Zhang, Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. Backdoor attacks to graph
neural networks. In SACMAT, 2021.

Tianhang Zheng, Di Wang, Baochun Li, and Jinhui Xu. Towards assessment of randomized mechanisms for certifying adversarial robustness. arXiv preprint arXiv:2005.07347, 2020.


-----

A PROOF OF THEOREM 1

We define the following two random variables:

_U = h(x, e), V = h(x + δ, e)._ (9)

where U and V denote the ablated inputs derived from x and its perturbed version x + δ with
parameter e, respectively. We use S to denote the domain space of U and V .

Our proof is based on the Neyman-Pearson Lemma (Neyman & Pearson, 1933), and we present it as
follows:
**Lemma 1 (Neyman-Pearson Lemma). Suppose U and V are two random variables in the space**
_S with probability distributions ρu and ρv, respectively. Let F : S −→{0, 1} be a random or_
_deterministic function. Then, we have the following:_

-  If Z1 = {s ∈S : ρu(s) > µ · ρv(s)} and Z2 = {s ∈S : ρu(s) = µ · ρv(s)} for some
_µ > 0. Let Z = Z1_ _Z3, where Z3_ _Z2. If we have Pr(F_ (U ) = 1) _Pr(U_ _Z), then_
_Pr(F_ (V ) = 1) ≥ _Pr ∪(V ∈_ _Z)._ _⊆_ _≥_ _∈_

-  If Z1 = {s ∈S : ρu(s) < µ · ρv(s)} and Z2 = {s ∈S : ρu(s) = µ · ρv(s)} for some
_µ > 0. Let Z = Z1_ _Z3, where Z3_ _Z2. If we have Pr(F_ (U ) = 1) _Pr(U_ _Z), then_
_Pr(F_ (V ) = 1) ≤ _Pr ∪(V ∈_ _Z)._ _⊆_ _≤_ _∈_

_Proof. We show the proof of the first part, and the second part can be proved similarly. For simplicity,_
we use F (1|s) and F (0|s) to denote the conditional probabilities that F (s) = 0 and F (s) = 1,
respectively. We use Z _[c]_ to denote the complement of Z, i.e., Z _[c]_ = S \ Z. We have the following:

Pr(F (V ) = 1) − Pr(V ∈ _Z)_ (10)

= _F_ (1 **s)** _ρv(s)_ _ρv(s)_ (11)

_|_ _·_ _−_

Xs∈S _sX∈Z_

= _F_ (1 **s)** _ρv(s) +_ _F_ (1 **s)** _ρv(s)_ _F_ (1 **s)** _ρv(s)_ _F_ (0 **s)** _ρv(s)_ (12)

_|_ _·_ _|_ _·_ _−_ _|_ _·_ _−_ _|_ _·_
_sX∈Z[c]_ _sX∈Z_ _sX∈Z_ _sX∈Z_

= _F_ (1 **s)** _ρv(s)_ _F_ (0 **s)** _ρv(s)_ (13)

_|_ _·_ _−_ _|_ _·_
_sX∈Z[c]_ _sX∈Z_

_F_ (1 **s)** _ρu(s)_ _F_ (0 **s)** _ρu(s))_ (14)

_≥_ _µ[1]_ _|_ _·_ _−_ _|_ _·_

_[·][ (]sX∈Z[c]_ _sX∈Z_

= [1] _F_ (1 **s)** _ρu(s) +_ _F_ (1 **s)** _ρu(s)_ _F_ (1 **s)** _ρu(s)_ _F_ (0 **s)** _ρu(s)) (15)_

_µ_ _|_ _·_ _|_ _·_ _−_ _|_ _·_ _−_ _|_ _·_

_[·][ (]sX∈Z[c]_ _sX∈Z_ _sX∈Z_ _sX∈Z_

= [1] _F_ (1 **s)** _ρu(s)_ _ρu(s))_ (16)

_µ_ _|_ _·_ _−_

_[·][ (]sX∈S_ _sX∈Z_

= [1] (17)

_µ_

_[·][ (][Pr][(][F]_ [(][U] [) = 1)][ −] [Pr][(][U][ ∈] _[Z][))]_

_≥0._ (18)

We obtain (14) from (13) because ρu(s) _µ_ _ρv(s),_ **s** _Z and ρu(s)_ _µ_ _ρv(s),_ **s** _Z_ _[c]. We_
_≥_ _·_ _∀_ _∈_ _≤_ _·_ _∀_ _∈_
have the last inequality because Pr(F (U ) = 1) ≥ Pr(U ∈ _Z)._

Next, we will derive our certified robustness guarantee. For simplicity, we denote Γ = {1, 2, · · ·, c}\
_{l}, i.e., Γ denotes the set of all labels except l. We use Γk to denote a set of k labels in Γ._

**Calibrating the lower and upper bounds: Recall that pl and pj,** _j_ = l are integer multiple of 1d
_∀_ _̸_ (e[)] [.]

Then, given the probability lower and upper bounds in Equation (3), we have the following:

_d_ _d_
_e_ _e_
_p[′]l_ [≜] _[⌈][p][l][ ·]d_ _⌉_ _≤_ Pr(f (U ) = l), p[′]j [≜] _[⌊][p][j][ ·]d_ _⌋_ _≥_ Pr(f (U ) = j), ∀j ̸= l, (19)
_e _  _e _ 
     


-----

**Deriving a lower bound of Pr(f** (V ) = l): We will derive a lower bound of the probability
Pr(f (V ) = l). For simplicity, we define the following regions:

_A = {s ∈S|s ⪯_ **x, s ̸⪯** **x + δ}, B = {s ∈S|s ̸⪯** **x, s ⪯** **x + δ}, C = {s ∈S|s ⪯** **x, s ⪯** **x + δ},**
(20)

where we say s ⪯ **x if Pr(h(x, e) = s) > 0, and we say s ̸⪯** **x if Pr(h(x, e) = s) = 0. Intuitively,**
the notations ⪯ and ̸⪯ mean that an ablated input can or cannot be derived from an input, respectively.
For instance, region A contains ablated inputs that can be derived from x but cannot be derived from
**x + δ, region B contains ablated inputs that can be derived from x + δ but cannot be derived from x,**
and regionr = _δ_ 0. Then, the size of C contains ablated inputs that can be derived from both would be _d−e_ _r_ since d _r features are the same for x and x + δ. Suppose we have x and x + δ._
Similarly, we know the size of || _||_ _C A and B would be _  _de_ _− −d−e_ _r_ . Since we keep e features randomly
sampled from x or x + δ without replacement and set the remaining features to a special value, we
     
have the following probability mass functions:

1

Pr(U = s) = (de[)] _[,]_ if s ∈A ∪C (21)

(0, otherwise.

1

Pr(V = s) = (de[)] _[,]_ if s ∈B ∪C (22)

(0, otherwise.

Since we know the size of A, B, and C, as well as the probability mass functions of the random
variables U and V in these regions, we have the following probabilities:

Pr(U ) = _d−de_ _r, Pr(U_ ) = 1 _d−de_ _r, Pr(U_ ) = 0, (23)
_∈C_ _∈A_ _−_ _∈B_

  _e_    _e_ 

Pr(V ) = _d −der, Pr(V_ ) = 1 _d −de_ r, Pr(V ) = 0. (24)
_∈C_ _∈B_ _−_ _∈A_

  _e_    _e_ 

  _d−e_ _r[)]_   

We consider the case of p[′]l _[≥]_ [1][ −] [(](de[)][ . Note that we can do this because we aim to find a sufficient]

condition. We let A[′] _⊆C such that it satisfies the following:_

Pr(U ) = p[′]l (25)
_∈A[′]_ _[−]_ [Pr][(][U][ ∈A][)][.]

Given region A[′], we construct the following region:

_E = A[′]_ _∪A._ (26)

Then, we have the following probability based on Equation (25):

Pr(U ∈E) = Pr(U ∈A) + Pr(U ∈A[′]) = p[′]l[.] (27)

We define a binary function F (s) = I(f (s) = l). Then, we have the following:

Pr(F (U ) = 1) = Pr(f (U ) = l) ≥ _p[′]l_ [=][ Pr][(][U][ ∈E][)][.] (28)

The middle inequality is based on Equation (19) and the right-hand equality is from Equation (27).
Furthermore, we have Pr(U = s) > 1·Pr(V = s) if and only if s ∈A, and Pr(U = s) = 1·Pr(V = s)
if s ∈A[′]. Therefore, we can apply Lemma 1 and we have the following:

Pr(F (V ) = 1) = Pr(f (V ) = l) ≥ Pr(V ∈E). (29)

Therefore, we have the following lower bound for Pr(f (V ) = l):

Pr(V ∈E) (30)

=Pr(V ∈A[′]) + Pr(V ∈A) (31)

=Pr(V ∈A[′]) (32)

=Pr(U ∈A[′]) (33)


-----

=p[′]l _d−de_ _r )._ (34)

_[−]_ [(1][ −]   _e_ 

Note that we have Equation (34) from (33) based on Equation (25).  

**Deriving an upper bound of maxΓk⊂Γ minj∈Γk Pr(f** (V ) = j): We use Λ to denote an arbitrary
subset of Γk, i.e., Λ ⊆ Γk. We denote p[′]Λ [=][ P]j∈Λ _[p]j[′]_ [, which is the sum of the upper bound of the]

probability for the labels in Λ. We assume p[′]Λ
we aim to find a sufficient condition. Given p[′]Λ[≤][, we can find a region][Pr][(][U][ ∈C][)][. We can make this assumption because][ H][Λ][ ⊆C][ such that we have the]
following:

_p[′]Λ_ [=][ Pr][(][U][ ∈H][Λ][)][.] (35)

Given the region Λ, we construct the following region:
_H_

_IΛ = HΛ ∪B._ (36)

Then, we have the following probability:

Pr(U ∈IΛ) = Pr(U ∈HΛ) + Pr(U ∈B) = p[′]Λ[.] (37)

Furthermore, for any given Λ, we define a binary function G(s) = I(f (s) ∈ Λ). Then, we have the
following:


Pr(G(U ) = 1) = Pr(f (U ) ∈ Λ) =


Pr(f (U ) = j) ≤ _p[′]Λ_ [=][ Pr][(][U][ ∈I][Λ][)][.] (38)
_jX∈Λ_


We have _j_ Λ [Pr][(][f] [(][U] [) =][ j][)][ ≤] _[p]Λ[′]_ [based on Equation (19) and we have rightmost equality from]

_∈_
Equation (37). Then, we can apply Lemma 1 and we have the following:

[P] Pr(G(V ) = 1) Pr(V Λ). (39)

_≤_ _∈I_

The value of Pr(V Λ) can be computed as follows:
_∈I_

Pr(V _IΛ)_ (40)
_∈_
=Pr(V Λ) + Pr(V ) (41)
_∈H_ _∈B_

=Pr(U Λ) + (1 _d−de_ _r )_ (42)
_∈H_ _−_

  _e_ 

=p[′]Λ [+ (1][ −] _d−de_ _r ),_    (43)

  _e_ 

where the last equality is from Equation (35). Therefore, we have the following:  

Pr(f (V ) = j) (44)
_jX∈Λ_

=Pr(f (V ) ∈ Λ) (45)
=Pr(G(V ) = 1) (46)
Pr(V Λ) (47)
_≤_ _∈I_

=pΛ + (1 _d−de_ _r )._ (48)
_−_

  _e_ 

Moreover, we have the following:   

_j_ Λ [Pr][(][f] [(][V][ ) =][ j][)]

min _∈_ = [Pr][(][f] [(][V][ )][ ∈] [Λ)] _._ (49)
_j∈Γk_ [Pr][(][f] [(][V][ ) =][ j][)][ ≤] [min]j∈Λ [Pr][(][f] [(][V][ ) =][ j][)][ ≤] P _|Λ|_ _|Λ|_

We have the leftmost inequality because Λ Γk, and we have the middle inequality because the
_⊆_
smallest value in a set is no larger than the average value of the set. Taking all possible Λ into
consideration and we have the following:


min (50)
_j∈Γk_ [Pr][(][f] [(][V][ ) =][ j][)]


-----

Pr(f (V ) Λ)
min _∈_ (51)
_≤_ Λ Γk Λ
_⊆_ _|_ _|_

_k_ Pr(f (V ) Λ)
= min min _∈_ (52)
_t=1_ Λ⊆Γk,|Λ|=t _|Λ|_

_k_ Pr(f (V ) Υt)
= min _∈_ (53)
_t=1_ _t_

_d−e_ _r[)]_

_k_ _p[′]Υt_ [+ (1][ −] [(](de[) )]
min _,_ (54)
_≤_ _t=1_ _t_

where Υt is the set of t labels in Γk whose probability upper bounds are the smallest, where ties
are broken uniformly at random. The upper bound of Pr(f (V ) ∈ Υt) is increasing as p[′]Υt [increases.]
Therefore, the upper bound of [Pr][(][f] [(][V]t[ )][∈][Υ][t][)] reaches the maximum value when Γk = _a1, a2,_ _, ak_,

_{_ _· · ·_ _}_
i.e., Γk is the set of labels in Γ with the largest probability upper bounds. In other words, we have the
following:


_d−e_ _r[)]_
_p[′]Υt_ [+ (1][ −] [(](de[) )]


max min _t_ (e _,_ (55)
Γk⊂Γ _j[min]∈Γk_ [Pr][(][f] [(][V][ ) =][ j][)][ ≤] _t=1_ _t_

where Υt = {a1, a2, · · ·, at}.

**Deriving the certified radius: Our goal is to make Pr(f** (V ) = l) > maxΓk⊂Γ minj∈Γk Pr(f (V ) =
_j). Therefore, it is sufficient to satisfy the following:_

_d−e_ _r[)]_

_p[′]l_ _[−]_ [(1][ −]  d−dee _r )_ _>_ mint=1k _p[′]Υt_ [+ (1]t[ −] [(](de[) )] _,_ (56)

where Υt = _a1, a2,_ _, at_ . Therefore, we can find the maximum   _r that satisfies the above_
_{_ _· · ·_ _}_
condition. Formally, we can solve the following optimization problem to find rl:
_rl = arg max_ _r_ (57)
_r_

_d−e_ _r[)]_

s.t. p[′]l _[−]_ [(1][ −]  d−dee _r )_ _> mint_ _p[′]Υt_ [+ (1]t[ −] [(](de[) )] _,_ (58)

where Υt = _a1, a2,_ _, at_ . Note that we make two assumptions in our derivation, i.e.,   _p[′]l_
(d−e _r[)]_ _{_ _d− · · ·e_ _r[)]_ _}_ _[≥]_ _d[(1]−e_ _r[ −][)]_

(de[) )][ and][ p]Υ[′] _t_ _[≤]_ [(](de[)][ . In particular, when Equation (58) is satisfied, we must have][ p]l[′] _[≥]_ [(1][−] [(](de[) )]

since the left-hand side of Equation (58) is non-negative. In addition, we have p[′]l [+][ p]Υ[′] _t_

_d−e_ _r[)]_ _[≤]_ [1][ in]
practice. Therefore, we have p[′]Υt _[≤]_ [1][ −] _[p]l[′]_ _[≤]_ [(](de[)][ .]

**Technical differences with Jia et al. (2020): Our technical contribution in proving the theorem is**
the construction of new discrete regions such that the Neyman-Pearson Lemma can be used. Our
proof of Theorem 1 has the following differences with Jia et al. First, the construct of the regions
_A/B/C (Eq 18) are different from Jia et al. due to the discrete space. Second, deriving the lower_
bound of Pr(f (V ) = l) faces two new challenges in our case. The first challenge is that we need
to find two regions A and A[′] while Jia et al. just need to find one region. The second challenge is
how to find these regions. To address the challenge, we first take into consideration of whether A[′]
exists or not. If A[′] exists, we need to shrink region A[′] because our space is discrete. These two
challenges do not exist in the continuous case considered by Jia et al. Third, similar to deriving the
lower bound of Pr(f (V ) = l), our work is also different from Jia et al. at deriving the upper bound
of maxΓk∈Γ minj∈Γk Pr(f (V ) = j).

B PROOF OF THEOREM 2

We consider two scenarios: k = 1 and k ̸= 1. In particular, we first consider the scenario where
_k = 1. We have Γ1 = {a1} when k = 1. We consider two cases._


_d−e_ _r[)]_
_p[′]Υt_ [+ (1][ −] [(](de[) )]


_p[′]l_

_[−]_ [(1][ −]


_d−e_ _r[)]_
_p[′]Υt_ [+ (1][ −] [(](de[) )]


s.t. p[′]l

_[−]_ [(1][ −]


-----

**Case I: In this case, we consider p[′]l** _[<][ (1][ −]_ [(]d−(rldee[)]−1) ). We let Al ⊆A be the region that satisfies the

following:

_p[′]l_ [=][ Pr][(][U][ ∈A][l][)][.] (59)


We can find such region because p[′]l [is an integer multiple of]

following:


1

_d_
_e[)]_ [. We let][ D][l][ =][ A][l][ and we have the]


_p[′]l_ [=][ Pr][(][U][ ∈D][l][)][,][ Pr][(][V][ ∈D][l][) = 0][.] (60)

Then, we can divide the remaining region (A ∪C) \ Dl into c − 1 disjoint regions such that we have
the following:

_∀j ∈{1, 2, · · ·, c} \ {l}, Pr(U ∈Dj) ≤_ _p[′]j[.]_ (61)

We can find these regions because we have p[′]l [+][ P]s=l _[p]s[′]_

_̸_ _[≥]_ [1][. Moreover, we have the following:]

_j_ 1, 2, _, c_ _l_ _, Pr(V_ _j)_ 0. (62)
_∀_ _∈{_ _· · ·_ _} \ {_ _}_ _∈D_ _≥_

Given these regions, we construct the following base classifier:

_f_ (z) = j, if z _j._ (63)

_[∗]_ _∈D_

Note that f _[∗]_ is well defined and is consistent with Equation (3). It is easy to see that label l is not the
predicted label by the corresponding smoothed classifier g[∗] when ∥δ∥0 > rl.

**Case II: In this case, we consider p[′]l** _d−(rldee[)]−1)_ ). Since rl is the maximum value that satisfies

_[≥]_ [(1][ −] [(]

Equation (6), we have the following condition when ∥δ∥0 = rl + 1:

_p[′]l_ _[−]_ [(1][ −]  d−rdeel−1 ) ≤ _p[′]a1_ [+ (1][ −]  d−rdeel−1 ). (64)

We let Al = A and we can find Cl ∈C such that the following equation holds:     

Pr(U _l) = p[′]l_ _d−rdel−1_ ). (65)
_∈C_ _[−]_ [(1][ −]   _e_ 

Then, we let Dl = Cl ∪Al and we have the following:   

Pr(U ∈Dl) = p[′]l[.] (66)

Furthermore, we have the following:

Pr(V _l)_ (67)
_∈D_
=Pr(V _l) + Pr(V_ _l)_ (68)
_∈C_ _∈A_
=Pr(U _l) + 0_ (69)
_∈C_

=p[′]l _d−rdel−1_ ), (70)

_[−]_ [(1][ −]   _e_ 

where the last equality is from Equation (65). Since we have   _p[′]l_ [+][ p]a[′] 1 _[≤]_ [1][, we can find region]
_Ca1 ∈C \ Cl such that we have the following:_

Pr(U ∈Ca1 ) = p[′]a1 _[.]_ (71)

We definethe following: Da1 = Ca1 ∪B. Then, we have Pr(U ∈Da1 ) = Pr(U ∈Ca1 ) = p[′]a1[. Similarly, we have]

Pr(V _a1_ ) (72)
_∈D_
=Pr(V _a1_ ) + Pr(V ) (73)
_∈C_ _∈B_

=p[′]a1 [+ (1][ −] _d−rdel−1_ ). (74)

  _e_ 

  


-----

Finally, we can divide the remaining region ( _l_ _a1_ ) into c 2 disjoint regions such that
we have the following: _A ∪C \_ _D_ _∪C_ _−_

_∀j ∈{1, 2, · · ·, c} \ ({l} ∪{a1}), Pr(U ∈Dj) ≤_ _p[′]j[.]_ (75)

We can find these region because p[′]l [+][ P]s=l _[p]s[′]_

_̸_ _[≥]_ [1][. Given these regions, we construct the following]
base classifier:

_f_ (z) = j, if z _j._ (76)

_[∗]_ _∈D_

Note that f _[∗]_ is well defined and is consistent with Equation (3). Next, we show that label l is not in
the top-1 predicted labels by the smoothed classifier or there exist ties when the ℓ0 perturbation is
larger than rl. In particular, we have the following:

Pr(f _[∗](V ) = a1| ∥δ∥0 > rl)_ (77)
=Pr(V ∈Da1 _| ∥δ∥0 > rl)_ (78)

=p[′]a1 [+ (1][ −] _d−rdel−1_ ) (79)

  _e_ 

_p[′]l_ _d−der −1_ ) (80)
_≥_ _[−]_ [(1][ −]   _e_ 

=Pr(V _l_  δ 0 > rl) (81)
_∈D_ _| ∥_ _∥_
=Pr(f _[∗](V ) = l| ∥δ∥0 > rl)._ (82)

We have Equation (80) from (79) based on Equation (64). Therefore, the label l is not predicted by
the corresponding smoothed classifier g[∗] or there exist ties. Combining the two cases, we reach the
conclusion.

Next, we will show our bound is almost tight when k ̸= 1. In particular, we will show we can
construct a classifier f _[∗]_ such that the label l is not among the top-k predicted labels or there exist ties
when the adversarial perturbation is larger than rl + 1. Similarly, we consider two cases.

**Case I: In this case, we consider p[′]l** _[<][ (1][ −]_ [(]d−(rldee[)]−2) ). We let Al ⊆A be the region that satisfies the

following:

_p[′]l_ [=][ Pr][(][U][ ∈A][l][)][.] (83)


We can find such region because p[′]l [is an integer multiply of][ ν][ =]

the following:


1

_d_
_e[)]_ [. We let][ D][l][ =][ A][l][ and we have]


_p[′]l_ [=][ Pr][(][U][ ∈D][l][)][,][ Pr][(][V][ ∈D][l][) = 0][.] (84)

Then, we can divide the remaining region (A ∪C) \ Dl into c − 1 disjoint regions such that we have
the following:

_∀j ∈{1, 2, · · ·, c} \ {l}, Pr(U ∈Dj) ≤_ _p[′]j[.]_ (85)

We can find these regions because we have p[′]l [+][ P]s=l _[p]s[′]_

_̸_ _[≥]_ [1][. Moreover, we have the following:]

_j_ 1, 2, _, c_ _l_ _, Pr(V_ _j)_ 0. (86)
_∀_ _∈{_ _· · ·_ _} \ {_ _}_ _∈D_ _≥_

Given these regions, we construct the following base classifier:

_f_ (z) = j, if z _j._ (87)

_[∗]_ _∈D_

Note that f _[∗]_ is well defined and is consistent with Equation (3). It is easy to see that label l is not
among the top-k predicted labels or there exist ties when ∥δ∥0 > rl + 1.

**Case II: In this case, we consider p[′]l** _d−(rldee[)]−2)_ ). For simplicity, we denote the following

_[≥]_ [(1][ −] [(]

quantity:

1
_ν =_ _d_ _._ (88)
_e_
  


-----

Since rl is the maximum value that satisfies Equation (6), we have the following condition:


_p[′]Υt_ [+ (1][ −] [(]d−(rldee[)]−1


_p[′]l_ _[−]_ [(1][ −]  d−rdeel−1 ) ≤ mint _p[′]Υt_ [+ (1][ −]t [(]d−(rldee[)]−1) ) _._ (89)

In other words, the left-hand side of Equation (6) is no larger than its right-hand side when   _r = rl + 1._
Based on the recurrence relation of the binomial coefficient, we have the following:

_d_ _rl_ 1 _d_ _rl_ 2 _d_ _rl_ 2
_−_ _−_ = _−_ _−_ + _−_ _−_ _._ (90)
_e_ _e_ _e_ 1
     _−_ 

Combining with the condition _d−erl1−2_ 1, we have the following:
_−_ _≥_

_d_ _rl_ 1

  _p[′]l_  _−_ _de_ _−_ ) (91)

_[−]_ [(1][ −]   _e_ 

_d_ _rl_ 2 _d_ _rl_ 2

=p[′]l _− de−_ _−e−d_ 1− ) (92)

_[−]_ [(1][ −]   _e_  _−_   _e_ 

_d_ _rl_ 2 _d_ _rl_ 2

=p[′]l [+] _−e−d_ 1−    (1 _− de−_ ) (93)

_−_ _−_

  _e_    _e_ 

_p[′]l_ [+][ ν][ −] [(1][ −] _d−rdel−2_ ).   (94)
_≥_

  _e_ 

Similarly, we have the following:   

_p[′]Υt_ [+ (1][ −] [(]d−(rldee[)]−1) )

min (95)
_t_ _t_

_p[′]Υt_ _d−e(rl−de[)]1−2[)]_ + (1 − [(]d−(rldee[)]−2) )

= min _[−]_ [(] (96)
_t_ _t_

_p[′]Υt_ _d−(rldee[)]−2)_ )

min _[−]_ _[ν][ + (1][ −]_ [(] _._ (97)
_≤_ _t_ _t_

Then, based on Equation (89), we have the following:

_d−rel−2_ _p[′]Υt_ _d−(rldee[)]−2)_ )

_p[′]l_ [+][ ν][ −] [(1][ −] _d_ ) ≤ mint _[−]_ _[ν][ + (1]t[ −]_ [(] (98)

  _e_ 

_d−rle_ _−2)_

_d−rel−2 _  _p[′]Υt_ (de[)] )

_⇐⇒p[′]l_ _[−]_ [(1][ −]   _de_  ) ≤ mint _[−]_ _[ν][ −]_ _[t][ ·][ ν][ + (1]t_ _[ −]_ [(] (99)

_d−rle_ _−2)_

_d− rel−2_ _p[′]Υt_ (de[)] )

=⇒p[′]l _[−]_ [(1][ −]   _de_  ) < mint _[−]_ _[t][ ·][ ν][ + (1]t_ _[ −]_ [(] _._ (100)

For simplicity, we denote the following:  

_k_ _pΥt_ _t · ν + (1 −_ [(]d−(rldee[)]−2) )
_w =_ arg min _−_ _,_ (101)
_t=1_ _t_

where ties are broken uniformly at random. Then, based on Equation (100), we have the following:


_p[′]l_

_[−]_ [(1][ −]


_p[′]Υw_ _d−(rldee[)]−2_

_[−]_ _[w][ ·][ ν][ + (1][ −]_ [(]


_d−rdel−2_ ) <
  _e_ 

  


_p[′]l_

_[−]_ [(1][ −]


(102)


-----

Given Equation (101), we have the following if w < k:

_p[′]Υw+1_ _d−(rldee[)]−2)_ )

_[−]_ [(][w][ + 1)][ ·][ ν][ + (1][ −] [(]

_w + 1_ _≥_


_p[′]Υw_ _d−(rldee[)]−2_

_[−]_ _[w][ ·][ ν][ + (1][ −]_ [(]


(103)

(104)

(105)

(106)

(107)

(108)

(109)

(110)

(111)


_p[′]Υw+1_ [+ (1][ −] [(]d−(rldee[)]−2

_w + 1_


_p[′]Υw_ [+ (1][ −] [(]d−(rldee[)]−2


_p[′]Υw_ [+ (1][ −] [(]d−(rldee[)]−2


_p[′]Υw+1_ [+ (1][ −] _d−rdel−2_ ) (w + 1) _p[′]Υw_ [+ (1][ −] [(]d−(rldee[)]−2) )
_⇐⇒_ _≥_ _·_ _w_

  _e_ 

_d−rle_ _−2)_
_p [′]Υw_ [+ (1][ −] [(] (de[)] )

_⇐⇒p[′]Υw+1_ _[−]_ _[p]pΥ[′][′]Υww_ [+ (1][≥] _[ −]_ [(]d−(rldee[)]−w2) )

_⇐⇒p[′]aw+1_ _[≥]_ _w_ _,_

where Υw = {a1, a2, · · ·, aw}. Similarly, we have the following if w > 1:

_p[′]Υw−1_ _d−(rldee[)]−2)_ ) _p[′]Υw_ _d−(rldee[)]−2_

_[−]_ [(][w][ −] [1)][ ·][ ν][ + (1][ −] [(] _[−]_ _[wν][ + (1][ −]_ [(]

_w_ 1 _≥_ _w_

_p[′]Υw−1_ [+ (1][ −] [(]d−( −rldee[)]−2) ) _p[′]Υw_ [+ (1][ −] [(]d−(rldee[)]−2) )


_⇒p[′]Υw+1_ [+ (1][ −]


_⇐⇒_ _w_ 1 _≥_ _w_

_⇐⇒p[′]Υw−1_ [+ (1] −[ −] _d−rdel−2_ ) ≥ (w − 1) · _p[′]Υw_ [+ (1][ −]w [(]d−(rldee[)]−2) ) (110)

  _e_ 

_d−rle_ _−2)_
_p[′]Υw_ [+ (1][ −]  [(] (de[)] )

_⇐⇒p[′]aw_ _[≤]_ _w_ _._ (111)

Note that the Equation (111) also holds when w = 1. Next, we will show we can build a base
classifier f _[∗]_ such that the label l is not in the top-k predicted labels or there exist ties when the
adversarial perturbation is larger than rl + 1. Our proof relies on constructing disjoint regions for
label l, Υk, and 1, 2, _, c_ ( _l_ Υk), respectively.
_{_ _· · ·_ _} \_ _{_ _} ∪_

We let Al = A and we can find Cl ∈C such that the following equation holds:

Pr(U _l) = p[′]l_ _d−rdel−2_ ). (112)
_∈C_ _[−]_ [(1][ −]   _e_ 

Then, we let _l =_ _l_ _l and we have the following:_   
_D_ _C_ _∪A_

Pr(U ∈Dl) = p[′]l[.] (113)

Furthermore, we have the following:

Pr(V _l)_ (114)
_∈D_
=Pr(V _l) + Pr(V_ _l)_ (115)
_∈C_ _∈A_
=Pr(U _l) + 0_ (116)
_∈C_

=p[′]l _d−rdel−2_ ), (117)

_[−]_ [(1][ −]   _e_ 

where the last equality is from Equation (112). For simplicity, we denote the following value:  


_p[′]Υw_ [+ (1][ −] [(]d−(rldee[)]−2


(118)


_τ =_


-----

Next, we will construct the region for _j_ Υw. Based on Equation (112), we have the following:
_∀_ _∈_

Pr(U _l)_ (119)
_∈C \ C_
=Pr(U ) Pr(U _l)_ (120)
_∈C_ _−_ _∈C_

=(1 _d−rdel−2_ ) (p[′]l _d−rdel−2_ )) (121)
_−_   _e_  _−_ _[−]_ [(1][ −]   _e_ 

=1 _p[′]l[.]_       (122)
_−_

For ∀j ∈ Υw, we can find disjoint region Cj ⊆C \ Cl such that we have the following:

Pr(U ∈Cj) = p[′]j[.] (123)

We can find these regions because the summation of the probability of U in these regions is less than
the probability of U in _l, i.e., we have the following:_
_C \ C_

_jX∈Υw_ _p[′]j_ [=][ p]Υ[′] _w_ _[≤]_ [1][ −] _[p]l[′]_ [=][ Pr][(][U][ ∈C \ C][l][)][,] (124)

where the middle inequality is from the condition p[′]l [+][ P]s Υk _[p]s[′]_

_∈_ _[≤]_ [1][, and the right equality is based]
on Equation (119) - (122). Given these regions, we have the following:

_∀j ∈_ Υw, Pr(V ∈Cj) = p[′]j[.] (125)

Based on Equation (111), definition offollowing: _τ in Equation (118), and ∀j ∈_ Υw, p[′]j _[≤]_ _[p]a[′]_ _w_ [, we have the]

_j_ Υw, p[′]j _aw_ (126)
_∀_ _∈_ _[≤]_ _[p][′]_ _[≤]_ _[τ.]_

Then, for _j_ Υw, we can find disjoint region _j_ such that we have the following:
_∀_ _∈_ _B_ _∈B_

_τ −_ _ν −_ _p[′]j_ _[≤]_ [Pr][(][V][ ∈B][j][)][ ≤] _[τ][ −]_ _[p]j[′]_ _[.]_ (127)

We can construct these regions for three reasons: 1) the value of τ − _p[′]j_ [is no smaller than 0 based on]
Equation (126), 2)multiple of (1de[)] [, and 3) the summation of the probability of] ∀j ∈ Υw, there exists a number in the range[ V][ in these regions is no larger than the] [τ − _ν −_ _p[′]j[, τ][ −]_ _[p][′]j[]][ that is an integer]_

probability of V in B, i.e., we have the following:

Pr(V _j)_ (128)
_∈B_
_jX∈Υw_


_≤_ (τ − _p[′]j[)]_ (129)

_jX∈Υw_

=p[′]Υw [+ (1][ −] _d−rdel−2_ ) − _p[′]Υw_ (130)

  _e_ 

(1 _d−rdel−2_ )   (131)
_≤_ _−_

  _e_ 

=Pr(V ). (132)

  

_∈B_

For ∀j ∈ Υw, we let Dj = Cj ∪Bj. Then, we have the following:

Pr(V _j)_ (133)
_∈D_
=Pr(V _j) + Pr(V_ _j)_ (134)
_∈C_ _∈B_

_≥p[′]j_ [+][ τ][ −] _[ν][ −]_ _[p]j[′]_ (135)

=τ − _ν,_ (136)

where the Equation (135) from (134) is based on Equation (123) and (127). Next, we will construct
the regions for the labels in Υk Υw. In particular, for _j_ _aw+1, aw+2,_ _, ak_, we can find
disjoint region Dj ∈C \ (Cl ∪ (∪ \s∈Υw _Cs)) such that we have the following: ∀_ _∈{_ _· · ·_ _}_

Pr(U ∈Dj) = p[′]j[.] (137)


-----

Note that we can find these regions because p[′]l [+][ P]s Υk _[p]s[′]_

_∈_ _[≤]_ [1][. Similarly, we have the following]
for _j_ Υk Υw:
_∀_ _∈_ _\_

Pr(V _j) = p[′]j_ (138)
_∈D_ _[≥]_ _[τ.]_

We have the left inequality because _j_ Υk Υw, p[′]j
divide the remaining regionthat we have the following: _Dj ⊆C ∪A \ ∀_ _∈_ ( \Dl ∪ (∪s∈[≥]Υ[τ]k[ based on Equation (107). Finally, we can]Cs)) into c − _k −_ 1 disjoint regions such

_∀j ∈{1, 2, · · ·, c} \ ({l} ∪_ Υk), Pr(U ∈Dj) ≤ _p[′]j[.]_ (139)

We can find these region because p[′]l [+][ P]s=l _[p]s[′]_

_̸_ _[≥]_ [1][. Given these regions, we construct the following]
base classifier:

_f_ (z) = j, if z _j._ (140)

_[∗]_ _∈D_

Note that f _[∗]_ is well defined and is consistent with Equation (3). Next, we show that label l is not in
the top-k predicted labels by the smoothed classifier when the ℓ0 perturbation is larger than rl + 1. In
particular, for _j_ Υk, we have the following:
_∀_ _∈_

Pr(f _[∗](V ) = j| ∥δ∥0 > rl + 1)_ (141)
=Pr(V ∈Dj| ∥δ∥0 > rl + 1) (142)
_≥τp −[′]Υwν_ _d−(rldee[)]−2)_ ) (143)

= _[−]_ _[w][ ·][ ν][ + (1][ −]_ [(] (144)

_w_

_>p[′]l_ _d−der−2_ ) (145)

_[−]_ [(1][ −]   _e_ 

Pr(V _l_  δ 0 > rl + 1) (146)
_≥_ _∈D_ _| ∥_ _∥_
=Pr(f _[∗](V ) = l| ∥δ∥0 > rl + 1)._ (147)

We have Equation (145) from (144) based on Equation (102). Therefore, the label l is not among the
top-k predicted labels by the corresponding smoothed classifier g[∗]. Combining the two cases, we
reach the conclusion.

**Takeaway: The key challenge in proving the tightness of certified robustness guarantee is that we**
are not able to find regions in the discrete space that satisfy certain conditions. The reason is that
we cannot arbitrarily divide the discrete space into different regions. To address the challenge, we
propose to relax the conditions in finding the regions to prove that the certified robustness guarantee is
almost tight. The idea in our proof is very general and we hope our proof can inspire future research
in proving the (almost) tightness for ℓ0-norm certified robustness guarantee.

C OTHER APPLICATIONS

In this paper, we focus on image classification. However, our method is also applicable for other
applications such as graph neural networks and 3D deep learning. For example, we conduct experiments for 3D deep learning. In particular, we evaluate our methods on the ModelNet40 (Wu et al.,
2015) benchmark dataset and use PointNet (Qi et al., 2017) as the base classifier. We set e = 16,
_n = 10, 000, and α = 0.001. When the number of modified points is 10, 20, 30, 40, and 50, the_
certified accuracies for top-1 prediction are 0.779, 0.743, 0.700, 0.649, and 0.570; and the certified
accuracies for top-3 prediction are 0.901, 0.867, 0.829, 0.803, and 0.775.

D COMPARING WITH CHIANG ET AL. (2020)

We also compare with our method with Chiang et al. (2020). We note that the method in Chiang et al.
is only applicable for top-1 prediction. We compare with the method on the CIFAR10 dataset for
top-1 predictions using the publicly available code. The results are as follows. When the number of
perturbed pixels is 1, 2, 3, 4, and 5, the certified accuracies for our method are respectively 0.746,


-----

0.718, 0.690, 0.660, and 0.636. In contrast, the certified accuracies of Chiang et al. are 0.400, 0.369,
0.342, 0.312, 0.308. As the results show, our method is better than Chiang et al. (2020). We note that
our certified robustness guarantee is probabilistic while Chiang et al. (2020) can give a deterministic
certified robustness guarantee.


-----


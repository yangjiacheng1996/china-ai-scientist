# COMPOSITIONAL TRAINING FOR END-TO-END DEEP AUC MAXIMIZATION

**Zhuoning Yuan[1], Zhishuai Guo[1], Nitesh V. Chawla[2], Tianbao Yang[1]**

1Department of Computer Science, University of Iowa
2Computer Science & Engineering, University of Notre Dame
{zhuoning-yuan, zhishuai-guo, tianbao-yang}@uiowa.edu, nchawla@nd.edu

ABSTRACT

Recently, deep AUC maximization (DAM) has achieved great success in different domains (e.g., medical image classification). However, the end-to-end training for deep AUC maximization still remains a challenging problem. Previous
studies employ an ad-hoc two-stage approach that first trains the network by optimizing a traditional loss (e.g., cross-entropy loss) and then finetunes the network by optimizing an AUC loss. This is because that training a deep neural
network from scratch by maximizing an AUC loss usually does not yield a satisfactory performance. This phenomenon can be attributed to the degraded feature
representations learned by maximizing the AUC loss from scratch. To address
this issue, we propose a novel compositional training framework for end-to-end
DAM, namely compositional DAM. The key idea of compositional training is
to minimize a compositional objective function, where the outer function corresponds to an AUC loss and the inner function represents a gradient descent step
for minimizing a traditional loss, e.g., the cross-entropy (CE) loss. To optimize
the non-standard compositional objective, we propose an efficient and provable
stochastic optimization algorithm. The proposed algorithm enhances the capabilities of both robust feature learning and robust classifier learning by alternatively
taking a gradient descent step for the CE loss and for the AUC loss in a systematic
way. We conduct extensive empirical studies on imbalanced benchmark and medical image datasets, which unanimously verify the effectiveness of the proposed
method. Our results show that the compositional training approach dramatically
improves both the feature representations and the testing AUC score compared
with traditional deep learning approaches, and yields better performance than the
two-stage approaches for DAM as well. The proposed method is implemented in
our open-sourced library LibAUC (www.libauc.org) and code is available at
[https://github.com/Optimization-AI/LibAUC.](https://github.com/Optimization-AI/LibAUC)

1 INTRODUCTION

Deep AUC maximization (DAM) represents a new learning paradigm for deep learning, which maximizes the area under ROC curve (AUC) on a training dataset for learning a deep neural network.
It has received increasing attention recently due to the advancement in large-scale non-convex optimization algorithms for AUC maximization (Liu et al., 2019a; Yuan et al., 2021; Guo et al., 2020a;b).

Recently, DAM has been successfully applied to different domains with imbalanced data (Yuan
et al., 2020; Wang et al., 2021b). For example, Yuan et al. (2020) has employed DAM for a variety of medical image classification tasks, e.g., classification of X-ray images, skin lesion images,
mammograms, and microscopic images, and they observed great improvements with about 1%∼5%
AUC increase over traditional deep learning approaches by optimizing a standard loss function, e.g.,
the cross-entropy (CE) loss. These pioneering studies on DAM open a new direction for deep learning in the presence of imbalanced data but also raise many questions yet to be solved. A particular
question relates to how the network is trained by DAM. Existing studies employ a two-stage approach for DAM, in which the first stage pretrains the network on the training data by optimizing a
traditional loss function (e.g. the CE loss) and the second stage finetunes the network by optimizing an AUC loss. It was conjectured in (Yuan et al., 2020) the feature extraction layers learned by
directly optimizing AUC from scratch are not as good as optimizing the standard CE loss, similarly
as optimizing a class-weighted loss for deep learning with imbalanced data (Cao et al., 2019).


-----

Figure 1: t-SNE visualization of feature representations of an imbalanced training set for the CatvsDog visualized by tSNE learned by different methods (from left to right): optimizing CE loss, an
AUC loss, a linear combination of CE and AUC loss, and a compositional objective by our method.

Although the ad-hoc two-stage method of DAM has achieved some success, this approach leads
to several undesirable consequences increasing the engineering costs in practice: (i) which layers
should we finetune in the second stage? Fine-tuning all layers increases the training costs but not
necessarily improves the final performance (Jamal et al., 2020; Qi et al., 2020); (ii) when do we stop
the training for the first-stage? A long training time for the first-stage increases the overall training
costs but not necessarily increases the final prediction performance, while a short training time for
the first-stage could harm the prediction performance (Kang et al., 2019). Hence, the literature has
suggested different tricks for the two-stage approach, including the decoupling method that simply
optimizes the classifier layer in the second-stage (Kang et al., 2019) and deferred re-weighting that
only dedicates the iterations with the largest step size to the CE loss (Cao et al., 2019), which could
be borrowed to DAM as well. However, an important question remains open regarding DAM:

_How can we conduct end-to-end training for deep AUC maximization?_


To answer this question, we have examined the learned feature representations by optimizing an
AUC loss directly from scratch and confirmed the conjecture in (Yuan et al., 2020) that the learned
feature representations exhibit no advantage over optimizing the CE loss directly. In Figure 1 we
visualize the feature representations on an imbalanced training set for the CatvsDog classification
learned by different methods and visualized by t-SNE (van der Maaten & Hinton, 2008). We
can see that optimizing an AUC loss from scratch (2nd column) does not yield a cleaner feature
representations for the two classes of data than optimizing the CE loss. What makes end-to-end
deep learning successful is its superb feature learning capability, i.e., the lower layers capture the
low-level features and higher layers capture the high-level features. In terms of feature learning,
different examples roughly have equal weights regardless which classes they belong to. From this
perspective, we could understand why optimizing AUC loss alone bears worse feature learning
capability. The AUC loss assigns different weights to different examples from different classes for
more robust classifier learning. In particular, the data in the positive class has a higher weight than
data in the negative class. These non-equal weights are important for learning a robust classifier
given that feature representations have been learned well but are not readily helpful for learning
feature representations in an end-to-end fashion. Can we achieve both effects in a unified and
end-to-end learning framework, i.e., optimizing the CE loss with equal weights for robust feature
learning and optimizing an AUC loss with uneven weights for robust classifier learning? A naive
approach is to simply optimize a linear combination of the CE loss and an AUC loss. However, this
approach has a trade-off, meaning that AUC is not necessarily maximized due to the presence of
the CE loss in the objective and the learned feature representations could be degraded by the AUC
loss (Figure 1, 3rd column).

In this paper, we propose a better and novel end-to-end training method that not only achieves both
benefits of minimizing the CE loss for robust feature learning and minimizing an AUC loss for
robust classifier learning, but also achieves the effect of “1+1>2", i.e., achieves better performance
than the naive linear combination approach. The novel synthesis lies in how we composite the two
training steps corresponding to the CE loss and the AUC loss. The central idea is to minimize a
two-level compositional objective, where the outer function is an AUC loss, and the inner function
is a gradient descent step towards minimizing the CE loss, which represents a quick adaptation to the
solution to minimizing the CE loss. We propose a novel efficient stochastic algorithm with provable
convergence for minimizing the compositional objective, which performs alternating gradient-based
updates that are first based on the gradient of CE loss and then based on the gradient of an AUC loss
at the point obtained in the first step. We summarize our contributions below.

-  We propose a novel training framework for end-to-end deep AUC maximization, namely compositional DAM. The novel compositional objective enables not only the robust feature learning of


-----

lower layers from minimizing the standard loss function but also the robust learning of a classifier
from minimizing an AUC loss.

-  Theoretically, we propose an efficient stochastic optimization algorithm for solving compositional
DAM, and establish the same convergence rate as standard SGD for optimizing a standard averaged loss. Empirically, we conduct extensive studies on benchmark and medical image datasets,
and observe that the proposed method not only improves the baseline methods including the
naive linear combination approach but also improves ad-hoc two-stage approaches for DAM. The
learned feature representations of compositional DAM (e.g., Figure 1 right) are much better than
those learned by minimizing the CE loss or an AUC loss alone and their combination.

2 RELATED WORK

**Deep AUC Maximization. AUC maximization has a history of two decades. Most of the existing**
studies revolve around the design of efficient optimization algorithms. Earlier papers have focused
on full batch methods (Herbrich et al., 1999; Yan et al., 2003; Ferri et al., 2002; Freund et al., 2003;
Joachims, 2005; Herschtal & Raskutti, 2004; Rakotomamonjy, 2004; Zhang et al., 2012) and online
optimization methods (Zhao et al., 2011; Kar et al., 2014; 2013; Gao et al., 2013). Recently, stochastic optimization for AUC maximization has become the dominating approach (Ying et al., 2016; Liu
et al., 2018; Natole et al., 2018; 2019). Ying et al. (2016) propose a milestone work for stochastic
optimization of AUC. They consider optimizing the pairwise square loss and propose an equivalent
min-max formulation that transforms the original non-decomposable objective into a decomposable
one, which enables the design of efficient stochastic methods based on mini-batch of data without
explicitly constructing the pairs. The min-max formulation also serves as the basis for recent works
on DAM (Liu et al., 2019a; Yuan et al., 2021; Guo et al., 2020a;b). (Liu et al., 2019a) is the first work
that explicitly considers DAM and develops the first practical and provable stochastic algorithms for
DAM based on the min-max formulation of the pairwise square loss function. However, this work
only focuses on optimization and experiments are done on simple benchmark datasets. Later, Yuan
et al. (2020) propose a new robust loss in the min-max form for DAM and evaluates the performance
of DAM on various medical image classification tasks, which demonstrates great success of DAM.
However, none of these works have addressed the problem of end-to-end training for DAM.

**Deep Learning with Imbalanced data. Deep learning in the presence of imbalanced data has**
recently attracted tremendous attention (Cui et al., 2019; Johnson & Khoshgoftaar, 2019; Masko &
Hensman, 2015; Lee et al., 2016; Khan et al., 2017; Dablain et al., 2021; Ren et al., 2018; Jamal
et al., 2020; Qi et al., 2020; Lin et al., 2017; Cao et al., 2019; Kang et al., 2019; Liu et al., 2019b;
Zhu & Yang, 2020; Zhou et al., 2020; Xiang et al., 2020; Wang et al., 2021a; 2020; Menon et al.,
2021). Among these studies that are closely related to our work include (Lin et al., 2017; Cui
et al., 2019; Cao et al., 2019; Qi et al., 2020; Kang et al., 2019; Jamal et al., 2020), which focus on
optimizing different objectives from the standard CE loss, including class-weighted loss, focal loss,
individually weighted loss functions, etc. Nevertheless, these works are not directly comparable to
our method for maximizing AUC.

**Two-stage Approaches. However, directly optimizing a weighted loss for training a deep neural**
network from scratch does not work well (Cao et al., 2019; Kang et al., 2019; Jamal et al., 2020; Qi
et al., 2020; Yuan et al., 2020). This phenomenon was first observed in (Cao et al., 2019), which
is attributed to the degraded feature representations. To tackle this issue, Cao et al. (2019) propose
a deferred re-weighting/re-sampling trick. It minimizes the standard average loss for the first stage
and switches to minimizing the class-weighted loss or re-sampling method in the second stage. In
their paper, the first stage is defined as the training period from the beginning to the iteration that
the step size was reduced for the first time in SGD or momentum methods. Kang et al. (2019)
investigate a decoupling approach, where the first stage learns the feature representations (i.e., a
feature extraction network) by optimizing a standard loss with a large number of iterations, and the
second stage learns a robust classifier (i.e. the classifier layer). The authors show that the decoupling
approach can achieve better performance than the deferred re-weighting trick in (Cao et al., 2019).
However, the decoupling approaches do not necessarily yield the best performance. In particular,
some studies have found that fine-tuning some higher layers besides the classifier layer in the second
stage is beneficial (Jamal et al., 2020; Qi et al., 2020). Recently, Yang & Xu (2020) propose to use
self-supervised learning for learning the feature representations for the first stage and to switch to
re-weighting method in the second stage. Different from these studies, our work is to design an
elegant end-to-end training framework for deep learning with an AUC loss.


-----

3 COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION

**Notations. We use (x, y) to denote an example, where x ∈** R[d][0] denotes the input and y ∈Y denotes
its corresponding label. Let ∥· ∥ denote the Euclidean norm of a vector, and let w ∈ R[d] denote
the weight parameters of a deep neural network. A function F (w) is called L-smooth if its gradient
is L-Lipschitz continuous, i.e., ∥∇F (w) −∇F (w[′])∥≤ _L∥w −_ **w[′]∥. Let f** (w; x) denote the
prediction scores of a deep neural network parameterized by w on an input x, where f (w; x) ∈ R
for binary classification with = 1, 1 . Denote by = (x1, y1), . . ., (xn, yn) a set of n
_Y_ _{_ _−_ _}_ _D_ _{_ _}_
training examples. Let ℓ(w; x, y) denote a loss function on an individual data, e.g., cross-entropy
loss. We let L(w; S) denote an aggregate loss function defined on a set of samples S ⊆D. When
=, we simply use the notation L(w) = L(w; ). Let ΠΩ[θ] denotes an Euclidean projection
_S_ _D_ _D_
on the set Ω. Denote by n+(n−) the number of positive (negative) examples.

A standard approach of deep learning is to minimize an averaged loss on training examples, i.e.,


min
**w** R[d][ L][AVG][(][w][) = 1]n
_∈_


_ℓ(w; xi, yi)._ (1)
_i=1_

X


**AUC losses. AUC (area under the ROC curve) is a commonly used measure for evaluating classi-**
fiers for binary classification with imbalanced data. Recently, there emerge voluminous studies on
optimizing AUC score for learning a predictive model (e.g., a deep neural network). The idea is to
optimize a surrogate loss for the AUC score. A special surrogate loss is the AUC square loss (Gao
& Zhou, 2015), which is defined as:

1
min (c (f (w; xi) _f_ (w; xj)))[2],
**w** _n+n_ _−_ _−_

_−_ _yi=1_ _yj_ = 1

X X−

where c is a margin parameter (e.g., 1). Since directly optimizing the above pairwise loss is computationally expensive, existing works transform the above problem into an equivalent min-max
optimization (Liu et al., 2019a), which is decomposable over individual examples:

_n_

min _φ (w, a, b, θ; xi, yi),_ where (2)
**w,a,b** [max]θ∈Ω [Φ (][w][, a, b, θ][) := 1]n _i=1_

X

_φ(w, a, b, θ; xi, yi) = (1_ _p) (f_ (w; xi) _a)[2]_ I[yi=1] + p(f (w; xi) _b)[2]I[yi=_ 1] (3)
_−_ _−_ _−_ _−_

_p(1_ _p)θ[2]_ + 2θ _p(1_ _p)c + pf_ (w; xi)I[yi= 1] (1 _p)f_ (w; xi)I[yi=1] _,_
_−_ _−_ _−_ _−_ _−_ _−_
Ω= R and p = n+/n. From the above objective function φ, we can see that each example xi also
  
has a class-level weight for their contributed loss, i.e., the data from the positive class is weighted
by 1 − _p and the data from the negative class is weighted by p._

It was recently shown that the AUC square loss is sensitive to noisy data and also has adverse
effect when trained with easy data. Hence, Yuan et al. (2020) proposed the min-max AUC margin
(AUCM) loss, whose optimization problem is (2) with Ω= {0 ≤ _θ ≤_ _u} for some u. Let us define_
_LAUC(w) = mina,b maxθ_ Ω Φ (w, a, b, θ) as the AUC loss function.
_∈_

3.1 COMPOSITIONAL DAM: A COMPOSITIONAL TRAINING METHOD FOR DAM


In this section, we present the proposed compositional training for DAM. Our proposed objective
for end-to-end deep learning is given by
min (4)
**w** R[d][ L][AUC][(][w][ −] _[α][∇][L][AVG][(][w][))][,]_
_∈_

where α is hyper-parameter. Different from LAUC(w), the above objective is a compositional function, where the inner component w − _α∇LAVG(w) is another function of w. We refer to the above_
objective as the compositional objective and a method for minimizing the above compositional objective as compositional training.

To understand the compositional objective (4), we take the second-order Taylor expansion of the
compositional objective, which include three terms:
_LAUC(w −_ _α∇LAVG(w)) ≈_ _LAUC(w) −_ _α∇LAUC(w)[⊤]∇LAVG(w) + Cα[2]/2∥∇LAVG(w)∥[2], (5)_
where C represents the Lipchitz continuity constant of ∇LAUC(·). In order to understand how the
three terms play their roles and evolve in the optimization process by our proposed algorithm presented in next subsection (Algorithm 1), we conduct some empirical studies on several benchmark


-----

Figure 2: Evolution of different terms in (5) computed in the process of our optimization algorithm
(Algorithm 1) on the CatvsDog data. LAVG is the averaged CE loss. Please refer to Appendix A.6
for more details of the calculations.

datasets reported in Appendix A.6. Here, we explain the result of the CatvsDog classification shown
in Figure 2. Initially, the first term LAUC(w) dominates the objective and the algorithm will focus on pushing this term to be smaller (1st column), once it reaches the same level of the third
term the algorithm will shift its focus to push ∥∇LAVG(w)∥ smaller (2nd column) while keeping
_∇LAUC(w)[⊤]∇LAVG(w) to be positive (3rd column). This process will continue by alternating be-_
tween the efforts of pushing LAUC(w) smaller and of pushing ∥∇LAVG(w)∥[2] to be smaller while
keeping ∇LAUC(w)[⊤]∇LAVG(w) to be non-negative. We also notice that the final AUC loss is close
to zero. The same phenomena are also observed on other datasets.

To further understand the compositional training intuitively, let us take a thought experiment by
using a gradient descent method to optimize the compositional objective. First, we evaluate the
inner function by u = w − _α∇LAVG(w). We can see that u is computed by a gradient descent step_
for minimizing the averaged loss LAVG(w), which facilitates the learning of lower layers for feature
extraction due to equal weights of all examples. Then, we take a gradient descent step to update w
for minimizing the outer function LAUC(·) by using the gradient ∇LAUC(u) instead of ∇LAUC(w).
Because u is better than w in terms of feature extraction layers, taking a gradient descent step using
_∇LAUC(u) would be better than using ∇LAUC(w). In addition, taking a gradient descent step for_
the outer function LAUC(·) will make the classifier more robust to the minority class due to the
higher weights of examples from the minority class. Overall, we have two alternating conceptual
**steps, i.e., the inner gradient descent step u = w −** _α∇LAVG(w) acts as a feature purification_
**step, and the outer gradient descent step w −** _η(I −_ _α∇[2]LAVG(w))∇LAUC(u) acts as a classifier_
**robustification step, where η is a step size.**

**VS. linear combination approach.** It is notable that minimizing the compositional objective
_LAUC(w −_ _α∇LAVG(w)) is different from minimizing a linear combination of an AUC loss and_
the averaged loss, i.e., LAUC(w)+ _cLAVG(w), where c > 0 is a combination weight. First, minimiz-_
ing the latter objective will push ∇LAUC(w) + c∇LAVG(w) = 0. This makes ∇LAUC(w) to have
an opposite direction from ∇LAVG(w) at the optimal solution, which is different from minimizing
the compositional objective in light of the three terms in (5). Second, if we take a gradient descent
method for minimizing this objective, the update of w is given by w−η(∇LAUC(w)+c∇LAVG(w)).
This update is fundamentally different from the two alternating steps of compositional training that
use gradients of the AUC loss and the average loss at different points. Third, minimizing the linear
combination has a trade-off, meaning that the AUC score is not necessarily maximized due to the
presence of the CE loss in the objective and the learned feature representations are degraded due to
the presence of AUC loss.

**More discussions. Finally, we note that the inner gradient descent step w −** _α∇LAVG(w) is sim-_
ilar to the idea used in model-agnostic meta learning (MAML) (Finn et al., 2017). However, our
compositional objective works fundamentally different from that for MAML. In MAML, the outer
loss function and the loss function for the inner gradient descent step is the same. In contrast, the
two loss functions in our objective are different. But similar to MAML approaches, we can also run
multiple gradient descent steps for the inner function, i.e, the inner function w − _α∇LAVG(w) can_
be replaced by multiple gradient descent steps. In our experiments, we also found this trick to be
helpful for improving the performance.

3.2 STOCHASTIC OPTIMIZATION ALGORITHMS
In this subsection, we develop efficient stochastic optimization algorithms for optimizing the compositional objective (4) for DAM. First, we argue the necessity for such development. (i) the problem is
a min-max form and the objective is a compositional function, which makes computing an unbiased
stochastic gradient of the objective LAUC(w − _α∇LAVG(w)) impossible. Existing algorithms of_


-----

**Algorithm 1 Primal-Dual Stochastic Compositional Adaptive (PDSCA) method for solving (6)**


1: Require Parameters: β0, β1, α, G0, η1, η2
2:3: Initialization: for t = 0, 1, ..., T ¯w0 = ( do **w0; a0; b0) ∈** R[d][+2], θ0, u0 ∈ R[d][+2]

4: Sample two sets of examples denoted by 1, 2
_S_ _S_

5: **ut+1 = (1 −** _β0)ut + β0h( ¯wt; S1)_

6: _Ot = ∇w¯_ _[h][( ¯]wt; S1)[⊤][∇ug1(ut+1; S2) + θt∇ug2(ut+1; S2)]_

7: **zt+1 = (1 −** _β1)zt + β1Ot_

8: **z2,t+1 = ht(** _j, j = 0, . . ., t)_ _ht can be implemented by that in Appendix B_
_{O_ **zt+1** _}_ _⋄_

9: **w¯** _t+1 = ¯wt −_ _η1_ _√z2,t+1+G0_ _⋄with the simplest form ht = 1_

10:11: end forθt+1 = ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))]

non-convex min-max optimization for DAM that focus on minimizing LAUC(w) (Liu et al., 2019a;
Yuan et al., 2021; Guo et al., 2020a;b) are not applicable due to the presence of inner function
**w −** _α∇LAVG(w). (ii) Our objective is also different from that of MAML due to that LAUC(·) is a_
min-max form, which renders existing algorithms for MAML (Finn et al., 2017; Fallah et al., 2020)
not applicable. Hence, below we propose an efficient stochastic algorithm for solving the compositional training for DAM whose objective is of the min-max compositional form, and establish its
convergence rate similar to that of standard SGD for minimizing the standard averaged loss.

In particular, for the considered AUC loss, the compositional objective becomes:

_n_

min _φ (w_ _α_ _LAVG(w), a, b, θ; xi, yi) ._ (6)
**w,a,b** [max]θ Ω [Φ (][w][ −] _[α][∇][L][AVG][(][w][)][, a, b, θ][) = 1]n_ _−_ _∇_
_∈_ _i=1_

X

We denote by a tuple ¯w = (w; a; b). For simplicity of presentation, we write φ(w, a, b, θ, xi, yi) as
_φ( ¯w, θ; xi, yi) = g1( ¯w; xi, yi) + θg2( ¯w; xi, yi)_ _g3(θ),_
_−_
where
_g1( ¯w; xi, yi) =(1_ _p) (f_ (w; xi) _a)[2]_ I[yi=1] + p(f (w; xi) _b)[2]I[yi=_ 1]
_−_ _−_ _−_ _−_ (7)
+ 2pf (w; xi)I[yi=1] 2(1 _p)f_ (w; xi)I[yi= 1],
_−_ _−_ _−_

and g2( ¯w; xi, yi) = 2 _pf_ (w; xi)I[yi= 1] (1 _p)f_ (w; xi)I[yi=1] and g3(θ) = p(1 _p)θ[2]._
_−_ _−_ _−_ _−_

1 1
Denote by g1( ¯w; S)   = _|S|_ _i∈S_ _[g][1][( ¯]w; xi, yi), g2( ¯w; S)_ =  _|S|_ _i∈S_ _[g][2][( ¯]w; xi, yi)._ Let

_h( ¯w) = (w_ _α_ _LAVG(w); a; b),_ **w¯** _[h][( ¯]w) = (I_ _α_ **w[L][AVG][(][w][); 1; 1)][, and][ h][( ¯]w;** ) =
_−_ _∇_ P _∇_ _−_ _∇[2]_ P _S_
(w − _α∇LAVG(w; S); a; b)._

We propose a primal-dual stochastic algorithm shown in Algorithm 1, which is referred to as
PDSCA. We provide some explanations of our algorithmic design. First, the step 5 of updating
**ut+1 corresponds to feature purification step. We use a moving average technique to update ut+1**
that takes all historical updates into account, which is inspired by existing stochastic algorithms for
optimizing compositional functions (Wang et al., 2017). This is important for us to prove the convergence rate of O(1/√T ) without using a large batch size at each iteration. If we simply using

**ut+1 = h( ¯wt; S1) (i.e., setting β0 = 1) to estimate h( ¯wt), there will be a large error in estimating**
the gradient **ug1(ut+1;** 2) and **ug2(ut+1;** 2) in step 6. Second, the step 6 is to estimate the
_∇_ _S_ _∇_ _S_
gradient of the outer function. We use two independent mini-batches S1, S2 to ensure that Ot is an
unbiased estimator of ∇h( ¯wt)[⊤]∇w¯ _[φ][(][u]t+1[, θ][)][. Using two independent mini-batches is also help-]_
ful for improving generalization as demonstrated in experiments. Third, the steps 7 - 9 are similar
to the momentum and adaptive methods for updating the model parameter. The step 8 is used for
computing the adaptive step size 1/[√]z2,t+1 + ϵ0, which is similar to adaptive methods used for
deep learning, such as Adam, AMSGrad, AdaBound (Kingma & Ba, 2015; Reddi et al., 2018; Luo
et al., 2019). We use a general function ht in the algorithm, which can be implemented by different
methods corresponding to different adaptive step size choices. We present different ht in the Appendix B. The simplest one ht = 1 corresponds to that we do not use adaptive step size and only
use the momentum update. Fourth, the step 10 is for updating the dual variable θ using a stochastic
gradient ascent method. Finally, we point out that PDSCA is similar to some existing non-convex
strongly-concave min-max optimization algorithms (Guo et al., 2021) but with additional care on
the inner gradient descent step w − _α∇LAVG(w). We present an informal convergence of PDSCA_
below.


-----

**Theorem 1. (Informal) Under appropriate conditions on the functions LAVG, g1, g2 and a boundness**
_condition onand a small constant θt, wt, ∇ τℓ, Algorithm 1 ensures that(wt; x, y), ∇[2]ℓ(wt; x, y), with E_ _T β +11_ 0, β1Tt ==0 _O[∥∇](1[F]_ [( ¯]/w√tT)∥)[2], η[i] 1≤, η2O =( _√ O[1]T_ [)](1[. where]/√T )

_F_ ( ¯w) = maxθ Ω Φ (w _α_ _LAVG(w), a, b, θ)._ h
_∈_ _−_ _∇_ P

**Remark: We will present the detailed conditions in the supplement when proving the above the-**
orem due to limit of space. The above theorem indicates that we can optimize the compositional
objective (6) with the same convergence rate as optimizing the averaged loss (1) for deep learning.

**Practical Implementations. It is notable that ∇h( ¯w, S1) = (I −** _α∇[2]L(w; S1); 1, 1) (step 6)_
involves the Hessian matrix _L(w;_ 1). Indeed, we only need to compute the Hessian vector
_∇[2]_ _S_
product involving in step 6. Similar computation occurs in the meta learning algorithms (Finn et al.,
2017; Fallah et al., 2020). Inspired by practical implementations of MAML (Finn et al., 2017) that
simply ignore the second-order term, we use the same trick in our experiments. An additional useful
trick inspired by MAML is that we can take k ≥ 1 gradient descent steps for the inner function,
correspondingly we maintain and update several u variables similar to step 5, i.e., using h( ¯wt, 1)
_S_
for updating the first u[(1)]t+1[, and using][ h][(][u][(1)]t+1[;][ S][1][)][ for updating second][ u][(2)]t+1[, and so on so forth. In]
our experiments, we found that tuning k ∈{1, 2, 3} is useful.

Finally, it is notable that although we focus on optimizing AUC loss for binary classification in this
work, our compositional training method can be also extended to optimize other weighted losses in
an end-to-end fashion, and we include some discussion and results in the Appendix D.

4 EXPERIMENTS

In this section, we present some experimental results. We choose five baselines: optimizing the
AUC loss from scratch (AUC[sc]), optimizing the CE loss (CE), optimizing a linear combination of
the AUC loss and the CE loss with a tuned weight (AUC-CE), the two-stage method with deferred
re-weighting trick (Cao et al., 2019) (TS-DRW), the two-stage method by decoupling the learning of
feature network by minimizing CE loss and the learning of a classifier by minimizing the AUC loss
(TS-DEC) (Kang et al., 2019). We denote our method by CT (AUC). For AUC loss, we use AUCM
loss with the margin parameter fixed to be 1 (Yuan et al., 2020). We conduct experiments on four
benchmark datasetes and four medical image datasets. The statistics of these datasets are included
in the Appendix A.1. More training configurations can be found in Appendix A.2.

**Benchmark datasets. We choose four benchmark image classification datasets, namely CatvsDog,**
CIFAR10 (C10), CIFAR100 (C100), and STL10 (S10). For AUC maximization, we construct imbalanced binary versions of these datasets by varying the imbalanced ratios (the ratio of positive
examples to the total number of training examples) similar to (Yuan et al., 2020). We use ResNet20
as the prediction network. The weight decay is set to 1e-4 for all experiments. For algorithms to
maximize AUC, we use a batch size = 128 and train a total of 100 epochs, and we use step size 0.1
and decrease it by 10 times at 50% and 75% of total training time. We tune the beta parameters of
our method in a range [0.1, 0.99] with a grid search and find that good values are around 0.9. For
linear combination methods, we tune the weight c of two losses in {0.25, 0.5, 0.75}. We tune the
number of inner gradient steps for CT in k ∈{1, 2, 3} with α = 0.1. For all benchmark data, we
run three times for different random seeds and compute the mean and standard deviations.

**Medical image datasets. We also conduct experiments on naturally imbalanced medical datasets.**
We choose four medical image datasets, namely Melanoma data, CheXpert, DDSM+, and PatchCam
data. The Melanoma dataset is from the Kaggle 2020 competition (Rotemberg et al., 2021), which
contains 33,126 labeled images in training set, including 584 positive samples and 32,542 negative
samples. We manually construct training, validation and testing datasets following 70/10/20 split.
For this dataset, we use the images with 256x256 resolution in the experiments. CheXpert is a largescale chest X-ray dataset (Irvin et al., 2019), which has 224,316 images with 224 x 224 resolution.
The dataset contains 5 binary classification tasks corresponding to 5 diseases, i.e., Cardiomegaly
(C0), Edema, Consolidation, Atelectasis, Pleural Effusion. We evaluate the performance on the
official validation set consisting of 200 patient studies and report the averaged AUC scores of all
5 diseases. The DDSM+ data is a combination of two datasets namely DDSM and CBIS-DDSM
(Lee et al., 2017; Bowyer et al., 1996; Heath et al., 1998), which consists of 55,890 mammographic
training images (224×224) with an imratio of 13% and 15,364 images for testing with an imratio of 13%. The PatchCamelyon dataset consists of 294,912 color images (96×96) extracted from


-----

Table 1: Testing performance on benchmark datasets and medical datasets. The percentage number
is the second row denotes the imbalanced ratio (cf the text).

|Datasets|For AUC Maximization|
|---|---|
||imratio 1% 10% 30%|
|CATvsDOG|CE 0.742±0.003 0.917±0.006 0.957±0.001 AUCsc 0.753±0.003 0.915±0.002 0.964±0.003 AUC-CE 0.770±0.007 0.939±0.004 0.974±0.003 TS-DRW 0.750±0.009 0.914±0.003 0.961±0.001 TS-DEC 0.754±0.010 0.918±0.003 0.963±0.001 CT (AUC) 0.789±0.008 0.946±0.002 0.977±0.001|
|CIFAR10|CE 0.689±0.003 0.901±0.002 0.944±0.001 AUCsc 0.728±0.002 0.905±0.002 0.946±0.001 AUC-CE 0.735±0.003 0.928±0.001 0.957±0.001 TS-DRW 0.708±0.002 0.896±0.002 0.946±0.003 TS-DEC 0.707±0.002 0.897±0.002 0.944±0.001 CT (AUC) 0.739±0.004 0.935±0.001 0.964±0.001|
|STL10|CE 0.655±0.005 0.819±0.004 0.885±0.004 AUCsc 0.665±0.005 0.805±0.017 0.887±0.007 AUC-CE 0.668±0.007 0.836±0.006 0.905±0.001 TS-DRW 0.655±0.004 0.803±0.013 0.887±0.002 TS-DEC 0.661±0.002 0.816±0.007 0.882±0.007 CT (AUC) 0.673±0.010 0.837±0.006 0.906±0.001|
|CIFAR100|CE 0.586±0.001 0.691±0.005 0.758±0.004 AUCsc 0.606±0.004 0.705±0.003 0.779±0.003 AUC-CE 0.605±0.004 0.716±0.003 0.795±0.001 TS-DRW 0.588±0.003 0.691±0.004 0.762±0.001 TS-DEC 0.587±0.001 0.692±0.003 0.762±0.002 CT (AUC) 0.609±0.002 0.725±0.001 0.809±0.002|


|Datasets|For AUC Maximization|
|---|---|
||Method AUC|
|Melanoma|CE 0.879±0.008 AUCsc 0.868±0.006 AUC-CE 0.880±0.005 TS-DRW 0.878±0.007 TS-DEC 0.877±0.005 CT (AUC) 0.900±0.002|
|CheXpert|CE 0.892±0.001 AUCsc 0.899±0.002 AUC-CE 0.902±0.002 TS-DRW 0.900±0.002 TS-DEC 0.897±0.001 CT (AUC) 0.909±0.003|
|DDSM+|CE 0.949±0.001 AUCsc 0.929±0.001 AUC-CE 0.957±0.001 TS-DRW 0.942±0.003 TS-DEC 0.941±0.001 CT (AUC) 0.981±0.001|
|PatchCam|CE 0.869±0.007 AUCsc 0.868±0.006 AUC-CE 0.868±0.005 TS-DRW 0.867±0.006 TS-DEC 0.869±0.009 CT (AUC) 0.891±0.003|



histopathologic scans of lymph node section for training and 32,768 images for testing with balanced class ratio (Veeling et al., 2018; Bejnordi et al., 2017). For PathCamelyon, we manually
construct an imbalanced training dataset with an imratio of 1% and keep the testing set balanced.
For Melanoma data, we adopt a EfficientNetV2-S (Tan & Le, 2021) as the network structure, and for
CheXpert, DDSM+, PatchCam, we use DenseNet121 (Huang et al., 2017). We tune the number of
inner gradient steps for CT in k ∈{1, 2, 3} and also tune α in {0.1, 0.05, 0.01} for the inner steps.

**Results. The testing AUC results are reported in Table 1. We can see that the proposed composition**
training method outperforms all baselines on all datasets for maximizing AUC. In addition, we have
the following observations: (i) optimizing an AUC loss from scratch does not necessarily yield a
better performance than minimizing the standard CE loss; (ii) the CT (AUC) method dramatically
improves the performance of optimizing the AUC loss from scratch, with about 2%∼5% improvement on difficult medical classification tasks; (iii) the CT (AUC) method is generally better than the
linear combination approach (AUC-CE), especially on the more difficult medical image datasets. It
is notable that the reported results on some medical datasets are not comparable with that in (Yuan
et al., 2020) because (i) we report the performance on official CheXpert validation data instead of
the official testing data; (ii) we use a smaller resolution on Melanoma data; (ii) we do not tune the
margin parameter in the AUCM loss. We also plot the learned feature representations of training
data of different datasets visualized by t-SNE in Figure 3. We can see that the proposed CT (AUC)
method obtains better feature representations than the baseline approaches of optimizing CE or AUC
alone and the naive linear combination approach.

4.1 ABLATION STUDY
We conduct some ablation study including (i) the comparison of convergence curves and the running
time analysis of different methods; (ii) the verification of our algorithmic design.

**Convergence Curve.** Below, we compare the convergence speed of our CT (AUC) approach
with other end-to-end learning baselines, i.e., CE, AUC, AUC-CE, with results on four benchmark
datasets plotted in Figure 4. The results indicate that our algorithm enjoys even faster convergence in
terms of number of epochs. The convergence curves of testing AUC are included in Appendix A.4.

**Runtime analysis. We notice our method has larger running time per-iteration than minimizing the**
CE and the AUC loss alone because of several backpropagations, but with a reward of faster convergence in epochs and better testing performance. For fair comparison, we have run the baselines
with the same amount of time as our method and observed they are still worse than our method (cf
Appendix A.5). For example, on CIFAR10 (10%), CT (AUC) can achieve an AUC of 0.944 with a
running time of 1000s, in contrast, the baselines CE, AUC, AUC-CE, TS-DRW, and TS-DEC use
same running time and achieve AUC scores of 0.925, 0.915, 0.943, 0.917, 0.917, respectively.


-----

Figure 3: t-SNE visualization of training data (• is positive and • is negative) by (from top to bottom)
optimizing the CE loss, an AUC loss from scratch, a linear combined loss, and our CT method.

Figure 4: Convergence curves on four benchmark datasets with an imbalance ratio of 10%.

**Verification of Algorithmic Design. We validate three algorithmic choices. (i) Using two inde-**
pendent mini-batchesmomentum update for S u1t ̸+1= (i.e., S2 is generally better than using the same mini-batch. (ii) Using the β0 < 1) is better than without using momentum update (β0 = 1).
(iii) tuning the number of inner gradient steps k ∈{1, 2, 3} is helpful for improving the performance. The results are demonstrated in Table 2, where all results are averaged over three trials.

Table 2: Left:k 1, 2, 3 for for the left table and fix S1 ̸= S2 vs S1 = S2, right: k = 1 β0 = 1 for the right table. left ( vs β0 < 1 in Algorithm 1. Note that we tune1 = 2) vs right (β0 1)
verifies that tuning ∈{ _}_ _k is helpful._ _S_ _̸_ _S_ _≤_

**Imbalance Ratio** **Imbalance Ratio**
**Dataset** **Method** **Method**

**1%** **10%** **30%** **1%** **10%** **30%**

CATvsDOGCIFAR100CIFAR10STL10 _SSSSSSSS11111111 = ̸ = ̸ = ̸ = ̸==== S S S S S S S S22222222_ **0.789±0.0080.740±0.0040.681±0.0050.609±0.0020.784±0.0070.738±0.0050.671±0.0070.608±0.004** **0.946±0.0020.935±0.0010.839±0.0040.725±0.0000.941±0.0020.931±0.0020.820±0.0250.709±0.002** **0.977±0.0010.964±0.0010.907±0.0010.809±0.0020.975±0.0010.959±0.0000.902±0.0030.788±0.005** _ββββββββ00000000 = 1 < = 1 < = 1 < = 1 < 1 1 1 1_ **0.769±0.0070.725±0.0110.666±0.0060.598±0.0020.765±0.0050.724±0.0060.663±0.0120.590±0.014** **0.939±0.0040.929±0.0020.832±0.0080.714±0.0030.937±0.0040.928±0.0040.819±0.0180.714±0.004** **0.975±0.0060.960±0.0010.900±0.0020.801±0.0010.971±0.0020.957±0.0010.895±0.0040.791±0.004**

5 CONCLUSIONS
In this paper, we have proposed a novel end-to-end compositional training framework for deep AUC
maximization by optimizing a compositional objective. We also proposed an efficient stochastic
optimization method for compositional training of deep AUC maximization. We demonstrated the
effectiveness of compositional training on multiple benchmark datasets and medical datasets for
maximizing AUC. In future work, we will investigate compositional training for other imbalanced
loss functions more extensively.


-----

ACKNOWLEDGEMENTS
We thank anonymous reviewers for their valuable comments. This work was partially supported by
NSF Career Award #1844403, NSF Award #2110545, NSF Award #1933212.

REFERENCES

Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes Van Diest, Bram Van Ginneken, Nico
Karssemeijer, Geert Litjens, Jeroen AWM Van Der Laak, Meyke Hermsen, Quirine F Manson,
Maschenka Balkenhol, et al. Diagnostic assessment of deep learning algorithms for detection of
lymph node metastases in women with breast cancer. Jama, 318(22):2199–2210, 2017.

K Bowyer, D Kopans, WP Kegelmeyer, R Moore, M Sallam, K Chang, and K Woods. The digital
database for screening mammography. In Third international workshop on digital mammography,
volume 58, pp. 27, 1996.

Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced
datasets with label-distribution-aware margin loss. In Advances in Neural Information Processing
_Systems, pp. 1567–1578, 2019._

Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on
effective number of samples. In Proceedings of the IEEE Conference on Computer Vision and
_Pattern Recognition, pp. 9268–9277, 2019._

Damien Dablain, Bartosz Krawczyk, and Nitesh V. Chawla. Deepsmote: Fusing deep learning and
[SMOTE for imbalanced data. CoRR, abs/2105.02340, 2021. URL https://arxiv.org/](https://arxiv.org/abs/2105.02340)
[abs/2105.02340.](https://arxiv.org/abs/2105.02340)

Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. On the convergence theory of gradientbased model-agnostic meta-learning algorithms. In International Conference on Artificial Intelli_gence and Statistics, pp. 1082–1092. PMLR, 2020._

C Ferri, PA Flach, and J Hernández-Orallo. Learning decision trees using the area under the roc
curve. In Claude Sammut and Achim Hoffmann (eds.), Proceedings of the 19th International
_Conference on Machine Learning, pp. 139 – 146. Morgan Kaufmann, 2002. ISBN 1558608737._

Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th Interna_tional Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017,_
volume 70 of Proceedings of Machine Learning Research, pp. 1126–1135. PMLR, 2017. URL
[http://proceedings.mlr.press/v70/finn17a.html.](http://proceedings.mlr.press/v70/finn17a.html)

Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efficient boosting algorithm for
combining preferences. J. Mach. Learn. Res., 4(null):933–969, December 2003. ISSN 15324435.

Lawrence Fulton, Alex McLeod, Diane Dolezel, Nathaniel Bastian, and Christopher P Fulton. Deep
vision for breast cancer classification and segmentation. Cancers, 13(21):5384, 2021.

Wei Gao and Zhi-Hua Zhou. On the consistency of AUC pairwise optimization. In Qiang Yang and
Michael J. Wooldridge (eds.), Proceedings of the Twenty-Fourth International Joint Conference
_on Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 939–945._
[AAAI Press, 2015. URL http://ijcai.org/Abstract/15/137.](http://ijcai.org/Abstract/15/137)

Wei Gao, Rong Jin, Shenghuo Zhu, and Zhi-Hua Zhou. One-pass auc optimization. In International
_conference on machine learning, pp. 906–914, 2013._

Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv preprint
_arXiv:1802.02246, 2018._

Saeed Ghadimi, Andrzej Ruszczynski, and Mengdi Wang. A single timescale stochastic approximation method for nested stochastic optimization. SIAM J. Optim., 30(1):960–979, 2020. doi:
[10.1137/18M1230542. URL https://doi.org/10.1137/18M1230542.](https://doi.org/10.1137/18M1230542)


-----

Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, and Tianbao Yang. Communicationefficient distributed stochastic AUC maximization with deep neural networks. In Proceedings of
_the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual_
_Event, volume 119 of Proceedings of Machine Learning Research, pp. 3864–3874. PMLR, 2020a._
[URL http://proceedings.mlr.press/v119/guo20f.html.](http://proceedings.mlr.press/v119/guo20f.html)

Zhishuai Guo, Zhuoning Yuan, Yan Yan, and Tianbao Yang. Fast objective and duality gap convergence for non-convex strongly-concave min-max problems. CoRR, abs/2006.06889, 2020b. URL
[https://arxiv.org/abs/2006.06889.](https://arxiv.org/abs/2006.06889)

Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, and Tianbao Yang. On stochastic moving-average
[estimators for non-convex optimization. CoRR, abs/2104.14840, 2021. URL https://arxiv.](https://arxiv.org/abs/2104.14840)
[org/abs/2104.14840.](https://arxiv.org/abs/2104.14840)

Michael Heath, Kevin Bowyer, Daniel Kopans, Philip Kegelmeyer, Richard Moore, Kyong Chang,
and S Munishkumaran. Current status of the digital database for screening mammography. In
_Digital mammography, pp. 457–460. Springer, 1998._

Ralf Herbrich, Thore Graepel, and Klause Obermayer. Large Margin Rank Boundaries for Ordinal
Regression. In Advances in Large Margin Classifiers, chapter 7, pp. 115–132. The MIT Press,
[1999. URL http://www.herbrich.me/papers/nips98_ordinal.pdf.](http://www.herbrich.me/papers/nips98_ordinal.pdf)

Alan Herschtal and Bhavani Raskutti. Optimising area under the ROC curve using gradient descent. In Carla E. Brodley (ed.), Machine Learning, Proceedings of the Twenty-first International
_Conference (ICML 2004), Banff, Alberta, Canada, July 4-8, 2004, volume 69 of ACM Inter-_
_national Conference Proceeding Series. ACM, 2004._ doi: 10.1145/1015330.1015366. URL
[https://doi.org/10.1145/1015330.1015366.](https://doi.org/10.1145/1015330.1015366)

Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
_recognition, pp. 4700–4708, 2017._

Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik
Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, et al. Chexpert: A large chest
radiograph dataset with uncertainty labels and expert comparison. In Proceedings of the AAAI
_Conference on Artificial Intelligence, volume 33, pp. 590–597, 2019._

Muhammad Abdullah Jamal, Matthew Brown, Ming-Hsuan Yang, Liqiang Wang, and Boqing Gong.
Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation
perspective. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog_nition, pp. 7610–7619, 2020._

Thorsten Joachims. A support vector method for multivariate performance measures. In Pro_ceedings of the 22nd International Conference on Machine Learning, ICML ’05, pp. 377–384,_
New York, NY, USA, 2005. Association for Computing Machinery. ISBN 1595931805. doi:
[10.1145/1102351.1102399. URL https://doi.org/10.1145/1102351.1102399.](https://doi.org/10.1145/1102351.1102399)

Justin M Johnson and Taghi M Khoshgoftaar. Survey on deep learning with class imbalance. Journal
_of Big Data, 6(1):27, 2019._

Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis
Kalantidis. Decoupling representation and classifier for long-tailed recognition. arXiv preprint
_arXiv:1910.09217, 2019._

Purushottam Kar, Bharath Sriperumbudur, Prateek Jain, and Harish Karnick. On the generalization
ability of online learning algorithms for pairwise loss functions. In Sanjoy Dasgupta and David
McAllester (eds.), Proceedings of the 30th International Conference on Machine Learning, volume 28 of Proceedings of Machine Learning Research, pp. 441–449, Atlanta, Georgia, USA, 17–
[19 Jun 2013. PMLR. URL https://proceedings.mlr.press/v28/kar13.html.](https://proceedings.mlr.press/v28/kar13.html)

Purushottam Kar, Harikrishna Narasimhan, and Prateek Jain. Online and stochastic gradient methods for non-decomposable loss functions. In Proceedings of the 27th International Conference
_on Neural Information Processing Systems - Volume 1, NIPS’14, pp. 694–702, Cambridge, MA,_
USA, 2014. MIT Press.


-----

Salman H Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous A Sohel, and Roberto Togneri.
Cost-sensitive learning of deep feature representations from imbalanced data. IEEE transactions
_on neural networks and learning systems, 29(8):3573–3587, 2017._

Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _International_
_Conference on Learning Representations, 2015._

Hansang Lee, Minseok Park, and Junmo Kim. Plankton classification on imbalanced large scale
database via convolutional neural networks with transfer learning. In 2016 IEEE international
_conference on image processing (ICIP), pp. 3713–3717. IEEE, 2016._

Rebecca Sawyer Lee, Francisco Gimenez, Assaf Hoogi, Kanae Kawai Miyake, Mia Gorovoy, and
Daniel L Rubin. A curated mammography data set for use in computer-aided detection and
diagnosis research. Scientific data, 4(1):1–9, 2017.

Tianyi Lin, Chi Jin, and Michael I Jordan. On gradient descent ascent for nonconvex-concave
minimax problems. arXiv preprint arXiv:1906.00331, 2019.

Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense
object detection. In Proceedings of the IEEE international conference on computer vision, pp.
2980–2988, 2017.

Mingrui Liu, Xiaoxuan Zhang, Zaiyi Chen, Xiaoyu Wang, and Tianbao Yang. Fast stochastic auc
maximization with o (1/n)-convergence rate. In International Conference on Machine Learning,
pp. 3195–3203, 2018.

Mingrui Liu, Zhuoning Yuan, Yiming Ying, and Tianbao Yang. Stochastic auc maximization with
deep neural networks. arXiv preprint arXiv:1908.10831, 2019a.

Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X. Yu. Largescale long-tailed recognition in an open world. In IEEE Conference on Computer Vision and
_Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pp. 2537–2546._
[Computer Vision Foundation / IEEE, 2019b. doi: 10.1109/CVPR.2019.00264. URL http:](http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html)
[//openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_](http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html)
[Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html.](http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html)

Liangchen Luo, Yuanhao Xiong, Yan Liu, and Xu Sun. Adaptive gradient methods with dynamic
bound of learning rate. In 7th International Conference on Learning Representations (ICLR),
2019.

David Masko and Paulina Hensman. The impact of imbalanced training data for convolutional
neural networks, 2015.

Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and
Sanjiv Kumar. Long-tail learning via logit adjustment. In International Conference on Learning
_[Representations, 2021. URL https://openreview.net/forum?id=37nvvqkCo5.](https://openreview.net/forum?id=37nvvqkCo5)_

Michael Natole, Yiming Ying, and Siwei Lyu. Stochastic proximal algorithms for auc maximization.
In International Conference on Machine Learning, pp. 3707–3716, 2018.

Michael Natole, Yiming Ying, and Siwei Lyu. Stochastic auc optimization algorithms with linear
convergence. Frontiers in Applied Mathematics and Statistics, 5, 2019.

Qi Qi, Yi Xu, Rong Jin, Wotao Yin, and Tianbao Yang. Attentional biased stochastic gradient for
[imbalanced classification. CoRR, abs/2012.06951, 2020. URL https://arxiv.org/abs/](https://arxiv.org/abs/2012.06951)
[2012.06951.](https://arxiv.org/abs/2012.06951)

Alain Rakotomamonjy. Support vector machines and area under roc curves. Technical report, 2004.

Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond. In 6th
_International Conference on Learning Representations (ICLR), 2018._

Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. arXiv preprint arXiv:1803.09050, 2018.


-----

Veronica Rotemberg, Nicholas Kurtansky, Brigid Betz-Stablein, Liam Caffery, Emmanouil
Chousakos, Noel Codella, Marc Combalia, Stephen Dusza, Pascale Guitera, David Gutman, et al.
A patient-centric dataset of images and metadata for identifying melanomas using clinical context.
_Scientific data, 8(1):1–8, 2021._

Eric Scuccimarra. Ddsm mammography: tfrecords files of scans from the ddsm dataset. Online,
[2021. URL https://www.kaggle.com/skooch/ddsm-mammography.](https://www.kaggle.com/skooch/ddsm-mammography)

Mingxing Tan and Quoc V Le. Efficientnetv2: Smaller models and faster training. arXiv preprint
_arXiv:2104.00298, 2021._

Laurens van der Maaten and Geoffrey E. Hinton. Visualizing high-dimensional data using t-sne.
_Journal of Machine Learning Research, 9:2579–2605, 2008._

Bastiaan S Veeling, Jasper Linmans, Jim Winkens, Taco Cohen, and Max Welling. Rotation equivariant cnns for digital pathology. In International Conference on Medical image computing and
_computer-assisted intervention, pp. 210–218. Springer, 2018._

Mengdi Wang, Ethan X Fang, and Han Liu. Stochastic compositional gradient descent: algorithms
for minimizing compositions of expected-value functions. Mathematical Programming, 161(1-2):
419–449, 2017.

Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella X. Yu. Long-tailed recognition
by routing diverse distribution-aware experts. _CoRR, abs/2010.01809, 2020._ [URL https:](https://arxiv.org/abs/2010.01809)
[//arxiv.org/abs/2010.01809.](https://arxiv.org/abs/2010.01809)

Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella Yu. Long-tailed recognition by
routing diverse distribution-aware experts. In International Conference on Learning Representa_[tions, 2021a. URL https://openreview.net/forum?id=D9I3drBz4UC.](https://openreview.net/forum?id=D9I3drBz4UC)_

Zhengyang Wang, Meng Liu, Youzhi Luo, Zhao Xu, Yaochen Xie, Limei Wang, Lei Cai, Qi Qi,
Zhuoning Yuan, Tianbao Yang, and Shuiwang Ji. Advanced graph and sequence neural networks
for molecular property prediction and drug discovery, 2021b.

Liuyu Xiang, Guiguang Ding, and Jungong Han. Learning from multiple experts: Self-paced
knowledge distillation for long-tailed classification. In Andrea Vedaldi, Horst Bischof, Thomas
Brox, and Jan-Michael Frahm (eds.), Computer Vision - ECCV 2020 - 16th European Confer_ence, Glasgow, UK, August 23-28, 2020, Proceedings, Part V, volume 12350 of Lecture Notes_
_in Computer Science, pp. 247–263. Springer, 2020. doi: 10.1007/978-3-030-58558-7\_15. URL_
[https://doi.org/10.1007/978-3-030-58558-7_15.](https://doi.org/10.1007/978-3-030-58558-7_15)

Lian Yan, Robert Dodier, Michael C. Mozer, and Richard Wolniewicz. Optimizing classifier performance via an approximation to the wilcoxon-mann-whitney statistic. In Proceedings of the Twen_tieth International Conference on International Conference on Machine Learning, ICML’03, pp._
848–855. AAAI Press, 2003. ISBN 1577351894.

Yuzhe Yang and Zhi Xu. Rethinking the value of labels for improving class-imbalanced learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Ad_vances in Neural Information Processing Systems, volume 33, pp. 19290–19301. Curran As-_
[sociates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/](https://proceedings.neurips.cc/paper/2020/file/e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf)
[e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf.](https://proceedings.neurips.cc/paper/2020/file/e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf)

Yiming Ying, Longyin Wen, and Siwei Lyu. Stochastic online auc maximization. In Advances in
_neural information processing systems, pp. 451–459, 2016._

Zhuoning Yuan, Yan Yan, Milan Sonka, and Tianbao Yang. Robust deep AUC maximization: A
new surrogate loss and empirical studies on medical image classification. CoRR, abs/2012.03173,
[2020. URL https://arxiv.org/abs/2012.03173.](https://arxiv.org/abs/2012.03173)

Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, and Tianbao Yang. Federated deep AUC maximization for hetergeneous data with a constant communication complexity. In Marina Meila
and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning,
_ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Re-_
_[search, pp. 12219–12229. PMLR, 2021. URL http://proceedings.mlr.press/v139/](http://proceedings.mlr.press/v139/yuan21a.html)_
[yuan21a.html.](http://proceedings.mlr.press/v139/yuan21a.html)


-----

Xinhua Zhang, Ankan Saha, and S. V. N. Vishwanathan. Smoothing multivariate performance measures. J. Mach. Learn. Res., 13(1):3623–3680, December 2012. ISSN 1532-4435.

Peilin Zhao, Steven C. H. Hoi, Rong Jin, and Tianbao Yang. Online auc maximization. In ICML,
pp. 233–240, 2011.

Yan Zheng, Yuchen Zheng, Daiki Suehiro, and Seiichi Uchida. Top-rank convolutional neural network and its application to medical image-based diagnosis. Pattern Recognition, 120:108138,
2021.

Boyan Zhou, Quan Cui, Xiu-Shen Wei, and Zhao-Min Chen. BBN: bilateral-branch network with
cumulative learning for long-tailed visual recognition. In 2020 IEEE/CVF Conference on Com_puter Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pp._
[9716–9725. IEEE, 2020. doi: 10.1109/CVPR42600.2020.00974. URL https://doi.org/](https://doi.org/10.1109/CVPR42600.2020.00974)
[10.1109/CVPR42600.2020.00974.](https://doi.org/10.1109/CVPR42600.2020.00974)

Linchao Zhu and Yi Yang. Inflated episodic memory with region self-attention for long-tailed
visual recognition. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recogni_tion, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pp. 4343–4352. IEEE, 2020. doi: 10._
[1109/CVPR42600.2020.00440. URL https://doi.org/10.1109/CVPR42600.2020.](https://doi.org/10.1109/CVPR42600.2020.00440)
[00440.](https://doi.org/10.1109/CVPR42600.2020.00440)


-----

A SUPPLEMENT OF EXPERIMENTAL SECTION

A.1 DATASET DESCRIPTIONS

The detailed statistics of different datasetse are reported in Table 3. Note that ”# of images” refers to
the number of samples for the original training set. "LT" denote long-tailed version of the datasets
for multi-class tasks. Imbalance ratio (imratio) of XXX (Binary) data means the ratio of number of
positive examples to number of all examples. Imbalance ratio (imratio) of XXX (LT) data means
ration of the size of smallest class to the size of largest class. The DDSM+ is slightly different from
the standard version of CBIS-DDSM or DDSM (Lee et al. (2017); Bowyer et al. (1996); Heath et al.
(1998)). We actually use the dataset from (Scuccimarra (2021)) constructed by Eric A. Scuccimarra,
which consists of 55k images for training and 15k images for testing. The details about the dataset
construction can be found here (Scuccimarra (2021); Zheng et al. (2021); Fulton et al. (2021)).
For constructing DDSM+, the positive samples (cancer cases) are from CBIS-DDSM and negative
samples (normal cases) are from DDSM. To increase the size of the training data, the author applies
offline data augmentation and adds multiple augmented copies to the dataset. In particular, each
image (ROI) is randomly cropped three times into 598x598 images, with random flips and rotations,
and then the images are resized down to 299x299. For the testing set, the same augmentation is also
applied and thus the imbalance ratios remain the same as the training set. The imbalance ratio is
about 13% in both training and testing sets. The train/test split in terms of patient ID follows the
CBIS-DDSM split, which do not have any overlap. We will add these references in the revision and
also correct the citation for CBIS-DDSM. Please also note that this dataset (DDSM+) has also been
used for some recent works (Zheng et al. (2021); Fulton et al. (2021)).

Table 3: Description of datasets for classification tasks.

**Dataset** **# of images** **# of classes** **Imbalance Ratio**

CATvsDOG (binary) 20,000 2 1%, 10%, 30%
CIFAR10 (binary) 50,000 2 1%, 10%, 30%
CIFAR100 (binary) 50,000 2 1%, 10%, 30%
STL10 (binary) 5,000 2 1%, 10%, 30%

CheXpert 223,416 2 12.2%, 32.2%, 6.8%, 31.2%, 40.3%
Melanoma 33,126 2 1.76%
DDSM+ 55,000 2 13%
PatchCam 294,912 2 1%

CIFAR10 (LT) 50,000 10 1%, 10%
CIFAR100 (LT) 50,000 100 1%, 10%
STL10 (LT) 5,000 10 1%, 10%
ImageNet (LT) 115,800 1000 0.39%

A.2 TRAINING CONFIGURATIONS

All benchmark datasets are experimented by NVIDIA GTX-2080Ti and four medical datasets,
i.e., CheXpert, Melanoma, DDSM+ and PatchCam, are experimented by NVIDIA V100. For the
datasets of binary classification in Table 1, we use the dataloaders from (Yuan et al., 2020). For the
long-tailed datasets of multi-class classification as in Section D, we uses the dataloaders from (Cui
et al., 2019). For TS-DRW, we train the models using cross-entropy loss at the first stage and then
switch to imbalanced losses at the later stages. For TS-DEC, we first conduct the regular training
using cross-entropy loss and same settings and then we discard the trained classifiers and finetune
the new classifier for additional 10 epochs using imbalanced loss with the learning rate of 0.01. For
the proposed compositional training methods, we consider the non-adaptive version with ht( ) = 1

_·_
in all experiments. For all datasets, we use the train/val split to do cross-validation for parameter
tuning, except CheXpert as explained below. For the benchmark datasets, we use 19k/1k, 45k/5k,
45k/5k. 4k/1k training/validation split on CatvsDog, CIFAR10, CIFAR100, STL10, respectively.
For melanoma dataset, we use 70/10/20 split for train/val/test. For PatchCam, we use their official
validation set for tuning parameters, which includes about 37k images with balanced positive and
negative samples. For DDSM+, we tune the parameters on 10% data sampled from the training set.
For CheXpert, since the official testing set is not released and it will take a long time to evaluate all
methods on the official testing data, hence, we evaluate different methods only based on the official
validation set with parameters tuned according to this set. To make the experiment on Chexpert con

-----

sistent with other datasets, we run experiments for all methods on CheXpert by following the same
cross-validation procedure, i.e., by sampling 10% training data based on patient ID as the validation
set to tune parameters and then we report the average scores of five diseases on the testing set (i.e.,
the official validation set as a testing set).

A.3 EVALUATIONS ON MEDICAL DATASET WITH MULTIPLE RUNS

For medical datasets, we run all experiments and report the average performance over three runs.
We use batch size of 32 except for PatchCam that is 64, initial learning rate of 0.1 and weight decay
of 1e-5. We train Melanoma for 12 epochs, CheXpert for 2 epochs, DDSM+ for 5 epochs and
PatchCam for 5 epochs. The learning rate is decayed at 50%, 75% of total training iterations by
10 times. For compositional training, we tune the number of inner gradient steps in k ∈{1, 2, 3}
and also tune α ∈{0.1, 0.05, 0.01} for the inner steps. The results are summarized in the following
table.

Table 4: Testing performance on medical datasets.

**Melanoma** **CheXpert** **DDSM+** **PatchCam**
**Method**

**AUC**

**CE** 0.879±0.008 0.892±0.001 0.949±0.001 0.869±0.007
**AUC** 0.868±0.006 0.899±0.002 0.929±0.001 0.868±0.006
**AUC-CE** 0.880±0.005 0.902±0.002 0.957±0.001 0.868±0.005
**TS-DRW** 0.878±0.007 0.900±0.002 0.942±0.003 0.867±0.006
**TS-DEC** 0.877±0.005 0.897±0.001 0.941±0.001 0.869±0.009
**CT (AUC)** **0.900±0.002** **0.909±0.003** **0.981±0.001** **0.891±0.003**


A.4 TESTING CONVERGENCE CURVES.

The convergence curves of testing AUC on the benchmark datasets of different methods are plotted
in Figure 5.

Figure 5: Convergence curves of testing AUC on four benchmark datasets with imbalance ratio of
10%.

A.5 COMPARISON WITH THE SAME RUNTIME

To compare the performance with the same running time, we train ResNet20 on four benchmark
datasets with an imbalance ratio of 10% on a GTX-2080Ti. For each method, we train 1000 seconds
and report the best achieved testing AUC. The results are summarized in Table 5.

Table 5: Achieved testing AUC for each method after training ResNet20 for 1000 seconds.

**Dataset** **CT (AUC)** **CE** **AUC** **AUC-CE** **TS-DRW** **TS-DEC**

CATvsDOG (10%) **0.944** 0.925 0.915 0.943 0.917 0.917
CIFAR10 (10%) **0.936** 0.900 0.905 0.928 0.897 0.898
STL10 (10%) **0.837** 0.815 0.783 0.829 0.816 0.815
CIFAR100 (10%) **0.724** 0.691 0.701 0.718 0.696 0.696


A.6 EVOLUTION OF DIFFERENT TERMS OF THE COMPOSITIONAL OBJECTIVE.

To better understand the proposed compositional objective, we plot the evolution curves of each term
in the decomposition equation (5) and compare them with that of naive linear combination approach


-----

(Linear Comb.). We conduct experiments on CATvsDOG, CIFAR10, CIFAR100 and STL10 with
imbalance ratio of 10% using ResNet20. We start with initial learning rate of 0.1 and decay it at 50th,
75th epoch by 0.1. In Figure 6, we plot the values of LAUC(w), LAVG(w), ∇LAUC(w)[⊤]∇LAVG(w),
_∥∇LAVG(w)∥[2]_ v.s. the number of epochs on training set. For the calculations of LAUC(w), we
compute its values based on the optimal values of a, b, α according to (Yuan et al., 2020) for each
epoch. Regarding the calculations of w, we compute the mean values of all layers of models. We
defer results on other datasets to appendix. From the results, we observe that initially LAUC(w)
dominate the objective and keep decreasing at earlier iterations. When it reaches similar level of
the third term ∥∇LAVG(w)∥, the objective shifts its focus on third term and pushes it to smaller
while maintaining second term positive. Eventually, we can see that both AUC and CE losses of
CT method reach to a level close to zero. In addition, comparing CT with the linear combination
method, it is amazing to see that CT drives both the CE loss and the AUC loss decrease faster and
to a smaller level than the linear combination method.

Figure 6: Evolution of each term of compositional objective function on CATvsDog, CIFAR10,
STL10 and CIFAR100 datasets (from top to bottom).

B IMPLEMENTATION OF z2,t+1 = ht(O0, O1, . . ., Ot)

The ht is usually implemented by a recursion, where examples are given in Table 6. Similar to (Guo
et al., 2021), we make the following assumption for our analysis.
**Assumption 1. For the Adam-style algorithms in Table 6, we assume that st = 1/([√]z2,t+1 + G0)**
_is upper bounded and lower bounded, i.e., there existswhere st,i denotes the i-th element of st._ 0 < cl < cu such that ∀i, cl ≤∥st,i∥≤ _cu,_

**Remark: Different implementations of ht that satisfy this assumption is presented in Table 6.**

We need the following lemma to tackle the variance recursion.
**Lemma 1 (Lemma 2, Ghadimi & Wang (2018)). Consider a moving average sequence zt+1 = (1** _−_
_β)zt + βtOh(xt) for tracking h(xt), where E[Oh(xt)] = h(xt) and h is a L-Lipschitz continuous_


-----

Table 6: Different Adam-style methods and their satisfactions of Assumption 1

method update for ht Additional assumption _cl and cu_


SHB _ht(·) = 1, G = 0_ -  _cl = 1, cu = 1_

Adam **z2,t+1 = (1 −** _βt[′][)][z][2][,t]_ [+][ β]t[′][O]t[2] _∥Ot∥∞≤_ _G_ _cl =_ _G+1G0_ _[, c][u][ =]_ _G10_

**z[′]2,t+1** [= (1][ −] _[β]t[′][)][z][′]2,t_ [+][ β]t[′][O]t[2] 1 1
AMSGrad **z2,t+1 = max(z2,t, z[′]2,t+1[)]** _∥Ot∥∞≤_ _G_ _cl =_ _G+G0_ _[, c][u][ =]_ _G0_

(AdaGrad)AdaFom **z2,t+1 =** _t+11_ _ti=0_ _[O]t[2]_ _∥Ot∥∞≤_ _G_ _cl =_ _G+1G0_ _[, c][u][ =]_ _G10_

**z[′]2,t+1** [= (1][ −] _[β]t[′][)]P[z][′]2,t_ [+][ β]t[′][O]t[2]
Adabound **z2,t+1 = Π[1/c2u[,][1][/c][2]l** []][[][z]2[′] _,t+1[]][,]_ _G0 = 0_ -  _cl = cl, cu = cu_

_mapping. Then we have_

Et∥zt+1 − _h(xt)∥[2]_ _≤_ (1 − _βt)∥zt −_ _h(xt−1)∥[2]_ + 2βt[2][E][t][∥O][h][(][x][t][)][ −] _[h][(][x][t][)][∥][2][ +][ L][2][∥][x][t][ −]βt[x][t][−][1][∥][2]_ _,_

(8)
_where Et denotes the expectation conditioned on all randomness before Oh(xt)._

C PROOF OF THEOREM 1

Denote ηt = η1st, where st = 1/([√]z2,t+1 + G0). We make the following assumptions regarding
problem 6.

**Assumption 2.**

-  _LAVG(w) is CLAVG_ _-Lipschitz continuous, g1( ¯w) is Cg1_ _-Lipschitz continuous and g2( ¯w) is Cg2_ _-_
_∇_
_Lipschitz continuous._

-  _LAVG(w) is LLAVG_ _-Lipschitz continuous,_ _g1( ¯w) is Lg1_ _-Lipschitz continuous, and_ _g2( ¯w) is_
_∇[2]_ _∇_ _∇_
_Lg2_ _-Lipschitz continuous._

-  E∥α∇LAVG(w) − _α∇LAVG(w; S)∥[2]_ _≤_ _σ[2], E∥α∇[2]LAVG(w) −_ _α∇[2]LAVG(w; S)∥[2]_ _≤_ _σ[2],_
E∥∇g1(w) −∇g1(w; S)∥[2] _≤_ _σ[2], E∥g1(w) −_ _g1(w; S)∥[2]_ _≤_ _σ[2], E∥∇g2(w) −∇g2(w; S)∥[2]_ _≤_
_σ[2], E∥g2(w) −_ _g2(w; S)∥[2]_ _≤_ _σ[2]._

-  Ω _is a bounded convex set with radius D._

It is notable that the last assumption can be replaced by a condition that the dual variables θt are
bounded.

We also know that g3(θ) is λ := 2p(1 − _p)-strongly convex and also Lg3 = λ-smooth. De-_
note θ[∗]( ¯w) = arg max **w, θ). Based on Assumption 2, we have that h( ¯w) is (Ch := 1 +**
_θ_ Ω [Φ( ¯]
_∈_

_αCLAVG_ )-Lipschitz continuous, ∇h( ¯w) is (Lh := 1 + αLLAVG)-Lipschitz continuous, E∥∇h( ¯w) −

_L∇Fh -smooth, where( ¯w; S)∥[2]_ _≤_ (1 + L DF := ([2])σ[2]L, andg1 + E DL∥h( ¯gw2 +) − λh) +( ¯w;( SLg)1∥+[2]DL≤λ _g(1 +2_ +λ) D[2] (Lemma 4.3 of (Lin et al., 2019)).[2])σ[2]. We also know that F ( ¯w) is


We present Theorem 1 formally in the following Theorem.

**Theorem 2. Assume F** ( ¯w0) _F_ ∆F where F = min **w).** _Suppose Assumptions 1_
_−_ _∗_ _≤_ _∗_ **w¯** _[F]_ [( ¯]

_and 2 hold._ _With β0 = O(1/√T_ ), β1 = O(1/√T ), β0 = O(1/√T ), β1 = O(1/√T ),

_η1 ≤_ min{ _c[3]uc[C]l_ [3] _β21_ _[,]_ _c[3]u[(][C][1][λ][2]c[+512]l_ _[C]g[2]2_ [)] 2βC0λh _[,]_ 2c[2]ucl[L][F] _[}][, and][ η][2][ =][ O][(1][/]√T_ ) where C1 and C3 are

_proper constants specified in the proof, Algorithm 1 can ensure thatq_


_O( [1]_
_≤_ _√_


_F_ ( ¯wt)
_∥∇_ _∥[2]_
_t=0_

X


).


_T + 1_


To prove this theorem, we first need a couple of lemmas.


-----

**Lemma 2. Suppose Assumption 1 and Assumption 2 hold. Considering the update in Algorithm 1,**
_we have_
_F_ ( ¯wt+1) _F_ ( ¯wt) + _[η][1][c][u]_ [ _hg1(h( ¯wt)) + θ[∗](h( ¯wt))_ _hg2(h( ¯wt))]_ **zt+1**
_≤_ 2 _∥_ _∇_ _∇_ _−_ _∥[2]_

(9)

**wt)**

_−_ _[η][1]2[c][l]_ _[∥∇][F]_ [( ¯] _∥[2]_ _−_ _[η][1]4[c][l]_ _[∥][z][t][+1][∥][2][.]_

_Proof of Lemma 2. Due to the smoothness of F_, we can prove that under η1LF ≤ _cl/(2c[2]u[)][,]_

_F_ ( ¯wt+1) _F_ ( ¯wt) + _F_ ( ¯wt)[⊤]( ¯wt+1 **w¯** _t) +_ _[L][F]_ **wt+1** **w¯** _t_
_≤_ _∇_ _−_ 2 _[∥]_ [¯] _−_ _∥[2]_

= F ( ¯wt) _F_ ( ¯wt)[⊤](ηt **zt+1) +** _[L][F]_
_−∇_ _◦_ 2 _[∥][η][t][ ◦]_ **[z][t][+1][∥][2]**

= F ( ¯wt) + [1] **wt)** **zt+1)** **wt)** + ( _[L][F]_

2 _[∥√][η][t][ ◦]_ [(][∇][F] [( ¯] _−_ _∥[2]_ _−_ [1]2 _[∥√][η][t][ ◦∇][F]_ [( ¯] _∥[2]_ 2 _[∥][η][t][ ◦]_ **[z][t][+1][∥][2][ −]** 2[1] _[∥√][η][t][ ◦]_ **[z][t][+1][∥][2][)]**

_F_ ( ¯wt) + _[η][1][c][u]_ [ _hg1(h( ¯wt)) + θ[∗](h( ¯wt))_ _hg2(h( ¯wt))]_ **zt+1**
_≤_ 2 _∥_ _∇_ _∇_ _−_ _∥[2]_

1[c]u[2] _[L][F]_
**wt)** + _[η][2]_ _[−]_ _[η][1][c][l]_ **zt+1**

_−_ _[η][1]2[c][l]_ _[∥∇][F]_ [( ¯] _∥[2]_ 2 _∥_ _∥[2]_

_F_ ( ¯wt) + _[η][1][c][u]_ [ _hg1(h( ¯wt)) + θ[∗](h( ¯wt))_ _hg2(h( ¯wt))]_ **zt+1** **wt)**
_≤_ 2 _∥_ _∇_ _∇_ _−_ _∥[2]_ _−_ _[η][1]2[c][l]_ _[∥∇][F]_ [( ¯] _∥[2]_ _−_ _[η][1]4[c][l]_ _[∥][z][t][+1][∥][2][.]_


**Lemma 3. Let θt+1 = ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))], we have**

_∥θt+1 −_ _θ[∗](h( ¯wt+1))∥[2]_ _≤(1 −_ _[η][2]2 [λ]_ [)][E][∥][θ][t][ −] _[θ][∗][(][h][( ¯]wt))∥[2]_ + 2η2[2][σ][2]

(10)

+ [16][η][2] _Cg[2]2_ [E][∥][u][t][+1] **wt)** + [4][L]θ[2] **wt)** _h( ¯wt+1)_

_λ_ _[−]_ _[h][( ¯]_ _∥[2]_ _η2λ_ [E][∥][h][( ¯] _−_ _∥[2]_


_where Lθ :=_ _[C]λ[g][2]_


_is the Lipschitz continuous constant of θ[∗](·)._


_Proof of Lemma 3. Since θ[∗](h( ¯wt)) = ΠΩ[θ[∗](h( ¯wt)) + η2(g2(h( ¯wt))_ _g3(θ[∗](h( ¯wt))))], we_
_−∇_
have
E∥θt+1 − _θ[∗](h( ¯wt))∥[2]_

= E∥ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))] − ΠΩ[θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ[∗](h( ¯wt))))]∥[2]

_≤_ E∥[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))] − [θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ[∗](h( ¯wt))))]∥[2]

= E∥[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt)) − _η2g2(ut+1) + η2g2(ut+1)]_

[θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) _g3(θ[∗](h( ¯wt))))]_
_−_ _−∇_ _∥_

_≤_ E∥[θt + η2(g2(ut+1) −∇g3(θt))] − [θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ[∗](h( ¯wt))))]∥[2]

+ η2[2][E][∥][g][2][(][u][t][+1][;][ S][1]

_[∪S][2][)][ −]_ _[g][2][(][u][t][+1][)][∥][2]_

_≤_ E∥[θt + η2(g2(ut+1) −∇g3(θt))] − [θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ[∗](h( ¯wt))))]∥[2] + η2[2][σ][2][,]
(11)
where
E∥[θt + η2(g2(ut+1) −∇g3(θt))] − [θ[∗](h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ[∗](h( ¯wt))))]∥[2]

= E∥θt − _θ[∗](h( ¯wt))∥[2]_ + η2[2][E][∥][[][g][2][(][u][t][+1][)][ −∇][g][3][(][θ][t][)]][ −] [[][g][2][(][h][( ¯]wt)) −∇g3(θ[∗](h( ¯wt)))]∥[2]

+ 2η2 _θt_ _θ[∗](h( ¯wt)), [g2(ut+1)_ _g3(θt)]_ [g2(h( ¯wt)) _g3(θ[∗](h( ¯wt)))]_
_⟨_ _−_ _−∇_ _−_ _−∇_ _⟩_

E _θt_ _θ[∗](h( ¯wt))_ + 2η2[2][C]g[2]2 [E][∥][u][t][+1] **wt)** + 2η2[2][L][2]g3 [E][∥][θ][t] **wt))** (12)
_≤_ _∥_ _−_ _∥[2]_ _[−]_ _[h][( ¯]_ _∥[2]_ _[−]_ _[θ][∗][(][h][( ¯]_ _∥[2]_

+ _[η][2][λ]_ **wt))** + [4][η][2] _g2_ [E][∥][u][t][+1] **wt)** 2η2λE _θt_ _θ[∗](h( ¯wt))_

4 [E][∥][θ][t][ −] _[θ][∗][(][h][( ¯]_ _∥[2]_ _λ [C]_ [2] _[−]_ _[h][( ¯]_ _∥[2]_ _−_ _∥_ _−_ _∥[2]_

(1 _η2λ)E_ _θt_ _θ[∗](h( ¯wt))_ + [8][η][2] _g2_ [E][∥][u][t][+1] **wt)** _,_
_≤_ _−_ _∥_ _−_ _∥[2]_ _λ [C]_ [2] _[−]_ _[h][( ¯]_ _∥[2]_


-----

where the first inequality uses strong monotone inequality as g3( ) is λ-strongly convex and the
second inequality uses η2 ≤ min{ 8Lλ[2]g3 _[,][ 2]λ_ _[}][. Then,]_ _·_

E∥θt+1 − _θ[∗](h( ¯wt+1))∥[2]_

2

(1 + _[η][2][λ]_ **wt))** + (1 + **wt))** _θ[∗](h( ¯wt+1))_
_≤_ 2 [)][E][∥][θ][t][+1][ −] _[θ][∗][(][h][( ¯]_ _∥[2]_ _η2λ_ [)][E][∥][θ][∗][(][h][( ¯] _−_ _∥[2]_

_≤_ (1 + _[η][2]2 [λ]_ [)(1][ −] _[η][2][λ][)][E][∥][θ][t][ −]_ _[θ][∗][(][h][( ¯]wt))∥[2]_ + (1 + _[η][2]2 [λ]_ [)(][η]2[2][σ][2][ + 8]λ [η][2] _[C]g[2]2_ [E][∥][u]t+1 _[−]_ _[h][( ¯]wt)∥[2])_


2

_η2λ_ [)][E][∥][θ][∗][(][h][( ¯]wt)) − _θ[∗](h( ¯wt+1))∥[2]_


+ (1 +


_≤_ (1 + _[η][2]2 [λ]_ [)(1][ −] _[η][2][λ][)][E][∥][θ][t][ −]_ _[θ][∗][(][h][( ¯]wt))∥[2]_ + 2η2[2][σ][2][ + 16]λ[η][2]

_θ_
+ [4]η[L]2λ[2] [E][∥][h][( ¯]wt) − _h( ¯wt+1)∥[2]_


_Cg[2]2_ [E][∥][u]t+1 _[−]_ _[h][( ¯]wt)∥[2]_


_≤_ (1 − _[η][2]2 [λ]_ [)][E][∥][θ][t][ −] _[θ][∗][(][h][( ¯]wt))∥[2]_ + 2η2[2][σ][2][ + 16]λ[η][2] _Cg[2]2_ [E][∥][u]t+1 _[−]_ _[h][( ¯]wt)∥[2]_ + [4]η[L]2λθ[2] [E][∥][h][( ¯]wt) − _h( ¯wt+1)∥[2],_

where the third inequality is because that θ[∗](·) is Lθ = _[C]λ[g][2]_ [-Lipschitz Lin et al. (2019).]

_Proof of Theorem 2. Denote by g1(h( ¯wt))_ = Exi,yi [g1(h( ¯wt); xi, yi)] and g2(h( ¯wt)) =
Exi,yi [g2(h( ¯wt); xi, yi)]. Note that ∇hΦ(h( ¯wt), θt) = ∇hg1(h( ¯wt)) + θt∇hg2(h( ¯wt)). Denote by ∆u,t = ∥ut+1 − _h( ¯wt)∥[2], ∆z,t = ∥zt+1 −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θt)∥[2]_ = ∥zt+1 −
_∇h( ¯wt)[⊤][∇hg1(h( ¯wt)) + θt∇hg2(h( ¯wt))]∥[2], and δt = ∥θt −_ _θ[∗](h( ¯wt))∥[2]._

Applying Lemma 1 to ut, we have

E[∆u,t+1] (1 _β0)∆u,t + 2β0[2][σ][2][ +][ C]h[2]_ **w¯** _t+1_ **w¯** _t_ _._ (13)
_≤_ _−_ _β0_ _∥_ _−_ _∥[2]_

Hence we have

_T_ _T_ _T_

∆u,t ∆u,t+1 _Ch[2][η]1[2][c]u[2]_ _[∥][z][t][+1][∥][2]_

E ∆u,t E _−_ + 2β0σ[2](T + 1) + _._ (14)

"t=0 # _≤_ "t=0 _β0_ _t=0_ _β0[2]_ #
X X X

and

_T +1_ _T_ _T_

∆u,t ∆u,t+1 _Ch[2][η]1[2][c]u[2]_ _[∥][z][t][+1][∥][2]_

E ∆u,t E _−_ + 2β0σ[2](T + 1) + _._ (15)

" _t=1_ # _≤_ "t=0 _β0_ _t=0_ _β0[2]_ #
X X X


Define
**et = (1** _β1)(_ **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(h( ¯wt), θ[∗](h( ¯wt)))_ **w¯** _[h][( ¯]wt_ 1)[⊤] _hΦ(h( ¯wt_ 1), θ[∗]( ¯wt 1))).
_−_ _∇_ _∇_ _−∇_ _−_ _∇_ _−_ _−_

We have
_∥et∥[2]_ _≤_ 2(1 − _β1)[2][(Cg[2]1_ [+][ D][2][C]g[2]2 [)][C]h[2] [+][ C]h[2][(][L][2]g1 [+][ D][2][L]g[2]2 [)](][∥]w[¯] _t −_ **w¯** _t−1∥[2]_ + ∥θ[∗](h( ¯wt)) − _θ[∗](h( ¯wt−1))∥[2])_
and
E∥zt+1 −∇w¯ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θ[∗](h( ¯wt))) + et∥[2]_

_≤_ E∥(1 − _β1)[zt −∇w¯_ _[h][( ¯]wt−1)[⊤]∇hΦ(h( ¯wt−1), θ[∗](h( ¯wt−1)))]_

+ β1[ **w¯** _[h][( ¯]wt;_ 1) **uΦ(ut+1, θt;** 2) **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(ut+1, θt)]_
_∇_ _S_ _∇_ _S_ _−∇_ _∇_

+ β1[ **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(ut+1, θt)_ **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(h( ¯wt), θ[∗](h( ¯wt)))]_
_∇_ _∇_ _−∇_ _∇_ _∥[2]_

_≤_ E∥(1 − _β1)[zt −∇w¯_ _[h][( ¯]wt−1)[⊤]∇hΦ(h( ¯wt−1), θ[∗](h( ¯wt−1)))]_

+ β1[ **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(ut+1, θt)_ **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(h( ¯wt), θ[∗](h( ¯wt)))]_
_∇_ _∇_ _−∇_ _∇_ _∥[2]_

(16)

+ β1[2][E][∥∇]w[¯] _[h][( ¯]wt;_ 1) **uΦ(ut+1, θt;** 2) **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(ut+1, θt)_
_S_ _∇_ _S_ _−∇_ _∇_ _∥[2]_

_≤_ (1 + _[β]2 [1]_ [)(1][ −] _[β][1][)][2][E][∥][z][t][ −∇]w[¯]_ _[h][( ¯]wt−1)[⊤]∇hΦ(h( ¯wt−1), θ[∗](h( ¯wt−1)))∥[2]_

+ (1 + β[2]1 [)2][β]1[2][E][∥∇]w[¯] _[h][( ¯]wt)[⊤]∇hΦ(ut+1, θt) −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θt)∥[2]_

+ (1 + β[2]1 [)2][β]1[2][E][∥∇]w[¯] _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θt) −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θ[∗](h( ¯wt)))∥[2]_


+ β1[2][E][∥∇]w[¯] _[h][( ¯]wt;_ 1)[⊤] **uΦ(ut+1, θt;** 2) **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(ut+1, θt)_ _,_
_S_ _∇_ _S_ _−∇_ _∇_ _∥[2]_


-----

where the last three terms can be bounded as below. First,
E∥∇w¯ _[h][( ¯]wt)[⊤]∇hΦ(ut+1, θt) −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θt)∥[2]_ (17)

_≤_ 2Ch[2][(][L][2]g1 [+][ L]g[2]2 [)][E][∥][u][t][+1] _[−]_ _[h][( ¯]wt)∥[2]._

Second,
E∥∇w¯ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θt) −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(h( ¯wt), θ[∗](h( ¯wt)))∥[2]_ (18)

_Ch[2][C]g[2]2_ [E][∥][θ][t] **wt))** _._
_≤_ _[−]_ _[θ][∗][(][h][( ¯]_ _∥[2]_

Third,
E∥∇w¯ _[h][( ¯]wt; S1)[⊤]∇uΦ(ut+1, θt; S2) −∇w¯_ _[h][( ¯]wt)[⊤]∇hΦ(ut+1, θt)∥[2]_ (19)

_≤_ 8σ[2](Ch[2] [+][ D][2][C]h[2] [+][ σ][2][) + 4][C]h[2][(][σ][2][ +][ D][2][σ][2][) = 4][σ][2][(3][C]h[2] [+ 3][D][2][C]h[2] [+ 2][σ][2][)][.]

It follows that
**zt+1** **w¯** _[h][( ¯]wt)[⊤]_ _hΦ(h( ¯wt), θ[∗](h( ¯wt)))_
_∥_ _−∇_ _∇_ _∥[2]_

(1 + _[β][1]_ **w[h][( ¯]wt)[⊤]** _hΦ(h( ¯wt), θ[∗](h( ¯wt))) + et_ + (1 + [2]
_≤_ 2 [)][E][∥][z][t][+1][ −∇] [¯] _∇_ _∥[2]_ _β1_ [)][∥][e][t][∥][2]

_≤_ (1 + _[β]2 [1]_ [)][2][(1][ −] _[β][1][)][2][E][∥][z][t][ −∇]w[¯]_ _[h][( ¯]wt−1)∇hΦ(h( ¯wt−1), θt−1))∥[2]_

+ 32β1Ch[2][(][L][2]g1 [+][ L]g[2]2 [)][E][∥][u]t+1 _[−]_ _[h][( ¯]wt)∥[2]_ + 16β1E∥θt − _θ[∗](h( ¯wt))∥[2]_ (20)

+ 8β1[2][σ][2][(3][C]h[2] [+ 3][D][2][C]h[2] [+ 2][σ][2][) + 4]

_β1_

_[∥][e][t][∥][2]_

_≤_ (1 − _β1)E∥zt −∇w¯_ _[h][( ¯]wt−1)∇hΦ(h( ¯wt−1), θt−1))∥[2]_ + β1C1E∥ut+1 − _h( ¯wt)∥[2]_

+ 16β1E∥θt − _θ[∗](h( ¯wt))∥[2]_ + β1[2][C]2 [+][ C]β1[3] [E][∥]w[¯] _t −_ **w¯** _t−1∥[2]._

where C: = 32Ch[2][(][L]g[2]1 [+][L]g[2]2 [)][,][ C][2] [:= 8][σ][2][(3][C]h[2] [+3][D][2][C]h[2] [+2][σ][2][)][ and][ C][3][ := 8[(][C]g[2]1 [+][D][2][C]g[2]2 [)][C]h[2] [+]
_Ch[2][(][L]g[2]1_ [+][ D][2][L]g[2]2 [)]][. Thus,]

_T_ _T +1_ _T +1_ _T_

E ∆z,t E ∆z,0 + C1 ∆u,t + 16 _δt + β1C2(T + 1) +_ _[C][3][η]1[2][c][2]u_ **zt+1** _._

" _t=0_ # _≤_  _β1_ _t=1_ _t=1_ _β1[2]_ _t=0_ _∥_ _∥[2]_ 
X X X X

Using Lemma 3, we have


2

_η2λ_ [E][∥][θ][0][ −] _[θ][∗][(][h][( ¯]w0))∥[2]_ + [4][η][2][σ][2][(]λ[T][ + 1)]

2

_η2λ_ [E][∥][θ][0][ −] _[θ][∗][(][h][( ¯]w0))∥[2]_ + [4][η][2][σ][2][(]λ[T][ + 1)]


_T_

_θ[C]h[2][η]1[2][c][2]u_
E[∆u,t] + [8][L][2]
_t=0_ _η2[2][λ][2]_

X

_T_

_θ[C]h[2][η]1[2][c][2]u_
E[∆u,t] + [8][L][2]
_t=0_ _η2[2][λ][2]_

X


+ λ[32][2][ C]g[2]2

+ λ[32][2][ C]g[2]2


E∥zt+1∥[2],
_t=0_

X

_T_

E∥zt+1∥[2]
_t=0_

X


_δt_
_t=0_ _≤_

X

and
_T +1_

_δt_
_t=1_ _≤_

X


Combining the upper bound of _t_ [∆][z,t][,][ P]t [∆][u,t][,][ P]t _[δ][t][ and Lemma 2, we have]_

_T_ _T_ _T_ _T_

2

E _F_ ( ¯wt) E(F ( ¯wt) _F_ ( ¯wt+1)) + _[c][u]_ ∆z,t E **zt+1**
 _t=0_ _∥∇_ _∥[2]_ _≤_ _η1cl_ _t=0_ [P] _−_ _cl_ _t=0_ _−_ 2[1] _t=0_ _∥_ _∥[2]_
X X X X

_T_ _T +1_ _T +1_ _T_

**w0) −** _F∗)_ E **zt+1** + _[c][u]_ ∆z,0 + C1 ∆u,t + 16 _δt + β1C2 +_ _[C][3][η]1[2][c][2]u_ **zt+1**
_≤_ [2][E][(][F] [( ¯]η1cl _−_ 2[1] _t=0_ _∥_ _∥[2]_ _cl_ [E] _β1_ _t=1_ _t=1_ _β1[2]_ _t=0_ _∥_ _∥[2]_

X X X X

_T +1_ _T_

_≤_ [2][E][(][F] [( ¯]ηw10c)l − _F∗)_ + _[c]c[u]l_ [E] ∆βz,1 0 + η[32]2λ _[δ][0][ +][ β][1][C][2][(][T][ + 1) + 64][η][2][σ][2]λ[(][T][ + 1)]_ + C1 _t=1_ ∆u,t + [512]λ[2][ C]g[2]2 _t=0_ ∆u,t

X X

_T_

+ E _cu_ 1[c][2]u ) **zt+1**

_t=0_  _cl_ [(] _[C][3]β[η]1[2][2]_ _−_ 2[1] ∥ _∥[2]_

X

**w0) −** _F∗)_ + _[c][u]_ ∆z,0 + [32][δ][0] _g2_ ) [∆][u,][0]
_≤_ [2][E][(][F] [( ¯]η1cl _cl_ [E]  _β1_ _η2λ_ [+ (][C][1][ + 512]λ[C][2] [2] _β0_ 

+ _[c][u][(][T][ + 1)]_ E _β1C2 + [64][η][2][σ][2]_ + 2(C1 + [512][C]g[2]2 )β0σ[2]

_cl_ _λ_ _λ[2]_
 


_T_

E _cu_ 1[c][2]u + (C1 + [512][C]g[2]2 ) _[C]h[2][η]1[2][c][2]u_ )
_t=0_  _cl_ [(] _[C][3]β[η]1[2][2]_ _λ[2]_ _β0[2]_ _−_ 2[1]

X


**zt+1**
_∥_ _∥[2]_


-----

Due to the setting

_cl_ _β1_ _cl_ _β0λ_
_η1_ min _,_ (21)
_≤_ _{_ _c[3]u[C][3]_ 2 _[,]_ _c[3]u[(][C][1][λ][2][ + 512][C]g[2]2_ [)] 2Ch _}_
r

we have
_cu_ 1[c]u[2] _g2_ _h[η]1[2][c]u[2]_

( _[C][3][η][2]_ + (C1 + [512][C] [2] ) _[C]_ [2] ) 0. (22)
_cl_ _β1[2]_ _λ[2]_ _β0[2]_ _−_ 2[1] _≤_

 


Hence, we have


_T_

_F_ (xt) **w0) −** _F∗)_ + _[c][u]_ ∆z,0 + [32][δ][0] _g2_ ) [∆][u,][0]
_t=0_ _∥∇_ _∥[2]_ _≤_ [2][E][(][F] [( ¯]η1clT _clT_ [E]  _β1_ _η2λ_ [+ (][C][1][ + 512]λ[C][2] [2] _β0_

X


1

_T + 1_ [E]


+ _[c][u]_ _β1C2 + [64][η][2][σ][2]_

_cl_ [E]  _λ_


+ 2(C1 + [512][C]g[2]2 )β0σ[2]

_λ[2]_

_T_ ), we have


With β0 = O(1/


_T_ ), β1 = O(1/


_T_ ), and η2 = O(1/


_T_

_F_ (xt) _O( [1]_
_∥∇_ _∥[2]_ _≤_ _√_
_t=0_ 

X


1

_T + 1_ [E]


).


Table 7: Testing performance on benchmark datasets and ImageNet-LT. The percentage number is
the second row denotes the imbalanced ratio (cf the text). All experiments on benchmark datasets are
averaged over three runs with different random seeds. The network structure used in all experiments
is ResNet32.

|Datasets|For Accuracy Maximization|
|---|---|
||Method 1% 10%|
|CIFAR10 (LT)|CE 0.713±0.001 0.876±0.002 LDAM [Cao et al. (2019)] 0.744±0.003 0.872±0.002 TS-DRW [Cao et al. (2019)] 0.780±0.003 0.879±0.000 TS-DEC [Kang et al. (2019)] 0.758±0.016 0.842±0.004 CT (CB-LDAM) 0.787±0.001 0.883±0.001|
|CIFAR100 (LT)|CE 0.396±0.002 0.572±0.000 LDAM [Cao et al. (2019)] 0.407±0.004 0.559±0.003 TS-DRW [Cao et al. (2019)] 0.427±0.006 0.579±0.001 TS-DEC [Kang et al. (2019)] 0.403±0.003 0.536±0.001 CT (CB-LDAM) 0.430±0.005 0.585±0.002|
|STL10 (LT)|CE 0.441±0.017 0.639±0.009 LDAM [Cao et al. (2019)] 0.440±0.010 0.641±0.008 TS-DRW [Cao et al. (2019)] 0.458±0.006 0.651±0.017 TS-DEC [Kang et al. (2019)] 0.457±0.013 0.629±0.009 CT (CB-LDAM) 0.488±0.012 0.662±0.005|
|ImageNet (LT)|CE [Jamal et al. (2020)] 0.2526 CB-CE [Cui et al. (2019)] 0.2659 CT (CB-CE) 0.2661|


D COMPOSITIONAL TRAINING WITH CLASS WEIGHTED LOSS

In this section, we extend the compositional training method to deep learning with class weighted
loss. Let LCW(w) denote a class weighted loss written as:

_n_

_LCW(w) = n[1]_ _pyi_ _ℓ(w; xi, yi),_ (23)

_i=1_

X

where pyi (0, 1) denotes a weight assigned to the i-th example that depends on the class the data
belongs to. There are different methods for determining the class-level weight. A simple method ∈
is to set pi according to the reciprocal of its corresponding class size, i.e., pyi = 1/nyi . Recently,
Cui et al. (2019) proposed an improved variant of class-weighted loss by using an effective number
of samples per-class instead of the class size to compute the individual weight, i.e., pyi = 1 1−γ[nyi]γ [,]

_−_
whereweights as γ ∈ L(0CB, 1)(w is a hyper-parameter. We refer to the class weighted loss using these individual) = 1/n _i=1_ 1−1−γ[nyi]γ _[ℓ][(][w][;][ x][i][, y][i][)][.]_

[P][n]


-----

**With Class-Weighted Losses. The corresponding compositional objective is a standard two-level**
compositional function, i.e.,
min (24)
**w** R[d][ F] [(][w][) =][ L][CW][(][w][ −] _[α][∇][L][AVG][(][w][))][.]_
_∈_

Assuming that the stochastic gradient of LCW can be easily computed, the optimization of the above
problem is easier than that for AUC loss.

We present a simplified stochastic adaptive algorithm with an Adam-style adaptive step size in Algorithm 2 referred to as SCA, where ht( 0, . . ., _t) denotes an appropriate mapping function, which_
_O_ _O_
can be implemented by using different methods, including Adam, AMSGrad, Adabound, etc. Notice
that when ht( ) = 1 Algorithm 2 becomes the NASA algorithm (Ghadimi et al., 2020) to stochastic

_·_
compositional optimization. We present an informal convergence of Algorithm 2 below.
**Theorem 3. (Informal) Under appropriate conditions on the loss functions LAVG, LCW and**

1 _T_

_ℓ(w; x, y), with β0, β1, η = O(1/√T_ ), Algorithm 2 ensures that E _T +1_ _t=0_

_[∥∇][F]_ [(][w][t][)][∥][2][i] _≤_

_O(_ _√[1]T_ [)][.] h P

**Remark: The appropriate conditions include the Lipschitz continuous conditions on LAVG and**
_LCW and bounded variance conditions of ∇ℓ(w; xi, yi) and ∇[2]ℓ(w; xi, yi). We will present the_
detailed conditions below when proving the above theorem. The above theorem indicates that we
can optimize the compositional objective (24) with the same convergence rate as optimizing the
averaged loss (1) for deep learning.

D.1 EXPERIMENTS WITH MULTI-CLASS DATASETS

We conduct experiments on three benchmark multi-class image classification datasets, namely CIFAR10, CIFAR100, and STL10. We construct imbalanced versions of these datasets by keep their
classes but making the class sizes follow a long-tailed (LT) distribution with two imbalanced ratios
(the ratio of the size of minority class to the size of majority class) similar to (Cui et al., 2019).
We use ResNet32 as the network stucture. The weight decay is set to 2e-4 for all experiments. For
algorithms, we train a total of 200 epochs with a batch size 128 and we use step size 0.1 and decrease it by 10 times at at 80% and 90% of total training time. We tune the beta parameters of our
methods in a range [0.1, 0.99] with a grid search and find that good values are around 0.9. For the
class-weighted loss, we choose the class-weighted version of the LDAM loss (Cao et al., 2019). For
baselines, we compare with optimizing the CE loss (CE), optimizing the LDAM loss (LDAM), the
two-stage method with the deferred re-weighting that optimizes the class balanced LDAM loss in
the second stage (TS-DRW) (Cao et al., 2019), the two-stage method with the decoupling trick that
optimizes the class balanced LDAM loss in the second stage (TS-DEC) (Kang et al., 2019). The
results are shown in Table 7. We can see that the proposed CT method achieves the best accuracy
on all datasets. In addition, we conduct a large-scale experiment by following Jamal et al. (2020) on
ImageNet-LT with ResNet32. We use class-balanced loss (Cui et al., 2019) as outer loss function
of our compositional objective. We use an initial learning rate of 0.1 and run a total of 90 epochs
decaying learning rate every 35 epochs by a factor of 10. Eventually, we achieve the top1 accuracy
of 26.61%, which is better than two baselines, i.e., CE(25.26%) and CBCE(26.59%).

D.2 ANALYSIS OF THEOREM 3

In the section we analyze Algorithm 2. An algorithm utilizing the adaptive step size and moving
average for nonconvex optimization has been studied in (Guo et al., 2021). But here we have to
tailor the algorithm and analysis to the considered formulation with composition. Denote st =
1/(z2,t+1 + G0), ηt = ηst. We make the following assumptions regarding the problem 24.
**Assumption 3.**

-  LCW(u) is CLCW _-Lipschitz continuous,_ _LAVG(w) is CLAVG_ _-Lipschitz continuous._
_∇_

-  _LCW(u) is LLCW-Lipschitz continuous,_ _LAVG(w) is LLAVG_ _-Lipschitz continuous._
_∇_ _∇[2]_

-  The stochastic oracle satisfies E∥α∇LAVG(w) − _α∇LAVG(w; S)∥[2]_ _≤_ _σ[2], E∥α∇[2]LAVG(w) −_
_α∇[2]LAVG(w; S)∥[2]_ _≤_ _σ[2], E∥∇LCW(u) −∇LCW(u; S)∥[2]_ _≤_ _σ[2]._

We formally present Theorem 3 as follows


-----

**Algorithm 2 Stochastic Compositional Adaptive (SCA) method for solving (24)**

1: Require Parameters: β0, β1, α, G0, η
2:3: Initialization: for t = 0, 1, ..., T w0 ∈ doR[d], z0, u0
4: Sample three sets of examples denoted by 1, 2
_S_ _S_

6:5: _Outt+1 = ( = (1I − −α∇β0[2])LuAVGt +( βw0t(;w St1 −))∇αL∇CWLAVG(ut(+1w;t S; S2)1))_

7: **zt+1 = (1 −** _β1)zt + β1Ot_

8: **z2,t+1 = ht(** 0, . . ., _t)_ _ht can be implemented by that in Appendix B,_
_O_ **zt O+1** _⋄_

9: **wt+1 = wt −** _η_ _√z2,t+1+G0_ _⋄with the simplest form ht = 1_

10: end for

**Theorem 4. Assume F** (x0) _F_ ∆F where F = min
_−_ _∗_ _≤_ _∗_ **x** _[F]_ [(][x][)][. Suppose Assumptions 1 and 3]

_hold. With η ≤_ 4L√Fc[√]lβ1c[3]u _[,]_ 4(1+αC√LcAVGlβ0)[√]C5c[3]u _[,]_ 2c[2]ucl[L][F] _, β0 = O(_ _√[1]T_ [)][,][ β][1][ ≤] _[O][(][ 1]√T_ [)][, and constants]
 

_LF = 2LLCW(1 + αCLAVG_ )[2] + 2CLCWαLLAVG _, C5 = (4L[2]LAVG_ _[C]L[2]_ _CW_ [+ 2(1 +][ αL]L[2] _AVG_ [)][L][L]CW[)][, Algorithm]
_2 can ensure that_


_O( [1]_
_≤_ _√_


_F_ (wt)
_∥∇_ _∥[2]_
_t=0_

X


).


_T + 1_


_Proof of Theorem 4. By Assumption 2, we know that F_ (w) is smooth with coefficient LF :=
2LLCW(1 + αCLAVG)[2] + 2CLCWαLLAVG. We can prove that under ηLF ≤ _cl/(2c[2]u[)][,]_

_F_ (wt+1) ≤ _F_ (wt) + ∇F (wt)[⊤](wt+1 − **wt) +** _[L]2[F]_ _[∥][w][t][+1][ −]_ **[w][t][∥][2]**

= F (wt) −∇F (wt)[⊤](ηt ◦ **zt+1) +** _[L]2[F]_ _[∥][η][t][ ◦]_ **[z][t][+1][∥][2]**

= F (wt) + [1]2 _[∥√][η][t][ ◦]_ [(][∇][F] [(][w][t][)][ −] **[z][t][+1][)][∥][2][ −]** 2[1] _[∥√][η][t][ ◦∇][F]_ [(][w][t][)][∥][2][ + (] _[L]2[F]_ _[∥][η][t][ ◦]_ **[z][t][+1][∥][2][ −]** 2[1] _[∥√][η][t][ ◦]_ **[z][t][+1][∥][2][)]**

_u[L]F_ _l_

_F_ (wt) + _[ηc][u]_ _[−]_ _[ηc]_ **zt+1**
_≤_ 2 _[∥∇][F]_ [(][w][t][)][ −] **[z][t][+1][∥][2][ −]** _[ηc]2_ _[l]_ _[∥∇][F]_ [(][w][t][)][∥][2][ +][ η][2][c][2] 2 _∥_ _∥[2]_

_≤_ _F_ (wt) + _[ηc]2[u]_ _[∥∇][F]_ [(][w][t][)][ −] **[z][t][+1][∥][2][ −]** _[ηc]2_ _[l]_ _[∥∇][F]_ [(][w][t][)][∥][2][ −] _[ηc]4_ _[l]_ _[∥][z][t][+1][∥][2][.]_ (25)

Denote ∆z,t = ∥zt+1 −∇F (wt)∥ = ∥zt+1 − (I − _α∇[2]LAVG(wt))∇LCW(wt −_ _α∇LAVG(wt))∥[2]_

and ∆u,t = ∥ut+1 − (wt − _α∇LAVG(wt))∥[2]._

Applying Lemma 1 to ut, we have

E[∆u,t+1] (1 _β0)∆u,t + 2β0[2][σ][2][ + (1 +][ αC][L][AVG]_ [)][2] **wt+1** **wt** _._ (26)
_≤_ _−_ _β0_ _∥_ _−_ _∥[2]_

Hence we have

_T_ _T_ _T_

E ∆u,t E ∆u,t − ∆u,t+1 + 2β0σ[2](T + 1) + (1 + αCLAVG )[2]η[2]c[2]u[∥][z]t+1[∥][2] _._ (27)

" _t=0_ # _≤_ " _t=0_ _β0_ _t=0_ _β0[2]_ #
X X X

Defining
**et =(1** _β1)(_ _F_ (wt) _F_ (wt 1))
_−_ _∇_ _−∇_ _−_

=(1 _β1)[(I_ _α_ _LAVG(wt))_ _LCW(wt_ _LAVG_ (wt)) (28)
_−_ _−_ _∇[2]_ _∇_ _−∇_

_−_ (I − _α∇[2]LAVG(wt−1))∇LCW(wt−1 −∇LAVG_ (wt−1))],

we get
**et** (1 _β1)[2]L[2]F_ (29)
_∥_ _∥[2]_ _≤_ _−_ _[∥][w][t]_ _[−]_ **[w][t][−][1][∥][2][.]**


-----

It holds that
E∥zt+1 −∇F (wt) + et∥[2] _≤_ E∥(1 − _β1)(zt −∇F_ (wt−1)) + β1((I − _α∇[2]LAVG(wt; S1))∇f_ (ut+1; S2) − _F_ (wt))∥[2]

= E∥(1 − _β1)[zt −∇F_ (wt−1)]

+ β1[(I − _α∇[2]LAVG(wt; S1))∇LCW(ut+1; S2) −_ (I − _α∇[2]LAVG(wt))∇LCW(ut+1)_

+ (I − _α∇[2]LAVG(wt))∇LCW(ut+1) −_ (I − _α∇[2]LAVG(wt))∇LCW(wt −∇LAVG(wt))]∥[2]_

= E[(1 − _β1)[2]∥zt −∇F_ (wt−1)∥[2]]

+ β1[2][E][∥][(][I][ −] _[α][∇][2][L]AVG[(][w]t[;][ S]1[))][∇][L]CW[(][u]t+1[;][ S]2[)][ −]_ [(][I][ −] _[α][∇][2][L]AVG[(][w]t[))][∇][L]CW[(][u]t+1[)]_

+ (I − _α∇[2]LAVG(wt))∇LCW(ut+1) −_ (I − _α∇[2]LAVG(wt))∇LCW(wt −∇LAVG(wt))∥[2]_

+ 2(1 − _β1)β1E[(zt −∇F_ (wt−1))[⊤]((I − _α∇[2]LAVG(wt; S1))∇LCW(ut+1; S2) −_ (I − _α∇[2]LAVG(wt))∇LCW(ut+1))]_

+ 2(1 − _β1)β1E[(zt −∇F_ (wt−1))[⊤]((I − _α∇[2]LAVG(wt))∇LCW(ut+1) −_ (I − _α∇[2]LAVG(wt))∇LCW(wt −_ _α∇LAVG(wt)))]_

_≤_ E[(1 − _β1)[2]∥zt −∇F_ (wt−1)∥[2]]

+ 2β1[2][E][∥][(][I][ −] _[α][∇][2][L]AVG[(][w]t[;][ S]1[))][∇][L]CW[(][u]t+1[;][ S]2[)][ −]_ [(][I][ −] _[α][∇][2][L]AVG[(][w]t[))][∇][L]CW[(][u]t+1[)][∥][2]_

+ 2β1[2][E][∥][(][I][ −] _[α][∇][2][L]AVG[(][w]t[))][∇][L]CW[(][u]t+1[)][ −]_ [(][I][ −] _[α][∇][2][L]AVG[(][w]t[))][∇][L]CW[(][w]t_ _[−]_ _[α][∇][L]AVG[(][w]t[))][∥][2]_

+ (1 − _β1)[2][ β]2[1]_ [E][∥][z][t][ −∇][F] [(][w][t][−][1][)][∥][2]

+ 2β1E∥(I − _α∇[2]LAVG(wt))∇LCW(ut+1) −_ (I − _α∇[2]LAVG(wt))∇LCW(wt −_ _α∇LAVG(wt))∥[2]_

_≤_ (1 − _β1)[2](1 +_ _[β]2 [1]_ [)][E][∥][z][t][ −∇][F] [(][w][t][−][1][)][∥][2][ + 4((1 +][ αL][L][AVG] [)][2][ +][ σ][2][ +][ C]L[2] CW [)][β]1[2][σ][2]

+ 4β1(1 + αLLAVG )[2]L[2]LCW _[∥][u]t+1_ _[−]_ [(][w]t _[−]_ _[αL]CW[(][w]t[))][∥][2]_

_≤_ (1 − _β1)(1 −_ _[β]2 [1]_ [)][E][∥][z][t][ −∇][F] [(][w][t][−][1][)][∥][2][ +][ β]1[2][C]4[σ][2][ +][ β]1[C]5[∆]u,t[.]

where C4 := 4((1 + αLLAVG)[2] + σ[2] + CL[2] CW[)][,][ C][5][ := 4(1 +][ αL][L]AVG [)][2][L][2]LCW[.]

It follows that

**zt+1** _F_ (wt) (1 + _[β][1]_
_∥_ _−∇_ _∥[2]_ _≤_ 2 [)][E][∥][z][t][+1][ −∇][F] [(][w][t][) +][ e][t][∥][2][ + (1 + 2]β1 [)][∥][e][t][∥][2]


_≤_ (1 + _[β]2 [1]_ [)(1][ −] _[β][1][)(1][ −]_ _[β]2 [1]_ [)][E][∥][z][t][ −∇][F] [(][w][t][−][1][)][∥][2][ + (1 +][ β]2 [1] [)][C][4][β]1[2][σ][2]

+ (1 + _[β]2 [1]_ [)][C][5][β][1][∆][u,t][ + 4]β1 [(1][ −] _[β][1][)][2][L]F[2]_ _[∥][w]t_ _[−]_ **[w]t−1[∥][2]**

_≤_ (1 − _β1)E∥zt −∇F_ (wt−1)∥[2] + 2C4β1[2][σ][2]

+ 2C5β1∆u,t + [4] _F_ _t_ _t_ 1[∥][2][.]

_β1_ _[L][2]_ _[∥][w]_ _[−]_ **[w]** _−_


(30)

_T_

∆u,t
_t=0_ #

X


Thus,

_T_ _T_

E ∆z,t E ∆z,t − ∆z,t+1 + 2C4β1σ[2](T + 1) + [4][L]F[2] _η[2]c[2]u[∥][z][t][+1][∥][2][ + 2][C][5]_

"t=0 # _≤_ " _t=0_ _β1_ _β1[2]_ _t_
X X

_T_

E ∆z,t − ∆z,t+1 + 2C4β1σ[2](T + 1) + [4][L]F[2] _η[2]c[2]u[∥][z][t][+1][∥][2]_
_≤_ "t=0 _β1_ _β1[2]_

X

_T_ _T_

∆u,t ∆u,t+1 (1 + αCLAVG )[2]η[2]c[2]u[∥][z][t][+1][∥][2]

+2C5E _−_ + 2β0σ[2](T + 1) +

"t=0 _β0_ _t=0_ _β0[2]_
X X


##


(31)


-----

Combining this with (25), we obtain

_T_ _T_ _T_

_ηcl_ _ηcl_ _ηcu_

2 [E] "t=0 _∥∇F_ (wt)∥[2]# _≤_ _F_ (w0) − _F∗_ _−_ _t=0_ 4 _t=0_ 2 [∆][z,t]

_[∥][z][t][+1][∥][2][ +]_

X X X

_T_

∆z,t ∆z,t+1 ∆u,t ∆u,t+1

∆F + _[ηc][u]_ _−_ + 2C5 _−_
_≤_ 2 _β1_ _β0_

_t=0_   (32)

X

+ _[ηc][u]_

2 [[2][C][4][β][1][ + 4][C][5][β][0][]][σ][2][(][T][ + 1)]

+ _ηcu_ 4L2F _[η][2][c]u[2]_ + [2][C][5][(1 +][ αC][L][AVG][)][2][η][2][c]u[2] _T_ **zt+1** _._
 2  _β1[2]_ _β0[2]_  _−_ _[ηc]4_ _[l]_  _t=0_ _∥_ _∥[2]_

X

Due to the setting

_√clβ1_ _√clβ0_

_η ≤_ ( 4LF _c[3]u_ _,_ 4(1 + αCLAVG ) _C5c[3]u_ ) _,_ (33)

we have
_ηcu_ 4L2F _[η][2][c]u[2]_ + p[2][C][5][(1 +][ αC][L][AVG][)][2][η]p[2][c]u[2] 0. (34)

2 _β1[2]_ _β0[2]_ _−_ _[ηc]4_ _[l]_ _≤_

   

Thus,

_T_

1 E[∆z,0] E[∆u,0]

E _F_ (wt) + 2C5 + _[c][u]_ [2C4β1 + 4C5β0]σ[2].

" _T + 1_ _t=0_ _∥∇_ _∥[2]#_ _≤_ [2∆]ηclT[F] [+][ c]c[u]l  _β1T_ _β0T_  _cl_

X

(35)
With β0 = O( _√[1]T_ [)][,][ β][1][ =][ O][(][ 1]√T [)][ and][ η][ =][ O][(][ 1]√T [)][,]


_O( [1]_
_≤_ _√_


_F_ (wt)
_∥∇_ _∥[2]_
_t=0_

X


). (36)


_T + 1_


-----


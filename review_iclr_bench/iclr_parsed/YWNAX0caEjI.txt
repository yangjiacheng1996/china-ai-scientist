# NEURAL STRUCTURED PREDICTION FOR INDUCTIVE NODE CLASSIFICATION

**Meng Qu[∗][1][,][2], Huiyu Cai[∗][1][,][2], Jian Tang[1][,][3][,][4]**

1Mila - Qu´ebec AI Institute
2Universit´e de Montr´eal
3HEC Montr´eal
4Canadian Institute for Advanced Research (CIFAR)

ABSTRACT

This paper studies node classification in the inductive setting, i.e., aiming to
learn a model on labeled training graphs and generalize it to infer node labels on
unlabeled test graphs. This problem has been extensively studied with graph neural
networks (GNNs) by learning effective node representations, as well as traditional
structured prediction methods for modeling the structured output of node labels,
e.g., conditional random fields (CRFs). In this paper, we present a new approach
called the Structured Proxy Network (SPN), which combines the advantages of both
worlds. SPN defines flexible potential functions of CRFs with GNNs. However,
learning such a model is nontrivial as it involves optimizing a maximin game
with high-cost inference. Inspired by the underlying connection between joint
and marginal distributions defined by Markov networks, we propose to solve an
approximate version of the optimization problem as a proxy, which yields a nearoptimal solution, making learning more efficient. Extensive experiments on two
settings show that our approach outperforms many competitive baselines [1].

1 INTRODUCTION

Graph-structured data are ubiquitous in the real world, covering a variety of applications. This paper
studies node classification, a fundamental problem in the machine learning community. Most existing
efforts focus on the transductive setting (Kipf & Welling, 2017; Velickoviˇ c et al., 2018), i.e., using´
a small set of labeled nodes in a graph to classify the rest of nodes. In this paper, we study node
classification in the inductive setting (Hamilton et al., 2017), which is receiving growing interest.
Given some training graphs with all nodes labeled, we aim to classify nodes in unlabeled test graphs.

This problem has been recently studied with graph neural networks (GNNs) (Kipf & Welling, 2017;
Hamilton et al., 2017; Gilmer et al., 2017; Velickoviˇ c et al., 2018). GNNs infer the marginal label´
distribution of each node by learning useful node representations based on node features and edges.
Once a GNN is learned on training graphs, it can be further applied to test graphs to infer node labels.
Owing to the high capacity of nonlinear neural architectures, GNNs achieve impressive results on
many datasets. However, one limitation of GNNs is that they ignore the joint dependency of node
labels, and therefore node labels are predicted separately without modeling structured output.

Indeed, modeling structured output has been widely explored by the literature of structured prediction (BakIr et al., 2007). Structured prediction methods predict node labels collectively, so the label
prediction of each node can be improved according to the predicted labels of neighboring nodes.
One representative approach is the conditional random field (CRF) (Lafferty et al., 2001). A CRF
models the joint distribution of node labels with Markov networks, and thus training CRFs becomes
a learning task in graphical models, while predicting node labels corresponds to an inference task.
Typically, the potential functions in CRFs are parameterized as log-linear functions, which suffer
from low model capacities. One remedy for this is to define potential functions with GNNs (Ma
et al., 2018; Qu et al., 2019). However, most of the effective methods for learning CRFs involve a

*Equal contribution.
[1Codes are available at https://github.com/DeepGraphLearning/SPN.](https://github.com/DeepGraphLearning/SPN)


-----

maximin game (Wainwright & Jordan, 2008; Sutton & McCallum, 2012), making learning often hard
to converge, especially when GNNs are used to parameterize potential functions. Besides, as learning
CRFs requires doing inference on the graphical models, the combined model requires a long run time.

In this paper, we address these challenges by proposing SPN (Structured Proxy Network), which is
high in capacity, efficient in learning, and able to model the joint dependency of node labels. SPN is
inspired by theoretical works in graphical models (Wainwright & Jordan, 2008), which reveal close
connections between the joint label distribution and the node/edge marginal label distribution in a
Markov network. Based on that, we approximate the original optimization problem with a proxy
problem, where the potential functions in CRFs are defined by combining a collection of node/edge
pseudomarginal distributions, which are parameterized by GNNs that satisfy a few simple constraints.
This proxy problem can be easily solved by maximizing the data likelihood on each node and edge,
which yields a near-optimal joint label distribution on training graphs. Once the model is learned, we
apply it to test graphs and run loopy belief propagation (Murphy et al., 1999) to infer node labels.
Experiments on two settings against both GNNs and CRFs prove the effectiveness of our approach.

Note that although SPN is tested on inductive node classification, this method is quite general and
can be applied to many other structured prediction tasks as well, such as POS tagging (Church, 1988)
and named entity recognition (Sang & De Meulder, 2003). Please refer to Sec. 4.3 for more details.

2 RELATED WORK

Graph neural networks (GNNs) perform node classification by learning useful node representations (Kipf & Welling, 2017; Gilmer et al., 2017; Velickoviˇ c et al., 2018). Most earlier efforts focus´
on designing GNNs for transductive node classification (Yang et al., 2016; Gao & Ji, 2019; Xhonneux
et al., 2020), and many recent works move to the inductive setting (Hamilton et al., 2017; Gao et al.,
2018; Chiang et al., 2019; Li et al., 2019; Chen et al., 2020a; Zeng et al., 2020). Because of high
capacity and efficient training, GNNs achieve impressive results on inductive node classification.
Despite the success, GNNs only try to model the marginal distribution of each node label and predict node labels separately without considering joint dependency. In contrast, SPN models joint
distributions of node labels with CRFs, which predicts node labels collectively to improve results.

Another type of approach for inductive node classification is structured prediction, which focuses on
modeling the dependency of node labels, so that the predicted node labels are more consistent. One
representative approach is structured SVM (Tsochantaridis et al., 2005; Finley & Joachims, 2008;
Sarawagi & Gupta, 2008), but it lacks a probabilistic interpretation to handle the uncertainty of the
prediction. Another representative probabilistic approach is conditional random field (Lafferty et al.,
2001; Sutton & McCallum, 2006), which models the distribution of output spaces by using a Markov
network. CRFs have been proven effective in many applications, such as POS tagging (Lafferty
et al., 2001), shallow parsing (Sha & Pereira, 2003), image labeling (He et al., 2004), and sequence
labeling (Lample et al., 2016; Ma & Hovy, 2016; Liu et al., 2018). Nevertheless, the potential
functions in CRFs are typically defined as log-linear functions, suffering from low model capacity.

There are also some recent works trying to combine GNNs and CRFs. Some works use GNNs to
solve inference problems in graphical models (Dai et al., 2016; Satorras et al., 2019; Zhang et al.,
2020; Chen et al., 2020b; Satorras & Welling, 2020). In contrast, our approach uses GNNs to
parameterize the potential functions in CRFs, which is in a similar vein to Ma et al. (2018); Qu
et al. (2019); Ma et al. (2019; 2021); Wang et al. (2021). Among them, Ma et al. (2018) and Qu
et al. (2019) optimize the pseudolikelihood (Besag, 1975) for model learning, and Wang et al. (2021)
optimizes a cross-entropy loss on each single node, which can yield poor approximation of the
true joint likelihood (Koller & Friedman, 2009; Sutton & McCallum, 2012). Our approach instead
solves a proxy problem, which yields a near-optimal solution to the original problem of maximizing
likelihood, and thus gets superior results. For Ma et al. (2019) and Ma et al. (2021), they focus on
transductive node classification and continuous labels respectively, which are different from our work.

Lastly, learning CRFs has also been widely studied. Some works solve a maximin game as a surrogate
for learning (Sutton & McCallum, 2012) and some others maximize a lower bound of the likelihood
function (Sutton & McCallum, 2009). However, these maximin games are often hard to optimize and
the lower bounds are often loose. Different from them, we follow Wainwright et al. (2003) and build
an approximate optimization problem as a proxy, which is easier to solve and yields better results.


-----

3 PRELIMINARY

This paper focuses on inductive node classification (Hamilton et al., 2017), a fundamental problem
in both graph machine learning and structured prediction. We employ a probabilistic formalization
for the problem with some labeled training graphs and unlabeled test graphs. Each training graph is
given as (yV[∗] _[,][ x][V][, E][)][, where][ x][V][ and][ y]V[∗]_ [are features and labels of a set of nodes][ V][, and][ E][ is a set of]
edges. For each test graph (x ˜V _[,][ ˜]E), only features x ˜V_ [and edges][ ˜]E are given. Then we aim to solve:

-  Learning. On training graphs, learn a probabilistic model to approximate p(yV |xV, E).

-  Inference. For each test graph, infer node labels yV[∗]˜ [according to the distribution][ p][(][y][ ˜]V _[|][x][ ˜]V_ _[,][ ˜]E)._

The problem has been extensively studied in both graph machine learning and structured prediction
fields, and representative methods are GNNs and CRFs respectively. Next, we introduce the details.

3.1 GRAPH NEURAL NETWORKS

For inductive node classification, graph neural networks (GNNs) learn node representations to predict
marginal label distributions of nodes. GNNs assume all node labels are independent conditioned on
node features and edges, so the joint label distribution is factorized into a set of marginals as below:


_pθ(yV |xV, E) =_


_pθ(ys|xV, E)._ (1)
_sY∈V_


Each marginal distribution pθ(ys|xV, E) is modeled as a categorical distribution over label candidates,
and the label probabilities are computed by applying a linear softmax classifier to the representation of
node s. In general, node representations are learned via the message passing mechanism (Gilmer et al.,
2017), which brings high capacity to GNNs. Also, owing to the factorization in Eq. (1), learning and
inference can be easily solved in GNNs, where we simply need to compute loss and make prediction
on each node separately. However, GNNs approximate only the marginal label distributions of nodes
on training graphs, which may generalize badly and result in poor approximation of node marginal
label distributions on test graphs. Also, the labels of different nodes are separately predicted according
to their own marginal label distributions, yet the joint dependency of node labels is ignored.

3.2 CONDITIONAL RANDOM FIELDS

For inductive node classification, conditional random fields (CRFs) build graphical models for node
classification. A popular model is the pair-wise CRF, which formalizes the joint label distribution as:


_pθ(yV |xV, E) =_


_θs(ys, xV, E) +_

_Zθ(xV, E) [exp][{]sX∈V_


_θst(ys, yt, xV, E)}_ (2)
(s,tX)∈E


where Zθ(xV, E) is the partition function. θs(ys, xV, E) and θst(ys, yt, xV, E) are scalar scores
contributed by each node s and each edge (s, t). In practice, these θ-functions can be either defined
as simple linear functions or complicated GNNs. To make the notation concise, we will omit xV and
_E in the θ-functions, e.g., simplifying θs(ys, xV, E) as θs(ys). With these θ-functions, CRFs are_
able to model the joint dependency of node labels and therefore achieve structured prediction.

However, learning CRFs to maximize likelihood pθ(yV[∗]
eral, as the partition function Zθ(xV, E) is typically intractable in graphs with loops. Thus, a major[|][x][V][, E][)][ on training graphs is nontrivial in gen-]
line of research instead optimizes a maximin game equivalent to likelihood maximization (Wainwright
& Jordan, 2008). The maximin game for each training graph (yV[∗] _[,][ x][V][, E][)][ is formalized as follows:]_

max log pθ(yV[∗] _[, E][) = max]_ min (θ, q), with (θ, q) =
_θ_ _[|][x][V]_ _θ_ _q_ _L_ _L_

_{θs(ys[∗][)][ −]_ [E]qs(ys)[[][θ][s][(][y][s][)]][}][ +] _{θst(ys[∗][, y]t[∗][)][ −]_ [E]qst(ys,yt)[[][θ][st][(][y][s][, y][t][)]][} −] _[H][[][q][(][y][V]_ [)]][.][ (3)]
_sX∈V_ (s,tX)∈E


Here, q(yV ) is a variational distribution on node labels, qs(ys) and qst(ys, yt) are its marginal distributions on nodes and edges. H[q(yV )] := Eq(yV )[log q(yV )] is the entropy of q(yV ). Given the max_−_
imin game, q and θ can be alternatively optimized via coordinate descent (Sutton & McCallum, 2012).
In each iteration, we first update the node and edge marginals _qs(ys)_ _s_ _V,_ _qst(ys, yt)_ (s,t) _E_
_{_ _}_ _∈_ _{_ _}_ _∈_


-----

_τs_ _τt_ _τu_ _τv_

_st_ NodeGNN _s_ _t_ _u_ _v_

_s_ _t_ _ys_ _yt_

_vs_ _tu_

_τst_ _τtu_

_s_ _t_ _t_ _u_

_v_ _uv_ _u_ _τuv_ _τvs_ _yv_ _yu_

EdgeGNN _u_ _v_ _v_ _s_

Pseudomarginals by CRF for joint label

Graph

node and edge GNNs distribution


Figure 1: Framework overview of the SPN. Our approach formulates a proxy optimization problem
for learning, which is much easier to solve. Given a graph, a node GNN and an edge GNN are used to
predict the pseudomarginal label distributions on each node and each edge respectively. Then these
pseudomarginals serve as building blocks to construct a near-optimal joint label distribution.

towards those defined by pθ. This can be done by MCMC, but the time cost is high, so approximate
inference is often used, such as loopy belief propagation (Murphy et al., 1999). After q is optimized,
we further update θ-functions with the node and edge marginals defined by q via gradient descent.

The optimal θ-functions are characterized by the following moment-matching conditions:

_pθ(ys|xV, E) = Iys∗_ _[{][y][s][}]_ _∀s ∈_ _V,_ _pθ(ys, yt|xV, E) = I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}]_ _∀(s, t) ∈_ _E, (4)_

where Ia{b} is an indicator function whose value is 1 if a = b and 0 otherwise. See Sec. A and Sec. B
in appendix for detailed derivation of the maximin game as well as the moment-matching conditions.

Once the θ-functions are learned, they can be further applied to each test graph (x ˜V _[,][ ˜]E) to predict_
the joint label distribution asusing approximate inference algorithms, such as loopy belief propagation (Murphy et al., 1999). pθ(y ˜V _[|][x][ ˜]V_ _[,][ ˜]E). Then the best label assignment yV[∗]˜_ [can be inferred by]

The major challenge of CRFs lies in learning. On the one hand, learning relies on inference, meaning
that we have to update _qs(ys)_ _s_ _V,_ _qst(ys, yt)_ (s,t) _E to approximate the node and edge marginals_
_{_ _}_ _∈_ _{_ _}_ _∈_
of pθ at each step, which can be expensive. On the other hand, as learning involves a maximin game
and the optimal q of the inner minimization problem in Eq. (3) is intractable, we can only maximize
an upper bound of the likelihood function for θ, making learning unstable. The problem becomes
even more severe when θ is parameterized by highly nonlinear neural models, e.g. GNNs.

4 MODEL

In this section, we introduce our proposed approach Structured Proxy Network (SPN). The general
idea of SPN is to combine GNNs and CRFs by parameterizing potential functions in CRFs with
GNNs, and therefore SPN enjoys high capacity and can model the joint dependency of node labels.

However, as elaborated in Sec. 3.2, learning such a model on training graphs is challenging due
to the maximin game in optimization. Inspired by the connection between the joint and marginal
distributions of CRFs, we instead construct a new optimization problem, which serves as a proxy
for model learning. Compared with the original maximin game, the proxy problem is much easier
to solve, where we can simply train two GNNs to approximate the marginal label distributions on
nodes and edges, and further combine these pseudomarginals (defined in Prop. 1) into a near-optimal
joint label distribution. This joint label distribution can be further refined by optimizing the maximin
game, although it is optional and often unnecessary, as this distribution is often close enough to the
optimal one. With this proxy problem for model learning, learning becomes more stable and efficient.

Afterwards, the learned model is used to predict the joint label distribution on test graphs. Then we
run loopy belief propagation to infer node labels. Now, we introduce the details of our approach.

4.1 LEARNING

The learning task aims at training θ to maximize the log-likelihood function log pθ(yV[∗]
for each training graph (yV[∗] _[,][ x][V][, E][)][, which is highly challenging. Therefore, instead of directly][|][x][V][, E][)]_
optimizing this goal, we solve an approximate version of the problem as a proxy, which is training a
node GNN and an edge GNN to maximize the log-likelihood of observed labels on nodes and edges.


-----

**The Proxy Problem. The proxy problem is inspired by Wainwright & Jordan (2008), which points**
out that the marginal label distributions on nodes and edges defined by a Markov network have
inherent connections with the joint distribution. This connection is stated in the proposition below.

**Proposition 1 Consider a set of nonzero pseudomarginals** _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (st) _E_
_{_ _}_ _∈_ _{_ _}_ _∈_
_which satisfy_ _ys_ _[τ][st][(][y][s][, y][t][) =][ τ][t][(][y][t][)][ and][ P]yt_ _[τ][st][(][y][s][, y][t][) =][ τ][s][(][y][s][)][ for all][ (][s, t][)][ ∈]_ _[E][.]_

_If we parameterize the θ-functions of pθ in Eq. (2) in the following way:_

[P]

_θs(ys) = log τs(ys)_ _s_ _V,_ _θst(ys, yt) = log_ _[τ][st][(][y][s][, y][t][)]_ (s, t) _E,_ (5)
_∀_ _∈_ _τs(ys)τt(yt)_ _∀_ _∈_

_then_ _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E are specified by a fixed point of the sum-product loopy_
_{_ _}_ _∈_ _{_ _}_ _∈_
_belief propagation algorithm when applied to the joint distribution pθ, which implies that:_

_τs(ys)_ _pθ(ys)_ _s_ _V,_ _τst(ys, yt)_ _pθ(ys, yt)_ (s, t) _E._ (6)
_≈_ _∀_ _∈_ _≈_ _∀_ _∈_

The proof is provided in Sec. C. With the proposition, we observe that if we parameterize the θfunctions by combining a set of pseudomarginals _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E in the way_
_{_ _}_ _∈_ _{_ _}_ _∈_
defined by Eq. (5), then those pseudomarginals can well approximate the true marginals of the joint
distribution pθ, i.e., τs(ys) _pθ(ys) and τst(ys, yt)_ _pθ(ys, yt) for all nodes s and edges (s, t)._
_≈_ _≈_
Given this precondition, if we further havethen the moment-matching conditions in Eq. (4) for the optimal τs(ys) ≈ Iys∗ _[{][y][s][}][ and] θ[ τ]-functions are roughly satisfied.[st][(][y][s][, y][t][)][ ≈]_ [I][(][y]s[∗][,y]t[∗][)][{][(][y][s][, y][t][)][}][,]
This implies the joint distribution pθ(yV |xV, E) derived in this way is a near-optimal one.

With the observation, rather than directly using GNNs to parameterize the θ-functions, we use a node
GNN and an edge GNN to parameterize the pseudomarginals _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E._
_{_ _}_ _∈_ _{_ _}_ _∈_
For the pseudomarginal τs(ys) on node s, we apply the node GNN to node features xV and edges E,
yielding a representation us for node s. Then we apply a softmax classifier to us to compute τs(ys):

**us** _u_ _V = GNNnode(xV, E),_ _τs(ys) = softmax(f_ (us))[ys], (7)
_{_ _}_ _∈_

where f maps a node representation to a |Y|-dimensional logit and Y is the node label set. Similarly,
we apply the edge GNN to compute a representation vs for each node s, and model τst(ys, yt) as:

**vs** _s_ _V = GNNedge(xV, E)_ _τst(ys, yt) = softmax(g(vs, vt))[ys, yt],_ (8)
_{_ _}_ _∈_

where g is a function mapping a pair of representations to a (|Y| × |Y|)-dimensional logit.

Given the parameterization, we construct the following problem as a proxy for learning θ-functions:


minτ,θ _d_ Iys[∗] + _d_ I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][, τ][st][(][y][s][, y][t][)]

_sX∈V_   _[{][y][s][}][, τ][s][(][y][s][)]_ (s,tX)∈E  

subject to _θs = log τs(ys),_ _θst(ys, yt) = log_ _[τ][st][(][y][s][, y][t][)]_

_τs(ys)τt(yt)_ _[,]_


_d_ Iys[∗]
_sX∈V_   _[{][y][s][}][, τ][s][(][y][s][)]_


min
_τ,θ_


(9)


and


_τst(ys, yt) = τt(yt),_
_ys_

X


_τst(ys, yt) = τs(ys),_
_yt_

X


for all nodes and edges, where d can be any divergence measure between two distributions. By solving
the above problem, _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E will be valid pseudomarginals which can_
_{_ _}_ _∈_ _{_ _}_ _∈_
well approximate the true labels, i.e.,according to the constraint in the second line of Eq. (9), τs(ys) ≈ Iys[∗] _[{][y][s][}][ and] θ-functions are formed in a way to enable[ τ][st][(][y][s][, y][t][)][ ≈]_ [I][(][y]s[∗][,y]t[∗][)][{][(][y][s][, y][t][)][}][. Then]
_τs(ys)_ _pθ(ys) and τst(ys, yt)_ _pθ(ys, yt) as stated in the Prop. 1. Combining these two sets of_
_≈_ _≈_
formula results in pθ(ys) Iys∗ _s_
conditions in Eq. (4) for the optimal joint label distribution are roughly achieved, implying that the ≈ _[{][y][s][}][ and][ p][θ][(][y][s][, y][t][)][ ≈]_ [I][y][∗] _[{][y][s][}][. We see that the moment-matching]_
derived joint distribution pθ(yV |xV, E) is a near-optimal solution to the original learning problem.

One good property of the proxy problem is that it can be solved easily. The last consistency constraint
(i.e. _ys_ _[τ][st][(][y][s][, y][t][) =][ τ][t][(][y][t][)][ and][ P]yt_ _[τ][st][(][y][s][, y][t][) =][ τ][s][(][y][s][)][) can be ignored during optimization,]_

since by optimizing the objective function, the optimal pseudomarginals τ should well approximate
the observed node and edge marginals, i.e.,[P] _τs(ys)_ Iys∗ _s_ _[,y]t[∗][)][{][(][y][s][, y][t][)][}][,]_
and hence τ will almost naturally satisfy the consistency constraint. We also tried some constrained ≈ _[{][y][s][}][ and][ τ][st][(][y][s][, y][t][)][ ≈]_ [I][(][y][∗]


-----

optimization methods to handle the consistency constraint, but they yield no improvement. See Sec. D
of appendix for more details. Thus, we can simply train the pseudomarginals parameterized by GNNs
to approximate the true node and edge labels on training graphs, i.e., minimizing d(Iys∗
and d(I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][, τ][st][(][y][s][, y][t][))][. Then we build][ θ][-functions as in Eq. (5) to obtain a near-optimal][{][y][s][}][, τ][s][(][y][s][))]
joint distribution. In practice, we choose d to be the KL divergence, yielding an objective for τ as:

maxτ log τs(ys[∗][) +] log τst(ys[∗][, y]t[∗][)][.] (10)

_sX∈V_ (s,tX)∈E

This objective function is very intuitive, where we simply try to optimize the node GNN and edge
GNN to maximize the log-likelihood function of the observed labels on nodes and edges.

**Refinement. By solving the proxy problem, we can obtain a near-optimal joint distribution. In**
practice, we observe that when we have a large amount of training data, further refining this joint
distribution by solving the maximin game in Eq. (3) for a few iterations can lead to further improvement. Formally, each iteration of refinement has two steps. In the first step, we run sum-product
loopy belief propagation (Murphy et al., 1999), which yields a collection of node and edge marginals
(i.e., _qs(ys)_ _s_ _V and_ _qst(ys, yt)_ (s,t) _E) as approximation to the marginals defined by pθ. In the_
_{_ _}_ _∈_ _{_ _}_ _∈_
second step, we update the θ-functions parameterized by the node and edge GNNs to maximize:

_θs(ys[∗][)][ −]_ [E]qs(ys)[[][θ][s][(][y][s][)]] + _θst(ys[∗][, y]t[∗][)][ −]_ [E]qst(ys,yt)[[][θ][st][(][y][s][, y][t][)]] _._ (11)

_sX∈V_  (s,tX)∈E 

Intuitively, we treat the true label ys[∗] [and][ (][y]s[∗][, y]t[∗][)][ of each node and edge as positive examples, and]
encourage the θ-functions to raise up their scores. Meanwhile, those labels sampled from qs(ys) and
_qst(ys, yt) act as negative examples, and the θ-functions are updated to decrease their scores._

4.2 INFERENCE


After learning, we apply the node and edge GNNs to each test graph (x ˜V _[,][ ˜]E) to compute the θ-_
functions, which are integrated into an approximate joint label distribution pθ(y ˜V _[|][x][ ˜]V_ _[,][ ˜]E). Then we_
use this distribution to infer the best label ys[∗]˜ [for each node][ ˜]s ∈ _V[˜], where two settings are considered._

**Node-level Accuracy. Typically, we care about the node-level accuracy, i.e., how likely we can**
correctly classify a node in test graphs. Intuitively, the best label ys˜[∗] [for each test node][ ˜]s ∈ _V[˜] should_
be predicted as ys˜[∗] [= arg max][y]s˜ _[p][θ][(][y]s[˜][|][x]V˜_ _[,][ ˜]E), where pθ(ys˜[|][x]V˜_ _[,][ ˜]E) is the marginal label distribution_
of nodeapply loopy belief propagation (Murphy et al., 1999) for approximate inference. For each edge ˜s induced by the joint pθ(y ˜V _[|][x][ ˜]V_ _[,][ ˜]E). In practice, the exact marginal is intractable, so we (˜s,_ _t[˜])_
in test graphs, we introduce a message function mt˜→s˜[(][y]s[˜][)][ and iteratively update all messages as:]

_mt˜_ _s˜[(][y]s[˜][)][ ∝]_ exp(θt˜[(][y]t[˜][) +][ θ]s˜t[˜][(][y]s[˜][, y]t˜[))] _ms˜[′]_ _t[(][y]t[˜][)][}][,]_
_→_ _{_ _→[˜]_ (12)
Xyt˜ _s˜[′]∈YN_ (t[˜])\s˜

where N (˜s) denotes the set of neighboring nodes for node ˜s. Once the above process converges or
after sufficient iterations, the label of each node ˜s can be inferred in the following way:


_ys˜[∗]_ [= arg max]ys˜ [[exp(][θ]s[˜][(][y]s˜[))]


_mt˜→s˜[(][y]s[˜][)]][.]_ (13)
_t˜∈YN_ (˜s)


**Graph-level Accuracy. In some other cases, we might care about the graph-level accuracy, i.e., how**
likely we can correctly classify all nodes in a given test graph. In this case, the best prediction of node
labels is given by yV[∗]˜ [= arg max][y][ ˜]V _[p][(][y][ ˜]V_ _V_ _[,][ ˜]E). This problem can be approximately solved by the_
max-product variant of loopy belief propagation, which simply replaces the sum over[|][x][ ˜] _yt˜_ [in Eq. (12)]
with max (Weiss & Freeman, 2001). Afterwards, the best node label can be still decoded via Eq. (13).

4.3 DISCUSSION

In practice, many structured prediction problems can be viewed as special cases of inductive node
classification, where the graphs between nodes have some special structures. For example in sequence
labeling tasks (e.g., named entity recognition), the graphs between nodes have sequential structures.
Thus, SPN can be applied to these tasks as well. In order for better results, one might replace GNNs
with other neural models which are specifically designed for the studied task to better estimate the
pseudomarginals. For example in sequence labeling tasks, recurrent neural networks can be used.


-----

5 EXPERIMENT

5.1 DATASETS

We consider datasets in two settings, which focus on node-level and graph-level accuracy respectively.

**Node-level Accuracy. The node-level accuracy measures how likely a model can predict the correct**
_label of a node in test graphs. We use the PPI dataset (Zitnik & Leskovec, 2017; Hamilton et al.,_
2017), which has 20 training graphs. To make the dataset more challenging, we also try using only
the first 1/2/10 training graphs, yielding another three datasets PPI-1, PPI-2, and PPI-10. Besides,
we also build a DBLP dataset from the citation network in Tang et al. (2008). Papers from eight
conferences are treated as nodes, and we split them into three categories for classification according
to conference domains [2]. For each paper, we compute the mean GloVe embedding (Pennington et al.,
2014) of words in the title and abstract as node features. The training/validation/test graph is formed
as the citation graph of papers published before 1999, from 2000 to 2009, after 2010 respectively.

**Graph-level Accuracy. The graph-level accuracy measures how likely a model can correctly classify**
_all the nodes for a given test graph. We construct three datasets from the Cora, Citeseer, and Pubmed_
datasets used for transductive node classification (Yang et al., 2016). Each raw dataset has a single
graph. For each training/validation/test node of the raw dataset, we treat its ego network [3] as a
training/validation/test graph. We denote the datasets as Cora*, Citeseer*, Pubmed*.

5.2 COMPARED ALGORITHMS

**Graph Neural Networks. For GNNs, we choose a few well-known model architectures for compar-**
ison, including GCN (Kipf & Welling, 2017), GraphSage (Hamilton et al., 2017), GAT (Velickoviˇ c´
et al., 2018), Graph U-Net (Gao & Ji, 2019) and GCNII (Chen et al., 2020a).

**Conditional Random Fields. For CRFs, we consider three variants. (1) CRF-linear. This variant**
uses linear θ-functions in Eq. (2), which takes the features on nodes and edges for computation. (2)
_CRF-GNN. This variant parameterizes the θ-functions as θs(ys) = f_ (us) and θst(ys, yt) = g(vs, vt),
with f and g defined in Eq. (7) and Eq. (8), where the node representations are generated by different
GNN architectures (e.g., CRF-GAT). We train these models via the maximin game as in Eq. (3) with
sum-product loopy belief propagation. (3) GMNN. We also consider GMNN (Qu et al., 2019), an
approach combining GNNs and CRFs, which optimizes the pseudolikelihood function for learning.

**Our Approach. For SPNs, we try different GNN architectures for defining the node and edge GNNs**
(e.g., SPN-GAT). By default, we only solve the proxy problem without performing refinement. We
systematically compare the results with and without refinement in part 2 of Sec. 5.5.

5.3 EVALUATION METRICS

On Cora*, Citeseer*, and Pubmed*, we report the percentage of test graphs where all the nodes are
correctly classified (i.e., graph-level accuracy). On DBLP and PPI, we report accuracy and micro-F1
based on the percentage of test nodes which are correctly classified (i.e., node-level accuracy). For
Cora*, Citeseer*, and Pubmed*, we run each compared method with 10 different seeds to report the
mean accuracy and the standard deviation. For DBLP and PPI, we run each method with 5 seeds.

5.4 EXPERIMENTAL SETUP

For GNNs, by default we use the same architectures (e.g., number of neurons, number of layers) as
used in the original papers. Adam (Kingma & Ba, 2015) is used for training. For the edge GNN
in Eq. (8), we add a hyperparameter γ to control the annealing temperature of the logit g(vs, vt)
before the softmax function during belief propagation. Empirically, we find that max-product belief
propagation works better than the sum-product variant in most cases, so we use the max-product
version by default. By default, we do not run refinement when training SPNs. See Sec. F for details.

2ML: ICML/NeurIPS. CV: ICCV/CVPR/ECCV. NLP: ACL/EMNLP/NAACL.
3The local subgraph formed by a node and its direct neighbors.


-----

Table 1: Result on PPI datasets (in %). SPNs get consistent improvement on GNNs and CRFs.

**PPI-1** **PPI-2** **PPI-10** **PPI**
**Algorithm**
Accuracy Micro-F1 Accuracy Micro-F1 Accuracy Micro-F1 Accuracy Micro-F1

CRF-GraphSAGESPN-GraphSAGEGraph U-NetGraphSAGECRF-GCNIISPN-GCNIICRF-linearCRF-GCNSPN-GCNCRF-GATSPN-GATGMNNGCNIIGCNGAT 81.0279.9882.0177.4977.1765.3376.3377.0782.1180.9979.0176.6277.4377.5576.50 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.07 0.07 0.53 0.20 0.49 0.32 0.17 0.03 0.10 0.07 2.77 0.21 0.28 0.05 0.03 65.7955.5457.2060.7252.9561.2264.0267.8067.3050.7954.5754.5548.3054.1568.56 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.25 0.33 1.10 2.63 0.11 0.25 0.40 0.40 0.29 0.11 0.35 0.74 1.07 0.17 0.07 84.8178.2281.7381.2181.3576.7683.5577.4884.1367.2076.2777.2578.0285.4085.83 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.06 0.04 0.33 0.87 0.04 0.04 0.19 0.10 0.36 0.61 0.05 0.12 0.12 2.24 0.05 74.5459.1267.4668.5555.0166.3772.3756.1072.9349.4549.4753.4855.7374.4575.96 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.14 0.30 0.56 2.92 0.05 0.04 0.30 0.63 1.00 0.93 0.07 0.18 0.36 0.97 0.15 97.5383.1592.1194.6796.1495.3477.0877.6574.5895.2896.6880.4369.7280.5997.55 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.04 0.01 2.77 0.15 0.92 0.28 0.13 0.01 0.10 0.03 0.65 0.07 0.38 0.04 0.02 68.7095.8690.7293.5354.9887.1094.4162.4892.1850.1752.3654.4461.3691.9995.87 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.08 0.01 5.28 0.24 1.13 0.40 0.21 0.02 0.27 0.05 0.39 0.72 1.34 0.11 0.04 86.2999.3997.0098.8570.4296.9499.0482.2898.5169.9877.3477.2182.5698.5599.41 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.04 0.00 2.98 0.05 0.72 0.12 0.06 0.00 0.24 0.02 0.30 0.07 0.19 0.20 0.02 75.5798.9794.6998.0653.2794.9598.3866.5297.5150.6153.6054.5066.7097.5699.02 ± ± ± ± ± ± ± ± ± ± ± ± ± ± ± 0.18 0.00 5.60 0.08 0.42 0.19 0.10 0.00 0.89 0.03 0.35 0.36 3.09 0.77 0.03


Table 2: Accuracy on Cora*, Citeseer*, Pubmed*, DBLP (in %). SPNs achieve the best result.


**Algorithm** **Cora*** **Citeseer*** **Pubmed*** **DBLP**

Graph U-NetGraphSAGEGCNIIGCNGAT 49.0251.9956.0759.1557.26 ± ± ± ± ± 0.66 0.57 2.37 3.51 0.67 46.2441.3247.9445.9146.39 ± ± ± ± ± 0.61 1.65 2.41 0.46 0.92 51.8448.6150.8951.7753.54 ± ± ± ± ± 0.45 0.97 1.28 0.52 0.98 76.6075.2173.8179.1681.79 ± ± ± ± ± 2.32 0.90 1.44 2.68 0.88

CRF-GCNIICRF-linearCRF-UNetCRF-GATGMNN 36.1842.7849.1054.3053.49 ± ± ± ± ± 3.94 3.80 2.47 5.75 1.15 40.6042.8943.6638.2748.46 ± ± ± ± ± 0.81 1.30 2.12 4.82 1.06 43.9047.7950.0241.7151.70 ± ± ± ± ± 2.91 1.33 0.88 4.79 1.23 54.2659.1457.4660.5576.54 ± ± ± ± ± 1.27 4.15 3.07 2.23 2.93

SPN-GCNIISPN-UNetSPN-GAT **60.4758.0358.78 ± ± ± 1.21 0.54 0.49** 46.9748.3449.02 ± ± ± 0.78 1.06 0.50 52.9153.3654.35 ± ± ± 0.54 0.67 0.64 80.1183.5784.84 ± ± ± 0.73 1.59 1.33

5.5 RESULTS

**1. Comparison with other methods. The main results in the two settings are presented in Tab. 1 and**
Tab. 2. Compared against different GNN models, our approach achieves consistent improvement (the
relative underperformance of SPN-GCN and SPN-SAGE is related to the capacity of the backbone
GNNs and is explained in Sec. G.1) by using these GNNs as backbone networks for approximating
marginal label distributions on nodes and edges, which demonstrates SPNs are able to model the
structured output of node labels by combining with CRFs, and thus achieve better results.

Besides, SPNs also achieve superior results to CRF-GNNs which are trained by directly solving the
maximin game in Eq. (3), as well as GMNN which optimizes the pseudolikelihood function. This
observation proves the advantage of our proposed proxy optimization problem for learning CRFs.


Table 3: Run time comparison (in sec).

**Algorithm** **DBLP** **PPI**

GAT 23.15 460.81
CRF (GAT) 500.43 27136.90
SPN(GAT) 46.86 962.92


Table 4: Micro-F1 with and w/o refinement (in %).

**Algorithm** **Refine** **PPI-2** **PPI-10** **PPI**

GraphSAGESPN-SPN-GAT withwithw/ow/o 73.6871.5271.5873.93 ± ± ± ± 0.21 0.20 0.08 0.10 94.4191.9994.6392.49 ± ± ± ± 0.21 0.20 0.04 0.02 98.3897.5698.6897.77 ± ± ± ± 0.10 0.09 0.03 0.02


**2. Effect of refinement. By solving the proxy optimization problem in Eq. (9), we can obtain a**
near-optimal joint label distribution on training graphs, based on which we may optionally refine the
distribution with the maximin game in Eq. (3). Next, we study the effect of refinement, and we present
the results in Tab. 4. By only solving the proxy problem, our approach already achieves impressive
results, showing that the proxy problem can well approximate the original learning problem. Only on
datasets with sufficient labeled data (e.g., PPI-10, PPI), refinement leads to some improvement.

**3. Model architecture. SPN uses a node GNN and an edge GNN for computing node and edge**
marginals independently. In practice, we can also use a shared GNN for both node and edge marginals.
We show results of this variant in Tab. 6, where it also achieves significant improvement over GNNs.

**4. Efficiency comparison. We have seen SPNs achieve better classification results than GNNs and**
CRFs. Next, we further compare their efficiency by showing the run time on DBLP and PPI. For PPI,


-----

Table 5: Comparison of learning methods (in %).

**Algorithm** **Cora*** **Citeseer*** **PPI-10**

Maximin Game 49.10 ± 3.80 42.89 ± 1.30 54.98 ± 1.13

Pseudolikelihood 54.30 ± 1.15 48.46 ± 1.06 90.72 ± 5.28

Proxy Problem **58.78 ± 1.21** **49.02 ± 0.78** **95.87 ± 0.02**


Table 6: Micro-F1 of model variants (in %).

**Algorithm** **PPI-1** **PPI-2** **PPI-10**

GAT 60.72 ± 0.25 68.55 ± 0.30 93.53 ± 0.24

SPN-GAT
**64.02** 0.40 **72.37** 0.18 94.41 0.21
node and edge GNNs _±_ _±_ _±_

SPN-GAT
63.72 0.38 70.99 0.25 **95.19** 0.15
a shared GNN _±_ _±_ _±_


which has 121 labels, we only report the training times on a single label. We use GAT as the backbone
network for CRFs and SPNs. GAT and CRF are trained for 1000 epochs to ensure convergence. For
the SPN, we train the node GNN and edge GNN for node/edge classification as in Eq. (10) with 1000
epochs. The run times are presented in Tab. 3. SPNs take twice as long for training than GAT, as a
SPN needs to train a node GNN and an edge GNN. Compared with CRFs, we can see that SPNs are
much more efficient, because the proxy optimization problem in SPNs is much easier to solve.


90

80

70

60

Accuracy (%)

50 CRF

40 SPN w/o proxy

SPN

30 0 100 200 300 400 500

Epoch

(a) DBLP training.


90

80

70

60

Accuracy (%)50

40 CRF

SPN w/o proxy

30 SPN

0 100 200 300 400 500

Epoch

(b) DBLP validation.


(a) GAT. (b) Edge GNN. (c) SPN-GAT.

(same as ground truth)


Figure 2: Convergence curves for solving the
maximin game in Eq. (3) during model learning.


Figure 3: Case study. SPN correctly predicts all
node labels than GAT and the edge GNN.


**5. Comparison of learning methods. Next, we investigate different methods for learning SPNs,**
including directly solving the maximin game, optimizing pseudolikelihood, and solving our proposed
proxy problem. We show the results for optimizing SPN-GAT in Tab. 5. We see solving maximin
game yields poor results due to unstable training. Although the pseudolikelihood method performs
much better, the result is still unsatisfactory as it is not a good approximation of the true likelihood.
By solving our proposed proxy problem, SPN achieves the best result, which proves its effectiveness.

**6. Convergence analysis. To better illustrate the advantage of the proxy problem for learning CRFs,**
we look into the training curves of SPNs, SPNs w/o proxy, and CRFs when optimizing the maximin
game in Eq. (3). For SPNs, we optimize the node and edge GNNs on the proxy optimization problem
in Eq. (9) before doing refinement with the maximin game, while for SPNs w/o proxy we directly
perform refinement with the maximin game without solving the proxy problem. We show the results
in Fig. 2. CRFs and SPNs w/o proxy suffer from high variance and low accuracy. In contrast, owing
to the near-optimal joint distribution found by solving the proxy problem, SPNs get much higher
accuracy with lower variance even without refinement (see initial results of SPNs at epoch 0). Also,
the refinement process quickly converges after only a few epochs, showing good efficiency of SPNs.

**7. Case study. To intuitively see how SPNs outperform GNNs, we conduct some case studies on**
Cora*. We use GAT as backbone networks, and show the prediction made by the GAT (the node
GNN), the edge GNN, and SPN in Fig. 3. In all three cases shown in the figure, GAT (left column)
makes inconsistent predictions on linked nodes, as it fails to model the structured output. The edge
GNN (middle column) also makes a mistake in the bottom case. Finally, by combining GAT and
edge GNN with a CRF, the SPN (right column) is able to predict the correct labels for all nodes.

6 CONCLUSION

This paper studied inductive node classification, and we proposed SPN to combine GNNs and
CRFs. Inspired by the connection of joint and marginal distributions defined by Markov networks, we
designed a proxy problem for efficient model learning. In the future, we plan to explore more advanced
GNNs to model the pseudomarginals on edges, which are key to improving node classification results
in SPNs. In addition, SPNs model joint dependency of node labels by defining potential functions on
nodes and edges, and we also plan to further explore high-order local structures, e.g., triangles.


-----

REFERENCES

Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint, 2016.

Gokhan BakIr, Thomas Hofmann, Bernhard Sch¨ olkopf, Alexander J Smola, and Ben Taskar.¨ _Predict-_
_ing structured data. MIT press, 2007._

Julian Besag. Statistical analysis of non-lattice data. The statistician, pp. 179–195, 1975.

Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li. Simple and deep graph
convolutional networks. In ICML, 2020a.

Xinshi Chen, Yufei Zhang, Christoph Reisinger, and Le Song. Understanding deep architecture with
reasoning layer. NeurIPS, 2020b.

Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster-gcn: An
efficient algorithm for training deep and large graph convolutional networks. In KDD, 2019.

Kenneth Ward Church. A stochastic parts program and noun phrase parser for unrestricted text. In
_ANLC, 1988._

Djork-Arne Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network´
learning by exponential linear units (elus). In ICLR, 2016.

Hanjun Dai, Bo Dai, and Le Song. Discriminative embeddings of latent variable models for structured
data. In ICML, 2016.

Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In
_ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019._

Thomas Finley and Thorsten Joachims. Training structural svms when exact inference is intractable.
In ICML, 2008.

Hongyang Gao and Shuiwang Ji. Graph u-nets. In Proceedings of the 36th International Conference
_on Machine Learning, 2019._

Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. Large-scale learnable graph convolutional
networks. In KDD, 2018.

Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
message passing for quantum chemistry. In ICML, 2017.

Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In
_NeurIPS, 2017._

Xuming He, Richard S Zemel, and Miguel A Carreira-Perpi[´] n˜an. Multiscale conditional random fields´
for image labeling. In CVPR, 2004.

Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.

Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.
In ICLR, 2017.

Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT
press, 2009.

John Lafferty, Andrew McCallum, and Fernando CN Pereira. Conditional random fields: Probabilistic
models for segmenting and labeling sequence data. In ICML, 2001.

Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer.
Neural architectures for named entity recognition. In NAACL-HLT, 2016.

Guohao Li, Matthias Muller, Ali Thabet, and Bernard Ghanem. Deepgcns: Can gcns go as deep as
cnns? In ICCV, 2019.


-----

Liyuan Liu, Jingbo Shang, Xiang Ren, Frank Xu, Huan Gui, Jian Peng, and Jiawei Han. Empower
sequence labeling with task-aware neural language model. In AAAI, 2018.

Jiaqi Ma, Weijing Tang, Ji Zhu, and Qiaozhu Mei. A flexible generative framework for graph-based
semi-supervised learning. In NeurIPS, 2019.

Jiaqi Ma, Bo Chang, Xuefei Zhang, and Qiaozhu Mei. Copulagnn: Towards integrating representational and correlational roles of graphs in graph neural networks. In ICLR, 2021.

Tengfei Ma, Cao Xiao, Junyuan Shang, and Jimeng Sun. Cgnf: Conditional graph neural fields. ICLR
_Submission, 2018._

Xuezhe Ma and Eduard Hovy. End-to-end sequence labeling via bi-directional lstm-cnns-crf. In ACL,
2016.

Kevin P Murphy, Yair Weiss, and Michael I Jordan. Loopy belief propagation for approximate
inference: An empirical study. In UAI, 1999.

Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In
_ICML, 2010._

Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word
representation. In EMNLP, 2014.

Meng Qu, Yoshua Bengio, and Jian Tang. Gmnn: Graph markov neural networks. In ICML, 2019.

Erik F Sang and Fien De Meulder. Introduction to the conll-2003 shared task: Language-independent
named entity recognition. arXiv preprint cs/0306050, 2003.

Sunita Sarawagi and Rahul Gupta. Accurate max-margin training for structured output spaces. In
_ICML, 2008._

Victor Garcia Satorras and Max Welling. Neural enhanced belief propagation on factor graphs. arXiv
_preprint, 2020._

Victor Garcia Satorras, Zeynep Akata, and Max Welling. Combining generative and discriminative
models for hybrid inference. arXiv preprint, 2019.

Fei Sha and Fernando Pereira. Shallow parsing with conditional random fields. In HLT-NAACL,
2003.

Charles Sutton and Andrew McCallum. An introduction to conditional random fields for relational
learning. Introduction to statistical relational learning, 2006.

Charles Sutton and Andrew McCallum. Piecewise training for structured prediction. Machine
_learning, 2009._

Charles Sutton and Andrew McCallum. An Introduction to Conditional Random Fields. Now
Publishers Inc, 2012.

Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. Arnetminer: extraction and
mining of academic social networks. In KDD, 2008.

Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. Large margin
methods for structured and interdependent output variables. JMLR, 2005.

Petar Velickoviˇ c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li´ o, and Yoshua`
Bengio. Graph attention networks. In ICLR, 2018.

Martin J Wainwright and Michael Irwin Jordan. Graphical models, exponential families, and
_variational inference. Now Publishers Inc, 2008._

Martin J Wainwright, Tommi S Jaakkola, and Alan S Willsky. Tree-reweighted belief propagation
algorithms and approximate ml estimation by pseudo-moment matching. In AISTATS, 2003.


-----

Binghui Wang, Jinyuan Jia, and Neil Zhenqiang Gong. Semi-supervised node classification on graphs:
Markov random fields vs. graph neural networks. In AAAI, 2021.

Yair Weiss and William T Freeman. On the optimality of solutions of the max-product beliefpropagation algorithm in arbitrary graphs. IEEE Transactions on Information Theory, 2001.

Louis-Pascal Xhonneux, Meng Qu, and Jian Tang. Continuous graph neural networks. In ICML,
2020.

Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with
graph embeddings. In ICML, 2016.

Jonathan S Yedidia, William T Freeman, and Yair Weiss. Constructing free-energy approximations
and generalized belief propagation algorithms. IEEE Transactions on information theory, 2005.

Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. Graphsaint: Graph sampling based inductive learning method. In ICLR, 2020.

Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi, and Le Song. Efficient
probabilistic logic reasoning with graph neural networks. In ICLR, 2020.

Marinka Zitnik and Jure Leskovec. Predicting multicellular function through multi-layer tissue
networks. In ISMB, 2017.


-----

A DERIVATION OF THE MAXIMIN GAME

As discussed in the Sec. 3, optimizing the joint label distribution pθ to maximize the log-likelihood
logsection, we provide the detailed derivation. pθ(yV[∗] _[|][x][V][, E][)][ on a training graph][ (][y]V[∗]_ _[,][ x][V][, E][)][ is equivalent to solving a maximin game. In this]_

Let ψθ(yV, xV, E) be the potential function as below:

_ψθ(yV, xV, E) = exp_ _θs(ys, xV, E) +_ _θst(ys, yt, xV, E)_ (14)

 

_s_ _V_ (s,t) _E_

X∈ X∈ 

For each training graph (yV[∗] _[,][ x][V][, E][)][, we aim at maximizing the following log-likelihood function:]_ _[.]_


1
log pθ(yV[∗] _[, E][) = log]_ _V_ _[,][ x][V]_ _[, E][)]_

_[|][x][V]_ _Zθ(xV, E)_ _[ψ][θ][(][y][∗]_

= log ψθ(yV[∗] _[,][ x][V]_ _[, E][)][ −]_ [log][ Z][θ][(][x][V] _[, E][)]_

= log ψθ(yV[∗] _[,][ x][V]_ _[, E][)][ −]_ [log] _ψθ(yV, xV, E)._

**yV**

X


(15)


However, the term log **yV** _[ψ][θ][(][y][V][,][ x][V][, E][)][ is computationally intractable, as we need to sum over]_

all the possible yV . To solve the problem, we introduce a variational joint distribution q(yV )
defined on all node labels[P] **yV, and use the Jensen’s inequality to derive an estimation of the term**
log **yV** _[ψ][θ][(][y][V][,][ x][V][, E][)][ as follows:]_

_ψθ(yV, xV, E)_

[P] log **yV** _ψθ(yV, xV, E) = log Eq(yV )_  _q(yV )_ 

X

(16)

_≥_ Eq(yV ) log _[ψ][θ][(][y]q[V]([,]y[ x]V )[V][, E][)]_

 

= Eq(yV )[log ψθ(yV, xV, E)] Eq(yV )[log q(yV )].
_−_

The equation holds if and only if q(yV ) = pθ(yV |xV, E), and hence:


Eq(yV )[log ψθ(yV, xV, E)] − Eq(yV )[log q(yV )] _._ (17)


log


_ψθ(yV, xV, E) = max_
_q(yV )_
**yV**

X


By taking the above result into Eq. (15), we obtain:

log pθ(yV[∗] _[, E][) = log][ ψ][θ][(][y]V[∗]_ _[,][ x][V]_ _[, E][)][ −]_ [log] _ψθ(yV, xV, E)_

_[|][x][V]_ XyV (18)

= min log ψθ(yV[∗] _[,][ x][V]_ _[, E][)][ −]_ [E]q(yV )[[log][ ψ][θ][(][y][V] _[,][ x][V]_ _[, E][)] +][ E]q(yV )[[log][ q][(][y][V]_ [)]] _._
_q(yV )_




As ψθ(yV, xV, E) = exp{[P]s∈V _[θ][s][(][y][s][,][ x][V][, E][) +][ P](s,t)∈E_ _[θ][st][(][y][s][, y][t][,][ x][V][, E][)][}][, we have:]_

log pθ(yV[∗] _[|][x][V]_ _[, E][) = min]q_ _L(θ, q),_ (19)

with:


_L(θ, q) = −H[q(yV )]_

+ _{θst(ys[∗][, y]t[∗][)][ −]_ [E]qst(ys,yt)[[][θ][st][(][y][s][, y][t][)]][}][ +]

(s,tX)∈E


_{θs(ys[∗][)][ −]_ [E]qs(ys)[[][θ][s][(][y][s][)]][}][.] (20)
_sX∈V_


Therefore, optimizing θ to maximize the log-likelihood function is equivalent to solving the following
maximin game:
maxθ log pθ(yV[∗] _[|][x][V]_ _[, E][) = max]θ_ minq _L(θ, q)._ (21)


-----

B DERIVATION OF THE MOMENT-MATCHING CONDITIONS

In the CRF model defined in the preliminary section, the parameter θ consists of the output values
of all θ-functions. In other words, θ = _θs(ys)_ _ys_ _,s_ _V_ _θst(ys, yt)_ _ys_ _,yt_ _,s_ _V, where_ is
the set of all the possible node labels. _{_ _}_ _∈Y_ _∈_ _∪{_ _}_ _∈Y_ _∈Y_ _∈_ _Y_

By definition,nential family distributions, pθ(yV |xV, E log) belongs to the exponential family. According to properties of expo- pθ(yV[∗]
optimal θ is unique, which is characterized by the condition of[|][x][V][, E][)][ is strictly concave with respect to]∂θ∂ [log][ p][θ][(][y]V[∗] _[ θ][. Therefore, the]_

_∂_ _[|][x][V][, E][) = 0][. Formally,]_

_∂θ_ [log][ p][θ][(][y]V[∗] _[|][x][V][, E][)][ can be computed as below:]_
_∂_

_V_ _[, E][) =][ ∂]_ _V_ _[,][ x][V]_ _[, E][)][ −]_ _[∂]_ (22)
_∂θs(ˆys) [log][ p][θ][(][y][∗]_ _[|][x][V]_ _∂θ_ [log][ ψ][θ][(][y][∗] _∂θ_ [log][ Z][θ][(][x][V][, E][)][.]


For


_∂_

_∂θ_ [log][ Z][θ][(][x][V][, E][)][, we have:]
_∂_

_∂θ_ [log][ Z][θ][(][x][V][, E][) =][ ∂]∂θ [log]


_ψθ(yV, xV, E)_
**yV**

X


_∂_

_∂θ_ _[ψ][θ][(][y][V][,][ x][V][, E][)]_


**yV**


**yV** _[ψ][θ][(][y][V][,][ x][V][, E][)]_

PyV _[ψ][θ][(][y][V][,][ x][V][, E][)][ ∂]∂θ_ [log][ ψ][θ][(][y][V][,][ x][V][, E][)]

**yV** _[ψ][θ][(][y][V][,][ x][V][, E][)]_

P


(23)


_ψθ(yV, xV, E)_ _∂_

=

**yV** " **yV[′]** _[ψ][θ][(][y]V[′]_ _[,][ x][V][, E][)]_ _∂θ_ [log][ ψ][θ][(][y][V][,][ x][V][, E][)]#

X

_ψPθ(yV, xV, E)_ _∂_

=

_Zθ_ _∂θ_ [log][ ψ][θ][(][y][V][,][ x][V][, E][)]

**yV**  

X

_∂_

= Epθ(yV |xV,E) _∂θ_ [log][ ψ][θ][(][y][V][,][ x][V][, E][)] _._

 

By combining the above two equations, we have:
_∂_ _∂_

_V_ _[, E][) =][ ∂]_ _V_ _[,][ x][V]_ _[, E][)][ −]_ [E]pθ(yV **xV,E)** _. (24)_
_∂θ_ [log][ p][θ][(][y][∗] _[|][x][V]_ _∂θ_ [log][ ψ][θ][(][y][∗] _|_ _∂θ_ [log][ ψ][θ][(][y][V][,][ x][V][, E][)]

 

The potential function ψθ above is defined as ψθ(yV, xV, E) = exp{[P]s∈V _[θ][s][(][y][s][,][ x][V][, E][) +]_

(s,t) _E_ _[θ][st][(][y][s][, y][t][,][ x][V][, E][)][}][. If we consider each specific scalar][ θ][s][(ˆ]ys), and taking the derivative_
_∈_
with respect to the scalar to 0, we obtain:

P


_∂_

_∂θs(ˆys) [log][ p][θ][(][y]V[∗]_ _[|][x][V]_ _[, E][)]_

_∂_

_V_ _[,][ x][V]_ _[, E][)][ −]_ [E]pθ(yV **xV,E)**
_∂θs(ˆys) [log][ ψ][θ][(][y][∗]_ _|_


0 =


_∂θs(ˆys) [log][ ψ][θ][(][y][V][,][ x][V][, E][)]_


(25)


= Iys∗ _ys_

_[{][ˆ]_ _}_


_pθ(yV_ **xV, E)** Iys∗ _ys_
**yV** _|_  _[{][ˆ]_ _}_

X


_ys)_
_∂θs(ˆys)_ _[θ][s][(ˆ]_


_ys)_
_∂θs(ˆys)_ _[θ][s][(ˆ]_


_∂_ _∂_
= Iys∗ _[{]y[ˆ]s}_  _∂θs(ˆys)_ _[θ][s][(ˆ]ys)_ _−_ _pθ(ˆys|xV, E)_  _∂θs(ˆys)_ _[θ][s][(ˆ]ys)_

= Iys∗ _ys_ _pθ(ˆys_ **xV, E),**

_[{][ˆ]_ _} −_ _|_

which implies pθ(ˆys **xV, E) = Iys∗** _ys_ for the optimal θ. Moreover, this equation holds for all
_s_ _V and all ˆys_ _|._ _[{][ˆ]_ _}_
_∈_ _∈Y_

Similarly, for each scalar θst(ˆys, ˆyt), we have that _∂θst(ˆ∂ys,yˆt)_ [log][ p][θ][(][y]V[∗] _[|][x][V][, E][) = 0][ is equivalent]_

(ˆtoys p, ˆθy(ˆty)s, ˆyt|xV, E. ) = Iys∗[,y]t[∗] _[{]y[ˆ]s, ˆyt}. This equation holds for all (s, t) ∈_ _E and all the choices of_
_∈Y × Y_

Therefore, the optimal θ-functions are characterized by the moment-matching conditions as below:
_pθ(ys|xV, E) = Iys∗_ _[{][y][s][} ∀][s][ ∈]_ _[V,]_ _pθ(ys, yt|xV, E) = Iys∗[,y]t[∗]_ _[{][y][s][, y][t][} ∀][(][s, t][)][ ∈]_ _[E.]_ (26)


-----

C PROOF OF PROPOSITION 1

Next, we prove Prop. 1. We first restate the proposition as follows:


**Proposition Consider a set of nonzero pseudomarginals** _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (st) _E which_
_{_ _}_ _∈_ _{_ _}_ _∈_
_satisfy_ _ys_ _[τ][st][(][y][s][, y][t][) =][ τ][t][(][y][t][)][ and][ P]yt_ _[τ][st][(][y][s][, y][t][) =][ τ][s][(][y][s][)][ for all][ (][s, t][)][ ∈]_ _[E][.]_
_If we parameterize the θ-functions of pθ in Eq. (2) in the following way:_

[P]

_θs(ys) = log τs(ys)_ _s_ _V,_ _θst(ys, yt) = log_ _[τ][st][(][y][s][, y][t][)]_ (s, t) _E,_ (27)
_∀_ _∈_ _τs(ys)τt(yt)_ _∀_ _∈_

_then_ _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E are specified by a fixed point of the sum-product loopy_
_{_ _}_ _∈_ _{_ _}_ _∈_
_belief propagation algorithm when applied to the joint distribution pθ, which implies that:_
_τs(ys)_ _pθ(ys)_ _s_ _V,_ _τst(ys, yt)_ _pθ(ys, yt)_ (s, t) _E._ (28)
_≈_ _∀_ _∈_ _≈_ _∀_ _∈_
**Proof: To prove the proposition, we first summarize the workflow of the sum-product loopy belief**
propagation algorithm. In sum-product loopy belief propagation, we introduce a message function
_mt→s(ys) for each edge (s, t) ∈_ _E. Then we iteratively update all message functions as follows:_

_mt→s(ys) ∝_  _ms′→t(yt)_ (29)

_yt_ _s[′]_ _N_ (t) _s_

X  _∈Y_ _\_ 

where N (t) represents the set of neighbors for node t.

[exp(][θ][t][(][y][t][) +][ θ][st][(][y][s][, y][t][))]  _[,]_

Once the process converges or after sufficient iterations, the approximation of the node marginals
and the edge marginals (i.e., _qs(ys)_ _s_ _V and_ _qst(ys, yt)_ (s,t) _E) can be recovered by the message_
_{_ _}_ _∈_ _{_ _}_ _∈_
functions _mt_ _s(ys)_ (s,t) _E as follows:_
_{_ _→_ _}_ _∈_

_qs(ys) ∝_ exp(θs(ys)) _mt→s(ys),_ (30)

_t∈YN_ (s)

_qst(ys, yt) ∝_ exp(θs(ys) + θt(yt) + θst(ys, yt)) _mt′→s(ys)_ _ms′→t(yt)._ (31)

_t[′]∈NY(s)\t_ _s[′]∈YN_ (t)\s

Next, let us move back to our case, where we parameterize the θ-functions with a set of pseudomarginals as in Eq. (27). For such a specific parameterization of the θ-functions, we claim that one
fixed point of Eq. (29) is achieved when mt→s(ys) = 1 for all (s, t) ∈ _E. To prove that, we notice_
that when all the message functions equal to 1, the left side of Eq. (29) is apparently 1. The right side
of Eq. (29) can be computed as below:


exp(θt(yt) + θst(ys, yt))
_yt_

X

exp(θt(yt) + θst(ys, yt))
_yt_

X


_ms′→t(yt)_
_s[′]∈YN_ (t)\s


exp log τt(yt) + log _[τ][st][(][y][s][, y][t][)]_

_τs(ys)τt(yt)_

_yt_ 

X

exp log _[τ][st][(][y][s][, y][t][)]_

_τs(ys)_

_yt_  

X

_τst(ys, yt)_


(32)


_τs(ys)_


_yt_


= _[τ][s][(][y][s][)]_

_τs(ys)_
=1.

We can see that both the left side and the right side of Eq. (29) are 1, and hence {mt→s(ys) =
1 (s,t) _E specifies a fixed point of sum-product loopy belief propagation. For this fixed point, qs(ys)_
_}_ _∈_
can be computed as follows:


_mt→s(ys) = exp(θs(ys)) = τs(ys)._ (33)
_t∈YN_ (s)


_qs(ys)_ exp(θs(ys))
_∝_


-----

Similarly, we can compute qst(ys, yt) as:

_qst(ys, yt) ∝_ exp(θs(ys) + θt(yt) + θst(ys, yt)) _mt′→s(ys)_

_t[′]∈NY(s)\t_

= exp(θs(ys) + θt(yt) + θst(ys, yt))


_ms′→t(yt)_
_s[′]∈YN_ (t)\s


(34)


= exp log τs(ys) + log τt(yt) + log _[τ][st][(][y][s][, y][t][)]_

_τs(ys)τt(yt)_




= τst(ys, yt).

From the above two equations, we can see that _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E are specified_
_{_ _}_ _∈_ _{_ _}_ _∈_
by a fixed point (i.e., mt→s(ys) = 1 for all (s, t) ∈ _E) of sum-product loopy belief propagation._
As sum-product loopy belief propagation often works well in practice to approximate the marginal
distributions on nodes and edges, we thus have τs(ys) _pθ(ys) for each node and τst(ys, yt)_
_≈_ _≈_
_pθ(ys, yt) for each edge._

D SOLVING THE PROXY PROBLEM WITH CONSTRAINED OPTIMIZATION

The key innovation of our proposed approach is on the proxy optimization problem which is used to
approximate the original learning problem. Formally, the proxy optimization problem is stated as:


minτ,θ _d_ Iys∗ + _d_ I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][, τ][st][(][y][s][, y][t][)]

_sX∈V_   _[{][y][s][}][, τ][s][(][y][s][)]_ (s,tX)∈E  

subject to _θs = log τs(ys),_ _θst(ys, yt) = log_ _[τ][st][(][y][s][, y][t][)]_

_τs(ys)τt(yt)_ _[,]_


(35)


and


_τst(ys, yt) = τt(yt),_
_ys_

X


_τst(ys, yt) = τs(ys),_
_yt_

X


for all nodes and edges, where d can be any divergence measure between two distributions.

In our implementation, we ignore these consistency constraints, i.e., _ys_ _[τ][st][(][y][s][, y][t][) =][ τ][t][(][y][t][)][ and]_

_yt_ _[τ][st][(][y][s][, y][t][) =][ τ][s][(][y][s][)][. This ie because by by optimizing the objective, the obtained pseudo-]_
marginals τ would well approximate the observed node and edge marginals, i.e.,[P] _τs(ys)_ Iys∗

Pand τst(ys, yt) ≈ I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][, and hence][ τ][ would almost naturally satisfy the constraints.] ≈ _[{][y][s][}]_

To demonstrate ignoring the consistency constraint makes sense, we also tried a constrained optimization method for solving the proxy problem. Specifically, we add a quadratic term to penalize the
inconsistency between τst(ys, yt) and τs(ys) as well as τt(yt), resulting in the following problem:


minτ,θ _d_ Iys∗ + _d_ I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][, τ][st][(][y][s][, y][t][)]

_sX∈V_   _[{][y][s][}][, τ][s][(][y][s][)]_ (s,tX)∈E   

+ α _τst(ys, yt)_ _τt(yt)_ + _τst(ys, yt)_ _τs(ys)_

_{_ _−_ _}[2]_ _{_ _−_ _}[2]_

(s,tX)∈E "Xyt Xys Xys Xyt

subject to _θs = log τs(ys),_ _θst(ys, yt) = log_ _[τ][st][(][y][s][, y][t][)]_

_τs(ys)τt(yt)_ _[,]_


(36)


for all nodes and edges. Again, d is a divergence measure between two distributions, and we choose
to use the KL divergence. α is a hyperparameter deciding the weight of the penalty term.

Table 7: Analysis of constrained optimization methods for solving the proxy problem.

**Algorithm** **Constrained Optimization** **Cora*** **Citeseer*** **Pubmed***

w/o **49.10** 3.80 **42.89** 1.30 **47.79** **1.33**
SPN-GAT with 48.83 ± ± 3.51 42.04 ± ± 1.23 47.55 ± ± 1.24

We conduct empirical comparison of this constrained optimization method and our default implementation where the consistency constraint is ignored. The results are presented in Tab. 7. We can see
that the constrained optimization method does not lead to improvement, which shows that ignoring
the consistency constraint is empirically reasonable.


-----

E UNDERSTANDING SPNS AS OPTIMIZING A SURROGATE FOR THE
LOG-LIKELIHOOD FUNCTION

In the model section, we motivate SPNs from the moment-matching conditions of the optimal θfunctions. Specifically, we initialize the θ-functions at a state where the moment-matching conditions
are approximately satisfied, yielding a near-optimal joint distribution. Then we further tune the
_θ-functions to solve the maximin game. Besides this perspective, SPNs can also be understood as_
optimizing a surrogate for the log-likelihood function. Next, we introduce the details.

Remember that maximizing the log-likelihood function is equivalent to solving a maximin game as:

max log pθ(yV[∗] _[, E][) = max]_ min (θ, q), with (θ, q) = _H[q(yV )]_
_θ_ _[|][x][V]_ _θ_ _q_ _L_ _L_ _−_

(37)

+ _{θs(ys[∗][)][ −]_ [E]qs(ys)[[][θ][s][(][y][s][)]][}][ +] _{θst(ys[∗][, y]t[∗][)][ −]_ [E]qst(ys,yt)[[][θ][st][(][y][s][, y][t][)]][}][.]

_sX∈V_ (s,tX)∈E


Here, q(yV ) is a joint distribution on all the node labels. qs(ys) and qst(ys, yt) are the corresponding
marginal distributions.

Although the above maximin game is equivalent to the original problem of maximizing likelihood,
solving the maximin game is nontrivial. In particular, there are two key challenges, i.e., (1) how to
specify constraints to characterize a valid joint distribution q(yV ) and (2) how to compute its entropy
_H(q) =_ Eq(yV )[log q(yV )]. To deal with the challenge, a common practice used in loopy belief
_−_
propagation is to make the following two approximations:

(1) Instead of specifying constraints to let q(yV ) be a valid joint distribution, we introduce a set of
pseudomarginals as approximation to a valid joint distribution. Specifically, these pseudomarginals
are denoted as ˜q = {qs(ys)}s∈V ∪{qst(ys, yt)}(s,t)∈E, and they satisfy _ys_ _[q][st][(][y][s][, y][t][) =][ q][t][(][y][t][)]_

and _yt_ _[q][st][(][y][s][, y][t][) =][ q][s][(][y][s][)][ for all][ (][s, t][)][ ∈]_ _[E][.]_

[P]

(2) We approximate the entropy H(q) with Bethe entropy approximation HBethe(˜q), which is defined

[P]

as follows:


log _[q][st][(][y][s][, y][t][)]_

_qs(ys)qt(yt)_


Eqs(ys)[log qs(ys)] −
_sX∈V_


Eqst(ys,yt)
(s,tX)∈E


(38)


_HBethe(˜q) = −_


With the two approximations, we get the following maximin game as a surrogate for the likelihood
maximization problem:

maxθ log pθ(yV[∗] _[|][x][V]_ _[, E][)][ ≈]_ [max]θ minq˜ _LBethe(θ, ˜q),_ (39)


with:
_LBethe(θ,q˜) = −HBethe(˜q)_

+ _{θs,t(ys[∗][, y]t[∗][)][ −]_ [E]qst(ys,yt)[[][θ][s,t][(][y][s][, y][t][)]][}][ +]

(s,tX)∈E


_{θs(ys[∗][)][ −]_ [E]qs(ys)[[][θ][s][(][y][s][)]][}][.] (40)
_sX∈V_


This problem is known as the Bethe variational problem (BVP) (Wainwright & Jordan, 2008).

Such a problem can be solved by coordinate descent, where we alternate between updating ˜q to
minimize LBethe(θ, ˜q) and updating θ to maximize LBethe(θ, ˜q). According to Yedidia et al. (2005),
updating ˜q to minimize LBethe(θ, ˜q) can be exactly achieved by running sum-product loopy belief
propagation on pθ, where a fixed point of the belief propagation algorithm yields a local optima of ˜q.
On the other hand, updating θ to maximize LBethe(θ, ˜q) can be easily achieved by gradient ascent.

In addition to that, a stationary point (θ[∗], ˜q[∗]) of the above BVP is specified by following conditions:


_∂_ Bethe(θ[∗], ˜q[∗]) _∂_ Bethe(θ[∗], ˜q[∗])
_L_ = 0 _L_ = 0. (41)

_∂q˜[∗]_ _∂θ[∗]_

According to Yedidia et al. (2005) and Wainwright & Jordan (2008), the first condition is equivalent
to the condition that ˜q[∗] is specified by a fixed-point of sum-product loopy belief propagation. The
second condition states that the moment-matching conditions are satisfied, i.e., qs(ys) = Iys∗
each node and qst(ys, yt) = I(ys∗[,y]t[∗][)][{][(][y][s][, y][t][)][}][ on each edge.] _[{][y][s][}][ on]_


-----

For our proposed approach SPN, it can be viewed as solving the BVP as defined in Eq. (39). Through
solving the proxy problem, SPN initializes θ at a state where the conditions of stationary points in
Eq. (41) are approximately satisfied. Then the fine-tuning stage of SPN further adjusts θ to solve the
maximin game by alternatively updating θ and ˜q.

More specifically, when solving the proxy optimization problem, by initializing θ in the way defined
by Eq. (27), the collection of pseudomarginal distributions _τs(ys)_ _s_ _V and_ _τst(ys, yt)_ (s,t) _E is_
_{_ _}_ _∈_ _{_ _}_ _∈_
specified by a fixed point of sum-product loopy belief propagation according to Prop. 1. This implies
that _∂∂q˜[L][Bethe][(][θ,][ ˜]q) = 0 for ˜q = {τs(ys)}s∈V ∪{τst(ys, yt)}(s,t)∈E. Meanwhile, as {τs}s∈V and_

_{τst}(s,t)∈E are learned to match the true labels yV[∗]_ [on each training graph, we thus have][ τ][s][(][y][s][)][ ≈]
IEq. (41) are approximately satisfied bymeans that solving the proxy problem yields ays[∗] _[{][y][s][}][ on each node and][ τ][st][(][y][s][, y][t][)][ ≈]_ ([I][(]θ,[y]s[∗] ˜q[,y])t[∗] θ with[)][{] to roughly match the conditions of stationary points[(][y][s] ˜q[, y] =[t][)] {[}][ on each edge. Therefore, the conditions in]τs(ys)}s∈V ∪{τst(ys, yt)}(s,t)∈E, which
for the BVP in Eq. (39). Afterwards, the refinement stage of SPN is exactly trying to solve the
maximin game of BVP in Eq. (39), where we alternate between updating ˜q to minimize LBethe(θ, ˜q)
via sum-product loopy belief propagation and updating θ to maximize LBethe(θ, ˜q) via gradient ascent.

As a result, we see that the SPN can also be understood as solving the Bethe variational problem in
Eq. (39), which acts as a surrogate for the log-likelihood function.

F EXPERIMENTAL DETAILS

Next, we describe our experimental setup in more details.

F.1 DATASETS

The statistics of the datasets used in our experiment are summarized in Tab. 8. For the Cora*,
Citeseer*, Pubmed*, and PPI datasets, they are under the MIT license.

Table 8: Dataset statistics. ML and MC stand for multi-label classification and multi-class classification respectively.

|Dataset Task # Features # Labels|Training Graphs # Graphs Avg. # Nodes Avg. # Edges|Validation Graphs # Graphs Avg. # Nodes Avg. # Edges|Test Graphs # Graphs Avg. # Nodes Avg. # Edges|
|---|---|---|---|
|PPI ML 50 121 Cora* MC 1433 7 Citeseer* MC 3703 6 Pubmed* MC 500 3 DBLP MC 100 3|20 2245.3 61318.4 140 5.6 7.0 120 4.0 4.3 60 6.0 6.7 1 6488 10262|2 3257 99460.0 500 4.9 5.8 500 3.8 4.0 500 5.4 5.8 1 14142 48631|2 2762 80988.0 1000 4.7 5.3 1000 3.8 3.8 1000 5.6 6.7 1 26813 155899|



For the DBLP dataset, it is constructed from the citation network [4] in Tang et al. (2008). Scientific
papers from eight conferences are treated as nodes, which are divided into three categories based
on conference domains [5] for classification. For each paper, we compute the mean GloVe embedding [6] (Pennington et al., 2014) of words in the title and abstract as features. We split the dataset
into three disjoint graphs for training/validation/test. The training graph contains papers published
before 1999 (with 1999 included). The validation graph contains papers published between 2000 and
2009 (with 2000 and 2009 included). The test graph contains papers published after 2010 (with 2010
included). There exists an undirected edge between two papers if one cites the other one. Cross-split
edges (e.g., an edge between a paper in the training set and a paper in the validation set) are removed.

For the PPI datasets, there are 121 binary labels, and we treat each binary label as an independent
task. For each compared algorithm, we train a separate model for each task, and report the overall
results across all tasks.

F.2 ARCHITECTURE CHOICES

To facilitate reproducibility, we use the GNN module implementations of PyTorch Geometric (Fey
[& Lenssen, 2019), and follow the GNN models provided in the examples of the repository, unless](https://github.com/rusty1s/pytorch_geometric/tree/master/examples)

[4https://originalstatic.aminer.cn/misc/dblp.v12.7z](https://originalstatic.aminer.cn/misc/dblp.v12.7z)
5ML: ICML/NeurIPS. CV: ICCV/CVPR/ECCV. NLP: ACL/EMNLP/NAACL.
[6http://nlp.stanford.edu/data/glove.6B.zip](http://nlp.stanford.edu/data/glove.6B.zip)


-----

otherwise mentioned. Note that most architecture choices are not optimal on the benchmark datasets,
but we did not tune them since we only aim to show that our method brings consistent and significant
improvement.

**GCN (Kipf & Welling, 2017).** We set the number of hidden neurons to 16, and the number of
layers to 2. ReLU (Nair & Hinton, 2010) is used as the activation function. We do not dropout
between GNN layers.

**GraphSage (Hamilton et al., 2017).** We set the number of hidden neurons to 64, and the number
of layers to 2. ReLU (Nair & Hinton, 2010) is used as the activation function. We do not dropout
between GNN layers.

**GAT (Veliˇckovi´c et al., 2018).** We set the number of hidden neurons to 256 per attention head, and
the number of layers to 3. The number of heads for each layer is set to 4, 4 and 6. ELU (Clevert et al.,
2016) is used as the activation function. We do not dropout between GNN layers.

**Graph U-Net (Gao & Ji, 2019).** We set the number of hidden neurons to 64 and the number of
layers to 3. We randomly dropout 20% of the edges from the adjacency matrix. We do not dropout
node features or between layers.

**GCNII (Chen et al., 2020a).** We set the number of hidden neurons to 2048 for the citation datasets
(Cora*, Citeseer*, Pubmed* and DBLP) and 256 for the PPI dataset. We set the number of layers to
9. ReLU (Nair & Hinton, 2010) is used as the activation function. For PPI, layer normalization (Ba
et al., 2016) is applied between the GCNII layers. We do not dropout between GNN layers. We
set the strength α of the initial residual connection to 0.5, and the hyperparameter θ to compute the
strength of the identity mapping to 1.

**The g function.** In Eq. (8) of the model section, we define g as a function mapping a pair of Ldimensional representations to a (|Y| × |Y|)-dimensional logit. Two variants of this function are
used in our experiment. For the PPI and DBLP dataset, we use the linear variant, where the pair of
node representations are concatenated and plugged into a linear layer:

_glinear(vs, vt) = W[vs; vt] + b,_ (42)

where W ∈ R[(][|Y|×|Y|][)][×][2][L] is the weight matrix and b ∈ R[|Y|×|Y|] is the bias. For the citation datasets
(Cora*, Citeseer*, Pubmed*), we use the bilienar variant, where the pair of node representations are
plugged in a bilinear mapping:

_gbilinear(vs, vt) = (Wvs)(Wvt)[T]_ _,_ (43)

where W ∈ R[|Y|×][L] is a weight matrix.

**SPN with a shared GNN.** By default, the SPN uses a node GNN and an edge GNN to approximate
the pseudomarginals on nodes and edges respectively. In the experiment, we also consider using a
shared GNN for both pseudomarginals on nodes and edges. In other words, us = vs, ∀s ∈ _V (see_
Eq. (7) and Eq. (8)). All the other components are the same as the default SPN. The results of this
variant are shown in Tab. 6 of the experiment section.

F.3 HYPERPARAMETER CHOICES

**GNNs and SPNs.** For node classification, the learning rate of the node GNN τs in GNNs and SPNs
is presented in Tab. 9. For edge classification, the learning rate of the edge GNN τst is presented in
Tab. 10. For the temperature γ used in the edge GNN τst of SPNs, we report its values in Tab. 11.

**CRF-linear.** For CRF-linear training, we set the learning rate to 5 × 10[−][4].

**CRF-GNNs and SPN.** For CRF and the refinement stage of SPN, we set learning rates to 1 _×_ 10[−][5].

**GMNN.** For GMNN training, we set the learning rate to 5 × 10[−][3].


-----

Table 9: Learning rate of the node GNN τs.

**Algorithm** **PPI** **Cora*** **Citeseer*** **Pubmed*** **DBLP**

GCN 5 × 10[−][3] 5 × 10[−][3] 1 × 10[−][2] 1 × 10[−][2] 1 × 10[−][2]
GraphSage 5 × 10[−][3] 5 × 10[−][3] 5 × 10[−][3] 5 × 10[−][3] 5 × 10[−][3]
GAT 5 × 10[−][3] 1 × 10[−][2] 1 × 10[−][3] 1 × 10[−][3] 1 × 10[−][3]
Graph U-Net 5 × 10[−][3] 1 × 10[−][2] 1 × 10[−][2] 1 × 10[−][2] - 
GCNII 5 × 10[−][3] 1 × 10[−][2] 1 × 10[−][2] 1 × 10[−][2] 1 × 10[−][3]

Table 10: Learning rate of the edge GNN τst.

**Algorithm** **PPI** **Cora*** **Citeseer*** **Pubmed*** **DBLP**

GCN 1 × 10[−][3] 1 × 10[−][2] 5 × 10[−][2] 1 × 10[−][2] 5 × 10[−][3]
GraphSage 1 × 10[−][3] 1 × 10[−][3] 1 × 10[−][3] 1 × 10[−][3] 1 × 10[−][3]
GAT 1 × 10[−][3] 1 × 10[−][3] 5 × 10[−][4] 5 × 10[−][4] 5 × 10[−][4]
Graph U-Net 1 × 10[−][3] 1 × 10[−][2] 1 × 10[−][2] 1 × 10[−][2] - 
GCNII 1 × 10[−][3] 5 × 10[−][3] 1 × 10[−][3] 1 × 10[−][3] 1 × 10[−][4]

Table 11: Temperature γ of the edge GNN τst.

**Algorithm** **PPI** **Cora*** **Citeseer*** **Pubmed*** **DBLP**

GCN 10 0.2 1 2 2
GraphSage 10 10 10 10 10
GAT 10 0.2 10 0.2 0.2
Graph U-Net 10 0.5 1 0.2 - 
GCNII 10 0.5 0.5 0.5 2

F.4 COMPUTATIONAL RESOURCES

We run the experiment by using NVIDIA Tesla V100 GPUs with 16GB memory.

G ADDITIONAL RESULTS

In this section, we present some additional experimental results.

G.1 ADDITIONAL ANALYSIS OF GNN ARCHITECTURES

In this analysis, we study the effect of node/edge GNN architectures on SPNs. We fix one of the GNNs
and change the capacity of the other (Fig. 4), then evaluate SPN-GAT on PPI-1-0, a subset of PPI-1
that only contains its first label. The results show that our model benefit from capacity gain in both
node and edge GNNs, highlighting their effective synergy. This also explains the underperformance
of SPN-GCN in Tab. 1, where the edge GCN backbone with only two layers and 16 hidden neurons
is incapable of modeling the edge label dependencies and thus drags the performance behind. We
also find that the node and edge GNNs need not share the same backbone, and in many cases SPNs
with different node and edge GNNs perform superior to those with same backbone (Fig. 4). The
expressiveness of edge GNNs is crucial to the performance of SPN. Though we did not optimize the
design of our edge GNNs, they have shown to be helpful in boosting the performance once plugged
into our approach.

0.735 0.745

2 0.730 GAT 0.740

0.725 0.735

4 0.720 GCN2 0.730

# Heads in the Node GNN8 0.715 Node GNN Architecture 0.725

SAGE

0.710 0.720

2 4 8 GAT GCN2 SAGE

# Heads in the Edge GNN Edge GNN Architecture


Figure 4: Left: effect of #heads in SPN-GAT. Right: effect of backbones in SPN.


-----

G.2 NODE-LEVEL ACCURACY ON CORA*, CITESEER*, AND PUBMED*

In the experiment, we report the graph-level accuracy on the Cora*, Citeseer*, and Pubmed* datasets,
where SPNs consistently outperform other methods. Besides the graph-level accuracy, we also
compute the node-level accuracy on these datasets, and the results are reported in Tab. 12. We can
see that our approach still consistently outperforms other methods in terms of node-level accuracy.

Table 12: Node-level accuracy on Cora*, Citeseer*, Pubmed* (in %).

**Algorithm** **Cora*** **Citeseer*** **Pubmed***

GCN 79.85 ± 0.24 72.25 ± 0.71 78.05 ± 0.55
GraphSAGE 73.43 ± 1.67 62.48 ± 2.19 73.99 ± 1.26
GAT 79.65 ± 1.25 74.15 ± 0.12 78.62 ± 0.52
Graph U-Net 78.72 ± 0.63 71.36 ± 1.37 77.93 ± 0.60
GCNII 82.84 ± 0.37 72.61 ± 0.49 79.47 ± 0.55

CRF-linear 68.47 ± 2.13 65.88 ± 0.85 65.93 ± 2.18
CRF-GAT 77.75 ± 1.24 69.13 ± 1.10 75.96 ± 1.06
CRF-UNet 78.32 ± 1.51 70.78 ± 1.15 77.91 ± 0.56
CRF-GCNII 35.98 ± 7.40 33.73 ± 5.87 60.55 ± 4.17
GMNN 79.90 ± 0.93 72.18 ± 0.48 78.00 ± 1.04

SPN-GAT 83.13 ± 0.48 **74.50 ± 0.36** 79.23 ± 0.33
SPN-UNet 81.11 ± 0.55 72.28 ± 0.94 78.70 ± 0.37
SPN-GCNII **83.54 ± 0.27** 74.04 ± 0.29 **79.95 ± 0.38**


G.3 COMPARISON OF SUM-PRODUCT AND MAX-PRODUCT BELIEF PROPAGATION

As explained in section 4.2, the sum-product belief propagation algorithm is more applicable to
the case of node-level accuracy, as it aims at inferring the marginal label distribution on each node.
Nevertheless, in practice we find that the max-product algorithm usually achieves better empirical
node-level accuracy. For example, the results on the PPI-10 dataset are presented in Tab. 13.

Table 13: Micro-F1 on PPI-10 (in %).

**Algorithm** **Micro-F1**

Sum-product BP 94.50 ± 0.16
Max-product BP 94.65 ± 0.13

Because of the better empirical results, we choose to use max-product belief propagation by default.

G.4 HYPERPARAMETER ANALYSIS

Finally, We present analysis of the hyperparameter γ (i.e., edge temperature) in Fig. 5.


84

StructGNN

83

82

Test Accuracy (%)

81

80

0.05 0.1 0.2 0.5 1.0 2.0

Temperature

(a) Edge temperature on Cora.


86

StructGNN

85

84

83

Test Accuracy (%)82

81

80

0.05 0.1 0.2 0.5 1.0 2.0

Temperature

(b) Edge temperature on DBLP.


Figure 5: Hyperparameter analysis.


-----


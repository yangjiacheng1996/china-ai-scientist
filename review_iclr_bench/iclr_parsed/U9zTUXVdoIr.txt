# GSMOOTH: CERTIFIED ROBUSTNESS AGAINST SEMANTIC TRANSFORMATIONS VIA GENERALIZED RANDOMIZED SMOOTHING

**Anonymous authors**
Paper under double-blind review

ABSTRACT

The vulnerability of deep learning models to adversarial examples and semantic transformations has limited the applications in risk-sensitive areas. The recent development of certified defense approaches like randomized smoothing provides a promising direction towards building reliable machine learning systems.
However, current certified defenses cannot handle complex semantic transformations like rotational blur and defocus blur which are common in practical applications. In this paper, we propose a generalized randomized smoothing framework
(GSmooth) for certified robustness against semantic transformations. We provide
both a unified and rigorous theoretical framework and scalable algorithms for certified robustness on complex semantic transformations. Specifically, our key idea
is to use a surrogate image-to-image neural network to approximate a transformation which provides a powerful tool for studying the properties of semantic transformations and certify the transformation based on this neural network. Experiments on multiple types of semantic perturbations and corruptions using multiple
datasets demonstrate the effectiveness of our approach.

1 INTRODUCTION

Although deep learning models have achieved remarkable success on various applications (LeCun
et al., 2015), they are vulnerable to adversarial examples (Biggio et al., 2013; Szegedy et al., 2013;
Goodfellow et al., 2014) and semantic transformations (Hendrycks & Dietterich, 2019). The vulnerability of deep learning models can limit their applications on many important tasks. For example,
the autonomous driving system can be misled even by a small adversarial patch on the road mark
(Jing et al., 2021). Compared with the maliciously crafted adversarial examples, semantic transformations are more practical in real-world scenarios, such as rotation, translation, blur, bad weather,
and so on. Such transformations do not damage the semantic features of images and can be easily
recognized by humans, but they also degrade the performance of deep learning models. Therefore,
it is imperative to improve model robustness against semantic transformations.

To develop more reliable machine learning systems, many efforts have been made to design defense
techniques against adversarial attacks or semantic transformations. The existing defense methods
can be categorized into empirical defenses and certified defenses. Adversarial training (AT) (Madry
et al., 2017; Zhang et al., 2019a) is one of the most effective empirical defenses against ℓp-norm
bounded adversarial examples. Moreover, methods based on data augmentation (Hendrycks et al.,
2019; Wang et al., 2019; Calian et al., 2021) have been proposed to empirically improve the performance under semantic transformations. However, the performance of empirical defenses is difficult
to be fully justified and these defenses can be further broken by new adaptive attacks (Athalye et al.,
2018; Tramer et al., 2020). In contrast, the certified defenses aim to theoretically provide a certified
region where the model is theoretically safe under any attack or perturbation (Wong & Kolter, 2018;
Cohen et al., 2019; Gowal et al., 2018; Zhang et al., 2019b). Along this line, developing certified
defense methods is a crucial step towards reliable machine learning systems.

Although certified defenses have achieved great success, most of them are limited to defend against
_ℓp-norm bounded attacks. However, the ℓp distance between the original image and its corrupted_
counterpart by a semantic transformation (e.g., translation, rotation) would be large even when the


-----

corruption is slight. Therefore, the current methods are incapable of certifying robustness against
such semantic perturbations. To solve this problem, several recent works (Fischer et al., 2020;
Mohapatra et al., 2020; Li et al., 2021) attempt to extend the certified defenses to several simple
semantic corruptions, including translation, rotation, and Gaussian blur. However, these works are
not scalable to certify robustness against complex and general semantic perturbations. First, deterministic certified defenses (Mohapatra et al., 2020) based on convex relaxation for the activation
function require solving a complex optimization problem for computing bound which is computationally expensive. Second, probabilistic approaches based on randomized smoothing also demand
a handcrafted Lipschitz bound (Li et al., 2021), which is intractable for complicated semantic transformations. For example, many semantic transformations such as glass blur and pixelate do not have
a closed form expression or they are black boxes and hard to be analyzed theoretically, but they are
common in real-world scenarios. Therefore, it is still highly challenging to certify robustness against
these complex and realistic semantic transformations.

To address the aforementioned challenges, we propose a generalized randomized smoothing framework (GSmooth). First, we provide a unified framework of GSmooth for certifying general semantic transformations. Then we categorize the transformations into resolvable transformations (e.g.,
translation) and non-resolvable transformations (e.g., rotational blur) similar with Li et al. (2021).
As mentioned above, most non-resolvable transformations are complex and the existing methods
cannot provide their certified radius. To handle the challenge, we propose to use an image-to-image
translation neural network to approximate all these transformations. Due to the strong capacity of
neural networks, our method is flexible and scalable to model these complex semantic transformations. By introducing an augmented noise in the layers of the surrogate model, we can theoretically
provide the certified radius for the proxy neural networks which can be used for certifying the original transformations. Next, we provide theoretical analysis and error bounding for the approximation. Finally, we validate the effectiveness of our methods on several publicly available datasets.
Extensive experimental results demonstrate that our methods are effective for certifying complex
semantic transformations including different types of blur or image quality corruptions.

2 RELATED WORK

2.1 ATTACKS AND DEFENSES FOR SEMANTIC TRANSFORMATIONS

Unlike ℓp perturbation which adds small noise to every pixel of an image, semantic attacks or physical attacks are usually unrestricted. Brown et al. (2017); Song et al. (2018) use a small patch added
to the image to mislead the classifier or the object detector. Engstrom et al. (2019; 2018); Xiao
et al. (2018) construct adversarial examples using spatial transformations like rotation or translation. Hendrycks & Dietterich (2019) show that a wide variety of semantic perturbations degrade
the performance for many deep learning models. Many works (Cubuk et al., 2019; Hendrycks et al.,
2019; 2020; Robey et al., 2020) propose diverse data augmentation techniques to enhance robustness
under semantic perturbations. Calian et al. (2021) propose adversarial data augmentation that can
be viewed as adversarial training for defending semantic perturbations. Beyond empirical defenses,
several works (Mohapatra et al., 2020; Madry et al., 2017; Singh et al., 2019; Balunovi´c et al.,

2019) attempt to certify some simple geometric transformations. However, all of them belong to
deterministic certification approaches and their performance on realistic datasets are unsatisfactory.

2.2 RANDOMIZED SMOOTHING

Randomized smoothing is a novel certification method originated from differential privacy (Lecuyer
et al., 2019). Cohen et al. (2019) then improve the certified bound and apply it to large scale deep
neural networks and datasets. Yang et al. (2020) exhaustively analyze the robust radius by using
different noise distribution and norms. Hayes (2020); Yang et al. (2020) point out that randomized
smoothing suffers from curse of dimensionality for the l norm. Salman et al. (2019) adopt adver_∞_
sarial training to train smoothed classifiers to obtain better robustness guarantees. Li et al. (2021);
Fischer et al. (2020) extend randomized smoothing to certify some simple semantic transformations, e.g., image translation and rotation. It shows that randomized smoothing could be generalized
to certify more diverse attacks or corruptions. However, their methods are limited to simple semantic
transformations, which are easy to analyze their mathematical properties.


-----

3 PROPOSED METHOD

In this section, we present the framework and theoretical analyses of our Generalized Randomized
Smoothing (GSmooth). We first introduce the basic notations. Then we divide the semantic transformations into resolvable transformations and non-resolvable transformations similar with Li et al.
(2021). Next we introduce the details of our GSmooth for these two types of semantic transformations, respectively. Finally, we show the theoretical insight and proof sketch of our main results.

3.1 NOTATIONS

We first introduce the notations and formulation of the task. Given the input of x ∈ R[n] and the
labels of Y = {1, 2, . . . p}, we denote the classifier as f (x) : R[n] _→_ [0, 1][p], which outputs predicted
probabilities over all p classes. The prediction of f is arg maxi _f_ (x)i, where f ( )i denotes the
_∈Y_ _·_
_i-th element of f_ (·). Let τ (θ, x) : R[m] _×_ R[n] _→_ R[n] be a semantic transformation of raw input x with
parameter θ ∈ R[m]. We define the smoothed classifier as

_G(x) = Eθ_ _g[f_ (τ (θ, x))], (1)
_∼_

which is the average prediction for the samples under a smoothing distribution g(θ) where g(θ) =
exp(−ψ(θ)) and ψ(θ) is a smooth function from R[m] _→_ R. Let ||u|| = 1 be any vector with unit
norm and a random variable γu = ⟨u, ∇ψ(δ)⟩ where δ ∼ _g and ∇_ is the gradient operator of a
function. The complementary CDF is ϕu(c) = P[γu > c] and the inverse complementary CDF is
_ϕ[−]u_ [1][(][p][) = inf][{][c][|][P][(][γ][u] _[> c][)][ ⩽]_ _[p][}][. Following][ Yang et al.][ (][2020][), we define a function][ Φ][ as]_

Φ(p) = max||u||=1 E[γuI{γu > ϕ[−]u [1][(][p][)][}][]][,] (2)

which will be used to represent the certified radius. Let yA= arg maxi _G(x)i be the predicted_
_∈Y_
label by the smoothed classifier G(x) and yB = arg maxi _yA G(x)i is the runner-up class. With-_
_∈Y\_
out causing confusion, we use G(x)A to denote the probability of the top class G(x)yA ; likewise for
_G(x)B._

3.2 CERTIFIED BOUND FOR RESOLVABLE SEMANTIC TRANSFORMATIONS


We first discuss a class of transformations that are resolvable — the composition of two transformations with parameters belonging to a perturbation set θ, ξ ∈ _P ⊂_ R[m] is still a transformation with
a new parameter γ(θ, ξ) ∈ _P ⊂_ R[m], where γ(·, ·) : P × P → _P is a function depending on these_
parameters. For resolvable semantic transformations, we have the following theorem.
**Theorem 1. Let f** (x) be any classifier and G(x) be the smoothed classifier defined in Eq. (1). If
_there exists a function M_ (·, ·) : P × P → R, the transformation τ (·, ·) satisfies

_∂γ(θ, ξ)_

= _[∂γ][(][θ, ξ][)]_ _M_ (θ, ξ),
_∂ξ_ _∂θ_

_and there exist two constants pA, pB satisfying_

_G(x)A ⩾_ _pA ⩾_ _pB ⩾_ _G(x)B,_


_then yA = arg maxi_ _G(τ_ (ξ, x))i holds for any _ξ_ ⩽ _R where_
_∈Y_ _∥_ _∥_

1 _pA_ 1
_R =_ (3)

2M _[∗]_ ZpB Φ(p) _[dp,]_

_and M_ = maxξ,θ _P_ _M_ (ξ, θ) _._

_[∗]_ _∈_ _||_ _||_

**Remark. The settings of Theorem 1 are similar with Li et al. (2021) for resolvable semantic transfor-**
mations. But here we adopt a different presentation and proof for the theorem which could be easier
to extend to our GSmooth framework for general semantic transformations. Specifically, we show
two examples of the theorem which are additive transformations and commutable transformations.
A transformation is additive if τ (θ, τ (ξ, x)) = τ (ξ + θ, x) for any θ, ξ ∈ _P_ ; or it is commutable if
_τ_ (θ, τ (ξ, x)) = τ (ξ, τ (θ, x)) for any θ, ξ ∈ _P_ . For these two types of transformations, it is straightforward to verify that they satisfy the property proposed in Theorem 1. As an example, we simply
apply Theorem 1 for isotropic Gaussian distribution g(θ) = N (0, σ[2]I) and get the certified radius

_R =_ _[σ]_ Ψ _pA_ Ψ (pB) _,_ (4)

2 _−_
     


-----

Base Classifier


Transformation Parameters

Input Image _F 2(  )x_

|Surrogate Model|Col2|
|---|---|
|F (θ ) 1 H (. ) F ( x ) 2||
|||


_F 1θ( )_

_H ( )._

_F 2( )x_


Noise

Augmented Noise


_R_


Augmented Noisy Images

~  g


Certified Radius


~  g


Figure 1: A graphical illustration of our GSmooth. We use a surrogate image-to-image translation
network to accurately fit a semantic transformation. Then we add a new augmented noise into the
surrogate model and construct the GSmooth classifier. The augmented noise are sampled to ensure
the transformation to be resolvable in the semantic space. We theoretically calculate the certification
bound for the surrogate model to certify the original semantic transformation.

where Ψ is the inverse CDF of the standard Gaussian distribution. These two kinds of transformations include image translation and Gaussian blur, which are basic semantic transformations and
widely discussed in previous works (Li et al., 2021; Fischer et al., 2020). The certification of these
simple transformations only requires applying translation or Gaussian blur to the sample and gets
the average classification score under the noise distribution.

3.3 CERTIFIED BOUND FOR GENERAL SEMANTIC TRANSFORMATIONS

Translation and Gaussian blur are two specific cases of semantic transformations. In practice, most
semantic transformations are not commutable or even not resolvable. Therefore, we need to develop better methods for certifying more types of semantic transformations. However, the existing
methods like Semanify-NN (Mohapatra et al., 2020) based on convex relaxation and TSS (Li et al.,
2021) based on randomized smoothing require to develop a specific algorithm or bound for each individual semantic transformation. This is not scalable and might be infeasible for more complicated
transformations without explicit mathematical forms.

To address the challenge, we draw inspiration from the fact that neural networks are able to approximate functions including a complex and unknown semantic transformation (Zhu et al., 2017).
First, we propose to use a surrogate image-to-image translation model to accurately fit the semantic
transformation. Then we theorectially show that by introducing an augmented noise in the layers
of the surrogate model, as shown in Fig 1, randomized smoothing can be extended to handle these
transformations. Specifically, we define the surrogate model as the following form that will lead to
a simple certification bound as we shall see:

_τ_ (θ, x) = H(F1(θ) + F2(x)), (5)

where F1(·) : R[m] _→_ R[d], F2(·) : R[n] _→_ R[d], and H(·) : R[d] _→_ R[n] are three individual neural
networks. F1( ) and F2( ) are the encoders for transformation parameters and images respectively,

_·_ _·_
and their encodings are added together in the semantic space which is critical for its theoretical
certification. We find that the surrogate neural network is much easier to analyze and can be certified
by introducing a dimensional augmentation strategy for both noise parameters and input images.

As illustrated in Fig. 1, an augmented noise is added to the semantic layers H(·) in the surrogate
model. Our key insight is that the transformation could be viewed as the superposition of a resolvable
part and a non-resolvable residual part in the augmented semantic space. Then we could use the
augmented noise to control the non-resolvable residual part if the augmented dimension d ⩾ _m_ + _n._
This dimension augmentation is the key step of our technique. The augmentation for noise is from
R[m] to R[d]. To keep the dimension consistent, we also augment data x to R[d] by padding 0 entries.


-----

By certifying the transformation based on the surrogate model, we are able to certify the original
transformation if the approximation error is within an acceptable region (detailed analysis is in
Theorem 3). Our method is flexible and scalable since the surrogate neural network has a uniform
mathematical form for theoretical analysis and they are trained automatically. Next, we discuss the
details of GSmooth.


Specifically, we introduce the augmented data ˜x ∈ R[d] and the augmented parameter _θ[˜] ∈_ R[d] as

_x[′]_ _θ_
_x˜ =_ _,_ _θ[˜] =_ _,_
_x_ _θ[′]_
   


(6)


where the additional parameters θ[′] _∈_ R[n] are sampled from g[′](θ[′]), and the joint distribution of θ[′]

and θ is _θ[˜] ∼_ _g˜ where ˜g(θ[˜]) = g[′](θ[′])g(θ). Moreover, the augmented data x[′]_ _∈_ R[m]. We define the
_generalized smoothed classifier as_

_G˜(˜x) = Eθ˜∼g˜(θ[˜])_ _f˜(˜τ_ (θ,[˜] ˜x)) _,_ (7)
h i

where _f[˜] is the “augmented target classifier” that equals the original classifier when constrained on_
the original input x, which means _f[˜](˜x) = f_ (x). This can be achieved by setting the weights of
additional dimensions to 0. Note that now all the functions are augmented for a d dimensional
input. We further augment our surrogate neural network to represent the augmented transformation
_τ˜ : R[d]_ _→_ R[d],
_τ˜(θ,[˜]_ ˜x) = H[˜] ( F[˜]1(θ[˜]) + F[˜]2(˜x)), (8)

where _H[˜]_ (·), _F[˜]1(·),_ _F[˜]2(·) : R[d]_ _→_ R[d] are parts of the augmented surrogate model. By carefully
designing the interaction between the augmented parameters and the original parameters, we could
turn the transformation to a resolvable one and it does not change the original surrogate model when
constraining to the original input x and θ. Specifically, we design the function _F[˜]1 and_ _F[˜]2 as follows:_


_x[′]_
_,_ _F[˜]2(˜x) =_ _F2(x)_



_,_ _H[˜]_ (˜x) = _Id−n_
_H(x)_



_θ_
_F˜1(θ[˜]) =_ _F1(θ) + θ[′]_



(9)


Before stating our main theorem, we introduce several notations ˜zξ = F[˜]1(ξ[˜])+ F[˜]2(˜x), ˜zθ = F[˜]1(θ[˜])+
_F˜2(˜x), ˜yξ = (yξ[′]_ _[, y][ξ][)][T][ = ˜]H( F[˜]1(ξ[˜])+ F[˜]2(˜x)) and ˜yθ = (yθ[′]_ _[, y][θ][)][T][ = ˜]H( F[˜]1(θ[˜])+ F[˜]2(˜x)) for simplicity._
Then we theoretically prove that the GSmooth classifier is certifiably robust within a given range:

**Theorem 2. Suppose f** (x) is a classifier and _G[˜](˜x) is the smoothed classifier defined in Eq. (7), if_
_there exist pA and pB satisfying_

_G˜(˜x)A ⩾_ _pA ⩾_ _pB ⩾_ _G[˜](˜x)B,_

_then yA = arg maxi∈Y_ _G[˜](˜τ_ (ξ,[˜] ˜x))i for any ∥ξ∥2 ⩽ _R, where_

1 _pA_ 1
_R =_ (10)

2M _[∗]_ ZpB Φ(p) _[dp,]_

_and the coefficient M_ _[∗]_ _is defined as_

2

_∂F2(yξ)_

_M_ _[∗]_ = maxξ,θ∈P s1 + _∂ξ_ _−_ _[∂F]∂θ[1][(][θ][)]_ 2. (11)

As the main result of our GSmooth, we have several observations about it. First, we see that the
certified radius is similar to the result in Theorem 1. Second, compared with resolvable transformations, we need to add a new type of noise when constructing the GSmooth classifier. This isotropic
noise has the same dimension as the data and is added to the intermediate layers of surrogate neural
networks. The theoretical explanation behind this is that this isotropic noise makes the Jacobian
matrix of the semantic transformation to be invertible which is crucial for the proof. Third, we observe that the coefficient M _[∗]_ depends on the norm of the difference of two Jacobian matrices and is
independent with the target classifier, later we will discuss the meaning of this term in detail.

Before diving into our theoretical insight and proof of the theorem, we introduce a specific case
of Theorem 2 which is more convenient for practical usage. We empirically found that taking a


-----

linear transformation as F1(θ) = A1θ + b1 where A1 ∈ R[n][×][m], b1 ∈ R[n] does not sacrifice the
precision of the surrogate network and we have _[∂F]∂θ[1][(][θ][)]_ = A1. After substituting the term in Eq. (44)

we only need to optimize ξ for calculating M _[∗]_ and we make the bound tighter. Additionally, we
use two gaussian distributions for the noise distribution and the augmented noise distribution, i.e.
_g(θ) = N_ (0, σ1[2][I][)][ and][ g][′][(][θ][′][) =][ N] [(0][, σ]2[2][I][)][. Formally, we have the following corollary,]

**Corollary 1. Suppose f** (x) is a classifier and _G[˜](˜x) is the smoothed classifier defined in Eq. (7), if_
_the layer F1(θ) in the surrogate neural network has the following form:_

_F1(θ) = A1θ + b1_ (12)

_where A1∈_ R[n][×][m], b1 ∈ R[n] _are the parameters; and if there exists pA and pB satisfying_

_G˜(˜x)A ⩾_ _pA ⩾_ _pB ⩾_ _G[˜](˜x)B,_

_then yA = arg maxi∈Y_ _G[˜](˜τ_ (ξ,[˜] ˜x))i for any ∥ξ∥2 ⩽ _R where_

1
_R =_ Ψ _pA_ Ψ (pB) _,_ (13)

2M _−_

_[∗]_

_where Ψ(·) is the inverse CDF of standard Gaussian distribution, and the coefficient _     _M_ _[∗]_ _is defined_
_as,_


1 + [1]

_σ1[2]_ _σ2[2]_


_∂F2(yξ)_

_A1_
_∂ξ_ _−_


_M_ _[∗]_ = maxξ∈P


(14)


4 PROOF SKETCH AND THEORETICAL ANALYSIS

4.1 PROOF SKETCH OF OUR MAIN THEOREM

In this section, we briefly summarize the main idea for proving the Theorem 2 and the theoretical
insight of our GSmooth. The key idea is to prove that the gradient of the smoothed classifier can be
bounded by a function of the classification confidence and the parameters of the noise distribution.
Formally, we calculate the gradient to the perturbation parameter ξ for our augmented smoothed
classifier as
_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) = ∇ξ˜[E]θ[˜]∼g˜(θ[˜])[[ ˜]f (˜τ (θ,[˜] ˜τ (ξ,[˜] ˜x)))]. (15)

We expand the expectation into integral and see that


_∂f[˜](˜τ_ (θ,[˜] ˜yξ))

_g˜(θ[˜])dθ.[˜]_ (16)

R[n][+][d] _∂ξ[˜]_


_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) =


The key step is to eliminate the gradient of _[∂]F[˜] (˜τ_ (θ,[˜] _y˜ξ))_ and replace it with _[∂]f[˜](˜τ_ (θ,[˜] _y˜ξ))_ . Then we

_∂ξ[˜]_ _∂θ[˜]_

integrate it by parts to get the following obejective,

_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) = − R[n][+][d] _F˜(˜τ_ (θ,[˜] ˜yξ)) _∂[∂]θ[˜]( M[˜]_ (ξ,[˜] _θ[˜])˜g(θ[˜]))dθ.[˜]_ (17)
Z

After that, we could bound the gradient of the GSmooth classifier using the technique similar to
randomized smoothing (Yang et al., 2020). More details of the proof can be found in Appendix A.

4.2 THEORETICAL INSIGHT


Next, we provide the theoretical insight for our augmentation scheme on transformation parameters
and data. First, the key is to expand the transformation space by adding additional dimensions to
form a closed space. In the augmented space, the Jacobian matrix of the semantic transformation
became invertible which is crucial for our proof. Second, as we can see in Eq. (14) that M _[∗]_ is
influenced by two factors. One is the standard deviation of two noise distributions. The other is the
norm of the Jacobian matrix _[∂F]∂ξ[2][(][y][ξ][)]_ _A1. It can be viewed as the residual of the non-resolvable_

_−_
part of the transformation. Along this line, our method decomposes the unknown semantic transformation into a resolvable part and a residual part. The non-resolvable residual part could be handled
by introducing additional noise with standard deviation σ2.


-----

4.3 ERROR ANALYSIS FOR SURROGATE MODEL APPROXIMATION

In this subsection, we theoretically analyze the effectiveness of certifying real semantic transformation due to the existence of approximation error of surrogate neural networks.
**Theorem 3. Suppose the simulation of the semantic transformation has an small enough error**

_∥τ˜(ξ,[˜]_ ˜x) − _τ_ (ξ,[˜] ˜x)∥2 < ε,

_Then there exists a constant ratio A = A(∥F1[′][(˜]ξ)∥2, ∥F2[′][(˜]yξ)∥2, ∥F2[′][(˜]zξ)∥2) > 0 does not depend_
_on the target classifier, we have the certified radius for the real semantic transformation satisfies_
_that_
_Rr > R(1 −_ _Aε)_
_where R is the certified radius for surrogate the neural network in Theorem 2 and_

1 _pA_ 1
_R =_

2M _[∗]_ ZpB Φ(p) _[dp,]_

We find that the reduction of the certified radius is influenced by two factors. The first one is the
approximation error ϵ between the surrogate transformation and the real semantic transformation.
The second one the ratio A is about the norm of the Jacobian matrix for some layers of the surrogate
model which is also an inherent property of the semantic transformation itself and does not depend
on the target classifier.

5 EXPERIMENTS

5.1 EXPERIMENTAL SETUP AND EVALUATION METRICS

In this section, we conduct extensive experiments to show the effectiveness of our GSmooth on
various types of semantic transformations. We use MNIST, CIFAR-10 and CIFAR-100 (Krizhevsky
et al., 2009) datasets to verify our methods. We train a resnet with 110 layers (He et al., 2016a)
from scratch. Similar to prior works, we apply moderate data augmentation (Cohen et al., 2019)
to improve the generalization of the classifier. For the surrogate image-to-image translation model
for simulating semantic transformations, we adopt the U-Net architecture (Ronneberger et al., 2015)
for _H[˜]_ ( ) layers and several simple convolutional or linear layers for _F[˜]1(_ ) and _F[˜]2(_ ). All models

_·_ _·_ _·_
are trained using Adam optimizer with an initial learning rate of 0.001 that decays every 50 epochs
until convergence. The algorithms for calculating M _[∗]_ and other details in our experiments are listed
in Appendix B due to limited space. The evaluation metric is the certified accuracy, which is the
percentage of samples that are correctly classified and has a larger certified radius than the given
range. We use ∥α∥ to indicate the preset certified radius.

5.2 MAIN RESULTS

To demonstrate the effectiveness of our GSmooth on certifying complex semantic transformations, we measure the certified correct accuracy for different semantic transformations on different datasets in Table 1. We compare the results of our GSmooth with several baselines, including
_randomized smoothing for some simple semantic transformation of TSS (Li et al., 2021) and Indi-_
**vSPT/distSPT (Fischer et al., 2020), and our GSmooth is a natural and powerful extension of their**
methods. We also compare our method with the deterministic certification approaches, including
**DeepG (Balunovi´c et al., 2019) that uses linear relaxations similar to Wong & Kolter (2018), Inter-**
**val (Singh et al., 2019) that is based on interval bound propagation, VeriVis (Pei et al., 2017) that**
enumerates all possible outcomes for semantic transformations with finite values of parameters, and
**Semanify-NN (Mohapatra et al., 2020) which uses a new preprocessing layer to turn the problem**
into a ℓp norm certification.

We have the following observations for the experimental results. First, only our method achieves
non-zero accuracy on certifying some complex semantic transformations and the results verify our
Theorem 2. This is a breakthrough that greatly extends the boundary of randomized smoothing
based methods. Second, we see the performance of GSmooth is similar to the state-of-the-art randomized smoothing approaches like TSS on several simple semantic transformations like Gaussian


-----

|Cert Acc(%)|Type Dataset Attack Range|Certified Accuracy(%) GSmooth TSS DeepG Interval VeriVis Semanify- IndivSPT/ (Ours) NN distSPT|
|---|---|---|
|Gaussian Blur|MNIST ∥α∥2 < 6 Additive CIFAR-10 ∥α∥2 < 4 CIFAR-100|91.0 90.6 – – – – – 67.4 63.6 – – – – – 22.1 21.0 – – – – –|
|Translation|MNIST ∥α∥2 < 8 Additive CIFAR-10 ∥α∥2 < 20 CIFAR-100|98.7 99.6 0.0 0.0 98.8 98.8 99.6 82.2 80.8 0.0 0.0 65.0 65.0 78.8 42.2 41.3 – – 24.2 24.2 –|
|Brightness, Contrast|MNIST ∥α∥∞< 0.5 Resolvable CIFAR-10 ∥α∥∞< 0.4 CIFAR-100|97.7 97.6 ⩽0.4 0.0 – ⩽74 – 82.5 82.4 0.0 0.0 – – – 42.3 41.4 0.0 0.0 – – –|
|Rotation|MNIST ∥α∥2 < 50◦ Non-resolvable CIFAR-10 ∥α∥2 < 10◦ CIFAR-100|95.7 97.4 ⩽85.8 ⩽6.0 – ⩽92.48 ⩽76 64.6 70.6 62.5 20.2 – ⩽49.37 ⩽34 33.2 36.7 0.0 0.0 – ⩽21.7 ⩽18|
|Scaling|MNIST ∥α∥2 < 0.3 Non-resolvable CIFAR-10 ∥α∥2 < 0.3 CIFAR-100|95.9 97.2 85.0 16.4 – – – 54.3 58.8 0.0 0.0 – – – 31.2 37.8 0.0 0.0 – – –|
|Rotational Blur|MNIST ∥α∥2 < 10 Non-resolvable CIFAR-10 ∥α∥2 < 10 CIFAR-100|95.9 – – – – – – 39.7 – – – – – – 27.2 – – – – – –|
|Defocus Blur|MNIST ∥α∥2 < 5 Non-resolvable CIFAR-10 ∥α∥2 < 5 CIFAR-100|89.2 – – – – – – 25.0 – – – – – – 13.1 – – – – – –|
|Zoom Blur|MNIST ∥α∥2 < 0.5 Non-resolvable CIFAR-10 ∥α∥2 < 0.5 CIFAR-100|93.9 – – – – – – 44.6 – – – – – – 14.2 – – – – – –|
|Pixelate|MNIST ∥α∥2 < 0.5 Non-resolvable CIFAR-10 ∥α∥2 < 0.5 CIFAR-100|87.1 – – – – – – 45.3 – – – – – – 30.2 – – – – – –|


Table 1: Our main results of certification accuracy on several datasets and multiple types of semantic
transformations. – or 0.0% means the method fails to certify this type of semantic transformation.

Figure 2: Results of ablation experiments on the influence of smoothing distribution for zoomed
blur on CIFAR-10 dataset. The horizontal axis ∥α∥2 is the certified raidus.

blur, translation. This is a natural result since our method works similarly for resolvable transformations. For two specific non-resolvable transformations, i.e. rotation and scaling, our accuracy
is slightly lower. The possible reason is that in TSS (Li et al., 2021) they derive more elaborate
Lipschitz bound for rotation which is better than us. Third, those inherently non-resolvable transformations like image blurring (except Gaussian blur) and pixelate are more difficult than resolvable or
approximately resolvable (rotation) transformations. Thus their certified accuracy is also lower.

5.3 ABLATION STUDY

**Ablation study on the influence of noise distribution. The choice of noise distribution is important**
for randomized smoothing based methods. Since our GSmooth could certify different types of
semantic transformations that exhibit different properties. Understanding the influence of different
smoothing distributions for different semantic transformations is necessary. We choose (folded)
Gaussian, uniform, and exponential distribution and compare the certified accuracy on zoom blur
transformation for both CIFAR-10 and CIFAR-100 datasets. As shown in Fig. 2, We found that


-----

|Cert Acc|CIFAR-10|Col3|CIFAR-100|Col5|
|---|---|---|---|---|
|Rotational Blur|σ 2 σ 1|0.05 0.10 0.15 0.25|σ 2 σ 1|0.05 0.10 0.15 0.20|
||0.1 0.25 0.5 0.75|44.3 46.4 35.5 16.1 45.7 47.1 38.3 18.9 46.5 48.4 38.8 18.3 42.1 45.5 36.6 17.0|0.1 0.25 0.5 0.75|23.1 26.2 17.2 10.4 23.2 27.2 20.3 11.3 22.2 26.1 18.6 11.8 24.0 25.5 18.3 13.2|


Table 2: Results of ablation study on the influence of standard deviation of smoothing distributions,
i.e. transformation noise σ1 and augmented noise σ2 for certification accuracy on rotational blur.

Figure 3: Visualization of difference between the augmented noise in the semantic layers and the
noise on raw images. Left: original images from CIFAR-10. Middle: images with augmented noise
of σ2 = 0.2. Right: images with additive Gaussian noise σ = 0.2.

the impact of smoothing distributions depends on datasets. Uniform distribution is better for small
radius certification while exponential distribution is more suitable for certifying large radius on
average.

**Ablation study on the influence of noise variance for certification. Since our GSmooth contains**
two different variances for controlling the resolvable part and the residual part for a non-resolvable
semantic transformation. Here we investigate the effect of different noise variance on the certified
accuracy. The results are shown in Table 2. We found that using medium transformation noise and
augmented noise achieves the best certified accuracy. The fact is consistent with results in (Cohen
et al., 2019). An explanation is that there is a trade-off since higher the noise variance decreases the
coefficient M _[∗]_ but it might also degrade the clean accuracy.

**Visulization experiments: comparsion between augmented semantic noise and image noise.**
Our GSmooth needs to add a new noise in the semantic layers of the surrogate model. Here we
compare the difference between these two types of noise and visualize them. We random sample
images from CIFAR-10 and add gaussian noise with σ = 0.2 to both the semantic layer of the
surrogate model simulating zoomed blur transformation and raw images. Results are shown in Fig.
3. Both two types of noise severely blur the images. But we found that the augmented semantic
noise is more placid which can therefore keep the holistic semantic features better, e.g., shapes.

6 CONCLUSIONS

In this paper, we proposed a generalized randomized smoothing framework (GSmooth) for certifying
robustness against general semantic transformations. We proposed a novel idea that using a surrogate
neural network to fit semantic transformations. Then we prove tight certified robustness bound for
the surrogate model and use it for certifying semantic transformations. Extensive experiments verify
the effectiveness of our method and we achieved state-of-the-art performance on various types of
semantic transformations. In the future, we plan to extend our method to real-world scenarios on
more diverse semantic transformations.


-----

7 REPRODUCIBILITY STATEMENT

We ensure the reproducibility of our paper from three aspects. (1) Experiment: The implementation
of our experiment is described in Sec. 5.1. Ablation study for our experiments is in Sec. 5.3. Further
details are in Appendix B. (2) Code: Our code is included in supplementary materials. (3) Theory
and Method: A complete proof of the theoretical results described is provided in Appendix A.

8 ETHICS STATEMENT

Machine learning models are easily attacked by adversarial examples and semantic transformations.
Thus it is fundamental problem to develop certified robust machine learning methods. This paper
proposed GSmooth to certify against semantic transformations. It may promote the development of
safe and reliable machine learning models in the future.

REFERENCES

Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. In International Conference on Machine
_Learning (ICML), pp. 274–283, 2018._

Mislav Balunovi´c, Maximilian Baader, Gagandeep Singh, Timon Gehr, and Martin Vechev. Certifying geometric robustness of neural networks. Advances in Neural Information Processing Systems
_32, 2019._

Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Pavel Laskov, Giorgio Giacinto, and
Fabio Roli. Evasion attacks against machine learning at test time. In Joint European Conference
_on Machine Learning and Knowledge Discovery in Databases, pp. 387–402, 2013._

Tom B Brown, Dandelion Man´e, Aurko Roy, Mart´ın Abadi, and Justin Gilmer. Adversarial patch.
_arXiv preprint arXiv:1712.09665, 2017._

Dan A Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, Andras Gyorgy, Timothy
Mann, and Sven Gowal. Defending against image corruptions through adversarial augmentations.
_arXiv preprint arXiv:2104.01086, 2021._

Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310–1320. PMLR, 2019.

Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment:
Learning augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on
_Computer Vision and Pattern Recognition, pp. 113–123, 2019._

Foivos I Diakogiannis, Franc¸ois Waldner, Peter Caccetta, and Chen Wu. Resunet-a: A deep learning
framework for semantic segmentation of remotely sensed data. ISPRS Journal of Photogrammetry
_and Remote Sensing, 162:94–114, 2020._

Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. A
rotation and a translation suffice: Fooling cnns with simple transformations. 2018.

Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. Exploring the landscape of spatial robustness. In International Conference on Machine Learning,
pp. 1802–1811. PMLR, 2019.

Marc Fischer, Maximilian Baader, and Martin Vechev. Certified defense to image transformations
via randomized smoothing. arXiv preprint arXiv:2002.12463, 2020.

Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.

Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval
bound propagation for training verifiably robust models. arXiv preprint arXiv:1810.12715, 2018.


-----

Jamie Hayes. Extensions and limitations of randomized smoothing for robustness guarantees. In
_Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Work-_
_shops, pp. 786–787, 2020._

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770–778, 2016a.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual
networks. In European conference on computer vision, pp. 630–645. Springer, 2016b.

Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.

Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness and uncertainty.
_arXiv preprint arXiv:1912.02781, 2019._

Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul
Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical
analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241, 2020.

Pengfei Jing, Qiyi Tang, Yuefeng Du, Lei Xue, Xiapu Luo, Ting Wang, Sen Nie, and Shi Wu. Too
good to be safe: Tricking lane detection in autonomous driving with crafted perturbations. In 30th
_{USENIX} Security Symposium ({USENIX} Security 21), 2021._

Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009.

Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436–444,
2015.

Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security
_and Privacy (SP), pp. 656–672. IEEE, 2019._

Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Bhavya Kailkhura, Tao Xie, Ce Zhang, and
Bo Li. Tss: Transformation-specific smoothing for robustness certification, 2021.

Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep residual networks for single image super-resolution. In Proceedings of the IEEE conference on com_puter vision and pattern recognition workshops, pp. 136–144, 2017._

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.

Jeet Mohapatra, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel. Towards verifying
robustness of neural networks against a family of semantic perturbations. In Proceedings of the
_IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 244–252, 2020._

Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. Towards practical verification of machine
learning: The case of computer vision systems. arXiv preprint arXiv:1712.01785, 2017.

Alexander Robey, Hamed Hassani, and George J Pappas. Model-based robust deep learning: Generalizing to natural, out-of-distribution data. arXiv preprint arXiv:2005.10247, 2020.

Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer_assisted intervention, pp. 234–241. Springer, 2015._

Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, and Sebastien
Bubeck. Provably robust deep learning via adversarially trained smoothed classifiers. _arXiv_
_preprint arXiv:1906.04584, 2019._


-----

Gagandeep Singh, Timon Gehr, Markus P¨uschel, and Martin Vechev. An abstract domain for certifying neural networks. Proceedings of the ACM on Programming Languages, 3(POPL):1–30,
2019.

Dawn Song, Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Florian
Tramer, Atul Prakash, and Tadayoshi Kohno. Physical adversarial examples for object detectors.
In 12th {USENIX} Workshop on Offensive Technologies ({WOOT} 18), 2018.

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.

Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry. On adaptive attacks to
adversarial example defenses. Advances in Neural Information Processing Systems, 33, 2020.

Yulin Wang, Xuran Pan, Shiji Song, Hong Zhang, Gao Huang, and Cheng Wu. Implicit semantic
data augmentation for deep networks. Advances in Neural Information Processing Systems, 32:
12635–12644, 2019.

Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, pp. 5286–5295. PMLR,
2018.

Yuxin Wu and Kaiming He. Group normalization. In Proceedings of the European conference on
_computer vision (ECCV), pp. 3–19, 2018._

Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, and Dawn Song. Spatially transformed adversarial examples. arXiv preprint arXiv:1801.02612, 2018.

Greg Yang, Tony Duan, J Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. In International Conference on Machine Learning, pp. 10693–
10705. PMLR, 2020.

Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
_on Machine Learning, pp. 7472–7482. PMLR, 2019a._

Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning,
and Cho-Jui Hsieh. Towards stable and efficient training of verifiably robust neural networks.
_arXiv preprint arXiv:1906.06316, 2019b._

Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation
using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference
_on computer vision, pp. 2223–2232, 2017._


-----

A PROOF OF THEOREMS

In this section, we will provide detailed proofs of theorems in our paper.

First, we restate the theorem of randomized smoothing for additive noise and binary classifiers
_f_ (·) : R[n] _→_ [0, 1],
_G(x) = Eθ_ _g[f_ (x + θ)] (18)
_∼_

**Theorem 4. Let f** (x) be any classifier and G(x) be the smoothed classifier defined in Eq. (18), if
_G(x) <_ 2[1] _[, then][ G][(][x][ +][ δ][)][ <][ 1]2_ _[for any]_


(19)
Φ(p) [d][p]


_∥δ∥_ _<_


_G(x)_


_where Φ(·) is a function about smoothing distribution defined in Eq. (2)._

_Proof. We first calculate the gradient of the smoothed classifier_


_∇G(x)_


R[n][ f] [(][x][ +][ θ][)][g][(][θ][)d][θ]

_∂_

_∂x_ _[f]_ [(][x][ +][ θ][)][g][(][θ][)d][θ]

_∂_

_∂θ_ _[f]_ [(][x][ +][ θ][)][g][(][θ][)d][θ]


_∂x_

R[n]

Z

R[n]

Z


Then we multiple any vector with unit norm u ∈Bn(1) = {u : ∥u∥= 1, u ∈ R[n]},


_|⟨∇G(x), u⟩|_


_∂θ_ _[f]_ [(][x][ +][ θ][)][g][(][θ][)d][θ, u]

_∂_

_g(θ)dθ_
_∂θ_ _[f]_ [(][x][ +][ θ][)][, u]


R[n]

R[n] 


_∂f_ (x + θ)

_uig(θ)dθ_

R[n] _∂θi_


+∞
Z−∞


+∞ _∂f_ (x + θ)

_uig(θ)dθi_ dθj
_∂θi_

_−∞_  Yj≠ _i_

+∞ _∂g(θ)_

_f_ (x + θ)ui dθi dθj

_∂θi_

Z−∞  Yj≠ _i_


_∂f_ (x + θ)

_uig(θ)dθi_
_∂θi_


R[n][−][1]


R[n][−][1]


_uidθ_

R[n][ f] [(][x][ +][ θ][)] _[∂g]∂θ[(][θ]i_ [)]


=

R[n][ f] [(][x][ +][ θ][)][⟨∇][g][(][θ][)][, u][⟩][d][θ]

Z

=

R[n][ f] [(][x][ +][ θ][)][g][(][θ][)][⟨∇][ψ][(][θ][)][, u][⟩][d][θ]

Z

= Eθ _g[f_ (x + θ) _ψ(θ), u_ ] (20)
_|_ _∼_ _⟨∇_ _⟩_ _|_

To bound the gradient of the smoothed classifier, we use the following inequality,

_G(x), u_ ⩽ sup Eθ _g_ _fˆ(x + θ)_ _ψ(θ), u_ (21)
_|⟨∇_ _⟩|_ _f_ : G[ˆ](x)=G(x) _∼_ _⟨_ _⟩_
h i
b

As shown in Yang et al. (2020), the optimal _f[ˆ](x) achieves at,_

_fˆ(x + θ) =_ 1, if⟨u, ψ(θ)⟩ _> ϕ[−]u_ [1][(][G][(][x][))] (22)
0, else



-----

Then,


Eθ _g_ _fˆ(x + θ)_ _u, ψ(θ)_ = E _γuI_ _γu > ϕ[−]u_ [1][(][G][(][x][))][}]
_∼_ _⟨_ _⟩_ _{_
h i ⩽ Φ(G(x))  (23)

which means that,
_|⟨∇G(x), u⟩| ⩽_ Φ(G(x)) (24)

and this is true for all u _n(1), so we have,_
_∈B_

max (25)
_u∈Bn(1)[⟨∇][G][(][x][)][, u][⟩]_ [⩽] [Φ(][G][(][x][))]


Consider a path from ξt : [0, _δ_ ] R[d] with ξ0 = x and ξ _δ_ = x + δ and ξt[′] [=]
_∥_ _∥_ _→_ _∥_ _∥_


_δ_

_∥δ∥_ [, we have]


dG(ξt)

= _G(ξt), u_ ⩽ Φ(G(ξt)). (26)
dt _⟨∇_ _⟩_


If the norm of δ satisfies that,


1

(27)
Φ(p) [d][p,]


_∥δ∥_ _<_


_G(x)_


1
if right hand side exists, we name it ∥δ0∥ = _G2(x)_ [1][/][Φ(][p][)d][p][. Without loss of generality, we assume]

that G(ξt) is increasing in t, then we cound calculate the minimalR _twhen G(ξt) increase to_ [1]2 [,]


1

(28)
Φ(p) [d][p][ =][ ∥][δ][0][∥][.]


_T =_


_G(ξ0)_


By the generality of δ we have,

for any δ < _δ0_ .
_∥_ _∥_


_G(x + δ) <_ [1]


(29)


This theorem is naturally extended to problems with p > 2 classes by considering the two top classes
which are G(x)A and G(x)B. This turns the problem into a binary classification problem.

A.1 THE PROOF OF THEOREM 1

**Theorem 1. Let f** (x) be any classifier and G(x) be the smoothed classifier defined in Eq. (1), if
_there exists a function M_ (·), and the transformation τ (·, ·) satisfies that

_∂γ(θ, ξ)_

= _[∂γ][(][θ, ξ][)]_ _M_ (θ, ξ),
_∂ξ_ _∂θ_


_and there exists two constants pA, pB that satisfies that_

_G(x)A ⩾_ _pA ⩾_ _pB ⩾_ _G(x)B,_

_then yA = arg maxi_ _G(τ_ (ξ, x))i holds for any _ξ_ ⩽ _R where_
_∈Y_ _∥_ _∥_

1 _pA_ 1
_R =_ (30)

2M _[∗]_ ZpB Φ(p) _[dp,]_


_here M_ = maxξ,θ _M_ (ξ, θ) _._

_[∗]_ _||_ _||_


-----

_Proof. WLOG, we only prove it for binary cases that f_ (·) : R[n] _→_ [0, 1].

_ξG(τ_ (γ(θ, ξ), x))
_∇_

_∂f_ (τ (γ(θ, ξ), x))
= _[∂τ]_ [(][γ][(][θ, ξ][)][, x][)] _g(θ)dθ_

_∂τ_ (γ(θ, ξ), x) _·_ _∂ξ_

Z

_∂f_ (τ (γ(θ, ξ), x)) _∂γ(θ, ξ)_
= _[∂τ]_ [(][γ][(][θ, ξ][)][, x][)] _g(θ)dθ_

_∂τ_ (γ(θ, ξ), x) _·_ _∂γ(θ, ξ)_ _∂ξ_

Z

_∂f_ (τ (γ(θ, ξ), x)) _∂γ(θ, ξ)_
= _[∂τ]_ [(][γ][(][θ, ξ][)][, x][)] _M_ (θ, ξ)g(θ)dθ

_∂τ_ (γ(θ, ξ), x) _·_ _∂γ(θ, ξ)_ _∂θ_

Z

_∂f_ (τ (γ(θ, ξ), x))
= _M_ (θ, ξ)g(θ)dθ

_∂θ_

Z


(31)


For u ∈ _R[d]_ and ∥u∥ = 1, we have:

_ξG(γ(ξ, x)), u_
_|⟨∇_ _⟩|_


_∂f_ (τ (γ(θ, ξ), x))

_M_ (θ, ξ)ug(θ)dθ (32)
_∂θ_

Z

_∂f_ (τ (γ(θ, ξ), x))

_M_ _[∗]_ _∥maxv∥=1_ Z _∂θ_ _vg(θ)dθ_ (33)

_M_ _[∗]_ maxv =1 _f_ (τ (γ(θ, ξ), x)) _[∂g]∂θ [(][θ][)]_ _[v][d][θ]_ (34)
_∥_ _∥_ Z

(35)


here M = maxθ,ξ _M_ (θ, ξ) and we assume that g(θ) = exp( _ψ(θ)):_

_[∗]_ _∥_ _∥_ _−_


_f_ (τ (γ(θ, ξ), x)) _[∂g]∂θ [(][θ][)]_ _[v][d][θ]_ (36)

_f_ (τ (γ(θ, ξ), x))g(θ)∇ψ(θ)vdθ (37)


_|⟨∇ξG(γ(ξ, x)), u⟩|_ ⩽ _M_ _[∗]_ maxv =1
_∥_ _∥_


_M_ _[∗]_ maxv =1 _f_ (τ (γ(θ, ξ), x))g(θ)∇ψ(θ)vdθ (37)
_∥_ _∥_ Z

_M_ _[∗]_ _∥maxv∥=1_ _[|][E][θ][∼][g][ [][f]_ [(][τ] [(][γ][(][θ, ξ][)][, x][))][⟨∇][ψ][(][θ][)][, v][⟩][]][|] (38)

_M_ _[∗]_ _∥maxv∥=1_ _f_ : G[ˆ](τ (ξ,xsup))=G(τ (ξ,x)) Eθ∼g[ f[ˆ](τ (γ(θ, ξ), x))⟨ψ(θ), u⟩] (39)


Similar with Theorem 4, the optimal _f[ˆ] achieves at_

_fˆ(τ_ (γ(θ, ξ), x)) = 1, if⟨ψ(θ), u⟩ _> ϕ[−]u_ [1][(][G][(][τ] [(][ξ, x][))))] (40)
0, else


Then we have
_|⟨∇ξG(τ_ (ξ, x)), u⟩| ⩽ Φ(G(τ (ξ, x))). (41)

Consider a path from ζt : [0, ∥δ∥] → R[d] with ζ0 = x and ζ∥δ∥ = τ (ξ, x) and ζt[′] [=] _∥δδ∥_ [, we have]

dG(ξt)

= _G(ξt), u_ ⩽ Φ(G(ξt)). (42)
dt _⟨∇_ _⟩_


The last part of proof is the same with Theorem 4.

A.2 THE PROOF OF THEOREM 2

**Theorem 2. Suppose f** (x) is any classifier and _G[˜](˜x) is the smoothed classifier defined in Eq. (7),_
_if there exists pA, pB that satisfies that_

_G˜(˜x)A ⩾_ _pA ⩾_ _pB ⩾_ _G[˜](˜x)B,_


-----

_then yA = arg maxi∈Y_ _G[˜](˜τ_ (ξ,[˜] ˜x))i for any ∥ξ∥2 ⩽ _R where_

1 _pA_ 1
_R =_ (43)

2M _[∗]_ ZpB Φ(p) _[dp,]_

_and the coefficient M_ _[∗]_ _is defined as_

2

_∂F2(yξ)_

_M_ _[∗]_ = maxξ,θ∈P s1 + _∂ξ_ _−_ _[∂F]∂θ[1][(][θ][)]_ 2. (44)

_Proof. In this part, we will prove Theorem 2, which is the main result in this paper. WLOG, we_
prove it for binary cases where f (·) : R[n] _→_ [0, 1]. First, we will calculate the gradient of _G[˜](˜τ_ (ξ,[˜] ˜x))
to _ξ[˜]:_

_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) = ∇ξ˜[E]θ[˜]∼g˜(θ[˜])[[ ˜]f (˜τ (θ,[˜] ˜τ (ξ,[˜] ˜x)))]. (45)

We expand the expectation into integral and use chain rule to see that


_∂f[˜](˜τ_ (θ,[˜] ˜yξ)) _τ_ (θ,[˜] ˜yξ) _yξ_

_[∂]_ [˜] _[∂]_ [˜] _g˜(θ[˜])dθ.[˜]_ (46)

R[n][+][d] _∂τ˜(θ,[˜]_ ˜yξ) _·_ _∂y˜ξ_ _·_ _∂ξ[˜]_


_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) =


The key step is to eliminate the gradient of _[∂]f[˜](˜τ_ (θ,[˜] _y˜ξ))_ and replace it with _[∂]f[˜](˜τ_ (θ,[˜] _y˜ξ))_ . Since:

_∂τ˜(θ,[˜]_ _y˜ξ)_ _∂θ[˜]_

_∂τ˜(θ,[˜]_ ˜yξ) = _σ1[′]_ [(][z]θ[′] [)] _F ′21[(][y]ξ[′]_ [)] _,_

_∂y˜ξ_ _σ2[′]_ [(][z][θ][)] _F22[′]_ [(][y][ξ][)]
   

_∂y˜ξ_ _H1′_ [(][z]ξ[′] [)] _Id_

= _._
_∂ξ[˜]_ _H2[′]_ [(][z][ξ][)] _F1[′][(][ξ][)]_ _In_
   


(47)

(48)


We have:

_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x))

here we define


_∂F[˜](˜τ_ (θ,[˜] ˜yξ)) _H1[′]_ [(][z]θ[′] [)] _F ′21[(][y]ξ[′]_ [)]

ZR[n][+][d] _∂τ˜(θ,[˜]_ ˜yξ) _·_  _H2[′]_ [(][z][θ][)]  _F22[′]_ [(][y][ξ][)]

_H1′_ [(][z]ξ[′] [)] _Id_

_g˜(θ[˜])dθ[˜]_ (49)

_H2[′]_ [(][z][ξ][)] _F1[′][(][ξ][)]_ _In_
   

_∂F[˜](˜τ_ (θ,[˜] ˜yξ)) _H1[′]_ [(][z]θ[′] [)] _Id_ _Id_

ZR[n][+][d] _∂τ˜(θ,[˜]_ ˜yξ) _·_  _H2[′]_ [(][z][θ][)] F1[′][(][θ][)] _In −F1[′][(][θ][)]_ _In_

_F ′21[(][y]ξ[′]_ [)] _H1′_ [(][z]ξ[′] [)] _Id_ _g˜(θ[˜])dθ[˜]_ (50)
_F22[′]_ [(][y][ξ][)] _H2[′]_ [(][z][ξ][)] _F1[′][(][ξ][)]_ _In_
     

_∂F[˜](˜τ_ (θ,[˜] ˜yξ)) _Id_ _F ′21[(][y]ξ[′]_ [)]

ZR[n][+][d] _∂θ[˜]_ −F1[′][(][θ][)] _In _ _F22[′]_ [(][y][ξ][)]

_H1′_ [(][z]ξ[′] [)] _Id_

_g˜(θ[˜])dθ[˜]_ (51)

_H2[′]_ [(][z][ξ][)] _F1[′][(][ξ][)]_ _In_
   

_∂F[˜](˜τ_ (θ,[˜] ˜yξ)) _M˜_ (ξ,[˜] _θ[˜])g(θ[˜])dθ,[˜]_ (52)
R[n][+][d] _∂θ[˜]_

Z


_F ′21[(][y]ξ[′]_ [)] _H1′_ [(][z]ξ[′] [)] _Id_
_F22[′]_ [(][y][ξ][)] _H2[′]_ [(][z][ξ][)] _F1[′][(][ξ][)]_ _In_
     


_M˜_ (ξ,[˜] _θ[˜]) ≜_ _Id_
−F1[′][(][θ][)] _In_


(53)


We consider the Unit enlargement, which means:


-----

_H1(z[′]) = z[′], F21(x[′]) = x[′]_ (54)


thus:

_M˜_ (ξ,[˜] _θ[˜]) =_ _Id_ _Od×n_ (55)
_F21[′]_ [(][y][ξ][)][ −] _[F][ ′]1[(][θ][)]_ _F22[′]_ [(][y][ξ][)][H]2[′] [(][z][ξ][)]
 

Since θ[′] is the virtual parameter introduced, which can be taken as 0 in case of actual disturbance.
Thus we only need to consider the projection of ∇ξ˜G[˜](˜yξ) in the space of ξ. Thus we set


(56)


_u˜ =_
 _On×1_


here u ∈ R[d] and ∥u∥ = 1. Assume

And we have


_g˜(θ[˜]) = exp(−ψ[˜](θ[˜]))_ (57)

_∂g˜(θ[˜])_

_∂θ[˜]_ = −g˜(θ[˜]) · ∇ψ[˜](θ[˜]). (58)


_∂f[˜](˜τ_ (θ,[˜] ˜yξ)) _M˜_ (ξ,[˜] _θ[˜])˜ug˜(θ[˜])dθ[˜]_
R[n][+][d] _∂θ[˜]_


_⟨∇ξ˜G[˜](˜yξ), ˜u⟩_


(59)

(60)

(61)

(62)

(63)


_∂f[˜](˜τ_ (θ,[˜] ˜yξ))
R[n][+][d] _∂θ[˜]_


_Id,_ _Od×n_
_F22[′]_ [(][y][ξ][)][ −] _[F][ ′]1[(][θ][)][,]_ _On×n_


_u˜g˜(θ[˜])dθ[˜]_


_∂f[˜](˜τ_ (θ,[˜] ˜yξ))

_M_ (ξ, θ)˜ug˜(θ[˜])dθ[˜]

R[n][+][d] _∂θ[˜]_


_∂f[˜](˜τ_ (θ,[˜] ˜yξ))

_v˜g˜(θ[˜])dθ[˜]_

R[n][+][d] _∂θ[˜]_

_g(θ[˜])_
_f˜(˜τ_ (θ,[˜] ˜yξ)) _[∂][˜]_ _v˜dθ[˜]_
R[n][+][d] _∂θ[˜]_


_M_ _[∗]_ _∥maxv˜∥2=1_

_M_ _[∗]_ _∥maxv˜∥2=1_

_M_ _[∗]_ _∥maxv˜∥2=1_

_M_ _[∗]_ _∥maxv˜∥2=1_


_f˜(˜τ_ (θ,[˜] ˜yξ))˜g(θ[˜]) _ψ(θ[˜])˜vdθ[˜]_ (64)
_∇_ [˜]
R[n][+][d]


= _M_ _[∗]_ maxv˜ 2=1 Eθ∼g _f˜(˜τ_ (θ,[˜] ˜τ (ξ, x[˜] )))⟨∇ψ[˜](θ[˜]), ˜v⟩ (65)
_∥_ _∥_

h i

We bound the right hand side by
_⟨∇ξ˜G[˜](˜yξ), ˜u⟩_ ⩽ _f_ : G[ˆ](τ (ξ,xsup))=G(τ (ξ,x)) _M_ _[∗]_ _∥maxv˜∥2=1_ Eθ∼g _fˆ(˜τ_ (θ,[˜] ˜τ (ξ, x[˜] )))⟨∇ψ[˜](θ[˜]), ˜v⟩ (66)

h i

b

and the optimal _f[ˆ] is as follows,_


_fˆ(˜τ_ (θ,[˜] ˜τ (ξ,[˜] ˜x)) = 1, if⟨ψ[˜](θ[˜]), ˜u⟩ _> ϕ[−]u_ [1][( ˜]G(˜τ (ξ,[˜] ˜x)))) (67)
0, else



here


_M_ (ξ, θ) = _Id,_ _Od×n_
F22[′] [(][y][ξ][)][ −] _[F][ ′]1[(][θ][)][,]_ _On×n_


(68)


-----

and M _[∗]_ is


_Id,_ _Od×n_
_F22[′]_ [(][y][ξ][)][ −] _[F][ ′]1[(][θ][)][,]_ _On×n_

_Id_
_∂F22(yξ)_

_∂ξ_ _−_ _[∂F]∂θ[1][(][θ][)]_ 2

_∂F22(yξ)_

1 +

_∂ξ_ _−_ _[∂F]∂θ[1][(][θ][)]_




_M_ _[∗]_ = maxξ,θ∈P

= max
_ξ,θ∈P_

= max
_ξ,θ∈P_


(69)


Notice that here F22( ) is the same as F2( ) the notations in the main text. Then we could apply the

_·_ _·_
techniques used in Theorem 1 and Theorem 4, we have:


_pA_

_pB_

Z


1

(70)
Φ(p) _[dp,]_


_R =_


2M _[∗]_


Thus we have proven this Theorem.

A.3 THE PROOF OF THEOREM 3

**Theorem 3. Suppose the simulation of the semantic transformation has an small enough error**

_∥τ˜(ξ,[˜]_ ˜x) − _τ_ (ξ,[˜] ˜x)∥ _< ε,_

_Then there exists a constant ratio A = A(∥F1[′][(˜]ξ)∥, ∥F2[′][(˜]yξ)∥, ∥F2[′][(˜]zξ)∥) > 0 does not depend on_
_the target classifier, we have the certified radius for the real semantic transformation satisfies that_

_Rr > R(1 −_ _Aε)_

_where R is the certified radius for surrogate the neural network in Theorem 2 and_


_pA_

_pB_

Z


_R =_


Φ(p) _[dp.]_


2M _[∗]_


_Proof. We set_

_u_
_u˜ =_
 _On×1_

here u ∈ R[d] and ∥u∥ = 1. Then we have


(71)

_u˜g˜(θ[˜])dθ[˜]_


_∂f[˜](˜τ_ (θ,[˜] ˜τ (ξ,[˜] ˜x))) _f_ (˜τ (θ,[˜] ¯τ (ξ,[˜] ˜x)))
_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) −∇ξ˜G[˜](¯τ (ξ,[˜] ˜x)), ˜uE = Z _∂ξ[˜]_ _−_ _[∂]_ [˜] _∂ξ[˜]_ ! _u˜g˜(θ[˜]_

_∂2 ˜f_ (˜τ (θ,[˜] ˆτ (ξ,[˜] ˜x)))
= _τ˜(ξ,[˜]_ ˜x) − _τ¯(ξ,[˜]_ ˜x) _∂ξ∂[˜]_ _τˆ_ _u˜g˜(θ[˜])dθ[˜]_
Z  


(72)

(73)


Set L = _[∂][2][ ˜]f_ (˜τ (θ,[˜] _τ¯(ξ,[˜]_ _x˜)))_, we have

_∂ξ∂[˜]_ _τˆ_


_∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x)))

_∂τˆ_


_∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x))) _∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x))

_∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x)) _∂τˆ_


_L =_ _[∂]_

_∂ξ[˜]_


= _[∂]_

_∂ξ[˜]_


Set yξ˜ [= ˜]τ (θ,[˜] ˆτ (ξ,[˜] ˜x)), we have:


-----

_∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x)) _H( F[˜]1(θ[˜]) + F[˜]2(ˆτ_ (ξ,[˜] ˜x)))

= _[∂]_ [˜]
_∂τˆ_ _∂τˆ_

= H[˜] _[′][ ]F˜1(θ[˜]) + F[˜]2(ˆτ_ (ξ,[˜] ˜x)) _∂F˜2(ˆτ_ (ξ,[˜] ˜x))

_∂τˆ_

= H[˜] _[′][ ]F˜1(θ[˜]) + F[˜]2(ˆτ_ (ξ,[˜] ˜x))  []F1I[′][(]d[θ][)] _In −FI1d[′][(][θ][)]_ _In ∂F˜2(ˆτ∂(τˆξ,[˜]_ ˜x))

= _[∂]τ[˜](θ,[˜]_ ˆ∂τθ[˜](ξ,[˜] ˜x)) −FI1d[′][(][θ][)] _In_ _F˜2′(ˆτ_ (ξ,[˜] ˜x))

_τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x))
= _[∂]_ [˜] _A1_

_∂θ[˜]_


(74)


here A1 = _Id_
−F1[′][(][θ][)] _In_


_F˜2′(ˆτ_ (ξ,[˜] ˜x)). By the proof above, we have


_F˜2′(ˆτ_ (ξ,[˜] ˜x)). By the proof above, we have _∂_ _∂_

_[θ][)]_ _In_ _∂ξ[˜]_ [=] _∂θ[˜][A][2][, thus we have:]_



_∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x))) _∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x))

_L =_ _[∂]_

_∂ξ[˜]_ _∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x)) _∂τˆ_ !

_∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x))) _∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x))

= _[∂]_ _A1_ _A2_ (75)

_∂θ[˜]_ _∂τ˜(θ,[˜]_ ˆτ (ξ,[˜] ˜x)) _∂θ[˜]_ !

_∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x)))

= _[∂]_ _A1_ _A2._

_∂θ[˜]_ _∂θ[˜]_ !

_∇ξ˜G[˜](˜τ_ (ξ,[˜] ˜x)) −∇ξ˜G[˜](¯τ (ξ,[˜] ˜x)), ˜u
D _∂2 ˜f_ (˜τ (θ,[˜] ˆτ (Eξ,[˜] ˜x)))

_τ˜(ξ,[˜]_ ˜x) − _τ¯(ξ,[˜]_ ˜x) _∂ξ∂[˜]_ _τˆ_ _u˜g˜(θ[˜])dθ[˜]_
Z   (76)

_∂_ _∂f[˜](˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x)))
_τ˜(ξ,[˜]_ ˜x) _τ¯(ξ,[˜]_ ˜x) _A1_ _A2u˜g˜(θ[˜])dθ[˜]_
_−_ _∂θ[˜]_ _∂θ[˜]_ !
Z  


⩽Aϵ[˜] _· |_ _f˜(˜τ_ (θ,[˜] ˆτ (ξ,[˜] ˜x)))˜g(θ[˜])⟨∇ψ[˜](θ[˜]), ˜u⟩ d θ[˜]|,
Z

where _A[˜] is a constant depending on ∥F1[′][(˜]ξ)∥, ∥F2[′][(˜]yξ)∥, ∥F2[′][(˜]zξ)∥. Then there exists A and we have_

_Rr ⩾_ _R(1 −_ _ϵA),_ (77)

where

1 _pA_ 1
_R =_

2M _[∗]_ ZpB Φ(p) _[dp]_

B IMPLEMENTATION DETAILS AND EXPERIMENTAL SETTINGS

B.1 PRACTICAL ALGORITHMS FOR CALCULATING M _[∗]_

For resolvable transformations in Theorem 1, the M _[∗]_ is defined as

_M_ _[∗]_ = maxξ,θ∈P _[∥][M]_ [(][ξ, θ][)][∥][.] (78)

Since if we have verified that the semantic transformation is resolvable, most of time we have a
closed form of M _[∗]_ like contrast/brightness transformation and we are able to calculate it analytically
as shown in Li et al. (2021).


-----

For non-resolvable transformations in Corollary 1, M _[∗]_ is defined as


1 + [1]

_σ1[2]_ _σ2[2]_


_∂F2(yξ)_

_A1_
_∂ξ_ _−_


_M_ _[∗]_ = maxξ∈P


(79)


This ratio is similar with the Lipschitz bound for a semantic transformation in Li et al. (2021).For low
dimensional semantic transformations, we are able to interpolate the domain to find a maximum M _[∗]_
and corresponding ξ. But this remains a challenge for high dimensional semantic transformations.
Specifically, for a given ξ, we need to compute the norm of _[∂F]∂ξ[2][(][y][ξ][)]_ _A1. The Jacobian matrix is_

_−_
_n × n. Caculating it requires n times of backpropagation. Thus it is inefficient to store the matrix or_
directly compute its norm. To solve the problem, we noitice that

2 2

_∂F2(yξ)_ _∂F2(yξ)_

_A1_ = max _A1_ _u_ _._ (80)
_∂ξ_ _−_ 2 _∥u∥2=1_  _∂ξ_ _−_  2

And then we have

_T_

_∂F2(yξ)_

_A1_ _u =_ _[∂]_ (81)
_∂ξ_ _−_ _∂ξ_

  _[⟨][F][2][(][y][ξ][)][ −]_ _[A][1][, u][⟩]_

Since tranposing a matrix does not change its norm, we could calculate its norm by optimizing u
that,

2

_∂_

max _._ (82)
_∥u∥2=1_ _∂ξ_ _[⟨][F][2][(][y][ξ][)][ −]_ _[A][1][, u][⟩]_ 2

Using this formulation, we only need to multiply the output with an unit vector and perform one
backpropagation. This is a simple convex optimization problem. Then we could use any iterative
algorithm to find its solution which is very fast to compute. This trick is crucial and it makes the
matrix norm computation to be scalable in practice.

B.2 OTHER DETAILS FOR EXPERIMENTS.

Our GSmooth requires to train two neural networks. First we randomly generate corrupted images
to train a image-to-image neural network. The training process of classifiers and certification for
semantic transformations are done on 2080Ti GPUs. We use a U-Net (Ronneberger et al., 2015) for
the surrogate model and replace all BatchNorm layers with GroupNorm (Wu & He, 2018) since we
might use the model in low bacthsize settings. The U-Net could be replace by other networks used
in image segmentation or superresolution like Res-UNet (Diakogiannis et al., 2020) or EDSR (Lim
et al., 2017). We use L1-loss to train the surrogate model which achieves better accuracy than others
which is also reported (Lim et al., 2017).

After train a surrogate model to simulate the semantic transformation. Then we train the base classifier for certification with a moderate data augmentation like (Li et al., 2021; Cohen et al., 2019) to
ensure that training and testing of the classifier is performed on the same distribution. There are two
types of data augmentation, one is the semantic transformation and the other is the augmented noise
introduced only in our work. Data augmentation based semantic transformation could be done using
both the surrogate model or the raw semantic transformation. We can only use the surrogate model
to add the augmented noise because this noise is a type of semantic noise in the layers of surrogate
model. In our experiments the standard deviation of the augmented noise is chosen from 0.1 ∼ 0.4
depending on the performance. The basic network architectures for these datasets are kept the same
with (Li et al., 2021). On CIFAR-100 daatsets, we use a PreResNet (He et al., 2016b) re-implement
the method by Li et al. (2021). We also adopt the progressive sampling trick mentioned in TSS (Li
et al., 2021) which is useful to reduce computational cost and certify larger radius. The details could
also be found in Li et al. (2021).

C SUPPLEMENTARY EXPERIMENTS

In this section, we report the results of our GSmooth under adaptive attacks to verify the tightness
of our certified bound. The experiments are conducted on CIFAR-10 dataset. We use expectation
of transformation to calculate the gradient of the model. Then we apply projected gradient descent


-----

|Col1|Cert Acc(%)|EoT attacks(%)|
|---|---|---|
|Gaussian blur Tanslation Rotation Rotational blur Defocus blur Pixelate|67.4 82.2 64.6 39.7 25.0 45.3|68.1 87.5 68.4 45.0 25.0 49.2|


Table 3: Accuracy of our GSmooth under adaptive attacks (PGD using expectation over transformations) on CIFAR-10 dataset.

|Type/Acc(%)|Augmix TSS Ours|
|---|---|
|Zoom blur|70.8 75.2 77.1|
|Defocus blur|72.2 75.6 76.8|
|Pixelate|50.9 76.0 76.7|
|Brightness|82.4 71.8 72.1|
|Motion blur|68.6 70.2 70.5|
|Gaussian blur|67.4 75.8 75.2|



Table 4: Empirical accuracy on subsets of CIFAR-10-C.

to find adversarial examples until it converged. Then we report the accuracy of our model on the
corrupted dataset. The result is listed in the following table. We found that the empirical attack is
no less than the certified accuracy. This shows that the bound for our model is effective. Additional,
some empirical results are much higher than the certified accuracy, which might indicate the bound
still has space for improvement.

We have conducted some experiments under the common benchmark CIFAR-10-C to show the
empirical robustness under these corruptions. We conducted the experiments on some subsets of
CIFAR-10-C. The corruption types of these subsets are related to the experiments in our paper. The
settings of these experiments and the results of baselines are from TSS(Li et al 2021).


-----


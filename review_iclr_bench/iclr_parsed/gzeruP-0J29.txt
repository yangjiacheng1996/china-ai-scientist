# REVISITING AND ADVANCING FAST ADVERSARIAL TRAINING THROUGH THE LENS OF BI-LEVEL OPTI## MIZATION

**Anonymous authors**
Paper under double-blind review

ABSTRACT

Adversarial training (AT) has become a widely recognized defense mechanism
to improve the robustness of deep neural networks against adversarial attacks. It
originated from solving a min-max optimization problem, where the minimizer
(i.e., defender) seeks a robust model to minimize the worst-case training loss in the
presence of adversarial examples crafted by the maximizer (i.e., attacker). However,
the min-max nature makes AT computationally intensive and thus difficult to scale.
Thus, the problem of FAST-AT arises. Nearly all the recent progress is achieved
based on the following simplification: The iterative attack generation method used
in the maximization step of AT is replaced by the simplest one-shot gradient signbased PGD method. Nevertheless, FAST-AT is far from satisfactory, and it lacks
theoretically-grounded design. For example, a FAST-AT method may suffer from
_robustness catastrophic overfitting when training with strong adversaries._
In this paper, we foster a technological breakthrough for designing FAST-AT
through the lens of bi-level optimization (BLO) instead of min-max optimization.
First, we theoretically show that the most commonly-used algorithmic specification
of FAST-AT is equivalent to the linearized BLO along the direction given by the
sign of input gradient. Second, with the aid of BLO, we develop a new systematic
and effective fast bi-level AT framework, termed FAST-BAT, whose algorithm is
rigorously derived by leveraging the theory of implicit gradient. In contrast to FASTAT, FAST-BAT has the least restriction to placing the tradeoff between computation
efficiency and adversarial robustness. For example, it is capable of defending
sign-based projected gradient descent (PGD) attacks without calling any gradient
sign method and explicit robust regularization during training. Furthermore, we
empirically show that our method outperforms state-of-the-art FAST-AT baselines.
In particular, FAST-BAT can achieve superior model robustness without inducing
robustness catastrophic overfitting and losing standard accuracy.

1 INTRODUCTION

Given the fact that machine learning (ML) models can be easily fooled by tiny adversarial perturbations (also known as adversarial attacks) on the input (Goodfellow et al., 2014; Carlini & Wagner,
2017; Papernot et al., 2016), learning robust deep neural networks (DNNs) is now a major focus in
research. Nearly all existing effective defense mechanisms (Madry et al., 2018; Zhang et al., 2019b;
Shafahi et al., 2019; Wong et al., 2020; Zhang et al., 2019a; Athalye et al., 2018a) are built on the adversarial training (AT) recipe, first developed in (Szegedy et al., 2014) and later formalized in (Madry
et al., 2018) using min-max optimization. In contrast to standard model training using empirical
risk minimization, AT (Madry et al., 2018) calls min-max optimization. That is, a minimizer (i.e.
defender) seeks to update model parameters against a maximizer (i.e. attacker) that aims to worsen
the training loss by perturbing each training example.

The AT-type defenses have been widely adopted in various application domains including image
classification (Goodfellow et al., 2014; Madry et al., 2018; Kurakin et al., 2017), object detection
(Zhang & Wang, 2019), natural language processing (Miyato et al., 2016; Zhu et al., 2019), and
healthcare (Finlayson et al., 2019; Mahmood et al., 2019). Despite their effectiveness, the min-max
optimization nature makes them difficult to scale. This is because multiple maximization steps


-----

(required by an iterative attack generator) are needed at every model training step in AT. The resulting
prohibitive computation cost prevents AT from a feasible solution to enhance adversarial robustness
when computing resource is limited. For example, Xie et al. (2019) used 128 GPUs to make AT
practical on ImageNet. Thereby, how to speed up AT without losing accuracy and robustness is now
a grand challenge for adversarial defense.

Very recently, some work attempted to develop computationally-efficient alternatives of AT, which we
call ‘fast’ versions of AT (Shafahi et al., 2019; Zhang et al., 2019a; Wong et al., 2020; Andriushchenko
& Flammarion, 2020). To the best of our knowledge, FAST-AT (Wong et al., 2020) and FAST-AT
with gradient alignment (GA) regularization, termed FAST-AT-GA (Andriushchenko & Flammarion,
2020), are the two state-of-the-art (SOTA) ‘fast’ versions of AT, since they achieve a significant
reduction in computation complexity and preserve accuracy and robustness to some extent. To
be specific, FAST-AT (Wong et al., 2020) replaces an iterative attack generator used in AT with
a heuristics-based single-step attack generation method. Thus, it merely takes computation cost
comparable to standard model training. However, FAST-AT suffers two main issues: (i) lack of
stability, i.e., large variance in performance (Li et al., 2020), and (ii) robustness catastrophic overfitting,
_i.e., a large drop of robustness when training with strong adversaries (Andriushchenko & Flammarion,_
2020). To alleviate these problems, Andriushchenko & Flammarion (2020) proposed FAST-AT-GA
by penalizing FAST-AT using an explicit robust regularization given by GA. However, we will show
that FAST-AT-GA encounters a new problem (iii): FAST-AT-GA hampers standard accuracy, making
a poor accuracy-robustness tradeoff at large attack budget (ϵ = 16/255), i.e. the improvement on RA
is at cost of a sharp drop on SA. Given the limitations (i)-(iii), we ask:

How to design a theoretically-grounded ‘fast’ version of AT with improved stability, mitigated
_catastrophic overfitting, and enhanced accuracy-robustness tradeoff_ ?

To address above question, paper we revisit and advance AT through the lens of bi-level optimization
(BLO) (Dempe, 2002), where we cast the attack generation problem as a lower-level optimization
problem with constraints and the defense as an upper-level optimization problem in the objective.
To the best of our knowledge, this is the first work to make a solid connection between adversarial
defense and BLO. Technically, we show that FAST-AT can be interpreted as BLO with linearized
lower-level problems. Delving into linearization of BLO, we propose a novel, theoretically-grounded
‘fast’ AT framework, fast bi-level AT (FAST-BAT). Practically, Table 1 highlights some achieved
improvements over FAST-AT and FAST-AT-GA: When a stronger train-time attack (i.e., ϵ = 16/255
vs. 8/255) is adopted, FAST-AT suffers a large degradation of robust accuracy (RA) and standard
accuracy (SA), together with higher variances than proposed FAST-BAT. Although FAST-AT-GA
outperforms FAST-AT, it still incurs a significant SA loss (over 21%) at ϵ = 16/255. By contrast,
FAST-BAT yields a more graceful SA-RA tradeoff: 9% improvement of SA without loss of RA.
Different from FAST-AT-GA, FAST-BAT achieves above improvements in stability, RA and SA
without resorting to any extra robust regularization and thus takes less computation cost.

Table 1: Performance overview of proposed FAST-BAT vs. the baselines FAST-AT (Wong et al., 2020) and
FAST-AT-GA (Andriushchenko & Flammarion, 2020) on (CIFAR-10, PreActResNet-18). All methods are
robustly trained under two perturbation budgets ϵ = 8/255 and 16/255 over 20 epochs. We use the early-stop
policy (Rice et al., 2020) to report the model of best robustness for each method. The evaluation metrics include
robust accuracy (RA) against PGD-50-10 attacks (50-step PGD attack with 10 restarts) (Madry et al., 2018) at
_ϵ = 8/255 and 16/255 (test-time ϵ is same as the train-time), RA against AutoAttack (AA) (Croce & Hein,_
2020) at ϵ = 8/255 and 16/255, and computation time (per epoch). The result a _b represents mean a and_
_±_
standard deviation b over 10 random trials. All experiments are run on a single Tesla-P100 GPU.

RA-PGD (%) RA-PGD (%) RA-AA (%) RA-AA (%) SA (%) SA (%)
Method Time (s)
(ϵ = 8/255) (ϵ = 16/255) (ϵ = 8/255) (ϵ = 16/255) (ϵ = 8/255) (ϵ = 16/255)

FAST-AT 45.47±0.39 21.79±0.93 41.97±0.15 12.57±0.33 81.72±0.36 46.02±2.79 42
FAST-AT-GA 47.43±0.42 26.22±0.19 43.52±0.32 18.03±0.39 79.84±0.49 58.57±1.19 150

**FAST-BAT** 48.74±0.11 26.15±0.12 44.89±0.12 18.21±0.15 79.43±0.08 67.79±0.08 135


**Contributions.** We summarize our contributions below.

x We propose a new formulation of adversarially robust training through the lens of BLO, yielding a
novel and theoretically-grounded interpretation of FAST-AT.

y We propose a new systematic and effective fast BLO-oriented AT framework, termed FAST-BAT,
with rigorously-established theory and algorithm.


-----

z We conduct extensive experiments on FAST-BAT, showing its improved stability, mitigated
catastrophic overfitting, and enhanced accuracy-robustness tradeoff; see illustrations in Table 1.

2 RELATED WORK

**Adversarial attack.** Adversarial attacks are techniques to generate malicious perturbations that are
imperceptible to humans but can mislead the machine learning (ML) models (Goodfellow et al., 2014;
Carlini & Wagner, 2017; Croce & Hein, 2020; Xu et al., 2019; Athalye et al., 2018b). A popular
threat model that an adversary used is known as ℓp-norm ball constrained attack (p 0, 1, 2, ).
_∈{_ _∞}_
This is also the focus of this paper. The adversarial attack has become a major approach to evaluate
the robustness of deep neural networks (DNNs) and thus, help build safe artificial intelligence in
many high stakes applications such as autonomous driving (Deng et al., 2020; Kumar et al., 2020),
surveillance (Thys et al., 2019; Xu et al., 2020), and healthcare (Finlayson et al., 2019).

**Adversarial defense and robust training at scale.** Our work falls into the category of robust
training, which was mostly built upon min-max optimization. For example, Madry et al. (2018)
established the framework of AT for the first time, which has been recognized as one of the most
powerful defenses (Athalye et al., 2018a). Extended from AT, TRADES (Zhang et al., 2019b) sought
the optimal balance between robustness and generalization ability. Further, AT-type defense has
been generalized to the semi-/self-supervised settings (Carmon et al., 2019; Chen et al., 2020) and
integrated 1 with certified defense techniques such as randomized smoothing (Salman et al., 2019).

Despite the effectiveness of AT and its variants, they need to take high computation costs. How to
speed up AT without losing performance remains an open question. Some recent works attempted
to impose algorithmic simplifications to AT, leading to fast but approximate AT algorithms, such
as ‘free’ AT (Shafahi et al., 2019), you only propagate once (YOPO) (Zhang et al., 2019a), FASTAT (Wong et al., 2020), and FAST-AT regularized by gradient alignment (termed FAST-AT-GA)
(Andriushchenko & Flammarion, 2020). In particular, FAST-AT and FAST-AT-GA are the baselines
most relevant to ours since they were designed with the least computation complexity. However,
their defense performance is far from satisfactory. For example, FAST-AT has poor training stability
(Li et al., 2020) and suffers catastrophic overfitting when facing strong attacks (Andriushchenko &
Flammarion, 2020). In contrast to FAST-AT, FAST-AT-GA yields improved robustness but has a
poor accuracy-robustness tradeoff (e.g., Table 1). In this paper, we aim to advance the algorithm
foundation of ‘fast robust training’ through the lens of BLO (bi-level optimization). We will show that
the proposed FAST-BAT can lead to stable robust learning without suffering catastrophic overfitting
and graceful tradeoff between accuracy and robustness.

**Bi-level optimization (BLO).** BLO is a unified hierarchical learning framework, where the objective and variables of an upper-level problem depend on the optimizer of certain lower-level problems.
The BLO problem in its most generic form is a class of very challenging problems, and thus, the
design of algorithms and theory for BLO focuses on special cases (Vicente et al., 1994; White
& Anandalingam, 1993; Gould et al., 2016; Ghadimi & Wang, 2018; Ji et al., 2020; Hong et al.,
2020). In practice, some successful applications of BLO to ML have been witnessed in meta-learning
(Rajeswaran et al., 2019), data poisoning attack design (Huang et al., 2020), and reinforcement
learning (Chen et al., 2019). However, as will be evident later, the existing BLO approach is not
directly applied to adversarial defense due to the presence of the constrained nonconvex lower-level
problem (for attack generation). To the best of our knowledge, our work makes a rigorous connection
between adversarial defense and BLO for the first time.

3 A BI-LEVEL OPTIMIZATION VIEW ON FAST-AT

**Preliminaries on FAST-AT.** FAST-AT is designed for solving the adversarial training problem
(Madry et al., 2018) given below

minimize E(x,y) maximize _ℓtr(θ, x + δ, y)_ _,_ (1)
**_θ_** _∈D_  **_δ∈C_** 

where θ ∈ R[n] denotes model parameters, D is the training set consisting of labeled data pairs
with feature x and label y, δ ∈ R[d] represents adversarial perturbations subject to the perturbation


-----

constraint, e.g., = **_δ_** **_δ_** _ϵ, δ_ [0, 1] for ϵ-toleration ℓ -norm constrained attack
_C_ _C_ _{_ _| ∥_ _∥∞_ _≤_ _∈_ _}_ _∞_
(normalized to [0, 1]), (x + δ) is then called adversarial example, and ℓtr( ) represents a training loss.

_·_

The standard solver to problem (1) is known as AT (Madry et al., 2018). However, it has to call an
_iterative optimization method (e.g., K-step PGD attack) to solve the inner maximization problem of_
(1). As a result, AT is computationally intensive. To improve its scalability, FAST-AT that only takes
the single-step PGD attack for inner maximization was proposed and successfully implemented in
(Wong et al., 2020). The algorithm backbone of FAST-AT is summarized below.

**FAST-AT algorithm**

Let θt be the model parameters at iteration t. The (t + 1)th iteration is given by
x (Inner maximization by 1-step PGD): δ (δ0 + α sign ( **_δℓtr(θt, x + δ0, y))),_**
_←−PC_ _·_ _∇_
where (a) denotes the projection operation that projects the point a onto, i.e., (z) =
_PC_ _C_ _PC_
arg minδ **_δ_** **z** 2[,][ δ][0] [is a random uniform initialization within][ [][0][,][ 1][]][,][ α >][ 0][ is a proper]
learning rate (y (Outer minimization for model training∈C ∥ _e.g. −, 1∥.[2]25ϵ), and sign(·) is the element-wise sign operation.): This can be conducted by any standard optimizer,_
_e.g., SGD. That is, θt+1_ **_θt_** _β_ **_θℓtr(θt, x + δ, y), where β > 0 is a proper learning rate_**
(e.g., cyclic learning rate), and ←− _− δ is provided from the inner maximization step.∇_


Roughly speaking, FAST-AT is a simplification of AT using 1-step PGD for inner maximization.
However, as shown in (Wong et al., 2020), the successful implementation of FAST-AT is different
from the 1-step PGD-based AT (Madry et al., 2018) due to the former’s sophisticated hyperparameter
choices in α, δ0, and β. Despite the efficacy of FAST-AT in some cases, Andriushchenko &
Flammarion (2020) demonstrated that it could lead to the issue of robustness catastrophic overfitting
when facing strong adversaries during training. In the literature, there was no grounded theory to
justify the pros and cons of FAST-AT. We will show that BLO provides a promising solution.

**BLO: Towards a unified formulation of robust training.** BLO (bi-level optimization) is a unified
hierarchical learning framework, involving two levels (i.e., upper and lower levels) of optimization
tasks, where one task is nested inside the other (i.e., the objective and variables of an upper-level
problem depend on the optimizer of the lower-level problem). The hierarchical learning framework
provided by BLO can be used to precisely depict a robust training paradigm. Specifically, we can
cast robustification as an upper-level problem whose optimization relies on a lower-level problem
defined for attack generation. Thus, the BLO formulation of (1) is given by

minimize E(x,y) [ℓtr(θ, x + δ[∗](θ; x, y), y)]
**_θ_** _∈D_ (2)

subject to **_δ[∗](θ; x, y) = arg min_** _ℓatk(θ, δ; x, y),_
**_δ∈C_**

where ℓatk denotes an attack objective. For notation simplicity, we will use data-omitted expressions
of ℓtr, ℓatk, and δ[∗]. The formulation (2) has two key differences from (1):

– First, the lower-level attack objective ℓatk is customizable, not necessarily to be same as the opposite
of the training objective, _ℓtr. As will be evident later, the flexibility of attack configuration in (2)_
_−_
enables us to interpret FAST-AT through the lens of BLO.

– Second, BLO calls an optimization routine different from min-max optimization used by (1). Even
if we setδ ∈C (see rigorous analysis in Appendix B ℓatk = −ℓtr, problem (2) does not reduce to (1) due to the presence of lower-level constraint). Specifically, solving the upper-level problem of (2) by
gradient descent yields

_dℓtr(θd, δθ_ _[∗](θ))_ = ∇θℓtr(θ, δ[∗](θ)) + _[d][δ][∗]d[(]θ[θ][)][⊤]_ _∇δℓtr(θ, δ[∗](θ)),_ (3)

IG

where the superscript denotes the transpose operation, and| {z } **_θℓtr(θ, δ[∗](θ)) denotes the partial_**
_⊤_ _∇_
derivative with respect to (w.r.t.) the first input argument θ. In (3), _[d][δ][∗]d[(]θ[θ][)][⊤]_ R[n][×][d] is referred to

_∈_
as implicit gradient (IG) because it is defined through an implicit constrained optimization problem
minδ _ℓatk. The dependence on IG is a ‘fingerprint’ of BLO (1) in contrast to AT or FAST-AT._
_∈C_

**BLO-enabled interpretation of FAST-AT.** In what follows, we demonstrate how FAST-AT relates
to BLO. Our main finding is summarized below.


-----

**Bi-level interpretation of FAST-AT**

FAST-AT can be interpreted as the lower-level linearized BLO with z = δ0 and λ = 1/α:

minimize E(x,y) [ℓtr(θ, δ[∗](θ))]
**_θ_** _∈D_ (4)

subject to **_δ[∗](θ) = arg minδ∈C_** [(δ − **z)[⊤]sign(∇δ=zℓatk(θ, δ)) + (λ/2)∥δ −** **z∥2[2][]][,]**

where z is the linearization point, ∇δ=zℓatk denotes the partial derivative of ℓatk (w.r.t. δ)
evaluated at z, sign( **_δ=zℓatk(θ, δ)) is the linearization direction, and λ > 0 is a regulariza-_**
_∇_
tion parameter associated with the quadratic residual of linearization.


Our justification on the above claim is elaborated on below.

– First, the simplified lower-level problem of (4) leads to the closed-form solution

**_δ[∗](θ) = arg min_** (λ/2) **_δ_** **z + (1/λ)sign(** **_δ=zℓatk(θ, δ))_** 2
**_δ∈C_** _∥_ _−_ _∇_ _∥[2]_

= (z (1/λ)sign( **_δ=zℓatk(θ, δ))),_** (5)
_PC_ _−_ _∇_

which is given by the 1-step PGD attack with initialization z and learning rate (1/λ). In the linearization used in (4), a quadratic regularization term (with regularization parameter λ) is introduced
to ensure the strong convexity of the inner-level attack objective within the constraint set δ ∈C.
Assisted by that, the lower-level solution is unique and its closed form is given by (5). Note that
imposing such a strongly convex regularizer is also commonly used to stabilize the convergence
of min-max optimization and BLO (Qian et al., 2019; Hong et al., 2020). If we set z = δ0 and
_λ = 1/α, then (5) precisely depicts the inner maximization step used in FAST-AT ._

– Second, by substituting (5) into the upper-level problem of (4), we can then follow (3) to update
the model parameters θ. However, this calls the computation of IG _[d][δ][∗]d[(]θ[θ][)][⊤]_ . If we regard PC is

differentiable, then based on the closed-form of δ[∗](θ) in (5), IG becomes


_dδ[∗](θ)[⊤]_

= 0, (6)
_dθ_

where we use two facts: (1) The linearization point z is independent of θ, i.e. z = δ0; And (2)
_dsign(dθ_ _·)_ = 0 holds almost everywhere. Please refer to Appendix C for a rigorous proof of (6) using

KKT conditions. Clearly, the use of gradient sign method simplifies the IG computation. Substituting
(6) into (3), the upper-level optimization of (4) yields θ **_θ_** _β_ **_θℓtr(θ, δ[∗](θ)) (with learning rate_**
_←−_ _−_ _∇_
_β), which is precisely same as the outer minimization step used in FAST-AT._

The aforementioned analysis shows that the linearized BLO (4) is equivalent to FAST-AT by setting
the linearization point z and the regularization parameter λ as z = δ0 and λ = 1/α.

4 FAST-BAT: ADVANCING FAST-AT BY BLO

**FAST-BAT and rationale.** The key take-away from (4) is that the conventional FAST-AT adopts
the sign of input gradient to linearize the lower-level attack objective. However, a more natural and
wiser choice is to use the first-order Taylor expansion for linearization. By doing so, problem (4) can
be modified to the form of FAST-BAT

minimize E(x,y) [ℓtr(θ, δ[∗](θ))]
**_θ_** _∈D_ (7)

subject to **_δ[∗](θ) = arg minδ∈C_** [(δ − **z)[⊤]∇δ=zℓatk(θ, δ) + (λ/2)∥δ −** **z∥2[2][]][,]**

where similar to (5), the lower-level problem can be solved analytically as

**_δ[∗](θ) =_** (z (1/λ) **_δ=zℓatk(θ, δ)) ._** (8)
_PC_ _−_ _∇_

In contrast to (6), the IG associated with (7) is no longer vacant since the gradient sign operation
is not present in (8). To compute IG, the auto-differentiation (which calls the chain rule) can be
applied to the closed-form of δ[∗](θ). However, this will not give us an accurate and generalizable IG
solution since the projection operation is not smooth and thus, the use of chain rule does not yield
_PC_
a rigorous derivation. Therefore, the IG challenge arises, which will be addressed in what follows.


-----

**IG theory for FAST-BAT.** The problem of FAST-BAT (7) falls into a class of very challenging
BLO problems, which require constrained lower-level optimization. The unconstrained case is easier
to handle since one can apply the implicit function theory to the stationary condition of the lower-level
problem to obtain IG (Hong et al., 2020). Yet, in the case of constrained problems, a stationary point
could violate the constraints, and thus the stationary condition becomes non-applicable.

In problem (7), we are dealing with a special class of lower-level constraints – linear constraints:

**I** min _ϵ1, 1_ **x**
= **_δ_** _ϵ, δ_ [ **x, 1** **x]** **Bδ** **b, with B :=** _, b :=_ _{_ _−_ _}_ _._ (9)
_C_ _{∥_ _∥∞_ _≤_ _∈_ _−_ _−_ _} ⇐⇒_ _≤_ **I** max _ϵ1,_ **x**
−  − _{−_ _−_ _}_

By exploiting above linearly constrained problem structure, we show that the IG challenge associated
with (7) can be addressed via Karush–Kuhn–Tucker (KKT) conditions. We summarize our main
theoretical result below and refer readers to Appendix A for detailed derivation.

**Theorem 1 With a Hessian-free assumption, i.e., ∇δδℓatk = 0, the IG (implicit gradient) of (7) is**

_dδ[∗](θ)[⊤]_

_dθ_ = −(1/λ)∇θδℓatk(θ, δ[∗])HC, with HC := 1p1<δ1∗[<q][1] **[e][1]** _· · ·_ 1p1<δd[∗][<q][d] **[e][d]** _,_ (10)

_where δ[∗]_ _is given by (8), and ∇θδℓ(θ, δ[∗]) ∈_ R[n][×][d] _denotes the second-order partial derivative_ 
_evaluated at θ and δ[∗](θ), respectively. In HC ∈_ R[d][×][d], 1pi<δi[∗][<q][i][ ∈{][0][,][ 1][}][ denotes the indicator]
_function over the constraint ofδi[∗]_ _[denotes the][ i][th entry of][ δ][∗][(][θ] {[)][,]δ[ p]i |[i] p[ = max]i < δi[∗][{−][< q][ϵ,][ −][i][}][x][, which returns][i][}][ and][ q][i][ = min][ 1][ if the constraint is satisfied,][{][ϵ,][ 1][ −]_ _[x][i][}][ characterize the]_
_boundary of the linear constraint (9) for the variablethe ith entry being 1 and others being 0s._ _δi, and ei ∈_ R[d] _denotes the basis vector with_

In Theorem 1, the rationale behind the Hessian-free assumption is that ReLU-based neural networks
commonly lead to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) ∇δδℓatk is close to zero.
In Appendix E, we will empirically show that the Hessian-free assumption is reasonable for both
ReLU and non-ReLU neural networks.

**FAST-BAT algorithm and implementation.** Similar to FAST-AT or AT, the FAST-BAT algorithm
follows the principle of alternating optimization. Specifically, it consists of the IG-based upper-level
gradient descent (3), interlaced with the lower-level optimal attack (8). We summarize the FAST-BAT
algorithm below.

**FAST-BAT algorithm**

The (t + 1)th upper-level iteration of FAST-BAT is given below
x (Lower-level solution): Obtain δ[∗](θt) from (8);
y (Upper-level model training): Integrating the IG (10) into (3), call SGD to update

**_θt+1 = θt_** _α1_ **_θℓtr(θt, δ[∗](θt))_** _α2(_ 1/λ) **_θδℓatk(θt, δ[∗](θt))H_** **_δℓtr(θt, δ[∗](θt)),_** (11)
_−_ _∇_ _−_ _−_ _∇_ _C∇_

where α1, α2 > 0 are learning rates associated with the standard model gradient and the
IG-augmented descent direction, respectively.


It is clear from (11) that to train a robust model, FAST-BAT can be dissected into the regular FAST-AT
update (i.e., α1-associated term) and the additional update that involves IG, (i.e., α2-associated term).
To successfully implement FAST-BAT, we highlight some key hyper-parameter setups different from
FAST-AT (Wong et al., 2020) and FAST-AT-GA (Andriushchenko & Flammarion, 2020).

**Remark 1 Choice of learning rate for IG-involved descent term: In (11), the choice of α2 could**
_affect the trade-off between accuracy and robustness (see empirical justification in Appendix E)._
_Clearly, if α2 = 0, then the upper-level model parameter updating step reduces to the standard_
FAST-AT. In Sec. 5.1, we will show that the α2-associated term plays a positive role in alleviating
_catastrophic robust overfitting. Meanwhile, λ in (7) could also affect the accuracy-robustness tradeoff._
_For example, if λ →∞, then δ = 0 (no robustness gain). Spurred by above, we choose the following_
_combination of α2 and λ, α2/λ = 0.1α1, which works well in practice; see Table A1._

**Remark 2 Choice of linearization point z: To specify (7), we investigate two classes of linearization**
_schemes. The first class is random constant linearization, which includes: “uniformly random_


-----

_linearization”, i.e., z = δ0 as FAST-AT, and “random corner linearization" under the ϵ-radius ℓ_ _-_
_∞_
_ball, i.e., z ∈{−ϵ, ϵ}[d]. The second class is 1-step perturbation warm-up-based linearization, which_
_includes the other two specifications: “1-step PGD" z = P_ (δ0 + α sign ( **_δℓtr(θt, δ0))), and_**
_C_ _·_ _∇_
_“1-step PGD w/o sign" z = P_ (δ0 + α **_δℓtr(θt, δ0)). We consider the aforementioned linearization_**
_C_ _∇_
_schemes since FAST-BAT combined with these linearizations takes computation cost comparable_
_to the baselines FAST-AT and FAST-AT-GA. Our experiments show that FAST-BAT using “1-step_
_PGD w/o sign" leads to the best defense performance; see justification in Table A3._

5 EXPERIMENTS

5.1 EXPERIMENT SETUP

**Datasets and model architectures.** We will evaluate the effectiveness of our proposal under
CIFAR-10 (Krizhevsky & Hinton, 2009) and ImageNet (Deng et al., 2009). Unless specified
otherwise, we will train DNN models PreActResNet (PARN)-18 (He et al., 2016b) for CIFAR-10,
and ResNet (RN)-50 (He et al., 2016a) for ImageNet. As a part of ablation study, we also train larger
models PARN-50 and WideResNet (WRN)-16-8 (Zagoruyko & Komodakis, 2016) on CIFAR-10.

**Baselines.** We consider three methods as our baselines: FAST-AT (Wong et al., 2020), FAST-ATGA (Andriushchenko & Flammarion, 2020), and PGD-2-AT (Madry et al., 2018), i.e., the 2-step
PGD attack-based AT. The primal criterion of baseline selection is computation complexity. The
training time of all methods including ours falls between the time of FAST-AT and that of FAST-ATGA. We remark that when evaluating on ImageNet, we only compare ours with FAST-AT since as
shown in Table 6 of (Andriushchenko & Flammarion, 2020), the other baseline methods did not show
improvement over Fast-AT at the attack budget ϵ = 2/255.

**Training details.** We choose the training perturbation strength ϵ ∈{2, 4, . . ., 16}/255 for CIFAR10 and ϵ = 2/255 for ImageNet following (Wong et al., 2020; Andriushchenko & Flammarion, 2020).
Throughout the experiments, we utilize an SGD optimizer with a momentum of 0.9 and weight
decay of 5 × 10[−][4]. For CIFAR-10, we train each model for 20 epochs in total, where we use cyclic
scheduler to adjust the learning rate. The learning rate linearly ascends from 0 to 0.2 within the first
10 epochs and then reduces to 0 within the last 10 epochs. Our batch size is set to 128 for all settings.
In the implementation of FAST-BAT, we adjust the hyperparameter λ from 255/5000 to 255/2000
based on the specification of train-time ϵ. For ImageNet, we strictly follows the setup given by Wong
et al. (2020). In FAST-BAT, we set λ = 255/3000. For each method, we use the early stopping
method to pick the model with best robust accuracy, following (Rice et al., 2020). All the CIFAR-10
experiments are conducted on a single Tesla P-100 GPU and all ImageNet experiments run on a
single machine with two Tesla P-100s. All the baselines are implemented using the recommended
training configurations in their official GitHub repos. We refer readers to Appendix D for more details
on training setup.

**Evaluation details.** For adversarial evaluation, we report robust test accuracy (RA) of a learned
model against PGD attacks (Madry et al., 2018) (RA-PGD). Unless otherwise specified, we set
the test-time perturbation strength (ϵ) same as the train-time value, and take 50-step PGD with 10
restarts for both CIFAR-10 and ImageNet evaluation. We also measure robust accuracy against
AutoAttacks (Croce & Hein, 2020), termed RA-AA. Further, we measure the standard accuracy (SA)
against natural examples. Results are averaged over 5 independent trials with different random seeds.

5.2 RESULTS Table 3: SA and RA on ImageNet.

**Overall performance of FAST-BAT.** In Table 2 and 3, we
compare the performance of our proposed FAST-BAT with base- FAST-BAT 60.18 44.64
lines on CIFAR-10 and ImageNet, respectively.

|Method SA (%) RA-PGD (%)|Col2|Col3|
|---|---|---|
|FAST-AT FAST-BAT|60.90 60.18|43.43 44.64|


_First, we find that FAST-BAT consistently outperforms the other baselines across datasets and attack_
types. For example, FAST-BAT at least improves 1.35% RA-PGD and 1.41% RA-AA with test-time
_ϵ = 8/255 in the training setup (CIFAR-10, ϵ = 8/255). On ImageNet, FAST-BAT outperforms_
FAST-AT by 1.23% when facing attacks with ϵ = 2/255.


-----

Table 2: SA, RA-PGD and RA-AA of different robust training methods in the setup (CIFAR-10, PARN-18
training with ϵ = 8/255) and (CIFAR-10, PARN-18 training with ϵ = 16/255), respectively. All the results are
averaged over 5 independent trials with different random seeds.

|Col1|Col2|CIFAR-10, PARN-18 trained with ϵ = 8/255|Col4|
|---|---|---|---|
|Method|SA (%)|RA-PGD (%) ϵ = 4 ϵ = 8 ϵ = 12 ϵ = 16|RA-AA (%) ϵ = 2 ϵ = 8 ϵ = 16|
|FAST-AT FAST-AT-GA PGD-2-AT FAST-BAT|81.89±0.31 79.78±0.47 83.26±0.28 79.47 ±0.14|65.92 ±0.11 45.44 ±0.38 23.69 ±0.34 9.56 ±0.26 65.74 ±0.19 47.32 ±0.35 28.67 ±0.26 11.57±0.32 65.59 ±0.34 44.71 ±0.42 23.67 ±0.35 9.42 ±0.33 66.26 ±0.08 48.67 ±0.18 29.87 ±0.46 14.00 ±0.21|72.54 ±0.20 41.95 ±0.13 7.91 ±0.06 71.60 ±0.39 43.45 ±0.27 9.48 ±0.15 73.28±0.15 41.73 ±0.20 7.54±0.25 72.07 ±0.22 44.86 ±0.34 11.51 ±0.20|



CIFAR-10, PARN-18 trained with ϵ = 16/255

|FAST-AT FAST-AT-GA PGD-2-AT FAST-BAT|46.13±2.25 58.53 ±1.20 69.40 ±0.30 67.81 ±0.18|42.74 ±0.91 37.17 ±0.74 27.99 ±0.72 21.92 ±0.71 51.71 ±0.99 43.86 ±0.67 35.46 ±0.36 26.29 ±0.14 59.25 ±0.16 48.79 ±0.31 32.12 ±5.63 24.30 ±0.46 59.35 ±0.13 49.05 ±0.12 37.71 ±0.36 26.07 ±0.28|36.31 ±2.20 31.66 ±0.27 12.48 ±0.29 53.61 ±1.10 38.69 ±0.56 18.11 ±0.36 61.90 ±0.28 41.59 ±0.22 15.40 ±0.29 62.16 ±0.14 43.64 ±0.26 18.18 ±0.34|
|---|---|---|---|



_Second, FAST-BAT leads to a better SA-RA trade-off compared with the other baselines. For_
example, in the setup of (CIFAR-10, PARN-18 trained with ϵ = 8/255), we observe that FAST-BAT
outperforms FAST-AT-GA in RA, without losing SA.And in the setup of (CIFAR-10, PARN-18
trained with ϵ = 16/255), FAST-BAT significantly outperforms FAST-AT-GA, with 9.28% SA
improvement and comparable or even better RA. Compared with PGD-2-AT, FAST-BAT is much
more resilient against strong adversaries, e.g., ϵ = 16.

_Third, the robustness advantage of our method becomes more notable when the test-time attack budget_
becomes smaller than the train-time budget. For examples, the RA-AA improvement of FAST-BAT
over FAST-AT-GA grows from 0.07% (evaluated at ϵ = 16/255) to 4.95% (evaluated at ϵ = 8/255),
and 8.55% (evaluated at ϵ = 2/255) in the case of (CIFAR-10, trained with ϵ = 16/255).

**Performance under different model architectures.** Besides PARN-18 reported above, Table 4
presents experiment results on both deeper (PARN-50) and wider (WRN-18-6) models. As we can
see, FAST-BAT consistently yields RA improvement over the other baselines. We also note that
PGD-2-AT could be a competitive baseline in terms of SA, e.g., the case of (PARN-50, ϵ = 8/255).
In contrast to FAST-AT and FAST-AT-GA, FAST-BAT is the only approach that yields an evident RA
improvement over PGD-2-AT.
Table 4: Performance of different robust training methods under different model types. All the models are both

|aluated with the same perturbation strength ϵ.|Col2|Col3|
|---|---|---|
|SA(%) RA-PGD(%) SA(%) RA-PGD(%) Model Method (ϵ = 8/255) (ϵ = 8/255) (ϵ = 16/255) (ϵ = 16/255)|||
|PARN-50|FAST-AT FAST-AT-GA PGD-2-AT FAST-BAT|73.15±6.10 41.03±2.99 43.86±4.31 22.08±0.27 77.40±0.81 46.16±0.98 42.28±6.69 22.87±1.25 83.53±0.17 46.17±0.59 68.88±0.39 22.37±0.41 78.91±0.68 49.18±0.35 69.01±0.19 24.55±0.06|
|WRN-16-8|FAST-AT FAST-AT-GA PGD-2-AT FAST-BAT|84.39±0.46 45.80±0.57 49.39±2.17 21.99±0.41 81.51±0.38 48.29±0.20 45.95±13.65 23.10±3.90 85.52±0.14 45.47±0.14 72.11±0.33 23.61±0.16 81.66±0.54 49.93±0.36 68.12±0.47 25.63±0.44|



**Mitigation of robustness catas-**
**trophic overfitting.** As shown in
(Andriushchenko & Flammarion,
2020), FAST-AT suffers robustness catastrophic overfitting when
the train-time and test-time attack
strength ϵ grows. Following (Andriushchenko & Flammarion, 2020),
Figure 1 presents two RA-PGD tra
(a) Without early stopping (b) With early stopping

jectories, i.e., training w/o early stop
Figure 1: RA-PGD of different robust training methods for (CIFAR
ping and training w/ early stopping,

10, PARN-18) with the same training and evaluation attack strengths.

versus the train- and test-time ϵ. As
we can see, FAST-AT encounters a sharp RA drop when ϵ > 8 when early stopping is not used,
consistent with (Andriushchenko & Flammarion, 2020). Assisted by early stopping, the overfitting


-----

of RA can be alleviated to some extent for FAST-AT, but its performance still remains the worst.
Moreover, different from (Andriushchenko & Flammarion, 2020), we find that PGD-2-AT yields
resilient performance against robustness catastrophic overfitting. Our implementation gives a more
positive baseline than the implementation of PGD-2-AT in (Andriushchenko & Flammarion, 2020),
since the latter did not use random initialization to generate train-time attacks. Furthermore, Figure 1
shows that our proposal mitigates the issue of robustness catastrophic overfitting and yields improved
RA over the other baselines. We highlight that such a achievement made by FAST-BAT is ‘free’ of
any robustness stability regularization, like gradient alignment used in FAST-AT-GA.

**Gradient alignment for ‘free’.** As shown by Andriushchenko &
Flammarion (2020), gradient alignment (GA) is a key performance
indicator to measure the appearance of robustness catastrophic overfitting. The insight from Figure 1 suggested that FAST-BAT can mitigate overfitting without using explicit GA regularization. Spurred by
above, Figure 2 presents the GA score versus the training epoch number, where GA characterizes the sensitivity of loss landscape against
random input perturbations; see derivations in (Andriushchenko &
Flammarion, 2020). The higher GA is, the more stable the robust
training is. Figure 2 shows that FAST-BAT automatically enforces Figure 2: GA evaluation.
GA and it outperforms FAST-AT and PGD-2-AT. FAST-BAT remains very close to FAST-AT-GA,
which maximizes GA using an extra train-time regularization The above empirical results imply
that gradient alignment may be just a necessary condition for avoiding catastrophic overfitting, but
not a sufficient one. A possible justification can be made from the perspective of the flatness of the
loss landscape. A higher gradient alignment implies a flatter loss landscape with respect to input
perturbations. However, the direct penalization on the norm of the input gradient may not achieve the
state-of-the-art model robustness.
Table 5: RA of robust PARN-18 trained by the four different methods against adaptive attacks (‘RA-PGD’ column)

**Sanity check for obfuscated gradients** and transfer attacks (‘Transfer Attack’ columns). Naturally
As pointed out by Athalye et al. (2018a), trained PARN-18, PARN-50, and WRN-16-8 are used as

summarizes the comparison between our

|urrogate models for PGD-20 attack with ϵ = 8/255.|Col2|Col3|
|---|---|---|
|RA-Transfer Attack(%) Method RA-PGD(%) PARN-18 PARN-50 WRN-16-8|||
|FAST-AT PGD-2-AT FAST-AT-GA FAST-BAT(Ours)|45.44 44.71 47.31 48.67|76.35 76.94 77.23 77.56 78.64 78.84 77.34 78.34 78.53 78.03 79.93 79.21|

proposal and the other baselines when facing white-box adaptive and black-box transfer attacks.
Firstly, RA increases if the transfer attack is present for each method, implying that the transfer attack
is weaker than the white-box adaptive attack. This is desired in the absence of obfuscated gradients.
Moreover, FAST-BAT consistently outperforms the other three baselines when defending against
both adaptive and transfer attacks. The absence of obfuscated gradients can also be justified by RA vs.
the growth of attack budget ϵ in Table 2, and the flatness of adversarial loss landscape in Figure. A1.

**Ablation studies.** In Appendix E, we present additional empirical studies including 1) the sensitivity
analysis of the linearization hyperparameter λ, 2) the choice of the linearization point, 3) the sensitivity
analysis of α2, 4) the influence of Hessian matrix on ReLU, and 5) non-ReLU neural networks.

6 CONCLUSION

In this paper, we introduce a novel bi-level optimization (BLO)-based fast adversarial training
framework, termed FAST-BAT. The rationale behind designing fast robust training through the lens
of BLO lies in two aspects. First, from the perspective of implicit gradients, we show that existing
FAST-AT framework is equivalent to the lower-level linearized BLO along the sign direction of input
gradient. Second, we show that FAST-BAT enables the least restriction to achieve improved staibility
of performance, mitigated catastrophic overfitting, and enhanced accuracy-robustness trade-off. To
the best of our knowledge, we for the first time establish the theory and the algorithmic foundation
of BLO for adversarially robust training. Extensive experiments are provided to demonstrate the
superiority of our method to state-of-the-art accelerated AT baselines.


-----

REFERENCES

Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, and Bernard Ghanem. On the decision
boundaries of deep neural networks: A tropical geometry perspective. arXiv preprint arXiv:2002.08838,
2020.

Maksym Andriushchenko and Nicolas Flammarion. Understanding and improving fast adversarial training.
_NeurIPS, 2020._

Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security:
Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018a.

Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. Synthesizing robust adversarial examples. In
_International Conference on Machine Learning, pp. 284–293, 2018b._

Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium
_on S&P, 2017._

Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John C Duchi. Unlabeled data improves
adversarial robustness. arXiv preprint arXiv:1905.13736, 2019.

T. Chen, S. Liu, S. Chang, Y. Cheng, L. Amini, and Z. Wang. Adversarial robustness: From self-supervised
pretraining to fine-tuning. In CVPR, 2020.

Zhangyu Chen, Dong Liu, Xiaofei Wu, and Xiaochun Xu. Research on distributed renewable energy transaction
decision-making based on multi-agent bilevel cooperative reinforcement learning. 2019.

Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse
parameter-free attacks. In International Conference on Machine Learning, pp. 2206–2216. PMLR, 2020.

Stephan Dempe. Foundations of bilevel programming. Springer Science & Business Media, 2002.

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical
image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pp.
248–255. IEEE, 2009.

Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, and Miryung Kim. An analysis of adversarial
attacks and defenses on autonomous driving models. In 2020 IEEE International Conference on Pervasive
_Computing and Communications (PerCom), pp. 1–10. IEEE, 2020._

Logan Engstrom, Andrew Ilyas, and Anish Athalye. Evaluating and understanding the robustness of adversarial
logit pairing. arXiv preprint arXiv:1807.10272, 2018.

Samuel G Finlayson, John D Bowers, Joichi Ito, Jonathan L Zittrain, Andrew L Beam, and Isaac S Kohane.
Adversarial attacks on medical machine learning. Science, 363(6433):1287–1289, 2019.

Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv preprint:1802.02246,
2018.

Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
_arXiv preprint arXiv:1412.6572, 2014._

Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On
differentiating parameterized argmin and argmax problems with application to bi-level optimization. arXiv
_preprint arXiv:1607.05447, 2016._

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
_Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016a._

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In
_European conference on computer vision, pp. 630–645. Springer, 2016b._

Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale framework for bilevel
optimization: Complexity analysis and application to actor-critic. arXiv preprint arXiv:2007.05170, 2020.

W Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, and Tom Goldstein. Metapoison: Practical
general-purpose clean-label data poisoning. arXiv preprint arXiv:2004.00225, 2020.

Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Nonasymptotic analysis and faster algorithms.
_arXiv preprint arXiv:2010.07962, 2020._


-----

A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s thesis, Department
_of Computer Science, University of Toronto, 2009._

K Naveen Kumar, C Vishnu, Reshmi Mitra, and C Krishna Mohan. Black-box adversarial attacks in autonomous
vehicle technology. In 2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), pp. 1–7. IEEE,
2020.

Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale. 2017 ICLR, arXiv
[preprint arXiv:1611.01236, 2017. URL http://arxiv.org/abs/1611.01236.](http://arxiv.org/abs/1611.01236)

Bai Li, Shiqi Wang, Suman Jana, and Lawrence Carin. Towards understanding fast adversarial training. arXiv
_preprint arXiv:2006.03089, 2020._

Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep
learning models resistant to adversarial attacks. In International Conference on Learning Representations,
2018.

Faisal Mahmood, Daniel Borders, Richard J Chen, Gregory N McKay, Kevan J Salimian, Alexander Baras, and
Nicholas J Durr. Deep adversarial training for multi-organ nuclei segmentation in histopathology images.
_IEEE transactions on medical imaging, 39(11):3257–3267, 2019._

Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semi-supervised text
classification. arXiv preprint arXiv:1605.07725, 2016.

Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and Pascal Frossard. Robustness via
curvature regularization, and vice versa. In Proceedings of the IEEE Conference on Computer Vision and
_Pattern Recognition, pp. 9078–9086, 2019._

Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. The
limitations of deep learning in adversarial settings. In Security and Privacy (EuroS&P), 2016 IEEE European
_Symposium on, pp. 372–387. IEEE, 2016._

Qi Qian, Shenghuo Zhu, Jiasheng Tang, Rong Jin, Baigui Sun, and Hao Li. Robust optimization over multiple
domains. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 4739–4746, 2019.

Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine. Meta-learning with implicit gradients.
_arXiv preprint arXiv:1909.04630, 2019._

Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. _arXiv preprint_
_arXiv:1710.05941, 2017._

Leslie Rice, Eric Wong, and Zico Kolter. Overfitting in adversarially robust deep learning. In International
_Conference on Machine Learning, pp. 8093–8104. PMLR, 2020._

Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, and Sebastien Bubeck.
Provably robust deep learning via adversarially trained smoothed classifiers. arXiv preprint arXiv:1906.04584,
2019.

Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S
Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free! In Advances in Neural Information
_Processing Systems, pp. 3353–3364, 2019._

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing properties of neural networks. International Conference on Learning Representations,
2014.

Simen Thys, Wiebe Van Ranst, and Toon Goedemé. Fooling automated surveillance cameras: adversarial
patches to attack person detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern
_Recognition Workshops, pp. 0–0, 2019._

Luis Vicente, Gilles Savard, and Joaquim Júdice. Descent approaches for quadratic bilevel programming.
_Journal of Optimization Theory and Applications, 81(2):379–399, 1994._

Douglas J White and G Anandalingam. A penalty function approach for solving bi-level linear programs.
_Journal of Global Optimization, 3(4):397–419, 1993._

Eric Wong, Leslie Rice, and J. Zico Kolter. Fast is better than free: Revisiting adversarial training. In
_International Conference on Learning Representations, 2020._


-----

Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan L Yuille, and Kaiming He. Feature denoising for
improving adversarial robustness. In Proceedings of the IEEE/CVF Conference on Computer Vision and
_Pattern Recognition, pp. 501–509, 2019._

Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang, and Xue
Lin. Structured adversarial attack: Towards general implementation and better interpretability. In ICLR, 2019.

Kaidi Xu, Gaoyuan Zhang, S. Liu, Quanfu Fan, Mengshu Sun, Hongge Chen, Pin-Yu Chen, Yanzhi Wang, and
Xue Lin. Adversarial T-Shirt! evading person detectors in a physical world. In ECCV, 2020.

Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.

Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong. You only propagate once:
Accelerating adversarial training via maximal principle. arXiv preprint arXiv:1905.00877, 2019a.

Haichao Zhang and Jianyu Wang. Towards adversarially robust object detection. In Proceedings of the IEEE/CVF
_International Conference on Computer Vision, pp. 421–430, 2019._

Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P Xing, Laurent El Ghaoui, and Michael I Jordan. Theoretically
principled trade-off between robustness and accuracy. ICML, 2019b.

Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced adversarial
training for natural language understanding. arXiv preprint arXiv:1909.11764, 2019.


-----

A PROOF OF THEOREM 1

**Proof: Upon defining g(θ, δ) = (δ −** **z)[⊤]∇δ=zℓatk(θ, δ) + (λ/2)∥δ −** **z∥2[2][, we repeat (7) as]**

minimize E(x,y) [ℓtr(θ, δ[∗](θ))]
**_θ_** _∈D_

(12)
subject to **_δ[∗](θ) = arg min_** _g(θ, δ),_
**Bδ≤b**

where we have used the expression of linear constraints in (9).

Our goal is to derive the IG _[d][δ][∗]d[(]θ[θ][)][⊤]_ shown in (3). To this end, we first build implicit functions by

leveraging KKT conditions of the lower-level problem of (12). We say δ[∗](θ) and λ[∗](θ) (Lagrangian
multipliers) satisfy the KKT conditions:

Stationarity: **_δg(θ, δ[∗](θ)) + B[⊤]λ[∗](θ) = 0,_**
_∇_
Complementary slackness : **_λ[∗](θ) · (Bδ[∗](θ) −_** **b) = 0** (13)
Dual feasibility: **_λ[∗](θ) ≥_** **0**

where · denotes the elementwise product.

_Active constraints and definition of B0: Let B0 denote the sub-matrix of B and b0 the sub-vector_
of b, which consists of only the active constraints at δ[∗](θ), i.e., those satisfied with the equality
**B0δ[∗](θ) = b0 (corresponding to nonzero dual variables). The determination of active constraints is**
done given θ at each iteration.


With the aid of (B0, b0), KKT (13) becomes

**_δg(θ, δ[∗](θ)) + B[⊤]0_** **_[λ][∗][(][θ][) =][ 0][,][ and][ B][0][δ][∗][(][θ][)][ −]_** **[b][0]** [=][ 0][,] (14)
_∇_

where the nonzero λ[∗](θ) only correspond to active constraints. We take derivatives w.r.t. θ for (14),
and thus obtain
_d_ **_δg(θ, δ[∗](θ))[⊤]_**
_∇_ + **_θλ[∗](θ)[⊤]B0 = 0_**

_dθ_ _∇_

= **_θδg(θ, δ[∗](θ)) +_** _[d][δ][∗][(][θ][)][⊤]_ **_δδg(θ, δ[∗](θ)) +_** **_θλ[∗](θ)[⊤]B0 = 0,_** (15)
_⇒∇_ _dθ_ _∇_ _∇_

IG

and _[d][δ][∗][(][θ][)][⊤]_ **B[⊤]0** [=][ 0]|[,] {z } (16)

_dθ_
IG

where **_θδ_** R[|][θ][|×|]| **_[δ]{z[|]_** denotes second-order partial derivatives (recall that} **_θ_** = n and **_δ_** = d).
According to (15), we have ∇ _∈_ _|_ _|_ _|_ _|_

_dδ[∗](θ)[⊤]_

= [ **_θδg(θ, δ[∗](θ)) +_** **_θλ[∗](θ)[⊤]B0]_** **_δδg(θ, δ[∗](θ))[−][1]._** (17)
_dθ_ _−_ _∇_ _∇_ _∇_

Substituting the above into (16), we obtain

_∇θδg(θ, δ[∗](θ))∇δδg(θ, δ[∗](θ))[−][1]B[⊤]0_ [+][ ∇][θ][λ][∗][(][θ][)][⊤][B][0][∇][δδ][g][(][θ][,][ δ][∗][(][θ][))][−][1][B]0[⊤] [=][ 0][,] (18)

which yields:

_∇θλ[∗](θ)[⊤]_ = −∇θδg(θ, δ[∗](θ))∇δδg(θ, δ[∗](θ))[−][1]B[⊤]0 [[][B][0][∇][δδ][g][(][θ][,][ δ][∗][(][θ][))][−][1][B]0[⊤][]][−][1][,] (19)

and thus,

_∇θλ[∗](θ)[⊤]B0 = −∇θδg(θ, δ[∗](θ))∇δδg(θ, δ[∗](θ))[−][1]B[⊤]0_ [[][B][0][∇][δδ][g][(][θ][,][ δ][∗][(][θ][))][−][1][B]0[⊤][]][−][1][B][0][.][ (20)]

Substituting (20) into (17), we obtain the IG


_dδ[∗](θ)[⊤]_

= **_θδg(θ, δ[∗](θ))_** **_δδg(θ, δ[∗](θ))[−][1]_** **_θλ[∗](θ)[⊤]B0_** **_δδg(θ, δ[∗](θ))[−][1]_**
_dθ_ _−∇_ _∇_ _−∇_ _∇_

= **_θδg(θ, δ[∗](θ))_** **_δδg(θ, δ[∗](θ))[−][1]_**
_−∇_ _∇_

+ ∇θδg(θ, δ[∗](θ))∇δδg(θ, δ[∗](θ))[−][1]B[⊤]0 [[][B][0][∇][δδ][g][(][θ][,][ δ][∗][(][θ][))][−][1][B]0[⊤][]][−][1][B][0][∇][δδ][g][(][θ][,][ δ][∗][(][θ][))][−][1][.]
(21)


-----

To further compute (21), the Hessian matrix ∇δδℓatk is needed. Recall from the definition of the
lower-level objective that the Hessian matrix is given by

_∇δδg(θ, δ[∗](θ)) = ∇δδℓatk + λI = 0 + λI._ (22)

Here we used the assumption that ∇δδℓatk = 0. The rationale behind that is neural networks
commonly leads to a piece-wise linear decision boundary w.r.t. the inputs (Moosavi-Dezfooli et al.,
2019; Alfarra et al., 2020), and thus, its second-order derivative (Hessian) ∇δδℓatk is close to zero.

Based on the simplification (22), we have

_dδ[∗](θ)[⊤]_

= (1/λ) **_θδg(θ, δ[∗](θ))_** **I** **B[⊤]0** [[][B][0][B]0[⊤][]][−][1][B][0]
_dθ_ _−_ _∇_ _−_

:=H

  _C_ 

(1/λ) **_θδℓatk(θ, δ[∗](θ))H_** _,_ (23)
_−_ _∇_ | _C_ {z }

where we have used the fact that **_θδg =_** **_θδℓatk._**
_∇_ _∇_

**I**
What is HC in (23)? Since B = −I, we can obtain that B0B[⊤]0 [=][ I][ and][ B]0[⊤][B][0] [is a sparse diagonal]

matrix with diagonal entries being 0 or 1. Thus, H can be first simplified to
_C_

**H** = I **B[⊤]0** **[B][0][.]** (24)
_C_ _−_

Clearly, H is also a diagonal matrix with either 0 or 1 diagonal entries. The 1-valued diagonal
_C_
entry of H corresponds to the inactive constraints in Bδ[∗](θ) < b, i.e., those satisfied with strict
_C_
_inequalities in_ **_δ_** _ϵ, 0_ **_δ_** **1** . This can be expressed as
_{∥_ _∥∞_ _≤_ _≤_ _≤_ _}_

**HC =** 1p1≤δ1∗[≤][q][1] **[e][1][, . . .,][ 1][p][1][≤][δ]d[∗][≤][q][d]** **[e][d]** (25)

where 1pi _δi[∗]_   _i_
returns 1 if the constraint is satisfied,≤ _[≤][q][i][ ∈{][0][,][ 1][}][ denotes the indicator function over the constraint] δi[∗]_ [denotes the][ i][th entry of][ δ][∗][(][θ][)][,][ p][i][ = max][ {][p][i][ ≤][{−][δ][∗][ϵ,][≤][ −][x][q][i][i][}][}][ and][ and]
_qbeingi = min 0s._ _{ϵ, 1 −_ _xi}, and ei ∈_ R[d] denotes the basis vector with the ith entry being 1 and others

Based on the definition of g, (23) and (25), we can eventually achieve the desired IG formula (10).
The proof is now complete. □


-----

B DISCUSSION ON CASE ℓatk = −ℓtr

We provide an explanation on the argument "Even if we set ℓatk = −ℓtr, problem (2) does not reduce
to problem (1) due to the presence of lower-level constraint" from the following two points.

-  In the absence of the constraint δ ∈C, if we set ℓatk = −ℓtr, then Problem 2 will reduce to
Problem 1.
This is a known BLO result (e.g. Ghadimi & Wang (2018)) and can be readily proven
using the stationary condition. To be specific, based on the stationary condition of unconstrained lower-level optimization, we have ∇δℓatk(θ, δ[∗]) = 0. Since ℓatk = −ℓtr, we have
_∇δℓtr(θ, δ[∗]) = 0. As a result, the second term in Eq. 3 becomes 0 and solving problem 2_
becomes identical to solving the min-max problem 1.

-  In the presence of the constraint δ ∈C, the stationary condition cannot be applied since the
stationary point may not be a feasible point in the constraint. In other words, ∇δℓatk(θ, δ[∗]) =
0 does not hold in the case of ℓatk = −ℓtr. As a matter of fact, one has to resort to KKT
conditions instead of the stationary condition for a constrained lower-level problem. Similar
to our proof in Theorem 1, the implicit gradient (and thus the second term of Eq. 3) cannot
be omitted in general. This makes problem 2 different from the problem 1.

C DERIVATION OF IMPLICIT GRADIENT FOR FAST-AT

We can derive Eq. 6 using KKT condition similar to Theorem 1. Specifically, let


_g(θ, δ) =_ sign( **_δ=zℓatk(θ, δ; x, y)), δ_** **z** + _[λ]_ 2[,] (26)
_⟨_ _∇_ _−_ _⟩_ 2 _[∥][δ][ −]_ **[z][∥][2]**


we have


**_θδg = 0._** (27)
_∇_

Following (21), we can further obtain (6) based on (27).

D DETAILED EXPERIMENT SETTINGS

D.1 TRAINING SET-UP

For CIFAR-10, we summarize the training setup for each method. 1) FAST-AT: We use FGSM with
an attack step size of 1.25ϵ to generate perturbations; 2) PGD-2-AT: 2-step PGD attacks[1] with an
attack step size of 0.5ϵ is implemented; 3) FAST-AT-GA: The gradient alignment regularization
parameter is set to the recommended value for each ϵ; 4) FAST-BAT: We select λ from 255/5000 to
255/2000 for different ϵ. At the same time, we adjust α2 accordingly, so that the coefficient of the
second term in (11), namely α2/λ always equals to 0.1α1.

For ImageNet, we set ϵ to 2/255, and we strictly follow the training setting adopted by Wong et al.
(2020). In FAST-BAT, we fix λ at 255/3000 and adopt the same α2 selection strategy as CIFAR-10.

**Parameter for FAST-AT-GA** Regarding FAST-AT-GA with different model types, we adopt the
same regularization parameter recommended in its official repo[2] intended for PreActResNet-18
(namely 0.2 for ϵ = 8/255 and 2.0 for ϵ = 16/255).

1We use random initialization to generate perturbations for PGD, while in the paper of FAST-AT-GA (Andriushchenko & Flammarion, 2020), 2-step PGD is initialized at zero point, which we believe will underestimate
the effect of PGD-2-AT
[2FAST-AT-GA: https://github.com/tml-epfl/understanding-fast-adv-training/](https://github.com/tml-epfl/understanding-fast-adv-training/blob/master/sh)
[blob/master/sh](https://github.com/tml-epfl/understanding-fast-adv-training/blob/master/sh)


-----

E ADDITIONAL EXPERIMENTAL RESULTS

**FAST-AT** **FAST-AT-GA** **FAST-BAT**

Figure A1: Visualization of adversarial loss landscapes of FAST-AT, FAST-AT-GA and FAST-BAT trained
using the ResNet-18 model on the CIFAR-10 dataset. The losses at are calculated w.r.t. the same image example
ID #001456, and the landscape is obtained by tracking the loss changes w.r.t. input variations following Engstrom
et al. (2018). That is, the loss landscape is generated by z = loss(I + x · r1 + y · r2), where I denotes an image,
and the x-axis and the y-axis correspond to linear coefficients associated with the sign-based attack direction
**r1 = sign(∇I** loss(I)) ˆx and a random direction r2 ∼ Rademacher(0.5), respectively.

**Sensitivity to regularization parameter λ**
In Table A1, we show the sensitivity of FAST- Table A1: Performance of FAST-BAT with different
BAT to the regularization parameter λ. All the parameter λ. We train and evaluate with the same attack
parameters remain the same as default setting, budget ϵ = 16/255 on CIFAR-10 to show the influence
except that for different λ. We always adjust brought by λ.
_α2 so that α2/λ = 0.1α1 holds. Note 1/λ also_ CIFAR-10, PreActResNet-18, ϵ = 16/255
serves as the attack step in (8). As λ decreases,
the improvement on robust accuracy is evidently
strengthened, and there is a obvious trade-off SA (%) **83.20** 75.06 69.31 67.81 67.59
between robust accuracy (SA) and standard ac
|CIFAR-|-10, PreActResNet-18, ϵ = 16/255|
|---|---|
|1/λ (/255)|500 1000 1500 2000 2500|
|SA (%) 83.20 75.06 69.31 67.81 67.59 RA-PGD (%) 19.02 21.42 23.34 26.07 26.12||

curacy (RA). At a certain level of λ, namely
when λ ≤ 255/2000, RA starts to converge and stop surging.

**Sensitivity to different α2 choices** We consider the case of robust training with the large ϵ Table A2: Performance of FAST-BATwith different α2

choices on CIFAR-10. Models are trained and evaluated

choice (16/255). As we can see from Table A2,

with the same attack budget (ϵ = 16/255). Here α1 is

if α2 is set too small (α2 = 0.008α1), then both

set as the cyclic learning rate and thus, is not a constant

SA and RA will drop significantly. Here α1 is parameter. α2 is always set proportionate to α1 for
set as the cyclic learning rate and thus not a simplicity.
constant parameter. However, in the α2 inter- _α2 (CIFAR-10,_
val [0.0125α1, 0.025α1], we observed a tradeoff **PreActResNet18,** **0.025α1** **0.0167α1** **0.0125α1** **0.008α1**
between standard accuracy (SA) and robust ac- _ϵ = 16/255)_
curacy (RA): That is, the improvement in RA SA (%) **75.06** 69.31 67.81 57.92
corresponds to a loss in SA. In our experiments, RA-PGD (%) 21.42 23.34 **26.07** 20.53
we choose α2 when the tradeoff yields the best
RA without suffering a significant drop of SA (which still outperforms the baseline approaches).

**Sensitivity of linearization schemes** Fast
Table A3: Performance of FAST-BAT with different

BAT needs a good linearization point z in (7).

linearization schemes. Besides 1-step PGD without sign

In experiments, we adopt the perturbation gener- (PGD w/o Sign), we further generate linearization point
ated by 1-step PGD without sign as our default with the following methods: uniformly random noise
linearization scheme. In Table A3, we show [−ϵ, ϵ][d] (Uniformly Random); uniformly random corthe performance of the other possible lineariza- ner {−ϵ, ϵ}[d] (Random Corner); and perturbation from
tion options. We can find 1-step PGD without 1-step PGD attack with 0.5ϵ as attack step (PGD).
sign achieves best robust accuracy among all the
choices. This is not spurring since this linearization point choice is consistent with the first- Linearization PGD Uniformly Random PGD
Taylor expansion that we used along the direction of input gradient without sign involved. By SA (%) 69.31 43.42 62.19 **75.30**
contrast, FAST-BAT linearized with uniformly

|CIFAR|R-10, PreActResNet-18, ϵ = 16/255|
|---|---|
|Linearization Method|PGD Uniformly Random PGD w/o Sign Random Corner|
|SA (%) 69.31 43.42 62.19 75.30 RA-PGD (%) 23.34 21.25 16.5 19.42||

random noise suffers from catastrophic overfitting and reaches a rather low standard accuracy (SA).
FAST-BAT with other linearizations also yields worse SA-RA trade-off than our proposal.


-----

Table A4: Performance of Hessian-free and Hessian-aware FAST-BATon CIFAR-10. We train and evaluate
with the same attack budgets ϵ = 8/255 and ϵ = 16/255 to show the influence brought by Hessian matrix.

**RA-PGD (%)** **RA-PGD (%)** **RA-AA (%)** **RA-AA (%)** **SA (%)** **SA (%)** **Time**
**Method**
**(ϵ = 8/255)** **(ϵ = 16/255)** **(ϵ = 8/255)** **(ϵ = 16/255)** **(ϵ = 8/255)** **(ϵ = 16/255)** **(s/epoch)**

Hessian-free
48.67 26.07 44.86 18.18 79.47 67.81 135
Fast-BAT

Hessian-aware
48.52 26.12 44.81 18.31 79.54 67.93 179
Fast-BAT

Table A5: Performance of FAST-ATand FAST-BATwith different activation functions on CIFAR-10. ReLU,
Swish and Softplus are taken into consideration. For FAST-BAT, we compare the Hessian-free and Hessian-aware
version to verify the influence of Hessian matrix. The results are averaged over 3 independent trials.

**SA (%)** **RA-PGD (%)** **SA (%)** **RA-PGD (%)** **Time**
**Setting**
**(ϵ = 8/255)** **(ϵ = 8/255)** **(ϵ = 16/255)** **(ϵ = 16/255)** **(s/epoch)**

Fast-AT-ReLU 81.88 45.44 46.13 21.75 42
Fast-BAT-ReLU
79.54 48.52 67.93 26.12 179
(Hessian-aware)

Fast-BAT-ReLU
79.47 48.67 67.81 26.07 135
(Hessian-free)

Fast-AT-Softplus 81.29 47.26 45.39 22.40 42
Fast-BAT-Softplus
79.59 49.74 68.63 25.54 178
(Hessian-aware)

Fast-BAT-Softplus
79.48 49.67 68.57 25.59 137
(Hessian-free)


Fast-AT-Swish 75.61 44.43 52.03 23.08 49
Fast-BAT-Swish
73.93 45.97 62.49 23.99 196
(Hessian-aware)

Fast-BAT-Swish
73.89 45.90 62.59 23.81 141
(Hessian-free)

**Influence of Hessian matrix** In Theorem 1, the Hessian-free assumption, i.e.∇δδℓatk = 0, was
made to simplify the computation of IG term (implicit gradient). To examine how the Hessian matrix
_∇δδℓatk affects the performance of Fast-BAT, we conduct experiments to compare the Hessian-free_
FAST-BATwith the Hessian-aware version. In Hessian-aware FAST-BAT, the implicit gradient is
calculated based on (21). In Table A4, the results do not indicate much difference when Hessian is
used. However, the extra calculation brought by Hessian heavily slows down FAST-BATas around
30% more time is needed. Therefore, the Hessian-free assumption is reasonable and also necessary
in terms of the efficiency of the algorithm.

**Ablation study on smooth activation functions** The Hessian-free assumption is based on the
fact that the commonly used ReLU activation function is piece-wise linear w.r.t. input. We further
conduct experiments to verify the feasibility of such assumption on models with non-ReLU activation
functions. We choose two commonly used activation functions, Swish(Ramachandran et al., 2017)
and Softplus, as alternatives for non-smooth ReLU function. We compare the results both calculating
Hessian as well as the Hessian-free version to see if the Hessian-free assumption still holds for the
non-ReLU neural network. The results are shown in Table A5. As we can see, the use of Hessian does
not affect performance much. A similar phenomenon can be observed across different ϵ and different
model activation functions (ReLU, Softplus, and Swish). However, the introduction of Hessian leads
to an increase in time consumption by more than 30%. Therefore, we can draw the conclusion that
the Hessian-free assumption is reasonable across different activation function choices.


-----


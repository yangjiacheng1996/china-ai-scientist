## ENERGY-BASED LEARNING FOR COOPERATIVE GAMES, WITH APPLICATIONS TO VALUATION PROB### LEMS IN MACHINE LEARNING

**Yatao Bian[1][∗], Yu Rong[1], Tingyang Xu[1], Jiaxiang Wu[1], Andreas Krause[2], Junzhou Huang[1]**

1 2
Tencent AI Lab ETH Zürich

ABSTRACT

Valuation problems, such as feature interpretation, data valuation and model valuation for ensembles, become increasingly more important in many machine
learning applications. Such problems are commonly addressed via well-known
game-theoretic criteria, such as the Shapley value or Banzhaf value. In this work,
we present a novel energy-based treatment for cooperative games, with a theoretical justification via the maximum entropy principle. Surprisingly, through
mean-field variational inference in the energy-based model, we recover classical
game-theoretic valuation criteria by conducting one-step of fixed point iteration for
maximizing the ELBO objective. This observation also further supports existing
criteria, as they can be seen as attempting to decouple the correlations among
players. By running the fixed point iteration for multiple steps, we achieve a trajectory of the variational valuations, among which we define the valuation with the
best conceivable decoupling error as the Variational Index. We prove that under
uniform initialization, these variational valuations all satisfy a set of game-theoretic
axioms. We empirically demonstrate that the proposed variational valuations enjoy
lower decoupling error and better valuation performance on certain synthetic and
real-world valuation problems.[1]

1 INTRODUCTION


Valuation problems are becoming increasingly moresignificant in various machine learning applications, **Shapley** **Energy Based Modela cooperative game** for:
ranging from feature interpretation (Lundberg and **Banzhaf** (𝑁, 𝐹S )
Leeto model valuation for ensembles (, 2017), data valuation (Ghorbani and ZouRozemberczki and, 2019) **Player valuations cooperative games** in minMean field variational parameters𝐱 as[KL(𝑞S; 𝐱||𝑝S )] principled player valuations
Sarkar, 2021). They are often formulated as a player -step
valuation problem in cooperative games. A cooper- 𝐱 Variational Values
ative gameN = 1, ..., n (N, F of(S n)) players and a value function consists of a grand coalition qproblems Feature interpretationValuation in ML 𝑞S; 𝐱 𝐱[!] 𝐾 𝐱[!]⋯ 𝐱𝑝S[∗]
(a.k.a. characteristic function)scribing the collective payoff of a coalition/coopera- { _}_ _F_ (S) : 2[N] _→_ R de- qq Data valuation Model valuation fixed pointiteration **Recovering- Shapley- Banzhaf𝐱[𝐾]**
tion S. A fundamental problem in cooperative game ?

**Energy Based Model for**

**Shapley** a cooperative game :

**Banzhaf** (𝑁, 𝐹S )

𝑝S ∝exp 𝐹S /𝑇

**Player valuations in** Mean field variational parameters
cooperative games min𝐱 as[KL(𝑞S; 𝐱||𝑝S )] principled player valuations

-step

Variational Values

𝐱

**Valuation** 𝐾

qproblems Feature interpretation in ML 𝑞S; 𝐱 𝐱[!] 𝐱[!]⋯ 𝐱𝑝S[∗]
qq Data valuation Model valuation fixed pointiteration **Recovering- Shapley𝐱[𝐾]**

- Banzhaf

# ?

theory is to assign an importance vector (i.e., solution Figure 1: An energy based treatment of coopconcept) φ(F ) ∈ R[n] to n players. valuations:erative games leads to a series of new player K-step variational values, satis
In this paper, we explore a probabilistic treatment fying basic valuation axioms: null player,
of cooperative games (N, F (S)). Such a treatment marginalism & symmetry.
makes it possible to conduct learning and inference
in a unified manner, and will yield connections with classical valuation criteria. Concretely, we
seek a probability distribution over coalitions p(S = S)[2], measuring the odds that a specific coalition

_∗Correspondence to: Yatao Bian <yatao.bian@gmail.com>_
[1Project page & code: https://valuationgame.github.io](https://valuationgame.github.io)
2Note that distributions over subsets of N are equivalent to distributions of |N _| = n binary random variables_
_Xabuse of notation, we use1, ..., Xn ∈{0, 1}: We use S as a random variable represented as sets and often abbreviate Xi as the indicator function of the event i ∈_ _S, or Xi = [ pi( ∈S =S S]. With slight) as p(S)._


-----

_S happens. Generally, we consider distributions where the probability of a coalition p(S) grows_
monotonically with the payoff F (S).

Among all the possible probability mass functions (pmfs), how should we construct the proper
_p(S)? We advocate to choose the pmf with the maximum entropy H(p). This principle makes sense_
since maximizing the entropy minimizes the amount of prior information built into the distribution.
In other words, it amounts to assuming nothing about what is unknown, i.e., choosing the most
“uniform” distribution. Now finding a proper p(S) becomes the following constrained optimization
problem: suppose each coalition S is associated with a payoff F (S) with probability p(S). We
would like to maximize the entropy H(p) = − [P]S⊆N _[p][(][S][) log][ p][(][S][)][, subject to the constraints that]_

_S_ _[p][(][S][) = 1][, p][(][S][)][ ≥]_ [0][ and][ P]S _[p][(][S][)][F]_ [(][S][) =][ µ][ (i.e., the average payoff is known as][ µ][). Solving]

this optimization problem (derivation in Appendix A), we reach the maximum entropy distribution:

P

_p(S) = [exp(][F]_ [(][S][)][/T] [)] _,_ Z := (1)

Z _S[′]⊆N_ [exp(][F] [(][S][′][)][/T] [)][,]
X

where T > 0 is the temperature. This is an energy-based model (EBM, cf. LeCun et al., 2006) with
_−F_ (S) as the energy function.

The above energy-based treatment admits two benefits: i) Where supervision is available, it enables
learning of value functions F (S) through efficient training techniques for energy-based learning,
such as noise contrastive estimation (Gutmann and Hyvärinen, 2010) and score matching (Hyvärinen,
2005). ii) Approximate inference techniques such as variational inference or sampling can be adopted
to solve the valuation problem. Specifically, it enables to perform mean-field variational inference
where parameters of the inferred surrogate distribution can be used as principled player valuations.

Below, we explore mean-field variational inference for the energy-based formulation (Fig. 1). Perhaps
surprisingly, by conducting only one-step fixed point iteration for maximizing the mean-field (ELBO)
objective, we recover classical valuation criteria, such as the Shapley value (Shapley, 1953) and the
Banzhaf value (Penrose, 1946; Banzhaf III, 1964). This observation also further supports existing
criteria, motivating them as decoupling the correlations among players via the mean-field approach.
By running the fixed point iteration for multiple steps, we achieve a trajectory of valuations, among
which we define the valuation with the best conceivable decoupling error as the Variational Index.
Our major contributions can be summarized as below:

i) We present a theoretically justified energy-based treatment for cooperative games. Through mean
field inference, we provide a unified perspective on popular game-theoretic criteria. This provides an
alternative motivation of existing criteria via a decoupling perspective, i.e., decoupling correlations
among n players through the mean-field approach. ii) In pursuit of better decoupling performance,
we propose to run fixed point iteration for multiple steps, which generates a trajectory of valuations.
Under uniform initializations, they all satisfy a set of game-theoretic axioms, which are required for
being suitable valuation criteria. We define the valuation with the best conceivable decoupling error as
the Variational Index. iii) Synthetic and real-world experiments demonstrate intriguing properties of
the proposed Variational Index, including lower decoupling error and better valuation performance.

2 PRELIMINARIES AND BACKGROUND

**Notation.and x ∈** R We assume[n] interchangebly to indicate an ei ∈ R[n] being the standard n-dimensional vector, where i[th] basis vector and use boldface letters xi is the i[th] entry of x ∈ x. ByR[N]
default, f (·) is used to denote a continuous function, and F (·) to represent a set function. For a
differentiable function f ( ), _f_ ( ) denotes its gradient. x _xi_ _k is the operation of setting the i[th]_
element oftwo sets S x and to T k, while keeping all other elements unchanged, i.e.,, S + T and· _∇ S −·_ _T represent set union and set difference, respectively.|_ _←_ **x|xi ←** _k = x −_ _xiei + | kSe| is thei. For_
cardinality of S. i is used to denote the singleton {i} with a bit abuse of notation.

**Existing valuation criteria. Various valuation criteria have been proposed from the area of coop-**
erative games, amongst them the most famous ones are the Shapley value (Shapley, 1953) and the
Banzhaf value, which is extended from the Banzhaf power index (Penrose, 1946; Banzhaf III, 1964).
For the Shapley value, the importance assigned to player i is:


_._ (2)

_S⊆N_ _−i[[][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)]] _[|][S][|][!(][n][ −|]n![S][| −]_ [1)!]


Shi =


-----

One can see that it gives less weight to n/2-sized coalitions. The Banzhaf value assigns the following
importance to player i:

1

Bai = (3)

_S_ _N_ _i[[][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)]] 2[n][−][1][,]
_⊆_ _−_

which uses uniform weights for all the coalitions. SeeX Greco et al. (2015) for a comparison of them.

**Valuation problems in machine learning. Currently, most classes of valuation problems (Lundberg**
and Lee, 2017; Ghorbani and Zou, 2019; Sim et al., 2020; Rozemberczki and Sarkar, 2021) use
Shapley value as the valuation criterion. Along with the rapid progress of model interpretation in the
past decades (Zeiler and Fergus, 2014; Ribeiro et al., 2016; Lundberg and Lee, 2017; Sundararajan
et al., 2017; Petsiuk et al., 2018; Wang et al., 2021a), attribution-based interpretation aims to assign
importance to the features for a specific data instance (x ∈ R[N] _, y) given a black-box model M. Here_
each feature maps to a player in the game (N, F (S)), and the value function F (S) is usually the
model response, such as the predicted probability for classification problems, when feeding a subset
_S of features to M. The data valuation problem (Ghorbani and Zou, 2019) tries to assign values_
to the samples in the training dataset N = {(xi, yi)}1[n] [for general supervised machine learning:]
one training sample corresponds to one player, and the value function F (S) indicates the predictor
performance on some test dataset given access to only a subset of the training samples in S. Model
valuation in ensembles (Rozemberczki and Sarkar, 2021) measures importance of individual models
in an ensemble in order to correctly label data points from a dataset, where each pre-trained model
maps to a player and the value function measures the predictive performance of subsets of models.

3 RELATED WORK

**Energy-based modeling. Energy based learning (LeCun et al., 2006) is a classical learning frame-**
work that uses an energy function E(x) to measure the quality of a data point x. Energy based models
have been applied to different domains, such as data generation (Deng et al., 2020), out-of-distribution
detection (Liu et al., 2020), reinforcement learning (Haarnoja et al., 2017), memory modeling (Bartunov et al., 2019), discriminative learning (Grathwohl et al., 2019; Gustafsson et al., 2020) and
biologically-plausible training (Scellier and Bengio, 2017). Energy based learning admits principled training methods, such as contrastive divergence (Hinton, 2002), noise contrastive estimation
(Gutmann and Hyvärinen, 2010) and score matching (Hyvärinen, 2005). For approximate inference,
sampling based approaches are mainly MCMC-style algorithms, such as stochastic gradient Langevin
dynamics (Welling and Teh, 2011). For a wide class of EBMs with submodular or supermodular
energies (Djolonga and Krause, 2014), there exist provable mean field inference algorithms with
constant factor approximation guarantees (Bian et al., 2019; Sahin et al., 2020; Bian et al., 2020).

**Shapley values in machine learning. Shapley values have been extensively used for valuation**
problems in machine learning, including attribution-based interpretation (Lipovetsky and Conklin,
2001; Cohen et al., 2007; Strumbelj and Kononenko, 2010; Owen, 2014; Datta et al., 2016; Lundberg
and Lee, 2017; Chen et al., 2018; Lundberg et al., 2018; Kumar et al., 2020; Williamson and Feng,
2020; Covert et al., 2020b; Wang et al., 2021b), data valuation (Ghorbani and Zou, 2019; Jia et al.,
2019b;a; Wang et al., 2020; Fan et al., 2021), collaborative machine learning (Sim et al., 2020) and
recently, model valuation in ensembles (Rozemberczki and Sarkar, 2021). For a detailed overview
of papers using Shapley values for feature interpretation, please see Covert et al. (2020a) and the
references therein. To alleviate the exponential computational cost of exact evaluation, various
methods have been proposed to approximate Shapley values in polynomial time (Ancona et al., 2017;
2019). Owen (1972) proposes the multilinear extension purely as a representation of cooperative
games and Okhrati and Lipani (2021) use it to develop sampling algorithms for Shapley values.

4 VALUATION FOR COOPERATIVE GAMES: A DECOUPLING PERSPECTIVE

In the introduction, we have asserted that under the setting of cooperative games, the Boltzmann
distribution (see Eq. (1)) achieves the maximum entropy among all of the pmf functionals. One can
naturally view the importance assignment problem of cooperative games as a decoupling problem:
The n players in a game (N, F (S)) might be arbitrarily correlated in a very complicated manner.
However, in order to assign each of them an individual importance value, we have to decouple their
interactions, which can be viewed as a way to simplify their correlations.


-----

We therefore consider a surrogate distribution q(S; x) governed by parameters in x. q has to be simple,
given our intention to decouple the correlations among the n players. A natural choice is to restrain
_q(S; x) to be fully factorizable, which leads to a mean-field approximation of p(S). The simplest_
form of q(S; x) would be a n independent Bernoulli distribution, i.e., q(S; x) := _i∈S_ _[x][i]_ _j /∈S[(1]_ _[−]_

_xj), x_ [0, 1][n]. Given a divergence measure D( ) for probability distributions, we can define the
_∈_ _·∥·_ Q
_best conceivable decoupling error to be the divergence between p and the best possible[Q]_ _q._
**Definition 1 (Best Conceivable Decoupling Error). Considering a cooperative game (N, F** (S)), and
_given a divergence measure D(·∥·) for probability distributions, the decoupling error is defined as_
_the divergence between q and p: D(q∥p), and the best conceivable decoupling error is defined as the_
_divergence between the best possible q and p:_
_D[∗]_ := min _D(q_ _p)._ (4)
_q_ _∥_

Note that the best conceivable decoupling error D[∗] is closely related to the intrinsic coupling amongst
_n players: if all the players are already independent with each other, then D[∗]_ could be zero.

4.1 MEAN FIELD OBJECTIVE FOR EBMS

If we consider the decoupling error D(q∥p) to be the Kullback-Leibler divergence between q and
_p, then we recover the mean field approach[3]. Given the EBM formulation in Eq. (1), the classical_
mean-field inference approach aims to approximate p(S) by a fully factorized product distribution
_q(S; x) :=_ _i∈S_ _[x][i]_ _j /∈S[(1][ −]_ _[x][j][)][,][ x][ ∈]_ [[0][,][ 1]][n][, by minimizing the distance measured w.r.t. the]

Kullback-Leibler divergence between q and p. Since KL(q _p) is non-negative, we have:_

Q _∥_

[Q]

0 KL(q _p) =_
_≤_ _∥_ _S_ _N_ _[q][(][S][;][ x][) log][ q][(]p[S](S[;][ x])_ [)]

_⊆_

X

= −Eq(S;x)[log p(S)] − H(q(S; x)) (5)

= Eq(S;x)[ _[F]_ [(][S][)] log Z] H(q(S; x)) (6)
_−_ _T_ _−_ _−_

_F_ (S) _n_

= _xi_ (1 _xj) +_ (7)
_−_ _T_ _−_ _i=1[[][x][i][ log][ x][i][ + (1][ −]_ _[x][i][) log(1][ −]_ _[x][i][)] + log][ Z][.]_

_SX⊆N_ _iY∈S_ _j /Y∈S_ X

In Eq. (6) we plug in the EBM formulation that log p(S) = _[F][ (]T[S][)]_ log Z. Then one can get

_−_

_F_ (S) _n_

log Z _xi_ (1 _xj)_
_≥_ _T_ _−_ _−_ _i=1[[][x][i][ log][ x][i][ + (1][ −]_ _[x][i][) log(1][ −]_ _[x][i][)]]_

_SX⊆N_ _iY∈S_ _j /Y∈S_ X

mt[(][x][)]
= _[f][ F]_ + H(q(S; x)) := (ELBO) (8)

_T_

where H(·) is the entropy, ELBO stands for the evidence lower bound, and

_fmt[F]_ [(][x][) :=] (9)

_S_ _N_ _[F]_ [(][S][)] _i_ _S_ _[x][i]_ _j /S[(1][ −]_ _[x][j][)][,][ x][ ∈]_ [[0][,][ 1]][n][,]
_⊆_ _∈_ _∈_

is the multilinear extension ofX F (S) (OwenY, 1972; Calinescu et al.Y, 2007). Note that the multilinear
extension plays a central role in modern combinatorial optimizaiton techniques (Feige et al., 2011),
especially for guaranteed submodular maximization problems (Krause and Golovin, 2014).

Maximizing (ELBO) in Eq. (8) amounts to minimizing the Kullback-Leibler divergence between q
and p. If one solves this optimization problem to optimality, one can obtain the q(S; x[∗]) with the
best conceivable decoupling error. Here x[∗]i [describes the odds that player][ i][ shall participate in the]
game, so it can be naturally used to define the importance score of each player.
**Definition 2 (Variational Index of Cooperative Games). Consider a cooperative game (N, F** (S))
_and its mean field approximation. Let x[∗]_ _be the variational marginals with the best conceivable_
_decoupling error, we define s[∗]_ := Tσ[−][1](x[∗]) to be the variational index of the game. Formally,
**x[∗]** = arg minxKL(q(S; x)∥p(S)), (10)

_where x[∗]_ _can be obtained by maximizing the ELBO objective in Eq. (8), and σ[−][1](_ ) is the inverse of
_x_ _·_
_the sigmoid function, i.e. σ[−][1](x) = log_ 1 _x_ _[. For a vector it is applied element-wise.]_

3Notably, one could also apply the reverse KL divergence− KL(p∥q), which would lead to an expectation
propagation (Minka, 2001) treatment of cooperative games.


-----

4.2 ALGORITHMS FOR CALCULATING THE VARIATIONAL INDEX

**Equilibrium condition. For coordinate i, the partial derivative of the multilinear extension is**
_∇ifmt[F]_ [(][x][)][, and for the entropy term, it is][ ∇][i][H][(][q][(][S][;][ x][)) = log][ 1][−]xi[x][i] [. By setting the partial derivative]

of ELBO in Eq. (8) to be 0, we have the equilibrium condition:


_x[∗]i_ [=][ σ][(][∇][i][f][ F]mt[(][x][∗][)][/T] [) =] 1 + exp(−∇ifmt[F] [(][x][∗][)][/T] _−1,_ _∀i ∈_ _N,_ (11)

where σ is the sigmoid function. This equilibrium condition implies that one cannot change the value  
assigned to any player in order to further improve the overall decoupling performance. It also implies
the fixed point iterationrecover the classic naive mean field algorithm as shown in Appendix xi ← _σ(∇ifmt[F]_ [(][x][)][/T] [)][. When updating each coordinate sequentially, we] C.

Instead, here we suggest to use the full-gradient method shown in Alg. 1 for maximizing the ELBO
objective. As we will see later, the resultant valuations satisfy certain game-theoretic axioms. It needs
an initial marginal vector x[0] _∈_ [0, 1][n] and the number of epochs K. After K steps of fixed point
iteration, it returns the estimated marginal x[K].

**Algorithm 1: Mean Field Inference with Full Gradient: MFI(x; K)**

**Input: A cooperative game (N, F** (S)) with n players. Initial marginals x[0] _←_ **x ∈** [0, 1][n].
#epochs K.

**Output: Marginals after K steps of iteration: x[K]**

**1 for k = 1** _K do_
_→_ 1

**2** **x[k]** _←_ _σ(∇fmt[F]_ [(][x][k][−][1][)][/T] [) =] 1 + exp(−∇fmt[F] [(][x][k][−][1][)][/T] _−_ ;
  

In case Alg. 1 solves the optimization problem to optimality, we obtain the Variational Index. However, maximizing ELBO is in general a non-convex/non-concave problem, and hence one can only
ensure reaching a stationary solution. Below, when we say Variational Index, we therefore refer to its
approximation obtained via Alg. 1 by default. Meanwhile, the MFI(x; K) subroutine also defines
a series of marginals, which enjoy interesting properties as we show in the next part. So we define
variational valuations through intermediate solutions of MFI(x; K).

**Definition 3 (K-Step Variational Values). Considering a cooperative game (N, F** (S)) and its mean
_field approximation by Alg. 1, we define the K-Step Variational Values initialized at x as:_

_Tσ[−][1](MFI(x; K)),_ (12)

_where σ[−][1]() is the inverse of the sigmoid function (σ[−][1](x) = log_ 1 _xx_ _[).]_

_−_


Notice when running more steps, the K-Step variational value will be more close to the
Variational Index. The gradient ∇fmt[F] [(][x][)][ itself is defined with respect to an exponential sum via the]
multilinear extension. Next we show how it can be approximated via principled sampling methods.

**Sampling methods for estimating the partial derivative. The partial derivative follows,**


_ifmt[F]_ [(][x][) =][ E]q(S;(x _xi_ 1))[[][F] [(][S][)]][ −] [E]q(S;(x _xi_ 0))[[][F] [(][S][)]] (13)
_∇_ _|_ _←_ _|_ _←_

= fmt[F] [(][x][|][x][i] mt[(][x][|][x][i]

_[←]_ [1)][ −] _[f][ F]_ _[←]_ [0)]

= _F_ (S) _xj_ (1 _xj′_ ) _F_ (S) _xj_ (1 _xj′_ )

_−_ _−_ _−_

_S⊆XN,S∋i_ _j∈YS−i_ _jY[′]∈/S_ _S⊆XN_ _−i_ _jY∈S_ _j[′]∈/YS,j[′]≠_ _i_



[F (S + i) − _F_ (S)]
_S⊆XN_ _−i_


(1 _xj′_ )
_−_
_j[′]∈NY−S−i_


_xj_
_jY∈S_


= [F (S + i) _F_ (S)]q(S; (x _xi_ 0)) = ES _q(S;(x_ _xi_ 0)) [[][F] [(][S][ +][ i][)][ −] _[F]_ [(][S][)]][.]

_S⊆XN_ _−i_ _−_ _|_ _←_ _∼_ _|_ _←_

All of the variational criteria are based on the calculation of the partial derivative ∇ifmt[F] [(][x][)][, which can]
be approximated by Monte Carlo sampling since _ifmt[F]_ [(][x][) =][ E]S _q(S;(x_ _xi_ 0)) [[][F] [(][S][ +][ i][)][ −] _[F]_ [(][S][)]][:]
_∇_ _∼_ _|_ _←_
we first sample m coalitions Sk, k = 1, ..., m from the surrogate distribution q(S; (x _xi_ 0)),
then approximate the expectation by the average _m[1]_ _mk=1_ [[][F] [(][S][k][ +][ i][)][ −] _[F]_ [(][S][k][)]][. According to the]| _←_

P


-----

Chernoff-Hoeffding bound (Hoeffding, 1963), the approximation will be arbitrarily close to the true
value with increasingly more samples: With probability at least 1 exp( _mϵ[2]/2), it holds that_

_m_ _−_ _−_
_m[1]_ _k=1[[][F]_ [(][S][k][ +][ i][)][ −] _[F]_ [(][S][k][)]][ −∇][i][f][ F]mt[(][x][)][| ≤] _[ϵ][ max][S]_

_|_ _[|][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)][|][, for all][ ϵ >][ 0][.]

**Roles of the initializerP** **x[0]** **and the temperature T** **. This can be understood in the following respects:**
1) The initializer x[0] represents the initial credit assignments to the n players, so it denotes the prior
knowledge/initial belief of the contributions of the players; 2) If one just runs Alg. 1 for one step, x[0]
matters greatly to the output. However, if one runs Alg. 1 for many steps, x[k] will converge to the
stationary points of the ELBO objective. Empirically, it takes around 5∼10 steps to converge. The
temperature T controls the “spreading” of importance assigned to the players: A higher T leads to
flatter assignments, and a lower T leads to more concentrated assignments.

**Computational efficiency of calculating Variational Index and variational values. Alg. 1 calcu-**
lates the K-step variational values, 1-step variational value has the same computational cost as that
of Banzhaf value and of the integrand of the line integration of Shapley value in Eq. (15) below, since
they all need to evaluate ∇fmt[F] [(][x][)][. Sampling methods could help with approximating all of the three]
criteria when there are a large number of players. The Variational Index can be approximated by the
_K-step variational value, where the number K depends on when Alg. 1 converges. One can easily_
show that, under the setting of maximizing ELBO, x[k] will converge to some stationary point x[∗],
based on the analysis of mean field approximation in Wainwright and Jordan (2008). We have also
empirically verified the convergence rate of Alg. 1 in Sec. 5.3, and find that it converges within 5 to
10 steps. So the computational cost is roughly similar as that of Shapley value and Banzhaf value.

4.3 RECOVERING CLASSICAL CRITERIA

Perhaps surprisingly, it is possible to recover classical valuation criteria via the K-step variational
values as in Def. 3. Firstly, for Banzhaf value, by comparing with Eq. (13) it reads,

1

Bai = mt[(0][.][5][ ∗] **[1][) =][ Tσ][−][1][(][MFI][(0][.][5][ ∗]** **[1][; 1))][,]** (14)

_S_ _N_ _i[[][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)]] 2[n][−][1][ =][ ∇][i][f][ F]
_⊆_ _−_

X

which is the 1-step variational value initialied at 0.5 ∗ **1. We can also recover the Shapley value**
through its connection to the multilinear extension (Owen, 1972; Grabisch et al., 2000):

1 1
Shi = 0 _∇ifmt[F]_ [(][x][1][)][dx][ =] 0 _Tσ[−][1](MFI(x1; 1))dx,_ (15)
Z Z

where the integration denotes integrating the partial-derivative of the multilinear extension along
the main diagonal of the unit hypercube. A self-contained proof is given in Appendix D.

These insights offer a novel, unified interpretation of the two classical valuation indices: both the
Shapley value and Banzhaf value can be viewed as approximating the variational index by running
_one step of fixed point iteration for the decoupling (ELBO) objective. Specifically, for the Banzhaf_
value, it initializes x at 0.5 ∗ **1, and runs one step of fixed point iteration. For the Shapley value, it**
also performs a one-step fixed point approximation. However, instead of starting at a single initial
point, it averages over all possible initializations through the line integration in Eq. (15).

**Relation to probabilistic values. Probabilistic values for games (Weber, 1988; Monderer and Samet,**
2002) capture a class of solution concepts, where the value of each player is given by some averaging
of the player’s marginal contributions to coalitions, and the weights depend on the coalitions only.
According to (Monderer and Samet, 2002, Equation (3.1)), a solution φ is called a probabilistic value,
if for each player i, there exists a probability p[i] _∈_ ∆(C _[i]), such that φi is the expected marginal_
contribution of i w.r.t. p[i]. Namely, φi = _S_ _C[i][ p][i][(][S][)[][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)]][,][ where][ C] _[i][ is the set of all]_

_∈_
subsets of N − _i, and ∆(C_ _[i]) is the set of all probability measures on C_ _[i]. One can easily see that, for_
any fixed x, 1-step variational value in Def.[P] 3 is a probabilistic value with p[i](S) = q(S; (x _xi_ 0)),
where q(S; x) is the surrogate distribution in our EBM framework. _|_ _←_

4.4 AXIOMATISATION OF K-STEP VARIATIONAL VALUES

Our EBM framework introduces a series of variational values controlled by T and the running
step number K. We now establish that the variational values Tσ[−][1](MFI(x; K)) in Def. 3 satisfy
certain game-theoretic axioms (see Appendix B for definitions of five common axioms: Null player,


-----

synthetic breast cancer digits

20 groups,
each w. 1 sample,
= 0.5

16 groups, random,

𝑇 = 0.1 10 groups,

kmeans,

𝑇 = 0.1

𝑇

12 groups,

20 groups, each w. random,
50 samples, kmeans = 0.5
= 1 14 groups, kmeans

= 0.5 𝑇

𝑇

𝑇


Figure 2: Data removal results. Numbers in the legend are the decoupling errors. Columns: 1st:
synthetic data; 2nd: breast cancer data with 569 samples; 3rd: digits data with 1797 samples. Specific
configurations (e.g., temperature) are put inside the figure texts.

Symmetry, Marginalism, Additivity and Efficiency). We prove that all the variational values in the
trajectory satisfy three fundamental axioms: null player, marginalism and symmetry. The detailed
proof is deferred to Appendix E. We expect it to be very difficult to find equivalent axiomatisations
of the series of variational values, which we leave for future work. Meanwhile, our methods incur
a decoupling and fairness tradeoff by tuning the hyperparameters K and T .

**Theorem 1 (Axiomatisation of K-Step Variational Values of Def. 3). If initialized uniformly, i.e.,**
**x[0]** = x1, x ∈ [0, 1], all the variational values in the trajectory Tσ[−][1](MFI(x; k)), k = 1, 2, 3...
_satisfy the null player, marginalism and symmetry axioms._

According to Theorem 1, our proposed K-step variational values satisfy the minimal set of axioms
often associated with appropriate valuation criteria. Note that specific realizations of the K-step
variational values can also satisfy more axioms, for example, the 1-step variational value initialized
at 0.5 ∗ **1 also satisfies the additivity axiom. Furthermore, we have the following observations:**

**Satisfying more axioms is not essential for valuation problems. Notably, in cooperative game**
theory, one line of work is to seek for solution concepts that would satisfy more axioms. However,
for valuation problems in machine learning, this is arguably not essential. For example, similar as
argued by Ridaoui et al. (2018), efficiency does not make sense for certain games. We give a simple
illustration in Appendix F, which further shows that whether more axioms shall be considered really
depends on the specific scenario being modeled, which will be left for important future work.

5 EMPIRICAL STUDIES

Throughout the experiments, we are trying to understand the following: 1) Would the proposed Variational Index have lower decoupling error compared to others? 2) Could the proposed
Variational Index gain benefits compared to the classical valuation criteria for valuation problems?

Since we are mainly comparing the quality of different criteria, it is necessary to rule out the influence
of approximation errors when estimating their values. So we focus on small-sized problems where
one can compute the exact values of these criteria in a reasonable time. Usually this requires the
number of players to be no more than 25. Meanwhile, we have also conducted experiments with
a larger number of players in Appendix G.5, in order to show the efficiency of sampling methods.
We choose T empirically from the values of 0.1, 0.2, 0.5, 1.0. We choose K such that Alg. 1 would
converge. Usually, it takes around 5 to 10 steps to converge. We give all players a fair start, so x[0]
[was intialized to be 0.5 × 1. Code is available at https://valuationgame.github.io.](https://valuationgame.github.io)

We first conduct synthetic experiments on submodular games (details defered to Appendix G.1), in
order to verify the quality of solutions in terms of the true marginals p(i ∈ **S). One can conclude**


-----

Variational Shapley Banzhaf

Shapley

Banzhaf


xgboost

logistic

regression

MLP

|st 𝑇= 0.8 Data id: 24038 GT label: True c n 𝑇= 0.1 Data id: 7977 GT label: True 𝑇= 0.5 Data id: 16139 GT label: True|Col2|Col3|
|---|---|---|



Figure 3: First column: Change of predicted probabilities when removing features. The decoupling
_error is included in the legend. Last three columns: waterfall plots of feature importance._

that Variational Index obtains better performance in terms of MSE and Spearman’s rank correlation
compared to the one-point solutions (Shapley value and Banzhaf value) in all experiments. More
experimental results on data point and feature valuations are deferred to Appendix G.

5.1 EXPERIMENTS ON DATA VALUATIONS

[We follow the setting of Ghorbani and Zou (2019) and reuse the code of https://github.com/](https://github.com/amiratag/DataShapley)
[amiratag/DataShapley. We conduct data removal: training samples are sorted according to](https://github.com/amiratag/DataShapley)
the valuations returned by different criteria, and then samples are removed in that order to check
how much the test accuracy drops. Intuitively, the best criteria would induce the fastest drop of
performance. We experiment with the following datasets: a) Synthetic datasets similar as that of
Ghorbani and Zou (2019); b) The breast cancer dataset, which is a binary classification dataset
with 569 samples; c) The digits dataset, that is a 10-class classification dataset with 1797 samples.
[The above two datasets are both from UCI Machine Learning repository (https://archive.](https://archive.ics.uci.edu/ml/index.php)
[ics.uci.edu/ml/index.php). Specifically, we cluster data points into groups and studied two](https://archive.ics.uci.edu/ml/index.php)
settings: 1) Grouping the samples randomly; 2) Clustering the samples with the k-means algorithm.
For simplicity, we always use equal group sizes. The data point removal corresponds to singleton
groups. Fig. 2 shows the results. One can observe that in certain situations the Variational Index
achieves the fastest drop rate. It always achieves the lowest decoupling error (as shown in the legends
in each of the figures). Sometimes Variational Index and Banzhaf show similar performance. We
expect that this is because the Banzhaf value is a one-step approximation of Variational Index, and
for the specific problem considered, the ranking of the solutions does not change after one-step of
fixed point iteration. There are also situations where the rankings of the three criteria are not very
distinguishable, however, the specific values are also very different since the decoupling error differs.

5.2 EXPERIMENTS ON FEATURE VALUATIONS/ATTRIBUTIONS

[We follow the setting of Lundberg and Lee (2017) and reuse the code of https://github.com/](https://github.com/slundberg/shap)
[slundberg/shap with an MIT License. We train classifiers on the Adult dataset[4], which predicts](https://github.com/slundberg/shap)
whether an adult’s income exceeds 50k dollar per year based on census data. It has 48,842 instances
and 14 features such as age, workclass, occupation, sex and capital gain (12 of them used).

**Feature removal results. This experiment follows a similar fashion as the data removal experiment:**
we remove the features one by one according to the order defined by the returned criterion, then
observe the change of predicted probabilities. Fig. 3 reports the behavior of the three criteria. The first
row shows the results from an xgboost classifier (accuracy: 0.893), second row a logistic regression

[4https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)


-----

|GT Labels: True|1|2 3|4|5|6 7|8 9|10|11|12|
|---|---|---|---|---|---|---|---|---|---|
|Var. Index C|apital Gain R|elationship Age|Education-Num|Occupation|Marital Status Capital|Loss Hours per week Sex|Race|Workclass C|ountry|
|Shapley C|apital Gain R|elationship Education-Num|Age|Occupation|Marital Status Hours pe|r week Capital Loss Sex|Workclass|Race C|ountry|
|Banzhaf C|apital Gain R|elationship Education-Num|Age|Occupation|Marital Status Capital|Loss Hours per week Sex|Race|Workclass C|ountry|


Variational Shapley Banzhaf

GT Labels: True 1 2 3 4 5 6 7 8 9 10 11 12

Var. Index Capital Gain [Relationship] Age Education-Num Occupation Marital Status Capital Loss Hours per week Sex Race Workclass Country

Shapley Capital Gain [Relationship][ Education-Num] Age Occupation Marital Status Hours per week Capital Loss Sex Workclass Race Country

Banzhaf Capital Gain [Relationship][ Education-Num] Age Occupation Marital Status Capital Loss Hours per week Sex Race Workclass Country


Figure 4: Statistics on valuations with the xgboost classifier. First row: box plot of valuations. We
always consider the predicted probability of the ground truth label. “True” means the samples with
positive ground truth label and “False” means with the negative ground truth label. Second row:
Average ranking of the 12 features. Colored texts denote different rankings among the three criteria.

classifier (accuracy: 0.842), third row a multi-layer perceptron (accuracy: 0.861). For the probability
dropping results, Variational Index usually induces the fastest drop, and it always enjoys the smallest
decoupling error, as expected from its mean-field nature. From the waterfall plots, one can see that
the three criteria indeed produce different rankings of the features. Take the first row for example.
All criteria put “Capital Loss” and “Relationship” as the first two features. However, the remaining
features have different ranking: Variational Index and Banzhaf indicate that “Marital Status” should
be ranked third, while Shapley ranks it in the fourth position. It is hard to tell which ranking is the
best because: 1) There is no golden standard to determine the true ranking of features; 2) Even if
there exists a ground truth ranking of some “perfect model”, the trained xgboost model here might
not be able to reproduce it, since it might not be aligned with the “perfect model”.

**Average results. We further provide the bar plots and averaged ranking across the adult datasets in**
Fig. 4. From the bar plots one can see that different criterion has slightly different values for each
feature on average. Average rankings in the table demonstrate the difference: The three methods do
not agree on the colored features, for example, “Age”, “Education-Num” and “Captical Loss”.

5.3 EMPIRICAL CONVERGENCE RESULTS OF ALG. 1

Table 1 shows convergence results of Alg. 1 on feature and data valuation experiments. The value in
the cells are the stepwise difference of x[k], _[∥][x][k][−][x]n[k][−][1][∥][2]_, which is a classical criterion to measure the

convergence of iterative algorithms. One can clearly see that Alg. 1 converges in 5 to 10 iterations.

Table 1: Stepwise difference _[∥][x][k][−][x]n[k][−][1][∥][2]_ of Alg. 1 for different experiments.

Step/Iteration Num 1 2 3 5 9 10

Data Val (breast cancer) 0.0023 3.61e-6 1.53e-7 2.77e-10 9.12e-16 0
Data Val (digits) 0.00099 5.93e-7 1.46e-8 8.92e-12 9.25e-18 0
Data Val (synthetic) 0.00059 2.49e-8 3.13e-10 6.06e-14 0 0
Feature Val (xgboost) 0.0066 1.68e-5 8.71e-7 2.35e-9 1.75e-14 9.25e-16
Feature Val (LR) 0.0092 2.63e-5 1.44e-6 4.31e-9 2.14e-15 1.28e-16
Feature Val (MLP) 0.0040 4.86e-6 1.86e-7 2.84e-10 6.82e-16 3.20e-17


DISCUSSIONS AND FUTURE WORK. We have presented an energy-based treatment of
cooperative games, in order to improve the valuation problem. It is very worthwhile to explore more
in the following directions: 1) Choosing the temperature T . The temperature controls the level of
fairness since, when T →∞, all players have equal importance, when T → 0, whereas a player has
either 0 or 1 importance (assuming no ties). Perhaps one can use an annealing-style algorithm in
order to control the fairness level: starting with a high temperature and gradually decreasing it, one
can obtain a series of importance values under different fairness levels. 2) Given the probabilistic
treatment of cooperative games, one can naturally add priors over the players, in order to encode
more domain knowledge. It may also make sense to consider conditioning and marginalization in
light of practical applications. 3) It is very interesting to explore the interaction of a group of players
in the energy-based framework, which would result in an “interactive” index among size-k coalitions.


-----

ETHICS STATEMENT AND BROADER IMPACT

Besides the valuation problems explored in this work, cooperative game theory has already been
applied to a wide range of disciplines, to name a few, economics, political science, sociology, biology,
so this work could potentially contribute to broader domains as well.

Meanwhile, we have to be aware of possible negative societal impacts, including: 1) negative side
effects of the technology itself, for example, possible unemployment issues due to the reduced
amount of the need of valuations by human beings; 2) applications in negative downstream tasks, for
instance, the data point valuation technique could make it easier to conduct underground transactions
of private data.

REPRODUCIBILITY STATEMENT

All the datasets are publicly available as described in the main text. In order to ensure reproducibility,
we have made the efforts in the following respects: 1) Provide code as supplementary material. 2)
Provide self-contained proofs of the main claims in Appendices D and E; 3) Provide more details on
experimental configurations and experimental results in Appendix G.

REFERENCES

M. Ancona, E. Ceolini, C. Öztireli, and M. Gross. Towards better understanding of gradient-based
attribution methods for deep neural networks. arXiv preprint arXiv:1711.06104, 2017.

M. Ancona, C. Öztireli, and M. Gross. Explaining deep neural networks with a polynomial time
algorithm for shapley values approximation. arXiv preprint arXiv:1903.10992, 2019.

J. F. Banzhaf III. Weighted voting doesn’t work: A mathematical analysis. Rutgers L. Rev., 19:317,
1964.

S. Bartunov, J. W. Rae, S. Osindero, and T. P. Lillicrap. Meta-learning deep energy-based memory
models. arXiv preprint arXiv:1910.02720, 2019.

Y. Bian, J. M. Buhmann, and A. Krause. Continuous submodular function maximization. arXiv
_preprint arXiv:2006.13474, 2020._

Y. A. Bian, J. M. Buhmann, and A. Krause. Optimal continuous dr-submodular maximization and
applications to provable mean field inference. In Proceedings of the 36th International Conference
_on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 644–653,_
Long Beach, California, USA, 09–15 Jun 2019. PMLR.

G. Calinescu, C. Chekuri, M. Pál, and J. Vondrák. Maximizing a submodular set function subject to
a matroid constraint. In International Conference on Integer Programming and Combinatorial
_Optimization, pages 182–196. Springer, 2007._

J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan. L-shapley and c-shapley: Efficient model
interpretation for structured data. arXiv preprint arXiv:1808.02610, 2018.

Y. Chun. A new axiomatization of the shapley value. Games and Economic Behavior, 1(2):119–130,
1989.

S. Cohen, G. Dror, and E. Ruppin. Feature selection via coalitional game theory. Neural Computation,
19(7):1939–1961, 2007.

I. Covert, S. Lundberg, and S.-I. Lee. Explaining by removing: A unified framework for model
explanation. arXiv preprint arXiv:2011.14878, 2020a.

I. Covert, S. Lundberg, and S.-I. Lee. Understanding global feature contributions with additive
importance measures. arXiv preprint arXiv:2004.00668, 2020b.

A. Datta, S. Sen, and Y. Zick. Algorithmic transparency via quantitative input influence: Theory and
experiments with learning systems. In 2016 IEEE symposium on security and privacy (SP), pages
598–617. IEEE, 2016.


-----

Y. Deng, A. Bakhtin, M. Ott, A. Szlam, and M. Ranzato. Residual energy-based models for text
generation. arXiv preprint arXiv:2004.11714, 2020.

J. Djolonga and A. Krause. From map to marginals: Variational inference in bayesian submodular
models. In Neural Information Processing Systems (NIPS), 2014.

Z. Fan, H. Fang, Z. Zhou, J. Pei, M. P. Friedlander, C. Liu, and Y. Zhang. Improving fairness for data
valuation in federated learning. arXiv preprint arXiv:2109.09046, 2021.

U. Feige, V. S. Mirrokni, and J. Vondrák. Maximizing non-monotone submodular functions. SIAM
_Journal on Computing, 40(4):1133–1153, 2011._

A. Ghorbani and J. Zou. Data shapley: Equitable valuation of data for machine learning. In
_International Conference on Machine Learning, pages 2242–2251. PMLR, 2019._

M. Grabisch. K-order additive discrete fuzzy measures and their representation. Fuzzy sets and
_systems, 92(2):167–189, 1997._

M. Grabisch, J.-L. Marichal, and M. Roubens. Equivalent representations of set functions. Mathe_matics of Operations Research, 25(2):157–178, 2000._

W. Grathwohl, K.-C. Wang, J.-H. Jacobsen, D. Duvenaud, M. Norouzi, and K. Swersky. Your
classifier is secretly an energy based model and you should treat it like one. arXiv preprint
_arXiv:1912.03263, 2019._

G. Greco, F. Lupia, and F. Scarcello. Structural tractability of shapley and banzhaf values in allocation
games. In Twenty-Fourth International Joint Conference on Artificial Intelligence, 2015.

F. K. Gustafsson, M. Danelljan, R. Timofte, and T. B. Schön. How to train your energy-based model
for regression. arXiv preprint arXiv:2005.01698, 2020.

M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for
unnormalized statistical models. In Proceedings of the Thirteenth International Conference on
_Artificial Intelligence and Statistics, pages 297–304. JMLR Workshop and Conference Proceedings,_
2010.

T. Haarnoja, H. Tang, P. Abbeel, and S. Levine. Reinforcement learning with deep energy-based
policies. In International Conference on Machine Learning, pages 1352–1361. PMLR, 2017.

P. L. Hammer and S. Rudeanu. Boolean methods in operations research and related areas, volume 7.
Springer Science & Business Media, 2012.

G. E. Hinton. Training products of experts by minimizing contrastive divergence. Neural computation,
14(8):1771–1800, 2002.

W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the
_American statistical association, 58(301):13–30, 1963._

A. Hyvärinen. Estimation of non-normalized statistical models by score matching. Journal of
_Machine Learning Research, 6(4), 2005._

E. T. Jaynes. Information theory and statistical mechanics. Physical review, 106(4):620, 1957a.

E. T. Jaynes. Information theory and statistical mechanics. ii. Physical review, 108(2):171, 1957b.

R. Jia, D. Dao, B. Wang, F. A. Hubis, N. Hynes, N. M. Gürel, B. Li, C. Zhang, D. Song, and C. J.
Spanos. Towards efficient data valuation based on the shapley value. In The 22nd International
_Conference on Artificial Intelligence and Statistics, pages 1167–1176. PMLR, 2019a._

R. Jia, X. Sun, J. Xu, C. Zhang, B. Li, and D. Song. An empirical and comparative analysis of data
valuation with scalable algorithms. arXiv preprint arXiv:1911.07128, 2019b.

A. Krause and D. Golovin. Submodular function maximization. Tractability, 3:71–104, 2014.


-----

I. E. Kumar, C. Scheidegger, S. Venkatasubramanian, and S. Friedler. Shapley residuals: Quantifying
the limits of the shapley value for explanations. In ICML Workshop on Workshop on Human
_Interpretability in Machine Learning (WHI), 2020._

Y. LeCun, S. Chopra, R. Hadsell, M. Ranzato, and F. Huang. A tutorial on energy-based learning.
_Predicting structured data, 1(0), 2006._

S. Lipovetsky and M. Conklin. Analysis of regression in game theory approach. Applied Stochastic
_Models in Business and Industry, 17(4):319–330, 2001._

W. Liu, X. Wang, J. D. Owens, and Y. Li. Energy-based out-of-distribution detection. arXiv preprint
_arXiv:2010.03759, 2020._

S. Lundberg and S.-I. Lee. A unified approach to interpreting model predictions. arXiv preprint
_arXiv:1705.07874, 2017._

S. M. Lundberg, G. G. Erion, and S.-I. Lee. Consistent individualized feature attribution for tree
ensembles. arXiv preprint arXiv:1802.03888, 2018.

T. P. Minka. Expectation propagation for approximate bayesian inference. In Proceedings of the
_Seventeenth conference on Uncertainty in artificial intelligence, pages 362–369, 2001._

D. Monderer and D. Samet. Variations on the shapley value. Handbook of game theory with economic
_applications, 3:2055–2076, 2002._

R. Okhrati and A. Lipani. A multilinear sampling algorithm to estimate shapley values. In 2020 25th
_International Conference on Pattern Recognition (ICPR), pages 7992–7999. IEEE, 2021._

A. B. Owen. Sobol’indices and shapley value. SIAM/ASA Journal on Uncertainty Quantification, 2
(1):245–251, 2014.

G. Owen. Multilinear extensions of games. Management Science, 18(5-part-2):64–79, 1972.

L. S. Penrose. The elementary statistics of majority voting. Journal of the Royal Statistical Society,
109(1):53–57, 1946.

V. Petsiuk, A. Das, and K. Saenko. Rise: Randomized input sampling for explanation of black-box
models. arXiv preprint arXiv:1806.07421, 2018.

M. T. Ribeiro, S. Singh, and C. Guestrin. " why should i trust you?" explaining the predictions of
any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge
_discovery and data mining, pages 1135–1144, 2016._

M. Ridaoui, M. Grabisch, and C. Labreuche. An axiomatisation of the banzhaf value and interaction
index for multichoice games. In International Conference on Modeling Decisions for Artificial
_Intelligence, pages 143–155. Springer, 2018._

B. Rozemberczki and R. Sarkar. The shapley value of classifiers in ensemble games. arXiv preprint
_arXiv:2101.02153, 2021._

A. Sahin, Y. Bian, J. Buhmann, and A. Krause. From sets to multisets: provable variational inference
for probabilistic integer submodular models. In International Conference on Machine Learning,
pages 8388–8397. PMLR, 2020.

B. Scellier and Y. Bengio. Equilibrium propagation: Bridging the gap between energy-based models
and backpropagation. Frontiers in computational neuroscience, 11:24, 2017.

L. S. Shapley. A value for n-person games. Contributions to the Theory of Games, 2(28):307–317,
1953.

R. H. L. Sim, Y. Zhang, M. C. Chan, and B. K. H. Low. Collaborative machine learning with incentiveaware model rewards. In International Conference on Machine Learning, pages 8927–8936. PMLR,
2020.


-----

E. Strumbelj and I. Kononenko. An efficient explanation of individual classifications using game
theory. The Journal of Machine Learning Research, 11:1–18, 2010.

M. Sundararajan, A. Taly, and Q. Yan. Axiomatic attribution for deep networks. In International
_Conference on Machine Learning, pages 3319–3328. PMLR, 2017._

S. Tschiatschek, J. Djolonga, and A. Krause. Learning probabilistic submodular diversity models
via noise contrastive estimation. In Proc. International Conference on Artificial Intelligence and
_Statistics (AISTATS), 2016._

M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference.
Now Publishers Inc, 2008.

J. Wang, J. Wiens, and S. Lundberg. Shapley flow: A graph-based approach to interpreting model
predictions. In International Conference on Artificial Intelligence and Statistics, pages 721–729.
PMLR, 2021a.

R. Wang, X. Wang, and D. I. Inouye. Shapley explanation networks. arXiv preprint arXiv:2104.02297,
2021b.

T. Wang, J. Rausch, C. Zhang, R. Jia, and D. Song. A principled approach to data valuation for
federated learning. In Federated Learning, pages 153–167. Springer, 2020.

R. J. Weber. Probabilistic values for games. The Shapley Value. Essays in Honor of Lloyd S. Shapley,
pages 101–119, 1988.

M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient langevin dynamics. In
_Proceedings of the 28th international conference on machine learning (ICML-11), pages 681–688._
Citeseer, 2011.

B. Williamson and J. Feng. Efficient nonparametric statistical inference on population feature
importance using shapley values. In International Conference on Machine Learning, pages
10282–10291. PMLR, 2020.

H. P. Young. Monotonic solutions of cooperative games. International Journal of Game Theory, 14
(2):65–72, 1985.

M. D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In European
_conference on computer vision, pages 818–833. Springer, 2014._


-----

## Appendix of “Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning”

CONTENTS

**A Derivations of the Maximum Entropy Distribution** **14**

**B** **Common Axioms of Valuation Criteria** **15**

**C The Naive Mean Field Algorithm** **16**

**D Proof of Recovering Classical Criteria** **16**

**E** **Proof of Theorem 1** **17**

**F** **Miscellaneous Results in Sec. 4** **18**

**G More Configuration Details and Experimental Results** **19**

G.1 Synthetic Experiments on Submodular (FLID) Games . . . . . . . . . . . . . . . . 19

G.2 Details of the Models for Feature Valuations . . . . . . . . . . . . . . . . . . . . . 20

G.3 More Results on Feature Valuations . . . . . . . . . . . . . . . . . . . . . . . . . 20

G.4 More Average Results on Feature Valuations . . . . . . . . . . . . . . . . . . . . . 20

G.5 Experiments with More Players . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

G.6 Effect of Number of Samples in MCMC Sampling . . . . . . . . . . . . . . . . . 22

A DERIVATIONS OF THE MAXIMUM ENTROPY DISTRIBUTION

One may wonder why do we need energy-based treatment of valuation problems in machine learning?
Specifically, under the setting of cooperative games (N, F (S)), why we have to take the exponential
form of EBM p(S) ∝ exp(F (S)/T )? Because one may also formulate it as something else, say,
_p(S) ∝_ (1 + |F (S)|)?

In one word, because EBM is the maximum entropy distribution. Being a maximum entropy
distribution means minimizing the amount of prior information built into the distribution. Another
lens to understand it is that: Since the distribution with the maximum entropy is the one that makes
the fewest assumptions about the true distribution of data, the principle of maximum entropy can be
seen as an application of Occam’s razor. Meanwhile, many physical systems tend to move towards
maximal entropy configurations over time (Jaynes, 1957a;b).

In the following we will give a derivation to show that p(S) ∝ exp(F (S)/T ) is indeed the maximum
entropy distribution for a cooperative game. The derivation bellow is closely following Jaynes
(1957a;b) for statistical mechanics. Suppose each coalition S is associated with a payoff F (S) with
probability p(S). We would like to maximize the entropy H(p) = − [P]S⊆N _[p][(][S][) log][ p][(][S][)][, subject]_

to the constraints that _S_ _[p][(][S][) = 1][, p][(][S][)][ ≥]_ [0][ and][ P]S _[p][(][S][)][F]_ [(][S][) =][ µ][ (i.e., the average payoff is]

known as µ).

Writing down the Lagrangian[P]


-----

_L(p, λ0, λ1) :=_ _p(S) log p(S) + λ0(_ _p(S)_ 1) + λ1(µ _p(S)F_ (S)) (16)
_−_  _−_ _−_ 

_S⊆N_ _SX⊆N_ _SX⊆N_

 [X] 

Setting
_∂L(p, λ0, λ1)_

= [log p(S) + 1 + λ0 _λ1F_ (S)] (17)
_∂p(S)_ _−_ _−_

= 0 (18)
we get:
_p(S) = exp[−(λ0 + 1 −_ _λ1F_ (S))] (19)


exp(λ1F (S)) =: log Z (20)
_SX⊆N_


_λ0 + 1 = log_

is the log-partition function. So,


_p(S) = [exp[][λ][1][F]_ [(][S][))]]

Z

Note that the maximum value of the entropy is


(21)


_p(S) log p(S)_ (22)
_SX⊆N_


_Hmax = −_


= λ0 + 1 − _λ1_ _p(S)F_ (S) (23)

_SX⊆N_

= λ0 + 1 − _λ1µ_ (24)


So one can get,

which defines the inverse temperature.


_λ1 =_ =: [1]
_−_ _[∂H]∂µ[max]_ _T_


(25)


So we reach the exponential form of p(S) as:

exp[F (S)/T )]
_p(S) =_ (26)
_S_ _N_ [exp[][F] [(][S][)][/T] []] _[.]_
_⊆_
P

B COMMON AXIOMS OF VALUATION CRITERIA

Following the definitions in Covert et al. (2020a), the five common axioms are listed as bellow. φi(F )
denotes the value assigned to player i in the game (N, F (S)). Note that the notions might be slightly
different in classical literature of game theory.

**Null player: For a player i in the cooperative game (N, F** (S)), if F (S + i) = F (S) holds for all
_S_ _N_ _i, then its value should be φi(F_ ) = 0.
_⊆_ _−_

**Symmetry: For any two players i, j in the cooperative game (N, F** (S)), if F (S + i) = F (S + j)
holds for all S _N_ _i_ _j, then it holds that φi(F_ ) = φj(F ).
_⊆_ _−_ _−_

**Marginalism: For two games (N, F** (S)) and (N, G(S)) where all players have identical marginal
contributions, the players obtain equal valuations: F (S + i) − _F_ (S) = G(S + i) − _G(S) holds for_
all (i, S), then it holds that φi(F ) = φi(G).

**Additivity: For two games (N, F** (S)) and (N, G(S)), if they are combined, the total contribution of
a player is equal to the sum of its individual contributions on each game: φi(F +G) = φi(F )+φi(G).

**Efficiency: The values add up to the difference in value between the grand coalition and the empty**
coalition: _i_ _N_ _[φ][i][(][F]_ [) =][ F] [(][N] [)][ −] _[F]_ [(][∅][)][.]

_∈_

[P]


-----

**Remark 1 (The notion of “marginalism”). Specifically, the marginalism axiom was first mentioned by**
_(Young, 1985, Equation 7 on page 70), where it was called the “independence” condition; Following_
_(Chun, 1989, page 121), it was formally called the “marginality”. This axiom requires a player’s_
_payoffs to depend only on his own marginal contributions – whenever they remain unchanged, his_
_payoffs should be unaffected._

**Algorithm 2: NAIVE MEAN FIELD FOR CALCULATING THE VARIATIONAL INDEX**
**Input: A cooperative game (N, F** (S)) with n players. Initial marginal x[0] _∈_ [0, 1][n]; #epochs K.
**Output: The Variational Index s[∗]** = σ[−][1](x[∗])

**1 x ←** **x[0];**

**2 for epoch from 1 to K do**

**3** **for i = 1 →** _n do_

**4** let vi be the player being operated;

**5** _xvi ←_ _σ(∇vi_ _fmt[F]_ [(][x][)][/T] [) =] 1 + exp(−∇vi _fmt[F]_ [(][x][)][/T] _−1 ;_

**6 x[∗]** _←_ **x;**   


C THE NAIVE MEAN FIELD ALGORITHM

The naive mean field algorithm is one of the most classical algorithm for mean field inference. It is
summarized in Alg. 2.

D PROOF OF RECOVERING CLASSICAL CRITERIA

For Banzhaf value, by comparing its definition in Eq. (2) with Eq. (13) it reads,

1

Bai = mt[(0][.][5][ ∗] **[1][) =][ Tσ][−][1][(][MFI][(0][.][5][ ∗]** **[1][; 1))][,]** (27)

_S_ _N_ _i[[][F]_ [(][S][ +][ i][)][ −] _[F]_ [(][S][)]] 2[n][−][1][ =][ ∇][i][f][ F]
_⊆_ _−_

X

which is the 1-step variational value initialied at 0.5 ∗ **1.**

For Shapley value, according to Grabisch et al. (2000), here we prove a stronger conclusion regarding
the generalization of Shapley value: Shapley interaction index, which is defined for any coalition S:


(n −|T _| −|S|)!|T_ _|!_

(n −|S| + 1)!


ShS =


(−1)[|][S][|−|][L][|]F (L + T ). (28)
_LX⊆S_


_T ⊆N_ _−S_


Given Hammer and Rudeanu (2012), we have a second form of the multilinear extension as:


_fmt[F]_ [(][x][) =]


_xi, x_ [0, 1][n], (29)
_∈_
_iY∈S_


_a(S)_
_SX⊆N_


where a(S) := _T_ _S[(][−][1)][|][S][|−|][T][ |][F]_ [(][T] [)][ is the Mobius transform of][ F] [(][S][)][.]

_⊆_

Then, one can show the S-derivative of fmt[F] [(][x][)][ is (suppose][ S][ =][ {][i][1][, ..., i] _S_

[P] _|_ _|[}][),]_

_∂[|][S][|]fmt[F]_ [(][x][)]
∆Sfmt[F] [(][x][) :=] = _a(T_ ) _xi._ (30)

_∂xi1_ _, ..., ∂xi|S|_ _TX ⊇S_ _i∈YT −S_

So,

∆Sfmt[F] [(][x][1][) =] _a(T_ )x[|][T][ |−|][S][|]. (31)

_TX ⊇S_

Then it holds,
1 1

∆Sfmt[F] [(][x][1][)][dx][ =] _a(T_ )x[|][T][ |−|][S][|]dx (32)

Z0 Z0 _TX ⊇S_


-----

1

= _a(T_ ) _x[|][T][ |−|][S][|]dx_ (33)

_TX ⊇S_ Z0

= _a(T_ )(|T _| −|S| + 1)[−][1]_ (34)

_TX ⊇S_

According to Grabisch (1997), we have ShS = _T_ _S_ _[a][(][T]_ [)(][|][T] _[| −|][S][|][ + 1)][−][1][, then we reach the]_

_⊇_
conclusion:

1

[P]

ShS = ∆Sfmt[F] [(][x][1][)][dx.] (35)

0

Z

When |S| = 1, we recover the conclusion for Shapley value.

E PROOF OF THEOREM 1

**Theorem 1 (Axiomatisation of K-Step Variational Values of Def. 3). If initialized uniformly, i.e.,**
**x[0]** = x1, x ∈ [0, 1], all the variational values in the trajectory Tσ[−][1](MFI(x; k)), k = 1, 2, 3...
_satisfy the null player, marginalism and symmetry axioms._

_Proof of Theorem 1. In step k, we know that the value to player i is:_


_Tσ[−][1](MFI(x; k))i =_ [F (S + i) − _F_ (S)] _xj_ (1 − _xj[′]_ ) (36)

_S⊆XN_ _−i_ _jY∈S_ _j[′]∈NY−S−i_

For the null player property, since F (S + i) = F (S) always holds, it is easy to see that
_Tσ[−][1](MFI(x; k))i = 0 holds for all i ∈_ _N_ .

Now we will show that the symmetry property holds. The value to player i[′] is:

_Tσ[−][1](MFI(x; k))i′ =_ [F (S[′] + i[′]) _F_ (S[′])] _xj_ (1 _xj′_ ) (37)

_−_ _−_
_S[′]⊆XN_ _−i[′]_ _jY∈S[′]_ _j[′]∈NY−S[′]−i_

Now let us compare different terms in the summands of Eq. (36) and Eq. (37). We try to match the
summands one by one. There are two situations:

**Situation I: For any S ⊆** _N −_ _i −_ _i[′], we choose S[′]_ = S.

In this case we have F (S + i) − _F_ (S) = F (S[′] + i[′]) − _F_ (S[′]). For the products of x we have:

_xj_ (1 _xj′_ ) _xj_ (1 _xj′_ ) = (38)

_−_ _−_ _−_

_jY∈S_ _j[′]∈NY−S−i_ _jY∈S[′]_ _j[′]∈NY−S[′]−i_

_xj_ (1 _xj[′]_ )[(1 _xi[′]_ ) (1 _xi)]_ (39)

_−_ _−_ _−_ _−_

_jY∈S_ _j[′]∈N_ _−YS−i−i[′]_

We know that xi′ = xi holds from step 0, by simple induction, we know that xi′ = xi holds for step
_k as well. So in this situation, the summands equal to each other._

**Situation II: For any S = A + i[′], we choose S[′]** = A + i, where A ⊆ _N −_ _i −_ _i[′]. In this case, it still_
holds that F (S + i) − _F_ (S) = F (S[′] + i[′]) − _F_ (S[′]). For the products of x we have:

_xj_ (1 _xj′_ ) _xj_ (1 _xj′_ ) = (40)

_−_ _−_ _−_

_jY∈S_ _j[′]∈NY−S−i_ _jY∈S[′]_ _j[′]∈NY−S[′]−i[′]_

_xj_ (1 _xj′_ )[xi′ _xi]._ (41)

_−_ _−_

_jY∈A_ _j[′]∈N_ _−YA−i−i[′]_

Again, by the simple induction, we know that xi′ = xi holds for step k.

The above two situations finishes the proof of symmetry.

For the marginalisim axiom, one can see that the update step for the two games are identical, and
it is easy to deduce that they produce exactly the same trajectories, given that they have the same
initializations.


-----

F MISCELLANEOUS RESULTS IN SEC. 4

**Gradient of entropy in Sec. 4.2** Note that q is a fully factorized product distribution q(S; x) :=

_i∈S_ _[x][i]_ _j /∈S[(1][−][x][j][)][,][ x][ ∈]_ [[0][,][ 1]][n][, so its entropy][ H][(][q][(][S][;][ x][))][ can be written as the sum of entropy of]

_n independent Bernoulli distributions. And the entropy of one Bernoulli distribution with parameter_

Q Q

_xi is_
_−xi log xi −_ (1 − _xi) log(1 −_ _xi)_


So we have,


_∇iH(q(S; x)) = ∇i_


_i=1[−xi log xi −_ (1 − _xi) log(1 −_ _xi)]_ (42)

X


= ∇i[−xi log xi − (1 − _xi) log(1 −_ _xi)]_ (43)

= log [1][ −] _[x][i]_ (44)

_xi_

**Satisfying more axioms is not essential for valuation problems. Notably, in cooperative game**
theory, one line of work is to seek for solution concepts that would satisfy more axioms. However,
for valuation problems in machine learning, this is arguably not essential. For example, similar as
what Ridaoui et al. (2018) argues, efficiency does not make sense for certain games.

For a simple illustration, let us consider a voting game from a classification model with 3 binary
features x ∈{0, 1}[3] with weights w = [2, 1, 1][⊤]: f (x) := 1{w⊤x≥3}. Now we are trying to find
the valuation of each feature in N = _x1, x2, x3_ . Naturally, the value function in the corresponding
_{_ _}_
voting game shall be F (S) = f (xS) where xS means setting the coordinates of x inside S to be
1 while leaving others to be 0. In this game let us count how many times each feature could flip
the classification result: for feature x1, there are three situations: F ( 1, 2 ) _F_ ( 2 ), F ( 1, 3 )
_{_ _}_ _−_ _{_ _}_ _{_ _}_ _−_
_F_ ( 3 ) and F ( 1, 2, 3 ) _F_ ( 2, 3 ); for feature x2, there are one situation: F ( 1, 2 ) _F_ ( 1 );
_{_ _}_ _{_ _}_ _−_ _{_ _}_ _{_ _}_ _−_ _{_ _}_
for feature x3, there are one situation: F ( 1, 3 ) _F_ ( 1 ). Then the voting power (or valuation)
_{_ _}_ _−_ _{_ _}_
of each feature shall follows a 3 : 1 : 1 ratio. By simple calculations, one can see that the Banzhaf
values of the three features are [3]4 _[,][ 1]4_ _[,][ 1]4_ [, which is consistent with the ratio of the expected voting]

power. However, the Shapley values of them are [4]6 _[,][ 1]6_ _[,][ 1]6_ [, which is not consistent due to satisfying the]

efficiency axiom.

By the above example we are trying to explain that for valuation problems, satisfying more axioms
is not necessary, sometimes even does not make sense. Whether more axioms shall be considered
and which sets of them shall be added really depend on the specific scenario, which will be left for
important future work.

**The “one-shot sampling trick” to accelerate Alg. 1.** Indeed, Variational Index needs 5 to 10
iterations to converge. In each iteration one has to evaluate the gradient of multilinear extension
_∇fmt[F]_ [(][x][)][, which needs MCMC sampling to estimate the exponential sum.]

Here we suggest a “one-shot sampling trick”, when it is expensive to evaluate the value function
_F_ (S). This trick could reuse the sampled values in each iteration, such that Alg. 1 could run with the
similar cost as calculating Banzhaf values.

The one-shot sampling trick is built upon one formulation taken from Eq. (13):


_∇ifmt[F]_ [(][x][) =]



[F (S + i) _F_ (S)]q(S; (x _xi_ 0))
_S⊆XN_ _−i_ _−_ _|_ _←_


For coordinate i of ∇fmt[F] [(][x][)][, we can firstly sample][ m][ coalitions uniformly randomly from][ 2][N] _[−][i][, and]_
evaluate their marginal contributions. Then in each of the following iterations, one could reuse the
one-shot sampled marginal contributions to estimate the gradient according to the above equation. In
this way, we could make the cost of multi-step running of Alg. 1 similar as that of Banzhaf value in


-----

terms of the number of F (S) evaluations. Compared to the original iterative sampling from q, this
one-shot sampling might come with a variance-complexity tradeoff, for which we will explore as a
future work.

G MORE CONFIGURATION DETAILS AND EXPERIMENTAL RESULTS

G.1 SYNTHETIC EXPERIMENTS ON SUBMODULAR (FLID) GAMES

=
6
𝑛

=
8
𝑛

=
10
𝑛

𝐷 = 4 𝐷 = 8


Figure 5: Comparison of different importance measures for FLID games. Hidden dimensions: First
column D=4, second column D=8. n denotes # of players. Vertical lines means (marginals - 0.5)
since we would like to clearly show positive players (marginal > 0.5) and negative players (marginal
< 0.5).

Here we define a synthetic game with the value function as a FLID (Tschiatschek et al., 2016)
objective F (S), which is a diversity boosting model satisfying the submodularity property. We
know that its multilinear extension admits polynomial time algorithms (Bian et al., 2019). Let
**W** R[|]+[N] _[|×][D]_ be the weights, each row corresponds to the latent representation of an item, with D as
_∈_


-----

the dimensionality. Then

_D_ _D_

_F_ (S) := _i_ _S_ _[u][i][ +]_ _d=1[(max]i_ _S_ _[W][i,d][ −]_ _i_ _S_ _[W][i,d][) =]_ _i_ _S_ _[u]i[′]_ [+] _d=1_ [max]i _S_ _[W][i,d][,][ (45)]_

_∈_ _∈_ _∈_ _∈_ _∈_

X X X X X

which models both coverage and diversity, and u[′]i [=][ u][i] _[−][P]d[D]=1_ _[W][i,d][. In order to test the performance]_
of the proposed variational objectives, we consider small synthetic games with 6, 8 and 10 players
such that the ground truth marginals can be computed exhaustively. We would like to compare
with the true marginals p(i ∈ **S) since they represent the probability that player i participates in all**
coalitions, which is hard to compute in general. The distance to the true marginals is also a natural
measure of the decoupling error as defined in Def. 1. We apply a sigmoid function to Shapley value
and Banzhaf value in order to translate them to probabilities. We calculate the mean squared error
(MSE) and Spearman’s rank correlation (ρ) to the ground truth marginals p(i ∈ **S) and report them**
in the figure legend. Fig. 5 collects the figures, one can see that the Variational Index clearly obtains
better performance in terms of MSE and Spearman’s rank correlation compared to the one-point
solutions (Shapley value and Banzhaf value) in all experiments.

G.2 DETAILS OF THE MODELS FOR FEATURE VALUATIONS

For xgboost, the train accuracy is 0.8934307914376094, the specific configuration with the xgboost
package is:

XGBClassifier ( base_score =0.5, b o o s t e r = ’ g b t r e e ’, c o l s a m p l e _ b y l e v e l =1,
colsample_bynode =1, c o l sa m p le _ b yt r e e =1, gamma=0, gpu_id =−1,
importance_type = ’ gain ’, i n t e r a c t i o n _ c o n s t r a i n t s = ’ ’,
l e a r n i n g _ r a t e =0.300000012, max_delta_step =0, max_depth =6,
min_child_weight =1, missing =nan, m o n o t o n e _ c o n s t r a i n t s = ’ ( ) ’,
n _ e s t i m a t o r s =100, n_jobs =56, n u m _ p a r a l l e l _ t r e e =1,
random_state =0, reg_alpha =0, reg_lambda =1,
scale_pos_weight =1, subsample =1, tree_method = ’ exact ’,
v a l i d a t e _ p a r a m e t e r s =1, v e r b o s i t y =None )

We used the sklearn package for the logistic regression and MLP classifiers. For logistic regression,
the accuracy is 0.8418967476428857, the specific configuration is:

L o g i s t i c R e g r e s s i o n ( random_state =0, s o l v e r =" l i b l i n e a r ", C=0.5)

For the MLP, its accuracy is 0.8614600288688923, and the configuration is:

MLPClassifier ( random_state =0, max_iter =300,
l e a r n i n g _ r a t e _ i n i t =0.002,
h i d d e n _ l a y e r _ s i z e s =(50,50))

G.3 MORE RESULTS ON FEATURE VALUATIONS

In this part we provide more results on feature removal in Figures 6 and 7. Fig. 6 shows similar
behavior as that shown in the main text. Fig. 7 provides not very distinguishable results of the three
criteria.

G.4 MORE AVERAGE RESULTS ON FEATURE VALUATIONS

We provide additional statistical results with the MLP model (Fig. 9) and logistic regression model
(Fig. 10). Meanwhile, we also put the full statistics on the xgboost model in Fig. 8 since in the main
text the table of the samples with “False” grouthtruth label is skipped due to space limit. From Fig. 9
one can observe that Variational Index induces different rankings of the features compared to Shapley
and Banzhaf: Variational Index ranks “Marital Status” the second, while Shapley and Banzhaf put it
in the third location.

It is also very interesting to see that the logistic regression model (with the lowest training accuracy
among the three models, shown in Fig. 10) provides different ranking for the first two features
compared to MLP and xgboost. For the samples with “True” groundtruth labels, “Education-Num” is
the first important feature for the logistic regression model, while “Captical Gain” was ranked first
for the MLP and xgboost.


-----

xgboost

logistic

regression

MLP

|𝑇= 0.8 𝑇= 0.1 𝑇= 0.5|Col2|
|---|---|



Figure 6: First column: Change of predicted probabilities when removing features. The decoupling
_error is included in the legend. Last three columns: waterfall plots of feature importance from_
Variational Index, Shapley and Banzhaf.



xgboost

logistic

regression

MLP

|𝑇= 0.8|Col2|
|---|---|

|𝑇= 0.1 𝑇= 0.5|Col2|
|---|---|


= 0.5
𝑇


Figure 7: Not very distinguishable results. First column: Change of predicted probabilities when
removing features. The decoupling error is included in the legend. Last three columns: waterfall
plots of feature importance from Variational Index, Shapley and Banzhaf.

G.5 EXPERIMENTS WITH MORE PLAYERS

Furthermore, we experiment with a bit larger number of players (n = 80) using MCMC sampling to
approximate the partial derivative in Eq. (13). The sampling based approximation works pretty fast.
Table 2 shows the top 15 ranked players returned by our method, Shapley value and Banzhaf value
for a synthetic data valuation problem. Note that the ranking of Variational Index is more similar to
that of Banzhaf value than that of Shapley value.


-----

|GT Label|s: True 1 2 3|4 5|6 7|8 9|10 11|
|---|---|---|---|---|---|
|Var. In|dex Capital Gain Relationship Age|Education-Num Occupation M|arital Status Capital|Loss Hours per week Sex|Race Workclass|
|Shapl|ey Capital Gain Relationship Education|-Num Age Occupation M|arital Status Hours per|week Capital Loss Sex|Workclass Race|
|Banzh|af Capital Gain Relationship Education|-Num Age Occupation M|arital Status Capital|Loss Hours per week Sex|Race Workclass|

|GT Labels|: False 1 2 3|4 5|6 7|8 9|10 11|
|---|---|---|---|---|---|
|Var. In|dex Capital Gain Relationship Age|Education-Num Occupation Ma|rital Status Capital L|oss Hours per week Sex|Race Workclass|
|Shapl|ey Capital Gain Relationship Capital|Loss Age Education- Ma Num|rital Status Hours per|Work week Occupation class|Country Race|
|Banzh|af Capital Gain Relationship Capital|Loss Age Education- Ma Num|rital Status Hours per|Work week Occupation class|Country Race|


GT Labels: True 1 2 3 4 5 6 7 8 9 10 11 12

Var. Index Capital Gain [Relationship] Age Education-Num Occupation Marital Status Capital Loss Hours per week Sex Race Workclass Country

Shapley Capital Gain [Relationship][ Education-Num] Age Occupation Marital Status Hours per week Capital Loss Sex Workclass Race Country

Banzhaf Capital Gain [Relationship][ Education-Num] Age Occupation Marital Status Capital Loss Hours per week Sex Race Workclass Country

GT Labels: False 1 2 3 4 5 6 7 8 9 10 11 12

Var. Index Capital Gain [Relationship] Age Education-Num Occupation Marital Status Capital Loss Hours per week Sex Race Workclass Country

Shapley Capital Gain [Relationship] Capital Loss Age Education-Num Marital Status Hours per week Occupation Workclass Country Race Sex

Banzhaf Capital Gain [Relationship] Capital Loss Age Education-Num Marital Status Hours per week Occupation Workclass Country Race Sex


Figure 8: Full statistics on valuations with the xgboost classifier (in the main text the last row is
skipped due to space limit). First row: box plot of valuations returned by the three criteria. We always
consider the predicted probability of the ground truth label. “True” means the samples with positive
ground truth label and “False” means with the negative ground truth label. Second and third rows:
Average ranking of the 12 features. Colored texts denote different rankings among the three criteria.

|Col1|Col2|Col3|Col4|Col5|Col6|
|---|---|---|---|---|---|
|||||||
|GT Label|s: True 1 2 3|4 5 6|7|8 9|10 11|
|Var. In|dex Capital Gain M Sta ar ti uta sl Edu Nc ua mt|ion- Relationship Age Hours p|er week Occupation|Capital Loss Sex|Country Race|
|Shapl|ey Capital Gain Edu Nc ua mtion- Marital S|Relationshi tatus p Age Hours p|er week Occupation|Capital Sex Loss|Race Country|
|Banzh|af Capital Gain Edu Nc ua mtion- Marital S|tatus Relationship Age Hours p|er week Occupation|Capital Sex Loss|Race Country|


|Banzh|haf Capital Gain Num Marital S|Status Relationship Age Hours pe|er week Occupation|Sex Loss|Race Country|
|---|---|---|---|---|---|
|GT Labels|: False 1 2 3|4 5|6 7|8 9|10 11|
|Var. In|dex Capital Gain Relationship Edu Nc ua mti|on- Capital Loss Age Ma|rital Status Hours per|week Sex Occupation|Country Workclass|
|Shapl|ey Capital Gain Relationship Education|Capital -Num Loss Marital Status|Age Hours per|week Sex Occupation|Workclass Country|
|Banzh|af Capital Gain Relationship Capital|Loss Marital Status Edu Nc ua mtion-|Age Hours per|week Sex Occupation|Workclass Country|



Figure 9: Statistics on valuations with the MLP classifier. First row: box plot of valuations returned
by the three criteria. We always consider the predicted probability of the ground truth label. “True”
means the samples with positive ground truth label and “False” means with the negative ground truth
label. Second and third rows: Average ranking of the 12 features. Colored texts denote different
rankings among the three criteria.

G.6 EFFECT OF NUMBER OF SAMPLES IN MCMC SAMPLING

Here we illustrate the accuracy sampling tradeoff when estimating the gradient of multilinear extension using MCMC sampling. The results is shown in Fig. 11. One can observe that with more
samples, Alg. 1 will converge faster (in fewer number of epochs).


-----

|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|
|---|---|---|---|---|---|---|---|---|---|---|
|GT Labels: True 1 2 3|||4 5 6|||7 8|9 10||11 12||
|Var. Inde|x Education- Num|Relationship Capital Gai|n Hours per week|Marital Status|Age|Sex Capital|Loss Race|Occupation|Country|Workclass|
|Shapley|Education- Num|Capital Gain Relationshi|Hours per p week|Marital Status|Age|Sex Occup|ation Race|Capital Loss|Country|Workclass|
|Banzhaf|Education- Num|Capital Gain Relationshi|p Hours per week|Marital Status|Age|Sex Occup|ation Race|Capital Loss|Country|Workclass|

|Banzhaf|f Num|Capital Gain Relationship|p week|Status|Age Sex Occupa|ation Race Cap|pital Loss|Country|Workclass|
|---|---|---|---|---|---|---|---|---|---|
|GT Labels: F|alse 1|2 3|4|5|6 7|8 9|10|11|12|
|Var. Inde|x Relationship|Capital Gain Edu Nc ua mtion-|Capital Loss|Age|Hours per week Marital Stat|us Sex Workclass|Race|Occupation|Country|
|Shapley|Relationship|Capital Gain Edu Nc ua mtion-|Capital Loss|Age|Hours per week Marital Stat|us Sex Workclass|Occupati|on Race|Country|
|Banzhaf|Relationship|Capital Gain Edu Nc ua mtion-|Capital Loss|Age|Hours per week Marital Stat|us Sex Workclass|Occupati|on Race|Country|


Figure 10: Statistics on valuations with the logistic regression classifier. First row: box plot of
valuations returned by the three criteria. We always consider the predicted probability of the ground
truth label. “True” means the samples with positive ground truth label and “False” means with the
negative ground truth label. Second and Third rows: Average ranking of the 12 features. Colored
texts denote different rankings among the three criteria.

Table 2: Indices of the top 15 ranked players returned by different methods.

Rank of players 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

Variational Index 9 13 11 3 54 7 18 36 32 42 46 40 6 18 23
Banzhaf value 9 13 11 3 54 18 7 32 46 36 2 27 40 17 10
Shaplay Value 52 33 27 1 4 58 32 14 42 46 40 6 18 23 47

0.0035 m = n

m = 5n
m = 10n

0.0030

0.0025

0.0020

0.0015

Stepwise Difference

0.0010

0.0005

2 4 6 8 10 12 14

# of Epochs


Figure 11: Stepwise difference with difference number of samples m when estimating the gradient of
multilinear extension using MCMC sampling. The three curves: m = n, m = 5n, m = 10n.


-----


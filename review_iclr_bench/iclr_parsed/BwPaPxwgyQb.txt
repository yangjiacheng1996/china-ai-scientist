# PROVABLE LEARNING-BASED ALGORITHM FOR SPARSE RECOVERY


**Xinshi Chen & Haoran Sun**
School of Mathematics
Georgia Institute of Technology
Atlanta, USA
_{xinshi.chen,haoransun}@gatech.edu_

ABSTRACT


**Le Song**
Machine Learning Department
MBZUAI & BioMap
UAE & China
songle@biomap.com


Recovering sparse parameters from observational data is a fundamental problem
in machine learning with wide applications. Many classic algorithms can solve
this problem with theoretical guarantees, but their performances rely on choosing
the correct hyperparameters. Besides, hand-designed algorithms do not fully exploit the particular problem distribution of interest. In this work, we propose a
deep learning method for algorithm learning called PLISA (Provable Learningbased Iterative Sparse recovery Algorithm). PLISA is designed by unrolling a
classic path-following algorithm for sparse recovery, with some components being more flexible and learnable. We theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, we analyze the empirical Rademacher
complexity of PLISA to characterize its generalization ability to solve new problems outside the training set. This paper contains novel theoretical contributions to
the area of learning-based algorithms in the sense that (i) PLISA is generically applicable to a broad class of sparse estimation problems, (ii) generalization analysis
has received less attention so far, and (iii) our analysis makes novel connections
between the generalization ability and algorithmic properties such as stability and
convergence of the unrolled algorithm, which leads to a tighter bound that can
explain the empirical observations. The techniques could potentially be applied to
analyze other learning-based algorithms in the literature.

INTRODUCTION


The problem of recovering a sparse vector β[∗] from finite observations Z1:n (Pβ∗ )[n] is fundamental in machine learning,
covering a broad family of problems including compressed ∼

**observations 𝒁𝟏:𝒏** **true parameter 𝜷[∗]**

sensing, sparse regression analysis, graphical model estimation, etc. It has also found applications in various domains.
For example, in magnetic resonance imaging, sparse signals
need to be reconstructed from measurements taken by a scanner. In computational biology, estimating a sparse graph structure from gene expression data is important for understanding
gene regulatory networks.


_MRI image_ _clean image_

_gene expression data_ _gene regulatory network_

Figure 1: Sparse recovery problems.


Various classic algorithms are available for solving sparse recovery problems. Many of them come
with theoretical guarantees for the recovery accuracy. However, the theoretical performance often
relies on choosing the correct hyperparameters, such as regularization parameters and the learning
rate, which may depend on unknown constants. Furthermore, in practice, similar problems may
need to be solved repeatedly, but it is hard for classic algorithms to fully utilize this information.

To alleviate these limitations, we consider the approach of learning-to-learn and propose a neural
algorithm, called PLISA (Provable Learning-based Iterative Sparse recovery Algorithm). PLISA
is a deep learning model that takes the observations Z1:n as the input and outputs an estimation for
**_β[∗]. To make use of classic techniques developed by domain experts, we design the architecture_**
of PLISA by unrolling and modifying a classic path-following algorithm proposed by Wang et al.


-----

(2014). To benefit from learning, some components in this classic algorithm are made more flexible
with careful design and treated as learnable parameters in PLISA. These parameters can be learned
by optimizing the performances on a set of training problems. The learned PLISA can then be used
for solving other problems in the target distribution.

With the algorithm design problem converted to a deep learning problem, we ask the two fundamental questions in learning theory:

1. Capacity: What’s the recovery accuracy achievable by PLISA? Can the flexible components in
PLISA lead to an algorithm which effectively improves the recovery performance?

2. Generalization: How well can the learned PLISA solve new problems outside the training set?
Is the generalization behavior related to the algorithmic properties of PLISA?

Aiming at supplying rigorous answers to these questions, we conduct theoretical analysis for PLISA
to provide guarantees for its representation and generalization ability. The results and the techniques
in our analysis can distinguish our work from existing studies on algorithm learning. We summarize
our novel contributions into the following three aspects.

**1. Theoretical understanding. In contrast to the plethora of empirical studies on algorithm learn-**
ing, there have been relatively few studies devoted to the theoretical understanding. Existing theoretical efforts primarily focus on analyzing the convergence rate achievable by the neural algorithm (Chen et al., 2018; Liu et al., 2019a; Zhang & Ghanem, 2018; Wu et al., 2020), but the
generalization error bound has received less attention so far. A substantial body of works only argue
intuitively that algorithm unrolling architectures can generalize well because they contain a small
number of parameters. In comparison, we provide theoretical guarantees for both the capacity and
the generalization ability of PLISA, which are more solid arguments.

**2. General setting. The problem setting in this paper is new and more challenging. Existing**
works mainly focus on a specific problem. For example, the compressed sensing problem with a
fixed design matrix is the mostly investigated one. PLISA, however, is generic and is applicable to
various sparse recovery problems as long as they satisfy certain conditions in Assumption C.1.

**3. Novel connection. The algorithmic structure in PLISA can make it behaves differently from**
conventional neural networks. Therefore, we largely utilize the analysis techniques in classic algorithms to derive its generalization bound. By combining the analysis tools of deep learning theory
and optimization algorithms, our result reveals a novel connection between the generalization ability
of PLISA and the algorithmic properties including the convergence rate and stability of the unrolled
algorithm. Benefit from this connection, our generalization bound is tight in the sense that it matches
the interesting behavior of PLISA observed in experiments - the generalization gap could decrease
in the number of layers, which is rarely observed in conventional neural networks.

2 PLISA: LEARNING TO SOLVE SPARSE ESTIMATION PROBLEMS

A sparse estimation problem is to recover β[∗] from finite observations Z1:n sampled from Pβ∗ .
As a concrete example, in a sparse linear regression problem, n observations _Zi = (xi, yi)_ _i=1_
_{_ _}[n]_
are sampled from a linear model y = x[⊤]β[∗] + ϵ, and an algorithm needs to estimate β[∗] from n
observations. Classic algorithms recover β[∗] by minimizing a regularized empirical loss:
**_βλ_** arg min Ln(Z1:n, β) + P (λ, β), (1)
_∈_
where Ln is an empirical loss that measures the “fit” between the parameter β and observations
_Z1:n, and P_ (λ, β) is a sparsity regularization with coefficientb _λ. When Ln is the least square loss_
and P (λ, β) is λ **_β_** 1, the optimization is known as LASSO and can be solved by the well-known
_∥_ _∥_
algorithm ISTA (Daubechies et al., 2004). Based on the idea of algorithm unrolling, Gregor &
LeCun (2010) proposed LISTA, a neural algorithm that interprets ISTA as layers of neural networks.
It has been demonstrated that LISTA outperforms ISTA thanks to its learnable components. Since
then, designing neural algorithms by unrolling ISTA has become an active research topic. However,
existing works mostly focus on the compressed sensing problem with a fixed design matrix only.

To enable for more general applicability, we design the architecture of PLISA by unrolling a classic path-following algorithm called APF (Wang et al., 2014) instead of ISTA. APF is applicable
to nonconvex losses and nonconvex penalty functions, covering a considerably larger range of objectives than LASSO. Designing the architecture based on APF allows PLISA to be applicable to


-----

a broader class of problems such as nonlinear sparse regression, graphical model estimation, etc.
Furthermore, employing nonconvexity can potentially lead to better statistical properties (Fan & Li,
2001; Fan et al., 2009; Loh & Wainwright, 2015), for which we will explain more in Section 3.

In the following, we will introduce APF and the architecture of our proposed PLISA. After that, we
will describe how to optimize the parameters in PLISA under the learning-to-learn setting.

2.1 A BRIEF INTRODUCTION TO APF

We briefly introduce the classic algorithm APF (Wang et al., 2014), and its details are presented in
Algorithm 3 in Appendix I. The key idea of path-following algorithms is creating a sequence of T
**many sub-objectives to gradually approach the target objective that is supposed to be more difficult**
to solve. More specifically, APF approximates the local minimizers of a sequence of sub-objectives:

**_βt_** **_βλt_** arg min _Ln(Z1:n, β) + P_ (λt, β), for t = 1, _, T,_ (2)
_≈_ [b] _∈_ **_β_** _· · ·_

where λ1 > λ2 > · · · > λT is a decreasing sequence of regularization parameters. The last
parameter λT is the target regularization parameter. As a result, APF contains T blocks, and each
block contains an iterative algorithm that minimizes one sub-objective in Eq. 2. The output of the
(t 1)-th block, denoted by βt 1, is used as the initialization of the t-th block, i.e., **_βt[0]_** [=][ β][t][−][1][.]
_−_ _−_
Then the t-th block minimizes the t-th sub-objective by the modified proximal gradient algorithm:

[e]

for k = 1, _, K,_ **_βt[k]_** _t_ **_βt[k][−][1]_** _α_ **_βLn(Z1:n,_** **_βt[k][−][1]) +_** **_βQ(λt,_** **_βt[k][−][1])_** _._ (3)
_· · ·_ _[←T][α][·][λ]_ _−_ _∇_ _∇_

output of t-th block: eβt = **_βt[K][.]_**  e   [e] [e] [] (4)

The notation _δ(β) := sign(β) max_ **_β_** _δ, 0_ is the soft-thresholding function, and the function
_T_ [e] _{|_ _| −_ _}_
_Q is the concave component of P defined as Q(λ, β) := P_ (λ, β) _λ_ **_β_** 1. The number of steps K
_−_ _∥_ _∥_
in each block is determined by certain stopping criteria. It can be seem that the update steps in each
block is similar to the ISTA algorithm, but it is modified in order to incorporate nonconvexity.



2.2 ARCHITECTURE OF PLISA

The architecture of PLISA is designed by unrolling the APF algorithm, and augmenting some learnable parameters θ. Therefore, the
architecture of PLISAθ contains T blocks and each block contains K
layers defined by the K-step algorithm in Eq. 3 (See Figure 2). Note
that in PLISAθ, both K and T are pre-defined. The architecture of
PLISAθ is different from APF as summarized below:

1. Element-wise and learnable regularization parameters. Most
classic algorithms including APF employ a uniform regularization parameter λt across all entries of β, but PLISAθ uses a ddimensional vector λt = [λt,1, · · ·, λt,d][⊤] to enforce different
levels of sparsity to different entries in β. Furthermore, the regularization parameters in PLISAθ are learnable, which will be optimized during the training.


2. Learnable penalty function: Classic algorithms use a pre-defined input ∇𝐿!(𝑍":!, 𝟎)
sparse penalty function P, but PLISAθ parameterizes it as a com- Figure 2: Architecture.

𝜷$

_algorithm stepscell0𝒘,𝜶_ 𝝀
𝜷$%"

… …

𝜷# 𝜼,𝝀[∗]

_algorithm stepscell0𝒘,𝜶_ 𝝀,

𝜷" 𝜼,𝝀[∗]

cell0𝒘,𝜶 𝝀!

_algorithm steps_

𝜷! = 𝟎 𝜼,𝝀[∗]

input𝑍!:# ∇𝐿!(𝑍":!, 𝟎) 𝝀$

bination of q different penalty functions and learns the weights of each penalty. In other words,
PLISAθ can learn to select a specific combination of the penalty functions from training data.

3. Learnable step size: The step sizes in APF are selected by line-search but they are learnable in
PLISAθ. Experimentally, we find the learned step sizes lead to a much faster algorithm.

In later sections of this paper, we will show how such differences can make PLISAθ perform better
than APF both empirically and theoretically.

Algorithm 1 and 2 present the mathematical details of the architecture, follow which we explain
some notations and definitions. Red-colored symbols indicate learnable parameters in PLISAθ.


-----

**Algorithm 1: PLISAθ architecture**


**Algorithm 2: Layers in each block Block[K]w,α**


_#blocks: T_, #layers per block: K
_Parameters: θ = {η, λ[∗], w, α}_
_Input: samples Z1:n_
**_β0_** **0,** **_λ0_** **_βLn(Z1:n, 0)_**
**For ← t = 1, . . ., T ←∇ do**

**_λt ←_** max {σ(η) ◦ **_λt−1, λ[∗]}_**
**_βt ←_** Block[K]w,α[(][Z][1:][n][,][ β][t][−][1][,][ λ][t][)]

**return βT**


_#blocks: T_, #layers per block: K
_Input:Parameters: samples θ = Z {1:nη, λ[∗], w, α}_ _Input:βt[0]_ _Z1:n, βt−1, λt_
**_β0_** **0,** **_λ0_** **_βLn(Z1:n, 0)_** **For[←] k = 1[β][t][−], . . ., K[1]** **do**
**For ← t = 1, . . ., T ←∇ do** **1** e **_gt[k]_** **_βt[k][−][1]) +_** **_βQw(λt,_** **_βt[k][−][1])_**

**_λt ←_** max {σ(η) ◦ **_λt−1, λ[∗]}_** **_βt[k]_** _[←∇][β][L]t[n][(][Z]β[1:]t[k][−][n][1][,][ e]_ _α_ **_gt[k] ∇_**
**_βt_** Block[K]w,α[(][Z][1:][n][,][ β][t][−][1][,][ λ][t][)] _[←T][α][·][λ]_ _−_ _·_ [e]

**return ← βT** **return βt =** **_βt[K]_** 

e e

**Regularzation parameters. In PLISAθ, the element-wise regularization parameters are initialized[e]**
by a vector λ0 := ∇βLn(Z1:n, 0), and then updated sequentially by
**_λt ←_** max {σ(η) ◦ **_λt−1, λ[∗]},_** (5)
where σ(·), ◦, and max{·, ·} are element-wise sigmoid function, multiplication, and maximization.
_{η, λ[∗]} are both d-dimensional learnable parameters. Eq. 5 creates a sequence λ1, · · ·, λT through_
the decrease ratio σ(η), until they reach the target regularization parameters λ[∗].

**Penalty function. PLISAθ parameterizes the penalty function as follows,**

exp(wi)
_Pw(λ, β) =_ _i=1_ _wi_ _P_ [(][i][)](λ, β), where _wi =_ _q_ (6)

In other words,weights of these functions are determined by learnable parameters Pw is a learnable convex combination of[P][q] [f] · _q penalty functions f_ **_wP = [i[′]_** =1w[exp(]1, (P[w][i], w[(1)][′] [)] _[.], · · ·q]. In this paper,, P_ [(][q][)]). The
_· · ·_
we focus on learning the combination of three well-known penalty functions:

_P_ [(1)](λ, β) = ∥λ ◦ **_β∥1, P_** [(2)](λ, β) = _j=1_ [MCP(][λ][j][, β][j][)][, P][ (3)][(][λ][,][ β][) =][ P]j[d]=1 [SCAD(][λ][j][, β][j][)][,]

where P [(1)] is convex, and MCP (Zhang, 2010a) and SCAD (Fan & Li, 2001) are nonconvex penal_ties whose analytical forms are given in Appendix[P][d]_ B. One can include any other penalty functions as
long as they satisfy a set of conditions specified in Appendix B. Qw(λ, β) := Pw(λ, β) **_λ_** **_β_** 1
_−∥_ _◦_ _∥_
represents the concave component of Pw. The analytical form of **_βQw(λt, β) are in Appendix B._**
_∇_


2.3 LEARNING-TO-LEARN SETTING

Now we describe how to train the parameters θ in PLISAθ under the learning-to-learn setting.

**Training set. Similar to other works in this domain, we assume the access to m problems from the**
target problem-space P, and use them as the training set:

_Dm = {(Z1:[(1)]n1_ _[,][ β][∗][(1)][)][,][ · · ·][,][ (][Z]1:[(][m]n[)]m_ _[,][ β][∗][(][m][)][)][}]_ with (Z1:[(][i]n[)] _i_ _[,][ β][∗][(][i][)][)][ ∈P][.]_
Here each estimation problem is represented by a pair of observations and the corresponding true
parameter to be recovered. A different problem i can contain a different number ni of observations.

**Training loss. Since the intermediate outputs βt(Z1:n; θ) of PLISAθ are also estimates of β[∗], a**
common design of the training loss is the weighted sum of the intermediate estimation errors (Chen
et al., 2021). More specifically, we employ the following training loss:

_m_ _T_

2

_train[(][D][m][;][ θ][) := 1]_ _γ[T][ −][t]_ **_βt(Z1:[(][i]n[)]_** _i_ [;][ θ][)][ −] **_[β][∗][(][i][)]_** (7)
_L[γ]_ _m_ 2 _[,]_

_i=1_ _t=1_

X X

where γ < 1 is a discounting factor If γ = 0 then the loss is only estimated at the last layer.

**Generalization error. The ultimate goal of algorithm learning is to minimize the estimation error**
on expectation over all problems in the target problem distribution:

_Lgen(P(P); θ) := E(Z1:n,β∗)∼P(P) ∥βT (Z1:n; θ) −_ **_β[∗]∥2[2]_** _[,]_ (8)

where P(P) is a distribution in the target problem-space P. Let θ[∗] _∈_ arg min Ltrain[γ][=0] [(][D][m][;][ θ][)][ be a]
minimizer of the training loss. It is well-known that the generalization error can be bounded by:


_Lgen(P(P); θ[∗]) ≤Lgen(P(P); θ[∗]) −Ltrain[γ][=0]_ [(][D][m][;][ θ][∗][)] + _Ltrain[γ][=0]_ [(][D][m][;][ θ][∗][)]
generalization gap: Theorem 4.1 training error: Theorem 3.1

We will theoretically characterize these two terms in Theorem 3.1 and Theorem 4.1.

| {z } | {z }


(9)


-----

3 CAPACITY OF PLISA

Can PLISAθ achieve a small training error without using too many layers? How can designs of
element-wise regularization and learnable penalty functions help PLISAθ to achieve a smaller training error compared to classic algorithms? We answer this question theorectically in this section.

3.1 FIRST MAIN RESULT: CAPACITY

Let βt(Z1:n; θ) be the output of the t-th block in PLISAθ. Let x _a denote entry-wise maximal_
_∨_
value max{x, a}. Let (x)S denote the sub-vector of x with entries indexed by the set S.
_TTheorem 3.1 be the number of blocks in (Capacity). Assume the problem space PLISAθ and let K be the number of layers in each block. For any P satisfies Assumption C.1 and Dm ⊆P. Let_
_ε > 0, there exists a set of parameters θ = {η, λ[∗], w, α} such that the estimation error of every_
_problem (Z1:n, β[∗]) ∈Dm is bounded as follows, ∀T > t0,_

_∥βT (Z1:n; θ) −_ **_β[∗]∥2 ≤_** _ε[−][1]cθs[∗]_ exp(−CθK(T − _t0))_ **_optimization error_** (10)

+ c[′]θ[κ][m][∥] [(][∇][β][L][n][(][Z][1:][n][,][ β][∗][)][ ∨] _[ε][)]S[∗]_ _[∥][2][,]_ **_statistical error_** (11)
_where S[∗]_ := supp(β[∗]) is the support indices of β[∗], cθ, c[′]θ[, and][ C][θ][ are some positive values de-]
_pending on the chosen θ, and κm is a condition number which reveals the similarity of the problems_
_in Dm. Note that K and t0 are required to be larger than certain values, but we will elaborate in_
_Appendix E that the required lower bounds are small. See Appendix E for the proof of this theorem._

This estimation error can be interpreted as a combination of the optimization error (in Eq. 10) and the
statistical error (in Eq. 11). The optimization error decreases linearly in both K and T . The statistical
erroroccurs because of the randomness in Z1:n. The gradient at the true parameter **_βLn(Z1:n, β[∗])_**
_∇_
characterizes how well the finite samples Z1:n can represent the distribution Pβ∗ .

A direct consequence of Theorem 3.1 is that the training error can be small without using too many
layers and blocks in PLISAθ. We will also elaborate on how the entry-wise regularization and
learnable penalty function can effectively reduce the training error in the following.

_(i) Impact of entry-wise regularization. Restricting the regularization to be uniform across entries_
will lead to an error bound that replaces the statistical error ( **_βLn(Z1:n, β[∗])_** _ε)S∗_ 2 in Eq. 11
_∥_ _∇_ _∨_ _∥_
by _√s[∗]_ (∥∇βLn(Z1:n, β[∗])∥∞ _∨_ _ε). To understand how the former has improved the latter, we_

can consider the sparse linear regression problem. If the design matrix is normalized such that
max1≤j≤d ∥([x1]j, · · ·, [xn]j)∥2 ≤ _[√]n, then ∥_ (∇βLn(Z1:n, β[∗]) ∨ _ε)S∗_ _∥2 ≤_ _C_ _s[∗]/n with high_

probability. In comparison, _√s[∗]_ **_βLn(Z1:n, β[∗])_** _C_ _s[∗]_ log d/n with high probability is a

_∥∇_ _∥∞_ _≤_ p

slower statistical rate due to the term log d.

p

_(ii) Impact of learnable penalty function. To explain the the benefit of using learnable penalty_
function, we give a more refined bound for the statistical error in Eq. 11 in the following lemma.
**Lemma 3.1 (Refined bound). Assume the same conditions and parameters θ in Theorem 3.1. As-**
_sume T →∞_ _so that the optimization error can be ignored. For simplicity, assume_ _w3 = 0 and only_
_consider the weights_ _w1 and_ _w2 for ℓ1 penalty and MCP. Then for every problem (Z1:n, β[∗]) ∈Dm:_

_w2)κm_
_∥β∞(Z1:n; θ) −_ **_β f[∗]∥2 ≤+_** [1+8(1] f[1+8(1+]ρρ−−−−[−]wwfw[f][f]222/b/b)κm _∥∥((∇∇ββLLnn((ZZ1:1:nn,, β β[∗][∗])) ∨ ∨_ _εε))SS2[∗]1[∗]_ _[∥][2]_  SS12[∗][∗][: Small][: Large] f _ββj[∗]j[∗]_ _’s’s_ _, (13)(12)_

_[∥][2]_

_where b > 1 is a hyperparameter inf MCP, and the index sets S1[∗]_ _[and][ S]2[∗]_ _[are defined as] _ _[ S]1[∗]_ [:=] _[ {][j][ ∈]_
_S[∗]_ : _βj[∗]_ _≤_ _bλ[∗]j_ _[}][ and][ S]2[∗]_ [:=][ {][j][ ∈] _[S][∗]_ [:] _βj[∗]_ _> bλ[∗]j_ _[}][. See Appendix][ E][ for the proof.]_

This refined bound reveals the benefit of learning the penalty function because:

1. According to Lemma 3.1, the optimal penalty function is problem-dependent. For example, if
(8(bρ + 1)κm + 1) ( **_βLn(Z1:n, β[∗])_** _ε)S1[∗]_
_ε)S2[∗]_ _−_ _w2∥ = 0∇_ can induce a smaller error bound. Otherwise, ∨ _[∥][2][ >][ (8(][bρ][−]_ _[−]_ [1)][κ][m][ −] [1)][∥][(][∇]w[β]2 = 1[L][n][(][Z][1:] is better.[n][,][ β][∗][)][ ∨]
Therefore, learning is a more suitable way of choosing the penalty function.[∥][2][, choosing][ f]

2. The convergence speed Cθ in Eq. 10 is also affected by the weights, monotonely decreasing

f

in _w2. Through gradient-based training, we can automatically find the optimal combination of_
penalty functions to strike a nice balance between the statistical error and convergence speed.
f


-----

4 GENERALIZATION ANALYSIS

How well can the learned PLISAθ solve new problems outside the training set? In this section, we
conduct the generalization analysis in a novel way to focus on answering the questions:

How is the generalization bound of PLISAθ related to its algorithmic properties?
And how is it different from conventional neural networks?

4.1 SECOND MAIN RESULT: GENERALIZATION BOUND

To analyze the generalization properties of neural networks, many works have adopted the analysis
framework of Bartlett & Mendelson (2002) to bound the Rademacher complexity via Dudley’s integral (Bartlett et al., 2017; Chen et al., 2019; Garg et al., 2020; Joukovsky et al., 2021). A key step
in this analysis framework is deriving the robustness of the training loss to the small perturbation in
model parameters θ. Since we can view PLISAθ as an iterative algorithm, we borrow the analysis
tools of classic optimization algorithms to derive its robustness in θ. The following lemma states this
key intermediate result, which connects the Lipschitz constant to algorithmic properties of PLISAθ.

**Lemma 4.1PLISAθ contains (Robustness to T > t0 blocks and θ). Assume K layers. Consider a parameter space P satisfies Assumption C.1 and D Θm ∼ in which the param-P(P)[m]. Assume**
_eters satisfy (i) α ∈_ [αmin, _ρ1+_ []][, (ii)][ η][j][ ∈] [[][σ][−][1][(0][.][9)][, η][max][]][, (iii)][ f]w2 [1]b [+][ f]w3 _a−1_ 1 _[≤]_ _[ξ][max][ < ρ][−][, and]_

_(iv) λ[∗]j_ (Z1:n,β∗ )∈Dm
_ηmax, ξmax[∈]_ [[8 sup], and λmax. Then for any[|][[][∇][β][L][n] θ[(][Z] =[1:][n][,]η[ β], λ[∗][)]][∗][j],[| ∨] w, α[ε, λ] and[max] θ[]][ with some positive constants][′] = **_η[′], λ[∗′], w[′], α[′]_** _in Θ, and for[ α][min][,]_
_{_ _}_ _{_ _}_
_any recovery problem (Z1:n, β[∗])_ _m, the following inequality holds,_
_∈D_

_∥βT (Z1:n; θ) −_ **_βT (Z1:n; θ[′])∥2 ≤_** _c1K(T −_ _t0)√s[∗]_ _|α −_ _α[′]| exp(−CΘK(T −_ _t0))_ (14)

convergence rate

+ _c2∥η −_ **_η[′]∥2 + c3∥λ[∗]_** _−_ **_λ[∗′]∥2 + c4√d∥w −_** **_w[′]∥2_** |(1 − exp({z−CΘKT ))}, (15)
  stability rate

| {z }

_where c1, c2, c3, c4 and CΘ are some positive constants. Note that similar to Theorem 3.1, K and t0_
_are required to be larger than certain small values. See Appendix F.1 for the proof._

**Convergence rate & step size perturbation. In Eq. 14, the Lipschitz constant in the step size α**
scales at the same rate as the convergence rate of PLISAθ, decreasing exponentially in T and K
(See Fig. 3 for a visualization). To understand this, consider when both step sizes α and α[′] are within
the convergence region (i.e., (0, ρ[−]+[1][]][). After infinitely many steps, their induced outputs will both]
converge to the same optimal point. This intuitively explains why the output perturbation caused by
_α-perturbation has the same decrease rate as the optimization error._


_∥βT (Z1:n; θ) −_ **_βT (Z1:n; θ[′])∥2 ≤_** _c1K(T −_ _t0)_


_c2∥η −_ **_η[′]∥2 + c3∥λ[∗]_** _−_ **_λ[∗′]∥2 + c4_**


**Stability rate & regularization perturbation.** Convergence Rate Stability Generalization Bound
In the literature of optimization, stability of an
algorithm expresses its robustness to small perturbation in the optimization objective. This
is clearly related to the robustness of PLISAθ KT KT KT
to the perturbation in η, λ[∗], w, because these Convergence Rate Stability Generalization Bound
parameters jointly determine the regularization
_Pw(λt, β), which is a part of the optimiza-_
tion objective. Therefore, we exploit the analysis techniques for algorithmic stability to derive KT KT KT
the robustness in (η, λ[∗], w)-perturbation and ob
Convergence Rate Stability Generalization Bound

KT KT KT

Convergence Rate Stability Generalization Bound

KT KT KT

tain the Lipschitz constant in Eq. 15, which is Figure 3: Visualization of convergence, stability,

and generalization bound in Theorem 4.1. The two

bounded but increasing in T and K (See Fig. 3

sets of visualizations are obtained by choosing differ
for a visualization).

ent speeds CΘ in the convergence rate and stability.

Based on the key result in Lemma 4.1, we can apply Dudley’s integral to measure the empirical
Rademachar complexity which immediately yields the following generalization bound.


-----

**Theorem 4.1 (Generalization gap). Assume the assumptions in Lemma 4.1. For any ϵ > 0, with**
_probability at least 1 −_ _ϵ, the generalization gap is bounded by_

_gen(P(_ ); θ) _train[(][D][m][;][ θ][)][ ≤]_ _[c][1]_ _m[−][1]_ log(4ϵ[−][1]) + (16)
_L_ _P_ _−L[γ][=0]_

_c2m[−][1]_ log _√mKT_ exp( _CΘK(T_ _t0))_ 1 + c3dmp _[−][1]_ log _√m(1_ exp( _CΘKT_ )) _,_
_−_ _−_ _∨_ _−_ _−_

q convergence rate stability

     

_where c1, c2, c3, CΘ are constants independent of d, m, K and T_ _. See Appendix F for the proof._

| {z } | {z }

Fig. 3 visualizes how the generalization bound in Theorem 4.1 grows when KT increases. The two
sets of plots look slightly different by picking different constants CΘ. We have also tried varying
the values of c2, c3, d, m in Theorem 4.1. Overall, they lead to the two types of behaviors in Fig. 3.

An important observation in Theorem 4.1 and Figure 3 is that the generalization gap could decrease
_in the number of layers, and we will see in Section 7 that this matches the empirical observations._
It also distinguishes algorithm-unrolling based architectures from conventional neural networks,
whose generalization gaps rarely decrease in the number of layers.

_Remark. The above generalization results are conducted on a constrained parameter space (as de-_
scribed in Lemma 4.1) so that we can utilize the algorithmic properties of PLISAθ. We focus on
this space because the analysis contains more interesting and new ingredients. For parameters outside this space, the analysis procedure is similar to other conventional recurrent networks. Since the
bound in Theorem 4.1 has matched the empirical observations, it is reasonable to believe that after
training, the learned parameters are likely to be in this ‘nice’ constrained space.

5 EXTENSION TO UNSUPERVISED LEARNING-TO-LEARN SETTING

Real-world datasets may not contain the ground-truth parameters β[∗], but only contain the samples
loss to minimize the empirical loss functionfrom each task, Dm[U] [=][ {][Z]1:[(1)]n[,][ · · ·][, Z]1:[(][m]n[)][}][. In this setting, we can construct an unsupervised training] Ln (e.g., the likelihood function) on the samples.


**Unsupervised training loss:** _train[(][D]m[U]_ [;][ θ][) := 1]
_L[U]_ _m_


_Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ β][T][ (][Z]1:[(][i]n[)]_ 1 [;][ θ][)] (17)
_i=1_

X   


In this loss, both Z1:[(][i]n[)] 1 [and][ Z]1:[(][i]n[)] 2 [are subsets of][ Z]1:[(][i]n[)] [. The samples][ Z]1:[(][i]n[)] 1 [are used as the input to]

PLISAθ and the samples Z1:[(][i]n[)] 2 [are used for evaluating the output][ β][T][ from][ PLISA][θ][.]

Let θU[∗] _train[(][D]m[U]_ [;][ θ][)][ be a minimizer to this unsupervised loss.][ Theoretically][, to bound]
the generalization error of[∈] [arg min][ L][U] _θU[∗]_ [, we can show that]

_gen(P(_ );θU[∗] [)][ ≤] _m[C]_ _mi=1_ _Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ β][T][ (][Z]1:[(][i]n[)]_ 1 [;][ θ]U[∗] [)] _Ln2_ _Z1:[(][i]n[)]_ 2 _[,][ β][∗][(][i][)][]_ (18)
_L_ _P_ _−_

P    unsupervised training error  

+ _gen|(P(_ ); θU[∗] [)][ −L][γ]train[=0] [(][D][m][;][ θ]U[∗]{z[)] + _m[C]_ _mi=1[∥∇][β][L][n]2_ [(][Z]1:[(][i]n[)] 2 _[,][ β]}_ _[∗][(][i][)][)][∥]2[2]_ _._ (19)
_L_ _P_
generalization gap: Theorem 4.1 statistical error

P

Compared to Eq. 9|, this upper bound contains an additional statistical error, which appears because{z } | {z }
of the gap between the unsupervised loss and the true error that we aim to optimize. Clearly, in this
upper bound, the generalization gap can be bounded by Theorem 4.1. Furthermore, the unsupervised
training error in Eq. 18 can be bounded by combining Theorem 3.1 with the following in equality.

_Ln2 (Z1:n2_ _, βT (Z1:n1_ ; θU[∗] [))][ −] _[L][n]2_ [(][Z][1:][n]2 _[,][ β][∗][)]_ (20)
_≤_ _Ln2 (Z1:n2_ _, βT (Z1:n1_ ; θ[∗])) − _Ln2 (Z1:n2_ _, β[∗])_

**_βLn2_** (Z1:n2 _, β[∗])_ 2 **_βT (Z1:n1_** ; θ[∗]) **_β[∗]_** 2 + _[ρ]2[+]_ 2 _._ (21)
_≤∥∇_ _∥_ _∥_ _−_ _∥_ _[∥][β][T][ (][Z][1:][n][1]_ [;][ θ][∗][)][ −] **_[β][∗][∥][2]_**
bounded by Theorem 3.1 bounded by Theorem 3.1

More details of the extension to unsupervised setting can be found in Appendix| {z } | {z H. }


-----

6 RELATED WORK

Learning-to-learn has become an active research direction in recent years (Bora et al., 2017;
Franceschi et al., 2017; Niculae et al., 2018; Denevi et al., 2018; Poganˇci´c et al., 2019; Liu et al.,

2019b; Berthet et al., 2020). Many works share the idea of unrolling or differentiating through algorithms to design the architecture (Yang et al., 2017; Borgerding et al., 2017; Corbineau et al.,
2019; Xie et al., 2019; Shrivastava et al., 2020; Chen et al., 2020a; Wei et al., 2020; Indyk et al.,
2019; Grover et al., 2019; Wu et al., 2019). A well-known example of learning-based algorithm is
LISTA (Gregor & LeCun, 2010) which interprets ISTA (Daubechies et al., 2004) as layers of neural networks and has been an active research topic (Zhang & Ghanem, 2018; Kamilov & Mansour,
2016; Chen et al., 2018; Liu et al., 2019a; Wu et al., 2020; Kim & Park, 2020).

However, the generalization of algorithm learning has received less attention. The only exceptions
are several works. However, Chen et al. (2020b) and Wang et al. (2021) only consider learning
to optimize quadratic losses. Behboodi et al. (2020); Joukovsky et al. (2021) do not connect the
generalization analysis with algorithmic properties to provide tighter bounds as in our work. Unlike
our work that analyzes the Lipschitz continuity (Lemma 4.1), the work of Gupta & Roughgarden
(2017); Balcan et al. (2021) studied the generalization of learning-based algorithms with a focus
on scenarios when the Lipschitz continuity is unavailable. We will refer the audience to Shlezinger
et al. (2020); Chen et al. (2021) for a more comprehensive summary of related works.

7 EXPERIMENTS

7.1 SYNTHETIC EXPERIMENTS

In synthetic datasets, we consider sparse linear regression problems and sparse precision matrix
estimation problems for Gaussian graphical models. Specifically, we recover target vectors β[∗] _∈_
R[d], where d = {256, 1024} in SLR, and estimate precision matrices Θ[∗] _∈_ R[d][×][d], where d =
_{50, 100} in SPE. See Appendix I.2 for descriptions of the dataset and data preparation.dim=256_ dim=1024

7.1.1 SPARSE LINEAR REGRESSION (SLR) 30 apf 40

In this experiment, we compare PLISA with several rnn 30
baselines and also verify the theorems. 20 rnn_l1

**Performance comparison. We consider baselines** 10
including APF (Wang et al., 2014), ALISTA (Liu 5
et al., 2019a), RNN (Andrychowicz et al., 2016), and 0
RNN-ℓ1. APF is the path-following algorithm that 0.0 0.1 0.2 0.3 0.4 0.5 0 0.0 0.2 0.4 0.6

|dim=256|Col2|Col3|
|---|---|---|
||apf||
||plisa alist|a|
||rnn||
||rnn_|l1|
||||
||||
||||
||||
||||


|Col1|dim=1024|Col3|
|---|---|---|
||||
||||
||||
||||
||||
||||

is used as the basis of our architecture. ALISTA is wall-clock time (sec) wall-clock time (sec)

dim=256 dim=1024

30 apfplisa 40

25 alista

rnn 30

20 rnn_l1

15 20

l2-error

10

10

5

0

0

0.0 0.1 0.2 0.3 0.4 0.5 0.0 0.2 0.4 0.6

wall-clock time (sec) wall-clock time (sec)

a representative of algorithm unrolling based archi- Figure 4: Convergence of recovery error. Since
tectures, which is an advanced variant of LISTA. We APF takes a long time to converge, its curve are
have tried the vanilla LISTA, but it performs worse outside the range of these plots. We use a dashthan ALISTA on our tasks so it is not reported. RNN line to represent the final ℓ2 error it achieves.
refers to the LSTM-based model in Andrychowicz et al. (2016). Besides, we add a soft-thresholding
operator to this model to enforce sparsity, and include this variant as a baseline, called RNN-ℓ1.
Except for APF, all methods are trained on the same set of training problems and selected by the
validation problems. For APF, we perform grid-search to choose its hyperparameters, which is also
selected by the validation set. The detailed specification of each model can be found in Appendix I.3.

Fig. 4 shows the convergence of **_βt_** **_β[∗]_** 2 for 0.20 −0.1−0.2
problems in the test set. The x ∥-axis indicates − _∥_ 0.15 −0.3
the wall-clock time. In terms of the final re- 0.10 −0.4
covery accuracy, PLISA outperforms all base- 0.05 −0.5
line methods. In the more difficult setting (i.e, 0 50 100 150 200 250 300 0 50 100 150 200 250 300
_d = 1024), its advantage is obvious. Although_ KT KT

0.20 −0.1

−0.2

0.15

−0.3

0.10 −0.4

0.05 −0.5

Generalization Gap −0.6

0 50 100 150 200 250 300 0 50 100 150 200 250 300

KT KT

PLISA is slightly slower than other deep learn- Figure 5: Generalization gap of PLISA with varying
ing based models due to the computations of _KT_, for two different experimental settings.
MCP and SCAD, PLISA achieves a better accuracy and it has been converging much faster than the
classic algorithm APF. APF is very slow mainly due to the use of line-search for selecting step sizes.


-----

**Generalization gap. We are interested in the generalization behavior of PLISA. As this experiment**
is conducted for theoretical interest, we do not use the validation set to select the model. We vary
the number of layers (K) and blocks (T ) in PLISA to create a set of models with different depths.
For each depth, we train the model with 2000 training problems, and then test it on a separate set of
100 problems to approximate the generalization gap. In Fig. 5, we observe the interesting behavior
of the generalization gap, where the left one increases in KT at the beginning and then decrease to
a constant, and the right one increases fast and then decrease very slowly. This surprisingly matches
the two different visualizations in Fig. 3 of the predicted generalization gap given by Theorem 4.1.

7.1.2 SPARSE PRECISION MATRIX ESTIMATION (SPE)

We compare PLISA with APF, GLASSO (Friedman et al., 2008), GISTA (Guillot et al., 2012), and
GGM (Belilovsky et al., 2017) on sparse precision estimation tasks in Gaussian graphical models.
GLASSO estimates the precision matrix by block-coordinate decent methods. GISTA is a proximal
gradient method for precision matrix estimation. GGM utilizes convolutional neural network to
estimate the precision matrix. Details of each model and the training can be found in Appendix I.4.


Table 1 reports the Frobenius error ∥Θ −
Θ[∗]∥F[2] [between the estimation][ Θ][ and the]
true precision matrix Θ[∗], averaged over
100 test problems. PLISA achieves consistent improvements. Classic algorithm
are slower because they perform linesearch. GLASSO is faster than other classic algorithm because we use the sklearn
package (Pedregosa et al., 2011) in which
the implementations are optimized.


Table 1: Recovery error in SPE. The reported time is the av
|erage wall-clock time for solving each instance in seconds.|Col2|
|---|---|
|Sizes p = 50 p = 100 Methods ∥Θ −Θ∗∥2 Time ∥Θ −Θ∗∥2 Time F F||
|PLISA GLASSO GISTA APF GGM|119.47 ± 12.23 0.117 142.70 ± 13.38 0.132 169.63 ± 17.99 1.66 237.95 ± 27.49 3.12 186.96 ± 25.48 53.47 373.66 ± 41.72 36.02 269.51 ± 32.28 46.02 485.94 ± 60.33 86.82 194.26 ± 10.73 0.007 445.00 ± 58.89 0.008|


7.1.3 DISCUSSION ON TRAINING-TESTING TIME

**Test time. Fig. 4 and Table 1 shows the wall-clock time for solving test problems. Overall, classic**
algorithms are slower because they need to perform line-search. It is noteworthy that learning-based
methods can solve a batch of problems parallelly but most classic algorithms cannot. To allow more
advantages for classic algorithms, the test problems are solved without batching in all methods.

**Train time. As metioned earlier, we perform grid-search to select the hyperparameters in classic**
algorithms using validation sets. The training time comparison is summarized in Table 3 and Table 4
in Appendix I.4. We can see that training time is not a bottleneck of this problem. Moreover, In
SPE, classic algorithms even require a longer training time than learning-based methods.

7.2 UNSUPERVISED LEARNING ON REAL-WORLD DATASETS

We conduct experiments of unsupervised algorithm learning on 3 datasets: Gene expression
dataset (Kouno et al., 2013), Parkinsons patient dataset (Tsanas et al., 2009), and School exam
score dataset (Zhou et al., 2011). See Appendix I.6 for details of datasets and the configuration.

The goal of the algorithm is to estima- Table 2: Recovery accuracy on real-world datasets.
tion the sparse linear regression parame
ror on a set of held-out samples for each
problem. Table 2 shows the effectiveness

|Col1|PLISA|APF|RNN|RNN-ℓ 1|ALISTA|
|---|---|---|---|---|---|
|Gene Parkinsons School|1.177 11.63 296.6|1.289 11.86 367.9|1.639 11.91 561.5|1.349 13.05 310.3|1.289 34.843 884.2|

of PLISA. Note that these real-world datasets may not satisfy the assumptions in this paper. This
set of experiments are conducted only to demonstrate the robustness of the proposed method.

8 DISCUSSION

We proposed PLISA for learning to solve sparse parameter recovery problems. We analyze its
capacity and generalization ability. The techniques could be used to derive guarantees for other
algorithm-unrolling based architectures. The model PLISA can be improved by using a more flexible penalty function (e.g., a conventional neural network) as long as it satisfies Assumption B.1.


-----

REFERENCES

Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient
descent. In Advances in Neural Information Processing Systems, pp. 3981–3989, 2016.

Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and Ellen
Vitercik. How much data is sufficient to learn high-performing algorithms? generalization guarantees for data-driven algorithm design. In Proceedings of the 53rd Annual ACM SIGACT Sym_posium on Theory of Computing, pp. 919–932, 2021._

Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002.

Peter L Bartlett, Dylan J Foster, and Matus J Telgarsky. Spectrally-normalized margin bounds for
neural networks. In Advances in Neural Information Processing Systems, pp. 6240–6249, 2017.

Arash Behboodi, Holger Rauhut, and Ekkehard Schnoor. Compressive sensing and neural networks
from a statistical learning perspective. arXiv preprint arXiv:2010.15658, 2020.

Eugene Belilovsky, Kyle Kastner, Ga¨el Varoquaux, and Matthew B Blaschko. Learning to discover
sparse graphical models. In International Conference on Machine Learning, pp. 440–448. PMLR,
2017.

Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, and Francis
Bach. Learning with differentiable perturbed optimizers. arXiv preprint arXiv:2002.08676, 2020.

Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. In International Conference on Machine Learning, pp. 537–546. PMLR, 2017.

Mark Borgerding, Philip Schniter, and Sundeep Rangan. Amp-inspired deep networks for sparse
linear inverse problems. IEEE Transactions on Signal Processing, 65(16):4293–4308, 2017.

S´ebastien Bubeck. Convex optimization: Algorithms and complexity. _arXiv preprint_
_arXiv:1405.4980, 2014._

Emmanuel J Candes and Terence Tao. Decoding by linear programming. IEEE transactions on
_information theory, 51(12):4203–4215, 2005._

Minshuo Chen, Xingguo Li, and Tuo Zhao. On generalization bounds of a family of recurrent neural
networks. arXiv preprint arXiv:1910.12947, 2019.

Tianlong Chen, Xiaohan Chen, Wuyang Chen, Howard Heaton, Jialin Liu, Zhangyang Wang, and
Wotao Yin. Learning to optimize: A primer and a benchmark. arXiv preprint arXiv:2103.12828,
2021.

Xiaohan Chen, Jialin Liu, Zhangyang Wang, and Wotao Yin. Theoretical linear convergence of unfolded ista and its practical weights and thresholds. In Advances in Neural Information Processing
_Systems, pp. 9061–9071, 2018._

Xinshi Chen, Yu Li, Ramzan Umarov, Xin Gao, and Le Song. Rna secondary structure prediction
by learning unrolled algorithms. arXiv preprint arXiv:2002.05810, 2020a.

Xinshi Chen, Yufei Zhang, Christoph Reisinger, and Le Song. Understanding deep architecture with
reasoning layer. Advances in Neural Information Processing Systems, 33, 2020b.

M-C Corbineau, Carla Bertocchi, Emilie Chouzenoux, Marco Prato, and J-C Pesquet. Learned
image deblurring by unfolding a proximal interior point algorithm. In 2019 IEEE International
_Conference on Image Processing (ICIP), pp. 4664–4668. IEEE, 2019._

Ingrid Daubechies, Michel Defrise, and Christine De Mol. An iterative thresholding algorithm
for linear inverse problems with a sparsity constraint. Communications on Pure and Applied
_Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences, 57(11):1413–_
1457, 2004.


-----

Giulia Denevi, Carlo Ciliberto, Dimitris Stamos, and Massimiliano Pontil. Learning to learn around
a common mean. Advances in Neural Information Processing Systems, 31:10169–10179, 2018.

Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle
properties. Journal of the American statistical Association, 96(456):1348–1360, 2001.

Jianqing Fan, Yang Feng, and Yichao Wu. Network exploration via the adaptive lasso and scad
penalties. The annals of applied statistics, 3(2):521, 2009.

Luca Franceschi, Paolo Frasconi, Michele Donini, and Massimiliano Pontil. A bridge between
hyperparameter optimization and larning-to-learn. stat, 1050:18, 2017.

Jerome Friedman, Trevor Hastie, and Robert Tibshirani. Sparse inverse covariance estimation with
the graphical lasso. Biostatistics, 9(3):432–441, 2008.

Vikas K Garg, Stefanie Jegelka, and Tommi Jaakkola. Generalization and representational limits of
graph neural networks. arXiv preprint arXiv:2002.06157, 2020.

Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of the
_27th International Conference on International Conference on Machine Learning, pp. 399–406._
Omnipress, 2010.

Aditya Grover, Eric Wang, Aaron Zweig, and Stefano Ermon. Stochastic optimization of sorting
networks via continuous relaxations. arXiv preprint arXiv:1903.08850, 2019.

Dominique Guillot, Bala Rajaratnam, Benjamin T Rolfs, Arian Maleki, and Ian Wong. Iterative
thresholding algorithm for sparse inverse covariance estimation. arXiv preprint arXiv:1211.2532,
2012.

Rishi Gupta and Tim Roughgarden. A pac approach to application-specific algorithm selection.
_SIAM Journal on Computing, 46(3):992–1017, 2017._

Piotr Indyk, Ali Vakilian, and Yang Yuan. Learning-based low-rank approximations. arXiv preprint
_arXiv:1910.13984, 2019._

Boris Joseph Joukovsky, Tanmoy Mukherjee, Nikos Deligiannis, et al. Generalization error bounds
for deep unfolding rnns. In Proceedings of Machine Learning Research. Journal of Machine
Learning Research, 2021.

Ulugbek S Kamilov and Hassan Mansour. Learning optimal nonlinearities for iterative thresholding
algorithms. IEEE Signal Processing Letters, 23(5):747–751, 2016.

Dohyun Kim and Daeyoung Park. Element-wise adaptive thresholds for learned iterative shrinkage
thresholding algorithms. IEEE Access, 8:45874–45886, 2020.

Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
_arXiv:1412.6980, 2014._

Tsukasa Kouno, Michiel de Hoon, Jessica C Mar, Yasuhiro Tomaru, Mitsuoki Kawano, Piero Carninci, Harukazu Suzuki, Yoshihide Hayashizaki, and Jay W Shin. Temporal dynamics and transcriptional control using single-cell gene expression analysis. _Genome biology, 14(10):1–12,_
2013.

Jialin Liu, Xiaohan Chen, Zhangyang Wang, and Wotao Yin. ALISTA: Analytic weights are as good
as learned weights in LISTA. In International Conference on Learning Representations, 2019a.
[URL https://openreview.net/forum?id=B1lnzn0ctQ.](https://openreview.net/forum?id=B1lnzn0ctQ)

Risheng Liu, Shichao Cheng, Yi He, Xin Fan, Zhouchen Lin, and Zhongxuan Luo. On the convergence of learning-based iterative methods for nonconvex inverse problems. IEEE transactions on
_pattern analysis and machine intelligence, 42(12):3027–3039, 2019b._

Po-Ling Loh and Martin J Wainwright. Regularized m-estimators with nonconvexity: Statistical and
algorithmic theory for local optima. The Journal of Machine Learning Research, 16(1):559–616,
2015.


-----

Vlad Niculae, Andre Martins, Mathieu Blondel, and Claire Cardie. Sparsemap: Differentiable sparse
structured inference. In International Conference on Machine Learning, pp. 3799–3808, 2018.

Edouard Ollier and Vivian Viallon. Regression modelling on stratified data with the lasso.
_Biometrika, 104(1):83–96, 2017._

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825–2830, 2011.

Marin Vlastelica Poganˇci´c, Anselm Paulus, Vit Musil, Georg Martius, and Michal Rolinek. Differentiation of blackbox combinatorial solvers. In International Conference on Learning Represen_tations, 2019._

Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo_rithms. Cambridge university press, 2014._

Nir Shlezinger, Jay Whang, Yonina C Eldar, and Alexandros G Dimakis. Model-based deep learning. arXiv preprint arXiv:2012.08405, 2020.

Harsh Shrivastava, Xinshi Chen, Binghong Chen, Guanghui Lan, Srinivas Aluru, Han Liu, and
Le Song. GLAD: Learning sparse graph recovery. In International Conference on Learning
_[Representations, 2020. URL https://openreview.net/forum?id=BkxpMTEtPB.](https://openreview.net/forum?id=BkxpMTEtPB)_

Athanasios Tsanas, Max Little, Patrick McSharry, and Lorraine Ramig. Accurate telemonitoring of
parkinson’s disease progression by non-invasive speech tests. Nature Precedings, pp. 1–1, 2009.

Xiang Wang, Shuai Yuan, Chenwei Wu, and Rong Ge. Guarantees for tuning the step size using a
learning-to-learn approach. In International Conference on Machine Learning, pp. 10981–10990.
PMLR, 2021.

Zhaoran Wang, Han Liu, and Tong Zhang. Optimal computational and statistical rates of convergence for sparse nonconvex learning problems. Annals of statistics, 42(6):2164, 2014.

Kaixuan Wei, Angelica Aviles-Rivero, Jingwei Liang, Ying Fu, Carola-Bibiane Sch¨onlieb, and Hua
Huang. Tuning-free plug-and-play proximal algorithm for inverse imaging problems. In Interna_tional Conference on Machine Learning, pp. 10158–10169. PMLR, 2020._

Kailun Wu, Yiwen Guo, Ziang Li, and Changshui Zhang. Sparse coding with gated learned ista. In
_[International Conference on Learning Representations, 2020. URL https://openreview.](https://openreview.net/forum?id=BygPO2VKPH)_
[net/forum?id=BygPO2VKPH.](https://openreview.net/forum?id=BygPO2VKPH)

Shanshan Wu, Alex Dimakis, Sujay Sanghavi, Felix Yu, Daniel Holtmann-Rice, Dmitry Storcheus,
Afshin Rostamizadeh, and Sanjiv Kumar. Learning a compressed sensing measurement matrix
via gradient unrolling. In International Conference on Machine Learning, pp. 6828–6839. PMLR,
2019.

Xingyu Xie, Jianlong Wu, Guangcan Liu, Zhisheng Zhong, and Zhouchen Lin. Differentiable linearized admm. In International Conference on Machine Learning, pp. 6902–6911. PMLR, 2019.

Y Yang, J Sun, H Li, and Z Xu. Admm-net: A deep learning approach for compressive sensing mri.
corr. arXiv preprint arXiv:1705.06869, 2017.

Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. The Annals of
_statistics, 38(2):894–942, 2010a._

Jian Zhang and Bernard Ghanem. Ista-net: Interpretable optimization-inspired deep network for
image compressive sensing. In Proceedings of the IEEE Conference on Computer Vision and
_Pattern Recognition, pp. 1828–1837, 2018._

Tong Zhang. Analysis of multi-stage convex relaxation for sparse regularization. Journal of Machine
_Learning Research, 11(3), 2010b._

Jiayu Zhou, Jianhui Chen, and Jieping Ye. Malsar: Multi-task learning via structural regularization.
_Arizona State University, 21, 2011._


-----

A LIST OF DEFINITIONS AND NOTATIONS

For the convenience of the reader, we summarize a list of notations blow.

1. ∥β∥λ,1 := _j=1_ _[λ][j][ |][β][j][|][ denotes element-wise][ ℓ][1][ norm.]_

2. (x)S is the sub-vector of x with entries in the index set S.

[P][d]

3. x _ϵ = max_ **_x, ϵ_** = [max _x1, ϵ_ _,_ _, max_ _xd, ϵ_ ][⊤].
_∨_ _{_ _}_ _{_ _}_ _· · ·_ _{_ _}_

4. Element-wise soft-threshold:


_sλ(β) = (_ **_β_** _sλ)+_ sign(β) (22)
_T_ _|_ _| −_ _◦_

(|β1| − _sλ1)+ sign(β1)_
.

= . (23)

 . 

 (|βd| − _sλd)+ sign(βd)_ 
 

5. Denote a single iteration of the modified proximal gradient step as


**_β[k]_** = MPG(β[k][−][1]; λ, w, α)

:= Tα·λ **_β[k][−][1]_** _−_ _α_ _∇Lλ,w(β[k][−][1])_
    

B PENALTY FUNCTIONS

We provide detailed descriptions of the penalty functions used in PLISA. We focus on learning the
combination of three well-known penalty functions:

_P_ [(1)](λ, β) = ∥λ ◦ **_β∥1, P_** [(2)](λ, β) = _j=1_ [MCP(][λ][j][, β][j][)][, P][ (3)][(][λ][,][ β][) =][ P]j[p]=1 [SCAD(][λ][j][, β][j][)][,]

where MCP (Zhang, 2010a) and SCAD (Fan & Li, 2001) are nonconvex penalties whose analytical

[P][p]

forms are given below.

B.1 ANALYTICAL FORMS

The MCP penalty can be written as


MCP(λ, β) = _λ_ _β_
_|_ _| −_ _[β]2b[2]_


where b > 0 is some hyperparameter.

The SCAD penalty can be written as


1 ( _β_ _bλ) +_ _[bλ][2]_

_·_ _|_ _| ≤_ 2



_· 1 (|β| > bλ),_


SCAD(λ, β) = λ _β_ 1 ( _β_ _λ)_ 1 (λ < _β_ _aλ)_
_|_ _| ·_ _|_ _| ≤_ _−_ _[β][2][ −]2([2][aλ]a_ _[ |][β]1)[|][ +][ λ][2]_ _·_ _|_ _| ≤_

_−_

+ [(][a][ + 1)][λ][2] 1 ( _β_ _> aλ),_

2 _·_ _|_ _|_

where a > 2 is some hyperparameter.


PLISA uses the concave components of these penalty functions. Their analytical forms are as
follows.

_bλ2_

_q[(2)](λ, β) = MCP(λ, β)_ _λ_ _β_ = _λ_ _β_ 1 ( _β_ _> bλ)_
_−_ _|_ _|_ _−_ _[β]2b[2]_ 2 _−_ _|_ _|_ _·_ _|_ _|_

_[·][ 1][ (][|][β][| ≤]_ _[bλ][) +]_  

_q[(3)](λ, β) = SCAD(λ, β)_ _λ_ _β_ = [2][λ][ |][β][| −] _[β][2][ −]_ _[λ][2]_ 1 (λ < _β_ _aλ)_
_−_ _|_ _|_ 2(a 1) _·_ _|_ _| ≤_

_−_

+ [(][a][ + 1)][λ][2][ −] [2][λ][ |][β][|] 1 ( _β_ _> aλ)_

2 _·_ _|_ _|_


-----

B.2 IMPLICATIONS

Based on the definitions of these penalty functions, it is easy to check that their convex combination
satisfies a set of conditions as stated in the following Assumption B.1.


**Assumption B.1 (Regularization). Let P** (λ, β) = Q(λ, β)+ _∥β∥λ,1 where Q is concave in β, and_
_that Q(λ, β) =_ _j=1_ _[q][(][λ][j][, β][j][)][. Denote the partial gradient of][ q][ as][ q]λ[′]_ [(][β][) :=][ ∂q][(]∂β[λ,β][)] _. Assume the_

_following regularization conditions._

[P][d]

_(a) There exists constants ξ ≥_ 0 such that for any β[′] _> β,_

_λ[(][β][′][)][ −]_ _[q]λ[′]_ [(][β][)]
_ξ_ 0.
_−_ _≤_ _[q][′]_ _β[′]_ _β_ _≤_

_−_

_(b) q(λ, −β) = q(λ, β)._

_(c) qλ[′]_ [(0) =][ q][(][λ,][ 0) = 0][.]

_(d) |qλ[′]_ [(][β][)][| ≤] _[λ][.]_

_(e) |qλ[′]_ 1 [(][β][)][ −] _[q]λ[′]_ 2 [(][β][)][| ≤|][λ][1][ −] _[λ][2][|][.]_

_Note that the penalty function Pw(λ, β) in PLISAθ satisfies all these conditions, with the constant_
_ξ in condition (a) being_

1 1
_ξw =_ _w2_ _w3_
_b_ [+][ f] _a_ 1 _[,]_

_−_

_where a and b are the hyperparameters in SCAD and MCP._

f


Next, we present an important lemma which states the restricted strongly convexity and smoothness
of the modified loss

_Lλ,w(β) := Ln(Z1:n, β) + Qw(λ, β)._

**Lemma B.1 (Restricted Strongly Convex and Restricted Strongly Smooth). Assume P satisfies**
_Assumption C.1 and (Zn, β[∗])_ _. If Q(λ, β) satisfies the regularization conditions in Assump-_
_∈P_
_tion B.1 with a constant ξ < ρ_ _. Then_
_−_

_Lλ(β) := Ln(Z1:n, β) + Q(λ, β)_

_is strongly convex and smooth in the subspace_ **_β[′]_** **_β_** 0 _s[∗]_ + 2˜s _. That is, for any β, β[′]_ _such_
_that_ **_β[′]_** **_β_** 0 _s[∗]_ + 2˜s, the following inequalities hold {∥ _−_ _∥_ _≤_ _}_
_∥_ _−_ _∥_ _≤_

_Lλ(β[′]) ≥_ _Lλ(β) + ∇Lλ(β)[⊤](β[′]_ _−_ **_β) +_** _[ρ][−]2[−]_ _[ξ]_ _∥β[′]_ _−_ **_β∥2[2]_** (24)

_Lλ(β[′]) ≤_ _Lλ(β) + ∇Lλ(β)[⊤](β[′]_ _−_ **_β) +_** _[ρ]2[+]_ _[∥][β][′][ −]_ **_[β][∥]2[2]_** (25)

_Proof. The proof is straightforward by using the condition (a) in Assumption B.1 and the sparse-_
eigenvalue condition in Assumption C.1.


-----

C PROBLEM SPACE ASSUMPTIONS

We follow the notations in Wang et al. (2014); Loh & Wainwright (2015) to describe some classic
assumptions on the estimation problems.

**Assumption C.1 (Problem Space). Let s[∗], ˜s be positive integers and ρ** _, ρ+ be positive constants_
_−_
_such that ˜s > (121(ρ+/ρ−) + 144(ρ+/ρ−)[2])s[∗]. Assume for every estimation problem (Z1:n, β[∗])_
_in the space P, the following conditions are satisfied._

_(a)(b) For any nonzero ∥β[∗]∥0 ≤_ _s[∗]_ _and v ∥ ∈β[∗]∥R∞[d]_ _with sparsity≤_ _B1;_ _∥v∥0 ≤_ _s[∗]_ + 2˜s, it holds **_v[⊤]∇β[2]_** _[L]∥[n]v[(]∥[Z]2[2][1:][n][,][β][)][v]_ _∈_ [ρ−, ρ+];

_(c) 8_ [ **_βLn(Z1:n, β[∗])]j_** [ **_βLn(Z1:n, 0)]j_** _B2,_ _j = 1,_ _, d._
_|_ _∇_ _| ≤|_ _∇_ _| ≤_ _∀_ _· · ·_

Condition (a) assumes β[∗] is s[∗]-sparse and B1-bounded. Condition (b) is commonly referred to as
‘sparse eigenvalue condition’ (Zhang, 2010b; Wang et al., 2014), which is weaker than the wellknown restricted isometry property (RIP) in compressed sensing (Candes & Tao, 2005). Note that
the class of functions satisfying conditions of this type is much larger than the class of convex losses.
In the special case when Ln(Z1:n, β) is strongly convex in β, condition (b) holds with ˜s . The
_→∞_
last condition bounds the gradient of the empirical loss Ln at the true parameter β[∗] and 0.


-----

D RECOVERY GUARANTEE FOR PARAMETERS IN CONSTRAINED SPACE

Our generalization analysis is conducted on a constrained parameter space. In this section, we
provide theoretical guarantees for the estimation error of PLISAθ when θ is in the constrained
space. We first formally define the parameter space as follows.
**Definition D.1Given some positive values (Constrained parameter space) αmin, ηmax, ξmax., and Assume λmax P. We definite the constrained parameter satisfies Assumption C.1 and Dm ⊆P.**
_space Θ(_ _m) as Θ(_ _m) :=_ _θ =_ **_η, λ[∗], w, α_** : conditions (i) (ii) (iii) (iv) are satisfied _, where_
_D_ _D_ _{_ _{_ _}_ _}_
_the conditions are:_


_(i) α_ [αmin,
_∈_


1

_ρ+_ []][.]


_(ii) ηj ∈_ [ηmin := σ[−][1](0.9), ηmax], for all j = 1, · · ·, d.

_(iii)_ _w2 [1]b_ [+][ f]w3 _a_ 1 1

_eter in SCAD−._ _[≤]_ _[ξ][max][ < ρ][−][, where][ b][ is the hyperparameter in][ MCP][ and][ a][ is the hyperparam-]_

_(iv) λ f[∗]j_ (Z1:n,β∗ )∈Dm

_[∈]_ [[8 sup] _[|][[][∇][β][L][n][(][Z][1:][n][,][ β][∗][)]][j][| ∨]_ _[ε, λ][max][]][, for all][ j][ = 1][,][ · · ·][, d][.]_

For parameters in this constrained space, we can show the performance guarantee for the outputs of
PLISAθ, as stated in the following Theorem D.1.
_be the constrained parameter space defined in DefinitionTheorem D.1 (Recovery guarantee). Assume P satisfies Assumption D.1 and assume C.1 and θ D =m ⊆P {η, λ. Let[∗], w Θ(, αD} ∈m)_
Θ( _m). Assume_
_D_

29ρ+ 1

_K_ log 4 (1 + ) _[∥][(][B][2][ ∨]_ **_[λ][∗][)][S][∗]_** _[∥][2]_ _/ log_ _δ[−][1][/][2][]_ + 1,
_≥_ s _ρ−_ _−_ _ξmax_ _αminρ+_ _ε_ ! 

_where δ := 1 −_ _αmin(ρ−_ _−_ _ξmax). Then for any problem (Z1:n, β[∗]) in the training set Dm, all_
_intermediate outputs of PLISAθ have the following error bounds for all t = 1, · · ·, T_ _._

15/2
**_βt[k][(][Z][1:][n][;][ θ][)][ −]_** **_[β][∗][∥][2]_** (λt(Z1:n; θ))S∗ 2, _k = 1,_ _, K,_
_∥_ [e] _[≤]_ _ρ_ _ξmax_ _∥_ _∥_ _∀_ _· · ·_

_−_ _−_

19/8
**_βt(Z1:n; θ)_** **_β[∗]_** 2 (λt(Z1:n; θ))S∗ 2.
_∥_ _−_ _∥_ _≤_ _ρ_ _ξmax_ _∥_ _∥_

_−_ _−_

_Proof. The proof of this theorem is based on a series of key lemmas for the properties of the modified_
proximal gradient steps in each cell of PLISA. We state these key lemmas and their proofs in
Section G. With these lemmas, the proof of this theorem is straightforward, and we state the proof
below.

Given a fixed problem (Z1:n, β[∗]) ∈Dm and a fixed set of parameters θ = {η, λ[∗], w, α} ∈ Θ(Dm),
we simplify some notations in this proof by removing the dependency on Z1:n and θ. For example,
we denote βt = βt(Z1:n; θ), **_βt[k]_** [=][ e]βt[k][(][Z][1:][n][;][ θ][)][,][ λ][t] [=][ λ][t][(][Z][1:][n][;][ θ][)][, etc.]

**Notations. Furthermore, we will use the following simplified notations and definitions.**

[e]

_empirical loss_ _Ln(β) := Ln(Z1:n, β)_
_modified loss_ _Lλ(β) := Ln(Z1:n, β) + Qw(λ, β)_
_regularized loss_ _φλ(β) := Ln(Z1:n, β) + Pw(λ, β) = Lλ(β) +_ **_β_** **_λ,1_**
_∥_ _∥_

_local optimal_ **_βλ_** arg min _φλ(β)_
_∈_ **_β∈R[d]:∥βS∗_** _∥0≤s˜_
b (β **_β′)⊤_**

_sub-optimality_ _ωλ(β) :=_ min _−_ ( _Lλ(β) + λ_ **_ξ[′])_** _._
**_ξ[′]_** _∂_ **_β_** 1 [max]β[′] **_β_** **_β[′]_** **_λ,1_** _∇_ _◦_
_∈_ _∥_ _∥_  _∥_ _−_ _∥_ 

Now we are ready to state the proof. We first show the following statement holds true for all t ≤ _T_
by mathematical induction.

**Statement(t):** _ωλt_ (βt[0][)][ ≤] [1] and (βt[k][)]S[∗] _[∥][0]_ _s,_ _k = 1,_ _, K._

[e] 2 _[,]_ _∥_ [e] _[≤]_ [˜] _∀_ _· · ·_


-----

**Statement(1). First we verify that Statement(1) holds true. Recall that λ0 = |∇Ln(0)|. In the**
following, we prove that **_β1[0]_** [is a local solution of][ φ][λ]0 [(][β][) :=][ L][λ]0 [(][β][) +][ ∥][β][∥][λ]0[,][1][.]

_Lλ0_ (β1[0][) +][ λ][0] **_β1[0][∥][1]_**
_∇[e]=_ _Ln(0) +_ **_β[◦]Q[∂]w[∥]_** ([e]λ0, 0) + λ0 _∂_ **0** 1
_∇_ _∇_ _◦_ _∥_ _∥_
= sign([e] _Ln(0))_ _Ln(0)_ + 0 + λ0 _∂_ **0** 1
_∇_ _◦|∇_ _|_ _◦_ _∥_ _∥_
= sign(∇Ln(0)) ◦ **_λ0 + λ0 ◦_** _∂∥0∥1._

Since − sign(∇Ln(0)) ∈ _∂∥0∥1, then we have 0 ∈∇Lλ0_ (β1[0][) +][ λ][0] _[◦]_ _[∂][∥]β[e]1[0][∥][1][.]_ Therefore,
_ωλ0_ (β1[0][) = 0][. Since][ λ][1] [=][ λ][0]

_[◦]_ **_[η][1][, by Lemma][ G.6][, we have]_**

**_β1[0][) + 0][.][2]_** [e]
_ωλ1_ (β1[0][)][ ≤] _[ω][λ][0]_ [(][ e] = [2]

[e] 0.9 9

_[≤]_ [1][/][2][.]

By Lemma G.5, we have φλ1 (β1[0][)][e][ −] _[φ][λ]1_ [(][β][∗][)][ ≤] [21][/]ρ[2]−[∥]−[(][λ]ξ[1]max[)][S][∗] _[∥]2[2]_, which implies that the conditions

in Lemma G.4 are satisfied. Therefore, we have proved that

[e] (β1[k][)]S[∗] _[∥][0]_ _s_ _k = 1, . . ., K._

_∥_ _[≤]_ [˜] _∀_
This finishes the proof of Statement(1).

**Statement(t). Now we assume Statement(t** _−_ 1) is true and prove Statement(t). First, we prove that
_ωλt−1_ (βt[K]−1[)][ ≤] [1][/][4][. By Lemma][ G.2][ and Lemma][ G.5][,]

1

_√2(1 +_ _αminρ+_ [)][√][ρ][+] 2

_ωλt−[e]1_ (βt[K]−1[)][ ≤] min(λt 1) s(1 − _αmin(ρ−_ _−_ _ξmax))[K][−][1][ 29][/]ρ[2][∥][(][λ][t]ξ[−]max[1][)][S][∗]_ _[∥][2]_

_−_ _−_ _−_

[e] 29ρ+ 1 _K−1_

_≤_ s _ρ−_ _−_ _ξmax_ (1 + _αminρ+_ ) _[∥][(][λ][0][ ∨]_ _ε[λ][∗][)][S][∗]_ _[∥][2]_ (1 − _αmin(ρ−_ _−_ _ξmax))_ _._

p

Assume K ≥ log 4 _ρ−29−ρξ+max_ [(1 +] _αmin1_ _ρ+_ [)][ ∥][(][λ][0][∨][λ]ε[∗][)][S][∗] _[∥][2]_ _/ log_ _δ[−][1][/][2][]_ + 1, where
 q _δ := 1_ _αmin(ρ_ _ξmax_ ).  

_−_ _−_ _−_
Then we have
_ωλt−1_ (βt[K]−1[)][ ≤] [1][/][4][.] (26)

Since **_βt[0]_** [=][ e]βt[K] 1[, Lemma][ G.6][ implies that]
_−_

[e]

_ωλt_ (βt[0][)][ ≤] [1][/][2][.]

[e]

Furthermore, by Lemma G.5, ωλt (βt[0][)][ ≤] [1][/][2][ implies]

[e]

_φλt_ (βt[0][)][ −] _[φ][λ]t_ [(][β][∗][)][ ≤] [21][/][2][∥][(][λ][t][)][S][∗] _[∥]2[2]_ _,_ (27)

[e] _ρ−_ _−_ _ξmax_

which in turns implies that the conditions in Lemma G.4 are satisfied. Therefore, we have

[e]

_∥(βt[k][)]S[∗]_ _[∥][0]_ _[≤]_ _s[˜]_ _∀k = 1, . . ., K,_
which completes the proof of Statement(t).

[e]

Now we derive the error bounds. Similar to how we derive Eq. 26 and Eq. 27, it is easy to show that

_ωλt_ (βt[K][)][ ≤] [1][/][4][,] _∀t = 1, · · ·, T,_

and φλt (β[e]t[0][)][ −] _[φ][λ]t_ [(][β][∗][)][ ≤] [21]ρ[/]−[2][∥]−[(][λ]ξ[t]max[)][S][∗] _[∥]2[2]_ _∀t = 1, · · ·, T._

Combining φλt (βt[0][)][ −] _[φ][λ]t_ [(][e][β][∗][)][ ≤] [21][/]ρ[2][∥][(][λ]ξ[t]max[)][S][∗] _[∥]2[2]_ with Lemma G.3, we have

_−−_

[e] **_βt[k]_** 2 _,_ _k = 1,_ _, K._ (28)

_∥_ [e] _[−]_ **_[β][∗][∥][2]_** _[≤]_ [15]ρ[/]−[2][∥]−[(][λ]ξ[t]max[)][S][∗] _[∥][2]_ _∀_ _· · ·_

Combining ωλt (βt[K][)][ ≤] [1][/][4][ with Lemma][ G.5][, we have]

**_βt[K]_** 1 _∥(λt)S∗_ _∥22_ = [19][/][8][∥][(][λ][t][)][S][∗] _[∥]2[2]_ _._

[e] _∥_ [e] _[−]_ **_[β][∗][∥][2]_** _[≤]_  4 [+ 17]8  _ρ−_ _−_ _ξmax_ _ρ−_ _−_ _ξmax_


-----

E CAPACITY ANALYSIS: PROOF OF THEOREM 3.1

_Proof. This theorem is a direct result of Theorem D.1, by taking a suitable set of parameters θ._
Similar to the proof of Theorem D.1, some notations are simplified. Please refer to the proof of
Theorem D.1 for detailed illustrations.

Denote the union support set of the true parameters β[∗] by Sm[∗] [:=][ {][j][ :][ j][ ∈] [supp][(][β][∗][)][,][ (][Z][1:][n][,][ β][∗][)][ ∈]
_Dm}. Then we specify a set of parameters θ = {η, λ[∗], w, α} for PLISAθ as follows._

-  α = _ρ1+_ [.]

-  w: The weights w can take any values as long as they satisfy _w2 [1]b_ [+][ f]w3 _a_ 1 1 _[< ρ][−][. Since][ f]w2 and_

_−_
_w3 and be arbitrary close to 0, there must exists a set of weights w that satisfy this constraint. In_
particular, we denote this value by ξw := _w2 [1]b_ [+][ f]w3 _a_ 1 1 [.] f

_−_

-  λf[∗]: For each j _Sm[∗]_ [, we take][ λ][∗]j [:= 8 max][(][Z]n[,][β][∗][)][∈D]m
regularization parameter. For each ∈ _j /∈_ fSm[∗] [, we take][ λ][∗]j [=][ B][|∇][L][2][, which is the upper bound of][n][(][Z][n][,][ β][∗][)][j][| ∨] _[ε][ as the target]_
_∥∇βLn(Z1:n, 0)∥∞_ by Assumption C.1.

-  η: For all j, take ηj = log 9 so that the decrease ratio is σ(ηj) = 0.9.

Clearly, this set of parameters satisfy the conditions in Theorem D.1, so we can apply its result in
this proof.

In the following, we will show that, with this specification of the parameters, PLISAθ can achieve
the recovery accuracy stated in Theorem 3.1.

be the number of blocks after whichLet t0 = min {t : t ≥ 0, λ[∗] = max{0 λ.9t[t](|∇Z1:βnL; θn) =(Z1: λn, 0[∗]. We know)|, λ[∗]}, Z1: tn0 ∈D is a small number becausem, λ[∗] _∈_ _θ ∈_ Θ(DM )}
the decrease rate is linear. To be more clear, it is easy to show that t0 log _Bε2_ _/ log(10/9)._

Therefore, after t0 cells, the regularization parameters do not change anymore. That is, ≤

  

**_λt(Z1:n; θ) = λ[∗],_** _t_ _t0._
_∀_ _≥_
Since the specified parameters satisfy the conditions in Theorem D.1, we can follow the same way
as how we derive Eq. 26 to obtain that
_ωλt−1_ (βt−1) ≤ 1/4, _∀t = 1, · · ·, T._
Since we have λt = λ[∗] for t ≥ _t0. The last (T −_ _t0) cells can be viewed as a single cell with_
_K(T_ _t0) many steps. Therefore, we can apply Lemma G.2 and Lemma G.5 to obtain_
_−_

_ωλt_ (βt[K][)][ ≤] [2][√][2][ρ][+] (1 _α(ρ_ _ξw))[K][(][t][−][t][0][)][−][1][ 29][/][2][∥][(][λ][t][−][1][)][S][∗]_ _[∥]2[2]_

_ϵ_ s _−_ _−_ _−_ _ρ_ _ξw_

_−_ _−_

[e] 29ρ+ 1 _K(t−t0)−1_

_≤_ s _ρ−_ _−_ _ξw_ (1 + _αρ+_ ) _[∥][(][λ][0][ ∨]_ _ε[λ][∗][)][S][∗]_ _[∥][2]_ (1 − _α(ρ−_ _−_ _ξw))_

p

29ρ+ 1 _√s[∗]B2_ _K(t−t0)−1_

_≤_ s _ρ−_ _−_ _ξw_ (1 + _αρ+_ ) _ε_ (1 − _α(ρ−_ _−_ _ξw))_

p

= cθ√s[∗]ε[−][1] exp( _CθK(t_ _t0)),_

_−_ _−_

where Cθ = − [1]2 [log (1][ −] _[α][(][ρ][−]_ _[−]_ _[ξ][w][))][,][ c][θ][ =]_ _ρ−29−ρξ+w_ [(1 +] _αρ1+_ [)] 1−α(ρB−2−ξw) [. By Lemma][ G.5][,]

q


_ωλt_ (βt[K][) +][ 17]8 **_λ[∗]S[∗]_** _[∥][2]_

_∥_

**_βt_** **_β[∗]_** 2
_∥_ _−_ _∥_ _≤_  _ρ_ _ξw_

[e] _−_ _−_ 17

_S[∗]_ _[∥][2]_ _cθε[−][1][√]s[∗]_ exp( _CθK(t_ _t0)) +_ 8 _[∥][λ]S[∗]_ _[∗]_ _[∥][2]_
_≤_ _ρ[∥]−[λ][∗]−_ _ξw_ _−_ _−_ _ρ−_ _−_ _ξw_

_c˜θε[−][1]s[∗]_ exp( _CθK(t_ _t0)) + c[′]θ[∥][λ][∗]S[∗]_ _[∥][2]_ (29)
_≤_ _−_ _−_

where ˜cθ = _ρ√−s−[∗]Bξw2_ _[c][θ][ and][ c]θ[′]_ [=] 8(ρ−17−ξw) [. What remains is bounding][ ∥][λ]S[∗] _[∗]_ _[∥][2][. First, we define a]_

condition number as

_κm = max_ 8 max(Zn,β∗)∈Dm |∇βLn(Zn, β[∗])j| _._
_j∈Sm[∗]_  8 min(Zn,β∗)∈Dm |∇βLn(Zn, β[∗])j| ∨ _ε_ 


-----

In fact, κm ≤ _[B]ε[2]_ [. Then recall the specification of][ λ][∗] [at the beginning of this proof. We have]


**_λ[∗]S[∗]_** _[∥][2]_ 8κm **_βLn(Zn, β[∗])j_** _ε_
_∥_ _[≤]_ _jX∈S[∗]_ _|∇_ _| ∨_

8κm ( **_βLn(Zn, β[∗])_** _ε)S∗_ 2.
_≤_ _∥_ _∇_ _∨_ _∥_

Plugging this back to Eq. 29, we have

_∥βt −_ **_β[∗]∥2 ≤_** _c˜θε[−][1]s[∗]_ exp(−CθK(t − _t0)) + c[′]θ[8][κ][m][∥][(][∇][β][L][n][(][Z][n][,][ β][∗][)][ ∨]_ _[ε][)][S][∗]_ _[∥][2][.]_

This is equivalent to the statement to be proved.


-----

F GENERALIZATION ANALYSIS: PROOF OF THEOREM 4.1

We first state a well-known inequality that bounds the generalization gap by empirical Rademacher
_complexity._

**Theorem F.1 (Adapted from Theorem 26.5 (Shalev-Shwartz & Ben-David, 2014)). Assume that for**
_all (Z1:n, β[∗]) ∈P and all θ ∈_ Θ we have that ℓ(βT (Z1:n; θ), β[∗]) ≤ _c. Then with probability at_
_least 1 −_ _ϵ, for all θ ∈_ Θ,


2 log(4ϵ[−][1])


_Lgen(P(P); θ) −Ltrain[γ][=0]_ [(][D][m][;][ θ][)][ ≤] [2][R][m][(][ℓ][Θ][) + 4][c]


_where ℓΘ := {(Z1:n, β[∗]) 7→∥βT (Z1:n; θ) −_ **_β[∗]∥2[2]_** [:][ θ][ ∈] [Θ][}][ is the space of loss functions of our]
_model PLISAθ, and Rm(ℓΘ) is its empirical Rademacher complexity. It is defined as_

2

_Rm(ℓΘ) := Eσ supθ_ Θ _m1_ _mi=1_ _[σ][i]_ **_βT (Z1:[(][i]n[)]_** _i_ [;][ θ][)][ −] **_[β][∗][(][i][)]_**
_∈_ 2 _[,]_

P

_where {σi}i[m]=1_ _[are][ m][ independent Rademacher random variables.]_


Therefore, it resorts to bound the empirical Rademacher complexity, which can be bounded via
Dudley’s integral. The following theorem states the bound for the empirical Rademacher complexity
and its proof follows.

**Theorem F.2 (Empirical Rademacher complexity bound). Assume the assumptions in Theorem 4.1.**
_Let Θ = Θ(Dm) be the constrained space defined in Definition D.1. Let ℓΘ := {(Z1:n, β[∗]) 7→_
_∥βT (Z1:n; θ) −_ **_β[∗]∥2[2]_** [:][ θ][ ∈] [Θ][}][ be the space of loss functions of our model][ PLISA][θ][. Then the]
_empirical Rademacher complexity is bounded by RmℓΘ_
_≤_

_c1_

log _c2√mK(T_ _t0) exp(_ _CΘK(T_ _t0))_ 1 + c3d log _c4√m (1_ exp( _CΘKT_ ))

_√m_ _−_ _−_ _−_ _∨_ _−_ _−_

q

     

_where c1, c2, c3, c4 are some constants independent of d, m, K and T_ _._

_Proof. The classical Dudley’s entropy integral bound gives us an upper bound for the empirical_
Rademacher complexity in terms of the covering number.


_∥ℓΘ∥Pm,∞_

inf 4α + [12] log (ϵ, ℓΘ, L2(Pm)) dϵ
_α>0_ _√m_ _α_ _N_

Z

4 _∥ℓΘ∥Pm,∞_ p

log (ϵ, ℓΘ, L2(Pm)) dϵ

_√m + √[12]m_ 1 _N_

Z _√m_

p

4 1

log Θ, L2(Pm) _._

_√m + [12][∥][ℓ]√[Θ][∥]m[P][m][,][∞]_ s _N_ _√m, ℓ_

 


4α + [12]
_√m_


_RmℓΘ_ inf
_α>0_
_≤_


The notation Pm means the empirical measure defined based on the samples in Dm, and

_∥ℓΘ∥Pm,∞_ := supθ∈Θ _Pm(ℓθ)_


**_βT (Z1:n; θ)_** **_β[∗]_** 2
_∥_ _−_ _∥[2]_
(Z1:nX,β[∗])∈Dm

19/8

(λt(Z1:n; θ))S∗ 2
_ρ_ _ξmax_ _∥_ _∥_

(Z1:nX,β[∗])∈Dm _−_ _−_

19/8 _√s[∗]_ max _B2, λmax_ _C._

_ρ_ _ξmax_ _{_ _} ≤_

(Z1:nX,β[∗])∈Dm _−_ _−_


= sup
_θ∈Θ_

by Theorem D.1 _≤_ _θsup∈Θ_

_≤_ _θsup∈Θ_


Here we use a constant C as the upper bound because we only care about the scales in d, m, K and
_T_ . Next, we bound the covering number _√1m_ _, ℓΘ, L2(Pm)_ . By the key result in Lemma 4.1, it
_N_
 


-----

is easy to derive that

_ℓθ_ _ℓθ′_ _L2(Pm)_ 2C _c1K(T_ _t0)_
_∥_ _−_ _∥_ _≤_ _−_



_s[∗]_ _α_ _α[′]_ exp( _CΘK(T_ _t0))_
_|_ _−_ _|_ _−_ _−_


+ _c2∥η −_ **_η[′]∥2 + c3∥λ[∗]_** _−_ **_λ[∗′]∥2 + c4√d∥w −_** **_w[′]∥2_** (1 − exp(−CΘKT ))
cK(T _t0)_ _α_ _α[′]_ exp( _CΘK(T_ _t0))_  

_≤_ _−_ _|_ _−_ _|_ _−_ _−_

+ c _∥η −_ **_η[′]∥2 + ∥λ[∗]_** _−_ **_λ[∗′]∥2 +_** _√d∥w −_ **_w[′]∥2_** (1 − exp(−CΘKT )) /
 

From now on, we abuse the symbol c to generally represent some constant that does not depend on
_d, m, K, T_ .


_ϵ_

_αmin,_ [1]
_cK(T_ _t0) exp(_ _CΘK(T_ _t0))_ _[,]_ _ρ+_
_−_ _−_ _−_ 

_ϵ_

_c (1_ exp( _CΘKT_ )) _[,][ [][η][min][, η][max][]][d][, ℓ][2]_
_−_ _−_ 


(ϵ, ℓΘ, L2(Pm))
_N_ _≤N_

_× N_

_× N_

_× N_


_, |·|_


_c (1_ exp( _CΘKT_ )) _[,]_
_−_ _−_



[λj,min, λj,max], ℓ2
_×_
_j=1_

Y


_ϵ_

_, [wmin, wmax][3], ℓ2_ _._

_× N_ _c√d (1_ exp( _CΘKT_ ))
 _−_ _−_ 

For the covering number of athe ϵ-packing number. That is, d-dimensional compact vector space(T, ϵ, ℓ2) (T, ϵ, ℓ2) _c_ _j=1 T ⊆Tj,maxR[d]−ϵ, we can bound it byTj,min_ + 1 for some
_N_ _≤M_ _≤_

constant c. Applying this fact, we have  

[Q][d]

_cK(T_ _t0) exp(_ _CΘK(T_ _t0))_
(ϵ, ℓΘ, L2(Pm)) _−_ _−_ _−_ 1
_N_ _≤_ _ϵ_ _∨_
 

_d_

_c (1_ exp( _CΘKT_ ))
_−_ _−_ + 1

_×_ _ϵ_

_j=1_  

Y

_d_

_c (1_ exp( _CΘKT_ ))
_−_ _−_ + 1

_×_ _ϵ_

_j=1_  

Y

3c√d (1 exp( _CΘKT_ )) 3

_−_ _−_

_×_ _ϵ_ !


which implies

1
log Θ, L2(Pm)
_N_ _√m, ℓ_
 

log _c[√]mK(T_ _t0) exp(_ _CΘK(T_ _t0))_ 1
_≤_ _−_ _−_ _−_ _∨_

+ (2d) log  _c[√]m (1_ exp( _CΘKT_ )) + 1 + 3 log _c√dm (1_ exp( _CΘKT_ ))
_−_ _−_ _−_ _−_

log _c[√]mK _ (T _t0) exp(_ _CΘK(T_ _t0))_ 1 + cd log _c[√]m (1_ exp( _CΘKT_ )) + 1
_≤_ _−_ _−_ _−_ _∨_ _−_ _−_

Therefore,  _RmℓΘ_   
_≤_

_c_

log _c[√]mK(T_ _t0) exp(_ _CΘK(T_ _t0))_ 1 + cd log _c[√]m (1_ exp( _CΘKT_ ))

_√m_ _−_ _−_ _−_ _∨_ _−_ _−_

q

    


-----

F.1 ROBUSTNESS TO PARAMETER PERTURBATION: PROOF OF LEMMA 4.1

We split the parametersθ2 = {λ[∗], w, η}. Clearly, the robustness can be bounded by θ = {λ[∗], w, η, α} into two sets θ = θ1 ∪ _θ2, where θ1 = {α} and_

_∥βT (Z1:n; θ1 ∪_ _θ2) −_ **_βT (Z1:n; θ1[′]_** _[∪]_ _[θ][2][)][∥][2]_ [+][ ∥][β][T] [(][Z][1:][n][;][ θ]1[′] _[∪]_ _[θ][2][)][ −]_ **_[β][T]_** [(][Z][1:][n][;][ θ]1[′] _[∪]_ _[θ]2[′]_ [)][∥][2][.]

We derive the upper bounds of these two terms in Lemma F.1 and Lemma F.2, which imply


_∥+βT (CZ11:ηn; θ)η −[′]_ **_β2 +T ( CZ1:2nλ; θ[∗][′])∥2λ ≤[∗′]_** _C2 +√s C[∗]K4√ (dT −w_ _t0)w δ[K][′]_ [(]2[T][ −] 1[t][0] −[)] _|αδ −KTα,[′]|_

_∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ 1 _δ_
  _−_


where δ := 1 − _αmin(ρ−_ _−_ _ξmax) < 1. Lemma 4.1 is equivalent to this inequality by taking_

_CΘ = −_ log(pδ) > 0. Therefore, the key derivation steps are in the proof of Lemma F.1 and
Lemma F.2, as stated below.

**Lemma F.1. Assume the assumptions in Lemma 4.1 are satisfied. Let**

_θ = {λ[∗], w, η, α}_ _and_ _θ[′]_ = {λ[∗], w, η, α[′]}

_be parameters in the constrained space Θ._ _Let {βt}t[T]=1_ [=][ PLISA][θ][(][Z][1:][n][)][ and][ {][β][t][′][}]t[T]=1 [=]
_PLISAθ[′]_ (Z1:n) be the intermediate outputs of PLISA with different parameters θ and θ[′]. Assume


_/ log_ _δ[−][1][]_ + 1,
 


_s[∗](B2 + λmax)_


29ρ+

(1 +
_ρ−_ _−_ _ξmax_


_K ≥_ log


_αminρ+_


_where δ :=_


1 − _αmin(ρ−_ _−_ _ξmax) < 1. Then_


_s[∗]K (T_ _t0) δ[K][(][T][ −][t][0][)]_ _α_ _α[′]_ _._
_−_ _|_ _−_ _|_


**_βT_** **_βT_** _′_ 2 _C_
_∥_ _−_ _∥_ _≤_

_Proof. By triangular inequality,_


**_βt[k]_** **_βt[k]′_** MPG(βt[k][−][1]; λt, w, α) MPG(βt[k][−][1]′; λt, w, α′)

_[−]_ [e] 2 [=] _−_ 2

_≤_ MPG[e] (βt[k][−][1]; λt, w, α) −[e] MPG(βt[k][−][1]; λt, w, α[′]) [e]2

WLOG, assume α > α+ MPG[′][e]. Applying Lemma(β[e]t[k][−][1]; λt, w, α[′]) − F.3MPG and Lemma[e] (β[e]t[k][−][1]′; λ F.4t, w to the above two terms on the right, α′) 2
hand side, we obtain


_α_ _α[′]_

**_βt[k]_** **_βt[k]′_** **_βt[k][−][1]_** **_βt[k][−][1]′_** 2 + _|_ _−_ _|_ **_βt[k]_** **_βt[k][−][1]_**

_[−]_ [e] 2 _[≤]_ _[δ][∥]_ [e] _−_ [e] _∥_ r _α + α[′]_ _[−]_ [e] 2

[e] _≤_ _δ∥β[e]t[k][−][1]_ _−_ **_β[e]t[k][−][1]′∥2 + c |α −_** _α′|_ **_βt[k][e][−]_** **_β[e]t[k][−][1]_** 2 (30)

where c is the Lipschtiz constant. c is a finite number because α is bounded and positive. Applying[e]
it recursively, we have


_K_

_δ[K][−][k]_ **_βt[k]_** **_βt[k][−][1]_** (31)
_k=1_ _[−]_ [e] 2 _[.]_

X

[e]


**_βt[K]_** **_βt[K]_** _′_ **_βt[0]_** **_βt[0]′_** 2 + c _α_ _α′_

[e] _[−]_ [e] 2 _[≤]_ _[δ][K][∥]_ [e] _[−]_ [e] _∥_ _|_ _−_ _|_


-----

Now we bound the term **_βt[k]_** **_βt[k][−][1]_**

_[−]_ [e] 2[. By Lemma][ G.1][ and Lemma][ G.2][,]

[e] 2αmin

**_βt[k]_** **_βt[k][−][1]_** _φλt,w(βt[k][−][1])_ _φλt,w(βλt_ )

_[−]_ [e] 2 s 2 _αminρ+_ _−_

_[≤]_ _−_ 

[e] 2 [e] [b]

_φλt,w(βt[0][)][ −]_ _[φ][λ]t[,][w][(][ b]βλt_ ) _δ[k][−][1]_

_≤_ s _ρ+_

 

2 10[e]

(By Lemma G.6) (λt)S∗ 2δ[k][−][1]
_≤_ s _ρ+_ s _ρ−_ _−_ _ξmax_ _∥_ _∥_


2 10

_B2_

_≤_ s _ρ+_ s _ρ−_ _−_ _ξmax_

= c[′][√]s[∗]δ[k],


_s[∗]δ[k][−][1]_


where c[′] :=


where c[′] := _ρ2+_ _ρ−−10ξmax_ _[B][2][δ][−][1][. However, we can have a tighter bound for this term if][ t][ is]_

larger than a certain integer. More precisely, recall the definition thatSince σ(ηmaxq) < 1q, the entries of λ0 _σ(η)[t]_ will decrease exponentially to reach the entry values of λt = max {λ0 ◦ _σ(η)[t], λ[∗]}._
**_λof blocks after which[∗]. Let t0 = min {t : λ tt ≥ = λ0, λ[∗]. We know[∗]_** = max ◦ _{ tλ00 is a small number because the decrease rate is linear. ◦_ _σ(ηmax)[t], λ[∗]}, ∀λ[∗]_ _∈_ _θ ∈_ Θ(DM )} be the number

Now, the regularization parameters satisfy λt = λ[∗], ∀t ≥ _t0. Therefore, we can apply Lemma G.1_
and Lemma G.2 again to obtain the following bound for all t _t0:_
_≥_


_ρ+_


2αmin

2 _αminρ+_
_−_


**_βt[k]_** **_βt[k][−][1]_**
2

[e] _[−]_ [e] _[≤]_

_≤_

(By Lemma G.6) _≤_


2αmin

_φλ∗,w(βt[k][−][1])_ _φλ∗,w(βλ∗_ )

s 2 _αminρ+_ _−_

_[≤]_ _−_  

2 [e] [b]

_≤_ s _ρ+_ _φλ[∗],w(βt[k]0[−][1]) −_ _φλ∗,w(βλ∗_ ) _δ[K][(][t][−][t][0][)+][k][−][1]_

 

2 10[e] [b]

(λ[∗])S∗ 2δ[K][(][t][−][t][0][)+][k][−][1]

_≤_ s _ρ+_ s _ρ−_ _−_ _ξmax_ _∥_ _∥_

= c[′][√]s[∗]δ[K][(][t][−][t][0][)+][k].


Combining the two different bounds for **_βt[k]_** **_βt[k][−][1]_**

_[−]_ [e] 2 [with Eq.][ 31][, we have]

[e] _C_ _α_ _α[′]_ _√s[∗]_ [P][K]k=1 _[δ][K][−][k][δ][k]_ if t < t0

**_βt_** **_βt[′][∥]2_** _t_ 1[∥][2] [+] _|_ _−_ _|_
_∥_ _−_ _[≤]_ _[δ][K][∥][β][t][−][1]_ _[−]_ **_[β][′]−_** (C |α − _α[′]|_ _√s[∗]_ [P][K]k=1 _[δ][K][−][k][δ][K][(][t][−][t][0][)+][k]_ if t ≥ _t0_

= δ[K]∥βt−1 − **_βt[′]−1[∥][2]_** [+] _CC |αα −_ _αα′[′]|_ _√√ss[∗][∗]KδKδ[K][K][(][t][−][t][0][+1)]_ ifif t < t t _t00_
 _|_ _−_ _|_ _≥_

where C = cc[′]. We apply the above inequality recursively and obtain that

**_βT_** **_βT_** _′_ 2 _C√s[∗]Kδ[K]_ _t0−1_ _δ[K][(][T][ −][t][)]_ _α_ _α[′]_ + _T_ _δ[K][(][T][ −][t][)]δ[K][(][t][−][t][0][)]_ _α_ _α[′]_
_∥_ _−_ _∥_ _≤_ _t=1_ _|_ _−_ _|_ _t=t0_ _|_ _−_ _|!_

X X

= C√s[∗]Kδ[K] _δ[K][(][T][ −][t][0][+1)][ 1][ −]_ _[δ][K][(][t][0][−][1)]_ + (T _t0)δ[K][(][T][ −][t][0][)]_ _α_ _α[′]_

1 _δ[K]_ _−_ _|_ _−_ _|_

 _−_ 

= C√s[∗]Kδ[K] _δK(1 −_ _δK(t0−1))_ + (T _t0)_ _δ[K][(][T][ −][t][0][)]_ _α_ _α[′]_

1 _δ[K]_ _−_ _|_ _−_ _|_

 _−_  

_≤_ _C√s[∗]K (T −_ _t0 + 1) δ[K][(][T][ −][t][0][+1)]_ _|α −_ _α[′]|_

_C√s[∗]K (T_ _t0) δ[K][(][T][ −][t][0][)]_ _α_ _α[′]_
_≤_ _−_ _|_ _−_ _|_


-----

**Lemma F.2. Assume the assumptions in Lemma 4.1 are satisfied. Let**

_θ = {λ[∗], w, η, α}_ _and_ _θ[′]_ = {λ[∗′], w[′], η[′], α}

_be parameters in the constrained space Θ._ _Let {βt}t[T]=1_ [=][ PLISA][θ][(][Z][1:][n][)][ and][ {][β][t][′][}]t[T]=1 [=]
_PLISAθ′_ (Z1:n) be the intermediate outputs of PLISA with different parameters θ and θ[′]. Then
**_βT (Z1:n; θ)_** **_βT (Z1:n, θ[′])_** 2
_∥_ _−_ _∥_ _≤_

_C1_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_** **_λ[∗′]_** 2 + C4√d **_w_** **_w[′]_** 2 1 − _δKT_ _,_
_∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ 1 _δ_
  _−_

_where δ :=_ 1 _αmin(ρ_ _ξmax) < 1 and C1,2,4 are some constants._

_−_ _−_ _−_

p

_Proof.PLISA Letθ(Z {1:nβ)t and}t[T]=1 PLISA[∪{]β[ e]t[k]θ[}]′t[T](=1Z1:Kk=1n) respectively. By triangle inequality,[and][ {][β][t][′][}]t[T]=1_ _[∪{]β[ e]t[k]′}Tt=1Kk=1_ [be the intermediate outputs of]

**_βt[k]_** **_βt[k]′_** MPG(βt[k][−][1]; λt, w, α) MPG(βt[k][−][1]′; λt′, w′, α′)

_[−]_ [e] 2 [=] _−_ 2

_≤[e]_ MPG(βt[k][−][1]; λt, w, α[e]) − MPG(βt[k][−][1]′; λt, w, α[e]) 2

+ MPG(β[e]t[k][−][1]′; λt, w, α) − MPG([e]βt[k][−][1]′; λt′, w, α) 2

+ MPG(β[e]t[k][−][1]′; λt′, w, α) − MPG( eβt[k][−][1]′; λt′, w′, α) 2 _[.]_

Applying Lemma F.3, Lemma F.5, and Lemma F.6 to the above 3 terms on the right hand side, we

[e] e

obtain
**_βt[k]_** **_βt[k]′_** **_βt[k][−][1]_** **_βt[k][−][1]′_** 2 + [2] **_λt_** **_λ[′]t[∥][2]_** + C **_w_** **_w[′]_** 2 **_λt_** 2, (32)

_[−]_ [e] 2 _[≤]_ _[δ][∥]_ [e] _−_ [e] _∥_ _ρ+_ _∥_ _−_ _∥_ _−_ (ii)∥ _∥_ _∥_

(i)

[e]

| {z }

where C is some absolute constant. | {z }

Term (i). By definition and triangular inequality,


**_λt_** **_λt′_** 2 max **_λ0_** _σ(η)[t], λ[∗]_ max **_λ0_** _σ(η[′])[t], λ[∗]_ 2
_∥_ _−_ _∥_ _≤∥_ _◦_ _−_ _◦_ _∥_
+ max **_λ0_** _σ(η[′])[t], λ[∗]_ max **_λ0_** _σ(η[′])[t], λ[∗′]_ 2
_∥_ _◦_ _−_ _◦_ _∥_
_≤∥λ0∥∞tσ(ηmax)[t][−][1]t∥σ(η) −_ _σ(η[′])∥2 + ∥λ[∗]_ _−_ **_λ[∗′]∥2_**

_≤_ _[B]4[2]_ _[σ][(][η][max][)][t][t][∥][η][ −]_ **_[η][′][∥][2][ +][ ∥][λ][∗]_** _[−]_ **_[λ][∗′][∥][2]_**


The last inequality holds by Assumptionsome constants C2 = _ρ2+_ [and][ ˜]C1 = C2 _[B]4 C.1[2]_ [,] and the bounded first derivative of σ(·). Therefore, for

(i) = [2] **_λt_** **_λ[′]t[∥][2]_** _C1σ(ηmax)[t]t_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_** **_λ[∗′]_** 2

_ρ+_ _∥_ _−_ _[≤]_ [˜] _∥_ _−_ _∥_ _∥_ _−_ _∥_


_≤_ _C1∥η −_ **_η[′]∥2 + C2∥λ[∗]_** _−_ **_λ[∗′]∥2._**

The last inequality holds because the value σ(ηmax)[t]t is bounded by some constant.

Term (ii). Since ∥λt∥2 ≤∥ max {σ(ηmax)[t]λ0, λ[∗′]} ∥2 ≤∥ max {σ(ηmax)[t]λ0, λ0} ∥2 = ∥λ0∥2 ≤
_B√d,_


(ii) = C **_w_** **_w[′]_** 2 **_λt_** 2 _C4_
_∥_ _−_ _∥_ _∥_ _∥_ _≤_


_d_ **_w_** **_w[′]_** 2.
_∥_ _−_ _∥_


Plugging the bounds for (i)-(iii) into Eq. 32, we have

**_βt[k]_** **_βt[k]′_** **_βt[k][−][1]_** **_βt[k][−][1]′_** 2 + C1 **_η_** **_η′_** 2 + C2 **_λ∗_** **_λ∗′_** 2 + C4

[e] _[−]_ [e] 2 _[≤]_ _[δ][∥]_ [e] _−_ [e] _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_


_d_ **_w_** **_w[′]_** 2.
_∥_ _−_ _∥_


-----

By direct computation,
**_βt[K]_** **_βt[K]_** _′_
2

_[−]_ [e]

[e]δ[K] **_βt[0]_** **_βt[0]′_** _C1_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_** **_λ[∗′]_** 2 + C4√d **_w_** **_w[′]_** 2 _[K][−][1]_ _δ[k]_

_≤_ _[−]_ [e] 2 [+] _∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ _k=0_
  X

= δ[K] **_β[e]t[0]_** **_βt[0]′_** _C1_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_** **_λ[∗′]_** 2 + C4√d **_w_** **_w[′]_** 2 1 − _δK_

_[−]_ [e] 2 [+] _∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ 1 _δ [.]_
  _−_

Recall that **_βt[K]_** [=][ β][t] [and][ e]βt[0] [=][ β][t][−][1][. We can apply the above inequality recursively and obtain that]

[e]

**_βT_** **_βT_** _′_ 2
_∥≤_ _δ −[K]_ _∥β[e]T −∥1 −_ **_βT −1′∥2 +_** _C1∥η −_ **_η[′]∥2 + C2∥λ[∗]_** _−_ **_λ[∗′]∥2 + C4√d∥w −_** **_w[′]∥2_** 11 − _δδK_

_C1_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_**  **_λ[∗′]_** 2 + C4√d **_w_** **_w[′]_** 2 1 − _δK_ _T −1(δ[K])[t]_  _−_
_≤_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ 1 _δ_

_t=0_

  _−_ X

= _C1_ **_η_** **_η[′]_** 2 + C2 **_λ[∗]_** **_λ[∗′]_** 2 + C4√d **_w_** **_w[′]_** 2 1 − _δKT_ _._
_∥_ _−_ _∥_ _∥_ _−_ _∥_ _∥_ _−_ _∥_ 1 _δ_
  _−_

**Lemma F.3 (Robustness to β). Assume (Z1:n, β[∗])** _and_ _satisfies Assumption C.1. Assume_
1 _∈P_ _P_
**_β, β[′]_** _satisfy ∥β −_ **_β[′]∥0 ≤_** _s = s[∗]_ + 2˜s and α ≤ _ρ+_ _[. Then]_


1 2α [(][ρ][−] _[−]_ _[ξ][w][)][ρ][+]_ **_β_** **_β[′]_** 2 (33)
_−_ _ρ_ _ξw + ρ+_ _∥_ _−_ _∥_

_−_ _−_

1 − _α (ρ−_ _−_ _ξw) ∥β −_ **_β[′]∥2_** (34)


_MPG(β; λ, w, α)_ _MPG(β[′]; λ, w, α)_ 2
_∥_ _−_ _∥_ _≤_


_Proof._

MPG(β; λ, w, α) MPG(β[′]; λ, w, α) 2
_∥_ _−_ _∥[2]_
= ∥Tα·λ (β − _α (∇Lλ,w(β))) −Tα·λ (β[′]_ _−_ _α (∇Lλ,w(β[′])))∥2[2]_
**_β_** _α (_ _Lλ,w(β))_ **_β[′]_** + α ( _Lλ,w(β[′]))_ 2
_≤∥_ _−_ _∇_ _−_ _∇_ _∥[2]_
= **_β_** **_β[′]_** 2 [+][ α][2][ ∥∇][L][λ][,][w][(][β][)][ −∇][L][λ][,][w][(][β][′][)][∥]2[2]
_∥_ _−_ _∥[2]_

_[−]_ [2][α][⟨][β][ −] **_[β][′][,][ ∇][L][λ][,][w][(][β][)][ −∇][L][λ][,][w][(][β][′][)][⟩](35)[.]_**
Since on the restricted subspace **_β :_** **_β_** **_β[∗]_** 0 _s[∗]_ + 2˜s, Lλ is (ρ _ξw)-strongly convex and_
_ρ+-smooth, by Lemma G.7,_ _{_ _∥_ _−_ _∥_ _≤_ _}_ _−_ _−_
**_β_** **_β[′],_** _Lλ,w(β)_ _Lλ,w(β[′])_
_⟨_ _−_ _∇_ _−∇_ _⟩_

**_β_** **_β[′]_** 2 [+][ ∥∇][L][λ][,][w][(][β][)][ −∇][L][λ][,][w][(][β][′][)][∥]2[2] _._

_≥_ _ρ[(][ρ][−]_ _[−]ξw[ξ][w] +[)] ρ[ρ][+]+_ _∥_ _−_ _∥[2]_ _ρ_ _ξw + ρ+_

_−_ _−_ _−_ _−_

Combining this inequality with Eq. 35, we have
MPG(β; λ, w, α) MPG(β[′]; λ, w, α) 2
_∥_ _−_ _∥[2]_

_≤_ 1 − 2α _ρ[(][ρ][−]_ _[−]ξw[ξ][w] +[)] ρ[ρ][+]+_ _∥β −_ **_β[′]∥2[2]_**
 _−_ _−_ 

2
+ α _α −_ _ρ_ _ξw + ρ+_ _∥∇Lλ,w(β) −∇Lλ,w(β[′])∥2[2]_
 _−_ _−_ 

By the assumption that α ≤ _ρ1+_ [, the second term in the above inequality is non-positive. Further-]

more, this assumption also implies that 1 − 2α [(]ρ[ρ]−[−]−[−]ξ[ξ]w[w]+[)]ρ[ρ]+[+]

_[≥]_ [0][. Therefore,]

MPG(β; λ, w, α) MPG(β[′]; λ, w, α) 2 1 2α [(][ρ][−] _[−]_ _[ξ][w][)][ρ][+]_ **_β_** **_β[′]_** 2
_∥_ _−_ _∥_ _≤_ s _−_ _ρ_ _ξw + ρ+_ _∥_ _−_ _∥_

_−_ _−_


-----

**Lemma F.4 (Robustness to α). With out loss of generalization, assume α ≥** _α[′]. Denote_

**_β[+]_** := MPG(β; λ, w, α) _and_ **_β[+][′]_** := MPG(β; λ, w, α[′]).

_Then_


_α_ _α[′]_

**_β[+][′]_** **_β[+]_** 2 _−_ **_β[+]_** **_β_**
_∥_ _−_ _∥_ _≤_ _α + α[′]_ _−_

r

_Proof. Define the quadratic approximation function as_


_ψα,λ,w(z, β) := Lλ,w(β) +_ _Lλ,w(β), z_ **_β_** + [1] 2 [+][ ∥][z][∥]λ,1 _[.]_ (36)
_⟨∇_ _−_ _⟩_ 2α _[∥][z][ −]_ **_[β][∥][2]_**


Clearly,


MPG(β; λ, w, α) = arg min _ψα,λ,w(z, β)._
**_z_**

Since ψα,λ,w(z, β) is _α[1]_ [-strongly convex in][ z][, and that][ β][+][ :=][ MPG][(][β][;][ λ][,][ w][, α][)][ is its optimal point,]

_ψα,λ,w(z, β) ≥_ _ψα,λ,w(β[+], β) + 2[1]α_ **_z −_** **_β[+]_** 2 _∀z._ (37)

Similarly,

[2]

1
_ψα′,λ,w(z, β) ≥_ _ψα′,λ,w(β[+][′], β) +_ 2α[′] **_z −_** **_β[+][′]_** 2 _∀z._ (38)

Taking z = β[+][′] in Eq. 37 and z = β[+] in Eq. 38 yields [2]

1

**_β[+]_** **_β[+][′]_**

2α _−_ 2 _[≤]_ _[ψ][α,][λ][,][w][(][β][+][′][,][ β][)][ −]_ _[ψ][α,][λ][,][w][(][β][+][,][ β][)][,]_

1

2α[′] **_β[+]_** _−_ **_β[+][′]_** 2 [2][≤] _[ψ][α][′][,][λ][,][w][(][β][+][,][ β][)][ −]_ _[ψ][α][′][,][λ][,][w][(][β][+][′][,][ β][)][.]_

Summing the above two inequalities, we have

[2]

1 1
2  _α_ [+ 1]α[′]  β[+] _−_ **_β[+][′]_** 2[2] _[≤]_ + ψα,ψλα,′w,λ(,βw[+](β[′],[+] β,) β −) _ψαψ′,α,λ,λw,w(β(β[+][+][′], β, β))_

_−_

(by α _α[′])_ _ψα ′,λ,w(β[+], β)_ _ψα,λ,w(β[+], β)_ 
_≥_ _≤_ _−_

1

= [1] **_β[+]_** **_β_**

2 _α[′][ −]_ _α[1]_ _−_ 2 _[.]_

 

[2]


**Lemma F.5 (Robustness to λ). Let β[+]** = MPG(β; λ, w, α) and β[+][′] = MPG(β; λ[′], w, α). Then

**_β[+]_** **_β[+][′]_** 2 2α (λ **_λ[′])S_** 2, (39)
_∥_ _−_ _∥_ _≤_ _∥_ _−_ _∥_

_where S := supp(β[+]) ∪_ supp(β[+][′]).

_Proof. Recall the quadratic approximation in Eq. 51 and the definition that MPG(β; λ, w, α) =_
arg minz ψα,λ,w(z, β). By the _α[1]_ [-strongly convexity of][ ψ][α,][λ][,][w][ in][ z][, it holds true for all][ z][ that]

1

**_z_** **_β[+]_**

2α _−_ 2 _[≤]_ _[ψ][α,][λ][,][w][(][z][,][ β][)][ −]_ _[ψ][α,][λ][,][w][(][β][+][,][ β][)]_

= _Lλ,w(β)[2], z_ **_β[+]_** + [1] **_z_** **_β_** 2 **_β[+]_** **_β_** 2 + ( **_z_** **_λ,1_** **_β[+]_** **_λ,1[)]_** (40)
_⟨∇_ _−_ _⟩_ 2α _∥_ _−_ _∥[2]_ _[−]_ _−_ _∥_ _∥_ _−_

 

Similarly,

[2]

1

2α **_z −_** **_β[+][′]_** 2 (41)

_Lλ′,w(β)[2], z_ **_β[+][′]_** + [1] **_z_** **_β_** 2 **_β[+][′]_** **_β_** 2 + ( **_z_** **_λ′,1_** **_β[+][′]_** **_λ[′],1[)][.]_** (42)
_≤⟨∇_ _−_ _⟩_ 2α _∥_ _−_ _∥[2]_ _[−]_ _−_ _∥_ _∥_ _−_

 

[2]


-----

Taking z = β[+][′] in Eq. 40, taking z = β[+] in Eq. 42, and summing up the two inequalities, we have

1

**_β[+]_** **_β[+][′]_**

_α_ _−_ 2 _[≤⟨∇][L][λ][,][w][(][β][)][ −∇][L][λ][′][,][w][(][β][)][,][ β][+][′][ −]_ **_[β][+][⟩]_**

+ **_β[+]_** (λ[′] **_λ)_** 1 **_β[+][′]_** (λ[′] **_λ)_** 1

[2] _∥_ _◦_ _−_ _∥_ _−∥_ _◦_ _−_ _∥_

= ⟨∇Qλ,w(β) −∇Qλ′,w(β), β[+][′] _−_ **_β[+]⟩_** + ∥β[+] _−_ **_β[+][′]∥|λ−λ′|,1_**

_d_

_qw[′]_ [(][λ][j][, β][j][)][ −] _[q]w[′]_ [(][λ][′]j[, β][j][)][||][β]j[+]′ _βj+_

_≤_ _j=1_ _|_ _−_ _[|][ +][ ∥][β][+][ −]_ **_[β][+][′][∥][|][λ][−][λ][′][|][,][1]_**

X


_λj_ _λ[′]j[||][β]j[+]′_ _βj+_
_j=1_ _|_ _−_ _−_ _[|][ +][ ∥][β][+][ −]_ **_[β][+][′][∥][|][λ][−][λ][′][|][,][1]_**

X


(by Assumption B.1) ≤


= 2∥β[+] _−_ **_β[+][′]∥|λ−λ′|,1_**
2 (λ **_λ[′])S_** 2 **_β[+][′]_** **_β[+]_** 2
_≤_ _∥_ _−_ _∥_ _−_

where S := supp(β[+])∪supp(β[+][′]). Dividing both side by ∥β[+][′] _−_ **_β[+]∥2 draws the conclusion._**

**Lemma F.6 (Robustness to w). Let β[+]** = MPG(β; λ, w, α) and β[+][′] = MPG(β; λ, w[′], α). Then

**_β[+]_** **_β[+][′]_** 2 _C_ **_w_** **_w[′]_** 2 (λ)S 2, (43)
_∥_ _−_ _∥_ _≤_ _∥_ _−_ _∥_ _∥_ _∥_

_where S := supp(β[+]) ∪_ supp(β[+][′]) and C is some absolute constant.

_Proof. Recall the quadratic approximation in Eq. 51 and the definition that MPG(β; λ, w, α) =_
arg minz ψα,λ,w(z, β). By the _α[1]_ [-strongly convexity of][ ψ][α,][λ][,][w][ in][ β][, it holds true for all][ z][ in the]

restricted subspace that


1

**_z_** **_β[+]_**

2α _−_ 2 _[≤]_ _[ψ][α,][λ][,][w][(][z][,][ β][)][ −]_ _[ψ][α,][λ][,][w][(][β][+][,][ β][)]_

= ⟨∇Lλ,w(β)[2], z − **_β[+]⟩_** + 2[1]α _∥z −_ **_β∥2[2]_** _[−]_ **_β[+]_** _−_ **_β_**



Similarly,


+ (∥z∥λ,1 − **_β[+]_** **_λ,1[)]_** (44)


1

**_z_** **_β[+][′]_**

2α _−_ 2

_Lλ,w[′]_ (β)[2], z **_β[+][′]_** + [1] **_z_** **_β_** 2 **_β[+][′]_** **_β_** 2 + ( **_z_** **_λ,1_** **_β[+][′]_** **_λ,1[)][.]_** (45)
_≤⟨∇_ _−_ _⟩_ 2α _∥_ _−_ _∥[2]_ _[−]_ _−_ _∥_ _∥_ _−_

 

Taking z = β[+][′] in Eq. 44, taking z = β[+] in Eq. 45, and summing up the two inequalities, we have[2]


**_β[+]_** **_β[+][′]_**
2
_−_ _[≤⟨∇][L][λ][,][w][(][β][)][ −∇][L][λ][,][w][′]_ [(][β][)][,][ β][+][′][ −] **_[β][+][⟩]_**

= **_λ,w(β)_** **_λ,w′_** (β), β[+][′] **_β[+]_**

[2] _⟨∇Q_ _−∇Q_ _−_ _⟩_


_qw[′]_ [(][λ][j][, β][j][)][ −] _[q]w[′]_ _[′]_ [(][λ][j][, β][j][)][||][β]j[+]′ _βj+_

_≤_ _j=1_ _|_ _−_ _[|][.]_

X

Note that qw[′] [(][λ][j][, β][j][) =][ P][3]i=1 exp(Z(ww)i) _[q][(][i][)][′][(][λ][j][,][ β][j][)][ where][ Z][(][w][) =][ P]i[3]=1_ [exp(][w][i][)][. Then]

3

exp(wi) _i[)]_

_qw[′]_ [(][λ][j][, β][j][)][ −] _[q]w[′]_ _[′]_ [(][λ][j][, β][j][)][| ≤] _q[(][i][)][′](λj, βj)_
_|_ _Z(w)_ _−_ [exp(]Z(w[w][′])[′]

_i=1_

X

3

exp(wi) _i[)]_

(by Assumption B.1) _[λ][j][.]_
_≤_ _Z(w)_ _−_ [exp(]Z(w[w][′])[′]

_i=1_

X


-----

Therefore,


**_β[+]_** **_β[+][′]_**
2
_−_ _[≤]_

[2]


exp(wi) _i[)]_

_Z(w)_ _−_ [exp(]Z(w[w][′])[′]


_λj_ _βj[+]′_ _βj+_
_j=1_ _|_ _−_ _[|]_

X


_i=1_


3

exp(wi) _i[)]_

**_β[+][′]_** **_β[+]_**

_≤_ _i=1_ _Z(w)_ _−_ [exp(]Z(w[w][′])[′] _[∥][(][λ][)][S][∥][2]_ _−_

X

(By Lipschitz continuity) _≤_ _C∥w −_ **_w[′]∥2∥(λ)S∥2_** **_β[+][′]_** _−_ **_β[+]_** 2 _[,]_

for some constant C.


-----

G KEY LEMMAS

This section supplies some fundamental results for the modified proximal gradient algorithm. All
the results in this section are based on the following assumption and notations.
**Assumption G.1. Assume P satisfies Assumption C.1 and consider a problem (Zn, β[∗]) ∈P. As-**
_sume we have a penalty function P_ (λ, β) whose concave component Q(λ, β) = P (λ, β) **_λ_** **_β_** 1
_−∥_ _◦_ _∥_
_satisfies the regularization conditions in Assumption B.1 with a Lipschitz constant ξ for the condition_
_(a). We adopt the following notations for the statements in this sections._

_empirical loss_ _Ln(β) := Ln(Z1:n, β)_
_modified loss_ _Lλ(β) := Ln(Z1:n, β) + Q(λ, β)_
_regularized loss_ _φλ(β) := Ln(Z1:n, β) + P_ (λ, β) = Lλ(β) + **_β_** **_λ,1_**
_∥_ _∥_

_local optimal_ **_βλ_** arg min _φλ(β)_
_∈_ **_β∈R[d]:∥βS∗_** _∥0≤s˜_
b

_quadratic approximation_ _ψα,λ(z, β) := Lλ(β) +_ _Lλ(β), z_ **_β_** + [1] 2 [+][ ∥][z][∥]λ,1
_⟨∇_ _−_ _⟩_ 2α _[∥][z][ −]_ **_[β][∥][2]_**

(β **_β′)⊤_**

_sub-optimality_ _ωλ(β) :=_ min _−_ ( _Lλ(β) + λ_ **_ξ[′])_** _._
**_ξ[′]_** _∂_ **_β_** 1 [max]β[′] **_β_** **_β[′]_** **_λ,1_** _∇_ _◦_
_∈_ _∥_ _∥_  _∥_ _−_ _∥_ 

**Lemma G.1 (Contraction of MPG). Assume Assumption G.1. Let β[0], · · ·, β[k]** _be a sequence of_
_vectors obtained by the modified proximal gradient updates:_

**_β[k]_** = MPG(β[k][−][1]; λ, w, α)

:= Tα·λ **_β[k][−][1]_** _−_ _α_ _∇Ln(β[k][−][1]) + ∇βQ(λ, β[k][−][1])_ _._

_Assume_ (β[k])S∗ 0 _s˜. Then_     
_∥_ _∥_ _≤_
1
 _α_ _[−]_ _[ρ]2[+]_ **_β[k]_** _−_ **_β[k][−][1]_** 2 _[≤]_ _[φ][λ][(][β][k][−][1][)][ −]_ _[φ][λ][(][β][k][)][.]_ (46)



[2]

_Proof. Note that_

**_β[k]_** = β[k][−][1] _−_ _αδα(β[k][−][1]),_ where δα(β) := α[−][1] (β −Tαλ (β − _α∇Lλ(β))) ._

It is easy to observe that δα(β) _Lλ(β) + λ_ _∂_ **_β_** _αδα(β)_ 1. By RSS in Lemma B.1, it
_∈∇_ _◦_ _∥_ _−_ _∥_
holds that

_Lλ_ **_β[k][]_** _≤_ _Lλ(β[k][−][1]) −_ _α∇Lλ(β[k][−][1])[⊤]δα(β[k][−][1]) +_ _[ρ]2[+]_ _[α][2]_ **_δα(β[k][−][1])_** 2 _[.]_

Furthermore, by RSC in Lemma  B.1, for any z in the space **_z_** **_β[k][−][1]_** 0 _s[2]_,
_{_ _−_ _[≤]_ _[s][∗]_ [+ 2˜]}

_Lλ_ **_β[k][]_** _Lλ(z) +_ _Lλ(β[k][−][1])[⊤](β_ **_z)_** _α_ _Lλ(β[k][−][1])[⊤]δα(β[k][−][1])_ (47)
_≤_ _∇_ _−_ _−_ _∇_
  + _[ρ]2[+]_ _[α][2]_ **_δα(β[k][−][1])_** 2 _[−]_ _[ρ][−]2[−]_ _[ξ]_ **_β[k][−][1]_** _−_ **_z_** 2 _[.]_ (48)

Denote v = δα(β[k][−][1]) −∇Lλ(β[k][−][1]). [2]We have v ∈ **_λ ◦_** _∂_ [2]β[k][−][1] _−_ _αδα(β[k][−][1])_ 1 [since]
**_δα(β[k][−][1]) ∈∇Lλ(β[k][−][1]) + λ ◦_** _∂_ **_β[k][−][1]_** _−_ _αδα(β[k][−][1])_ 1[. By the convexity of][ ∥·∥][λ][,][1][,]
**_β[k][−][1]_** _αδα(β[k][−][1])_ **_λ,1_** [+][ v][⊤] [ ]β[k][−][1] _αδα(β[k][−][1])_ **_z_** _._
_−_ _[≤∥][z][∥][λ][,][1]_ _−_ _−_

Combining this inequality with Eq. 48, we have 

_Lλ(β[k]) + ∥β[k]∥λ,1 ≤_ _Lλ(z) + λ ∥z∥λ,1 + δα(β[k][−][1])[⊤](β[k][−][1]_ _−_ **_z)_** (49)

_−_ _α_ 1 − _[α][(][ρ]2[+][)]_ **_δα(β[k][−][1])_** 2 2 **_β[k][−][1]_** _−_ **_z_** 2 _[.]_ (50)
  _[−]_ _[ρ][−]_ _[−]_ _[ξ]_

Taking z = β[k][−][1] in Eq. 50 implies that [2] [2]


_Lλ(β[k]) + ∥β[k]∥λ,1 ≤_ _Lλ(β[k][−][1]) +_ **_β[k][−][1]_** **_λ,1_** _[−]_ _α[1]_


**_β[k]_** **_β[k][−][1]_**
_−_ 2 _[.]_

[2]


1
_−_ _[α][(][ρ]2[+][)]_


-----

Therefore,
1

_α_ 2

 _[−]_ _[ρ][+]_


**_β[k]_** **_β[k][−][1]_**

2

_−_ _[≤]_ _[φ][λ][(][β][k][−][1][)][ −]_ _[φ][λ][(][β][k][)][.]_

[2]


**Lemma G.2 (Convergence of modified proximal gradient). Assume Assumption G.1.** _Let_
**_β[0], · · ·, β[k]_** _be a sequence of vectors obtained by the modified proximal gradient updates:_

**_β[k]_** = MPG(β[k][−][1]; λ, w, α)

:= Tα·λ **_β[k][−][1]_** _−_ _α_ _∇Ln(β[k][−][1]) + ∇βQ(λ, β[k][−][1])_

_with a step size α in (0,_ _ρ1+_ []][. Assume]  _[ ∥][(][β][k][)]S [∗]_ _[∥][0][ ≤]_ _s[˜]. Then_ 

_φλ(β[k]) −_ _φλ(βλ) ≤_ (1 − _α(ρ−_ _−_ _ξw))[k][ ]φλ(β[0]) −_ _φλ(βλ)_ _,_


**_β[k]_** **_βλ_** 2 **_βλ_** 2[,]
_∥_ _−_ [b][b]∥[2] _[≤]_ [(1][ −] _[α][(][ρ][−]1[−]_ _[ξ][w][))][k][ ∥][β][0][ −]_ [b] _∥[2]_ [b]

_√2(1 +_ _αρ+_ [)][√][ρ][+]

_ωλ(β[k]) ≤_ min(λ) (1 − _α(ρ−_ _−_ _ξw))[k][−][1][ ]φλ(β[0]) −_ _φλ(βλ)_ _._

r



[b]

_Proof. Consider the quadratic approximation function_


_ψα,λ(z, β) := Lλ(β) +_ _Lλ(β), z_ **_β_** + [1] 2 [+][ ∥][z][∥]λ,1 _[.]_ (51)
_⟨∇_ _−_ _⟩_ 2α _[∥][z][ −]_ **_[β][∥][2]_**


By definition,


MPG(β[k][−][1]; λ, w, α) = arg min _ψα,λ(z, β[k][−][1])._
**_z_**

Since ψα,λ(z, β[k][−][1]) is _α[1]_ [-strongly convex with respect to][ z][, and that][ β][k][ is its optimal point, we]

can obtain

_ψα,λ(z, β[k][−][1]) ≥_ _ψα,λ(β[k], β[k][−][1]) + 2[1]α_ **_z −_** **_β[k]_** 2 _[,]_ _∀z._ (52)

Note that by Lemma B.1,

[2]

_ψα,λ(β[k], β[k][−][1]) = Lλ(β[k][−][1]) + ∇Lλ(β[k][−][1])[⊤]_ [ ]β[k] _−_ **_β[k][−][1][]_** + 2[1]α _[∥][β][k][ −]_ **_[β][k][−][1][∥]2[2]_**

+ **_β[k]_** **_λ,1_**
_∥_ _∥_

1

_Lλ(β[k]) +_ _α_ _[−]_ _[ρ][+]_ **_β[k]_** **_β[k][−][1]_** 2 [+][ ∥][β][k][∥][λ][,][1]
_≥_ 2 _∥_ _−_ _∥[2]_

1

= φλ(β[k]) + _α_ _[−]_ _[ρ][+]_ **_β[k]_** **_β[k][−][1]_** 2[.]

2 _∥_ _−_ _∥[2]_

Similarly, by Lemma B.1,


_ψα,λ(z, β[k][−][1]) = Lλ(β[k][−][1]) + ∇Lλ(β[k][−][1])[⊤]_ [ ]z − **_β[k][−][1][]_** + 2[1]α _[∥][z][ −]_ **_[β][k][−][1][∥]2[2]_**

+ **_z_** **_λ,1_**
_∥_ _∥_

1

_φλ(z) +_ _α_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_ **_z_** **_β[k][−][1]_** 2[.]
_≤_ 2 _∥_ _−_ _∥[2]_

Combining the above two results with Eq. 52, we have


1

_φλ(β[k])_ _φλ(z) +_ _α_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_
_≤_ 2

**_z_** **_β[k]_**

_−_ 2[1]α _−_ 2

1

_φλ(z) +_ _α_ _[−]_ [(][ρ][2][−] _[−]_ _[ξ][)]_
_≤_ 2


1

_α_

_[−]_ _[ρ][+]_

2

1

_α_

_[−]_ _[ρ][+]_

2


**_β[k]_** **_β[k][−][1]_** 2
_∥_ _−_ _∥[2]_

_∥β[k]_ _−_ **_β[k][−][1]∥2[2][.]_**


**_z_** **_β[k][−][1]_** 2
_∥_ _−_ _∥[2]_ _[−]_

**_z_** **_β[k][−][1]_** 2
_∥_ _−_ _∥[2]_ _[−]_


(53)


-----

Taking z = cβλ + (1 − _c)β[k][−][1]_ for some c ∈ [0, 1], then

_φλ(β[k])_

[b]

1

_cφλ(βλ) + (1_ _c)φλ(β[k][−][1]) +_ _α_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_ _c[2]_ **_β[k][−][1]_** **_βλ_** 2
_≤_ _−_   2  _∥_ _−_ [b] _∥[2]_ _[−]_

_cφλ(β[b]λ) + (1_ _c)φλ(β[k][−][1]) +_ _[c]_ _c_ _α[1]_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_ **_β[k][−][1]_** **_βλ_** 2
_≤_ _−_   2  _∥_ _−_ [b] _∥[2]_ _[−]_

Taking c = α (ρ _ξ), it implies_

[b] _−_ _−_


1

_α_

_[−]_ _[ρ][+]_

2

1

_α_

_[−]_ _[ρ][+]_

2


**_β[k]_** **_β[k][−][1]_** 2
_∥_ _−_ _∥[2]_

**_β[k]_** **_β[k][−][1]_** 2
_∥_ _−_ _∥[2]_


1

_α_

_[−]_ _[ρ][+]_

2


_∥β[k]_ _−_ **_β[k][−][1]∥2[2][.]_**


_φλ(β[k]) −_ _φλ(βλ) ≤_ (1 − _α (ρ−_ _−_ _ξ))_ _φλ(β[k][−][1]) −_ _φλ(βλ)_


Assume α ≤ _ρ1+_ [. Then][b] [b]


_φλ(β[k]) −_ _φλ(βλ) ≤_ (1 − _α (ρ−_ _−_ _ξ))_ _φλ(β[k][−][1]) −_ _φλ(βλ)_ _._
 

Taking z = **_βλ in Eq. 53 implies[b]_** [b]

1

[b]φλ(β[k]) _φλ(βλ) +_ _α_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_ **_βλ_** **_β[k][−][1]_** 2 **_βλ_** **_β[k]_** 2[.]

_≤_ 2 _∥_ [b] _−_ _∥[2]_ _[−]_ 2[1]α _[∥]_ [b] _−_ _∥[2]_

By the optimality of **_βλ, we have[b]_**

1

[b] _α_ _[−]_ [(][ρ][−] _[−]_ _[ξ][)]_ **_βλ_** **_β[k][−][1]_** 2 **_βλ_** **_β[k]_** 2

2 _∥_ [b] _−_ _∥[2]_ _[−]_ 2[1]α _[∥]_ [b] _−_ _∥[2]_ _[≥]_ [0][,]

which implies

**_βλ_** **_β[k]_** 2 **_βλ_** **_β[k][−][1]_** 2[.]
_∥_ [b] _−_ _∥[2]_ _[≤]_ [(1][ −] _[α][ (][ρ][−]_ _[−]_ _[ξ][))][ ∥]_ [b] _−_ _∥[2]_

Finally, we derive the upper bound for ωλ(β[k]). Since β[k] = arg minz ψα,λ(z, β[k][−][1]), by the
optimality condition, for each j = 1, _, d, there exists a subgradient ξj_ _∂_ _βj[k]_ such that
_· · ·_ _∈_

_Lλ(β[k][−][1]) + [1]_
_∇_ _α_ [(][β][k][ −] **_[β][k][−][1][) +][ λ][ ◦]_** **_[ξ][ = 0][.]_**


By the definition of ωλ and combining it with the above equality,

_k_
(β **_β′)⊤_**

_ωλ(β[k]) =_ min max _−_ ( _Lλ(β[k]) + λ_ **_ξ[′])_**
**_ξ[′]∈∂∥β[k]∥1_** **_β[′]∈Ω_**  _∥β[k]_ _−_ **_β[′]∥λ,1_** _∇_ _◦_ 

_k_
(β **_β′)⊤_**

max _−_ ( _Lλ(β[k]) + λ_ **_ξ)_**
_≤_ **_β[′]∈Ω_**  _∥β[k]_ _−_ **_β[′]∥λ,1_** _∇_ _◦_ 

_k_
(β **_β′)⊤_**

= max _−_ _Lλ(β[k])_ _Lλ(β[k][−][1]) + [1]_
**_β[′]∈Ω_**  _∥β[k]_ _−_ **_β[′]∥λ,1_** ∇ _−∇_ _α_ [(][β][k][−][1][ −] **_[β][k][)]_**

_d_ (βj[k] _j[)][λ][j]_ _Lλ(β[k])_ _Lλ(β[k][−][1]) +_ _α[1]_ [(][β][k][−][1][ −] **_[β][k][)]_**

= max _[−]_ _[β][′]_ _∇_ _−∇_
**_β[′]∈Ω_** Xj=1 _∥β[k]_ _−_ **_β[′]∥λ,1_**   _λj_

1



_≤_ min(λ) _[∥∇][L][λ][(][β][k][)][ −∇][L][λ][(][β][k][−][1][) + 1]α_ [(][β][k][−][1][ −] **_[β][k][)][∥][∞]_**


1

min(λ) _[∥∇][L][λ][(][β][k][)][ −∇][L][λ][(][β][k][−][1][) + 1]α_ [(][β][k][−][1][ −] **_[β][k][)][∥][2]_**

1

min(λ) _[∥∇][L][λ][(][β][k][)][ −∇][L][λ][(][β][k][−][1][)][∥][2][ + 1]α_ _[∥][(][β][k][−][1][ −]_ **_[β][k][)][∥][2]_**


1

min(λ) [(][ρ][+][ + 1]α [)][∥][(][β][k][−][1][ −] **_[β][k][)][∥][2][.]_**


(by RSS) ≤


-----

By Lemma G.1, (β[k][−][1] **_β[k])_** 2
_∥_ _−_ _∥_ _≤_


2

2 _α[1]_

_[−][(][ρ][+][)][ (][φ][λ][(][β][k][−][1][)][ −]_ _[φ][λ][(][β][k][))][. Therefore,]_

2

s 2 _α[1]_

_[−]_ [(][ρ][+][) (][φ][λ][(][β][k][−][1][)][ −] _[φ][λ][(][β][k][))]_


1

min(λ) [(][ρ][+][ + 1]α [)]

1

min(λ) [(][ρ][+][ + 1]α [)]

1

min(λ) [(][ρ][+][ + 1]α [)]

1

min(λ) [(][ρ][+][ + 1]α [)]


_ωλ(β[k])_
_≤_


(φλ(β[k][−][1]) _φλ(β[k]))_
_ρ+_ _−_

2

_φλ(β[k][−][1])_ _φλ(βλ)_

_ρ+_ _−_

 

2 [b]

_ρ+_ (1 − _α (ρ−_ _−_ _ξ))[k][−][1][ ]φλ(β[0]) −_ _φλ(βλ)_

[b]


**Lemma G.3 (Statistical ℓ2 error). Assume Assumption G.1. If the following conditions are satisfied**

**_β_** **_β[∗]_** 0 _s[∗]_ + 2˜s, (54)
_∥_ _−_ _∥_ _≤_

21/2
_φλ(β)_ _φλ(β[∗])_ 2[,] (55)
_−_ _≤_ _ρ_ _ξ_

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_

_λj_ 8 [ _Ln(β[∗])]j_ _,_ (56)
_≥_ _∇_

_then ∥β −_ **_β[∗]∥2 ≤_** mina≥0 max 21 + [17]4 _[a,][ 21]a_ [+][ 17]4 _∥ρλ−S−∗_ _∥ξ2_ _[≤]_ [15][/]ρ[2]−[∥][λ]−[S]ξ[∗] _[∥][2]_ _._
nq o

_Proof. By the restricted strong convexity of Lλ in Lemma B.1,_


_ρ_ _ξ_
_−2−_ _∥β −_ **_β[∗]∥2[2]_**

_Lλ(β)_ _Lλ(β[∗])_ _Lλ(β[∗])[⊤](β_ **_β[∗])_**
_≤_ _−_ _−∇_ _−_

= φλ(β) _φλ(β[∗]) + (_ **_β[∗]_** **_λ,1_** **_β_** **_λ,1)_** _Lλ(β[∗])[⊤](β_ **_β[∗])_**
_−_ _∥_ _∥_ _−∥_ _∥_ _−∇_ _−_

21/2

2 [+ (][∥][β][∗][∥][λ][,][1] _Lλ(β[∗])[⊤](β_ **_β[∗])_** _._

_≤_ _ρ_ _ξ_ _[−∥][β][∥][λ][,][1][)]_ _−∇_ _−_

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_ (i) (ii)

For the term (i), | {z } | {z }


(57)


**_β[∗]_** **_λ,1_** **_β_** **_λ,1 =_** **_βS[∗]_** _[∗]_ _[∥][λ]S[∗]_ _[,][1]_ _S[∗]_ _[,][1]_ [+ (][∥][β]S[∗] _[∗]_ _[∥][λ]S[∗]_ _[,][1][ −∥][β][S][∗]_ _[∥][λ]S[∗]_ _[,][1][)]_
_∥_ _∥_ _−∥_ _∥_ _∥_ _[−∥][β][S][∗]_ _[∥][λ]_

= ∥βS[∗] _[∗]_ _[∥][λ]S[∗]_ _[,][1]_ _[−∥][β][S][∗]_ _[∥][λ]S[∗]_ _[,][1]_ _[−∥][β]S[∗]_ _[∥][λ]S∗_ _[,][1]_
_≤∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 −∥βS∗_ _∥λS∗_ _,1_
= ∥(β − **_β[∗])S∗_** _∥λS∗_ _,1 −∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1._

For the term (ii),

_Lλ(β[∗])[⊤](β_ **_β[∗]) =_** _Ln(β[∗])[⊤](β_ **_β[∗])_** _Qλ(β[∗])[⊤](β_ **_β[∗])_**
_−∇_ _−_ _−∇_ _−_ _−∇_ _−_

(By Eq. 56)
_≤_ [1]8 _[∥][β][ −]_ **_[β][∗][∥][λ][,][1][ −∇][Q][λ][(][β][∗][)][⊤][(][β][ −]_** **_[β][∗][)]_**

(since qλ[′] _j_ [(0) = 0][)][ = 1] _S[∗]_ [)][⊤][(][β][ −] **_[β][∗][)][S][∗]_**

8 _[∥][β][ −]_ **_[β][∗][∥][λ][,][1][ −∇][Q][λ][(][β][∗]_**

(since _qλ[′]_ _j_ [(][β][)] _λj)_
_≤_ _≤_ 8[1] _[∥][β][ −]_ **_[β][∗][∥][λ][,][1][ +][ ∥][(][β][ −]_** **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1]_

= [9]8 _[∥][(][β][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][ + 1]8_ _[∥][(][β][ −]_ **_[β][∗][)][S]∗_** _∥λS∗_ _,1._


-----

Combining the upper bounds of term (i) and term (ii) with Eq. 57, we have

**_β_** **_β[∗]_** 2
_∥_ _−_ _∥[2]_

21 17 7
_≤_ (ρ _ξ)[2][ ∥][λ][S][∗]_ _[∥]2[2]_ [+] 4(ρ _ξ)_ _[∥][(][β][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][ −]_ 4(ρ _ξ)_ _[∥][(][β][ −]_ **_[β][∗][)][S]∗_** _∥λS∗_ _,1,_ (58)

_−_ _−_ _−_ _−_ _−_ _−_

1 21

2 [+ 17] _._

_≤_ _ρ_ _ξ_ _ρ_ _ξ_ 4

_−_ _−_  _−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_ _[∥][(][β][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1]_

Let a 0 be a constant. If (β **_β[∗])S∗_** **_λS∗_** _,1_ _ρ_ _a_ _ξ_ _[∥][λ][S][∗]_ _[∥]2[2][, then]_
_≥_ _∥_ _−_ _∥_ _≤_ _−−_


21 + [17]

4 _[a]_ _[∥]ρ[λ][S][∗]_ _[∥]ξ [2]_ _[.]_

_−_ _−_


**_β_** **_β[∗]_** 2
_∥_ _−_ _∥_ _≤_


If (β **_β[∗])S[∗]_** **_λS∗_** _,1 >_ _ρ_ _a_ _ξ_ _[∥][λ][S][∗]_ _[∥]2[2][, then]_
_∥_ _−_ _∥_ _−−_

1 21 21 **_λS∗_** 2
_∥β −_ **_β[∗]∥2[2]_** _[≤]_ _ρ−_ _−_ _ξ_  _a_ [+ 17]4  _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_  _a_ [+ 17]4  ∥ρ− _−∥ξ_ _[∥][(][β][ −]_ **_[β][∗][)][∥][2][,]_**

which implies ∥β − **_β[∗]∥2 ≤_** 21a [+][ 17]4 _∥ρλ−S−∗_ _∥ξ2_ [. Combining the two cases, we know that]
  

**_λS∗_** 2

**_β_** **_β[∗]_** 2 min 21 + [17] _∥_ _∥_
_∥_ _−_ _∥_ _≤_ _a≥0_ [max] (r 4 _[a,][ 21]a_ [+ 17]4 ) _ρ−_ _−_ _ξ [.]_


Taking a = 7 it is easy to derive that

**_β_** **_β[∗]_** 2 _._
_∥_ _−_ _∥_ _≤_ [15][/]ρ[2][∥][λ][S]ξ[∗] _[∥][2]_

_−_ _−_

**Lemma G.4 (Retain in the restricted space). Assume Assumption G.1. Let β[0], · · ·, β[k]** _be a se-_
_quence of vectors obtained by the following update:_

**_β[k]_** = MPG(β[k][−][1]; λ, w, α)


_with a step sizes α in [αmin,_


1

_ρ+_ []][. Assume the following conditions:]


(β[0])S∗ 0 _s,˜_
_∥_ _∥_ _≤_

21/2
_φλ(β[0])_ _φλ(β[∗])_ 2[,]
_−_ _≤_ _ρ_ _ξ_

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_

_λj_ 8 [ _Ln(β[∗])]j_
_≥_ _∇_

2[! ] 2

121 _ρ+_ **_λS∗_** 2

_∥_ _∥_ _s,˜_

_αmin(ρ−_ _−_ _ξ) [+ 144]_  _ρ−_ _−_ _ξ_   min(λS∗ )  _≤_

_where κ :=_ _ρ_ _ρ+_ _ξ_ _[. Then for all][ k][ = 1][,][ · · ·][, K][,]_

_−−_


(β[k])S∗ 0 _s,˜_
_∥_ _∥_ _≤_


_and_


21/2
_φλ(β[k])_ _φλ(β[∗])_ 2[.]
_−_ _≤_ _ρ_ _ξ_

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_

_Proof. Recall that β[k]_ = _αλ_ ¯β[k][] where
_T_

**_β¯[k]_** = β[k][−] [1] _α_ _Lλ(β[k][−][1])_
_−_ _∇_

= β[k][−][1] _α_ _Lλ(β[∗]) + α_ _Lλ(β[∗])_ _Lλ(β[k][−][1])_
_−_ _∇_ _∇_ _−∇_
 


-----

To show (β[k])S∗ 0 _s, we need to prove that, for j_ _S[∗], the number of j’s such that_ **_β[¯]j[k]_**
is no more than ˜s. Note that[≤] [˜] _∈_ _|_ _[|][ > αλ][j]_

**_β[¯]j[k]_** _j_ + α _Lλ(β[∗])_ _Lλ(β[k][−][1])_ _j_ + α [ _Ln(β[∗])]j_
_|_ _[| ≤|][β][k][−][1]|_ _∇_ _−∇_ _∇_
  

_≤|βj[k][−][1]| + α_ _∇Lλ(β[∗]) −∇Lλ(β[k][−][1])_ _j_ + [1]8 _[·][ αλ][j][.]_
  

Therefore, ∀c ∈ [0, 1],

(β[k])S∗ 0 _[≤]_ [Card] {j ∈ _S[∗]_ : |βj[k][−][1]| > c [7]8 _[αλ][j][}]_ (59)

+ Card _{j ∈_ _S[∗]_ : _∇Lλ(β[∗]) −∇Lλ(β[k][−][1])_ _j_ _> (1 −_ _c) ·_ [7]8 _[λ][j][}]_ _,_ (60)
 
  

where Card () represents the size of the set. For the term in Eq. 59,


**_βj[k][−][1]_**
_|_

_c_ [7]8 _[αλ][j]_


**_βj[k][−][1]_**
_|_

_λj_


Card _{j ∈_ _S[∗]_ : |βj[k][−][1]| > c 8[7] _[αλ][j][}]_



_c · 7α_


_j∈S[∗]_


_j∈S[∗]_


8
_≤_ _c_ 7α min(λS∗ )[2][ ∥][(][β][k][−][1][)][S][∗] _[∥][λ][S][∗]_ _[,][1]_

_·_

8
=

_c_ 7α min(λS∗ )[2][ ∥][(][β][k][−][1][ −] **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1]_
_·_

**Bounding** (β[k][−][1] **_β[∗])S∗_** 1. Following the derivation of Eq. 58, we can obtain
_∥_ _−_ _∥_

(ρ− _−_ _ξ)∥β[k][−][1]_ _−_ **_β[∗]∥2[2]_**

21
_≤_ (ρ _ξ)_ _[∥][λ][S][∗]_ _[∥]2[2]_ [+ 17]4 4 _[∥][(][β][k][−][1][ −]_ **_[β][∗][)][S]∗_** _∥λS∗_ _,1,_

_−_ _−_ _[∥][(][β][k][−][1][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][ −]_ [7]


which implies

12
_∥(β[k][−][1]_ _−_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ _ρ_ _ξ_ 2 [+ 17]7

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_ _[∥][(][β][k][−][1][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][.]_

Let a 0 be a constant. If (β[k][−][1] **_β[∗])S∗_** **_λS∗_** _,1_ _ρ_ _a_ _ξ_ _[∥][λ][S][∗]_ _[∥]2[2][, then]_
_≥_ _∥_ _−_ _∥_ _≤_ _−−_

_∥(β[k][−][1]_ _−_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ 12 + [17]7[a] _∥ρλS∗_ _∥ξ 22_ _[.]_
  _−_ _−_

If (β[k][−][1] **_β[∗])S∗_** **_λS∗_** _,1 >_ _ρ_ _a_ _ξ_ _[∥][λ][S][∗]_ _[∥]2[2][, then]_
_∥_ _−_ _∥_ _−−_

12
_∥(β[k][−][1]_ _−_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ _a_ [+ 17]7 _∥(β[k][−][1]_ _−_ **_β[∗])S∗_** _∥λS∗_ _,1_
 

12

**_λS∗_** 2 (β[k][−][1] **_β[∗])_** 2

_≤_ _a_ [+ 17]7 _∥_ _∥_ _∥_ _−_ _∥_
 

(Lemma G.3) 12 _∥λS∗_ _∥22_
_≤_ [15]2 _a_ [+ 17]7 _ρ_ _ξ [.]_

  _−_ _−_

Combining the above two cases yields


12

_a_ [+ 17]7




**_λS∗_** 22
_∥_ _∥_

_ρ_ _ξ_

 _−_ _−_


_∥(β[k][−][1]_ _−_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ mina≥0 [max] 12 + [17]7[a] _[,][ 15]2_

423 **_λS∗_** 22

_∥_ _∥_

_≤_ 14 _ρ_ _ξ [,]_
  _−_ _−_


-----

where the last inequality is obtained by taking a = 25534 [. Therefore, the term in Eq.][ 59][ can be]

bounded by

Card {j ∈ _S[∗]_ : |βj[k][−][1]| > c [7]8 _[αλ][j][}]_ _≤_ 8∥(βc ·[k] 7[−]α[1] min(− **_β[∗])λSS∗∗∥)λ[2]S∗_** _,1_

1692 **_λS∗_** 22

_∥_ _∥_

_≤_  49cα min(λS∗ )[2]  _ρ−_ _−_ _ξ_

2

1692 **_λS∗_** 2)

_∥_ _∥_ _._

_≤_ 49cα(ρ− _−_ _ξ)_  min(λS∗ ) 

Now we bound the term in Eq. 60 as follows. Denote the set as S[′] := _{j_ _∈_ _S[∗]_ :
_Lλ(β[∗])_ _Lλ(β[k][−][1])_ _j_ _> (1_ _c)_ 8[7] _[λ][j][}][ and its size as][ s][′][ :=][ |][S][′][|][. Then]_
_∇_ _−∇_ _−_ _·_
  

_s[′]_ = Card _j ∈_ _S[∗]_ : _∇Lλ(β[∗]) −∇Lλ(β[k][−][1])_ _j_ _> (1 −_ _c) ·_ [7]8 _[λ][j]_
 
  

1 _Lλ(β[∗])_ _Lλ(β[k][−][1])_ _j_

_∇_ _−∇_

_≤_ (1 _c)_ [7]8 _j_ _S[′]_   _λj_ 

_−_ _·_ X∈

1 _Lλ(β[∗])_ _Lλ(β[k][−][1])_ _j_

_∇_ _−∇_

_≤_ (1 _c)_ [7]8 _j_ _S[′]_   min(λS∗ ) 

_−_ _·_ X∈

1 _√s[′]_
_≤_ (1 _c)_ [7]8 min(λS∗ ) _∇Lλ(β[∗]) −∇Lλ(β[k][−][1])_ 2

_−_ _·_

1 _√s[′]_
_≤_ (1 _c)_ [7]8 min(λS∗ ) [(][ρ][+][)][∥][β][∗] _[−]_ **_[β][k][−][1][∥][2][.]_**

_−_ _·_

The last inequality holds because Lλ is (ρ+)-smooth in the restricted subspace by Lemma B.1.
Applying Lemma G.3, we have

64(ρ+)[2]
_s[′]_ _≤_ 49(1 _c)[2]_ min(λS∗ )[2][ ∥][β][∗] _[−]_ **_[β][k][−][1][∥]2[2]_**

_−_

2 2 2

64(ρ+)[2] 15/2 **_λS∗_** 2 3600 _ρ+_ **_λS∗_** 2

_∥_ _∥_ _∥_ _∥_ _._

_≤_ 49(1 − _c)[2]_ min(λS∗ )[2]  _ρ−_ _−_ _ξ_  _≤_ 49(1 − _c)[2]_  _ρ−_ _−_ _ξ_   min(λS∗ ) 

Combining the above bounds for the terms in Eq. 59 and Eq. 60, we have

2[! ] 2

1692 1 3600 _ρ+_ **_λS∗_** 2

(β[k])S∗ 0 _[≤]_ _c∈[min](0,1)_  49cα  _ρ−_ _−_ _ξ_ [+] 49(1 − _c)[2]_  _ρ−_ _−_ _ξ_   ∥min(λ∥S∗ ) 

2[! ] 2

121 _ρ+_ **_λS∗_** 2

_∥_ _∥_

_≤_ _αmin(ρ−_ _−_ _ξ) [+ 144]_  _ρ−_ _−_ _ξ_   min(λS∗ ) 

_≤_ _s˜_

The second last inequality is obtained by taking c = 7[5] [.]


Finally, if we can show φλ(β[k]) _φλ(β[∗])_ _ρ21/2ξ_ _[∥][λ][S][∗]_ _[∥]2[2][, then we can show by math induction]_
_−_ _≤_ _−−_

that (β[k])S∗ 0 _s for all k._

_[≤]_ [˜]

Taking z = β[k][−][1] in Eq. 53, we have

_φλ(β[k]) ≤_ _φλ(β[k][−][1]) −_ [2][ 1]s _[−]2_ _[ρ][+]_ **_β[k]_** _−_ **_β[k][−][1]_** 2 _[≤]_ _[φ][λ][(][β][k][−][1][)][.]_

Therefore,

[2]

21/2
_φλ(β[k])_ _φλ(β[∗])_ _φλ(β[k][−][1])_ _φλ(β[∗])_ 2[.]
_−_ _≤_ _−_ _≤_ _ρ_ _ξ_

_−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_


-----

**Lemma G.5 (Statistical error). Assume Assumption G.1. If**

_ωλ(β)_ _ϵ,_ _with ϵ_ 1/2,
_≤_ _≤_
**_β_** **_β[∗]_** 0 _s[∗]_ + 2˜s,
_∥_ _−_ _∥_ _≤_
_λj_ 8 [Ln(β[∗])]j _,_
_≥_ _|_ _|_

_then the following relations hold true._


_ϵ +_ [17]8 **_λS∗_** 2 21/8

**_β_** **_β[∗]_** 2 _∥_ _∥_
_∥_ _−_ _∥_ _≤_   _ρ−−_ _ξ_ _≤_ _ρ−_ _−_ _ξ_ _[∥][λ][S][∗]_ _[∥][2][,]_

_φλ(β)_ _φλ(β[∗])_ _∥λS∗_ _∥2[2]_ 21/2 2[.]
_−_ _≤_ [3][ϵ][(]7[ϵ]/[ + 17]8 _ϵ[/][8)]_ _ρ_ _ξ_ _ρ_ _ξ_

_−_ _−_ _−_ _[≤]_ _−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_

_φλ(β)_ _φλ(βλ)_ _ϵ_ 3 (ϵ + 17/8) + 51/7 _∥λS∗_ _∥22_ 29/2 2[.]
_−_ _≤_ 7/8 _ϵ_ _ρ_ _ξ_ _ρ_ _ξ_

[b]  _−_  _−_ _−_ _[≤]_ _−_ _−_ _[∥][λ][S][∗]_ _[∥][2]_

_Proof. Since_ **_β_** **_β[∗]_** 0 _s[∗]_ + 2˜s, then by the RSC and RSS in Lemma B.1,
_∥_ _−_ _∥_ _≤_

(ρ− _−_ _ξ)∥β[∗]_ _−_ **_β∥2[2]_** _[≤]_ [(][β][ −] **_[β][∗][)][⊤][∇][L][λ][(][β][)][ −]_** [(][β][ −] **_[β][∗][)][⊤][∇][L][λ][(][β][∗][)][.]_** (61)

Let ξ ∈ _∂∥β∥1 be the subgradient that attains the minimum in ωλ(β). Adding and subtracting_
(β − **_β[∗])[⊤](λ ◦_** **_ξ) to the right-hand side of Eq. 61 yields_**

(ρ− _−_ _ξ)∥β[∗]_ _−_ **_β∥2[2]_** _[≤]_ [(][β][ −] **_[β][∗][)][⊤][(][∇][L][λ][(][β][) +][ λ][ ◦]_** **_[ξ][)]_** _−_ (β − **_β[∗])[⊤]∇Lλ(β[∗])_**
(i) (ii)
| (β **_β[∗])[⊤]({zλ_** **_ξ)_** _._ } | {z }

_−_ _−_ _◦_
(iii)

Now we bound the terms (i)-(iii). | {z }

**Bound (i) using ωλ(β). Since ξ attains the minimum in ωλ(β), by definition,**

(β **_β′)⊤_**

_ωλ(β) = max_ _−_ ( _Lλ(β) + λξ)_ _._
**_β[′]∈Ω_**  _∥β −_ **_β[′]∥λ,1_** _∇_ 

Therefore,


(i) = (β **_β[∗])[⊤](_** _Lλ(β) + λξ)_ _ωλ(β)_ **_β_** **_β[∗]_** **_λ,1_** _ϵ_ **_β_** **_β[∗]_** **_λ,1._**
_−_ _∇_ _≤_ _∥_ _−_ _∥_ _≤_ _∥_ _−_ _∥_

**Bound (ii). Note that Lλ = Ln + Qλ. Thus,**

(ii) = (β **_β[∗])[⊤]_** _Ln(β[∗]) + (β_ **_β[∗])[⊤]_** _Qλ(β[∗])_
_|_ _|_ _−_ _∇_ _−_ _∇_

(β **_β[∗])[⊤]_** _Ln(β[∗])_ + (β **_β[∗])[⊤]_** _Qλ(β[∗])_
_≤_ _−_ _∇_ _−_ _∇_

Since λj 8 [Ln(β[∗])]j, we have
_≥_ _|_ _|_

(β **_β[∗])[⊤]_** _Ln(β[∗])_
_|_ _−_ _∇_ _| ≤_ [1]8 _[∥][β][ −]_ **_[β][∗][∥][λ][,][1][.]_**


Since qλ[′] _j_ [(0) = 0][ and][ q]λ[′] _j_ [(][β][)][ ≤] _[λ][j][ (Assumption][ B.1][), it holds true that]_


_|(β −_ **_β[∗])[⊤]∇Qλ(β[∗])| = |(β −_** **_β[∗])[⊤]S[∗]_** [(][∇][Q][λ][(][β][∗][))][S][∗] _[|]_
(β **_β[∗])S∗_** **_λS∗_** _,1._
_≤∥_ _−_ _∥_


Therefore,


(ii)
_|_ _| ≤_ [1]8 _[∥][β][ −]_ **_[β][∗][∥][λ][,][1][ +][ ∥][(][β][ −]_** **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][.]_

**Bound (iii) by the definition of subgradient.**

(iii) = (β − **_β[∗])[⊤](λ ◦_** **_ξ)_**
= **_λS∗_** (β **_β[∗])S∗_** _, ξS∗_ + **_λS∗_** (β **_β[∗])S∗_** _, ξS∗_ _._
_⟨_ _◦_ _−_ _⟩_ _⟨_ _◦_ _−_ _⟩_


-----

By Holder’s inequality and the fact **_ξ_** 1,
_∥_ _∥∞_ _≤_

**_λS∗_** (β **_β[∗])S∗_** _, ξS∗_ (β **_β[∗])S∗_** **_λS∗_** _,1._
_⟨_ _◦_ _−_ _⟩≥−∥_ _−_ _∥_

Since ξ ∈ _∂∥β∥1 and that βS[∗]_ _[∗]_ [=][ 0][,]

_⟨λS∗_ _◦_ (β − **_β[∗])S∗_** _, ξS∗_ _⟩_ = ⟨λS∗ _◦_ **_βS∗_** _, ξS∗_ _⟩_ = ∥βS∗ _∥λS∗_ _,1 = ∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1._ (62)

Combining the above three equations, it holds true that

(iii) ≥−∥(β − **_β[∗])S∗_** _∥λS∗_ _,1 + ∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1._

**Combine (i)-(iii). Combining the bounds for (i)-(iii), it holds true that**


(ρ− _−_ _ξ)∥β[∗]_ _−_ **_β∥2[2]_**

_≤_ _ϵ + 8 [1]_ [+ 1 + 1] _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 −_ 1 − _ϵ −_ 8[1] _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1_
   

7

= _ϵ + [17]8_ _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 −_ 8 _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1_ (63)
   _[−]_ _[ϵ]_

_≥0_

_≤_ _ϵ + [17]8_ _∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1._ | {z }
 

Using the fact that (β **_β[∗])S∗_** **_λS∗_** _,1_ **_λS∗_** 2 (β **_β[∗])S∗_** 2, it implies the first conclusion:
_∥_ _−_ _∥_ _≤∥_ _∥_ _∥_ _−_ _∥_

_ϵ +_ [17]8 **_λS∗_** 2

**_β[∗]_** **_β_** 2 _∥_ _∥_ _._ (64)
_∥_ _−_ _∥_ _≤_   _ρ−−_ _ξ_

Now we prove the objective value. Since Lλ is convex on β, β[∗] and ∥·∥1 is convex,

_φλ(β[∗])_ _φλ(β) + (β[∗]_ **_β)[⊤](_** _Lλ(β) + λ_ **_ξ),_**
_≥_ _−_ _∇_ _◦_

which implies

_φλ(β)_ _φλ(β[∗])_ (β **_β[∗])[⊤](_** _Lλ(β) + λ_ **_ξ)_**
_−_ _≤_ _−_ _∇_ _◦_
**_β_** **_β[∗]_** **_λ,1ωλ(β)_** _ϵ_ **_β_** **_β[∗]_** **_λ,1_** (65)
_≤∥_ _−_ _∥_ _≤_ _∥_ _−_ _∥_

Now we bound the norm ∥β − **_β[∗]∥λ,1 as follows. By triangle inequality,_**

_∥β −_ **_β[∗]∥λ,1 ≤∥(β −_** **_β[∗])S∗_** _∥λS∗_ _,1 + ∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1._ (66)

To bound ∥(β − **_β[∗])S∗_** _∥λS∗_ _,1, moving the term ∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 in Eq. 63 to the left hand side_
yields


(7/8 − _ϵ)∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ (ϵ + 17/8)∥(β − **_β[∗])S∗_** _∥λS∗_ _,1,_


which implies


_∥(β −_ **_β[∗])S∗_** _∥λS∗_ _,1 ≤_ _[ϵ]7[ + 17]/8_ _[/]ϵ[8]_ (67)

_−_ _[∥][(][β][ −]_ **_[β][∗][)][S][∗]_** _[∥][λ][S][∗]_ _[,][1][.]_

Plugging it into Eq. 66, we have


**_β_** **_β[∗]_** **_λ,1_** 1 + _[ϵ][ + 17][/][8]_
_∥_ _−_ _∥_ _≤_ 7/8 _ϵ_
 _−_


(β **_β[∗])S∗_** **_λS∗_** _,1_
_∥_ _−_ _∥_ _≤_


**_λS∗_** 2 **_β_** **_β[∗]_** 2
_∥_ _∥_ _∥_ _−_ _∥_


7/8 − _ϵ_


_ϵ +_ [17]8



[17]8 **_λS∗_** 2

_∥_ _∥_

_ρ_ _ξ_
_−−_


(by Eq. 64) ≤


**_λS∗_** 2
_∥_ _∥_


_S∗_ 2

_≤_ 7/8 _ϵ_ _∥_ _∥_ _ρ_ _ξ_

_−_ _−_ _−_

**_λS∗_** 2

= [3(][ϵ][ + 17][/][8)] _∥_ _∥[2]_ (68)

7/8 _ϵ_ _ρ_ _ξ [.]_
_−_ _−_ _−_

Combining it with Eq. 65, we have


_φλ(β)_ _φλ(β[∗])_ _∥λS∗_ _∥2[2]_
_−_ _≤_ [3][ϵ][(]7[ϵ]/[ + 17]8 _ϵ[/][8)]_ _ρ_ _ξ [.]_

_−_ _−_ _−_


-----

convex on the restricted space, thenFinally, we derive the bound for the term φλ(β) − _φλ(βλ). Since ∥β −_ **_β[b]λ∥0 ≤_** _s[∗]_ + 2˜s and φλ is

[b]

_φλ(β)_ _φλ(βλ)_ ( _Lλ(β) + λ_ **_ξ)[⊤](β_** **_βλ)_**
_−_ _≤_ _∇_ _◦_ _−_ [b]

_ωλ(β)_ **_β_** **_βλ_** **_λ,1_**
_≤_ _∥_ _−[b]_ [b] _∥_

_≤_ _ϵ_ _∥β −_ **_β[∗]∥λ,1 + ∥β[∗]_** _−_ **_β[b]λ∥λ,1_**

(by Eq. 68) _ϵ_  3(ϵ + 17/8) _∥λS∗_ _∥2[2]_ βλ **_λ,1_** _._ (69)
_≤_ 7/8 _ϵ_ _ρ_ _ξ_ [+][ ∥][β][∗] _[−]_ [b] _∥_
 _−_ _−_ _−_ 

Now we only need to bound the term **_β[∗]_** **_βλ_** **_λ,1. We can derive its bound following the same_**
_∥_ _−_ [b] _∥_
steps as we derive Eq. 68 and using the fact that ωλ(βλ) = 0, which will imply that

**_βλ_** **_β[∗]_** 1 _∥[b]λS∗_ _∥2[2]_ 2 _._
_∥_ [b] _−_ _∥_ _≤_ [3 (0 + 17]7/8 0[/][8)] _ρ_ _ξ_ [= 51][/]ρ[7][∥][λ][S]ξ[∗] _[∥][2]_

_−_ _−_ _−_ _−_ _−_

Plugging it into Eq. 69, we have

_φλ(β)_ _φλ(βλ)_
_−_

_ϵ_ 3 (ϵ + 17/8) + 51/7 _∥λS∗_ _∥22_
_≤_ 7/8 [b] _ϵ_ _ρ_ _ξ [.]_
 _−_  _−_ _−_


Assuming ϵ ≤ 1/2, then

_φλ(β)_ _φλ(βλ)_ 2 _._
_−_ _≤_ [29][/]ρ[2][∥][λ][S]ξ[∗] _[∥][2]_

_−_ _−_

[b]

**Lemma G.6 (Optimality when λ decreases). Assume Assumption G.1. If**


_ωλt−1_ (β) ≤ _ϵt−1,_ (70)

**_λt = η_** **_λt_** 1 _with_ _ηj_ [0.9, 1], (71)
_◦_ _−_ _∈_
**_β_** 0 _s,˜_ (72)
_∥_ _∥_ _≤_


_then_


_ωλt_ (β) ≤ _[ϵ][t][−][1]0[ + 0].9_ _[.][2]_

_φλt_ (β) − _φλt_ (βλt ) ≤  3 (0.9(7ϵt−/18 + 17 − _ϵt−/8)1) [+ 51][/][7] ϵt−10 + 0.9_ _.2_ _∥(ρλ−t)−S∗ξ∥2[2]_

_If ϵt_ 1 1/4, then [b]
_−_ _≤_

_ωλt_ (β) ≤ [1]2

_φλt_ (β) − _φλt_ (βλt ) ≤ [10][∥]ρ[(][λ][t][)][S]ξ[∗] _[∥]2[2]_ _._

_−_ _−_

[b]

_Proof. Recall the definition of ωλt−1_ (β).


(β **_β[′])[⊤]_**

_∥β − −β[′]∥λt−1,1_ (∇Lλt−1 (β) + λt−1ξ[′])


_ωλt−1_ (β) = **_ξ[′]∈min∂∥β∥1_** **_β[max][′]∈Ω_**


Let ξ ∈ _∂∥β∥1 be the subgradient that attains the minimum in ωλt−1_ (β). Then


(β **_β[′])[⊤]_**

_∥β − −β[′]∥λt−1,1_ (∇Lλt−1 (β) + λt−1ξ)


_ωλt−1_ (β) = maxβ[′]∈Ω


-----

Now we consider λt = η **_λt_** 1. By definition,
_◦_ _−_

(β **_β′)⊤_**

_ωλt_ (β) = **_ξ[′]∈min∂∥β∥1_** **_β[max][′]∈Ω_**  _∥β − −β[′]∥λt,1_ (∇Lλt (β) + λtξ[′])

(β **_β′)⊤_**

_≤_ **_βmax[′]∈Ω_**  _∥β − −β[′]∥λt,1_ (∇Lλt (β) + λtξ) _._

Note that

_∇Lλt_ (β) + λtξ = _∇Lλt−1_ (β) + λt−1ξ

+ (λt **_λt_** 1) **_ξ_**

  _−_ _−_ _◦_ 

+ _∇Qλt_ (β) −∇Qλt−1 (β) _,_

which implies   


(β **_β′)⊤_**

_ωλt_ (β) ≤ **_βmax[′]∈Ω_**  _∥β − −β[′]∥λt,1_ _∇Lλt−1_ (β) + λt−1ξ

  []

(i)
| (β **_β′)⊤_** {z }

+ maxβ[′]∈Ω  _∥β − −β[′]∥λt,1_ (λt − **_λt−1) ◦_** **_ξ_**

(ii)
| (β **_β′)⊤_** {z }

+ maxβ[′]∈Ω  _∥β − −β[′]∥λt,1_ _∇Qλt_ (β) −∇Qλt−1 (β) _._

  []

(iii)

Using the fact that ∥β − **_β[′]∥λt,1 ≥|_** 0.9∥β − **_β[′]∥λt−1,1, term (i) can be bounded as follows.{z_** }

(β **_β[′])[⊤]_**

(i) ≤ 0[1].9 _∥β − −β[′]∥λt−1,1_ _∇Lλt−1_ (β) + λt−1ξ _≤_ 0[1].9 _[ω][λ][t][−][1]_ [(][β][)][ ≤] _[ϵ]0[t][−].9[1]_ _[.]_

  

1 1
Using the fact |ξj| ≤ 1 and the fact that [λt−1 − **_λt]j =_** _ηj_ _[−]_ [1] [λt]j ≤ 0.9 _[−]_ [1] [λt]j, term (ii)

can be bounded as follows.     

(ii) _d_ **_βj −_** **_βj[′]_** 1 [λt]j = 1 = [1]
_≤_ _j=1_ _∥β −_ **_β[′]∥λt,1_**  0.9 _[−]_ [1] _[∥]∥[β]β[ −] −_ **_[β]β[′][′][∥]∥[λ]λ[t]t[,],[1]1_**  0.9 _[−]_ [1] 0.9 _[−]_ [1][.]

X

Term (iii) is bounded similarly as term (ii). Since _qλj_ (β) − _qλ[′]j_ [(][β][)] _≤_ _λj −_ _λ[′]j_, we have

(iii) _d_ **_βj −_** **_βj[′]_** [λt 1 **_λt]j_** _d_ **_βj −_** **_βj[′]_** 1 [λt]j = [1]
_≤_ _j=1_ _∥β −_ **_β[′]∥λt,1_** _−_ _−_ _≤_ _j=1_ _∥β −_ **_β[′]∥λt,1_**  0.9 _[−]_ [1] 0.9 _[−]_ [1][.]

X X


Combining the bounds for (i)-(iii), we have

_ωλt_ (β) ≤ _[ϵ][t][−]0[1].[ + 2]9_ _−_ 2 = _[ϵ][t][−][1]0[ + 0].9_ _[.][2]_


The first part of the proof is finished. Now we bound the term φλt (β) _φλt_ (βλt ). Since **_β_**
_−_ _∥_ _−_
**_βλ∥0 ≤_** _s[∗]_ + 2˜s and φλ is convex on the restricted space, then

[b]
b _φλt_ (β) _φλt_ (βλt )

_−_

( _Lλt_ (β) + λt **_ξ)[⊤](β_** **_βλt_** )
_≤_ _∇_ [b] _◦_ _−_ [b]

_ωλt_ (β) **_β_** **_βλt_** **_λt,1_**
_≤_ _∥_ _−_ [b] _∥_

**_β_** **_β[∗]_** **_λt,1 +_** **_β[∗]_** **_βλt_** **_λt,1_** (73)

_≤_ _[ϵ][t][−][1]0[ + 0].9_ _[.][2]_ _∥_ _−_ _∥_ _∥_ _−_ [b] _∥_

 


-----

Following the same way we derive Eq. 67, we can obtain that


_∥(β −_ **_β[∗])S∗_** _∥(λt)S∗_ _,1 ≤_ _[ϵ]7[t][−]/8[1][ + 17]ϵt_ _[/]1[8]_ _∥(β −_ **_β[∗])S∗_** _∥(λt)S∗_ _,1._

_−_ _−_

_∥β −_ **_β[∗]∥λt,1 = ∥(β −_** **_β[∗])S∗_** _∥(λt)S∗_ _,1 + ∥(β −_ **_β[∗])S∗_** _∥(λt)S∗_ _,1_ (74)


Therefore,


3
_≤_ 7/8 − _ϵt−1_ _∥(β −_ **_β[∗])S∗_** _∥(λt)S∗_ _,1_

**_β_** **_β[∗]_** 2

_≤_ [3]7[∥]/[(]8[λ] −[t][)][S]ϵt[∗]−[∥]1[2] _∥_ _−_ _∥_

(By Lemma G.5) _ϵt−1 +_ [17]8 _∥(λt−1)S∗_ _∥2_
_≤_ [3]7[∥]/[(]8[λ][t][)][S]ϵt[∗] _[∥]1[2]_ _ρ_ _ξ_

_−_ _−_   _−_ _−_

(λt)S∗ 2

= [3 (][ϵ][t][−][1][ + 17][/][8)] _∥_ _∥[2]_ _._ (75)

0.9(7/8 − _ϵt−1)_ _ρ−_ _−_ _ξ_

Using the same arguments for the term ∥β[∗] _−_ **_β[b]λt_** _∥λt,1 and using the fact that ωλt_ (βλt ) ≤ 0 · λt,
we obtain that

(λt)S[∗] 2 2 [b]

_∥β[b]λt −_ **_β[∗]∥1 ≤_** [3 (0 + 17]7/8 − 0[/][8)] _∥_ _ρ−_ _−_ _ξ∥[2]_ = [51][/][7]ρ[∥]−[(][λ]−[t][)]ξ[S][∗] _[∥][2]_ _._

Combining this inequality with Eq. 73 and Eq. 75, we have


_φλt_ (β) _φλt_ (βλt )
_−_

3 (ϵt−1 + 17/8) _ϵt−1 + 0.2_ _∥(λt)S∗_ _∥2[2]_ _._
_≤_  0.9(7/8 −[b]ϵt−1) [+ 51][/][7] 0.9 _ρ−_ _−_ _ξ_

Assuming ϵt−1 ≤ 1/4, then

_φλt_ (β) − _φλt_ (βλt ) ≤ [10][∥]ρ[(][λ][t][)][S]ξ[∗] _[∥]2[2]_ _._

_−_ _−_

[b]

**Lemma G.7 (Coercivity of the gradient). [Lemma 3.11 in Bubeck (2014)] Let f be a-strongly convex**
_b-smooth and on B ⊆_ R[d]. Then for all β, β[′] _∈B, one has_

_ab_ 1
_f_ (β) _f_ (β[′]), β **_β_** 2 [+] 2 _[.]_
_⟨∇_ _−∇_ _−_ _⟩≥_ _a + b_ _[∥][β][ −]_ **_[β][′][∥][2]_** _a + b_ _[∥∇][f]_ [(][β][)][ −∇][f] [(][β][′][)][∥][2]


-----

H DETAILS OF SECTION 5: EXTENSION TO UNSUPERVISED
LEARNING-TO-LEARN SETTING

In addition to the assumptions in the supervised setting, in this unsupervised setting, we assume
for each estimation problem, both Ln1 (Z1:n1 ) and Ln2 (Z1:n2 ) satisfy condition (b) and (c) in Assumption C.1. Similar to the supervised setting, the generalization error of the optimizer θU[∗] [can be]
bounded by


_m_

2

_Lgen(P(P); θU[∗]_ [)][ ≤] [E](Z1:n,β[∗])∼P(P) _[∥][β][T]_ [(][Z][1:][n]1 [;][ θ]U[∗] [)][ −] **_[β][∗][∥][2]2_** _[−]_ _m[1]_ _i=1_ **_βT (Z1:[(][i]n[)]_** 1 [;][ θ]U[∗] [)][ −] **_[β][∗][(][i][)]_** 2

X

generalization gap: Theorem 4.1

(76)

| {z }

_m_

+ [1] **_βT (Z1:[(][i]n[)]_** 1 [;][ θ]U[∗] [)][ −] **_[β][∗][(][i][)]_** 2 _._ (77)

_m_ 2

_i=1_

X

supervised training error
| {z }

However, in the unsupervised setting, the minimizer θU[∗] [only guarantees that unsupervised training]

loss function _m[1]_ _mi=1_ _[L][n][2]_ _Z1:[(][i]n[)]_ 2 _[,][ β][T][ (][Z]1:[(][i]n[)]_ 1 [;][ θ]U[∗] [)] is small. It requires further derivations to show

that the corresponding supervised training loss in Eq.  77 is small, too.
P

Therefore, in the following, we bridge the gap between the supervised training loss and the unsupervised training loss. Based on the proof of Theorem D.1, we know that ∥βT (Z1:[(][i]n[)] 1 [;][ θ]U[∗] [)][|]S[∗] _[∥][0][ ≤]_ _s[˜]._
Therefore, we can apply the restricted strong convexity of Ln2 to obtain the following inequality for
**_βT = βT (Z1:[(][i]n[)]_** 1 [;][ θ]U[∗] [)][,][ β][∗] [=][ β][∗][(][i][)][, and][ Z][ =][ Z]1:[(][i]n[)] 2 [for each][ i][ = 1][,][ · · ·][, m][.]


**_βT_** **_β[∗]_** 2 _Ln2 (Z, βT )_ _Ln2 (Z, β[∗]) +_ _Ln2 (Z, β[∗])[⊤]_ (β[∗] **_βT )_**
_∥_ _−_ _∥[2]_ _[≤]_ _ρ[2]−_ _−_ _∇_ _−_

 

(Ln2 (Z, βT ) _Ln2 (Z, β[∗]) +_ _Ln2 (Z, β[∗])_ 2 (β[∗] **_βT )_** 2)

_≤_ _ρ[2]_ _−_ _∥∇_ _∥_ _∥_ _−_ _∥_

_−_

**_βT_** **_β[∗]_** 2 (Ln2 (Z, βT ) _Ln2 (Z, β[∗])) + [16]_ _Ln2 (Z, β[∗])_ 2
_⇒∥_ _−_ _∥[2]_ _[≤]_ _ρ[4]−_ _−_ _ρ[2]−_ _∥∇_ _∥[2]_

Aggregating this inequality for i = 1, · · ·, m, we can obtain the following inequality that bounds
the supervised training loss using the unsupervised loss.


_m_ _m_

1 2 16

**_βT (Z1:[(][i]n[)]_** 1 [;][ θ]U[∗] [)][ −] **_[β][∗][(][i][)]_** _Ln2_ (Z1:[(][i]n[)] 2 _[,][ β][∗][(][i][)][)][∥]2[2]_

_m_ 2 _ρ[2]_ _∥∇_

_i=1_ _[≤]_ _−[m]_ _i=1_

X X

statistical error

_m_

4

| {z }

+ _Ln2_ (Z1:[(][i]n[)] 2 _[,][ β][T][ (][Z]1:[(][i]n[)]_ 1 [;][ θ]U[∗] [))][ −] _[L][n]2_ [(][Z]1:[(][i]n[)] 2 _[,][ β][∗][(][i][)][)]_

_ρ_ _m_
_−_ _i=1_

X  

unsupervised training error

The right-hand-side of this inequality consists of a statistical error and the unsupervised training| {z }
error. Finally, to characterize how small the unsupervised training error can be, we can combine the
following inequality (by restricted strongly smooth) with the result of Theorem 3.1.


_Ln2 (Z1:n2_ _, βT (Z1:n1_ ; θU[∗] [))][ −] _[L][n]2_ [(][Z][1:][n]2 _[,][ β][∗][)]_
_≤_ _Ln2 (Z1:n2_ _, βT (Z1:n1_ ; θ[∗])) − _Ln2 (Z1:n2_ _, β[∗])_

_≤∥∇βLn2_ (Z1:n2 _, β[∗])∥2 ∥βT (Z1:n1_ ; θ[∗]) − **_β[∗]∥2_**
bounded by Theorem 3.1
| {z }


+ _[ρ]2[+]_ 2

_[∥][β][T][ (][Z][1:][n][1]_ [;][ θ][∗][)][ −] **_[β][∗][∥][2]_**
bounded by Theorem 3.1
| {z }


(78)


-----

Overall, the generalization error can be bounded by

_Lgen(P(P); θU[∗]_ [)]

_m_

2

_≤_ E(Z1:n,β∗)∼P(P) ∥βT (Z1:n1 ; θU[∗] [)][ −] **_[β][∗][∥][2]2_** _[−]_ _m[1]_ _i=1_ **_βT (Z1:[(][i]n[)]_** 1 [;][ θ]U[∗] [)][ −] **_[β][∗][(][i][)]_** 2 _∗_

X

generalization gap: Theorem 4.1
| _m_ {z }

4
+ _ρ−m_ _i=1_ ∥∇βLn2 (Z1:[(][i]n[)] 2 _[,][ β][∗][(][i][)][)][∥][2]_ _∥βT (Z1:[(][i]n[)]_ 1 [;][ θ][∗][)][ −] **_[β][∗][(][i][)][∥][2]_** + _[ρ]2[+]_ _[∥][β][T][ (][Z]1:[(][i]n[)]_ 1 [;][ θ][∗][)][ −] **_[β][∗][(][i][)][∥]2[2]_**

X statistical error bounded by Theorem 3.1 bounded by Theorem 3.1



_m_ 

16 | {z } | {z } | {z }
+ _Ln2_ (Z1:[(][i]n[)] 2 _[,][ β][∗][(][i][)][)][∥]2[2]_ _._

_ρ[2]_ _∥∇_
_−[m]_ _i=1_

X

statistical error
| {z }


-----

I DETAILS OF SYNTHETIC EXPERIMENTS

I.1 A GENTLE REVIEW OF LINEAR REGRESSION AND PRECISION ESTIMATION

I.1.1 SPARSE LINEAR REGRESSION

A sparse linear regression model reads

_y = x[⊤]β[∗]_ + ϵ

where β[∗] is a sparse vector and ϵ is Gaussian noise. Given n observations Z1:n :=
(x1, y1), _, (xn, yn)_, the goal is to estimate the vector β[∗].
_{_ _· · ·_ _}_

In our method, we use the the least-square error to define the empirical loss function.


_Ln(Z1:n, β) = [1]_

2n

I.1.2 SPARSE PRECISION ESTIMATION


**_x[⊤]j_** **_[β][ −]_** _[y][j]_


_j=1_


The sparse precision matrix estimation problem in Gaussian graphical models assumes the observation of n samples from a distribution N (0, Σ). Given the n samples, X1:n := {x1, · · ·, xn} from
_N_ (0, Σ), the goal is to estimate the precision matrix Θ[∗] := Σ[−][1] which is the inverse covariance
matrix. This precision matrix represents the conditional independency among random variables.

A commonly used objective for estimating the precision matrix is the ℓ1-penalized log determinant
divergence:

log det(Θ) + Θ, Σ[ˆ] _n_ + λ Θ 1
_−_ _⟨_ _⟩_ _∥_ _∥_

where Σ[ˆ] _n is the sample covariance matrix. In our method, we use the likelihood term as the empiri-_
cal loss.

_Ln(X1:n, Θ) =_ log det(Θ) + Θ, Σ[ˆ] _n_
_−_ _⟨_ _⟩_

I.2 DATA PREPARATION

For the sparse linear recovery problem, we follow the setting in Wang et al. (2014). We create the
synthetic data by sampling a set of estimation problems {((X [(][i][)], Y [(][i][)]), β[∗][(][i][)])}. In each problem,
the design matrix X [(][i][)] _∈_ R[n][×][d] contains n = 64 independent realizations of a random vector
**x ∈** R[p] with p = 256, 1024 in easy or difficult setting, respectively. x follows a zero mean Gaussian
distribution with covariance matrix (Σ)i,j = 0.9 1 _i=j_ + 1 1 _i=j_ . The true parameter vector
_·_ _{_ _̸_ _}_ _·_ _{_ _}_
**_β[∗][(][i][)]_** has a sparsity s[∗] = ∥β[∗][(][i][)]∥0 = 16 and its nonzero entries take values uniformly sampled
from ( 2, 2 [)][ ∪] [(][ 1]2 _[,][ 2)][. The support set of each][ β][∗][(][i][)][ is independently sampled from a union]_
_−_ _−_ [1]

support set S, with |S| = 128 to allow some similarity among the problems. The observation Y [(][i][)] is
sampled such that Y [(][i][)] _−_ _X_ [(][i][)]β[∗][(][i][)] is a n-dimensional Gaussian random vector with zero mean and
covariance matrix In. In all the experiments, 2000 such problems are used for training, 200 such
problems are used for validation, and 100 such problems are used for test.

In sparse precision matrix estimation problem, we follow the setting in Guillot et al. (2012). We
create the synthetic data by sampling a set of estimation problems {(Σ[ˆ] [(]n[i][)][,][ Θ][(][i][)][)][}][. In each problem,]
the ground truth precision matrix is generated in the following ways: the lower diagonal part (lower
triangular parting, exluding diagonal) of true precision matrix Θ has a sparsity s[∗], that are uniformly
selected from a union support with size S. After selecting the nonzero entries, we assign them values
uniformly from (−2, − [1]2 [)][ ∪] [(][ 1]2 _[,][ 2)][ and let the upper diagonal part has the same value as lower di-]_

agonal part. Finally, a multiple of the identity was added to the resulting matrix so that the smallest
eigenvalue was equal to 1. In this way, Θ was insured to be sparse, positive definite, and wellconditioned. After the precision matrix is generated, we generate the observational samples for each
precision matrix, by generating n independent samples of the random vector x ∼N (0, (Θ[(][i][)])[−][1]).
ance matrixThe samples are denoted byΣ[ˆ] [(]n[i][)] [=][ 1]n _ni=1 X[(][X][(][(][i][i][)][)][)]∈[T][ X]R[n][(][i][×][)][.][d]. Using the samples, we can compute the sample covari-_

P


-----

In all the experiments, 2000 such problems are used for training, 200 such problems are used for validation, and 100 such problems are used for test. We use (n, S, s[∗]) = (100, 375, 75), (200, 600, 150)
for d = 50, 200, respectively.

I.3 BASELINE IMPLEMENTATION

**ALISTA: We follow the implementation in Liu et al. (2019a).**

**RNN: The RNN is designed following Andrychowicz et al. (2016). Initialize the β0 as 0. At every**
step, we compute the gradient _βL(βt) w.r.t. to objective as the input to a LSTM with hidden_
_∇_
dimension equals to 128. Then we use the output of the LSTM as the increment:

_βt+1 = βt + LSTM(∇βL(βt))_ (79)

We repeat this iteration 20 steps and use β20 as our final output.

**RNN-ℓ1: RNN-ℓ1 use the same architecture as RNN. The only difference is we add an extra learn-**
able parameter λt for soft thresholding at each step:

_βt+1 = βt + LSTM(∇βL(βt))_ (80)
_βt+1 = ηλt_ (βt+1) (81)

where the softthresholding ηλ is an elementwise operator maps ηλ(x) = 0 is |x| < λ and ηλ(x) =
sign(x)(|x| − _λ)._

**[GLASSO: we use the implementation in the sklearn package.](https://scikit-learn.org/stable/auto_examples/covariance/plot_sparse_cov.html#sphx-glr-auto-examples-covariance-plot-sparse-cov-py)**

**GGM: We follow the implementation in Belilovsky et al. (2017).**

**APF: We follow the implementation in Wang et al. (2014). The specific algorithm steps are sum-**
marized in Algorithm 3.

**Algorithm 3: The Approximate Path Following Method**
**Input: λtgt > 0, ϵopt > 0 (Here we assume ϵopt ≪** _λtgt/4), η ∈_ [0.9, 1)

**1 Initialize** _β[˜]0_ **0, L0** _Lmin, λ0 =_ (0) _, N_ (λ0/λtgt)/ log(η[−][1]).

**2 for t = 1, ..., N ←** _−_ 1 do ← _∥∇L_ _∥∞_ _←_

**3** _λt_ _η[t]λ0_

**4** _ϵt_ _←_ _λt/4_
_←_

**5** _{β[˜]t, Lt} ←_ Proximal-Gradient(λt, ϵt, _β[˜]t−1, Lt−1, R) as in Algorithm 4._

**6 end**

**87 ϵ λNN ← ←** _ϵλopttgt_

**9 {β[˜]N** _, LN_ _} ←_ Proximal-Gradient(λN _, ϵN_ _,_ _β[˜]N_ _−1, LN_ _−1, R)._

**10 return {β[˜]t}t[N]=1[.]**


**Algorithm 4: The Proximal Gradient Method**

**1 InitializeInput: λ kt > ← 0, ϵ0.t > 0, βt[0]** _[∈]_ [R][p][, L]t[0] _[>][ 0]_

**2 repeat**

**3** _k ←_ _k + 1_

**4** _Linit_ max _Lmin, L[k]t_ _[−][1]/2_
_←_ _{_ _}_

**65 untilβ ωt[k][, L]λt** (t[k]β[←]t[k][)][ ≤][Line-Search][ϵ][t] _[as defined in Equation][(][λ][t][, β]t[k][−][1], Linit)[ 82] as in Algorithm[;]_ 5.

**7** _β[˜]t_ _βt[k]_
_←_

**8 Lt** _L[k]t_
_←_

**9 return** _βt, Lt_ .
_{_ [˜] _}_


-----

**Algorithm 5: The Line Search Method**


**Input: λt > 0, βt[k][−][1]** R[d], Linit > 0, R > 0
_∈_

**1 repeat**

**2** **_βt[k]_** _L[k],λt_ **_βt[k][−][1]_** as defined in Equation 83

**3** **if φλ[←T]t** **_βt[k]_** _> ψ _ _Lkt_ _[,λ][t]_ **_βt[k][;][ β]t[k][−][1]_** **then**

**4** _L[k]t_ _t_ [.]

     

**5** **end** _[←]_ _[L][k]_

**6 until φλt** (βt[k][)][ ≤] _[ψ]L[k]t_ _[,λ][t]_ [(][β]t[k][, β]t[k][−][1]) as defined in Equations 84 and 85;

**7** _β[˜]t_ _βt[k]_
_←_

**8 Lt** _L[k]t_
_←_

**9 return** _βt, Lt_ .
_{_ [˜] _}_

(β **_β[′])[T]_**

_ωλ(β) =_ min _−_ _λ(β) + λξ[′][)]_ (82)
**_ξ[′]∈∂∥β∥1_** **_β[max][′]∈Ω_** ( _∥β −_ **_β[′]∥1_** ∇L[e]

0 if _β¯j_ _λt/L[k]t_

_TLkt_ _[,λ][t]_ **_βt[k][−][1]_** _j_ [=] sign _β¯j_ _β¯j_ _λt/L[k]t_ if _β¯j_ _≤ > λt/L[k]t_ (83)
   []  _−_

_φλ(β) = _   λ(β) + λ **_β_** 1  (84)
_L[e]_ _∥_ _∥_

_T_ _t_
_ψLkt_ _[,λ][t]_ **_β; βt[k][−][1]_** = L **_βt[k][−][1]_** + ∇L **_βt[k][−][1]_** **_β −_** **_βt[k][−][1]_** + _[L]2[k]_ **_β −_** **_βt[k][−][1]_** 2 [+][ P][λ][t] [(][β][)][ (85)]
           

[2]

I.4 TRAINING AND EVALUATION

We trained the learning-based methods to minimize the weighted loss. That’s to say, for each sparse
linear recovery problem, given the sequence of outputs (β1, ..., βT ), the loss is computed as:


_γ[T][ −][i]_ **_βi_** **_β[∗]_** 2 (86)
_i=1_ _∥_ _−_ _∥[2]_

X


_L =_


where γ decreasing from 0.9 to 0.1 during the training process. The procedure is similar in the
sparse precision matrix estimation problem. We use optimizer Adam (Kingma & Ba, 2014). For
sparse linear recovery problem, we use batch size 10, we train 500 epochs with learning rate 1e4 and select the model based on the l2 loss on valid data. For sparse precision matrix estimation
problem, we use batch size 40, we train 200 epochs with learning rate 1e-3 and select the model
based on Frobenius loss on valid data.

For classical algorithms, we select their parameters, λ for APF and ρ for GISTA, based on their
performance on the validation set. Specifically, we evaluate APF or GISTA with ρ or λ from
_{0.01, 0.025, 0.05, 0.1, 0.2} and use one with the best recovery error in test._


Table 3: Training time for SLR (minutes)


Table 4: Training time for SPE (minutes)

|Sizes|d = 256 d = 1024|
|---|---|

|Sizes|d = 50 d = 100|
|---|---|

|PLISA ALISTA RNN RNN ℓ1 APF|393 462 176 271 96 99 101 106 214 426|
|---|---|

|PLISA GGM GISTA APF GLASSO|35 39 14 43 176 116 316 331 42 57|
|---|---|


We report the total training time for learning based methods as well as the parameter tuning time for
classical algorithms. From Table 3 and Table 4, we can see that training a learning-based method is


-----

cheap in our experiments, as 1) A single forward for PLISA or GGM is very fast as stated in Table 1.
2) We can easily parallel the computations to handle a batch of problems during the training time,
as the learning-based methods do not require line-search.

The evaluation is performed on a server with CPU: Intel(R) Xeon(R) Silver 4116 CPU @ 2.10GHz,
GPU: Nvidia GTX 2080TI, Memory 264G, in single thread.

I.5 ABLATION STUDY

Table 5:is the true positive rate of recovering the nonzero en- Ablation study of PLISA (p = 1024). TPR 30 plisaplisa_l1 30
tries of β[∗]. FPS is the cardinality of false positive 25 plisa_single 25
entries. Note that the true sparsity level is s[∗] = 20 20
16. Standard deviations over 100 test problems are 15 15

|Col1|plisa|
|---|---|
||plisa_l1|
||plisa_single|
|||
|||
|||
|||
|||
|||


dim=256 dim=1024

30 plisaplisa_l1 30

25 plisa_single 25

20 20

15 15

l2-error

10 10

5 5

0 0

# iterations # iterations


Figure 6: Ablation study.

|present in the parantheses.|Col2|Col3|Col4|
|---|---|---|---|
|PLISA PLISA-single PLISA-ℓ 1||||
|ℓ error 2 TPR FPS|1.34 (2.28) 0.99 (0.01) 16.65 (13.60)|18.25 (6.06) 0.62 (0.19) 51.07 (6.67)|2.20 (2.76) 0.99 (0.02) 25.11 (13.30)|



We consider two variants of PLISA to perform the ablation study. One is PLISA-single which
employs a single regularization parameter across different entries, i.e., η1 = · · · = ηd and λ[∗]1 [=]

_· · · = λ[∗]d[. The other is][ PLISA][-][ℓ][1][ which does not learn the penalty function but uses the][ ℓ][1][ norm,]_
i.e., Pw(λ, β) = **_λ_** **_β_** 1. Fig. 6 and Table 5 show the vanilla PLISA performs better than
_∥_ _◦_ _∥_
alternatives. Especially, it has a much better accuracy than PLISA-single. Therefore, this ablation
study has validated the effectiveness of using entry-wise regularization parameters and learning the
penalty function.

I.6 REAL-WORLD EXPERIMENTS

We use the following 3 real-world datasets.

(1) Gene - a single-cell gene expression dataset that contains expression levels of 45 transcription
factors measured at different time-points. We follow Ollier & Viallon (2017) to pick the transcription
factor, EGR2, as the response variable and the other 44 factors as the covariates. In this dataset, each
time-point is considered as an estimation problem. In each estimation problem, the goal is learning
the regression weights β[∗] on the 44 factors to predict the expression level of the target transcription
factor, EGR2. Therefore, in this problem, p = 44. This dataset contains the gene expression data for
120 single cells at 8 different time points. For each time point, we randomly split the 120 samples
into 6 sets, so that each set contains 20 samples. By doing this, we construct 48 estimation problems
each of which contains 20 samples. 10 samples are used for recovering the parameters β[∗] and the
other 10 samples are used for evaluate it by computing the least-square error. We use 36 problems
for training, 6 problems for validation, and 6 problems for testing.

(2) Parkinsons - a disease dataset that contains symptom scores of Parkinson for different patients.
Each patient is considered as an estimation problem. In each estimation problem, the goal is learning
the regression weights β[∗] on 19 bio-medical features to predict the symptom score. This dataset
contains 42 patients, so there are 42 estimation problems in total. Each patient is examined at
different time-point and each time a sample is generated. For each patient we randomly select 100
samples, so that eventually our dataset contains 42 estimation problems each of which contains 100
samples. 50 are used for recovering the parameter β[∗] and 50 are used for evaluation. We use 28
problems for training, 7 problems for validation, and 7 problems for testing.

(3) School - an examination score dataset of students from 139 secondary schools in London. Each
school is considered as an estimation problem. In each estimation problem, the goal is learning the
regression weights β[∗] on 28-dimensional school and student features to present the exam scores
for all students. We use the dataset from Malsar package (Zhou et al., 2011). For each school, we
randomly select 40 students as the samples. Since some schools contain less than 40 students, we
finally obtain 125 estimation problems (schools) each of wich contains 40 samples. 20 are used for


-----

recovering the parameter β[∗] and 20 are used for evaluation. We use 100 problems for training, 10
problems for validation, and 15 problems for testing.

On each dataset, we train each learning-based algorithm for 200 epochs using Adam with learning
rata 1e-3. The batch size is set to be 6.


-----


# ON INVARIANCE PENALTIES FOR RISK MINIMIZATION

ABSTRACT

The Invariant Risk Minimization (IRM) principle was first proposed by Arjovsky
et al. (2019) to address the domain generalization problem by leveraging data heterogeneity from differing experimental conditions. Specifically, IRM seeks to find
a data representation under which an optimal classifier remains invariant across
all domains. Despite the conceptual appeal of IRM, the effectiveness of the originally proposed invariance penalty has recently been brought into question through
stylized experiments and counterexamples. In this work, we investigate the relationship between the data representation, invariance penalty, and risk. In doing so,
we propose a novel invariance penalty, and utilize it to design an adaptive rule for
tuning the coefficient of the penalty proposed by Arjovsky et al. (2019). Moreover, we provide practical insights on how to avoid the potential failure of IRM
considered in the nascent counterexamples. Finally, we conduct numerical experiments on both synthetic and real-world data sets with the objective of building
invariant predictors. In our non-synthetic experiments, we sought to build a predictor of human health status using a collection of data sets from various studies
which investigate the relationship between human gut microbiome and a particular disease. We substantiate the effectiveness of our proposed approach on these
data sets and thus further facilitate the adoption of the IRM principle in other
real-world applications.

1 INTRODUCTION

Under the learning paradigm of Empirical Risk Minimization (ERM) (Vapnik, 1992), data is assumed to consist of independent and identically distributed (iid) samples from an underlying generating distribution. As the data generating distribution is often unknown in practice, ERM seeks
predictors with minimal average training error (i.e., empirical risk) over the training set. However,
shuffling and treating data as iid risks possibly losing important information about the underlying
conditions of the data generating process. Despite becoming a ubiquitous paradigm in machine
learning, a growing body of literature (Arjovsky et al., 2019; Teney et al., 2020) has revealed that
ERM and the the common practice of shuffling data inadvertently results in capturing all correlations
found in the training data, whether spurious or causal, and produces models that fail to generalize
to test data. The potential variation of experimental conditions that can exist at training time and
during deployment in real-world applications, manifests in discrepancies between training and testing distributions. This, in turn, highlights the need for machine learning algorithms to generalize
_out-of-distribution (OoD)._

Shuffling and treating data as iid risks possibly losing important information about the underlying
conditions of the data generating process. As will be demonstrated in this work, partitioning training
data into environments, e.g., based on the conditions under which data is generated, can exploit these
differences to enhance generalization. One promising approach based on this observation is that of
Arjovsky et al. (2019), in which the principle of Invariant Risk Minimization (IRM) is introduced.
The objective of IRM is to find a predictor that is invariant across all training environments (see
Definition 1 and Equation 1). Because of the conceptually appealing nature of IRM and its potential
to address the OoD-generalization problem, there is a stream of literature scrutinizing various facets
of the original framework, e.g., extensions to other settings including online learning (Javed et al.,
2020) and treatment effect estimation (Shi et al., 2020), fairness (Adragna et al., 2020), introducing game-theoretic interpretations (Ahuja et al., 2020), and raising concerns on the drawbacks and
limitations of current IRM implementations (Rosenfeld et al., 2021; Kamath et al., 2021). For an indepth overview of the broader generalization literature, we refer the interested reader to (Arjovsky,
2020) and the references therein, and for an empirical evaluation of the performance of a number
of the state-of-the-art methods on various test cases, we refer the reader to (Gulrajani & Lopez-Paz,
2020).


-----

In this paper, we introduce two practical implementations of the IRM principal to increase its appeal and applicability in real-world settings. First, we propose an invariance penalty that is directly
related to risk. More precisely, we show that the risk in each environment under an arbitrary classifier equals to the risk under the optimal classifier for that environment plus the newly proposed
invariance penalty between the said classifier and the optimal one. Second, we build on these initial findings to provide practitioners who currently use the original IRMv1 implementation with an
adaptive rule by which to choose the penalty coefficient appropriately. In doing so, we characterize the difference between our proposed invariance penalty and the one proposed by Arjovsky et al.
(2019) in terms of the eigenvalues of the Gram matrix of the data representation. This eigenstructure
plays a significant role in the failure of invariance penalties including the one proposed by Arjovsky
et al. (2019).

In addition to providing practitioners with two valid approaches for implementing IRM, this work
serves to illustrate the importance of the eigenstructure of the Gram matrix of the data representation
for IRM. In particular, we revisit the counterexample of Rosenfeld et al. (2021) where the invariance
penalty of Arjovsky et al. (2019) can be made arbitrarily small for a non-invariant representation.
We show that the Gram matrix is ill-conditioned in such cases. We then provide a practical solution
to alleviate such behavior, in particular for the case where the representation is parameterized by a
neural network. Moreover, we show that the proposed framework finds an invariant predictor for
the setting in which the data is generated according to a linear Structural Equation Model (SEM)
when provided a sufficient number of training environments under a mild non-degeneracy condition,
which is similar in nature to the ones considered in (Arjovsky et al., 2019; Rosenfeld et al., 2021).
Finally, we evaluate our method on various test cases including InvarianceUnitTests (Aubin et al.,
2020) and HealthyGutTests. InvarianceUnitTests is a test bed with three synthetically generated data
sets capturing different structures of spurious correlations. HealthyGutTests is a curated collection
of biomedical data sets based on a prior meta-analysis of various microbiome studies (Gupta et al.,
2020) in which the relationships between human gut microbiome composition and various disease
phenotypes can be investigated.

The remainder of the paper is organized as follows. In Section 2, we formally define the notion
of invariant prediction, the invariant risk minimization principle, and its relaxation proposed by
Arjovsky et al. (2019). In Sections 3 and 4, we introduce our more practical implementation and the
rationale for its design. In Section 5, we evaluate the efficacy of our proposed model and compare it
with other variations of IRM over a series of experiments. We conclude the paper in Section 6. All
mathematical proofs are presented in the Appendix.

2 BACKGROUND: INVARIANT PREDICTION

In this paper, we consider data (X _[e], Y_ _[e]) collected from multiple training environments e_ tr
_∈E_
where the distribution of (X _[i], Y_ _[i]) and (X_ _[j], Y_ _[j]) may be different for i_ = j with i, j tr. We
_̸_ _∈E_
denote byℓ : Y × Y → Re the risk under environmentR, the risk under environment e e. That is, for predictor is defined as Re(f ) = f E :X X →Ye,Y e [ℓ(f, and loss function(X _[e]), Y_ _[e])]._

2.1 INVARIANT RISK MINIMIZATION

Arjovsky et al. (2019) define the notion of invariant predictors under a multi-environment setting as
follows.

**Definition 1 (Invariant Predictor). A data representation φ : X →H is said to elicit an invariant**
predictor w ◦ _φ across environments E if there exists a classifier w : H →Y, which is optimal for_
all environments, i.e., w ∈ argmin ˜w:H→Y _[R][e]_ [( ˜]w ◦ _φ) for all e ∈E._

To find such invariant predictors, Arjovsky et al. (2019) introduce the notion of the Invariant Risk
Minimization (IRM) principle:

min _Re (w_ _φ)_
_φ:_ _◦_
_w:X→HH→Y_ _eX∈Etr_ (1)

subject to _w ∈_ argminw˜:H→Y _Re ( ˜w ◦_ _φ), ∀e ∈Etr._


-----

As this bi-leveled optimization problem is rather intractable, Arjovsky et al. (2019) propose a practical implementation of IRM by relaxing the invariance constraint (which itself requires solving an
optimization problem) to an invariance penalty. We review its derivation in what follows.

2.2 IRMV1: A RELAXATION OF IRM

In order to provide an implementation of IRM, Arjovsky et al. (2019) restrict the classifier w to
linear functions, i.e.,

min _Re_ _w[⊤]φ_
_φw:X→H∈R[dφ]_ _eX∈Etr_    (2)

subject to _w_ argmin _Re_ _w˜[⊤]φ_ _,_ _e_ tr.
_∈_ _w˜∈R[dφ]_ _∀_ _∈E_

To motivate their proposed penalty, Arjovsky et al. (2019) first consider the squared loss, i.e.,  
_ℓ(f_ (x), y) = _f_ (x) _y_ where denotes the Euclidean norm. Define matrix _e(φ) as_
_∥_ _−_ _∥[2]_ _∥· ∥_ _I_
_e(φ) := EX_ _e_ _φ(X_ _[e])φ(X_ _[e])[⊤][]_ _._ (3)
_I_
Assuming that _e(φ) is full rank for a fixed φ, its respective optimal classifier is unique, i.e.,_
_I_
argmin ˜w∈R[dφ][ R][e] _w˜[⊤]φ_ = we[⋆][(][φ][)][ where] []
   _we[⋆][(][φ][) :=][ I][e][(][φ][)][−][1][E][X]_ _[e][,Y][ e][ [][φ][(][X]_ _[e][)][Y][ e][]][ .]_ (4)

Hence, in this setting, the invariant constraint of IRM in equation 2 can be simplified to w = we[⋆][(][φ][)]
for all e ∈Etr. A natural relaxation of the constraint w − _we[⋆][(][φ][) = 0][ to a penalty is][ ∥][w][ −]_ _[w]e[⋆][(][φ][)][∥][2][.][1]_
However, Arjovsky et al. (2019) show that this penalty may not capture invariance by constructing
an example for which _w_ _we[⋆][(][φ][)][∥][2][ is not well-behaved (see Section 4.3 for more details). They]_
_∥_ _−_
argue that undoing the matrix inversion Ie(φ)[−][1], which appears in the computation of we[⋆][(][φ][)][ could]
improve the behavior of the invariance penalty. That is, considering _e(φ)(w_ _we[⋆][(][φ][))][∥][2][ as the]_
_∥I_ _−_
invariance penalty. Moreover, for the squared loss, one can show that

_∥Ie(φ)(w −_ _we[⋆][(][φ][))][∥][2][ = (1][/][4)]_ _∇wRe(w[⊤]φ)_ _._ (5)
Hence, Arjovsky et al. (2019) propose the following invariance penalty

[2]

_ρ[IRMv1]e_ (φ, w) := _wRe(w[⊤]φ)_ _._ (6)
_∇_
Using the penalty equation 6, the relaxation of IRM is given by

[2]

min _Re(w[⊤]φ) + λρ[IRMv1]e_ (φ, w), (7)
_φ, w_

_eX∈Etr_

where λ ≥ 0 is the penalty coefficient. Notice that for a given w and φ, the predictor w ◦ _φ can be_
expressed using different classifiers and data representations, i.e., w _◦φ = ˜w_ _◦φ˜ where ˜w = w_ _◦ψ[−][1]_
and ˜φ = ψ ◦ _φ for some invertible mapping ψ : H →H. Hence, in principle, it is possible to fix w_
without loss of generality. By relying on this observation, Arjovsky et al. (2019) fix the classifier as
a scalar w = 1, and, thus, search for an invariant data representation of the form φ ∈ R[1][×][d][x] . Their
relaxation of IRM, which they refer to by IRMv1 is given by

min _Re (φ) + λρ[IRMv1]e_ (φ, 1.0). (IRMv1)
_φ_

_eX∈Etr_

Although equation 5 only holds for squared loss, Arjovsky et al. (2019, Theorem 4) justify the choice
of ∥∇w|w=1.0Re(w[⊤]φ)∥[2] as an invariance penalty for other loss functions, e.g., cross-entropy loss.
More precisely, let Φ be the matrix that parameterizes the data representation. They show that for
all convex differentiable loss functions, (w[⊤]Φ)[⊤] _wR(w[⊤]Φ) = 0 if and only if w is optimal for all_
_∇_
environments.

Although the penalty ρ[IRMv1]e (φ, 1.0) seems to be an appropriate invariance penalty, which is easily implementable, its effectiveness to capture invariance has been brought into question. In particular, Rosenfeld et al. (2021) construct a non-invariant data representation such that the penalty
_ρ[IRMv1]e_ (φ, 1.0) is arbitrarily small. In what follows, we propose an alternative invariance penalty
that is directly comparable to risk. Hence, if the invariance penalty of a classifier is small, then so is
the difference between its risk and the risk under the optimal classifier.

1In the presence of known exogenous (environment dependent) variables, one can utilize anchor regression
Rothenh¨ausler et al. (2021) that is conceptually related to the invariance penalization. Instead of an invariance
penalty, anchor regression relies on the projection onto the span of the said variables.


-----

3 IRMV2: AN ALTERNATIVE PENALTY

We revisit the structure of the risk in order to propose an alternative penalty. In particular, in the following Lemma, we provide the sub-optimality gap of risk under an arbitrary classifier in comparison
to the optimal classifier.

**Lemma 1. Consider squared loss function. Let w ∈** R[d][φ] _and we[⋆][(][φ][)][ as defined in equation 4. Then,]_

2
_Re_ _w[⊤]φ_ = Re _we[⋆][(][φ][)][⊤][φ]_ + _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_ _._ (8)
     

Based on Lemma 1, we propose an invariance penalty that is directly comparable to risk.

2
_ρ[IRMv2]e_ (φ, w) := _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_ _._ (9)

The relaxation of IRM using the penalty equation 9 is then given by


_Re(w[⊤]φ) + λρ[IRMv2]e_ (φ, w). (10)
_eX∈Etr_


min
_φ, w_


We further simplify the relaxation equation 10 by finding its optimal classifier for a fixed data representation defined as


_Re_ _w[⊤]φ_ + λρ[IRMv2]e (φ, w). (11)
_eX∈Etr_   


_w[⋆](φ) := argminw_


In the following Lemma, we leverage on the structure of the squared loss to find w[⋆](φ).

**Lemma 2. Consider squared loss function and fix φ. Let we[⋆][(][φ][)][ and][ w][⋆][(][φ][)][ as defined in equation 4]**
_and equation 11, respectively. Then,_


_−1_

Xe∈Etr _Ie(φ)!_ Xe∈Etr _Ie(φ)we[⋆][(][φ][)]_


_w[⋆](φ) =_


(12)


_Moreover, it holds that_


_Re_ _w[⊤]φ_ = w[⋆](φ). (13)
_eX∈Etr_   


argminw


Based on Lemmas 1 and 2, we propose the following relaxation of IRM, which we refer to by
IRMv2.


_Re_ _w[⋆](φ)[⊤]φ_ + λρ[IRMv2]e (φ, w[⋆](φ)). (IRMv2)
_eX∈Etr_   


min


We provide the pseudo-code for IRMv2 in Algorithm 1 in Appendix A.

There are several comments in order. It is worth noting that Equation equation 13 in Lemma 1
reveals that for a fixed data representation, the optimal classifiers of ERM and IRMv2 are equal.
However, this equality would not imply the equality of the ERM and IRMv2 predictors (i.e., the
composition of the classifier and the data representation). The latter is due to the presence of the
invariance penalty in the optimization of φ in IRMv2 in comparison to ERM.

There are a number of factors distinguishing IRMv2 from IRMv1. First, IRMv2 relies on the optimal
classifier w[⋆](φ) while w = 1.0 in IRMv1. Second, the loss function in IRMv2 is squared loss
while IRMv1 allows for utilization of other loss functions. Although this additional flexibility of
IRMv1 may seem appealing, the counterexample of Rosenfeld et al. (2021) shows the failure of the
penalty of IRMv1 to capture invariance for logistic loss. More importantly, for squared loss, _e(φ)_
_I_
is incorporated differently in the invariance penalty of IRMv1 and IRMv2. We formalize this latter
observation in the Section 4.3.1.


-----

3.1 IRMV1A: AN ADAPTIVE PENALTY COEFFICIENT

We first bound the invariance penalty of IRMv1 in terms of the penalty of IRMv2 and the eigenvalues
of _e(φ). Then, based on this comparison, we propose an adaptive approach in choosing the penalty_
_I_
coefficient for IRMv1, which we refer to as IRMv1-Adaptive (IRMv1A).
**Lemma 3. Let ρ[IRMv1]e** (φ, w) and ρ[IRMv2]e (φ, w) be the invariance penalties of the IRMv1 and
_IRMv2 defined in Equations equation 6 and equation 9, respectively. Then,_

_λmin (_ _e(φ)) ρ[IRMv2]e_ (φ, w) _ρ[IRMv1]e_ (φ, w) _λmax (_ _e(φ)) ρ[IRMv2]e_ (φ, w). (14)
_I_ _≤_ _≤_ _I_

The proof of Lemma 3 directly follows from the definition of the invariance penalties ρ[IRMv1]e (φ, w)
and ρ[IRMv2]e (φ, w), and the fact that for a symmetric matrix A R[d][×][d] and a vector u R[d], it holds
_∈_ _∈_
that λmin(A) _u_ _u[⊤]Au_ _λmax(A)_ _u_ .
_∥_ _∥[2]_ _≤_ _≤_ _∥_ _∥[2]_

As IRMv1 is used in practice in conjunction with losses other than squared loss for classification,
in order to justify our adaptive penalty coefficient, we bound the difference of risk for cross-entropy
loss under two different classifiers in terms of the invariance penalty of IRMv2.
_thatLemma 4. Consider binary classification with cross-entropy loss. Then, for w1, w2 ∈_ R[d][φ] _it holds_

_|Re(w1[⊤][φ][)][ −]_ _[R][e][(][w]2[⊤][φ][)][| ≤]_ _Ie(φ)[1][/][2](w1 −_ _w2)_ _._

Using Lemmas 3 and 4, we suggest the following rule for the penalty coefficient of IRMv1.


1
_λe :=_ (15)

_λ0 + λmin(Ie(φ))_ _[,]_

whereλmin( λe(0φ ≥)) is small. Note that this is an adaptive rule, as0 is a user-specified parameter. The role of λ φ0 is to avoid numerical instability when may change throughout training.
_I_

4 THEORETICAL RESULTS AND ANALYSIS

In this section, we investigate the effectiveness of IRM and its practical implementations in capturing
invariance by focusing on a setting in which the data is generated according to a Structural Equation
Model (SEM) (Pearl, 2009). SEM refers to a set of equations specifying the relationship between
variables, which is a common structural assumption in causal inference. In particular, under an
SEM, variables are related through a causal graph such that each variable is only a function of its
parents and an exogenous random variable. Similar to Arjovsky et al. (2019) and Rosenfeld et al.
(2021), we establish conditions under which IRM recovers an invariant predictor for data generated
according to SEMs with linear functions. We then investigate the role of the eigenstructure of _e(φ),_
_I_
in particular, in relation to counterexamples of Arjovsky et al. (2019) and Rosenfeld et al. (2021),
and provide practical solution to alleviate the possibility of such failure modes.

4.1 SEM FOR CLASSIFICATION

For each environment e, data (X _[e], Y_ _[e]) is generated according to the following SEM:_

_X_ _[e]_ = S _Zc_ _,_ _Y_ _[e]_ = 1, with prob. η, (16)
_Ze_ 1, with prob. 1 _η, [,]_
  − _−_

where η ∈ [0, 1], and S ∈ R[d][×][(][d][e][+][d][c][)] is a left invertible matrix, i.e., there exists S[†] such that
_S[†]S = I. In this model, Zc captures the causal variables that are invariant across environments, and_
_Ze captures the spurious environment dependent variables._

The variables Zc and Ze are generated as follows


_Zc = µcY + Wc,_ _Wc ∼N_ (0, σc[2][I][)][,] (17)

_Ze = µeY + We,_ _We ∼N_ (0, σe[2][I][)][.] (18)

Here,and covariance µc ∈ R[d] Σ[c], µ. We further assume thate ∈ R[d][e], and N (µ, Σ) denotes multi-variate Gaussian distribution with mean Wc, We, and Y _[e]_ are independent for all environments. µ


-----

4.2 INVARIANT REPRESENTATION UNDER IRM

For the setting introduced in 4.1, the invariant data representation is linear. In particular, for any d ≥

_dc, φ(X_ _[e]) =_ _Idc_ **0** _S[†]X_ _[e]_ = Zc is an invariant data representation. Given that X is also linear
**0** **0**
 

in Y, the class of linear representations may be sufficiently reach to elicit an invariant predictor.
Naturally, the possibility of finding an invariant predictor depends on the number and the diversity
of training environments. We now introduce non-degeneracy conditions on training environments
under which IRM is guaranteed to find an invariant predictor, provided sufficient number of training
environments.

Let |Etr| > de. As span({µe}e∈Etr ) ≤ _de, for each e ∈Etr there exists a set of coefficients αi[e]_ [for]
_i_ tr _e such that_
_∈E_ _\_


_αi[e][µ][i][.]_ (19)
_i∈EXtr\e_


_µe =_


We say that Etr is a non-degenerate set of environments if for all e ∈Etr it holds that

_αi[e]_ (20)
_i∈EXtr\e_ _[̸][= 1][,]_

rank (Γe) = de, (21)


where Γe is defined as

1
Γe := _σe[2][I][ +][ µ][e][µ]e[⊤]_ (σi[2][I][ +][ µ][i][µ]i[⊤][)][α]i[e] _._

1 − [P]i∈Etr\e _[α]i[e]_  _[−]_ _i∈EXtr\e_ 

 

The conditions of equation 20 and equation 21 specify that the span of covariance matrices of Ze’s is
_R[d][e]. This is a natural requirement to eliminate the degrees of freedom on the dependency of the data_
representation on the environment dependent features. We note that the non-degeneracy conditions
considered in (Rosenfeld et al., 2021) are similar to the ones introduced here, with the difference
that instead of depending on covariance matrices of Ze as in equation 21, their condition relies only
on the variances σe[2][. This difference in the non-degeneracy requirements is due to the fact that they]
consider logistic loss and we consider squared loss.
**Theorem 1. Assume that |Etr| > de where (X** _[e], Y_ _[e]) generated according to equation 16. Consider_
_a linear data representation ΦX = AZc + BZe and a classifier w(Φ) on top of Φ that is invariant,_
_i.e., w(Φ) = we[⋆][(Φ)][ for all][ e][ ∈E][tr][. If non-degeneracy conditions Eqs. (19-21) holds, then either]_
_w(Φ) = 0 or B = 0._

Theorem 1 characterizes the connection between invariant predictors and the diversity of training
environments in the linear setting. Its conclusions are directly applicable to IRM and its relaxations
including IRMv1, v1A, and v2.

4.3 THE ROLE OF _e(φ)_
_I_

Recall that the main difference between the invariance penalty of IRMv1 (with squared loss) and
IRMv2 is the way that _e(φ) is incorporated. Although at a first glance this may not seem significant,_
_I_
in what follows we demonstrate the importance of _e(φ)._
_I_

4.3.1 THE POTENTIAL FAILURE OF INVARIANCE PENALIZATION

Arjovsky et al. (2019) consider a linear Structural Equation Model (SEM) of the following form.

_X1 ∼N_ (0, σ[2]), Y = X1 + Z1 with Z1 ∼N (0, σ[2]), X2 = Y + Z2 with Z2 ∼ (0, 1),

and X = [X1, X2][⊤]. The variance σ[2] is the only parameter that changes across environments,
and we assume that Z1, Z2, and X1 are independent in and across all environments. Hence, in
this setting, X1 models the invariant features and X2 models the environmental features as the
correlation between X2 and Y varies across environments.


-----

Consider the data representation φc(x) parameterized by a variable c ∈ R as

_φc(X) =_ _cXX12_ _,_
 


(22)


where c = 0 attains the invariant data representation, i.e., φ0(X) = [X1, 0][⊤]. Based on this model,
Arjovsky et al. (2019) argue that _winv_ _we[⋆][(][φ][c][)][∥][2][ is a poor choice for the invariance penalty as it]_
is discontinuous at the invariant representation with ∥ _−_ _c = 0, and vanishes as c →∞. Interestingly,_
_e(φc) is ill-conditioned for both small and large c’s. More precisely, in Appendix D.1 we show that_
_I_

lim lim
_c_ 0 _[κ][(][I][e][(][φ][c][)) =]_ _c_ +
_→_ _→_ _∞_ _[κ][(][I][e][(][φ][c][)) = +][∞][,]_

where κ(·) denotes the condition number. That is, for a normal matrix A, its condition number is
_κ(A) := |λmax(A)|/|λmin(A)| where λmax and λmin denote its maximum and minimum eigenval-_
ues, respectively.

We now examine the counterexample introduced by Rosenfeld et al. (2021), which is based on
the SEM setting introduced in Section 4.1 and equation 16. They consider the data representation
_φϵ(X_ _[e]) defined as_


_φϵ(X_ _[e]) :=_ _Zc_



1{Ze /∈Zϵ}[,] (23)


_Ze_


where {Ze /∈Zϵ} is an event with P(Ze ∈Zϵ) ≤ _pe,ϵ where pe,ϵ := exp(−de min{ϵ −_ 1, (ϵ −
1)[2]}/8). The parameter ϵ ≥ 1 control the degrees to which the environmental variable Ze appears
in the data representation by controlling the set Zϵ (see equation 40 in the Appendix). In particular,
_φϵ(X_ _[e]) converges to the invariant representation as ϵ →∞, i.e., limϵ→∞_ _φϵ(X_ _[e]) = φinv(X_ _[e]) :=_

[Zc, 0][⊤].

Rosenfeld et al. (2021) show that IRMv1’s invariance penalty ∥∇wRe(w[⊤]φ)∥[2] = O(p[2]e,ϵ[)][, and can]
be made arbitrarily small, hence it is poor discrepancy as an invariance penalty. This, together with
the fact that the training risk under φϵ is close to the risk under the invariant representation, they
argue that φϵ is a plausible representation under IRMv1. However, this observation is only true
for the case where λ is a constant. More specifically, φϵ is not a plausible solution of IRMv1 with
adaptive penalty coefficient, e.g., λ(φ) = 1/λmin( _e(φ))[2]._
_I_

4.3.2 PRACTICAL IMPLICATIONS

In both of the examples discussed in Section 4.3.1, I(φ) = E[φ(X)φ(X)[⊤]] is singular for the
invariant representation. This is due to the fact that for both of the examples, the span of data
representations φ(X) is the same as the span of inputs X while the span of the invariant features
is only a small subset of that space. As a consequence, in presence of environment dependent
variables, one should avoid utilizing data representations with codomain that is the same as the
input space. In particular, when φ is parameterized by a neural network, the common approach
of setting the size of the last layer equal to K − 1 for K-class classification, and 1 for regression


Figure 1 illustrate that the test accuracy of
IRMv1 drastically drops as we increase the dimension of the representation. However, the
test accuracy of IRMv2 gradually increases first
before dropping in a considerably overflexible
representation. It is worth noting that the condition number of I(φ) increases with dφ and
is ill-conditioned for large dφ, e.g., κ( (φ)) >
10[12] when dφ = 2048 (see Figure 2 in the Appendix). Note that in this experiment, images
are down-sampled and contain 14 × 14 pixels,
i.e., dX = 196.



problem avoids such phenomenon. We further illustrate such behavior on the Colored MNIST ex-
periment, a standard benchmark for evaluating the performance of domain generalization methods.

dcPKZM/gD5/MHE2SFA=</latexit>Test Accuracy

_dφ and_
_κ(I(φ)) >_

_daFvZWwMdWUoU2pYkPw1l/eJN2buteoe95Do9ZqFnmU4QIu4Ro8uIUW3EMbOsAgWd4hTcHnRfn3flYtZacYuYc/sD5/AFT/ZG4</latexit>_ _'_

_× 14 pixels,_ Figure 1: Effect of representation dimension on

test accuracy for IRMv1, IRMv1A, and IRMv2.


-----

5 EXPERIMENTS

In this section, we empirically evaluate the efficacy of our proposed implementations of IRM,
namely, IRMv2 and IRMv1A with IRMv1 and ERM. We demonstrate the appeal of our approach on
_InvarianceUnitTests (Aubin et al., 2020), a synthetic test bed for evaluation of OoD methods with_
multiple experiments and data sets, each of which embedding a different causal relationship. We
then evaluate each method on our curated data set HealthyGutTests to illustrate how the principle
of invariant risk minimization can be used to minimize disparities and discrepancies in biomedical
research. For completeness, we also perform numerical experiments on DomainBed, an extensive
framework released by (Gulrajani & Lopez-Paz, 2020) to test domain generalization algorithms for
image classification tasks on various benchmark data sets. Similar to Gulrajani & Lopez-Paz (2020),
we also observe that none of the domain generalization algorithms significantly outperform ERM.
We refer the reader to Appendix E for the detailed results and further discussion.

5.1 INVARIANCEUNITTESTS

In this section, we evaluate the efficacy of our proposed approaches for invariance discovery on the
_InvarianceUnitTests recently proposed by Aubin et al. (2020). These unit-tests entail three classes_
of low-dimensional linear problems, each capturing a different structure for inducing spurious correlations. The data set for each problem falls within the multi-environment setting described in
Section 2 with ne = 10[4]. For all problems, the input x[e] _∈_ R[d] is constructed as x[e] = (x[e]inv[, x]spu[e] [)]
where x[e]inv spu
To make the problems more realistic, Aubin et al. (2020) repeat each experiment and[∈] [R][d][inv][ and][ x][e] _[∈]_ [R][d][spu][ denote the invariant and the spurious features, respectively.] scramble the
inputs by multiplying x[e] by a rotation matrix. In each problem, the spurious correlations that exist
in the training environments are discarded in the test environment by random shuffling. As a basis
for comparison, similar to Aubin et al. (2020), we implement an Oracle ERM where the spurious
correlations are shuffled in the training data sets as well, and hence, ERM can readily identify them.

Table 1 illustrates the training and test errors of the various methods on linear unit test experiments.
One can observe that IRMv2 is the only method that discovered a nearly invariant predictor on
all experiments. However, on classification tasks (Example 2), all other methods except IRMv1A
attained near perfect training accuracy by relying on the spurious correlations while their test accuracy was comparable to random guessing as the spurious features were randomly shuffled in the test
set. The stability of IRMv2 in discovering invariant predictors makes it a suitable fit for real-world
applications as we will demonstrate in the following section.

|Col1|ERM IRMv1 IRMv1A IRMv2 Oracle|Col3|Col4|Col5|Col6|
|---|---|---|---|---|---|
||Training Test|Training Test|Training Test|Training Test|Training Test|
|Example1 Example1s Example2 Example2s Example3 Example3s|7.35 14.40 7.32 14.37 0.03 0.42 0.03 0.45 0.00 0.37 0.00 0.37|9.47 10.72 9.36 10.76 0.03 0.45 0.03 0.45 0.00 0.36 0.00 0.37|12.82 12.87 12.76 13.24 0.11 0.31 0.04 0.27 0.49 0.26 0.49 0.34|11.14 11.26 11.89 12.25 0.26 0.34 0.22 0.38 0.31 0.40 0.30 0.41|10.49 10.32 10.43 10.53 0.00 0.00 0.00 0.00 0.01 0.01 0.01 0.01|



Table 1: Training and Test Errors on InvarianceUnitTests for all algorithms and examples with
(dinv, dspu, denv) = (5, 5, 3). The errors for Examples 1 and 1s are in MSE and all others are classification error. The empirical mean and the standard deviation are computed using 10 independent
experiments. An ‘s’ indicates the scrambled variation of its corresponding problem setting.

5.2 HEALTHYGUTTESTS

In this section, we further evaluate the efficacy of our proposed approaches on a set of experiments
that highlight the importance of generalizability in real-world applications. An increasing number of
microbiome studies have associated various alterations in human gut microbiota composition with
both chronic and acute diseases, providing strong evidence that the gut microbiome is an essential
factor in the maintenance of human health. HealthyGutTests is a curated set of microbiomes extracted from an extensively phenotyped and standardized meta-analysis cohort (Gupta et al., 2020)
of 1770 individuals across 10 independent studies (Supplementary Table 7). Study selection was


-----

limited to case-control studies in adult populations wherein Whole-Genome Sequencing (WGS)
metagenome data of human stool (gut microbiome) and corresponding subject meta-data were publicly available. To reduce class imbalance, studies consisting of only control samples (healthy) or
those with fewer than 100 total samples were excluded.

This data set reflects the characteristics of the domain generalization problem setting, as the data
for each study is collected by different researchers, across various timepoints, locations and demographic populations. With this gut microbiome data set, we seek to illustrate a use-case in which the
IRM principle can be used to minimize the effect of spurious correlations confounding the discovery of real explanatory variables and thus build a fair and trustworthy ML model that is appropriate
for real-world deployment in a biomedical setting. We consider the task of human health status
_classification: predicting the binary label (healthy/unhealthy) associated with a sample. The data_
set falls within the multi-environment setting described in Section 2, with ne = 10 and inputs x[e]
consisting of 992 features, where each feature corresponds to a unique microbial species. When data
from multiple studies are collectively analyzed, systematic variation across different studies can give
rise to biases known as “batch-effects”. These batch effects may obscure biologically relevant and
under-represented sub-population effects in the data that are difficult to identify. When viewed in a
clinical setting, these sub-population effects may represent differential etiologies, and thus require
different treatment strategies. An ERM classifier trained on all such data (i.e. by shuffling and treating data as iid) may learn these batch effects as predictors of health status, and consequently ignore
invariant features that are indicative of under-represented subpopulation effects. We seek to build an
invariant predictor that is robust in its predictions when trained and tested on different experimental
splits across the data set’s ten studies. Table 2 illustrates the test accuracy of the various methods
on this binary classification task. One can observe that IRMv2 and IRMv1A methods demonstrate
superior performance when compared to ERM and perform as good if not better than IRMv1 across
9 out of 10 test splits.

ERM IRMv1 IRMv1A IRMv2

Feng (2015) 0.785 0.856 0.848 **0.856**
He (2017) 0.604 0.604 0.604 **0.606**
Jie (2017) 0.733 0.726 0.724 **0.734**
Karlsson (2013) 0.813 0.861 0.849 **0.866**
Le Chatelier (2013) 0.642 **0.655** 0.653 0.653
Nielsen (2014) 0.732 0.744 0.739 **0.744**
Qin (2012) 0.763 0.785 0.779 **0.795**
Vogtmann (2016) 0.692 0.696 **0.700** **0.700**
Zeller (2014) 0.775 0.755 0.768 **0.787**
Zhang (2015) 0.666 0.700 **0.701** **0.701**

Average 0.721 ± 0.064 0.738 ± 0.077 0.736 ± 0.074 **0.744 ± 0.079**

Table 2: Test Accuracy on HealthyGutTests health status classification task. Each test accuracy is
averaged over 5 independent experiments.

6 CONCLUSION

In this paper, we have presented IRMv2, an alternative implementation of the IRM principle that
aims to enable out-of-distribution generalization by finding environment invariant predictors. We
establish theoretical results on the effectiveness of our approach in the linear setting. In doing so,
we bring forward the importance of the eigenstructure of the Gramian matrix of the data representation. In particular, we show that for the existing counterexample on the potential failure of IRMv1,
the aforementioned matrix is ill-conditioned for the invariant representation. This highlights the
significance of the span of the data representations in relation to the span of the underlying true
invariant features of the data. That is, if the data representation allows for more degrees of freedom than needed to capture invariance, the Gramian matrix of the invariant representation would
be ill-conditioned. This observation provides intuition on the underlying reasons why current implementations of IRM may fail. Our work demonstrates the effectiveness of IRMv2 and IRMv1A
on both synthetic and real-world data sets. While this investigation of the IRM principle has lead
to the development of a more pragmatic solution, we leave for future work, establishing theoretical
guarantees beyond linear regimes.


-----

REPRODUCABILITY STATEMENT

We have provided detailed mathematical proofs of all of our theoretical claims in the appendices.
The data processing, neural network architecture, and the model selection for Colored MNIST,
InvarianceUnitTests, and DomainBed experiments are exactly replicated from their respective author
repositories. For HealthyGutTests experiments, we utilized the data sets curated and standardized
by domain experts Gupta et al. (2020). We discuss our additional data processing step in Section
5.2. We also provide details of the neural network architecture and the model selection in Appendix
F.

REFERENCES

Robert Adragna, Elliot Creager, David Madras, and Richard Zemel. Fairness and robustness in
invariant learning: A case study in toxicity classification. arXiv preprint arXiv:2011.06485, 2020.

Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar. Invariant risk minimization games. In Proceedings of the 37th International Conference on Machine Learning, pp.
145–155, 2020.

Martin Arjovsky. Out of Distribution Generalization in Machine Learning. PhD thesis, New York
University, 2020.

Martin Arjovsky, L´eon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
_arXiv preprint arXiv:1907.02893, 2019._

Benjamin Aubin, Martin Arjovsky, Leon Bottou, and David Lopez-Paz. Linear unit tests for invariance discovery. In Causal Discovery and Causality-Inspired Machine Learning Workshop at
_NeurIPS, 2020._

Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint
_arXiv:2007.01434, 2020._

Vinod K Gupta, Minsuk Kim, Utpal Bakshi, Kevin Y Cunningham, John M Davis, Konstantinos N
Lazaridis, Heidi Nelson, Nicholas Chia, and Jaeyun Sung. A predictive index for health status
using species-level gut microbiome profiling. Nature communications, 11(1):1–16, 2020.

Khurram Javed, Martha White, and Yoshua Bengio. Learning causal models online. arXiv preprint
_arXiv:2006.07461, 2020._

Pritish Kamath, Akilesh Tangella, Danica J Sutherland, and Nathan Srebro. Does invariant risk
minimization capture invariance? arXiv preprint arXiv:2101.01134, 2021.

Masanori Koyama and Shoichiro Yamaguchi. Out-of-distribution generalization with maximal invariant predictor. arXiv preprint arXiv:2008.01883, 2020.

David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le
Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). arXiv
_preprint arXiv:2003.00688, 2020._

Giambattista Parascandolo, Alexander Neitz, Antonio Orvieto, Luigi Gresele, and Bernhard
Sch¨olkopf. Learning explanations that are hard to vary. arXiv preprint arXiv:2009.00329, 2020.

Judea Pearl. Causality. Cambridge university press, 2009.

Elan Rosenfeld, Pradeep Kumar Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. In International Conference on Learning Representations, 2021. [URL https:](https://openreview.net/forum?id=BbNIbVPJ-42)
[//openreview.net/forum?id=BbNIbVPJ-42.](https://openreview.net/forum?id=BbNIbVPJ-42)

Dominik Rothenh¨ausler, Nicolai Meinshausen, Peter B¨uhlmann, and Jonas Peters. Anchor regression: Heterogeneous data meet causality. Journal of the Royal Statistical Society: Series B (Sta_tistical Methodology), 83(2):215–246, 2021._


-----

Claudia Shi, Victor Veitch, and David Blei. Invariant representation learning for treatment effect
estimation. arXiv preprint arXiv:2011.12379, 2020.

Damien Teney, Ehsan Abbasnejad, and Anton van den Hengel. Unshuffling data for improved
generalization. arXiv preprint arXiv:2002.11894, 2020.

Vladimir Vapnik. Principles of risk minimization for learning theory. In Advances in neural infor_mation processing systems, pp. 831–838, 1992._


-----

A IRMV2 ALGORITHM PSEUDO-CODE

**Algorithm 1 IRMv2**

1: Input: Data set: De for e ∈Etr. Loss function: Squared loss, Parameters: penalty coefficient
_λ ≥_ 0, data representation parameters θ ∈ R[d][θ], learning rate ηt, training horizon T .

2: Initialize θ1 randomly


3: for t = 1, 2, . . ., T do
4: **for e ∈Etr do**

5: compute the LSE we[⋆][(][φ][θ]t [)][ according to Eq. equation 4]

6: compute the optimal classifier w[⋆](φθt ) according to Eq. equation 12

7: _t(φθt_ ) _e_ tr _t_ [)][⊤][φ][θ]t [) +][ λρ][IRMv2]e (φθt _, w[⋆](φθt_ ))
_L_ _←_ [P] _∈E_

_[R][e][(][w][⋆][(][φ][θ]_

8: _θt+1_ _θt_ _ηt_ _θt_ _t(φθt_ )
_←_ _−_ _∇_ _L_

9: Output predictor w[⋆](φθT )[⊤]φθT .


B CONSIDERATIONS FOR PRACTICAL IMPLEMENTATION

As the data generating distributions for each environment are unknown, we provide further details on
practical implementations of IRMv2. As training is often done by gradient descent on mini-batches,
we focus on this setting. For simplicity of notation, assume that the sample size of all environments
are equal, each of which is divided into b mini-batches of size m. Then, _we[⋆]_ [the empirical estimate]
of the optimal classifier we[⋆] [is given by]

1 b

_b_ _−_ _b_

_we[⋆][(][φ][) :=]_ Φ[e]k⊤Φek Φ[e]k⊤Y ek _[,]_ (24)

_k=1_ ! _k=1_

X X

b

where Φ[e]k _i_ [)][⊤] [of the][ k][-th mini-batch of environment]
_emini-batch., and with some abuse of notation[∈]_ [R][m][×][d][φ][ is a matrix each of its row is] Yk[e] _[∈]_ [R][m][ is defined as the vector containing][ φ][(][x][e] _[ y]e[i]_ [for the same]

**Bias: Note that whether the estimator equation 24 is unbiased or not depends on the underlying data**
generating assumption. In particular, it may be natural to assume that for the underlying invariant
representation, it holds that E[Y _[e]|φinv(X_ _[e])] = winv[⊤]_ _[φ][inv][(][X]_ _[e][)][ with the error][ Y][ e][ −]_ **[E][[][Y][ e][|][φ][inv][(][X]** _[e][)]]_
being independent of X _[e]_ and Y _[e], e.g., ye[i]_ [=][ w]inv[⊤] _[φ][inv][(][x]i[e][) +][ η][i][ where][ {][η][}][n]i=1_ [is a sequence of zero-]
mean i.i.d. random variables. However, this may not hold for an arbitrary representation φ. One can
modify the estimator equation 24 to derive an unbiased estimator by using different mini-batches
for each term, e.g., by randomly dividing the mini-batches into two parts. More specifically, let B
be the set of randomly chosen mini-batches of size ⌊b/2⌋, and [b]\B be the rest of the mini-batches.
Let B be a set of such Bs. Then,

_−1_

_we[⋆][(][φ][) = 1]_ Φ[e]k⊤Φek Φ[e]k⊤Y ek (25)

 

_|B|_ _BX∈B_  Xk∈B ! _k∈X[b]\B_ 

b

The estimator equation 25 is unbiased if x[e]i [are i.i.d. and][ y]i[e] [is independent of all other] _[.]_ _[ x]j[e]_ [conditioned]
on x[e]i [.]

**Numerical Stability: Although** _k_ _B_ [Φ]k[e] _⊤Φek_ [is positive semi-definite almost surely, it is singular]

_∈_
for m|B| < dφ and may even be singular for m|B| > dφ. Hence, to improve numerical stability,
we consider the following empirical estimate of _e(φ)_

[P]

_I_


Φ[e]k⊤Φek[,]
_kX∈B_


_e,λ,B(φ) := λI +_
_Ib_


-----

where λ ≥ 0. That is, to improve the numerical stability, we consider the ℓ2 regularized least squares
estimate[2]


_wbe,B[⋆]_ [(][φ][) =][ b]Ie,λ,B(φ)[−][1]


Φ[e]k⊤Y ek _[.]_ (26)
_k∈X[b]\B_


Then,


_−1_
! Xe∈Etr


_wB[⋆]_ [(][φ][) =]


_Ibe,λ,B(φ) bwe,B[⋆]_ [(][φ][)][.]


_e,λ,B(φ)_
_Ib_


_e∈Etr_


We now provide an empirical estimate of the invariant penalty ρ[IRMv2]e . We further partition B into
_B1, B2, and B3. Then,_

_ρ[IRMv2]e_ = [1] _we,B[⋆]_ 1 [(][φ][)][ −] _w[b]B[⋆]_ 1 [(][φ][)] _⊤_ _Ie,λ,B2_ (φ) _we,B[⋆]_ 3 [(][φ][)][ −] _w[b]B[⋆]_ 3 [(][φ][)] _._

_|B|_ _BX∈B_ n     [o]

b b b b

Note that _ρ[IRMv2]e_ is an unbiased estimator of ρ[IRMv2]e for λ = 0.
b

C MATHEMATICAL PROOFS


C.1 PROOF OF LEMMA 1

First, the risk under environment e with w = we[⋆][(][φ][)][ is given by]


_Re_ _we[⋆][(][φ][)][⊤][φ]_ = EY e _∥Y_ _[e]∥[2][]_ _−_ **EX** _e,Y e [φ(X_ _[e])Y_ _[e]][⊤]_ _Ie(φ)[−][1]EX_ _e,Y e [φ(X_ _[e])Y_ _[e]] ._

Then,   

[]

_Re_ _w[⊤]φ_ _−_ _Re_ _we[⋆][(][φ][)][⊤][φ]_

= w  _[⊤]_ _e(φ)w_  2w[⊤]EX _e,Y e [φ(X_ _[e])Y_ _[e]] + EX_ _e,Y e [φ(X_ _[e])Y_ _[e]][⊤]_ _e(φ)[−][1]EX_ _e,Y e [φ(X_ _[e])Y_ _[e]]_
_I_ _−_ _I_

2
= _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_ _._

C.2 PROOF OF LEMMA 2


Recall the definition of w[⋆](φ)

_w[⋆](φ) = argminw_

That is,


_Re_ _w[⊤]φ_ + λρ[IRMv2]e (φ, w).
_eX∈Etr_   


2

_w[⋆](φ) = argminw_ **E** _w[⊤]φ(X_ _[e]) −_ _Y_ _[e]_ + λ _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_

_eX∈Etr_ h

[2][i]

= argminw (1 + λ)w[⊤]Ie(φ)w − 2w[⊤] (E [φ(X _[e])Y_ _[e]] + λIe(φ)we[⋆][(][φ][))]_

_e_ tr 

X∈E

+ we[⋆][(][φ][)][⊤][I][e][(][φ][)][w]e[⋆][(][φ][) +][ E] _∥Y_ _[e]∥[2][ ]._


2The ℓ2 regularized least squares estimate of we⋆ [is defined as]


_i=1(yi,k[e]_ _[−]_ _[w][⊤][φ][(][x]i,k[e]_ [))][2][ +][ λ][∥][w][∥][2]2[.]

X


_we[⋆][(][φ][) = argmin]w_


_k=1_


-----

Note that the objective function is a convex quadratic function of w. Hence, using the first-order
optimality condition we have that


_w[⋆](φ) −_


(E [φ(X _[e])Y_ _[e]] + λIe(φ)we[⋆][(][φ][)) = 0][.]_
_eX∈Etr_


(1 + λ)

_w[⋆](φ) =_


_e(φ)_
_I_

Xe∈Etr


Then,


_−1_

1
_w[⋆](φ) =_ _e(φ)_ (E [φ(X _[e])Y_ _[e]] + λ_ _e(φ)we[⋆][(][φ][))]_ _._

1 + λ Xe∈Etr _I_ ! Xe∈Etr _I_ !

Recall that we[⋆][(][φ][) =][ I][e][(][φ][)][−][1][ [][φ][(][X] _[e][)][Y][ e][]][. Then,][ [][φ][(][X]_ _[e][)][Y][ e][] =][ I][e][(][φ][)][w]e[⋆][(][φ][)][. Thus,]_

_−1_

_w[⋆](φ) =_ Xe∈Etr _Ie(φ)!_ Xe∈Etr _Ie(φ)we[⋆][(][φ][)]!_ _._

Finally, using a similar argument, we get

argminw _Re_ _w[⊤]φ_ = argminw **E** _w[⊤]φ(X_ _[e])_ _Y_ _[e]_

_−_

_eX∈Etr_    _eX∈Etr_ h

[2][i]

= argminw _w[⊤]_ _e(φ)w_ 2w[⊤]E [φ(X _[e])Y_ _[e]] + E_ _Y_ _[e]_

_I_ _−_ _∥_ _∥[2][]_
_eX∈Etr_ _−1_ 

= Xe∈Etr _Ie(φ)!_ Xe∈Etr _Ie(φ)we[⋆][(][φ][)]!_ _._


C.3 PROOF OF LEMMA 3

For a symmetric matrix A ∈ R[d][×][d] and a vector u ∈ R[d], it holds that λmin(A)∥u∥[2] _≤_ _u[⊤]Au ≤_
_λmax(A)∥u∥[2]. Let u = Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))][ and][ A][ =][ I][e][(][φ][)][. Then,]_

2
_∥Ie(φ) (w −_ _we[⋆][(][φ][))][∥][2][ ≤]_ _[λ][max][(][I][e][(][φ][))]_ _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_

2
_∥Ie(φ) (w −_ _we[⋆][(][φ][))][∥][2][ ≥]_ _[λ][min][(][I][e][(][φ][))]_ _Ie(φ)[1][/][2]_ (w − _we[⋆][(][φ][))]_ _._

C.4 PROOF OF LEMMA 4

Consider binary classification where Y ∈{0, 1} with binary cross-entropy loss, i.e.,

_ℓ(f_ (X), Y ) = −Y f (X) + log(1 + exp(f (X))).

Our objective is to bound the difference _R(w1[⊤][φ][)][ −]_ _[R][(][w]2[⊤][φ][)][|][ for two arbitrary classifiers][ w][1]_ [and]
_|_
_w2._

Let g(w) := log(1+exp(w[⊤]φ(X))). Then, using the multivariate mean-value theorem, there exists
_c ∈_ (0, 1) such that

_g(w2) = g(w1) + ∇g((1 −_ _c)w1 + cw2)[⊤](w2 −_ _w1)._

We have that

exp(w[⊤]φ(X))
_g(w) =_
_∇_ 1 + exp(w[⊤]φ(X)) _[φ][(][X][) =][ σ][(][w][⊤][φ][(][X][))][φ][(][X][)][,]_


where σ(·) denotes the sigmoid function. Let ¯w := (1 − _c)w1 + cw2. Then,_

_ℓ(w2[⊤][φ][(][X][)][, Y][ )][ −]_ _[ℓ][(][w]1[⊤][φ][(][X][)][, Y][ )]_

= −Y w2[⊤][φ][(][X][) + log(1 + exp(][w]2[⊤][φ][(][X][))) +][ Y w]1[⊤][φ][(][X][)][ −] [log(1 + exp(][w]1[⊤][φ][(][X][)))]

= _Y (w2_ _w1)[⊤]φ(X) + σ( ¯w[⊤]φ(X))φ(X)[⊤](w2_ _w1)_
_−_ _−_ _−_

= _Y_ _σ( ¯w[⊤]φ(X))_ (w2 _w1)[⊤]φ(X),_
_−_ _−_ _−_
  


-----

where the second equality follows from the application of mean-value theorem. Then,

_R(w1[⊤][φ][)][ −]_ _[R][(][w]2[⊤][φ][)][|][2][ =]_ **E** _Y_ _σ( ¯w[⊤]φ(X))_ (w2 _w1)[⊤]φ(X)_
_|_ _−_ _−_

2[i] 2[i]
**E**  Y _σ( ¯w[⊤]φ(X))_  **E** (w2 _w1)[⊤]φ(X)_
_≤_ _−_ _−_ [2]

(wh 2 _w1)[⊤]E_ _φ(X)φ(X)[⊤]h []_ (w2 _w1),_ 
_≤_ _−_ _−_

where the first equality follows from Cauchy-Schwarz and the second one follows from the fact that
_Y ∈{0, 1} and σ : R →_ [0, 1], hence |Y − _σ( ¯w[⊤]φ(X)| ≤_ 1 almost surely.

C.5 PROOF OF THEOREM 1

In order to prove Theorem 1, we first find the optimal classifier for a given data representation for
the linear setting in the following Lemma.


**Lemma 5. Let we[⋆][(Φ) = argmin]w** _[R][e][(][w][⊤][Φ)][ where][ R][e][(][w][⊤][Φ)][ is defined as]_

_Re(w[⊤]Φ) = E_ _tr_ _w[⊤]ΦX_ _[e]_ 11{Y =+1} _w[⊤]ΦX_ _[e]_ 11{Y =+1} _⊤[!#]_ _._

"  _−_  _{Y =−1} _ _−_  _{Y =−1}_

_Then,_

_we[⋆][(Φ) = [][ηβ]e[⋆][(Φ)]_ (1 − _η)βe[⋆][(Φ)]][,]_

_where_

1
_βe[⋆][(Φ) =]_ Σ¯ _[−]e_ [1]µ[¯]e. (27)

1 + ¯µ[⊤]e Σ[¯] _[−]e_ [1]µ[¯]e

_Here,_ Σ[¯] _e and ¯µe are defined as_


Σ¯ _e := ΦS_ _σc[2][I]_ 0
0 _σe[2][I]_


_µ¯e := ΦS_ _µc_ _._
_µe_
 


_S[⊤]Φ[⊤],_


_Proof of Lemma 5: We have that_

_we[⋆][(Φ) =][ I][e][(Φ)][−][1][E][X]_ _[e][,Y][ e]_ ΦX _[e][ ˜]Y_ _[e][⊤][i]_ _._
h

First, we have that

_Zc_ 1 _Y = 1_ _⊤[#]_

**EX** _e,Y e_ ΦX _[e][ ˜]Y_ _[e][⊤][i]_ = ΦSEX _e,Y e_ _Ze_ 1 _{Y =_ 1}
h "   _{_ _−_ _}_

= ΦS _ηµc_ (1 − _η)µc_
_ηµe_ (1 _η)µe_
 _−_ 

= [ηµ¯e (1 _η)¯µe] ._
_−_

Thus,

_we[⋆][(Φ) = [][ηβ]e[⋆][(Φ)]_ (1 − _η)βe[⋆][(Φ)]][,]_ (28)

where

_βe[⋆][(Φ) =][ I][e][(Φ)][−][1]µ[¯]e._ (29)

We now compute _e(Φ)[−][1]_ in terms of Σ[¯] _[−]e_ [1] and ¯µe. We have that
_I_

_Zc_ _Zc_ _⊤[#]_

_Ie(Φ) = EX_ _e_ ΦX _[e]X_ _[e][⊤]Φ[⊤][i]_ = ΦSE _Ze_ _Ze_ _S[⊤]Φ[⊤]._
h "   


-----

From the definition of Zc and Ze, it follows that

_Zc_ _Zc_ _⊤[#]_ _σc[2][I]_ 0

**E** =

_Ze_ _Ze_ 0 _σe[2][I]_
"     

Thus,

_e(Φ) = Σ[¯]_ _e + ¯µeµ¯[⊤]e_
_I_
Using Sherman-Morrison formula, we have that


_µc_ _⊤_
_µe_
  


_µc_
_µe_


Σ¯ _[−]e_ [1]µ[¯]eµ¯[⊤]e Σ[¯] _[−]e_ [1]
_e(Φ)[−][1]_ = Σ[¯] _[−]e_ [1] _._ (30)
_I_ _−_ 1 + ¯µ[⊤]e Σ[¯] _[−]e_ [1]µ[¯]e

Finally, using Equation equation 29 it follows that


_βe[⋆][(Φ) =]_ Σ¯ _[−]e_ [1] Σ¯ _[−]e_ [1]µ[¯]eµ¯[⊤]e Σ[¯] _[−]e_ [1]
 _−_ 1 + ¯µ[⊤]e Σ[¯] _[−]e_ [1]µ[¯]e


1

Σ¯ _[−]e_ [1]µ[¯]e.
1 + ¯µ[⊤]e Σ[¯] _[−]e_ [1]µ[¯]e


_µ¯e =_


The proof of Theorem 1 closely follows from the proof of Rosenfeld et al., 2021, Lemma C.3.. In
what follows, we include a proof to keep the manuscript self-contained.

_Proof of Theorem 1: First, notice that the decomposition φ(X_ _[e]) = AZc + BZe (or ΦS = [A_ _B])_
is without loss of generality under the assumption of left-invertibilibity of S. Then,

Σ¯ _e = σc[2][AA][⊤]_ [+][ σ]e[2][BB][⊤][,] (31)
_µ¯e = Aµc + Bµe._ (32)

Recall from Lemma 5 that βe[⋆][(Φ) = ¯]Σ[−]e [1]µ[¯]e/(1 + ¯µ[⊤]e Σ[¯] _[−]e_ [1]µ[¯]e). If βe[⋆][(Φ)][ is invariant, then][ β][⋆] [=]
_βe[⋆][(Φ)][ for all][ e][ ∈E][tr][. Then, by reorganizing terms, we get]_

Σ¯ _eβ[⋆]_ = 1 _µ¯[⊤]e_ _[β][⋆][]_ _µ¯e._
_−_

Thus, using Equation equation 31 and equation 32, we have that 

(σc[2][AA][⊤] [+][ σ]e[2][BB][⊤][)][β][⋆] [=] 1 − (Aµc + Bµe)[⊤]β[⋆][] (Aµc + Bµe).

Let v := −σ[2]AA[⊤]β[⋆] + (1 − _µ[⊤]c_ _[Aβ][⋆][)][Aµ][c] [. Then,]_

_B_ _σe[2][I][ +][ µ][e][µ]e[⊤]_ _B[⊤]β[⋆]_ _v =_ 1 _µ[⊤]c_ _[A][⊤][β][⋆][]_ _Bµe + µ[⊤]e_ _[B][⊤][β][⋆][Aµ][c][.]_ (33)
_−_ _−_

Similar to proof of Lemma C.3. in (Rosenfeld et al., 2021), we show that for all fixed     _β[⋆]_ and A
Eq. equation 33 for all environments only holds (with probability 1) if B = 0. If tr _> de. Then,_
_|E_ _|_
by the degeneracy assumption of the training sets, there exists at least one environment for which
Eq. equation 19 holds. Let ˜µ and ˜σ[2] be the mean of Ze and variance of We for this environment.
Then, we have that ˜µ = _i=1_ _[α][i][µ][i][. By applying this linear combination to Eq. equation 33 for this]_
environment, we get

[P][d][e] _de_ _de_ _⊤_

_B_ _σ˜[2]I + ˜µµ˜[⊤][]_ _B[⊤]β[⋆]_ _v =_ 1 _µ[⊤]c_ _[A][⊤][β][⋆][]_ _B_ _αiµi +_ _αiµi_ _B[⊤]β[⋆]Aµc_
_−_ _−_ _i=1_ _i=1_ !
   de X X

= _αi_ 1 _µ[⊤]c_ _[A][⊤][β][⋆][]_ _Bµi + µ[⊤]i_ _[B][⊤][β][⋆][Aµ][c]_

_−_
_i=1_

Xde    

= _αi_ _B_ _σi[2][I][ +][ µ][i][µ]i[⊤]_ _B[⊤]β[⋆]_ _−_ _v_ _,_ (34)

_i=1_

X      

where in the last identity, we applied Eq. equation 33 for all i = 1, . . ., de. By rearranging the terms
in Eq. equation 34, we get


_de_

_αi_ _σi[2][I][ +][ µ][i][µ]i[⊤]_
_i=1_

X  


_de_

1 _αi_
_−_

_i=1_

X


_σ˜[2]I + ˜µµ˜[⊤]_ _−_


_B[⊤]β[⋆]_ =


_v._ (35)


-----

From the non-degeneracy condition equation 20, Eq. equation 35 is equivalent to

_BΓαB[⊤]β[⋆]_ = v, (36)
where Γα is defined as

_σ[2]I + ˜µµ˜[⊤]_ _i=1_ _[α][i]_ _σi[2][I][ +][ µ][i][µ]i[⊤]_
Γα := [˜] _−_ [P][d][e] _._

1 _i=1_ _[α] [i]_ 
_−_ [P][d][e]

Note that B, β[⋆], and v are environment independent and Γα is an environment dependent matrix
for which it holds that rank(Γα) = de from the nondegeneracy condition equation 21. Thus, Eq.
equation 36 holds if and only v = BΓαB[⊤]β[⋆] = 0. Then, Eq. equation 33 reduces to
1 _µ[⊤]c_ _[A][⊤][β][⋆][]_ _Bµe + β[⋆][⊤]BµeAµc = 0_
_−_
for all e tr. Thus, Bµe = 0 for all e tr, which holds if and only if B = 0 given that the span
_∈E_   _∈E_
of µes is R[d][e].


D THE ROLE OF THE EIGENSTRUCTURE OF _e(φ)_
_I_

In this section, we elaborate on the discussions on the eigenstructure of _e(φ), and in particular, its_
_I_
condition number in the examples of (Arjovsky et al., 2019) and (Rosenfeld et al., 2021).

D.1 EXAMPLE 1 OF (ARJOVSKY ET AL., 2019)

Arjovsky et al. (2019) consider data that is generated according to the following SEM
_X1_ (0, σ[2]),
_∼N_
_Y = X1 + Z1,_
_X2 = Y + Z2,_


where Z1 (0, σ[2]), Z2 (0, 1), and X1 are independent, and X = _X1_
_∼N_ _∼_ _X2_


following data representation

_φc(X) =_ _cXX12_ _._
 


. Consider the

(37)


Then,

_I(φc) = E_ _cXX12_ _cXX12_ _⊤[#]_ = _cσσ[2][2]_ _c[2](2cσσ[2][2]+ 1)_ _._

"     

We now find the eigenvalues of (φc). That is, the solutions to det( (φc) _λI) = 0._
_I_ _I_ _−_

_λ[2]_ _−_ _λ_ _σ[2]_ + c[2](2σ[2] + 1) + c[2]σ[2](2σ[2] + 1) − _c[2]σ[4]_ = 0.
Then,
  


_λ = [1]_

2

= [1]


(σ[2] + c[2](2σ[2] + 1))[2] _−_ 4c[2]σ[2](σ[2] + 1)

_σ[4]_ + c[4](2σ[2] + 1)[2] _−_ 2c[2]σ[2] _._



_σ[2]_ + c[2](2σ[2] + 1) ±

_σ[2]_ + c[2](2σ[2] + 1) ±


Hence,


_κ(_ (φc)) = _[λ][max][(][I][(][φ][c][))]_
_I_ _λmin(_ (φc))

_I_

_σ[4]_ + c[4](2σ[2] + 1)[2] 2c[2]σ[2]

= _[σ][2][ +][ c][2][(2][σ][2][ + 1) +]_ _−_

_σ[2]_ + c[2](2σ[2] + 1) _σ[4]_ + c[4](2σ[2] + 1)[2] 2c[2]σ[2]

p

_−_ _−_

2

_σ[2]_ + c[2](2σ[2] + 1) +p _σ[4]_ + c[4](2σ[2] + 1)[2] _−_ 2c[2]σ[2]

=

(σ[2] + c[2](2σ[2] + 1))[2] _−p(σ[4]_ + c[4](2σ[2] + 1)[2] _−_ 2c[2]σ[2])

2

1 1 1
=

2(σ[2] + 1) _c [σ][2][ +][ c][(2][σ][2][ + 1) +]_ _c[2][ σ][4][ +][ c][2][(2][σ][2][ + 1)][2][ −]_ [2][σ][2]

r !


-----

Finally,

lim
_c_ _c_ 0 _[κ][(][I][(][φ][c][)) =][ ∞][.]_
_→∞_ _[κ][(][I][(][φ][c][)) = lim]→_

It is worth noting that Arjovsky et al. (2019) discuss that _w_ _we[⋆][(][φ][)][∥][2][ is poor discrepancy both]_
_∥_ _−_
for the invariant data representation, i.e., c = 0, and for a data representation that heavily rely on the
spurious features, i.e., large c.


D.2 EXAMPLE OF (ROSENFELD ET AL., 2021)

We show that in the setting that Rosenfeld et al. (2021) demonstrate that the invariance penalty is
arbitrarily small, the risk is also inevitably arbitrarily small and is of the same order as the invariance
penalty.


_φϵ(X_ _[e]) =_ _Zc_



1
_{Ze /∈Zϵ}[.]_


_Ze_


Here, Zϵ is defined as


( _r(µe)_ _r(_ _µe)),_ (38)
_B_ _∪B_ _−_
_e[∈E_


_Zϵ :=_


where r := _ϵσe[2][d][e]_ [and][ B][r][(][µ][)][ denotes the][ ℓ][2] [ball of radius][ r][ centered at][ µ][. Note that the invariant]

representation is given by

p

_φinv(X_ _[e]) =_ _Z0c_ _._
 

We compare the risk of the optimal predictor given the invariant and the Rosenfeld et al. (2021)
representations.

D.2.1 INVARIANT REPRESENTATION


_Ie(φinv) = E[φinv(X_ _[e])φinv(X_ _[e])[⊤]] = E_ _Zc0Zc[⊤]_



_µcµ[⊤]c_ [+][ σ]c[2][I]


Given that Ie(φinv) is singular, we consider ℓ2 regularized LSE with regularization parameter γ >
0, i.e.,

_winv[∗]_ [= (][I][e][(][φ][inv][) +][ γI][)][−][1][E][[][φ][inv][(][X] _[e][)][Y][e][]][.]_

Then,


_−1_ **E** _ZcY_
0
 


_winv[∗]_ [=] _µcµ[⊤]c_ [+ (][σ]c[2] [+][ γ][)][I] 0
0 _γI_


Recall from the proof of Lemma 1 that


(µcµ[⊤]c [+ (][σ]c[2] [+][ γ][)][I][)][−][1][µ][c]


_Re(winv[∗]_ _⊤φinv) = E[_ _Y_ 2] **E[φinv(X)Y ]⊤** _e(φinv)E[φinv(X)Y ]._
_∥_ _∥_ _−_ _I_

_Re(winv[∗]_ _⊤φinv) = 1 −_ _µ⊤c_ [(][µ][c][µ]c[⊤] [+ (][σ]c[2] [+][ γ][)][I][)][−][1][µ][c][.] (39)


Then,


D.2.2 ROSENFELD ET AL. (2021) REPRESENTATION

We have that

_e(φϵ) = E[φϵ(X_ _[e])φϵ(X_ _[e])[⊤]]_
_I_

= E _ZcZc[⊤]_ 0 + E 0 _ZcZe[⊤]_
0 0 _ZeZc[⊤]_ _ZeZe[⊤]_
  


1
_{Ze /∈Zϵ}_


-----

Recall that the first term is equal to _e(φinv). For the second term, we have that_
_I_

**E** _Ze0Zc[⊤]_ _ZZecZZee[⊤][⊤]_ 1{Ze /∈Zϵ} = P(Ze /∈Zϵ)E _Ze0Zc[⊤]_ _ZZecZZee[⊤][⊤]_ _Ze /∈Zϵ_
    

Now define matrix A and parameter p as

_A := E_ 0 _ZcZe[⊤]_ _Ze /_ _ϵ_ _,_
_ZeZc[⊤]_ _ZeZe[⊤]_ _∈Z_
  

_p := P(Ze /∈Zϵ)._

Then,

_e(φϵ) =_ _e(φinv) + pA._
_I_ _I_

Also,

_wϵ[∗]_ [= (][I][e][(][φ][ϵ][) +][ γI][)][−][1][E][[][φ][ϵ][(][X] _[e][)][Y][e][]]_

= (Ie(φinv) + γI + pA)[−][1]E ZeY 1Z{cZYe /∈Zϵ} _._

Let a = E[ZeY |Ze /∈Zϵ]. Then,

_wϵ[∗]_ [= (][I][e][(][φ][inv][) +][ γI][ +][ pA][)][−][1] _µpbc_ _._
 

For an invertible matrix S, we have that


(S + ∆)[−][1] = S[−][1] _−_ _S[−][1]∆S[−][1]_ + O(∥∆∥[2]).

Thus,

_wϵ[∗]_ [= ((][I][e][(][φ][inv][) +][ γI][)][−][1][ −] _[p][(][I][e][(][φ][inv][) +][ γI][)][−][1][A][(][I][e][(][φ][inv][) +][ γI][)][−][1][ +][ O][(][p][2][))]_ _µpbc_
 

0
= winv[∗] [+][ p] _b_ _−_ (Ie(φinv) + γI)[−][1]Awinv[∗] + O(p[2]).
  

Then,

_Re(wϵ[∗]⊤φϵ) = 1 −_ _µpbc_ _⊤_ _wϵ[∗]_
 

= 1 − _µ[⊤]c_ [(][µ][c][µ]c[⊤] [+ (][σ]c[2] [+][ γ][)][I][)][−][1][µ][c] [+][ O][(][p][2][)][.]

That is,

_Re(wϵ[∗]⊤φϵ)_ _Re(winv∗_ _⊤φinv) = O(p2)._
_−_

Recall that

_φϵ(X_ _[e]) =_ _Z0c_ 1{Ze∈Zϵ} + _ZZec_ 1{Ze /∈Zϵ}[.]
   

Here, Zϵ is defined as

_Zϵ :=_ (Br(µe) ∪Br(−µe)), (40)

_e[∈E_


where r := _ϵσe[2][d][e]_ [and][ B][r][(][µ][)][ denotes the][ ℓ][2] [ball of radius][ r][ centered at][ µ][. Then,]
p _Ie(φϵ) = E_ _φϵ(X_ _[e])φϵ(X_ _[e])[⊤][]_ = Ic + Ie.

where Ic and Ie are defined as 


_Ic :=_ **E** _ZcZc[⊤]0[|][Z][e]_ _[∈Z][ϵ]_ 00
   

_Ie := E_ _Zc_ _Zc_ _⊤_ _Ze_ _ϵ_

_Ze_ _Ze_ _∈Z_
"   


**P (Ze** _ϵ),_
_∈Z_

# **P (Ze /∈Zϵ) .**


-----

Here, we establish a lower bound on the condition number of _e(φϵ) in terms of the probability of_
event 1{Ze /∈Zϵ}[. Using Weyl’s inequality, we have that] _I_

_λmax(_ _e(φϵ))_ _λmax(Ic) + λmin(Ie),_
_I_ _≥_
_λmin(_ _e(φϵ))_ _λmin(Ic) + λmax(Ie)._
_I_ _≤_

As Ie is positive semidefinite, λmin(Ie) ≥ 0. Moreover, λmin(Ic) = 0. Then,

_λmax(_ _e(φϵ))_ _λmax(Ic),_
_I_ _≥_
_λmin(_ _e(φϵ))_ _λmax(Ie)._
_I_ _≤_

For the first term, we have


1

tr(Ic)
_de + dc_

1

**E** _Zc_ _Ze_ _ϵ_ **P (Ze** _ϵ)_
_de + dc_ _∥_ _∥[2]|_ _∈Z_ _∈Z_

1  

**E** _µc_ _Y_ [2] + _Wc_ + 2µ[⊤]c _[W][c][Y][ |][Z][e]_ **P (Ze** _ϵ)_
_de + dc_ _∥_ _∥[2]_ _∥_ _∥[2]_ _[∈Z][ϵ]_ _∈Z_

1  

( _µc_ + dcσc[2][)][P][ (][Z][e] (41)
_de + dc_ _∥_ _∥[2]_ _[∈Z][ϵ][)][,]_


_λmax(Ic)_
_≥_


where the last identity follows from the fact that Y [2] = 1 almost surely, and the fact that Wc is
independent of Y and We, and hence is independent of the event 1{Ze /∈Zϵ}[.]

For the second term, we have

_λmax(Ie)_ tr(Ic)
_≤_

= E _∥Zc∥[2]_ + ∥Ze∥[2]|Ze /∈Zϵ **P (Ze /∈Zϵ)**

= µc + dcσc[2] [+][ E] _Ze_ Ze / _ϵ_ **P (Ze /** _ϵ),_
_∥_ _∥[2]_ _∥_ _∥[2]|_ _∈Z_ _∈Z_

where the last identity follows similarly as Equation equation 41. Then,   


_Ze_ _Ze /_ _ϵ_ = E _µe_ _Y_ [2] + _We_ + 2µ[⊤]e _[W][e][Y][ |][Z][e]_ _[/]_ _ϵ_
_∥_ _∥[2]|_ _∈Z_ _∥_ _∥[2]_ _∥_ _∥[2]_ _∈Z_
 = _µe_ + E _We_ + 2µ[⊤]e _[W][e][Y][ |][Z][e]_ _[/]_ _ϵ_ _._

_∥_ _∥[2]_ _∥_ _∥[2]_ _∈Z_
 


We have that


**E** _∥We∥[2]|Ze /∈Zϵ_ _≤_ _deσe[2][.]_

Moreover, using Cauchy-Schwarz inequality, we get 


_µ[⊤]e_ _[W][e][Y][ |][Z][e]_ _[/]_ _ϵ_ _µe_ **E [** _We_ _Y_ _Ze /_ _ϵ]_ _µe_
_∈Z_ _≤∥_ _∥_ _∥_ _∥|_ _||_ _∈Z_ _≤∥_ _∥_



_deσe[2][.]_


Hence,

Thus,


_deσe[2][)][2][]_ **P (Ze /** _ϵ) ._
_∈Z_


_λmax(Ie) ≤_ _∥µc∥[2]_ + dcσc[2] [+ (][∥][µ][e][∥] [+]



_κ(_ _e(φϵ))_
_I_ _≥_ _λ[λ]max[max]([(]I[I]e[c][)])_

( _µc_ + dcσc[2][)][P][ (][Z][e] [+][ d][c][)]
_≥_ _∥_ _∥[2]_ _[∈Z][ϵ][)][ /][(][d][e]_
_∥µc∥[2]_ + dcσc[2] [+ (][∥][µ][e][∥] [+] _deσe[2][)][2]_ **P (Ze /∈Zϵ)**

=  _∥µc∥[2]_ + dpcσc[2]  1

(de + dc) _µc_ + dcσc[2] [+ (][∥][µ][e][∥] [+] _deσe[2][)][2]_  **P (Ze /∈Zϵ)** _[−]_ [1]
_∥_ _∥[2]_

Note that (Rosenfeld et al., 2021, Lemma F.3.) show that p 

**P (Ze /∈Zϵ) ≤** _pϵ,e,_


-----

where

Then,


_pϵ,e := exp_ _−_ 8 [1] [min][{][ϵ][ −] [1][,][ (][ϵ][ −] [1)][2][}] (42)
 


1

1

_deσe[2][)][2]_  _pϵ,e_ _−_



_κ(_ _e(φϵ))_ _∥µc∥[2]_ + dcσc[2]
_I_ _≥_

(de + dc) _∥µc∥[2]_ + dcσc[2] [+ (][∥][µ][e][∥] [+]



Rosenfeld et al. (2021) show that the invariance penalty of (Arjovsky et al., 2019) is no greater than
_O(p[2]ϵ,e[)][, which can be made arbitrarily small by choosing appropriately large][ ϵ][. However, for such]_
choices of ϵ, matrix _e(φϵ) is ill-conditioned. In particular,_
_I_

lim
_ϵ→∞_ _[κ][(][I][e][(][φ][ϵ][)) =][ ∞][.]_

D.3 EXTENDED COLORED MNIST EXPERIMENTS

The model and all its respective parameters are replicated from Arjovsky et al. (2019)’s GitHub
repository[3]. The penalty coefficient for IRMv2 is set at λ = 10 and for λ0 = 10[−][5] for IRMv1A.

Figure 2 depicts demonstrate the significance of the dimension of the representation in relation to
_I(φ) being ill-conditioned, and, in turn, the test accuracy of IRMv1, v1A, and v2. In particular, by_
allowing the representation to be overly flexible

E FULL LINEARUNITTESTS EXPERIMENTS

In this section, we provide more detailed tables for the numerical experiments on LinearUnitTests
data sets. In addition to ERM, IRMv1, IRMv1A, and IRMv2, we include two other invariance
discovery methods, namely Inter-environmental Gradient Alignment (IGA) (Koyama & Yamaguchi,
2020) and AND-Mask (Parascandolo et al., 2020), considered in (Aubin et al., 2020). The IGA
method seeks to elicit invariant predictors by an invariance penalty in terms of the variance of the
risk under different environments. The AND-Mask method, at each step of the training process,
updates the model using the direction where gradient (of the loss) signs agree across environments.

All experiments are run using default parameters of the experiments of Aubin et al. (2020) available
on their GitHub repository.[4]

**We note that in the majority of these experiment (13 out of 18) one of our proposed methods**
**IRMv1A or IRMv2 outperforms all other methods.**

F DETAILS OF THE HEALTHYGUTTESTS EXPERIMENTS

We summarize the details of each data set of the HealthyGutTests in Table 7.

Sample Size Geographical Region Health Status Studied

Feng (2015) 145 Austria Colorectal Cancer, Advanced Adenoma, Obesity, Overweight, Healthy
He (2017) 98 China Crohns Disease, Obesity, Overweight, Underweight, Healthy
Jie (2017) 281 China Atherosclerotic Cardiovascular Disease, Obesity, Overweight, Underweight, Healthy
Karlsson (2013) 133 Europe Type 2 Diabetes, Impaired Glucose Tolerance, Obesity, Overweight, Underweight, Healthy
Le Chatelier (2013) 112 Denmark Obesity, Overweight, Underweight, Healthy
Nielsen (2014) 226 Europe Crohns Disease, Ulcerative Colitis, Obesity, Overweight, Underweight, Healthy
Qin (2012) 297 China Type 2 Diabetes, Obesity, Overweight, Underweight, Healthy
Vogtmann (2016) 99 USA Colorectal Cancer, Obesity, Overweight, Underweight, Healthy
Zeller (2014) 196 Europe Colorectal Cancer, Obesity, Overweight, Underweight, Healthy
Zhang (2015) 183 China Rheumatoid Arthritis, Obesity, Overweight, Underweight, Healthy

Table 7: Details of the HealthyGutTests data sets.

[3https://github.com/facebookresearch/InvariantRiskMinimization](https://github.com/facebookresearch/InvariantRiskMinimization)
4https://github.com/facebookresearch/InvarianceUnitTests


-----

ANDMask ERM IGA IRMv1A IRMv1 IRMv2 Oracle

Example1.E0 0.14 ± 0.03 2.01 ± 0.27 4.68 ± 0.72 0.07 ± 0.01 0.13 ± 0.01 **0.05 ± 0.00** 0.05 ± 0.00
Example1.E1 **11.56 ± 0.20** 15.37 ± 0.52 19.61 ± 1.36 13.81 ± 1.11 11.60 ± 0.19 12.15 ± 0.81 11.25 ± 0.02
Example1.E2 **20.38 ± 0.27** 25.82 ± 0.89 31.13 ± 2.30 24.74 ± 2.20 20.43 ± 0.17 21.56 ± 1.11 19.66 ± 0.38
Example1s.E0 0.12 ± 0.05 1.96 ± 0.29 3.88 ± 0.17 0.07 ± 0.01 0.13 ± 0.01 **0.06 ± 0.01** 0.05 ± 0.00
Example1s.E1 13.68 ± 1.00 15.47 ± 0.87 18.21 ± 0.55 14.35 ± 1.62 **11.72 ± 0.08** 13.30 ± 1.87 11.03 ± 0.27
Example1s.E2 24.13 ± 1.40 25.69 ± 1.06 28.92 ± 0.53 25.32 ± 2.61 **20.44 ± 0.32** 23.38 ± 3.09 20.53 ± 0.28
Example2.E0 0.40 ± 0.03 0.40 ± 0.01 0.43 ± 0.00 **0.30 ± 0.09** 0.43 ± 0.00 0.43 ± 0.09 0.00 ± 0.00
Example2.E1 0.47 ± 0.04 0.47 ± 0.01 0.50 ± 0.00 **0.34 ± 0.11** 0.50 ± 0.00 0.35 ± 0.05 0.00 ± 0.00
Example2.E2 0.40 ± 0.03 0.39 ± 0.00 0.42 ± 0.00 0.31 ± 0.09 0.42 ± 0.00 **0.23 ± 0.02** 0.00 ± 0.00
Example2s.E0 0.43 ± 0.00 0.43 ± 0.00 0.43 ± 0.00 **0.25 ± 0.17** 0.43 ± 0.00 0.45 ± 0.06 0.00 ± 0.00
Example2s.E1 0.50 ± 0.00 0.50 ± 0.00 0.50 ± 0.00 **0.29 ± 0.20** 0.50 ± 0.00 0.40 ± 0.05 0.00 ± 0.00
Example2s.E2 0.42 ± 0.00 0.42 ± 0.00 0.42 ± 0.00 **0.26 ± 0.17** 0.42 ± 0.00 0.29 ± 0.07 0.00 ± 0.00
Example3.E0 0.34 ± 0.23 0.35 ± 0.21 0.34 ± 0.22 **0.25 ± 0.02** 0.36 ± 0.20 0.41 ± 0.03 0.01 ± 0.00
Example3.E1 0.36 ± 0.21 0.40 ± 0.14 0.38 ± 0.17 **0.26 ± 0.02** 0.37 ± 0.18 0.39 ± 0.00 0.01 ± 0.00
Example3.E2 0.34 ± 0.23 0.36 ± 0.20 0.35 ± 0.21 **0.26 ± 0.02** 0.36 ± 0.20 0.39 ± 0.00 0.01 ± 0.00
Example3s.E0 **0.28 ± 0.17** 0.35 ± 0.21 0.35 ± 0.21 0.34 ± 0.11 0.36 ± 0.20 0.41 ± 0.01 0.01 ± 0.00
Example3s.E1 0.47 ± 0.06 0.41 ± 0.14 0.40 ± 0.15 **0.34 ± 0.11** 0.38 ± 0.19 0.41 ± 0.01 0.01 ± 0.00
Example3s.E2 0.38 ± 0.17 0.36 ± 0.20 0.36 ± 0.20 **0.34 ± 0.11** 0.36 ± 0.20 0.41 ± 0.01 0.01 ± 0.00

Table 3: Test errors for all algorithms and examples with (dinv, dspu, denv) = (5, 5, 3). The errors
for Examples 1 and 1s are in MSE and all others are classification error. The empirical mean and the
standard deviation are computed using 10 independent experiments. An ‘s’ indicates the scrambled
variation of its corresponding problem setting.

ANDMask ERM IGA IRMv1A IRMv1 IRMv2 Oracle

Example1 **10.69 ± 0.17** 14.40 ± 0.56 18.48 ± 1.46 12.87 ± 1.11 10.72 ± 0.13 11.26 ± 0.64 10.32 ± 0.13
Example1s 12.64 ± 0.82 14.37 ± 0.74 17.00 ± 0.42 13.24 ± 1.41 **10.76 ± 0.14** 12.25 ± 1.66 10.53 ± 0.18
Example2 0.42 ± 0.03 0.42 ± 0.01 0.45 ± 0.00 **0.31 ± 0.10** 0.45 ± 0.00 0.34 ± 0.05 0.00 ± 0.00
Example2s 0.45 ± 0.00 0.45 ± 0.00 0.45 ± 0.00 **0.27 ± 0.18** 0.45 ± 0.00 0.38 ± 0.06 0.00 ± 0.00
Example3 0.34 ± 0.22 0.37 ± 0.18 0.36 ± 0.20 **0.26 ± 0.02** 0.36 ± 0.19 0.40 ± 0.01 0.01 ± 0.00
Example3s 0.38 ± 0.13 0.37 ± 0.18 0.37 ± 0.19 **0.34 ± 0.11** 0.37 ± 0.19 0.41 ± 0.01 0.01 ± 0.00

Table 4: Test errors averaged for each experiment.

ANDMask ERM IGA IRMv1A IRMv1 IRMv2 Oracle

Example1.E0 0.13 ± 0.03 1.98 ± 0.29 4.67 ± 0.74 0.07 ± 0.01 0.12 ± 0.01 0.05 ± 0.00 0.05 ± 0.00
Example1.E1 10.38 ± 0.43 7.80 ± 0.51 10.05 ± 0.75 13.82 ± 1.26 10.16 ± 0.10 12.01 ± 0.68 11.23 ± 0.20
Example1.E2 18.45 ± 0.63 12.27 ± 1.02 14.13 ± 1.39 24.59 ± 2.26 18.12 ± 0.24 21.36 ± 0.92 20.19 ± 0.13
Example1s.E0 0.12 ± 0.05 1.91 ± 0.27 3.82 ± 0.12 0.07 ± 0.01 0.12 ± 0.01 0.06 ± 0.01 0.05 ± 0.00
Example1s.E1 12.14 ± 0.26 7.83 ± 0.55 9.26 ± 0.52 13.85 ± 1.37 10.15 ± 0.10 12.87 ± 1.81 11.27 ± 0.02
Example1s.E2 21.33 ± 0.27 12.22 ± 1.17 13.23 ± 0.91 24.37 ± 2.43 17.80 ± 0.24 22.73 ± 3.27 19.96 ± 0.17
Example2.E0 0.05 ± 0.01 0.04 ± 0.00 0.05 ± 0.00 0.12 ± 0.06 0.05 ± 0.00 0.36 ± 0.11 0.00 ± 0.00
Example2.E1 0.03 ± 0.00 0.03 ± 0.00 0.03 ± 0.00 0.11 ± 0.06 0.03 ± 0.00 0.26 ± 0.09 0.00 ± 0.00
Example2.E2 0.01 ± 0.00 0.01 ± 0.00 0.01 ± 0.00 0.10 ± 0.07 0.01 ± 0.00 0.15 ± 0.05 0.00 ± 0.00
Example2s.E0 0.05 ± 0.00 0.05 ± 0.00 0.05 ± 0.00 0.05 ± 0.03 0.05 ± 0.00 0.31 ± 0.19 0.00 ± 0.00
Example2s.E1 0.03 ± 0.00 0.03 ± 0.00 0.03 ± 0.00 0.04 ± 0.03 0.03 ± 0.00 0.22 ± 0.14 0.00 ± 0.00
Example2s.E2 0.01 ± 0.00 0.01 ± 0.00 0.01 ± 0.00 0.03 ± 0.02 0.01 ± 0.00 0.13 ± 0.09 0.00 ± 0.00
Example3.E0 0.00 ± 0.01 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.35 ± 0.10 0.01 ± 0.00
Example3.E1 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.29 ± 0.01 0.01 ± 0.00
Example3.E2 0.01 ± 0.01 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.29 ± 0.01 0.01 ± 0.00
Example3s.E0 0.18 ± 0.09 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.30 ± 0.03 0.01 ± 0.00
Example3s.E1 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.29 ± 0.03 0.01 ± 0.00
Example3s.E2 0.02 ± 0.02 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.30 ± 0.03 0.01 ± 0.00

Table 5: Training errors for all algorithms and examples with (dinv, dspu, denv) = (5, 5, 3). The
errors for Examples 1 and 1s are in MSE and all others are classification error. The empirical mean
and the standard deviation are computed using 10 independent experiments. An ‘s’ indicates the
scrambled variation of its corresponding problem setting.


-----

ANDMask ERM IGA IRMv1A IRMv1 IRMv2 Oracle

Example1 9.65 ± 0.36 7.35 ± 0.61 9.62 ± 0.96 12.82 ± 1.17 9.47 ± 0.12 11.14 ± 0.53 10.49 ± 0.11
Example1s 11.20 ± 0.19 7.32 ± 0.66 8.77 ± 0.52 12.76 ± 1.27 9.36 ± 0.12 11.89 ± 1.70 10.43 ± 0.06
Example2 0.03 ± 0.00 0.03 ± 0.00 0.03 ± 0.00 0.11 ± 0.06 0.03 ± 0.00 0.26 ± 0.08 0.00 ± 0.00
Example2s 0.03 ± 0.00 0.03 ± 0.00 0.03 ± 0.00 0.04 ± 0.03 0.03 ± 0.00 0.22 ± 0.14 0.00 ± 0.00
Example3 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.31 ± 0.04 0.01 ± 0.00
Example3s 0.07 ± 0.04 0.00 ± 0.00 0.00 ± 0.00 0.49 ± 0.00 0.00 ± 0.00 0.30 ± 0.03 0.01 ± 0.00

Table 6: Training errors averaged for each experiment.

F.1 EXPERIMENT DETAILS

F.1.1 NEURAL NETWORK ARCHITECTURE AND HYPERPARAMETER TUNING

The neural network considered consists of 5 layers with input layer dX _dh, hidden layers of size_
_dh_ _dh/2, dh/2_ _dh/2, dh/2_ _dh/4, respectively, and the output layer ×_ _dh/4_ _dφ. We use the_
ReLU action function and the dropout parameter of each layer is set as × _×_ _×_ _p. We treat ×_ _dh, dφ, p, the_
learning rate, and the invariance penalty coefficient as hyperparameters, which we optimize using
the validation accuracy. More specifically, we randomly generate 200 hyperparameters. For each set
of parameters, we independently repeat 5 times training the model over 500 epochs. We then select
the model with best average validation accuracy (over 5 experiments), and report the average test
accuracy in Table 2.

For each data set in Table 2 that is considered as the test set, we treat each of the remaining data
sets as an environment. Before doing so, we split each of training data sets into (0.8, 0.2) split
of training and validation sets, respectively. We then concatenate all the validation subsets into a
unified validation set for model selection.

G FULL DOMAINBED EXPERIMENTS

G.1 EXPERIMENT SUMMARY

DomainBed is an extensive framework released by Gulrajani & Lopez-Paz (2020) to test domain
generalization algorithms for image classification tasks on various benchmark data sets. In a series of
experiments, Gulrajani & Lopez-Paz (2020) show that enabled by data augmentation various stateof-the-art generalization methods perform similar to each other and ERM on several benchmark data
sets.

Although the integration of additional data sets and algorithms to DomainBed is straightforward, we
note that performing an extensive set of experiments requires significant computational resources as
also pointed out by Krueger et al. (2020). For this reason, we limit the scope of our experiments to
the comparison of ERM, IRMv1, IRMv1A, and IRMv2.

Similar to Gulrajani & Lopez-Paz (2020), we observe that no method significantly outperforms
others on any of the benchmark data sets (see Table 8). For a complete set of results on DomainBed
with various model selection methods, we refer the reader to Appendix G. As these data sets are
image based and equipped with data augmentation, they may not provide comprehensive insight
on the strengths and weaknesses of domain generalization algorithms on other modes of data, e.g.,
gathered in real-world applications.


-----

**Algorithm** **ColoredMNIST** **RotatedMNIST** **PACS** **VLCS** **Avg**

ERM 51.7 ± 0.1 96.7 ± 0.0 81.1 ± 0.1 **78.8 ± 0.4** **77.0**
IRMv1 **51.8 ± 0.2** 95.2 ± 0.4 78.6 ± 1.0 76.0 ± 0.5 75.4
IRMv1A 50.9 ± 0.1 64.7 ± 20.1 80.9 ± 0.0 77.3 ± 0.2 68.4
IRMv2 50.8 ± 0.4 **97.1 ± 0.0** **82.6 ± 0.9** 76.5 ± 0.4 76.8

Table 8: The test accuracy of ERM and different implementations of IRM on benchmark data-sets.
Model selection of the DomainBed is chosen as training-domain validation set.

**Algorithm** **+90%** **+80%** **-90%** **Avg**

ERM **72.8 ± 0.1** 72.6 ± 0.2 9.8 ± 0.0 51.7
IRMv1 72.5 ± 0.3 72.9 ± 0.1 **9.9 ± 0.1** **51.8**
IRMv1A 70.7 ± 0.3 72.3 ± 0.5 9.7 ± 0.0 50.9
IRMv2 69.8 ± 0.8 **72.9 ± 0.3** 9.8 ± 0.1 50.8

Table 9: Benchmark: ColoredMNIST, Model selection: training-domain validation set.

G.2 FULL DOMAINBED RESULTS

**Algorithm** **A** **C** **P** **S** **Avg**

ERM 84.5 ± 1.6 77.1 ± 0.8 **96.9 ± 0.3** 65.8 ± 1.9 81.1
IRMv1 77.0 ± 3.0 76.7 ± 1.1 96.4 ± 0.4 64.4 ± 0.3 78.6
IRMv1A 82.6 ± 0.5 **77.7 ± 0.7** 96.6 ± 0.4 66.7 ± 0.5 80.9
IRMv2 **86.0 ± 0.9** 76.6 ± 0.7 **96.9 ± 0.0** **70.8 ± 2.0** **82.6**

Table 11: Benchmark: PACS, Model selection: training-domain validation set.

**Algorithm** **0** **15** **30** **45** **60** **75** **Avg**

ERM 90.3 ± 1.8 97.8 ± 0.0 98.2 ± 0.1 **98.2 ± 0.1** 97.8 ± 0.2 93.5 ± 0.4 96.0
IRMv1 89.6 ± 2.1 96.0 ± 0.5 97.9 ± 0.1 97.2 ± 0.0 97.0 ± 0.2 90.9 ± 0.5 94.8
IRMv1A 75.9 ± 5.9 64.2 ± 22.4 59.4 ± 26.1 59.8 ± 26.3 59.0 ± 26.7 55.9 ± 22.5 62.4
IRMv2 **94.1 ± 0.0** **98.1 ± 0.3** **98.5 ± 0.1** **98.2 ± 0.1** **98.3 ± 0.0** **94.4 ± 0.3** **97.0**

Table 15: Benchmark: RotatedMNIST, Model selection: leave-one-domain-out cross-validation.

**Algorithm** **A** **C** **P** **S** **Avg**

ERM 79.7 ± 0.6 73.0 ± 3.8 **97.1 ± 0.9** 62.1 ± 1.5 78.0
IRMv1 67.4 ± 6.7 72.3 ± 4.3 87.7 ± 5.7 64.1 ± 4.5 72.9
IRMv1A 78.8 ± 3.2 **78.9 ± 0.9** 96.0 ± 0.2 42.3 ± 16.3 74.0
IRMv2 **86.3 ± 0.3** 76.8 ± 0.5 97.0 ± 0.4 **69.7 ± 2.6** **82.5**

Table 16: Benchmark: PACS, Model selection: leave-one-domain-out cross-validation.


-----

**Algorithm** **0** **15** **30** **45** **60** **75** **Avg**

ERM 93.1 ± 0.1 97.8 ± 0.0 98.4 ± 0.0 98.3 ± 0.1 98.2 ± 0.0 94.3 ± 0.1 96.7
IRMv1 89.6 ± 2.1 96.8 ± 0.1 97.9 ± 0.1 97.8 ± 0.1 97.5 ± 0.1 91.6 ± 0.0 95.2
IRMv1A 75.9 ± 5.9 71.1 ± 17.7 60.8 ± 25.1 60.4 ± 25.8 60.2 ± 25.8 59.8 ± 20.5 64.7
IRMv2 **94.1 ± 0.0** **98.2 ± 0.0** **98.5 ± 0.1** **98.4 ± 0.1** **98.3 ± 0.0** **95.1 ± 0.2** **97.1**

Table 10: Benchmark: RotatedMNIST, Model selection: training-domain validation set.

**Algorithm** **C** **L** **S** **V** **Avg**

ERM **97.4 ± 0.1** 65.0 ± 0.9 **74.3 ± 1.1** **78.7 ± 0.1** **78.8**
IRM 96.3 ± 0.6 61.7 ± 0.3 70.1 ± 0.1 76.0 ± 1.8 76.0
IRMA 96.9 ± 0.8 64.8 ± 0.0 70.7 ± 1.4 77.0 ± 0.4 77.3
IRMv2 96.6 ± 1.1 **65.4 ± 1.5** 73.5 ± 0.5 70.6 ± 2.4 76.5

Table 12: Benchmark: VLCS, Model selection: training-domain validation set.

**Algorithm** **0** **15** **30** **45** **60** **75** **Avg**

ERM 92.5 ± 0.6 97.8 ± 0.0 97.9 ± 0.1 97.9 ± 0.2 **98.3 ± 0.1** 94.3 ± 0.1 96.4
IRMv1 89.6 ± 2.1 96.8 ± 0.1 98.0 ± 0.2 97.5 ± 0.3 97.5 ± 0.1 91.6 ± 0.0 95.2
IRMv1A 77.9 ± 7.4 71.1 ± 17.7 59.4 ± 26.1 59.8 ± 26.3 59.0 ± 26.7 55.9 ± 22.5 63.9
IRMv2 **94.7 ± 0.4** **98.0 ± 0.2** **98.5 ± 0.1** 98.3 ± 0.0 **98.3 ± 0.0** 95.0 ± 0.2 **97.2**

Table 20: Benchmark: RotatedMNIST, Model selection: test-domain validation set (oracle).

**Algorithm** **A** **C** **P** **S** **Avg**

ERM 83.7 ± 0.5 **82.1 ± 0.2** **97.5 ± 0.2** 69.1 ± 0.6 **83.1**
IRMv1 66.7 ± 4.3 68.5 ± 1.6 87.1 ± 5.3 67.7 ± 2.0 72.5
IRMv1A 83.5 ± 0.2 75.7 ± 3.2 96.4 ± 0.3 68.6 ± 1.8 81.0
IRMv2 **84.3 ± 0.3** 76.5 ± 0.7 96.8 ± 0.1 **70.3 ± 2.4** 82.0

Table 21: Benchmark: PACS, Model selection: test-domain validation set (oracle).

**Algorithm** **C** **L** **S** **V** **Avg**

ERM **98.4 ± 0.1** 65.1 ± 1.4 **72.9 ± 2.2** **77.1 ± 1.7** **78.4**
IRM 97.6 ± 1.2 61.9 ± 0.6 62.9 ± 1.3 73.0 ± 0.3 73.9
IRMA 98.0 ± 0.1 64.9 ± 1.1 71.8 ± 0.8 73.9 ± 1.5 77.1
IRMv2 96.3 ± 1.0 **67.1 ± 0.1** 70.9 ± 1.3 71.9 ± 1.5 76.5

Table 22: Benchmark: VLCS, Model selection: test-domain validation set (oracle).


-----

**Algorithm** **ColoredMNIST** **RotatedMNIST** **PACS** **VLCS** **Avg**

ERM 51.7 ± 0.1 96.7 ± 0.0 81.1 ± 0.1 **78.8 ± 0.4** **77.0**
IRMv1 **51.8 ± 0.2** 95.2 ± 0.4 78.6 ± 1.0 76.0 ± 0.5 75.4
IRMv1A 50.9 ± 0.1 64.7 ± 20.1 80.9 ± 0.0 77.3 ± 0.2 68.4
IRMv2 50.8 ± 0.4 **97.1 ± 0.0** **82.6 ± 0.9** 76.5 ± 0.4 76.8

Table 13: Model selection: training-domain validation set.

**Algorithm** **+90%** **+80%** **-90%** **Avg**

ERM 30.4 ± 13.4 50.5 ± 0.6 9.9 ± 0.0 30.2
IRMv1 50.1 ± 0.4 **60.6 ± 7.3** **30.0 ± 14.1** **46.9**
IRMv1A **69.5 ± 14.4** 49.8 ± 0.2 10.0 ± 0.1 43.1
IRMv2 10.0 ± 0.1 36.4 ± 3.0 9.9 ± 0.0 18.8

Table 14: Benchmark: ColoredMNIST, Model selection: leave-one-domain-out cross-validation.

**Algorithm** **C** **L** **S** **V** **Avg**

ERM 97.5 ± 0.8 60.3 ± 3.2 70.1 ± 4.2 **75.5 ± 2.8** 75.9
IRM 93.3 ± 2.7 61.8 ± 0.4 72.9 ± 0.9 74.1 ± 3.1 75.5
IRMA 79.2 ± 12.8 **66.8 ± 1.4** 68.3 ± 4.1 73.5 ± 1.3 71.9
IRMv2 **98.2 ± 0.1** 63.0 ± 0.1 **74.4 ± 1.2** 69.9 ± 0.2 **76.4**

Table 17: Benchmark: VLCS, Model selection: leave-one-domain-out cross-validation.

**Algorithm** **ColoredMNIST** **RotatedMNIST** **PACS** **VLCS** **Avg**

ERM 30.2 ± 4.3 96.0 ± 0.4 78.0 ± 0.9 75.9 ± 0.7 70.0
IRMv1 **46.9 ± 2.1** 94.8 ± 0.2 72.9 ± 3.0 75.5 ± 1.6 **72.5**
IRMv1A 43.1 ± 4.8 62.4 ± 21.6 74.0 ± 5.0 71.9 ± 2.8 62.8
IRMv2 18.8 ± 1.1 **97.0 ± 0.1** **82.5 ± 1.0** **76.4 ± 0.3** 68.7

Table 18: Model selection: leave-one-domain-out cross-validation.

**Algorithm** **+90%** **+80%** **-90%** **Avg**

ERM 72.2 ± 0.3 72.6 ± 0.4 12.4 ± 1.1 52.4
IRMv1 **72.5 ± 0.3** **72.9 ± 0.1** **63.3 ± 6.6** **69.6**
IRMv1A 71.4 ± 0.2 72.8 ± 0.3 50.2 ± 0.1 64.8
IRMv2 70.6 ± 1.2 71.9 ± 0.6 20.9 ± 0.9 54.4

Table 19: Benchmark: ColoredMNIST, Model selection: test-domain validation set (oracle).


-----

0.7

0.6


1e25

1e20


0.5

0.4


1e15

1e10


0.3

0.2


1e5

1e0


16 32 64 128 256 512 1024 2048

Test Accuracy
Condition Number


(a) IRMv1


1e25

1e20


0.7

0.6


0.5

0.4


1e15

1e10


0.3

0.2


1e5

1e0


0.1

Test Accuracy
Condition Number


0.70

0.65

0.60

0.55

0.50

0.45

0.40


16 32 64 128 256 512 1024 2048

(b) IRMv1A


1e25

1e20


1e15

1e10


1e5

1e0


16 32 64 128 256 512 1024 2048


Test Accuracy
Condition Number


(c) IRMv2

Figure 2: The figure depicts the evolution of test accuracy and the condition number of I(φ) in
relation to the dimension of the representation.


-----


paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
tDirSp3pczB,"The paper presents a novel theoretical advancement in contrastive unsupervised representation learning (CURL) by establishing sharp upper and lower bounds on downstream classification loss. These bounds explain the empirical observation that larger negative samples improve classification performance. The theoretical findings are validated through experiments on synthetic, vision, and language datasets.","['Can you provide more details on the mathematical derivations and proofs to improve clarity?', 'What are the potential limitations and broader impacts of this work? How might it affect future research or applications?', 'Can you provide more intuitive explanations or visualizations to complement the mathematical proofs?', 'How do the theoretical bounds perform on more complex, real-world datasets beyond CIFAR and Wiki-3029?', 'Are there any practical guidelines or insights derived from your bounds that practitioners can use to improve CURL implementations?', 'Can the authors explain the inconsistencies observed in the CIFAR-10/100 experiments in more detail?']","['The paper does not discuss the limitations and potential broader impacts in detail. It would be beneficial to understand the potential downsides or challenges in applying these theoretical findings.', 'The assumptions made in the theoretical derivations, such as the uniform class prior, might limit the generalizability of the results.', 'The practical applicability of the bounds in real-world scenarios is not convincingly demonstrated.']",False,3,2,3,6,4,"['Addresses a critical theoretical gap in CURL, providing sharp upper and lower bounds on downstream classification loss.', 'The theoretical contribution is significant and novel, explaining the benefit of larger negative samples in improving classification performance.', 'Comprehensive experimental validation across synthetic, vision, and language datasets.']","['The clarity of the paper can be improved, especially in the detailed mathematical derivations and proofs.', 'The limitations and potential broader impacts of the work are not discussed in detail.', 'The empirical validation, while robust, could benefit from additional datasets or comparisons to further strengthen the findings.', 'Some assumptions, such as the uniform class prior, may limit the applicability of the results.', 'Experimental results show some inconsistencies, particularly in the CIFAR-10/100 datasets, where the benefits of larger K are not always clear.']",3,3,2,4,Reject
YDud6vPh2V,"The paper introduces xi-learning, a novel approach to successor feature transfer learning in reinforcement learning. It extends the classical successor feature framework to handle general reward functions, providing theoretical proofs for convergence and demonstrating its performance in environments with both linear and general reward functions.","['Can the authors provide more diverse empirical evaluations to demonstrate the generalizability of xi-learning?', 'Are there any potential solutions to mitigate the increased computational complexity of xi-learning?', 'Can the authors discuss the potential limitations of xi-learning in different environments?', 'Can the authors provide more details on the experimental setup and the choice of parameters?', 'What was the rationale behind the chosen neural network architectures for function approximation in the experiments?', 'Can the authors elaborate on the practical implementation challenges of xi-learning and how they were addressed?', 'Can the authors provide more details on function approximation in continuous spaces and the impact of discretization?', 'How does xi-learning compare with other recent RL techniques that handle general reward functions?', 'Can the authors provide more intuitive explanations and visual aids for the xi-function mechanism and its updates?', 'Have additional baselines and ablation studies been considered to further validate the proposed method?', 'How does xi-learning compare to other recent advancements in RL transfer learning, such as those by Janner et al. (2020) and Touati and Ollivier (2021)?']","['The increased computational complexity and limited empirical evaluations are potential limitations that need to be addressed.', 'The paper could benefit from more diverse and complex experimental setups.', 'The clarity of the implementation details and reward model learning process could be improved.']",False,3,3,3,6,4,"['Addresses a significant limitation of the SF framework by allowing for general reward functions.', 'Provides thorough theoretical analysis with convergence proofs and performance guarantees.', 'Experimental results show improved performance over classical SF and Q-learning in both linear and general reward tasks.']","['The empirical evaluations are limited to a few environments, which may not fully demonstrate the generalizability of the method.', 'Clarity in some sections, particularly implementation details and the xi-function mechanism, could be improved.', 'The increased computational complexity of xi-learning is mentioned but not addressed with a concrete solution.', 'The paper lacks a discussion on the potential limitations of xi-learning in different environments.', 'More visual aids, such as graphs and charts, could improve the presentation of results.']",4,3,3,4,Reject
xZ6H7wydGl,"The paper proposes an importance-sampling estimator for learning stochastic differential equations (SDEs) that avoids traditional integrators. The method aims to lower gradient variance and enhance parallelizability, making it suitable for large-scale computations. The authors validate their method through theoretical justifications and comprehensive experiments, demonstrating its effectiveness compared to existing integrator-based methods.","['Can the authors provide a detailed comparison of computational costs (time and memory) with existing methods?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide more clarity on the implementation details of the Brownian bridge and its efficient sampling?', 'Can the authors include additional ablation studies to understand the sensitivity of the method to various hyperparameters and the choice of functions?', 'Can the authors provide more intuitive explanations or visualizations to make the theoretical sections more accessible?', 'Do the authors plan to test the method on more complex real-world datasets to further validate its robustness and scalability?', 'What are the impacts of different choices for the transformation T and the function approximator for f on the performance of the proposed method?']","['The paper does not discuss the limitations and potential negative societal impacts of the proposed method. Addressing these would enhance the transparency and applicability of the method.', 'More ablation studies could be conducted to explore the impact of different choices in the model architecture and hyperparameters.', ""The impact of the number of observations and the dimensionality on the estimator's performance is briefly mentioned but not deeply explored.""]",False,3,3,3,6,4,"['The paper addresses a significant issue in SDE learning by proposing a novel importance-sampling estimator.', 'The method is claimed to lower gradient variance and is highly parallelizable, making it suitable for large-scale parallel hardware.', 'Thorough experiments validate the claims, including comparisons with existing methods and tests on real-world datasets.', ""Theoretical foundation is solid, leveraging Girsanov's theorem and importance sampling.""]","['The paper lacks a detailed comparison of computational costs with existing methods in terms of both time and memory usage.', 'There is no thorough discussion on the limitations and potential negative societal impacts of the proposed method.', 'Some parts of the methodology, especially related to the Brownian bridge and its efficient implementation, need more clarity.', 'The paper lacks additional ablation studies to understand the sensitivity of the proposed method to various hyperparameters and the choice of functions.', 'The clarity of the paper can be improved, especially in the more technical sections where the derivation and algorithmic steps are described.']",3,3,3,4,Reject
CNY9h3uyfiO,"The paper investigates how reward shifting can be applied in value-based Deep Reinforcement Learning (DRL) to balance exploration and exploitation. The authors propose that a positive reward shift leads to conservative exploitation, while a negative shift leads to curiosity-driven exploration. They validate their insights through experiments in offline RL, online RL with continuous control, and RL with discrete action spaces.","['Can the authors provide a more rigorous theoretical proof for the equivalence of reward shifting and initialization priors in function approximation?', 'How does the proposed method perform across a wider variety of RL environments and tasks, beyond those presented in the paper?', 'Can the authors include more detailed ablation studies and comparative analyses with additional baselines?', 'How sensitive is the method to the choice of reward shifting constants? Can the authors propose a systematic way to select these parameters?', 'Can the authors provide clearer explanations and derivations for the key equations and algorithms?']","[""The paper's clarity and depth in explaining the methodology are lacking, which could hinder reproducibility."", 'Further theoretical and empirical validation is needed to confirm the robustness and generality of the approach.', 'The practical aspects of tuning reward shifting constants and the lack of detailed comparisons with other exploration methods are the main limitations.', 'The paper does not thoroughly discuss potential limitations, such as the impact of reward shifting on long-term policy performance.', 'There are no discussions on the ethical considerations of using reward shifts, especially in sensitive applications like healthcare or finance.']",False,3,3,3,6,4,"['The problem of balancing exploration and exploitation in RL is significant and well-motivated.', 'The concept of reward shifting as a method to influence policy learning is novel.', 'Experimental results show improvements in various RL tasks, demonstrating the potential utility of the approach.', 'The proposed method can be integrated into existing DRL algorithms with minimal modifications.']","['The theoretical justification for equating reward shifting with initialization priors lacks rigorous proof, particularly in the context of function approximation.', 'The generality and robustness of the approach across different RL environments and tasks are not convincingly demonstrated.', ""The paper's clarity and organization need improvement, especially in sections detailing the methodology and experimental setup, which impacts reproducibility."", 'More detailed ablation studies and comparisons with a broader range of baselines are needed to validate the claims.', 'The performance of the proposed method appears to be sensitive to the choice of reward shifting constants, and the paper does not provide a systematic way to select these parameters.']",3,3,3,3,Reject
fXHl76nO2AZ,"The paper proposes Gradient Importance Learning (GIL), a method that trains models to perform inference with missing data without requiring imputation. This is achieved by adjusting the gradients using a reinforcement learning policy to exploit the information behind missingness patterns. The approach is evaluated on multiple datasets, including real-world healthcare data, and shows superior performance compared to existing imputation-based methods.","['Could the authors provide more details on the computational overhead of the proposed method?', 'How does the proposed method compare with simpler heuristics for generating the importance matrix?', 'Can the authors provide more ablation studies to better understand the contribution of each component in the proposed framework?', 'Can the authors provide more detailed explanations and visualizations of how the RL-based importance matrix is generated and used during training?', 'How sensitive is GIL to the choice of hyperparameters, and what guidelines can be provided for tuning them in practice?']","['The method may have significant computational overhead due to the use of reinforcement learning.', 'The paper lacks detailed ablation studies that compare the reinforcement learning component with simpler heuristics.', 'The clarity of the RL methodology is a concern, and more detailed explanations and visualizations could help.', 'While the method shows improvement over traditional imputation-prediction frameworks, it would be valuable to compare it more extensively with other state-of-the-art approaches.', 'The paper does not thoroughly explore the impact of different hyperparameters on the performance of GIL, which could be crucial for understanding its practical applicability.']",False,3,3,3,5,4,"['The method is novel in leveraging reinforcement learning to handle missing data without imputation.', 'Comprehensive experimental evaluation on multiple datasets, including real-world healthcare data.', 'Clear improvement over existing imputation-based methods in terms of prediction accuracy.']","['The computational overhead of the proposed method is not clearly discussed.', 'The paper could benefit from additional ablation studies, especially comparing the reinforcement learning component with simpler heuristics.', 'Some experimental details, such as the exact configuration of the reinforcement learning algorithm, are not fully transparent.', 'The explanation of the RL framework and the generation of the importance matrix is somewhat complex and might be challenging for readers to follow.', 'The impact of different hyperparameters on the performance of GIL is not thoroughly explored.']",4,3,3,3,Reject
bglU8l_Pq8Q,"The paper investigates the performance gap between cross-attention (CA) and dual-encoder (DE) models in neural ranking tasks. It establishes theoretically that DE models with sufficient capacity can approximate any continuous score function. Empirically, it shows that DE models often overfit to the training data, leading to poor generalization. The authors propose a distillation strategy focusing on preserving the ordering amongst documents, which improves DE model performance on benchmark datasets.","['Can the authors provide more clarity on the theoretical analysis, particularly the assumptions and implications of Proposition 1 and Proposition 2?', 'How generalizable are the findings to other datasets beyond MSMARCO-Passage and Natural Questions?', 'Have the authors considered other regularization strategies beyond distillation? If so, what were the results?', 'Can you provide additional ablation studies to further validate the proposed distillation strategy?', 'What are the practical implications and potential deployment scenarios of your proposed methods?', 'Can you discuss the limitations and potential negative societal impacts of your work in more detail?', 'Can the authors provide more details on the implementation of the distillation strategy?', 'How sensitive are the results to the choice of hyperparameters in the distillation process?', 'Can the authors include additional ablation studies to isolate the effects of different components of the proposed method?']","['The paper could benefit from a more thorough exploration of alternative regularization strategies beyond distillation to address the generalization issues of DE models.', 'The clarity of certain sections, particularly the theoretical analysis, needs improvement to ensure that the paper is accessible to a broader audience.', 'The theoretical results rely on certain assumptions which may not hold in practice. The authors should discuss these limitations more thoroughly.', 'The paper lacks a detailed analysis of the computational overhead introduced by the proposed distillation strategy.', 'The impact of the proposed method on the retrieval phase is not thoroughly explored.']",False,3,2,3,4,4,"['The paper addresses a critical question in the field of neural ranking: the performance gap between CA and DE models.', 'The theoretical analysis is rigorous, showing that DE models have sufficient capacity under certain conditions.', 'The empirical validation is comprehensive, covering multiple datasets and demonstrating the efficacy of the proposed distillation strategy.', 'The proposed distillation strategy is simple yet effective, providing a practical solution to improve DE model performance.']","['Certain sections of the paper, particularly the theoretical analysis, are not clearly explained and may be difficult for readers to follow.', 'The reliance on specific datasets like MSMARCO-Passage and Natural Questions may limit the generalizability of the findings.', 'The exploration of alternative regularization strategies beyond distillation is limited. The authors mention standard strategies such as dropout and token dropout but do not provide a thorough analysis of their effectiveness.', 'The paper could benefit from additional ablation studies to explore different aspects of the proposed methods.', 'The practical implications and potential deployment scenarios of the proposed distillation strategy are not thoroughly discussed.', 'The clarity of the paper could be improved, especially in the sections describing the experimental setup and results.', 'The paper does not sufficiently address the limitations and potential negative societal impacts of the proposed methods.']",3,3,2,3,Reject
cU8rknuhxc,"The paper 'Learning More Skills Through Optimistic Exploration' introduces DISDAIN (Discriminator Disagreement Intrinsic Reward), a novel exploration bonus tailored to unsupervised skill learning algorithms. The proposed method uses an ensemble of discriminators to estimate epistemic uncertainty and encourages exploration in states with high discriminator disagreement. The approach aims to overcome the inherent pessimism in existing skill learning methods. The paper provides theoretical insights and comprehensive empirical validation in both grid world and Atari environments.","['Can the authors provide more detailed ablation studies to isolate the impact of each component of DISDAIN?', 'How were the hyperparameters tuned, and how sensitive is the approach to these hyperparameters?', 'What is the computational overhead of training an ensemble of discriminators, and how does it impact the overall training time?', 'Can the authors provide a more comprehensive comparison with state-of-the-art unsupervised skill learning methods?', 'Can the authors provide more details on how the ensemble discriminators were trained and managed?', 'How sensitive is DISDAIN to the size of the ensemble and the specific architecture used for the discriminators?', 'Can the authors provide additional visualizations or qualitative results to illustrate the learned skills and exploration patterns?']","['The paper does not provide detailed ablation studies, making it difficult to isolate the impact of each component of the proposed method.', 'There is insufficient discussion on the impact of hyperparameters and how they were tuned.', 'The computational overhead of training an ensemble of discriminators is not adequately addressed.', 'The comparison with state-of-the-art methods is not comprehensive.', 'The paper does not thoroughly investigate the scalability of DISDAIN to other environments or more complex tasks.']",False,3,3,3,7,4,"['Addresses a critical issue in unsupervised skill learning: pessimistic exploration.', 'Introduces a novel exploration bonus (DISDAIN) that leverages discriminator disagreement.', 'Strong theoretical foundation and clear formulation of the proposed method.', 'Comprehensive empirical validation across diverse environments (grid world and Atari).', 'Demonstrates significant improvements over existing methods in terms of the number of skills learned and downstream task performance.']","['More detailed ablation studies are needed to isolate the contribution of each component of the proposed method.', 'Certain technical aspects, such as the training of the ensemble and the specific implementation details, could be clarified further.', 'The impact of hyperparameter choices on the performance of DISDAIN should be explored in more detail.', 'The computational overhead of training an ensemble of discriminators is not adequately addressed.', 'The comparison with state-of-the-art methods is not comprehensive, making it difficult to gauge the true significance of the contributions.']",4,3,3,4,Accept
HFPTzdwN39,"The paper introduces a novel method for evaluating the interpretability of self-supervised visual representations through quantized reverse probing. This method estimates the mutual information between representation clusters and manually labeled concepts, providing a new measure of semanticity. The paper compares various self-supervised learning methods using this new metric and provides qualitative analyses of the discovered concepts.","['Can the authors provide more details on the autoencoder aggregator and its role in the method?', 'How sensitive are the results to the choice of the number of clusters (K)?', 'Can the authors provide more detailed implementation specifics and training details for the reverse probing mechanism?', 'How does the proposed method perform in ablation studies, specifically when varying the number of clusters and the types of concepts used?', 'Can the authors provide more quantitative analyses to support their claims regarding the interpretability of representations?']","[""The reliance on expert-labeled datasets might limit the method's applicability in some domains."", 'The sensitivity to the choice of the number of clusters (K) needs further discussion.', 'The primary limitation is the complexity and lack of clarity in the presentation of the methodology. Additional quantitative analyses and ablation studies are necessary to validate the proposed method.']",False,3,3,3,6,4,"['Addresses a highly relevant problem in the field of self-supervised learning.', 'Proposes a novel and well-motivated method grounded in information theory.', 'Provides comprehensive experimental results and comparisons with state-of-the-art methods.', 'Includes detailed qualitative analyses that offer insights into the interpretability of representations.']","['Relies heavily on the availability and quality of expert-labeled datasets, which might limit applicability.', 'The methodology section is complex and could benefit from further simplification and clearer explanations.', 'Results might be sensitive to the choice of the number of clusters (K); further discussion on this sensitivity is needed.', 'Additional quantitative analyses and ablation studies are necessary to validate the proposed method.']",4,3,3,3,Reject
EJKLVMB_9T,"The paper introduces a novel regex synthesis framework called SplitRegex that uses neural example splitting to improve the speed and accuracy of synthesizing regular expressions from positive and negative examples. The proposed approach divides the input examples into smaller parts using a neural network and synthesizes subregexes for each part, which are then combined to form the final regex.","['Can you provide more details on the NeuralSplitter architecture and its training process?', 'What is the impact of using different types of aggregators in the framework?', 'How does the performance change if the number of gating parameters in Eq. 10 is reduced by sharing the gate value of each filter in Conv layers?', 'What is the performance of the proposed model on more diverse and complex datasets?', 'Can the authors conduct additional ablation studies to evaluate the impact of different components of the proposed framework?', 'How does the proposed method perform on more diverse and complex real-world datasets?', 'Can the authors provide a more extensive comparison with state-of-the-art regex synthesis methods?', 'What are the potential limitations and ethical considerations of the proposed approach?']","['The potential limitations of the approach, such as its applicability to different types of regexes and the handling of more complex examples, should be discussed.', 'The societal impact of the proposed method, including any potential misuse, should be considered.', 'The paper should address the potential limitations of using a neural network for example splitting, such as overfitting and scalability issues.', 'The impact of the choice of hyperparameters on the performance of the NeuralSplitter model should be discussed.', 'The paper should consider the limitations of the proposed method in handling very large or highly complex regexes.']",False,2,2,2,4,4,"['The divide-and-conquer approach to regex synthesis is novel and addresses the complexity of the problem effectively.', 'The use of a neural network (NeuralSplitter) to split examples into similar substrings is innovative and shows potential for improving synthesis speed.', 'Comprehensive experiments on multiple benchmark datasets demonstrate the effectiveness of the proposed method.', 'The framework can be integrated with existing regex synthesis algorithms, enhancing their performance.']","['The explanation of the NeuralSplitter architecture is somewhat unclear and could benefit from additional details.', 'More ablation studies are needed to validate the individual components of the framework.', 'Potential limitations and negative societal impacts are not thoroughly discussed.', 'The evaluation primarily focuses on synthetic datasets, raising questions about real-world applicability.', 'The paper lacks a detailed comparison with state-of-the-art methods beyond the mentioned baselines.']",3,2,2,3,Reject
MWQCPYSJRN,"The paper introduces Generative Negative Replay (GNR), a novel approach for continual learning that uses generated data as negative examples to mitigate catastrophic forgetting. The method is validated on complex benchmarks like CORe50 and ImageNet-1000, showing significant improvements over traditional generative replay methods.","['Can you provide more details on the training procedure of the generative model and its integration with the classifier?', 'How does the proposed method generalize to other datasets and tasks beyond CORe50 and ImageNet-1000?', 'Have you explored the impact of different generative models on the performance of GNR?', 'Can you provide more details on the computational cost of training the generative model and classifier?', 'How does the quality of generated data affect the performance of the proposed generative negative replay method?', ""Could the authors include more ablation studies to explore the impact of different hyperparameters and alternative architectures on the proposed method's performance?""]","['The main limitation is the potential overfitting to the specific datasets and scenarios tested. Further exploration on generalizability to other tasks and datasets is needed.', 'The clarity of the methodology is another limitation; more detailed explanations are required for better reproducibility.', 'The paper does not thoroughly address the computational cost and efficiency of the proposed method, which could be a significant limitation in practical applications.', 'The quality of generated data is crucial for the effectiveness of the proposed method, but this aspect is not deeply explored in the paper.']",False,3,3,3,6,4,"['Novel approach of using generated data as negative examples, which is a fresh perspective in the continual learning domain.', 'Comprehensive experimental validation on challenging datasets like CORe50 and ImageNet-1000.', 'Thorough ablation study examining the impact of data quality on the proposed method.']","['The clarity of the methodology, particularly the training details of the generative model and its integration with the classifier, could be improved.', 'Potential overfitting to the specific scenarios tested; generalizability to other datasets and tasks is not thoroughly explored.', 'Additional analyses on different types of generative models and their impact on GNR would strengthen the paper.', 'The paper does not thoroughly address the computational cost and efficiency of the proposed method, which could be a significant limitation in practical applications.']",3,3,3,4,Reject
8CEJlHbKoP4,"The paper proposes METAGEN, an unsupervised model that enhances object recognition models through a metacognition inspired by human cognitive processes. It aims to improve detection accuracy by addressing hallucinations and misses using principles known as Spelke principles. The model is tested on synthetic datasets with various state-of-the-art object detection models, showing significant improvements.","['Can the authors provide more detailed explanations of the inference procedure and the implementation of Spelke principles?', 'How does the proposed model perform in a real-world scenario compared to the synthetic dataset used in the experiments?', 'What are the potential limitations and biases of the proposed model, and how can they be addressed?', 'Can the authors include more ablation studies to investigate the impact of different components, such as the choice of priors or the use of Spelke principles?', 'Can the authors provide more details about the autoencoder aggregator?', 'Can the authors provide more qualitative visualizations of the detection improvements?']","['The paper should address the potential biases in the model and the limitations of using synthetic datasets. More insights into the real-world applicability of the model would strengthen the evaluation.', 'The reliance on synthetic datasets limits the generalizability of the results.', 'The paper does not address potential negative societal impacts, such as biases in object detection models.']",False,3,3,3,6,4,"['The idea of incorporating metacognition into object detection is novel and inspired by human cognitive processes.', 'The proposed model, METAGEN, shows promising results in improving detection accuracy and generalizing to out-of-sample data.', 'The use of Spelke principles to guide inference is innovative and provides a strong theoretical foundation.', 'Comprehensive experiments with multiple object detection models provide a solid evaluation framework.']","['The implementation details, especially the inference procedure and the use of Spelke principles, need more clarity and precision.', 'The experimental setup and comparison against baselines must be thoroughly examined to ensure that the improvements are substantial.', 'The paper relies heavily on synthetic datasets, which limits the generalizability of the results to real-world scenarios.', 'More ablation studies are needed to isolate the impact of different components of METAGEN.', 'The limitations and potential negative societal impacts of the work are not adequately addressed.']",3,3,3,4,Reject
WVX0NNVBBkV,The paper explores the use of generative models to improve the robustness of machine learning models against adversarial attacks. It introduces a theoretical framework for understanding the transfer of robustness from proxy distributions to real data distributions and proposes practical methods to incorporate synthetic data into robust training. The ARC metric is proposed to evaluate the effectiveness of different generative models in improving robustness. Extensive experiments across multiple datasets and threat models demonstrate significant improvements in robustness using synthetic data.,"['Can the authors provide more visual aids or explanations to make the theoretical parts clearer?', 'How feasible is the computation of ARC in practical scenarios, especially for large datasets?', 'Have the authors considered evaluating a wider variety of generative models beyond diffusion-based models and GANs?', 'Can the authors provide more insights into the sensitivity of the proposed methods to hyperparameters, especially the choice of γ in PORT?', 'Can the authors provide more detailed explanations and proofs for the ARC metric and its practical applications?', 'How does the computational cost of the proposed method compare to existing methods? Can the authors provide more details on the resources required?', 'Can the authors conduct more comprehensive ablation studies to better understand the effectiveness and limitations of the ARC metric?', 'What are the potential limitations of using synthetic data in robust training, and how might it impact the generalization of models to real-world data?', 'What are the specific hyperparameter settings and random seeds used in the experiments?', 'How does your work compare with concurrent works, such as Rebuffi et al. (2021)?', 'Can you elaborate on the potential societal impacts, both positive and negative, of improving adversarial robustness using synthetic data?', 'Can the authors provide a more detailed breakdown of the computational cost and potential ways to mitigate it?', 'Are there specific scenarios where this approach might fail or be less effective? How can these be identified and addressed?']","['The paper could benefit from additional explanations or visual aids to make the theoretical parts clearer.', 'The feasibility of computing ARC in practical scenarios and the sensitivity of the proposed methods to hyperparameters could be explored in more detail.', 'The paper does not sufficiently address the potential limitations of using synthetic data, such as the impact on the generalization of models to real-world data.', 'The high computational cost is a significant limitation. The authors should discuss potential optimizations or approximations to reduce this cost.', 'The reliance on synthetic data may pose challenges in generalizing to more complex real-world scenarios. The authors should address this concern and suggest ways to mitigate it.']",False,3,3,3,6,4,"['The paper introduces a novel theoretical framework and practical methods for using proxy distributions to improve adversarial robustness.', 'The ARC metric is a valuable contribution that can help in selecting the most effective generative models for robust training.', 'The authors provide a solid theoretical foundation for their approach, including proofs and empirical validations.', 'The paper includes extensive experiments across multiple datasets and threat models, showing significant improvements in robustness using synthetic data.', 'The proposed methods are practical and can be readily applied to improve the robustness of existing machine learning models.']","['The paper is dense and could be clearer in some sections. The theoretical parts, while rigorous, are difficult to follow and may benefit from additional explanations or visual aids.', 'The proofs, especially those related to the ARC metric and its practical applications, are not thoroughly explained and may be difficult for readers to follow.', 'The experimental setup lacks detailed information on the computational cost and resources required, which raises concerns about the reproducibility of the results.', 'The ablation studies related to the ARC metric are not comprehensive enough to fully understand its effectiveness and potential limitations.', 'The paper does not sufficiently discuss the potential limitations of using synthetic data, such as the impact on model generalization to real-world data.']",4,3,3,4,Reject
74x5BXs4bWD,"The paper introduces EDO-CS, an Evolutionary Diversity Optimization algorithm with Clustering-based Selection for Reinforcement Learning. The algorithm aims to generate a set of policies with high quality and diverse behaviors by clustering policies based on their behaviors and selecting high-quality policies from each cluster for reproduction. The proposed method is tested on various continuous control tasks, including deceptive and multi-modal environments, showing superior performance over existing methods.","['Can the authors provide a more detailed explanation of the clustering-based selection mechanism and its theoretical advantages over existing methods?', 'How sensitive is the performance of EDO-CS to the choice of clustering algorithm and the number of clusters (K)?', 'Can the authors include more ablation studies to isolate the impact of individual components of EDO-CS?', 'What are the computational costs associated with the clustering-based selection compared to other selection mechanisms?', 'How does the proposed method scale with the size of the state and action spaces?']","['The paper does not adequately address the limitations of the proposed method, such as computational complexity and potential scalability issues.', 'The potential negative societal impact of the work is not discussed.']",False,3,3,3,5,4,"['The problem of balancing quality and diversity in RL is well-motivated and relevant.', 'The clustering-based selection mechanism is novel and provides a reasonable approach to ensure diversity in the selected policies.', 'Comprehensive experiments are conducted on a variety of tasks, including deceptive and multi-modal environments, which demonstrate the effectiveness of the proposed method.']","['The paper lacks clarity in several key sections, including the detailed algorithmic steps and the experimental setup.', 'The theoretical justification for the clustering-based selection and its advantages over other selection mechanisms is not well-explained.', 'The effect of hyper-parameters and the chosen clustering algorithm on the performance of EDO-CS is not thoroughly investigated.', 'The paper does not provide enough ablation studies to isolate the impact of individual components of EDO-CS.', 'The computational complexity and scalability of the proposed method are not discussed.']",3,3,3,3,Reject
4tOrvK-fFOR,"The paper presents SoundSynp, a novel framework for sound source detection from raw waveforms using multi-scale synperiodic filter banks. The framework aims to achieve high resolution in both time and frequency domains and employs a Transformer-like backbone with two branches for learning semantic identity and spatial location. Experiments on direction of arrival estimation and physical location estimation demonstrate improvements over existing methods.","['Can you provide more detailed implementation specifics, including the initialization parameters for the synperiodic filter bank and the Transformer-like backbone?', 'How do you ensure the reproducibility of your results? Are there plans to release the code and datasets used in your experiments?', 'Can you elaborate on the computational efficiency of your method? Are there potential optimizations to reduce the inference time?', 'Can the authors provide more details on the theoretical basis for the synperiodic filter banks?', 'What are the potential limitations or negative impacts of the proposed method?', 'Can additional ablation studies be conducted to further isolate the contributions of different components, such as the Transformer-like backbone and the synperiodic filter banks?', 'What are the computational requirements and scalability considerations for the proposed method?', 'How does the method perform on datasets other than those used in the paper? Can the authors provide additional validation on different datasets?', 'Can you provide additional insights into the choice of the period ρ and its impact on performance?', 'Could you clarify the detailed construction process of the synperiodic filter bank?', 'How does the complexity of the proposed method impact its practical applicability in real-world scenarios?', 'How does the Transformer-like backbone contribute to the overall performance improvement?', 'Can the authors include more ablation studies to isolate the effects of different components of the proposed architecture?']","['The paper does not adequately address the limitations regarding the computational efficiency and scalability of the proposed method.', 'Potential negative societal impacts of this technology, such as privacy concerns with sound detection, are not discussed.', ""The primary limitations concern the clarity of the method's explanation, computational efficiency, and generalizability across different datasets."", 'The readability could be improved by simplifying the presentation of technical details and adding more intuitive explanations.']",False,3,3,3,6,4,"['The paper addresses an important problem in sound source detection, which has practical applications in numerous fields.', 'The proposed synperiodic filter bank is novel and theoretically well-motivated to handle the time-frequency resolution trade-off.', 'The multi-scale learning approach in both time and frequency domains is innovative and can potentially lead to better sound representations.', 'The experiments include comparisons with state-of-the-art methods and demonstrate significant improvements.']","['The paper lacks clarity in several key sections, particularly in the methodology and implementation details, which makes it difficult to fully understand and reproduce the work.', 'Some aspects of the experimental setup, such as the specific parameters used for baseline methods and detailed dataset descriptions, are missing, leading to concerns about the robustness of the evaluations.', 'The ablation studies, while extensive, could be enhanced by including more detailed analyses on the impact of individual components of the synperiodic filter bank.', 'The computational complexity and inference time reported suggest that the proposed method is significantly slower than existing methods, which could limit its practical applicability.']",4,3,3,4,Reject
xFOyMwWPkz,The paper proposes a method for assessing the status of individual CNN units using a topological-based entropy measure called feature entropy. This measure aims to provide a rescaling-invariant and general indicator of unit effectiveness across different network architectures and training scenarios.,"['Can the authors provide a more detailed and clear explanation of the methodology, particularly the construction of the topological features and the calculation of feature entropy?', 'Have the authors considered other topological invariants or alternative methods for spatial pattern characterization? How do these compare to the chosen method?', 'Can the authors include more recent methods in their comparisons to strengthen the claim of the novelty and effectiveness of their approach?', 'Can the authors provide more detailed explanations and illustrative examples of the key concepts and methods?', 'How does the proposed method perform across different CNN architectures and datasets?', 'Can more recent and relevant baselines be included in the experimental comparisons?', 'Can the authors provide more details about the autoencoder aggregator?', 'Can the authors conduct additional ablation studies on the modulation function and different types of aggregators?', 'Can the authors provide a clearer explanation of the key topological concepts used in the methodology?', 'How does the proposed method compare to other recent methods using topological tools in deep learning?', 'Can the authors provide additional ablation studies and sensitivity analyses to strengthen their claims?', 'Can the authors discuss the computational complexity of their method and its implications for large-scale applications?']","['The current explanation of the methodology makes reproducibility challenging. Including pseudocode or a more detailed algorithmic description could help mitigate this issue.', 'The paper does not discuss the computational complexity of the proposed method, which is important for practical applicability, especially in large-scale networks.', 'The paper needs better clarity and comprehensive experimental validation. The practical utility and robustness of the method across various settings need to be demonstrated.', ""The paper lacks clarity in certain sections, particularly in the description of the autoencoder aggregator. Additional ablation studies are needed to support the claims about the method's robustness."", 'The paper does not clearly differentiate its contributions from existing related work.', 'The practical implications and potential impact of the proposed method are not well articulated.', 'The applicability of the method to other architectures and datasets should be validated.']",False,2,2,2,4,4,"['The paper addresses a practical and important issue in CNN interpretability and optimization: assessing unit status.', 'The proposed feature entropy is novel and theoretically intriguing, leveraging topological data analysis to characterize spatial patterns in feature maps.', 'Comprehensive experiments demonstrate the potential of feature entropy in various scenarios, including rescaling, random initialization, and generalization capability.']","['The methodology section lacks sufficient clarity and detail, making it difficult for readers to fully understand and reproduce the method.', 'The paper does not provide detailed ablation studies on key components such as the choice of topological features and the sensitivity of hyperparameters.', 'Comparisons with more recent and relevant methods in network interpretability and pruning are missing, which weakens the claim of the novelty and effectiveness of the proposed method.', 'The experiments, although extensive, fail to explore the limitations and potential failure cases of the method sufficiently.', 'The practical utility of the method is not well demonstrated.', 'The paper is dense and difficult to follow, particularly in the methodological sections.', 'The significance and practical implications of the proposed method are not well articulated.', 'The paper does not adequately discuss the computational complexity of the proposed method, which is important for practical applicability, especially in large-scale networks.']",3,2,2,3,Reject
gPvB4pdu_Z,The paper proposes a novel compositional training framework for end-to-end deep AUC maximization that integrates robust feature learning and classifier learning. The authors present a provable efficient stochastic optimization algorithm for the proposed compositional objective and validate the approach through extensive experiments on benchmark and medical datasets.,"['Can the authors provide more intuitive explanations and clearer transitions from conventional methods to the proposed compositional approach?', 'Could the authors expand the ablation studies to investigate the impact of various hyperparameters and configurations?', 'Is it possible to include comparisons with more recent methods for imbalanced learning and AUC optimization?', ""Can the authors provide a more detailed explanation of the proposed method's computational efficiency and scalability?"", 'Could the authors discuss potential limitations and societal impacts of their work?']","['The paper could be clearer in explaining the transition from conventional methods to the proposed compositional approach. Additionally, more comprehensive ablation studies and comparisons with recent methods could strengthen the evaluation.', 'The paper does not sufficiently address potential limitations and societal impacts. A more thorough discussion would be beneficial for understanding the broader implications of the work.', 'The complexity of the proposed method may limit its practical applicability.', 'The lack of clarity in some parts of the paper may hinder understanding and implementation by other researchers.', 'The paper needs to provide more details on the sensitivity of hyperparameters. Additionally, more visualization and qualitative analysis of the learned feature representations would strengthen the validation of the proposed method.']",False,3,2,3,6,4,"['The paper introduces a novel compositional training framework for deep AUC maximization, providing a unified approach to robust feature learning and classifier learning.', 'The authors present a provable efficient stochastic optimization algorithm with convergence rates similar to standard SGD.', 'Extensive empirical studies on benchmark and medical datasets demonstrate the effectiveness of the proposed method, showing significant performance improvements.', 'The proposed method is implemented in an open-source library, enhancing reproducibility and accessibility.']","['The paper is dense and could benefit from more intuitive explanations and clearer transitions from conventional methods to the proposed compositional approach.', 'The ablation studies could be expanded to investigate the impact of various hyperparameters and configurations, such as the number of inner gradient steps and different adaptive step size methods.', 'The comparison with more recent methods for imbalanced learning and AUC optimization could provide a more comprehensive evaluation.', 'The clarity and organization of the paper could be improved, especially the mathematical formulations.', 'The paper lacks a thorough discussion of potential limitations and societal impacts.', ""The proposed method's scalability and computational efficiency are not sufficiently discussed.""]",3,3,2,4,Reject
Eot1M5o2Zy,"The paper introduces AestheticNet, an approach to mitigate bias in facial beauty prediction models. It uses a novel architecture, synthetic data generated by GANs, and techniques for balancing biased data. The goal is to achieve fairer aesthetic judgments by reducing biases in training data.","['Can you provide more details on the methodology for debiasing the data?', 'How do you validate the efficacy of the synthetic data used?', 'Can you include more comprehensive evaluation metrics and comparisons with existing methods?', 'How does the proposed method compare with other bias mitigation techniques like re-weighting or adversarial debiasing?', 'Can the authors provide more detailed ablation studies to isolate the effects of each component of AestheticNet?', 'Can you provide more details on the modifications made to the VGG Face architecture for AestheticNet?', 'How are the synthetic GAN-generated images integrated into the training process?', 'What specific statistical methods were used to validate the effectiveness of the proposed bias mitigation techniques?', 'Can the authors provide more detailed explanations and justifications for the design choices in AestheticNet?', 'How does AestheticNet compare to other bias mitigation techniques in terms of computational efficiency and scalability?', 'Can the authors conduct experiments on more diverse datasets to validate the generalizability of their approach?', 'Can you elaborate on the methodology for generating unbiased data using GANs and provide more robust experiments to justify its effectiveness?', 'Can you improve the organization of the paper and provide detailed explanations of key components?', 'Can you explore the ethical considerations in more depth, especially in terms of practical implications and mitigation strategies?']","['The paper does not adequately address the limitations and potential negative societal impacts of its methodology.', 'The authors should include a detailed discussion of the limitations and potential biases introduced by their approach, especially the ethical implications of using synthetic data.', 'The paper should discuss the limitations of using GAN-generated synthetic images and the adjustment of annotation ratios in mitigating bias.', 'A thorough analysis of the potential areas for further research and improvement should be included.', 'The paper needs to address potential limitations in the synthetic data generation process and its impact on model fairness.', 'The paper does not provide enough experimental validation and comparison with existing methods.', 'The methodology for generating unbiased data using GANs is not well-explained or justified with robust experiments.', 'The paper lacks clarity and detailed explanations of key components.', 'The ethical considerations are not deeply explored in terms of practical implications and mitigation strategies.']",True,2,2,2,3,4,"['Addresses an important issue of bias in facial beauty prediction models.', 'Introduces a novel network architecture, AestheticNet.', 'Attempts to use synthetic data to balance biased datasets.']","['The methodology for debiasing data lacks sufficient detail and robustness.', 'Heavy reliance on synthetic data without thorough validation.', 'Evaluation metrics and comparisons with existing methods are not comprehensive.', 'Clarity and presentation are weak, making it difficult to follow the methodology and results.', 'The paper does not adequately address the limitations and potential negative societal impacts of its methodology.', 'Insufficient experimental validation and comparison with existing bias mitigation techniques.', 'Missing detailed explanations of technical components and metrics.', 'The significance of the contribution is limited due to the lack of comprehensive evaluation.', 'The broader applicability of the proposed approach beyond facial beauty prediction is not demonstrated.']",2,2,2,3,Reject
rxF4IN3R2ml,"The paper proposes MQTransformer, an advanced architecture for multi-horizon time series forecasting, incorporating context-dependent and feedback-aware attention mechanisms. The key contributions are a novel positional encoding scheme, horizon-specific decoder-encoder attention, and a decoder self-attention mechanism aimed at reducing forecast volatility. The empirical results show significant improvements over state-of-the-art models on multiple datasets.","['Can the authors provide a more detailed explanation of the positional encoding mechanism and how it compares to existing methods?', 'Could the authors elaborate on the specific contributions of each novel component through more detailed ablation studies?', 'How does the model handle potential limitations, and are there any ethical considerations that need to be addressed?', 'Can you provide more details about the architecture and hyperparameter settings for the proprietary dataset experiments?', 'How does the model handle missing data in the time series?', 'Can you provide more ablation studies focusing on the impact of different positional encodings?', 'What is the performance impact of using different aggregation methods in the attention mechanisms?', 'How do the proposed methods compare with other recent transformer-based approaches in terms of computational efficiency?', 'Are there plans to release the source code to improve reproducibility?']","['The paper should discuss potential limitations such as the scalability of the proposed methods to even larger datasets, and any assumptions that may not hold in different application domains.', 'Ethical considerations, particularly in the context of demand forecasting and its impact on supply chains, should be explicitly addressed.', 'The impact of varying data quality and missing data on forecasting performance is not fully addressed.', 'Proprietary dataset experiments are not fully reproducible due to lack of access to the dataset.', 'The main limitations are related to the clarity of certain architectural details and the potential challenge in reproducing the results without access to the source code.']",False,3,3,3,7,4,"['Addresses a critical problem in time-series forecasting by introducing novel attention mechanisms that enhance context understanding and reduce forecast volatility.', 'The empirical results are robust, showing clear improvements in accuracy and volatility reduction across multiple datasets, including a large-scale e-commerce demand forecasting task.', 'The use of martingale diagnostics to study forecast volatility is innovative and provides a solid theoretical foundation for assessing model performance.']","['The explanation of the positional encoding mechanism and its comparison with existing methods is somewhat lacking in detail.', 'The methodology section could be clearer, particularly in explaining the novel attention mechanisms and their formulations.', 'Although the ablation studies are comprehensive, a deeper analysis of the impact of individual components and their interactions would strengthen the paper.', 'The paper does not adequately address potential limitations and ethical considerations of the proposed approach.', 'Reproducibility is constrained by the inability to release the source code and the lack of transparency in the experimental setup for proprietary datasets.']",3,3,3,4,Reject
jJOjjiZHy3h,"The paper proposes AdversarialAugment (AdA), a method to defend against image corruptions by optimizing image-to-image models to generate adversarially corrupted images. The method is theoretically motivated, and empirical results show significant improvements on common image corruption benchmarks (CIFAR-10-C and IMAGENET-C) and adversarial perturbations. The paper also compares AdA with state-of-the-art methods like AugMix and DeepAugment, achieving better robustness.","['Can the authors provide more detailed explanations or visual aids to enhance the clarity of the methodology?', 'How feasible is the proposed method in resource-constrained environments, considering its computational demands?', 'Can additional ablation studies be provided to further validate the method’s robustness and performance?', ""What are the limitations of the current image-to-image models used, and how might they impact the method's generalizability?"", 'Can the authors clarify the SSIM line-search procedure and provide more details about its implementation and impact on the results?', 'How does AdA compare with other recent methods such as Diffenderfer et al. (2021) and Kireev et al. (2021)?', 'Can the authors provide more practical insights and implications of the theoretical analysis?', 'Can the authors provide more details about the autoencoder aggregator and its role in the method?', 'How does the performance of the proposed model change with different choices of modulating functions and aggregators?', 'Can the authors include more qualitative examples of the adversarially corrupted images generated by AdA?', 'How can the computational complexity of the method be reduced for practical applications?', ""Is there a way to mitigate the method's heavy reliance on pre-trained image-to-image models?"", 'Can the authors provide more details on the computational and memory requirements of AdA compared to other methods?', 'How does the performance of AdA change with different values of the perturbation radius ν?', 'Can the authors clarify the details of the approximate SSIM line-search procedure and its impact on the robustness of the model?']","['The authors have addressed some limitations and potential societal impacts, but the computational feasibility and resource requirements need more detailed discussion.', 'The paper acknowledges the computational complexity and dependence on pre-trained models but does not offer thorough solutions to these limitations. Further discussions on these aspects would be beneficial.']",False,3,3,3,7,4,"['Addresses both common image corruptions and adversarial attacks, bridging a gap between these two areas of robustness research.', ""Comprehensive theoretical motivation and sufficient conditions for consistency are provided, enhancing the paper's credibility."", 'Extensive empirical results demonstrate significant improvements over existing methods on multiple benchmarks.', 'Leverages multiple pre-trained image-to-image models, showing versatility and robustness in different contexts.']","['The clarity of the presentation is lacking, particularly in the explanation of the SSIM line-search procedure and the experimental setup.', ""The method's computational complexity is high compared to other data augmentation methods, and this is not thoroughly addressed in the limitations."", 'The approach relies heavily on pre-trained image-to-image models, which might limit applicability across different domains.', 'Certain ablation studies and sensitivity analyses, such as varying the number of inner optimization steps and perturbation radius, although included, could be more detailed to provide deeper insights.']",3,3,3,4,Reject
Jjcv9MTqhcq,"The paper introduces a novel supervised pre-training method called Leave-One-Out K-Nearest-Neighbor (LOOK) to improve downstream transferability by preserving intra-class semantic differences. LOOK employs a kNN classifier during pre-training, which allows for multi-modal class distributions, avoiding the overfitting problem seen with traditional supervised methods. Extensive empirical validation shows that LOOK outperforms state-of-the-art supervised and self-supervised pre-training methods on various downstream tasks.","['Can you provide more details on the autoencoder aggregator and its role in the proposed method?', 'Can you include more qualitative analyses, such as visualizations of feature distributions learned by LOOK compared to other methods?', 'What is the impact of varying hyperparameters (e.g., queue size, momentum, number of neighbors) on the performance of the proposed method?', 'Can the authors provide more details on the implementation of the projector-predictor module and the memory bank mechanism?', 'What are the potential limitations of the proposed method in terms of computational complexity and sensitivity to hyper-parameters?', 'Could the authors provide more details on the scalability of LOOK to extremely large datasets?', 'Can the authors provide a more detailed theoretical analysis or formal grounding for the proposed method to complement the empirical results?']","['The paper could benefit from more detailed ablation studies to further understand the impact of different hyperparameters and components of the proposed method.', 'The scalability of the method to extremely large datasets might be a concern, and this could be addressed more thoroughly.', 'The reliance on empirical results without sufficient theoretical grounding or formal analysis may limit the generalizability and robustness of the conclusions.']",False,3,3,4,7,4,"['Addresses the significant issue of overfitting to upstream tasks in supervised pre-training.', 'Proposes a novel and theoretically well-motivated method leveraging kNN to preserve intra-class semantic differences.', 'Extensive empirical validation across multiple datasets and tasks supports the claims of improved transferability and generalization.', 'The methodology section is detailed and well-organized, providing clarity on the implementation and training procedures.']","['The implementation details, particularly regarding the autoencoder aggregator, projector-predictor, and memory bank mechanisms, are not clearly explained and could benefit from additional clarification.', 'The paper could benefit from more detailed ablation studies to further understand the impact of different hyperparameters and components of the proposed method.', 'Scalability and computational complexity issues are not thoroughly addressed, especially for very large datasets.', 'The paper heavily relies on empirical results without providing sufficient theoretical grounding or formal analysis.']",4,3,3,4,Accept
9jsZiUgkCZP,"The paper proposes a unified framework for compressing Vision Transformers (ViTs) by integrating pruning, layer skipping, and knowledge distillation into an end-to-end constrained optimization problem. The method is evaluated on several ViT variants using the ImageNet dataset, showing superior performance compared to existing methods.","['Can the authors provide more details on the implementation and reproducibility of the proposed UVC framework?', 'How does the choice of hyperparameters affect the performance of UVC, and what guidelines can be provided for setting these hyperparameters?', 'Could the authors provide a more detailed analysis of the individual contributions of pruning, skipping, and distillation to the overall performance gains?', 'How does UVC perform on other types of neural networks beyond Vision Transformers?', 'Can you provide a more detailed explanation of the primal-dual optimization process?', 'How does the proposed method handle different datasets, and are there any specific challenges associated with different types of data?', 'Could you elaborate on the potential limitations of your approach?', 'Could the authors provide more details on the autoencoder aggregator used in the framework?', 'Would it be possible to provide more qualitative analyses and visualizations to better illustrate the impact of the method on the model architecture?']","['The complexity and multi-component nature of UVC might hinder its reproducibility.', 'The paper does not discuss potential negative societal impacts or limitations related to specific use cases of compressed ViTs.', 'The major concern is the clarity of the paper and the need for additional ablation studies to fully understand the contribution of each component of the proposed method.']",False,3,2,3,5,4,"['Addresses a significant issue of resource efficiency in deploying ViTs.', 'Novel integration of multiple compression strategies into a unified framework.', 'Rigorous mathematical formulation using constrained optimization and primal-dual algorithm.', 'Extensive experimental validation on popular ViT variants with strong empirical support.']","['Complexity of the proposed method might hinder reproducibility.', 'Limited ablation studies on the individual contributions of each compression component.', 'Lacks deeper discussion on comparative performance with other methods.', 'Focuses solely on ViTs without discussing applicability to other neural networks.', 'The methodology section is dense and may be difficult to follow for readers who are not experts in the field.', 'The paper does not discuss potential negative societal impacts or limitations related to specific use cases of compressed ViTs.']",3,3,2,3,Reject
Ve0Wth3ptT_,"The paper introduces DEGREE, a decomposition-based explanation method for Graph Neural Networks (GNNs). DEGREE decomposes the information flow in GNNs to measure the contribution of specific input components to the final prediction, thereby enhancing interpretability. The method is evaluated on both synthetic and real-world datasets, demonstrating its effectiveness in providing faithful explanations for node and graph classification tasks.","['Can the authors provide more details on the decomposition process, particularly for the different types of GNN layers?', 'What is the impact of different aggregation algorithms on the performance of DEGREE?', 'Can the authors include additional qualitative examples to better illustrate the effectiveness of the proposed method?', 'Can you provide more intuitive explanations and examples for the decomposition process of different GNN layers?', 'Can you include more datasets in the experiments to validate the generalizability of the proposed method?', 'Can you compare the proposed method against more baseline methods to provide a comprehensive evaluation?', 'What is the impact of different hyperparameters on the performance of DEGREE? Can the authors provide more ablation studies to illustrate this?', 'How does DEGREE scale with very large graphs in terms of computational complexity and runtime?', 'Can the authors provide more detailed explanations or examples for the attention decomposition step?', 'What are the computational complexity and scalability considerations for the method when applied to very large graphs?', 'Can you provide more details about the autoencoder aggregator?', 'Can you include additional ablation studies to validate the contribution of each component of DEGREE?', 'Can you provide more visualizations in the qualitative analysis to strengthen your claims?']","['The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the proposed method. It would be beneficial to address these aspects, especially considering the implications of interpretability in sensitive applications.', 'The authors should discuss the limitations of their method in more detail, particularly regarding its scalability to large graphs and potential computational overhead.', 'The potential negative societal impact of the work is not addressed. Given that explainable AI can have significant implications, it would be beneficial to include a discussion on this topic.']",False,3,3,3,5,4,"['The paper addresses a significant problem in the interpretability of GNNs, which is crucial for their wider applicability.', 'The proposed decomposition-based approach is novel and provides a clear methodology for tracking the contributions of individual components in the input graph.', 'Comprehensive experiments on synthetic and real-world datasets validate the effectiveness of the proposed method.', 'The paper includes both qualitative and quantitative analyses, providing a well-rounded evaluation of the method.', 'The subgraph-level explanation approach is particularly interesting and useful for capturing complex interactions between graph nodes.']","['The clarity of the paper is lacking in some sections, particularly in the detailed explanation of the decomposition process and the aggregation algorithm.', 'The paper does not provide sufficient ablation studies to isolate the impact of each component of the proposed method.', 'The qualitative analysis, while insightful, relies on a limited number of examples. More cases would strengthen the validation of the method.', 'The comparison with other state-of-the-art methods could be more extensive, including a more detailed discussion on the differences and potential advantages of DEGREE over existing methods.', 'Potential scalability concerns: The paper does not sufficiently address the scalability of the proposed method to very large graphs, which is a critical aspect for practical applications.', 'The evaluation mainly focuses on accuracy and qualitative results. More discussion on computational complexity and comparison with other methods in terms of efficiency would strengthen the paper.']",3,3,3,3,Reject
aYSlxlHKEA,"The paper proposes a decentralized model-based reinforcement learning algorithm named DMPO for networked multi-agent systems. The algorithm uses localized models, decentralized policy optimization with extended value functions, and branched rollouts to address sample efficiency and scalability. Theoretical analysis ensures monotonic policy improvement and bounds performance discrepancy caused by model usage. Empirical results demonstrate improved sample efficiency and competitive asymptotic performance against model-free methods in traffic control environments.","['Can the authors provide more details on the hyperparameter settings and the training process?', 'How does the algorithm perform compared to other state-of-the-art multi-agent RL algorithms in more diverse environments?', 'Can the authors include more ablation studies to highlight the contributions of different components of the proposed algorithm?', 'Can the authors provide more detailed ablation studies to isolate the impact of different components of DMPO, such as the extended value function and model usage probability?', 'Could the authors include additional discussion on the potential limitations and societal impacts of their approach?', 'Can the authors provide more details on the implementation of the decentralized predictive model using graph convolutional networks?', 'What are the communication costs associated with the proposed method, and how do they impact the overall performance?']","['The paper does not discuss potential limitations or negative societal impacts of the proposed algorithm. It would be beneficial to address these aspects to provide a more balanced view.', ""The local models' assumption might not hold in all networked systems, which could limit the algorithm's applicability."", 'The paper lacks a detailed discussion on the potential limitations and societal impacts of the proposed DMPO algorithm. Addressing this could provide a more balanced view of its applicability and risks.', 'The paper does not adequately address the communication costs and their impact on the performance of the decentralized method.']",False,3,2,3,5,4,"['Addresses an important and practical problem in multi-agent reinforcement learning, focusing on scalability and sample efficiency.', 'The proposed DMPO algorithm is novel, combining localized models, decentralized policy optimization, and branched rollouts in a practical and effective manner.', 'Strong theoretical contributions, including performance bounds and conditions for monotonic policy improvement, are provided, enhancing the robustness and reliability of the proposed approach.', 'Empirical validation in various traffic control environments shows that DMPO improves sample efficiency and achieves competitive asymptotic performance compared to state-of-the-art methods.']","['The clarity of the paper could be improved, particularly in the explanation of the theoretical analysis and the detailed workings of the localized model and extended value function.', 'Some experimental details are missing, such as hyperparameter settings and more extensive comparisons with other baseline algorithms.', 'The paper could benefit from additional ablation studies to isolate the contributions of different components of the algorithm, such as the localized model and the extended value function.', 'The experimental setup could be more comprehensive, including more diverse environments and baselines to strengthen the empirical validation.', 'Limited discussion on potential limitations or negative societal impacts of the proposed approach, which is important for a comprehensive evaluation.']",3,3,2,3,Reject
buSCIu6izBY,"The paper proposes a novel reinforcement learning method called Maximal Credit Assignment Occupancy (MaCAO) that aims to enhance exploration by matching rewards to occupancy probabilities using a variational formulation. The method is implemented in an actor-critic setup and tested on several RL benchmarks, showing promising results compared to existing methods like SAC and PPO.","['Can the authors provide ablation studies to isolate the impact of key components, such as the MaCAO regularizer?', 'How does the proposed method compare to existing methods in terms of computational complexity and training time?', 'Can the authors clarify the theoretical exposition and provide more intuitive explanations for the core contributions?', 'How do you estimate the occupancy distribution in practice? Are there any specific techniques or heuristics used?', 'Can you elaborate on the choice of hyperparameters and their impact on the performance of the proposed method?', 'Can the authors provide more intuitive explanations and diagrams to help readers understand the theoretical concepts?', 'How does the proposed method perform on a wider range of RL benchmarks?', 'Can the authors clarify the implementation details to better understand the reproducibility of the method?', 'Can the authors discuss the potential limitations of applying MaCAO to more complex environments or real-world scenarios?', 'Can the authors provide more details on the evaluation metrics used to measure sampling efficiency?']","[""The paper's clarity is a major limitation. The dense theoretical exposition and lack of intuitive explanations make it hard to follow."", 'The empirical results need to be more compelling to clearly demonstrate the advantages of the proposed method over existing methods.', 'The paper does not thoroughly discuss the potential computational overhead and scalability of the proposed method.', 'The scope of experimental benchmarks is limited, raising concerns about the generalizability of the proposed method.', 'The complexity and density of the paper make it difficult to follow, and additional clarity in explanations would be beneficial.']",False,3,2,3,5,4,"['The paper addresses a crucial problem in reinforcement learning: the exploration-exploitation trade-off.', 'The proposed MaCAO method introduces a novel way to match rewards to occupancy probabilities, potentially enhancing exploration.', 'The theoretical foundations are strong, providing a rigorous variational inference perspective on the proposed method.', 'The method is evaluated on several RL benchmarks, showing promising results.']","['The theoretical exposition is dense and challenging to follow, making it difficult to understand the core contributions without significant effort.', 'The empirical results, while promising, do not clearly demonstrate the claimed advantages over existing methods. The performance improvements in some tasks are not substantial.', 'The paper lacks ablation studies to isolate the impact of key components of the proposed method.', 'There are concerns about the clarity and organization of the methodology section. Important details are buried in dense mathematical formulations, making it hard to follow.', 'Limited details about the implementation, especially concerning the estimation of the occupancy distribution and the choice of hyperparameters.']",4,3,2,3,Reject
CC-BbehJKTe,The paper addresses the issue of program bloat in Genetic Programming (GP) and introduces a new concept termed 'winning trees' to improve the GP process. It proposes a combination of deterministic and heuristic simplification techniques to reduce the complexity of GP solutions and explores the use of winning trees to initialize the population for subsequent GP runs. The approach is validated through experiments on synthetic and real-world symbolic regression problems.,"['Can the authors provide more details on the exact and heuristic simplification methods?', 'What is the impact of each component of the proposed methodology? Could additional ablation studies be conducted?', 'Can the authors provide more cases and visualizations to support the qualitative analysis?', 'How does the approach compare to other state-of-the-art GP simplification techniques in more diverse and larger datasets?', 'Can the authors perform additional ablation studies to isolate the effects of different components of their approach?', 'Can the authors provide a more detailed explanation of the winning tree identification process?', 'How do the authors address the potential overfitting observed in the real-world datasets?', 'Can the authors provide more comprehensive experiments to validate the effectiveness of winning trees?', ""How are the 'winning trees' selected, and can the selection criteria be better justified?"", 'Can you provide more theoretical insights into why winning trees should outperform random initialization?', 'How sensitive are the results to the chosen pruning threshold of 15%?', 'Can you elaborate more on the details of the Compare-Match algorithm used for simplification?', 'What are the potential limitations and negative societal impacts of your approach?']","[""The paper's clarity needs improvement, especially regarding the simplification methods."", 'The mixed results suggest that the proposed approach may not be universally applicable.', 'The pruning process needs clearer explanation and justification.', 'The impact of the proposed method is not fully clear without comparisons to other state-of-the-art techniques.', 'The main limitation is the insufficient experimental validation and unclear methodology, which undermine the robustness of the presented approach.', ""The concept of 'winning trees' seems somewhat arbitrary, and the selection criteria for these trees could be better justified."", 'The authors have not fully explored and discussed the limitations of their approach.']",False,2,2,2,4,4,"['The concept of winning trees is novel and introduces a new perspective on building blocks in GP.', 'The combination of deterministic and heuristic simplification methods is interesting and can effectively reduce the complexity of GP solutions.', 'The paper provides comprehensive experiments, covering both synthetic and real-world datasets, to validate the proposed approach.']","['The exact and heuristic simplification methods are not clearly explained, which makes it difficult to fully understand the methodology.', 'The results are mixed, especially for smaller tree depths, raising questions about the robustness and general applicability of the proposed approach.', 'The originality is somewhat limited as it builds on existing simplification techniques without a strong differentiation.', 'Insufficient experimental results and analysis to robustly support the effectiveness of winning trees.', ""The selection criteria for 'winning trees' seems arbitrary and could be better justified."", 'Some sections could benefit from more detailed explanations.']",3,2,2,2,Reject
AUszBTiYBB6,"The paper proposes a new aggregation rule, Tmean(·), for federated learning to enhance robustness against Byzantine attacks. The aggregation rule trims a portion of the data before averaging, which is claimed to improve resilience. The paper includes theoretical analysis and experimental validation to support its claims.","['Can you provide more detailed explanations and clearer organization of the theoretical proofs?', 'Can you conduct more extensive experiments, possibly on more complex datasets or real-world federated learning scenarios?', 'How does Tmean(·) perform in non-convex optimization settings?', 'Can the authors provide a more detailed comparison with other state-of-the-art aggregation methods for Byzantine-resilient federated learning?', 'Can the authors elaborate on the choice of parameters for the experiments and provide more details on the experimental setup?', 'Can the authors conduct additional ablation studies to understand the impact of different components of the Tmean(·) aggregation rule?', 'Can the authors provide a clearer explanation and more details about the autoencoder aggregator?', 'Have the authors considered a wider range of scenarios and trim values in their experiments?', 'Can the authors discuss the potential negative societal impacts and ethical considerations of deploying this framework?']","['The paper does not adequately address the limitations of the proposed method, such as its applicability to non-convex problems and its performance under different types of Byzantine attacks.', 'The paper does not provide a thorough comparison with other state-of-the-art methods.', 'The explanation of the experimental setup and results is not detailed enough.', 'The paper does not clearly explain the autoencoder aggregator, which is crucial for understanding the proposed method.', 'The experiments do not cover a wide enough range of scenarios and trim values that could further validate the approach.', 'There is no discussion on the potential negative societal impacts and ethical considerations of deploying such a framework.']",False,2,2,2,3,4,"['Addresses a significant problem in federated learning: robustness against Byzantine attacks.', 'Proposes a novel aggregation rule, Tmean(·), which is theoretically shown to be more resilient to Byzantine attacks compared to traditional methods.', 'Provides theoretical proofs for the robustness and convergence of the proposed method.']","['The clarity of the paper is subpar, with many sections difficult to follow due to poor organization and unclear explanations, particularly the mathematical derivations and proofs.', 'The experimental validation is limited, with experiments conducted only on MNIST and CIFAR10 datasets, which are not sufficient to demonstrate robustness and scalability in more complex real-world scenarios.', 'The application of Tmean(·) in non-convex settings is not explored, limiting the generalizability of the method.', 'The comparison with existing methods like Krum(·) and Mean(·) is not thoroughly analyzed, and the results are not compelling enough to clearly show the superiority of Tmean(·).', 'Figures and tables are not well integrated into the text, making it hard to interpret the results in context.', 'The explanation of the autoencoder aggregator is unclear, making it difficult to fully understand and reproduce the proposed method.', 'The paper lacks a discussion on the potential negative societal impacts and ethical considerations of deploying such a framework in real-world scenarios.']",3,2,2,3,Reject
7gWSJrP3opB,"The paper provides a generalized framework for analyzing the impact of example-selection strategies on SGD convergence rates. The authors introduce the average gradient error condition, which unifies various example-selection strategies such as shuffle once, random reshuffling, and QMC-based data augmentation under a single theoretical framework. They also propose two new example-selection methods that demonstrate improved convergence rates both theoretically and empirically.","['Can the authors provide more details on the experimental setup for the empirical results?', 'What are the practical implications of the assumptions made in the theoretical analysis?', 'How might the proposed methods perform in real-world scenarios with noisy and large-scale data?', 'Can the authors provide more statistically rigorous results to support their empirical findings?', 'Can the authors provide more detailed explanations and justifications for the bounded gradient error assumption?']","['The assumptions made for the theoretical results are strong and might not always hold in practice.', 'The paper should discuss the practical implications of these assumptions and how they might be relaxed.', 'The potential computational overhead and scalability issues of the proposed methods are not discussed.']",False,3,3,3,6,4,"['The proposed average gradient error condition is a novel way to unify various example-selection strategies under a single theoretical framework.', 'The paper is technically sound with rigorous theoretical proofs and well-designed experiments.', 'The paper addresses an important problem in SGD by providing a general framework for analyzing example-selection methods.', 'The proposed condition on example gradients is novel and extends existing results.']","['The assumptions made in the theoretical analysis are strong and might not always hold in practice.', 'The clarity of the explanations, particularly in the theoretical sections, could be improved.', 'The empirical results need more detail and clarity, particularly regarding the experimental setup.', 'Some sections, especially the proofs, are difficult to follow and could be more accessible.']",3,3,3,4,Reject
04pGUg0-pdZ,The paper presents a decentralized multi-agent reinforcement learning (MARL) algorithm designed to maximize global average rewards. It introduces a novel approach with finite-time convergence guarantees and establishes sample complexity bounds that match state-of-the-art single-agent actor-critic methods.,"['Can you provide more details on the potential implications of the assumptions made in the paper and possible ways to relax these assumptions?', 'Could you include more experimental results with additional baselines and different environments to better understand the performance of the proposed algorithm?', 'Can the authors provide practical experiments to validate the theoretical claims?', 'How do the key assumptions hold in real-world applications, and what are the potential limitations?', 'Can the authors improve the clarity of the technical details and assumptions?', 'Please clarify some of the notations and theoretical steps which are not well-explained in the paper.', 'Can the authors provide more intuitive explanations or visualizations for the theoretical results?', 'What are the practical implications and potential applications of the proposed algorithm?', 'Could more comparisons to recent work be included, especially those addressing similar MARL problems?']","['The paper makes several assumptions that could be restrictive in practice. It would be beneficial to discuss the implications of these assumptions in more detail and explore potential relaxations.', 'Lack of real-world experiments limits the understanding of the practical impact and robustness of the proposed method.', 'The paper should discuss in more detail the limitations of the proposed method, particularly in terms of scalability and potential negative societal impacts.']",False,2,2,3,4,4,"['The paper addresses an important problem in MARL, particularly focusing on decentralized settings without joint action knowledge.', 'It proposes a novel algorithm with finite-time convergence proofs and sample complexity bounds, enhancing the theoretical understanding of MARL.', 'The approach is well-motivated, and the authors provide a detailed comparison with related works.']","['The paper is dense and could benefit from a clearer presentation, particularly in the theoretical sections. Some of the proofs are quite complex and could be simplified or moved to an appendix.', ""While the experiments show promising results, the evaluation could be more comprehensive. Including more baselines and different environments would provide a better understanding of the algorithm's performance."", 'The paper makes several assumptions that could be restrictive in practice. It would be beneficial to discuss the implications of these assumptions in more detail and explore potential relaxations.', 'Comparisons with other relevant MARL methods are limited, and more comprehensive experimental analysis is needed.']",3,2,2,3,Reject
B2pZkS2urk_,"The paper proposes a novel meta-learning framework named Evolutionary Plastic Recurrent Neural Networks (EPRNN), which combines evolutionary strategies, plasticity rules, and recursion-based learning to improve task generalization. Inspired by Biological Neural Networks, the framework aims to simulate natural evolution and learning mechanisms. The authors validate their approach with extensive experiments in sequence prediction and robot navigation tasks.","['Can the authors provide a detailed explanation of the autoencoder aggregator?', 'What is the impact of the neuron modulator on the performance of the proposed method?', 'How does the proposed method compare with other gradient-based methods not included in the experiments?', 'Can the authors provide more detailed explanations of the neuron modulator and plasticity rules?', 'Are there additional ablation studies that can be conducted to better understand the contributions of each component of EPRNN?', ""Can the authors provide more qualitative analysis or additional visualizations to better illustrate the model's behavior and performance?"", 'Can the authors provide a comparison to more sophisticated gradient-based methods, such as differentiable plasticity?', 'How does EPRNN perform on more complex and real-world tasks?', 'Can the authors conduct ablation studies to analyze the impact of the neuron modulator?', 'Can you provide more theoretical justification for the design choices made in the proposed framework?', 'Can you clarify the role and implementation of the neuron modulator in the plasticity rule?', 'Can you include more detailed ablation studies to isolate the contributions of each component of the proposed method?']","['The paper does not sufficiently address the impact of the neuron modulator and other critical components.', 'The main limitations include the need for more detailed explanations of key components and additional ablation studies to validate the contributions of each part of the proposed method.', 'The paper primarily evaluates EPRNN on simple and synthetic tasks, which may not fully showcase its potential.', 'There is a need for more detailed ablation studies to understand the contributions of different components, especially the neuron modulator.', 'The paper lacks detailed explanations and justifications for some design choices, which affects its clarity and perceived quality. Additionally, more thorough ablation studies and comparisons with other baselines are needed.', 'The potential negative societal impact of the proposed method is not discussed.']",False,2,2,2,4,4,"['The paper tackles an important problem of task generalization in meta-learning.', 'The proposed combination of evolutionary strategies, plasticity, and recursion-based learning is novel.', 'Extensive experiments are conducted to validate the approach.']","['The clarity and organization of the paper need significant improvement.', 'Some parts of the methodology, such as the autoencoder aggregator and neuron modulator effects, are not well-explained.', 'The paper lacks comparisons with more gradient-based methods, which could provide a broader assessment.', 'The novelty is interesting, but the explanations and experimental diversity could be enhanced.', 'There is a lack of ablation studies to thoroughly investigate the contribution of each component of the proposed method.', 'The theoretical backing for some design choices is lacking.']",3,2,2,3,Reject
iMqTLyfwnOO,"The paper introduces Augmented Sliced Wasserstein Distances (ASWDs), a new family of distance metrics that leverage neural networks to project data onto higher-dimensional hypersurfaces. This aims to improve the projection efficiency of traditional Sliced Wasserstein Distances (SWDs) by capturing complex data structures through nonlinear projections. The authors provide theoretical foundations proving the ASWD as a valid metric and demonstrate its superiority over other Wasserstein variants through extensive experiments.","['Can the authors provide more insights into the computational cost and efficiency of the ASWDs, particularly in comparison with other methods in practical settings?', 'Are there specific applications or scenarios where the ASWDs perform significantly better or worse than other methods?', 'How sensitive is the performance of ASWD to the choice of neural network architecture? Can the authors provide some insights or experiments on this?', 'Can the authors provide more intuitive explanations for the mathematical concepts introduced?', 'Can the authors clarify the implementation details to ensure reproducibility?']","['The primary limitation is the potential computational cost due to the use of neural networks. The authors should address this concern by providing a detailed analysis of the computational requirements.', 'The paper does not sufficiently discuss potential limitations like increased computational complexity due to the use of neural networks. A more detailed analysis of these aspects would be beneficial.', 'The paper does not address potential negative societal impacts or ethical concerns, which is crucial for such impactful research.']",False,3,3,3,6,4,"['The introduction of ASWDs is a novel contribution that advances the state of the art in sliced Wasserstein distances.', 'Theoretical rigor is demonstrated through comprehensive proofs validating ASWDs as metrics.', 'Empirical experiments on synthetic and real-world datasets show the superiority of ASWDs over existing methods.', 'The method is versatile and applicable to various tasks, including generative modeling, color transferring, and Wasserstein barycenters.']","['The complexity of the approach, particularly the reliance on neural networks, may limit its practical applicability in some settings.', 'The paper is dense with theoretical content, making it challenging to follow for readers not well-versed in optimal transport and neural network theory.', 'Despite claims of computational efficiency, the reliance on neural networks and the optimization process could still be resource-intensive.', 'The paper lacks a detailed discussion on the potential societal impacts of using ASWD, particularly in sensitive applications.', 'Implementation details are not sufficiently clear, which may hinder reproducibility.']",3,3,3,4,Accept
yx_uIzoHJv,"The paper proposes a method to induce compositionality in emergent languages by incorporating a topological similarity metric into the loss function of neural agents. The approach aims to improve generalization, convergence speed, and transmission efficiency without requiring additional training phases or supervision. The method is tested on various configurations of a reconstruction game involving neural agents.","['Can you provide more details on the autoencoder aggregator used?', 'Have you considered different modulation functions and aggregators in your experiments?', 'Can you provide additional visualizations to support your qualitative analysis?', 'Can the authors clarify how the experiments were conducted and ensure the results are reproducible?', 'Could you investigate and discuss more about the configurations where the method did not improve or worsened performance?']","['The paper needs to address the clarity of certain components and provide additional ablation studies for a more comprehensive evaluation of the proposed method.', 'The robustness and reproducibility of the results are concerns that need to be addressed.', 'A deeper investigation into failure cases and the combination with other regularization techniques would strengthen the paper.']",False,3,3,3,5,4,"['The problem addressed—enhancing compositionality in emergent languages—is significant and practical.', 'The proposed method of incorporating compositional pressure into the loss function is novel and straightforward.', 'The paper provides a range of experiments to validate the proposed method and investigates the relationship between compositionality and generalization.']","['The paper lacks clarity in some sections, particularly in the explanation of the autoencoder aggregator and certain experimental setups.', 'There are missing ablation studies, such as the impact of different modulation functions and aggregators, which could strengthen the validity of the findings.', 'The qualitative analysis is limited to a few visualizations, and additional cases would make the results more convincing.', 'The impact of the compositional pressure is not consistently positive across all configurations.', 'Concerns about the robustness of the experimental setup and whether the results are reproducible.']",3,3,3,3,Reject
4pijrj4H_B,The paper addresses the issue of fairness in node representation learning using Graph Neural Networks (GNNs). The authors propose an adaptive data augmentation framework to mitigate bias in the learned representations. The paper provides a theoretical analysis of the sources of bias and introduces augmentation schemes to reduce them. Empirical results on node classification and link prediction tasks demonstrate the effectiveness of the proposed method.,"['Can you provide more detailed ablation studies and sensitivity analyses to better understand the impact of each component of the proposed framework?', 'How do the hyperparameter choices affect the fairness and accuracy of the model?', 'Can you provide more intuitive explanations for the theoretical analysis to make it accessible to a broader audience?', 'How would the proposed method improve fairness in practical, real-world scenarios? Can you provide concrete examples?', 'Can you provide more details about the autoencoder aggregator used in the experiments?', 'Can you provide more case studies and visualizations in the qualitative analysis section?', 'How do different hyperparameter settings and alternative choices for the augmentation techniques affect the results? Can you provide more comprehensive ablation studies?', 'How do your methods compare with non-contrastive fairness-aware approaches in terms of both fairness and utility?', 'Can the authors provide more details on the implementation of the proposed methods, particularly the hyperparameter settings and the specific steps involved in the augmentation schemes?', 'What are the potential negative impacts and limitations of the proposed methods?']","['The paper lacks in-depth empirical validation of the proposed method. More detailed ablation studies and sensitivity analyses are needed.', 'The theoretical parts of the paper are dense and could benefit from more intuitive explanations.', 'The impact of the proposed method on real-world applications is not well-argued.', 'The paper does not adequately discuss the potential negative impacts and limitations of the proposed methods. It would be helpful to understand the scenarios in which the methods may not perform well or could introduce new biases.']",False,3,3,3,6,4,"['Addresses an important and under-explored issue of fairness in GNNs.', 'Proposes a novel adaptive data augmentation framework.', 'Provides a thorough theoretical analysis of the sources of bias.', 'Demonstrates effectiveness through empirical results on real-world datasets.']","['The clarity of the theoretical analysis and the detailed workings of the proposed augmentation techniques could be improved.', 'The empirical results, while promising, are not deeply analyzed. More ablation studies and sensitivity analyses are needed.', 'Certain sections of the paper, particularly the theoretical parts, are dense and could benefit from more intuitive explanations.', 'The impact of the proposed method on real-world applications could be better argued.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed methods.']",3,3,3,3,Reject
vh-0sUt8HlG,"The paper introduces MobileViT, a novel vision transformer that combines the strengths of CNNs and ViTs to create a lightweight, low-latency, and general-purpose model for mobile vision tasks. The MobileViT block replaces local processing in convolutions with global processing using transformers, resulting in improved performance across various tasks and datasets. The paper presents extensive experimental results, including comparisons with state-of-the-art models, ablation studies, and practical evaluations on mobile devices.","['Can the authors provide more detailed explanations and visual aids for the MobileViT block and overall architecture?', 'Can the authors include more detailed ablation studies to further validate the contributions of individual components?', ""Have the authors considered the impact of varying the number of transformer layers and their dimensions on the MobileViT model's performance and efficiency?"", 'Can you provide more theoretical justification for the choice of patch sizes?', 'What are the potential limitations and failure cases of MobileViT?', 'Could the multi-scale sampler be explained in more detail, possibly with a visual aid?']","['The clarity of the paper could be improved, especially in the sections detailing the architecture and methods.', 'More detailed ablation studies could strengthen the validation of the proposed approach.', 'The paper should clearly state the limitations of the proposed approach, particularly regarding the potential computational overhead introduced by the transformer layers.', 'The impact of the model on devices other than iPhone 12 should be discussed to generalize the findings.', 'The paper lacks a thorough discussion on the limitations and potential negative societal impacts of MobileViT.']",False,3,3,4,7,4,"['Addresses a significant gap in the literature by combining CNNs and ViTs for mobile vision tasks.', 'The proposed MobileViT block is a novel approach that effectively combines local and global processing.', 'Extensive experimental results demonstrate the superiority of MobileViT over existing models in terms of accuracy and efficiency.', 'Practical evaluations on mobile devices, which is important for real-world applications.']","['Some sections, especially the detailed architecture and methods, could benefit from clearer explanations and visual aids.', 'The combination of CNNs and transformers is not a novel idea, and many hybrid models already exist.', 'The theoretical justification for some design choices, like specific patch sizes, is not well-explored.', 'Insufficient ablation studies to understand the contribution of individual components of MobileViT.', 'Limited discussion on potential limitations and failure cases.']",4,3,3,4,Reject
0rjx6jy25R4,"The paper proposes a novel training framework that addresses the scarcity of class-labeled data by leveraging Positive-Unlabeled (PU) classification and conditional generation with extra data, particularly out-of-distribution unlabeled data. The key contribution is the Classifier-Noise-Invariant Conditional GAN (CNI-CGAN), which is designed to be robust to noisy labels predicted by a PU classifier. The framework aims to improve both classification and generation performance simultaneously.","['Can you provide more details on the estimation of the confusion matrix and how it affects the training of the CNI-CGAN?', 'How were the hyperparameters chosen for the experiments? Can you provide a more detailed explanation?', 'What are the potential limitations of using out-of-distribution data and how do you address them?', 'Can you conduct additional ablation studies to isolate the contributions of different components of the framework?', 'Can the authors provide more detailed explanations and clearer exposition of the mathematical formulations and theoretical guarantees?', 'How does the proposed method perform with different types and levels of noise in the initial PU classifier?', 'Can the authors provide further theoretical analysis on the robustness of the method against various noise levels?', 'Can the authors expand on the ethical considerations and discuss the potential societal impacts of the proposed method in more detail?']","['The use of out-of-distribution data could introduce biases or ethical concerns that are not fully addressed in the paper.', 'The clarity of the methodology and experimental setup needs improvement to ensure reproducibility.', 'The practical implications and scalability of the method need further elaboration.', 'The robustness of the proposed method against different types of noise and varying levels of initial PU classifier accuracy needs further investigation.', 'The complexity of the method may limit its applicability in real-world scenarios without significant computational resources.', 'Potential privacy issues when leveraging extra unlabeled data, which the authors briefly mention but do not deeply explore.']",True,3,3,3,6,4,"['Addresses a significant problem of leveraging unlabeled data, including out-of-distribution data.', 'Proposes a novel CNI-CGAN for handling noisy labels from PU classifiers, which is theoretically sound.', 'Provides extensive experimental validation on multiple datasets, showing improvements in both classification and generation tasks.', 'Theoretical analysis provides a solid foundation for the proposed method, ensuring its validity.']","['The clarity of the methodology section could be improved, particularly in the explanation of the CNI-CGAN and the estimation of the confusion matrix.', 'The experimental setup for some of the baselines and the choice of hyperparameters are not fully detailed.', 'Potential limitations and ethical concerns regarding the use of out-of-distribution data are not thoroughly discussed.', 'The paper could benefit from additional ablation studies to better understand the contributions of different components of the framework.', 'The practical utility and scalability of the method are not thoroughly discussed.']",3,3,3,4,Reject
7B3IJMM1k_M,"The paper proposes a novel Quantization Clip-Floor-Shift (QCFS) activation function to improve the performance of ANN-SNN conversion, aiming for high accuracy and ultra-low latency. It provides theoretical analysis of conversion errors and demonstrates the method's effectiveness on CIFAR-10, CIFAR-100, and ImageNet datasets.","['Can you provide more detailed ablation studies on the QCFS function?', 'How does the method generalize to other architectures and tasks?', 'Can you elaborate on the practical implications, including energy consumption and computational overhead?', 'What are the potential ethical considerations and societal impacts of deploying SNNs in real-world applications?', 'Can the authors provide more intuitive explanations or visual aids for the mathematical derivations?', 'Have the authors considered testing the method on tasks beyond image classification?', 'Can more detailed comparisons with existing methods be included to highlight the advantages of the proposed method?']","['The complexity and clarity of the methodology.', 'Generalization to other architectures and tasks.', 'Practical implications like energy consumption and computational overhead.', 'The paper does not discuss the potential limitations and negative societal impacts of the proposed method.']",False,3,2,3,6,4,"['Introduction of a novel QCFS activation function for ANN-SNN conversion.', 'Thorough theoretical analysis of conversion errors.', 'Impressive performance improvements on benchmark datasets.', 'Availability of code for reproducibility.']","['Complex and difficult-to-follow methodology.', 'Limited generalization to other architectures and tasks.', 'Need for more detailed ablation studies.', 'Insufficient discussion on practical implications like energy consumption.', 'Lack of discussion on broader societal impacts and ethical considerations.']",3,3,2,3,Reject
k7efTb0un9z,The paper proposes a Graph Network-based Scheduler (GNS) for dynamically adjusting learning rates in neural network training by leveraging the structure of the target network. GNS uses Graph Neural Networks to capture intermediate layer information and reinforcement learning to adjust the learning rate dynamically. The framework is evaluated on image classification and language understanding tasks and shows improved performance over traditional and learning-based baselines.,"['Could you provide more details on the GNN setup and its integration with the reinforcement learning framework?', 'How does the performance of GNS compare with other state-of-the-art learning rate schedulers not included in the current experiments?', 'Can you provide more ablation studies to understand the impact of different components of GNS?', 'Can you provide more details on the GNN architecture and how it was optimized?', 'What were the computational resources required for training the GNS compared to the traditional schedulers?', 'How does the proposed method handle very large-scale datasets and models, such as those used in industry?', 'Can you provide more detailed ablation studies to justify the design choices, particularly the choice of action space and reward collection procedure?', 'How does your method compare with other reinforcement learning-based learning rate schedulers?', 'Can you provide more detailed explanations of the autoencoder aggregator and hierarchical GCN?', 'Can you include more qualitative examples to support your claims?']","['The paper does not thoroughly discuss the limitations and potential negative societal impacts of the proposed method. It would be helpful to include a discussion on the computational overhead introduced by the GNN and reinforcement learning components, as well as any potential biases or ethical concerns that may arise from the use of this method.', 'The primary limitations are the lack of detailed explanation for the GNN architecture and the computational cost involved in training the GNS. Additionally, the paper could benefit from a broader range of datasets and model architectures in the experiments.']",False,3,3,3,6,4,"['Addresses the important problem of learning rate scheduling in deep learning.', 'Introduces a novel application of Graph Neural Networks to capture the structure of the target network for learning rate scheduling.', 'Demonstrates significant performance improvements over traditional and learning-based baselines on a variety of tasks.', 'Comprehensive experiments, including generalization to different datasets and network architectures.']","['The clarity of the methodology section could be improved, particularly the details of the GNN and reinforcement learning setup.', 'The novelty of applying GNNs in this context could be better justified, as GNNs are a known technique and their application here might not be groundbreaking.', 'More ablation studies and comparisons with alternative state-of-the-art methods would strengthen the paper.', 'The paper could benefit from a more detailed discussion of the limitations and potential negative societal impacts of the proposed method.', 'Insufficient details on the computational cost and efficiency of the proposed method compared to baselines.', 'Theoretical insights into why the proposed method works better than existing approaches are lacking.']",3,3,3,4,Reject
hcoswsDHNAW,"The paper proposes Fast AdvProp, a method to improve the efficiency of Adversarial Propagation (AdvProp) by reducing the training costs significantly while retaining the performance benefits. The authors demonstrate empirical results showing that Fast AdvProp can achieve better model performance without incurring extra training costs across various visual benchmarks.","['Can the authors provide more detailed ablation studies on the decoupled training strategy and gradient recycling?', 'How does the method compare with other state-of-the-art adversarial training techniques in terms of both performance and training costs?', 'Can the authors elaborate further on the implementation details to enhance the clarity of the methodology?', 'Can you provide more details on the hyperparameter settings used in the experiments?', 'Could additional ablation studies be conducted to isolate the contributions of each component of Fast AdvProp?', 'Can the authors provide more detailed explanations of the gradient recycling process and parameter synchronization?', 'Can you provide more details on the autoencoder aggregator and its implementation?', 'Have you tested Fast AdvProp on tasks other than image classification to verify its generalizability?']","['The paper needs more detailed ablation studies and comparisons with other state-of-the-art methods to validate the effectiveness of the proposed approach comprehensively.', 'The primary limitations revolve around the clarity of the methodology and the need for more comprehensive ablation studies to validate the proposed modifications.', 'The paper could benefit from more detailed explanations of certain methodological choices and additional ablation studies to validate the robustness of those choices.']",False,3,3,3,6,4,"['Addresses a critical issue in adversarial training by significantly reducing the training costs.', 'Empirical results show improvements in both accuracy and robustness without additional training costs.', 'The proposed method is compatible with existing data augmentation techniques like Mixup and CutMix.', 'Demonstrates scalability to larger models and adaptability to other recognition tasks like object detection.']","['The paper could benefit from more detailed ablation studies, especially concerning the decoupled training strategy and gradient recycling.', 'Some sections, particularly those detailing the methodology, could be elaborated further for better clarity.', 'Comparisons with other state-of-the-art methods are limited and could be expanded.', 'The robustness of the proposed method under different configurations (e.g., without random initialization) needs more extensive validation.', 'Certain sections of the paper, particularly those detailing the implementation specifics and the ablation studies, could benefit from more clarity and detail.']",3,3,3,3,Reject
QKEkEFpKBBv,"The paper proposes a Differentiable Nonparametric Belief Propagation (DNBP) method that combines neural networks with nonparametric belief propagation for articulated pose tracking. The proposed method replaces hand-crafted factors with differentiable neural networks, allowing for end-to-end learning of probabilistic factors. The approach is validated on simulated articulated tracking tasks and a real-world hand pose tracking task.","['Can the authors provide more details on the training process and the architecture of the neural networks used?', 'How does the performance of DNBP compare with other state-of-the-art methods in more detail?', 'Can the authors include more ablation studies to understand the contribution of each component of the proposed method?', 'Can the authors provide more detailed explanations and pseudocode for the belief and message update steps?', 'What is the impact of different components (e.g., diffusion model, pairwise potential networks) on the performance of DNBP? Please provide ablation studies.', 'How does DNBP perform in highly cluttered environments compared to traditional NBP and learning-based methods?', 'Can the authors discuss potential limitations and failure cases of DNBP in more detail?', 'What is the impact of the non-differentiable resampling step on the performance and training stability of DNBP?', 'Have you considered any potential limitations or negative societal impacts of the proposed method?']","['The paper does not adequately address the limitations of the proposed method, particularly the computational complexity and the scalability of the approach.', 'The approach relies on a graph model as input, which may limit its applicability in certain scenarios.', 'The evaluation of uncertainty estimates could be more quantitative.']",False,3,2,3,5,4,"['The paper addresses a significant problem in robotic perception by reducing the need for hand-crafted domain knowledge.', 'The combination of neural networks with nonparametric belief propagation is novel and shows promise in improving tracking performance.', 'The experiments are well-designed, covering both simulated and real-world tasks, which demonstrates the practical applicability of the proposed method.', 'DNBP provides measures of uncertainty, which are crucial for applications where incorrect estimates can lead to catastrophic decisions.']","['The paper lacks clarity in several sections, particularly in the methodology. The explanation of the training process and the architecture details are not sufficiently detailed.', 'The results section could benefit from more thorough analysis and comparison with baseline methods.', 'The paper does not provide sufficient ablation studies to understand the contribution of each component of the proposed method.', 'The potential limitations and failure cases of the proposed method are not adequately discussed.', 'The evaluation lacks comparisons with a broader set of baseline methods, particularly those that are state-of-the-art in probabilistic graphical models.']",3,3,2,3,Reject
AsyICRrQ7Lp,The paper proposes Bootstrapped Hindsight Experience Replay (BHER) with a counterintuitive prioritization mechanism to improve data efficiency in goal-conditioned environments with sparse rewards. The method combines Bootstrapped DQN principles with HER to enhance exploration and uses the variance of Q-values to prioritize hindsight experiences for exploitation. The paper demonstrates the effectiveness of the approach through experiments on various goal-reaching and robotics control tasks.,"['Can the authors provide more theoretical justification for the counterintuitive prioritization mechanism?', 'How does the proposed method perform on a wider variety of tasks and environments?', 'Can the authors provide more detailed explanations of the implementation of Bootstrapped DDPG and the intuition behind counterintuitive prioritization?', 'What is the impact of using multiple heads without counterintuitive prioritization? Can you include more ablation studies to clarify this?', 'How does the proposed method compare with baseline methods in terms of computational complexity and training time?', 'Can the authors provide more detailed descriptions of the experimental setup and hyperparameter settings?', 'How does the proposed method compare with more recent advancements in HER and sparse reward tasks?', 'Can you provide a more detailed explanation of the counterintuitive prioritization mechanism and its mathematical formulation?', 'How does the proposed method compare with other non-HER-based prioritization methods in reinforcement learning?', 'What are the specific hyperparameters used in the experiments, and how sensitive are the results to these hyperparameters?']","[""The method's performance on highly complex or varied tasks is not well examined."", 'The counterintuitive prioritization mechanism lacks strong theoretical backing.', 'The paper should discuss the computational overhead introduced by using multiple heads and the potential trade-offs.', 'Potential negative societal impacts, such as increased computational resources and environmental implications, are not addressed.', 'The scalability and generalizability of the proposed method to more complex environments and tasks are not discussed.']",False,2,2,2,4,4,"['Combines two established techniques (Bootstrapped DQN and HER) in a novel way.', 'Proposes a unique prioritization mechanism based on Q-value variance.', 'Addresses a significant problem in reinforcement learning: improving data efficiency in sparse reward environments.', 'Provides comprehensive experimental results showing improved performance over baseline methods.']","['The theoretical justification for the counterintuitive prioritization mechanism is weak.', 'The experimental validation lacks diversity in tasks and environments to prove generalizability.', 'Some implementation details and intuitions behind the method are not clearly explained.', 'Ablation studies do not cover all possible variants and important baselines comprehensively.', 'The paper lacks clarity in the explanation of the methodology, particularly in how the priorities are calculated and used during training.', 'The explanation for why lower uncertainty samples are more beneficial for HER lacks theoretical backing and relies heavily on empirical results.', 'The comparison with baseline methods is limited. Including more diverse and recent baselines would strengthen the claims.']",3,2,2,3,Reject
lQI_mZjvBxj,"The paper proposes a model-agnostic federated learning protocol using knowledge distillation (KD) to address the limitations of traditional FL methods that rely on uniform model architectures. The authors introduce a theoretical framework for federated kernel ridge regression to analyze KD-based federated learning protocols. Their theoretical analysis reveals limitations of existing KD methods under data heterogeneity, and they propose new protocols to mitigate these issues, which are validated through real-world experiments.","['Can you provide more intuitive explanations or visualizations to make the theoretical parts easier to understand?', 'How do you envision addressing the practical challenges of implementing EKD in real-world applications, especially the need for large ensembles?', 'Can the authors provide more empirical validation using real-world complex datasets?', 'Can the authors provide more theoretical depth and analysis to support their empirical observations and claims?', 'Can the authors provide additional ablation studies to explore the impact of different configurations and settings?', 'How do the proposed protocols compare with other state-of-the-art methods in federated learning?', 'Can the authors provide more detailed explanations of the experiments and their setup to improve reproducibility?', 'What are the practical implications of the proposed methods in real-world federated learning scenarios?', 'How can the performance of the proposed methods be improved to match the centralized performance more closely?']","['The paper could better address the practical limitations of the proposed methods, particularly the scalability and feasibility of EKD in real-world settings.', 'The clarity of the theoretical framework could be improved to make the paper more accessible to a broader audience.', 'The empirical validation shows that the performance of the proposed methods is still unsatisfactory despite theoretical insights.', 'The paper does not fully address the practical significance and utility of the proposed methods in real-world federated learning applications.']",False,3,3,3,5,4,"['The paper addresses a relevant and significant problem in federated learning, i.e., model-agnostic collaboration among agents with different model architectures.', 'The theoretical framework for federated kernel ridge regression is well-developed and provides valuable insights into the limitations of existing KD methods.', 'The authors conduct comprehensive experiments to validate their theoretical findings, including testing different KD protocols under various conditions of model and data heterogeneity.']","['The paper is quite dense and could benefit from improved clarity and organization. Some sections, especially the theoretical parts, are difficult to follow.', 'The proposed solutions, while theoretically sound, may face practical challenges. For example, the EKD method requires large ensembles, which might not be feasible in real-world applications.', 'The experiments are thorough but could be expanded to include more diverse datasets and more complex real-world scenarios to better demonstrate the practical applicability of the proposed methods.', 'The empirical validation is preliminary and does not convincingly demonstrate the practical utility of the proposed methods in real-world applications.']",3,3,3,4,Reject
OWZVD-l-ZrC,"The paper introduces RUNE, an exploration method for preference-based reinforcement learning (RL) that leverages reward uncertainty to guide exploration. The method uses the disagreement across an ensemble of reward models as an intrinsic reward, aiming to improve both the sample- and feedback-efficiency of preference-based RL algorithms. The experiments demonstrate that RUNE outperforms existing exploration methods on several robotic manipulation tasks from the MetaWorld benchmark.","['Can you provide more details on the autoencoder aggregator and its role in the proposed method?', 'Have you considered the impact of different numbers of reward models in the ensemble on the performance of RUNE?', 'Can you provide more qualitative examples of the learned reward functions and their alignment with the ground truth?', 'Can the authors provide more details on the computation of the intrinsic reward and the training procedure of RUNE?', 'How does RUNE handle the potential biases in human feedback and the resulting reward functions?', 'Can the authors provide more visualizations and case studies to illustrate the benefits of RUNE in different scenarios?']","['The paper does not discuss the limitations and potential negative societal impacts of the proposed method. It would be beneficial to address these aspects.', 'The experiments are somewhat limited in scope and could include more diverse task environments.']",False,3,3,3,5,4,"['The paper addresses a critical problem in preference-based RL: the need for efficient exploration to reduce the reliance on expensive human feedback.', 'The proposed method, RUNE, is novel and leverages the disagreement among an ensemble of reward models to guide exploration.', 'The experimental results show that RUNE improves both sample- and feedback-efficiency compared to existing exploration methods.', 'The paper is well-structured and provides a clear motivation for the proposed approach.']","['The paper lacks sufficient ablation studies to analyze the impact of various components of the proposed method. For example, the effect of different numbers of reward models in the ensemble is not thoroughly investigated.', 'The explanation of some components, such as the autoencoder aggregator, is not detailed enough. This makes it challenging to understand the complete methodology.', 'The qualitative analysis provided in the paper is limited. More examples of the learned reward functions and their alignment with ground truth would strengthen the paper.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed method.']",3,3,3,3,Reject
ghTlLwlBS-,"The paper proposes a Feudal Reinforcement Learning (FRL) framework to address the semantic mismatch between high-level language instructions and low-level actions in reinforcement learning tasks. The framework consists of a manager agent that generates sub-goals and a worker agent that executes these sub-goals. The approach is evaluated on two benchmarks, RTFM and Messenger, showing significant improvements over existing methods.","['Can you provide more details about the autoencoder aggregator used in the worker agent?', 'Can you provide more examples in the qualitative analysis to support the quantitative results?', 'Can you clarify the specific details of the curriculum learning compared to other methods?', 'Can the authors provide more details on the multi-hop plan generator and how it differs from existing hierarchical approaches?', 'What specific innovations are introduced in the backward sub-goal generation process?', 'Can additional ablation studies be conducted to isolate the contributions of different components of the proposed framework?']","['The paper could be clearer in explaining certain components and processes, and it would benefit from additional qualitative examples.', 'The paper lacks clarity in certain sections, which might make it difficult for readers to fully understand the proposed framework and its contributions.', 'Additional ablation studies are needed to validate the contributions of each component of the proposed framework.', 'The presentation of the results could be improved with more detailed visualizations and comparisons.']",False,3,2,3,5,4,"['Addresses a critical issue in reinforcement learning with language instructions: the semantic mismatch between high-level instructions and low-level actions.', 'The FRL framework, with its manager and worker agents, is a novel and effective approach.', 'The multi-hop plan generator for the manager agent allows the model to reason backward from the goal to generate sub-goals.', 'Experimental results on two challenging benchmarks are impressive, showing substantial improvements over existing methods.']","['The paper could benefit from more detailed descriptions of certain components, such as the autoencoder aggregator used in the worker agent.', 'The qualitative analysis could be enhanced by providing more examples to support the quantitative results.', 'Some aspects of the training process, such as the specific details of the curriculum learning compared to other methods, could be clarified.', 'The hierarchical approach of using a manager and worker agent is not entirely novel and has been explored in previous works.', 'The methodology section lacks clarity and detail, especially in explaining the multi-hop plan generator and the training process for the manager and worker agents.', 'Additional ablation studies are needed to isolate the contributions of different components, such as the backward sub-goal generation and the multi-hop reasoning capability of the manager.']",3,3,2,3,Reject
aq6mqSkwApo,"The paper introduces Meta-OLE, a method for few-shot learning that uses orthogonal low-rank embeddings to improve intra-class similarity and inter-class separation. It combines ideas from prototype-based methods and parameter adaptation, aiming to enhance the learning efficiency and robustness of the model. The method involves a universal feature extractor, an adaptive orthogonal low-rank transformation, and adaptive subspace projections. The experiments show that Meta-OLE achieves superior performance compared to state-of-the-art methods.","['Can you provide a more detailed description of the adaptive orthogonal low-rank transformation?', 'What is the computational complexity of the proposed method?', 'Can you discuss the limitations and potential failure cases of the method?', 'Can the authors provide a more detailed explanation of how the orthogonal low-rank embedding is achieved?', 'Can the authors include ablation studies to compare the performance with and without the orthogonal low-rank embedding?', 'Can the authors provide a detailed analysis of the hyperparameters used in the experiments?', 'What is the impact of different types of aggregators on the performance?', 'How does the method perform with varying hyperparameters beyond those discussed in the paper?']","['The paper does not provide a detailed analysis of the computational complexity, and there is limited discussion on the potential failure cases of the method.', ""The primary limitation is the lack of clarity in certain sections, which could hinder reproducibility. Additionally, more extensive ablation studies could provide deeper insights into the method's effectiveness.""]",False,3,2,3,5,4,"['The introduction of orthogonal low-rank embedding to enforce intra-class similarity and inter-class separation is novel and well-motivated.', 'The method provides a good balance between simplicity and effectiveness.', 'Extensive experiments demonstrate the superiority of Meta-OLE over existing methods.', 'The paper addresses an important issue in few-shot learning: improving generalization to novel tasks.']","['The description of the adaptive orthogonal low-rank transformation could be clearer.', 'The paper lacks a detailed analysis of the computational complexity of the proposed method.', 'There could be more discussion on the limitations and potential failure cases of the method.', 'Insufficient details about the training process of the adaptive orthogonal low-rank transformation make the method difficult to reproduce.', 'The experimental section lacks certain key ablations and comparisons to clearly demonstrate the impact of the proposed method.', 'The clarity of the paper could be improved, with more consistent notation and clearer explanations in the methodology section.']",3,3,2,3,Reject
eMudnJsb1T5,"The paper introduces three new particle evolution samplers: Stein Variational Mirror Descent (SVMD), Mirrored Stein Variational Gradient Descent (MSVGD), and Stein Variational Natural Gradient (SVNG). These methods leverage a novel mirrored Stein operator to handle constrained domains and non-Euclidean geometries. The authors provide theoretical analysis and demonstrate their methods' effectiveness on benchmark problems, post-selection inference, and large-scale posterior inference.","['Can the authors provide more details on the computational efficiency of SVMD and SVNG compared to existing methods?', 'What are the specific parameter settings used in the experiments? A more detailed description would help with reproducibility.', 'How sensitive are the proposed methods to different kernel choices? Can the authors provide a sensitivity analysis?', 'Can the authors provide more detailed explanations and justifications for the design choices in the proposed methods?', 'Can the authors include more detailed ablation studies and comparative analysis with existing methods?', 'What are the practical implications and potential limitations of the proposed methods in real-world scenarios?']","['The paper mentions the higher computational cost of SVMD and SVNG due to adaptive kernel construction. It would be beneficial to discuss potential solutions or approximations to mitigate this issue.', ""The paper does not adequately address the practical implications and potential limitations of the proposed methods. This oversight may impact the paper's overall significance and applicability in real-world scenarios.""]",False,3,3,3,6,4,"['Introduction of novel mirrored Stein operators for handling constrained domains and non-Euclidean geometries.', 'Development of three new particle evolution samplers (SVMD, MSVGD, SVNG) with theoretical convergence guarantees.', 'Comprehensive experimental evaluation demonstrating the advantages of the proposed methods on various tasks.', 'Thorough theoretical analysis and well-structured presentation of the methods.']","['The paper could benefit from more detailed comparisons with existing methods in terms of computational efficiency, especially for SVMD and SVNG.', 'Some experimental details and parameter settings are not clearly described, which may affect reproducibility.', 'The clarity of the paper is lacking, particularly in the detailed explanations of the proposed methods and design choices.', 'The practical implications and potential limitations of the proposed methods are not thoroughly discussed.', 'Certain sections, such as the derivation of the mirrored Stein operators and the convergence proofs, are dense and difficult to follow without additional context or explanations.']",3,3,3,4,Reject
VNdFPD5wqjh,"The paper proposes Unit DRO, a new method for generalizable person re-identification (ReID) without using demographic information. The approach leverages distributionally robust optimization (DRO) to reweight samples dynamically, aiming to improve generalization across unseen domains. The method is evaluated empirically on large-scale DG ReID and cross-domain ReID benchmarks, demonstrating superior performance compared to standard baselines.","['Can you clarify the DRO formulation and the specific steps involved in implementing the weights queue?', 'How were the hyperparameters chosen for the experiments? Were there any specific criteria or validation sets used?', 'Have you considered comparing the step τ* with other dynamic scheduling techniques?', 'Can the authors provide more detailed explanations of the weights queue and step τ*?', 'What is the performance of the proposed model by changing the type of aggregators?', 'Can the authors provide more comprehensive ablation studies to validate the contribution of each component?', 'What is the theoretical justification for the stepwise adjustment of the hyperparameter τ*?', 'Can the authors discuss potential limitations and failure cases of the proposed method?']","['The paper does not discuss potential limitations and failure cases of the proposed method, which could be important for understanding the scope of its applicability.', 'The practical implementation details are insufficient for reproducibility.', 'The paper lacks detailed ablation studies on the hyperparameters of Unit DRO, which are crucial for understanding the robustness and effectiveness of the proposed method.']",False,2,2,3,4,4,"['Addresses an important and realistic problem in ReID by eliminating the need for demographic information.', 'Proposes a novel method (Unit DRO) that reweights samples dynamically for better generalization.', 'Empirically demonstrates superior performance on large-scale DG ReID and cross-domain ReID benchmarks.', 'Provides comprehensive ablation studies to analyze the impact of different components of the method.']","['The description of the methodology is somewhat unclear, particularly the details of the DRO formulation and the implementation of the weights queue.', 'The experimental results, while promising, need additional validation. The authors should provide more details about the experimental setup and the selection of hyperparameters.', 'The ablation studies, although comprehensive, could benefit from further exploration of alternative methods for determining the step τ*. For example, a comparison with other dynamic scheduling techniques could provide more insight.', 'The paper lacks a thorough discussion on potential limitations and failure cases of the proposed method.', 'Important implementation details are missing, making it difficult to reproduce the results.', 'The comparison with other methods could be more comprehensive.']",3,2,2,3,Reject
_j4hwbj6Opj,"The paper presents a novel approach to 3D point cloud registration by framing it as a meta-learning problem. It introduces a 3D registration meta-learner to predict priors over the registration function space, enabling rapid adaptation to new tasks with limited data. The method is tested on several datasets, showing promising results.","['Can the authors provide more detailed mathematical formulations of the proposed method?', 'What is the impact of different meta-learner architectures on the performance?', 'Can the authors include more comprehensive comparisons with state-of-the-art methods?', 'Could the paper be restructured to improve readability and accessibility?', 'Could the authors provide more details about the autoencoder aggregator?', 'How does the proposed method perform in terms of computational efficiency compared to existing methods?', 'Can the authors include additional ablation studies to explore the impact of different components of the model?', 'Have you considered reducing the number of gating parameters in the modulation function by sharing the gate value of each filter in Conv layers?', 'What would be the performance impact of using different types of aggregators in the autoencoder?', 'Can the authors provide more detailed explanations and visualizations for the 3D registration learner and meta-learner components?', 'What are the potential limitations and negative societal impacts of the proposed approach?']","['The paper does not adequately address the limitations of the proposed method, particularly in terms of computational complexity and potential scalability issues.', 'There is no discussion on the potential negative societal impacts of the work.', 'The practical applicability of the proposed method in real-world scenarios remains to be demonstrated.', 'The paper lacks detailed discussions on the computational efficiency of the proposed method.', 'The paper could benefit from more detailed ablation studies to validate the contributions of each component.', 'The clarity of certain methodological details, such as the autoencoder aggregator, needs improvement.']",False,3,3,3,4,4,"['The approach of using meta-learning for 3D point cloud registration is innovative.', 'The paper addresses a relevant and challenging problem in 3D computer vision.', 'Experimental results on datasets like ModelNet, FlyingThings3D, and KITTI demonstrate the potential of the proposed method.']","['The paper lacks sufficient differentiation from other meta-learning applications in 3D vision.', 'Technical details are not thoroughly explained, especially the mathematical formulations and the architecture of the meta-learner.', 'The ablation studies are incomplete, missing critical components such as the impact of different meta-learner architectures.', 'The paper is difficult to follow due to dense technical jargon and insufficient explanations.', 'The significance of the results is not sufficiently demonstrated through a comprehensive comparison with a broader range of state-of-the-art methods.', 'The complexity of the proposed method may limit its practicality in real-world applications.', 'The clarity of the paper could be improved, particularly in the explanation of the autoencoder aggregator and the detailed methodology.', ""Additional qualitative results would strengthen the paper's claims and provide more evidence of the method's effectiveness."", 'The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the proposed method.']",3,3,3,3,Reject
iEvAf8i6JjO,"The paper proposes Trust Region Gradient Projection (TRGP), a novel approach for continual learning that aims to address the catastrophic forgetting problem while facilitating forward knowledge transfer. The key contributions include the introduction of a trust region for selecting correlated old tasks and a scaled weight projection to leverage the knowledge of these tasks. The method is evaluated on multiple datasets and compared with state-of-the-art continual learning methods, demonstrating significant performance improvements.","['Can the authors provide more details on the implementation of the autoencoder aggregator?', 'How does the performance of the proposed method change with different modulation functions?', 'Can the authors provide more qualitative analysis and visualizations to support their claims?', 'Can you provide more details on the selection and impact of different scaling matrices?', 'How does the computational complexity and memory usage of TRGP compare to baseline methods?', 'Can you include more detailed explanations and examples for the mathematical formulations, particularly for the scaled weight projection and trust region definitions?', 'Can the authors provide a more detailed ablation study to isolate the impact of layer-wise trust regions and scaled weight projection?', 'How does the proposed method compare with other recent continual learning methods not included in the current experiments?', 'How does the choice of initialization for the scaling matrix affect the performance of TRGP?', 'Can the method be generalized to other neural network architectures such as RNNs or transformers?', 'How does the method perform on more diverse datasets beyond image classification tasks?']","['The clarity of the paper could be improved with more detailed explanations of the implementation aspects, especially the autoencoder aggregator.', 'Further ablation studies on the modulation functions and additional qualitative analyses would strengthen the paper.', 'The paper could benefit from a more detailed discussion on the limitations related to computational complexity and memory requirements.', 'The method introduces additional computational complexity, making it challenging to implement and optimize.', 'There is a need for more diverse datasets to validate the generalizability of the method.']",False,3,2,3,5,4,"['The paper addresses a crucial problem in continual learning: catastrophic forgetting, and proposes a novel approach to mitigate it.', 'The introduction of a trust region and scaled weight projection is innovative and provides a mechanism for leveraging knowledge from correlated old tasks.', 'Comprehensive experimental evaluation on multiple datasets and comparisons with state-of-the-art methods show the effectiveness of the proposed approach.']","['The implementation details of the autoencoder aggregator are not clearly explained, which may hinder reproducibility.', 'The impact of different modulation functions on the performance of the proposed approach needs further investigation.', 'The qualitative analysis and visualization provided are limited. More examples and detailed visualizations would help in better understanding the proposed method.', 'The mathematical formulation of the trust region and scaled weight projection could be more rigorous.', 'The paper does not thoroughly discuss the computational complexity and memory requirements of the proposed method compared to baseline approaches.']",3,3,2,4,Reject
ptZfV8tJbpe,"The paper introduces a novel method called Latent Label Encoding Method (LLEM) for multi-label text classification (MLTC). This method uses latent labels to implicitly model label correlations rather than explicitly as previous methods do. The approach leverages BERT to map latent label encodings to actual labels. The authors claim significant improvements over state-of-the-art methods on two benchmark datasets, AAPD and RCV1-V2.","['Can the authors provide more ablation studies to highlight the impact of different components of the proposed method?', 'Can the methodology section be clarified, particularly around the random initialization and training process for the latent label embeddings?', 'Is there any way to provide more empirical evidence or theoretical justification for the avoidance of label-correlation overload?', 'Can you provide more details on the autoencoder aggregator?', 'Have you considered other types of modulation functions or aggregators? If so, what are the results?', 'Can you provide additional visualizations or qualitative analyses to support your claims more robustly?', 'How does the number of latent labels affect the performance? Have you experimented with different values?', 'Can you elaborate on the optional within-task pretraining process and its impact on the final results?']","['The main limitations are the lack of detailed ablation studies and the need for more clarity in the methodology. Additionally, a thorough analysis of the latent label embeddings and their interpretability is missing.', 'The paper should include more discussion on the limitations of the proposed method and potential negative societal impacts.']",False,3,3,3,6,4,"['The approach addresses a key challenge in MLTC by avoiding explicit modeling of label correlations, which can introduce inductive biases.', 'The method is straightforward and leverages the powerful BERT model.', 'The paper demonstrates significant improvements in performance over state-of-the-art methods.', 'The analysis section provides detailed insights into why the method works, focusing on label-correlation utilization.']","['The paper lacks sufficient ablation studies to understand the impact of different components of the proposed method.', 'The methodology section could use more clarity, especially concerning the random initialization and training of latent label embeddings.', 'The paper doesn’t provide a thorough analysis of the latent label embeddings and their interpretability.', 'Some claims, such as the avoidance of label-correlation overload, need more empirical evidence or theoretical justification.']",3,3,3,4,Reject
wQStfB93RZZ,"The paper introduces novel actor-critic methods for multi-agent reinforcement learning (MARL) with asynchronous decision-making using macro-actions. The methods are evaluated across various domains, demonstrating their potential in handling asynchronous multi-agent problems.","['Can the authors provide more details on the implementation of the autoencoder aggregator and its role in the proposed methods?', 'How are asynchronous updates handled in the training process, and how does this impact the learning dynamics?', 'Can the authors provide additional ablation studies to isolate the impact of different components of the proposed methods?', 'How do the proposed methods compare to other state-of-the-art methods that handle asynchronous decision-making?', 'Could the authors provide more detailed explanations and justifications for the design choices in the macro-actions and trajectory squeezing process?', 'What would be the impact of varying the frequency of policy updates and using different types of macro-actions on the performance of the proposed methods?', 'Are there any considerations for the potential societal impacts or ethical implications of deploying these multi-agent systems in real-world scenarios?']","['The paper should more clearly discuss the limitations of the proposed methods, particularly in terms of scalability and the handling of more complex environments.', 'Potential negative societal impacts are not discussed, which could be important given the application domains involving robots and coordination.']",False,3,3,3,6,4,"['The paper addresses a significant and challenging problem in multi-agent reinforcement learning: asynchronous decision-making using macro-actions.', 'The proposed methods are novel and extend existing actor-critic frameworks to accommodate asynchronous macro-actions.', 'The empirical results demonstrate the effectiveness of the proposed methods across multiple domains.']","['The paper lacks clarity in explaining certain technical aspects, such as the implementation of the autoencoder aggregator, the trajectory squeezing process, and the handling of asynchronous updates.', 'The experimental evaluation lacks ablation studies and detailed comparisons with other state-of-the-art methods, making it difficult to isolate the contributions of different components.', 'The scalability of the proposed methods to larger and more complex environments is not thoroughly discussed.', 'Potential societal impacts and ethical considerations are not addressed.', 'The clarity of the presentation can be improved, with suggestions for more detailed explanations, pseudo-code, and better organization of the content.']",3,3,3,3,Reject
W9G_ImpHlQd,"The paper introduces ZO-AE-DS, a novel approach to enhancing the robustness of black-box machine learning models against adversarial attacks. The method integrates denoised smoothing (DS) with zeroth-order (ZO) optimization and an autoencoder (AE) to reduce gradient estimate variance. The approach is validated through extensive experiments on multiple datasets, showing significant improvements in certified robustness and standard accuracy over existing baselines.","['Can you provide more details on the computational overhead introduced by the AE and ZO optimization, especially in large-scale settings?', 'How does the proposed method perform on non-image datasets or other types of black-box models (e.g., NLP models)?', 'Could alternative pre-training strategies for the denoiser be explored to avoid poor local optima?', 'Are there any specific hyperparameter settings that are crucial for achieving the reported performance? How sensitive is the method to these settings?', 'Can the authors provide more intuitive explanations or visualizations of how the autoencoder aids in reducing the variance of zeroth-order gradient estimates?', 'What are the computational overhead and query complexity introduced by the autoencoder, and how do they compare to traditional white-box defense methods?']","['The primary limitation is the complexity and resource intensiveness of the proposed approach, which may limit its applicability in real-world large-scale settings.', 'The generalizability to non-image datasets and other model types is also a concern that should be addressed in future work.', 'The paper does not sufficiently address the potential negative societal impacts, such as increased energy consumption and resource usage.']",False,3,3,3,6,4,"['Addresses a highly relevant and practical problem of black-box model robustness.', 'Innovative integration of denoised smoothing with zeroth-order optimization and autoencoders.', 'Comprehensive experimental validation covering multiple datasets.', 'Significant improvements in certified robustness and standard accuracy over existing baselines.']","['The methodology section lacks clarity and detailed explanation of the proposed approach.', 'The approach involves multiple components, which may introduce implementation complexity and require extensive hyperparameter tuning.', 'Limited exploration of scalability to larger datasets and generalizability to non-image data.', 'The computational overhead and practical applicability in real-world scenarios are not thoroughly discussed.']",4,3,3,4,Reject
l431c_2eGO2,"The paper proposes Mix-MaxEnt, a method to improve the accuracy and uncertainty estimates of deterministic neural networks by introducing an entropy maximization regularizer. This is achieved by generating between-cluster samples via convex combinations of images from different classes and maximizing their entropy. The method aims to guide the neural network to be more uncertain in regions away from training data, thus creating an entropy barrier. The approach is evaluated on CIFAR-10 and CIFAR-100 datasets using ResNet and Wide-ResNet architectures, demonstrating improved performance in classification accuracy, calibration, and uncertainty estimation under domain-shift and out-of-distribution scenarios.","['Can the authors provide more detailed ablation studies on the choice of hyperparameters for the entropy regularizer?', 'How does the method perform with different interpolation strategies (e.g., linear vs. non-linear)?', 'Can the authors clarify the impact of the specific choice of Beta distribution parameters on the final performance?', 'Can the authors clarify the experimental setup and hyperparameter tuning process?', 'Have the authors considered the impact of the proposed method on different neural network architectures?', 'How does the proposed method compare to more recent approaches in uncertainty estimation?', 'What is the effect of varying the entropy maximization parameter more extensively?', 'How does the method perform on other datasets and tasks beyond CIFAR-10 and CIFAR-100?', 'Can the authors provide more diverse visualizations and examples in the qualitative analysis?']","['The paper does not adequately address potential limitations of the proposed method, such as the choice of hyperparameters and the sensitivity to different interpolation strategies.', 'The paper primarily focuses on CIFAR-10 and CIFAR-100 datasets, which may limit the generalizability of the results.', 'The impact of different values for the entropy maximization parameter and other hyperparameters needs further investigation.', 'The potential limitations and negative societal impacts of the proposed method are not adequately addressed.']",False,3,2,3,5,4,"['Addresses a significant problem in neural networks: improving uncertainty estimates while maintaining high accuracy.', 'The approach is simple and does not require modifications to the network architecture.', 'Comprehensive experiments on CIFAR-10 and CIFAR-100 datasets demonstrate improved performance over several baselines.', 'The method is computationally efficient compared to other state-of-the-art methods.']","['The idea of entropy regularization is not entirely novel, and the paper does not provide significant novelty beyond the specific implementation of Mix-MaxEnt.', 'The paper lacks detailed ablation studies for key components, such as the choice of hyperparameters for the entropy regularizer and the impact of different interpolation strategies.', 'The manuscript is lengthy and somewhat convoluted, making it difficult to follow the core contributions and experimental results.', 'The incremental improvement over existing methods may not be substantial enough to warrant acceptance in a top-tier conference.', 'The impact of the proposed method on different types of neural network architectures is not thoroughly explored.', 'The comparison to more recent approaches in uncertainty estimation is limited.', 'The potential limitations and negative societal impacts of the proposed method are not adequately addressed.']",3,3,2,3,Reject
z3Tf4kdOE5D,"The paper proposes FEDDISCRETE, a federated learning framework using a probabilistic discretization mechanism to enhance robustness against weight poisoning attacks. The method transforms continuous model weights into discrete ones, aiming to protect the integrity and privacy of federated learning systems. Theoretical analyses on utility, robustness, and convergence are provided, and empirical validation is conducted on several image classification datasets.","['Can the authors provide more detailed explanations and better organization to improve clarity?', ""Can the authors include more comprehensive experimental results to validate the method's effectiveness in real-world scenarios?"", 'How does FEDDISCRETE compare with more recent defense mechanisms not included in the current experiments?', 'Can the authors elaborate on potential strategies to extend FEDDISCRETE to cross-silo federated learning settings?', 'Can you provide more detailed descriptions and pseudocode for the proposed algorithms?', 'Can you include more comprehensive ablation studies to evaluate the impact of different components of FEDDISCRETE?']","[""The method's applicability to real-world scenarios with varying client participation needs further validation."", 'The method is not suitable for cross-silo federated learning settings.', 'The approach cannot defend against Byzantine attacks.', 'Theoretical proofs and algorithm descriptions lack clarity and detailed explanations, which can make it difficult for readers to fully understand and reproduce the results.']",False,2,2,2,4,4,"['Addresses a significant issue in federated learning: defending against weight poisoning attacks.', 'Proposes a novel probabilistic discretization mechanism to enhance security.', 'Theoretical analyses cover utility, robustness, and convergence.', 'Empirical evaluations show potential effectiveness against various attacks.']","['The paper lacks clarity in several sections, making it difficult to follow.', ""Experimental validation is not sufficiently detailed to fully establish the method's effectiveness."", 'The practical applicability of the method in real-world scenarios, particularly in cross-silo federated learning, needs further validation.', 'The paper lacks detailed comparisons with recent and advanced defense mechanisms.', 'Insufficient ablation studies to explore the impact of different hyperparameters and settings.']",3,2,2,3,Reject
a34GrNaYEcS,"The paper presents RP-DRO, a method for Distributionally Robust Optimization (DRO) that employs parametric likelihood ratios to address distribution shifts. The approach removes the dependency on generative models, enabling broader applicability. The authors introduce three key components: mini-batch level normalization, a KL penalty, and simultaneous gradient updates, which together ensure robust performance. Extensive experiments on text and image classification tasks show that RP-DRO achieves better robustness and stability compared to nonparametric and parametric baselines.","['Can the authors provide more insights into the choice of adversary architectures and their impact on the performance of RP-DRO?', 'Are there any potential optimizations or strategies to reduce the computational overhead associated with training the adversary?', 'Can the authors provide more details about the autoencoder aggregator and its role in the framework?', 'How does the choice of hyper-parameters, particularly the KL penalty weight, affect the performance of RP-DRO?', 'How does RP-DRO perform on more complex tasks or in domains other than text and image classification?']","[""The primary limitation discussed is the computational overhead of training an additional adversary model, which could affect the method's practicality for large-scale applications. The authors suggest exploring parameter sharing and parallel computation as future directions."", 'The scalability of RP-DRO to larger models and datasets, as well as the potential computational overhead introduced by the simultaneous training of the adversary model, should be discussed.', 'The environmental impact of the increased computational requirements should be addressed.', 'Potential negative societal impacts, such as biases in the adversarial model, should be considered and mitigated.']",False,3,3,3,6,4,"['The proposed RP-DRO method is a significant advancement in the field of DRO, removing the dependency on generative models and allowing for the use of discriminative architectures.', 'The paper presents a thorough set of experiments on diverse benchmarks (text and image classification), demonstrating the robustness and stability of RP-DRO.', ""The authors introduce novel techniques such as mini-batch level normalization and simultaneous gradient updates, which are shown to be crucial for the method's performance."", 'The paper is well-written and clearly organized, making it easy to follow the methodology and experimental results.']","['The experiments, while comprehensive, could benefit from additional datasets to further validate the generalizability of RP-DRO.', 'The choice of adversary architectures could be explored in more detail, providing a deeper understanding of their impact on performance.', 'The computational overhead of jointly training a second neural model (the adversary) is acknowledged but not thoroughly addressed in terms of potential optimizations.', 'Some methodological aspects, particularly the autoencoder aggregator, lack clarity and detailed explanation.']",3,3,3,4,Accept
izvwgBic9q,"The paper presents an innovative unsupervised learning approach for Full-Waveform Inversion (FWI) by integrating Convolutional Neural Networks (CNN) and Partial Differential Equations (PDE) in a loop. The method, named UPFWI, aims to overcome the limitations of both physics-driven and data-driven methods. The authors also introduce a new large-scale dataset, OpenFWI, to benchmark their method. Experimental results show that UPFWI achieves comparable and sometimes better performance than supervised methods, especially when more seismic data is involved.","['Can the authors provide more details on the autoencoder aggregator and its role in the proposed method?', 'How are the boundary conditions handled during forward modeling to avoid reflection artifacts?', 'Can the authors provide additional comparisons with existing methods and more ablation studies to validate the robustness and generalizability of the method?', 'Can the authors provide more details on the computational efficiency of their method, specifically regarding memory consumption and training speed?', 'How does the method perform when evaluated on different real-world datasets beyond OpenFWI?', 'Can the authors elaborate on the choice of hyperparameters for the perceptual loss and their impact on the results?']","[""The paper needs to address the clarity of methodological details and provide more rigorous validation of the proposed method's impact and robustness. Additionally, the method's performance under different noise levels and missing data conditions needs further validation."", 'The authors acknowledge that the method needs improvement on velocity maps with very close adjacent layer values. They also mention the high memory consumption and speed requirements for forward modeling. Future work could explore different loss functions and methods to balance computational resources and accuracy.']",False,3,3,3,5,4,"['The proposed method addresses a significant challenge in geophysics by integrating CNN and PDE in an unsupervised learning loop, which is novel and impactful.', 'The introduction of the OpenFWI dataset provides a valuable benchmark for future research in the field.', 'The experimental results are comprehensive, demonstrating the potential of UPFWI to achieve high accuracy, especially with more data.']","['The paper lacks clarity on some technical aspects, such as the details of the autoencoder aggregator and the handling of boundary conditions during forward modeling.', 'The novelty and impact of the method need more rigorous validation through additional comparisons and ablation studies.', 'The robustness of the method under different noise levels and missing data conditions needs further validation.', 'The computational efficiency of the proposed method, especially in terms of memory consumption and speed during training, needs more discussion.', 'The evaluation section could include comparisons with a wider range of baselines beyond the three mentioned.', 'The paper would benefit from more visualizations and qualitative analysis to support the quantitative results.']",3,3,3,4,Reject
7pZiaojaVGU,The paper establishes an equivalence between data poisoning and Byzantine gradient attacks in personalized federated learning systems. It introduces the concept of gradient-PAC* learning and provides both theoretical proofs and empirical validation. The findings have significant implications for the security of federated learning systems.,"['Can the authors provide more intuitive explanations and examples for key concepts like gradient-PAC* learning?', 'Are there additional empirical scenarios or baselines that can be included to further validate the findings?', 'Can the theoretical sections be restructured for better clarity and readability?', 'How do the assumptions made in the theoretical analysis hold in practice, especially for deep learning models?', 'Can the empirical evaluation be extended to more diverse settings to demonstrate the robustness of the proposed attack?', 'How does the proposed method compare to existing data poisoning and Byzantine attack methods in terms of effectiveness and computational efficiency?']","['The paper should address the limitations related to the clarity and comprehensibility of the theoretical sections.', 'Additional empirical scenarios and comparisons with more baselines should be considered to strengthen the evaluation.', 'The authors should address the assumptions made in their theoretical analysis and discuss their validity in practical scenarios.', 'The empirical evaluation should be extended to more diverse settings and models to demonstrate the robustness and generalizability of the proposed attack.', 'The paper does not adequately address the potential limitations of the proposed methods, such as scalability and applicability to real-world scenarios. Additionally, the ethical implications of deploying such attacks are not discussed in depth.']",False,3,2,3,5,4,"['The problem tackled is significant and relevant to the field of federated learning and security.', 'The paper provides a novel theoretical framework that links data poisoning to Byzantine gradient attacks.', 'Extensive theoretical proofs are provided to support the claims.', 'Empirical evaluations support the theoretical findings and demonstrate the effectiveness of the proposed attack in practical scenarios.']","['The paper is dense and challenging to follow, especially the theoretical sections. More intuitive explanations and better structuring of proofs are needed.', 'The empirical evaluations, while extensive, could benefit from additional scenarios and more diverse comparisons.', 'Some key concepts, like gradient-PAC* learning, are not explained intuitively, making it difficult for readers to grasp their significance and implications.', 'Theoretical analysis relies on assumptions that may not hold in more complex models, particularly deep learning models.', 'Detailed proofs are relegated to the appendix, which may hinder understanding and reproducibility.', 'The novelty of the attack methodology is questionable; similar concepts have been explored in prior works.']",3,3,2,4,Reject
30SXt3-vvnM,"The paper proposes a kernelized classification layer for deep neural networks to enhance the effectiveness of embeddings produced by limited-capacity backbones. This layer optimizes over all possible radial kernel functions to find an optimal nonlinear classifier, significantly improving model efficiency and performance in various tasks, including image classification and natural language understanding.","['Can the authors provide more detailed ablation studies and additional experiments to validate their claims?', 'How does this method compare with a broader range of existing methods in kernelized deep learning?', 'Can the authors improve the clarity of the theoretical sections to make them more accessible?', 'Can the authors provide a more detailed discussion on the potential broader impact and applications of their method?', 'What are the computational costs and scalability considerations for the proposed method in real-world applications?', 'How does the added complexity of the kernelized layer affect real-world applications in terms of inference time and resource usage?', 'Can the authors provide more details on the autoencoder aggregator and its role in the proposed method?', 'How does the proposed method handle potential limitations and societal impacts?']","['The paper does not sufficiently address the limitations in the experimental evaluation.', 'The potential negative societal impact is not adequately discussed.', 'The computational cost and scalability of the proposed method in real-world applications need to be addressed.', 'More ablation studies are needed to thoroughly understand the contributions of different components.']",False,3,2,3,5,4,"['The idea of using a kernelized classification layer to improve model efficiency is intriguing.', 'The theoretical foundation is solid, providing a comprehensive background on kernel methods.', 'The paper includes a variety of applications, including computer vision and natural language processing tasks.', 'The method shows clear improvements in performance across multiple tasks, demonstrating its versatility.']","['The novelty is somewhat limited as kernel methods in deep learning are not entirely new.', 'Experimental evaluation lacks depth, with insufficient comparison to a broad range of baselines. Including comparisons with more recent kernelized deep learning methods would strengthen the evaluation.', 'The clarity of the paper could be improved, especially in the theoretical sections. Simplifying the explanations and providing more intuitive descriptions would help.', 'The significance and potential impact of the work are moderate, with limited discussion on broader applications and implications.', 'The ethical considerations are somewhat generic and could be expanded. Specific concerns such as the potential for bias amplification in classification tasks should be addressed.', 'Potential practical limitations and pitfalls, such as the computational cost and scalability in real-world scenarios, are not adequately addressed. Detailed analysis of inference time and resource usage would be beneficial.', 'More ablation studies are needed to understand the contributions of different components more thoroughly (e.g., the impact of different kernel choices and the scalability of the proposed approach).']",3,3,2,3,Reject
WxuE_JWxjkW,"The paper investigates the expressivity of emergent languages in referential games, proposing that expressivity is a trade-off between contextual complexity and unpredictability. It introduces a novel measure of expressivity based on generalization performance and highlights the problem of message type collapse, proposing the use of contrastive loss to mitigate this issue.","['Can the authors provide more details on the autoencoder aggregator?', 'Could additional ablation studies be conducted on the modulation function and different types of aggregators?', 'What are potential limitations or future directions for this line of research?', 'Can the authors provide more empirical evidence to support the discussion on mutual information as a measure of expressivity?', 'How do different factors such as the channel capacity and agent capacity specifically influence the results?', 'Can the authors clarify the definitions and methodology used in the experiments, particularly the measure of expressivity and the experimental setup?', 'Can the authors provide more examples in the qualitative analysis?', 'What is the impact of different modulation functions on the results?', 'Can the authors explore the practical implications and potential applications of their findings?', 'Can more ablation studies be included to isolate the effects of different components of their approach?', 'What are the limitations and potential negative societal impacts of this work?']","['The clarity of the paper needs improvement, and additional ablation studies are necessary to fully validate the findings. These points should be addressed to strengthen the paper.', 'The paper does not address potential limitations or negative societal impacts of the work. It would be beneficial to discuss these aspects to provide a more balanced view.']",False,3,2,3,4,4,"['Addresses an important and underexplored aspect of emergent languages in AI.', 'Introduces a novel hypothesis about the interplay between contextual complexity and unpredictability.', 'Comprehensive experimental setup covering a wide range of referential games and contexts.', 'Provides a new measure of expressivity and validates it through extensive experiments.', 'Discovery of message type collapse and the proposed solution using contrastive loss are valuable contributions.']","['The paper lacks clarity in some sections, making it difficult to follow the methodology and results.', 'Additional ablation studies, particularly on the modulation function and different types of aggregators, could strengthen the findings.', 'The autoencoder aggregator is not well-explained, and more details are needed to understand its implementation.', 'The novelty of the hypothesis is somewhat limited as it builds on existing theories from human communication studies.', 'The discussion of mutual information as a measure of expressivity is not entirely convincing and could be expanded with more empirical evidence.', 'Practical implications and potential applications are not well-articulated.', 'The proposed measure of expressivity relies on indirect evaluation which may not capture all aspects of expressivity.', 'There is a lack of discussion on the limitations and potential negative societal impacts of the work.']",3,3,2,3,Reject
MvO2t0vbs4-,"The paper revisits the use of ensembles and cascades in machine learning, providing a comprehensive analysis of their efficiency and accuracy compared to modern single-model architectures. The authors show that simple ensemble and cascade methods can outperform state-of-the-art models across various tasks and architectures, including EfficientNet, ResNet, MobileNetV2, and ViT.","['Can the authors provide more detailed ablation studies or discussions on the limitations of the ensemble and cascade approach?', 'How do the results generalize to other types of models or tasks not covered in the paper?', 'Can the authors provide more detailed ablation studies on the choice and combination of models within cascades?', 'What are the potential limitations or challenges of deploying committee-based models in real-world production environments?', 'How do the proposed methods handle the increased complexity of managing multiple models, especially in terms of maintenance and updates?', 'Can the authors elaborate on the potential limitations of committee-based models in terms of memory usage and real-time application bottlenecks?', 'How does the diversity of models in an ensemble/cascade impact the performance? Are there any specific architectures that perform better together?', 'Can the authors provide more details on the calibration process and its impact on ensemble performance?', 'How are the confidence thresholds determined in practice, and what is the computational cost of this grid search?', 'Are there any specific challenges or limitations encountered when applying these methods to different tasks?']","['The paper could benefit from a more detailed discussion on the limitations and potential drawbacks of using ensembles and cascades, such as the increased complexity in managing multiple models.', 'The lack of novelty and some missing details on the experimental setup and hyperparameters.', 'The primary limitation is the lack of discussion on memory usage and potential bottlenecks in real-time applications.', 'The impact of model diversity in the ensemble/cascade could be explored further.']",False,3,4,3,6,4,"['The paper addresses an important and practical problem by revisiting ensemble and cascade methods, which are often overlooked in recent literature.', 'The authors conduct a thorough empirical evaluation across multiple tasks and architectures, demonstrating the practical benefits of these methods.', 'The results show significant improvements in efficiency and accuracy, providing a strong case for considering ensembles and cascades in real-world applications.', 'The paper is well-organized and clearly written, making it easy to follow the experiments and results.']","['The paper does not propose a novel method but rather revisits and thoroughly evaluates existing techniques.', 'Some additional ablation studies or more detailed discussions on the limitations and potential drawbacks of this approach could strengthen the paper.', 'The analysis of the impact of different model architectures within cascades is somewhat limited.', 'The paper does not adequately address potential limitations or negative societal impacts of the proposed methods.', 'The presentation could be improved, as some parts of the paper are dense and require careful reading to understand the methodology and results.']",3,4,4,3,Accept
IptBMO1AR5g,"The paper proposes a novel regularization method for deep neural networks by penalizing the trace of the Hessian matrix using stochastic estimators and dropout techniques. This method aims to improve generalization and stability, showing promising results in various experiments.","['Can the authors provide more detailed theoretical analysis of the proposed method?', 'Could you clarify the workings of the dropout-based estimator in more detail?', 'How does the proposed method compare with other potential stochastic regularization techniques?', 'What is the impact of varying the dropout probabilities and the number of iterations in SEHT?', 'Can you provide more details on the implementation and computational cost of the proposed methods?', 'Can you include more ablation studies on the impact of different parameters (e.g., probability values) in the dropout-based estimator?', 'How does the method scale with larger models and datasets?', 'Could you compare the proposed method with a broader range of regularization techniques?']","['Potential limitations in broader contexts and practical applicability are not fully addressed.', 'The stochastic nature of the estimator might introduce variability in performance.', 'The paper should discuss the potential limitations in scalability and computational efficiency, especially with larger models and datasets.', 'More details on the implementation of the dropout-based estimator would enhance clarity.']",False,3,3,3,5,4,"['Addresses a relevant problem in deep learning: overfitting.', 'Introduces a novel regularization approach using the trace of the Hessian matrix.', 'Experimental results show improvement over existing regularization techniques.', 'Provides both theoretical motivation and empirical validation.']","['Theoretical analysis could be more rigorous.', 'Clarity in certain sections, such as the dropout-based estimator, needs improvement.', 'Lacks thorough comparison with all potential competing methods.', 'Additional ablation studies are needed to understand the impact of various components.', 'The connection to dynamical systems, while interesting, feels somewhat tangential and not fully integrated into the empirical study.']",3,3,3,4,Reject
NuzF7PHTKRw,"The paper proposes a novel framework called Environment-Adversarial Sub-Task Curriculum (EAT-C) for improving reinforcement learning (RL) efficiency and robustness. It introduces a co-operative planning policy to decompose a task into sub-tasks and an adversarial environment generator to modify these sub-tasks, creating a curriculum that adapts to the RL agent's progress. The approach is validated through extensive experiments on diverse benchmark tasks, showing significant advantages over existing methods.","['Can the authors provide more details on the computational resources required for jointly training the three policies?', 'How does the approach perform on more complex and dynamic environments beyond the benchmarks used in the paper?', 'Can the authors clarify the training procedures for the planning and environment policies, particularly how they interact with the RL policy?', 'Can the authors provide more detailed explanations of the notations and terminology used in the methodology section?', 'How does the environment generator (EG) ensure that the modified environments are feasible and not overly adversarial?', 'Can the authors provide additional ablation studies to isolate the contributions of the planning policy and the adversarial policy independently?', 'How does EAT-C compare to state-of-the-art hierarchical RL methods in terms of performance and computational complexity?']","['The main limitations include the potential over-complexity of the approach and the need for substantial computational resources.', 'The generalizability to more diverse environments is not fully explored.', 'The paper could benefit from additional clarity on experimental settings and hyperparameters to enhance reproducibility.', 'More ablation studies would strengthen the evaluation of the proposed method.', 'Exploring the scalability of the method to more complex tasks would provide further insights into its applicability.']",False,3,2,3,5,4,"['The paper addresses a critical challenge in RL: improving efficiency and robustness in long-horizon tasks with sparse rewards.', 'The proposed EAT-C framework is novel, combining curriculum learning with adversarial environment generation.', 'Extensive experiments demonstrate the effectiveness of the approach, with significant improvements over strong baselines.']","['The joint training of three policies (RL, planning, and environment generation) could be overly complex and might require substantial computational resources.', 'The clarity of the paper is a major concern, with several reviewers noting that the methodology and experimental setup are difficult to follow.', 'The generalizability of the approach to more diverse and complex environments is not fully explored.', 'The novelty of the approach is questioned by some reviewers, as it combines existing techniques without significant innovation.', 'The paper lacks comprehensive ablation studies and detailed comparisons with state-of-the-art methods.']",3,3,2,3,Reject
zuDmDfeoB_1,"The paper investigates the scenarios under which Model-Agnostic Meta-Learning (MAML) provides a significant performance gain over Non-Adaptive Learning (NAL). The authors focus on the task hardness and the landscape of the training tasks to draw their conclusions. They provide theoretical analyses and empirical results in both linear regression and neural network settings, along with image classification experiments to support their findings.","['Can the authors provide more intuitive explanations for the theoretical results?', 'Can the empirical section be expanded to include more datasets and configurations?', 'How can the theoretical findings be applied to real-world scenarios?', 'How do the results generalize to other meta-learning algorithms beyond MAML?', 'Can you provide more rigorous analysis and results for non-linear settings, especially neural networks?', 'Can you include more diverse datasets and additional baselines in the empirical validation?', 'Please clarify and better structure the theoretical sections for improved readability.', 'Can you discuss the limitations of your theoretical assumptions and their practical implications?', 'Please address any potential ethical concerns or societal impacts of your work.']","['The paper is dense and may be hard to follow in some sections. Additionally, the empirical evaluation is somewhat limited and could be expanded.', 'The theoretical assumptions, such as task hardness and geography, might not hold in all practical scenarios.', 'The practical implications of the theoretical results are not thoroughly discussed.']",False,3,3,3,7,4,"['The paper addresses an important aspect of meta-learning: understanding when MAML is most beneficial compared to NAL.', 'The theoretical analyses are thorough and provide clear conditions under which MAML outperforms NAL.', 'The paper includes empirical validation in both linear regression and neural network settings, which helps to bridge the gap between theory and practice.', 'The analysis of task hardness and geography provides a novel perspective that is distinct from the representation learning view often taken in meta-learning literature.']","['Some sections of the paper, particularly the theoretical parts, are dense and may be hard to follow for a general audience. Improved clarity and more intuitive explanations would enhance readability.', 'The experiments on image classification are somewhat limited. Expanding these experiments to include more datasets and different configurations would strengthen the empirical evidence.', 'The practical implications of the theoretical findings are not fully explored. For instance, how these findings can be applied to real-world scenarios needs further elaboration.', 'The paper does not adequately discuss the limitations and potential negative societal impacts of the work. Given the highly theoretical nature of the paper, it would be beneficial to discuss the assumptions made and the limitations of these assumptions in practical scenarios.']",3,3,3,4,Reject
4Muj-t_4o4,"The paper introduces a method for learning a subspace of policies for online adaptation in reinforcement learning, targeting scenarios where the test environment differs from the training environment. The approach involves constructing a convex hull of policies in the parameter space, defined by a set of anchor policies, allowing for fast adaptation during the test phase by sampling and selecting the best-performing policy. The method is validated across various benchmarks, showing competitive performance.","['Can the authors provide more detailed explanations or visualizations to make the methodology clearer?', 'How does the proposed method compare with state-of-the-art meta-RL approaches in terms of computational efficiency and adaptation performance?', 'Can the authors discuss the computational overhead of maintaining and sampling from the policy subspace?', ""Can the authors provide more theoretical analysis to support the claims made about the method's effectiveness?"", 'How does the performance of the proposed method vary with different hyper-parameter settings, particularly the β value?', 'What are the computational requirements for training and adapting the proposed method compared to the baselines?', 'Can the authors provide more detailed ablation studies to understand the contributions of different components of the proposed method?', 'Could the authors clarify the implementation details regarding the critic and policy networks?', 'Would it be possible to include more qualitative analyses and visualizations of the learned policies in different environments?']","['The main limitations include the potential complexity of the proposed method and the unclear computational overhead. The authors should also address the fairness of baseline comparisons and explore the practical implications of their approach in real-world scenarios.', 'The reliance on extensive hyper-parameter tuning, particularly the β value, raises concerns about the robustness and generalizability of the reported results.', 'The paper does not adequately address the computational cost associated with training and adapting the proposed method, which could limit its practical applicability.', ""The method's performance is dependent on the anchor parameters' selection, which might be non-trivial in complex environments."", 'The experimental setup and results presentation could be more streamlined for clarity.']",False,3,2,3,5,4,"['Addresses a practical issue in reinforcement learning related to generalization across different environments.', 'Proposes a novel method of representing a range of policies using a convex hull in parameter space, potentially enabling more robust adaptation.', 'Extensive experimentation across various benchmarks demonstrates the potential of the method.']","['The paper suffers from clarity and readability issues; the methodology and results sections are particularly dense and hard to follow.', 'Theoretical foundation is weak, with insufficient analysis to support the claims made about the effectiveness of the method.', 'Hyperparameter tuning for baselines might not be fair, leading to potential biases in the comparative results.', 'Lack of comparison with some strong baselines, such as recent advancements in meta-RL and robust RL, weakens the claim of superiority.', 'The practical implications and computational costs of maintaining and sampling from the policy subspace are not thoroughly discussed.', 'The paper could benefit from more detailed ablation studies to better understand the contributions of different components of the proposed method.']",3,3,2,3,Reject
m5EBN92vjN,"The paper introduces the Attention Aware Network (AASeg) for real-time semantic segmentation, integrating Spatial Attention (SA), Channel Attention (CA), and Multi Scale Context (MSC) modules. The network is evaluated on Cityscapes, ADE20K, and CamVid datasets, showing competitive results in terms of mean IoU and FPS.","['Can you provide more details about the implementation of the autoencoder aggregator?', 'Have you considered different configurations for the attention modules, such as varying the number of attention heads?', 'How does the model handle potential biases in the training data? Have you evaluated its robustness to adversarial attacks?', 'Can the authors provide more technical details on the MSC module and its integration with SA and CA modules?', 'How does the proposed method compare with state-of-the-art methods under the same experimental settings?', 'Can the authors conduct more thorough ablation studies to evaluate the contribution of each component, including different upsampling methods and kernel sizes?', 'Can you provide a more detailed theoretical analysis to support the proposed method?', 'Can you provide more detailed explanations and clearer visualizations of the experimental results?', 'How does the proposed method compare to existing methods in terms of computational complexity and resource requirements?', 'Can you include more visualizations and case studies in the qualitative analysis to better demonstrate the effectiveness of the proposed network?', 'How does the MSC module differ from existing multi-scale approaches in the literature?', 'Can the authors provide more details on how their spatial and channel attention modules differ from existing methods?', 'What are the potential limitations of the proposed AASeg network, and how do the authors plan to address them in future work?']","['The paper does not discuss the robustness of the model to adversarial attacks or biases in the training data.', 'The scalability and generalization of the proposed method to different real-world applications are not addressed.', 'The main limitation is the lack of clarity on certain components and the need for more qualitative analysis.', 'The paper lacks a thorough theoretical analysis and detailed explanations of the experimental results.']",False,2,2,2,4,4,"['The integration of attention mechanisms and multi-scale context information is well-motivated.', 'The paper addresses the balance between speed and accuracy in real-time applications.', 'Competitive performance on standard benchmarks is demonstrated.']","['The novelty of the proposed modules is questionable, as similar techniques have been explored in prior work.', 'The paper lacks sufficient detail in the methodology, particularly regarding the autoencoder aggregator and the exact configuration of the attention modules.', 'The clarity of the paper is lacking, with insufficient explanations and visualizations.', 'The experimental evaluation is not comprehensive enough, with limited ablation studies and comparisons with state-of-the-art methods.', 'Potential limitations and ethical concerns are not adequately addressed.']",2,2,2,3,Reject
mqIeP6qPvta,"The paper introduces FoveaTer, a foveated vision transformer model that mimics biological visual systems by using varying spatial resolution and eye movements for image classification. The model dynamically determines fixation locations based on transformer attention mechanisms, reducing computational costs while maintaining high classification accuracy. The robustness against adversarial attacks is also evaluated, demonstrating superior performance compared to full-resolution models.","['Can the authors provide more details on the implementation of the foveation module and the accumulator?', 'How does the dynamic-stop mechanism impact the overall performance, and are there scenarios where it may not be as effective?', 'Would different pooling strategies or configurations affect the results, and if so, how?', 'Can you provide more detailed ablation studies to isolate the contributions of the foveation module and the dynamic-stop mechanism?', 'Could you elaborate on the implementation details of the foveation module and the guided fixation sequence prediction?', 'Have you considered testing the model on other datasets with higher variability in object size and complexity?']","['The clarity of certain components, such as the foveation module and the accumulator, could be improved.', 'The impact of the dynamic-stop mechanism and different pooling strategies should be further evaluated.', 'The robustness results against adversarial attacks, although promising, require more detailed analysis and comparisons with other models.', ""The dynamic-stop mechanism's impact on computational savings is not thoroughly explored."", 'Limited baseline comparisons and datasets might affect the generalizability of the conclusions.']",False,3,3,3,6,4,"['The idea of incorporating foveated vision into transformer models is novel and biologically inspired.', 'The method shows significant computational savings while achieving similar or better accuracy compared to full-resolution models.', 'The robustness of the model against adversarial attacks is well demonstrated.', 'The paper includes comprehensive experiments and comparisons, providing strong empirical evidence for the proposed method.']","['The paper could benefit from more detailed explanations of certain components, such as the foveation module and the accumulator.', 'The dynamic-stop mechanism for fixation exploration could be further clarified and evaluated in different scenarios.', 'Ablation studies on the impact of different pooling strategies or configurations would strengthen the conclusions.', 'The clarity of some sections could be improved, and more detailed descriptions of the foveation module and guided fixation sequence prediction are needed.', 'The performance is only evaluated on ImageNet-100 and ImageNet datasets. Testing on additional datasets would strengthen the conclusions.']",3,3,3,3,Reject
JXSZuWSPH85,"The paper proposes a novel inverse reinforcement learning (IRL) method called SOLO-IRL, which incorporates adversarial one-class classification to estimate rewards using only expert trajectories. This approach eliminates the need for baseline trajectories and aims to achieve computational efficiency and high performance. The method is validated in various OpenAI Gym environments.","['Can you provide a more detailed explanation of how the adversarial one-class classification framework is integrated into the IRL framework?', 'What specific noise parameters were used in the experiments, and how sensitive is the method to changes in these parameters?', 'Can you provide additional ablation studies to demonstrate the contribution of each component of the proposed method (e.g., the effect of different noise levels, the importance of the reconstruction loss)?', 'Can the authors provide more theoretical justification for the combination of one-class classification and IRL?', 'What are the specific hyperparameters used in the experiments, and how sensitive are the results to these hyperparameters?', 'Can the authors include more details about the implementation and the potential limitations of the proposed approach?', 'How does the proposed method perform in comparison to a broader set of benchmarks and in different environments?']","['The paper should discuss the sensitivity of the method to the choice of noise parameters in more detail.', 'The potential for negative societal impacts or ethical concerns, such as the misuse of IRL in sensitive applications, should be addressed.']",False,2,2,2,4,4,"['Addresses a significant challenge in IRL by eliminating the need for baseline trajectories.', 'Proposes a novel combination of adversarial one-class classification with IRL.', 'Claims of computational efficiency due to the offline nature of the method without requiring an inner loop for reward estimation.', 'The experiments cover a range of environments, including both discrete and continuous action spaces.']","['The clarity of the methodology is lacking in some parts, particularly the explanation of the adversarial one-class classification framework and how it integrates with IRL.', 'The experimental results do not convincingly demonstrate the superiority of SOLO-IRL over existing methods in complex environments.', 'The paper lacks detailed sensitivity analyses and ablation studies to understand the contribution of each component of the proposed methodology.', 'Potential limitations and negative societal impacts are not adequately discussed.']",3,2,2,3,Reject
D78Go4hVcxO,"The paper 'HOW DO VISION TRANSFORMERS WORK?' provides a detailed investigation into the behavior of multi-head self-attentions (MSAs) in Vision Transformers (ViTs). It explains how MSAs improve accuracy and generalization by flattening loss landscapes, compares MSAs with convolutional layers (Convs), and introduces a new model called AlterNet that integrates MSAs into CNNs. The paper presents a series of experiments to support its claims, showing that MSAs act as low-pass filters and can complement Convs, leading to improved performance.","['Can the authors provide more detailed ablation studies to isolate the effects of different components in the AlterNet model?', 'How do the findings apply to other tasks beyond image classification, such as object detection or segmentation?', 'Can the authors provide more details on the experimental setups and hyperparameters to ensure reproducibility?', 'How do the findings of this paper translate to real-world applications and practical scenarios?', 'Can the authors clarify the theoretical justifications for some of the claims made in the paper?']","['The paper discusses potential limitations, including the non-convex losses caused by MSAs in small data regimes. However, it could more thoroughly address the broader applicability of the findings to different types of tasks and datasets.', 'The paper does not adequately address the practical significance and real-world applicability of the findings. The authors should provide more context and examples of how the proposed methods can be used in practical scenarios.', ""The paper could be clearer in some sections, particularly around the autoencoder aggregator. Additional ablation studies would further strengthen the paper's claims."", 'The paper does not extensively discuss the limitations of the proposed method AlterNet. For instance, the computational complexity and scalability of combining MSAs and Convs are not well-addressed.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,6,4,"['The paper addresses an important and timely topic, providing insights into the behavior of MSAs in ViTs.', 'It presents novel findings, such as the complementary nature of MSAs and Convs and the introduction of the AlterNet model.', 'The experiments are comprehensive, covering a range of datasets and scenarios to support the claims.', 'The paper is well-organized and clearly written, making complex concepts accessible.']","['The paper could benefit from more detailed ablation studies to isolate the effects of different components in the proposed model.', 'Some explanations, particularly those related to the theoretical underpinnings of MSAs as spatial smoothings, could be more rigorous.', 'The impact of the findings on practical applications beyond image classification is not fully explored.', 'The paper lacks clarity in certain sections, making it difficult to follow the methodology and results.', 'There are concerns about the reproducibility of the experiments due to insufficient details in the experimental setups.', 'The practical significance and real-world applicability of the findings are not well-justified.']",4,3,3,4,Reject
8QE3pwEVc8P,"The paper proposes a novel method, Zero-Cost-PT, which improves the operation scoring in differentiable NAS by using zero-cost proxies. This method is demonstrated to be faster and more accurate than existing methods on several benchmarks.","['Could you provide more details on how the zero-cost proxies are integrated into the NAS framework?', 'Can you discuss the limitations and potential negative societal impacts of your work in more detail?', 'Can the authors provide more details on the implementation of zero-cost metrics and the autoencoder aggregator?', 'Can the authors conduct more thorough ablation studies to better understand the impact of different components and choices in the proposed method?', 'Can the authors provide more details on the hyperparameter selection and its impact on the results?', 'How does the method perform on other non-DARTS search spaces?', 'Can the authors provide a more detailed explanation of the Zero-Cost-PT algorithm, including pseudocode or a flowchart?', 'Can the authors perform additional ablation studies to demonstrate the individual contributions of each component of the proposed method?', 'How does the proposed method perform on different types of search spaces beyond those already evaluated?', 'Can the authors provide theoretical justification for why the zero-cost proxies combined with perturbation should work better than existing methods?', 'Can you provide more details on the computation of zero-cost proxies?', 'Have you conducted any ablation studies on the impact of different zero-cost proxies?', 'What are the potential limitations in the scalability and robustness of Zero-Cost-PT?']","['The paper does not provide a detailed discussion on the limitations and potential negative societal impacts.', 'The paper should address the clarity of the explanation of its components and provide more comprehensive ablation studies.', 'The paper does not address the potential limitations of zero-cost proxies in various search spaces comprehensively.', 'The impact of the method in real-world scenarios is not thoroughly discussed.', 'The paper lacks detailed discussions on the potential limitations of the proposed method, particularly in terms of scalability and robustness.']",False,2,2,3,4,4,"['The paper addresses a significant problem in differentiable NAS, which is the inefficiency and potential inaccuracy of existing operation scoring methods.', 'The introduction of zero-cost proxies in differentiable NAS is novel and well-motivated.', 'Comprehensive empirical evaluations demonstrate the effectiveness of the proposed method across multiple benchmarks.']","['The paper could benefit from a more detailed explanation of how the zero-cost proxies are integrated into the NAS framework.', 'The discussion on the limitations and potential negative societal impacts of the work is limited.', 'The ablation studies are not thorough enough to fully understand the impact of various components and choices in the proposed method.', 'Some experimental details and hyperparameter justifications are lacking clarity.', 'The robustness of the proposed method across different search spaces is questionable.', 'The real-world impact and adoption of the method remain uncertain.']",3,2,2,3,Reject
reFFte7mA0F,"The paper proposes a novel approach, Conditional Expectation based Value Decomposition (CEVD), to improve the scalability and performance of on-demand ride pooling systems. The method addresses the limitation of existing value decomposition methods by incorporating the impact of other agents' actions using conditional expectations. The proposed method is evaluated on a real-world taxi dataset and shows significant improvements over the current state-of-the-art method, NeurADP.","['Can the authors provide more clarity on the mathematical formulations and the assumptions made in the conditional probabilities?', 'How sensitive is the proposed method to the choice of hyperparameters and the clustering algorithm?', 'Can the authors provide more details on the implementation and experimental setup to ensure reproducibility?', 'Have the authors considered any limitations or potential negative societal impacts of their proposed method? If so, can they elaborate on these?', 'Can the authors conduct an ablation study to demonstrate the individual contributions of the components of the CEVD method?', 'How does the proposed method scale with a larger number of vehicles and clusters?', 'Can the authors provide more detailed explanations and visualizations for the CEVD framework to enhance clarity?']","['The paper should address the clarity of the methodology section and provide more detailed descriptions of the experimental setup.', 'The assumptions made for the conditional probabilities and clustering should be further justified and validated.', 'The paper does not adequately address potential limitations and negative societal impacts of the proposed approach.', 'A more thorough analysis of these aspects is needed to understand the broader implications of the method.', 'The paper should include more ablation studies to understand the contributions of different components better.']",False,3,2,3,5,4,"['Addresses a significant and practical problem in on-demand ride pooling.', 'Introduces a novel approach to account for dependencies among agents using conditional probabilities, which is an improvement over existing methods.', 'Provides extensive experimental results showing significant improvements over the state-of-the-art approach (NeurADP).']","['The paper is dense and the methodology section is not very clear, making it difficult to follow the mathematical formulations and the implementation details.', 'The assumptions made in the method, particularly the conditional probabilities and clustering, need more justification and validation.', 'The experimental setup, while extensive, lacks detailed descriptions of certain hyperparameters and configurations, which are crucial for reproducibility.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed method.', 'There is no ablation study to show the contribution of individual components of the CEVD method.', 'Scalability concerns remain, particularly when dealing with a large number of vehicles and clusters.']",3,3,2,4,Reject
IsHQmuOqRAG,"The paper proposes OPPLE, an unsupervised learning framework for learning object-centric representations by predicting future scenes. The model infers objects' 3D locations and segments objects without supervision, inspired by how infants learn through prediction errors. The authors introduce a new dataset with complex textures to evaluate the model and show that previous models often rely too much on color clustering.","['Could you provide more details on the depth estimation process and its integration into the overall framework?', 'How does the model perform compared to other state-of-the-art models like IODINE and PSGNet?', 'Could you provide additional visualizations or ablation studies to clarify the importance of different components of the model?', 'Have the authors considered evaluating the model on real-world datasets? If yes, please provide the results. If not, what are the anticipated challenges?', 'Could the authors provide more details on the network architecture and training process to improve the clarity of the method?', 'What is the performance of the proposed model with different modulation functions and types of aggregators?']","['The paper should provide a more detailed explanation of the depth estimation process and its integration into the framework.', 'Comparisons with more state-of-the-art models would strengthen the evaluation.', 'Certain sections are dense and could benefit from clearer explanations and additional visual aids.', 'The evaluation is limited to synthetic datasets, which may not fully capture the complexities of real-world scenes.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed method. The authors should consider discussing the ethical implications of their work, particularly in the context of unsupervised learning and its applications.']",False,3,2,3,5,4,"['The paper addresses an important problem in unsupervised learning of object-centric representations.', 'The approach of using predictive learning to infer object segmentation and 3D localization is novel and well-motivated.', 'The introduction of a new dataset with complex textures provides a more challenging benchmark for evaluating models.', 'Comprehensive experiments demonstrate the effectiveness of the proposed model compared to existing methods.']","[""The paper lacks detail on the implementation of depth estimation and how it's integrated into the overall framework."", 'The comparison with some state-of-the-art models such as IODINE and PSGNet is missing, which would provide a more complete evaluation.', 'Some parts of the paper, particularly the methodology section, are dense and could benefit from clearer explanations and more visual aids.', 'The paper could provide additional ablation studies to better understand the impact of different components of the model.', 'The evaluation is limited to synthetic datasets, and it is unclear how the model would perform on real-world data with more diverse and complex scenes.', 'The discussion on potential negative societal impacts and ethical considerations is missing, which is essential for a complete evaluation.']",3,3,3,4,Reject
fCSq8yrDkc,"The paper presents a new algorithm for solving large-scale optimal transport (OT) problems using the Douglas-Rachford splitting technique. The proposed method claims to achieve faster convergence and higher accuracy compared to the Sinkhorn method, avoiding numerical issues associated with entropic regularization. The paper provides theoretical analysis of the algorithm's convergence rates and demonstrates an efficient GPU implementation.","['Can the authors provide additional empirical results on real-world datasets to strengthen the validation of their method?', 'Could the authors elaborate on how the algorithm performs in scenarios with different types of cost matrices, especially those encountered in practical applications?', 'Is there any specific reason why the experiments primarily focus on synthetic data? Would it be possible to include results for more diverse real-world problems?', 'Can the authors provide more detailed comparisons with other state-of-the-art methods beyond the Sinkhorn method?', 'Can the authors clarify some parts of the theoretical analysis, particularly the proofs of convergence?', 'Can the authors explore the impact of the choice of parameters, such as the penalty parameter ρ, on the performance of the method in more depth?', 'Can the authors provide a more detailed explanation of the DR splitting method and its implementation for readers who are not familiar with these concepts?', 'What are the potential weaknesses and limitations of the proposed method, and how might they be addressed in future work?', 'Are there any ethical considerations or societal impacts associated with the proposed method that need to be discussed?']","['The reliance on synthetic datasets for the majority of the experiments limits the generalizability of the results. Real-world applications might present different challenges that are not captured in the current experimental setup.', 'The paper could benefit from a more detailed discussion on potential limitations of the proposed approach, such as its scalability to extremely large problems or sensitivity to different types of cost matrices.', 'The potential weaknesses and limitations of the method are not thoroughly discussed. This could include scenarios where the method might not perform well or any assumptions that may limit its applicability.']",False,3,3,3,6,4,"['The paper addresses a significant problem in optimal transport, which has widespread applications in machine learning.', 'The proposed method is novel and leverages Douglas-Rachford splitting to handle OT problems directly, avoiding the pitfalls of regularized approaches.', 'Theoretical analysis includes a linear convergence rate and iteration complexity, which are improvements over existing methods.', 'The GPU implementation details and the open-source release add practical value to the contribution.']","['The experimental validation, while comprehensive in some aspects, lacks diversity in datasets and problem instances. The reliance on synthetic data and limited real-world applications weakens the empirical claims.', 'The clarity of the paper is affected by dense mathematical derivations, which could be better explained or summarized to improve accessibility for a broader audience.', 'While the theoretical convergence rates are impressive, the practical speedup and accuracy benefits over existing methods such as Sinkhorn need more robust empirical evidence.', 'The paper could provide more detailed comparisons with other state-of-the-art methods beyond the Sinkhorn method.', 'Potential weaknesses and limitations of the proposed method are not thoroughly discussed, including its scalability to extremely large problems or sensitivity to different types of cost matrices.']",3,3,3,4,Reject
vfsRB5MImo9,"The paper introduces Continual Knowledge Learning (CKL), a novel continual learning problem for language models that focuses on retaining, updating, and acquiring world knowledge without forgetting previous knowledge. The authors provide a benchmark and a new metric, FUAR, to evaluate the performance of different methods on this task. Extensive experiments are conducted to demonstrate the challenges and effectiveness of various methods.","['Can the authors provide more details on the dataset construction process, particularly the criteria for selecting and categorizing the data?', 'What are the specific challenges faced in adapting existing CL methods to the CKL formulation, and how were they addressed?', 'Can additional ablation studies be conducted to further validate the proposed methods, especially focusing on the individual contributions of each component?', 'Can the authors provide additional clarification on the methodology, particularly the construction and evaluation of the benchmark datasets?', 'How do the proposed methods scale with larger models and more complex datasets, and what are the computational trade-offs?', 'Can the authors provide more insights into the generalization of the methods across different language model architectures, including any observed limitations?']","['The paper could benefit from more rigorous evaluations and additional ablation studies to validate the proposed methods.', 'The clarity around the methodologies and dataset construction could be improved to make it easier for others to reproduce the results.', 'The lack of a detailed ablation study makes it difficult to understand the individual contributions of the components of the proposed methods.', 'The real-world applicability and effectiveness of the proposed benchmarks and metrics need further validation.']",False,3,2,3,6,4,"['Addresses a significant and timely issue in the field of language models.', 'Provides a well-constructed benchmark for evaluating the retention and acquisition of knowledge in LMs.', 'Introduces a novel metric, FUAR, to quantitatively measure the trade-off between forgotten and newly acquired knowledge.', 'Extensive experiments are conducted, including evaluations of different CL methods.']","['The novelty of the proposed methods is limited as they are mostly adaptations of existing CL methods.', 'The clarity of the paper could be improved, particularly in the explanation of the dataset construction process.', 'Additional ablation studies and varied experimental settings could strengthen the evaluation.', 'The scalability and computational efficiency of the proposed methods, especially parameter-expansion methods, need further exploration.', 'The generalization of the methods across different LM architectures needs more in-depth analysis.']",3,3,2,4,Reject
kSwqMH0zn1F,"The paper introduces PipeGCN, a method to improve the efficiency of distributed GCN training by pipelining inter-partition communication with intra-partition computation. The method addresses communication overhead and synchronization issues, providing theoretical convergence guarantees and empirical improvements over existing methods. The paper also introduces a smoothing method to handle staleness in features and gradients.","['Can the authors provide more ablation studies to understand the impact of various components?', 'What are the potential negative impacts or limitations of the smoothing method?', 'Could you provide more details on the practical implementation challenges and how they were overcome?', 'How does the proposed method impact different types of GCN architectures and datasets?', 'Can the authors provide more details on the impact of different smoothing parameters and pipeline depths in the ablation studies?', 'Are there any specific scenarios or types of graphs where PipeGCN might not perform well?', 'Can the authors discuss the memory usage and scalability of PipeGCN in more detail?', 'Can you provide more details and examples on the impact of the smoothing method?', 'How does PipeGCN perform under different network conditions?', 'Can you compare PipeGCN with more state-of-the-art methods?', 'Can the authors provide more details on the autoencoder aggregator used in the smoothing method?', 'Would it be possible to include additional ablation studies to assess the impact of each component of PipeGCN?', 'Can the authors provide more qualitative visualizations and analysis of the results?']","['The complexity of implementation may hinder reproducibility. More ablation studies are needed to understand the impact of different components. Limited discussion on potential negative impacts or limitations of the smoothing method.', 'The paper could improve clarity, especially in explaining theoretical aspects and the smoothing method.', 'Practical implementation challenges and their solutions are not thoroughly discussed.', 'The scope of ablation studies and the impact on different GCN architectures and datasets could be expanded.', 'The paper does not discuss potential limitations or edge cases where the proposed method might not be effective. Additionally, it would be beneficial to understand the memory usage and scalability aspects in more detail.', 'The clarity of the paper and some additional comparisons with state-of-the-art methods are needed.']",False,3,2,3,6,4,"['Addresses significant bottlenecks in distributed GCN training.', 'Provides a theoretical convergence analysis with staleness.', 'Extensive empirical validation showing significant throughput improvements.', 'Novel pipelining approach to interleave communication with computation.', 'Comprehensive experiments across multiple datasets and configurations.']","['Complexity of implementation and potential reproducibility issues.', 'Limited ablation studies to understand the impact of various components.', 'Clarity of presentation, especially in theoretical aspects and smoothing method, needs improvement.', 'Implementation challenges and solutions are not thoroughly discussed.', 'Limited discussion on potential negative impacts or limitations of the smoothing method.', 'Limited comparison with other state-of-the-art methods due to unavailable code.']",3,3,2,3,Accept
gFDFKC4gHL4,"The paper presents MASA, an algorithmic framework designed to efficiently assess shifts in ML API performance over time by modeling the shifts as changes in the confusion matrix. MASA uses an upper-confidence bound based approach for adaptive sampling to minimize the estimation error under a sample budget constraint. The paper empirically demonstrates significant shifts in commercial ML APIs and shows that MASA outperforms standard methods in estimating these shifts.","[""Can the authors provide more details on the choice and impact of the parameter 'a' used in MASA?"", 'How does MASA perform with different types of data distributions? Are there scenarios where MASA might not perform well?', 'Can the authors discuss in more detail the potential ethical implications of using personal data in their evaluation datasets?', 'Can the authors provide more rigorous proofs or empirical validations of the theoretical guarantees for MASA?', 'How does MASA perform compared to other advanced sampling methods or active learning techniques beyond uniform and stratified sampling?', 'What are the effects of different hyperparameters and partitioning strategies on the performance of MASA?', 'Can the authors provide more detailed explanations of the experimental setup, especially the partitioning process and the selection of datasets?']","['The paper does not adequately discuss the limitations of MASA, particularly regarding its applicability to different types of data distributions.', 'The potential negative societal impacts and ethical considerations related to the use of personal data are not sufficiently addressed.', 'The evaluation should cover more adaptive sampling methods for a fair comparison.', 'Potential limitations of MASA, such as its robustness to slight data distribution changes, should be discussed.']",True,3,3,3,5,4,"['Addresses a practical and important problem in monitoring the performance of commercial ML APIs.', 'MASA introduces a novel approach by modeling shifts as changes in the confusion matrix and using an adaptive sampling method.', 'The empirical evaluation includes comprehensive experiments on real-world ML APIs from major providers, demonstrating the effectiveness of MASA.']","['The clarity of the paper could be improved, particularly in the detailed explanation of the MASA algorithm and its components.', 'The theoretical guarantees provided for the MASA algorithm are not rigorously verified. The assumptions and limitations should be more explicitly discussed.', 'The paper lacks a detailed comparative analysis with more diverse baseline methods beyond uniform and stratified sampling.', 'The discussion on the limitations and potential negative societal impacts of the work is insufficient.', 'Ethical considerations related to the use of personal data in the datasets (e.g., facial recognition data) are not adequately addressed.']",3,3,3,4,Reject
d2TT6gK9qZn,"The paper proposes a new method for solving initial value problems (IVPs) by embedding exponential operators in a neural network architecture. It uses a Pade approximation to compute the exponential of operators, aiming to reduce the number of training parameters and improve data efficiency. The method is evaluated on synthetic datasets (KdV and KS equations) and a real-world problem (COVID-19 epidemic forecasting).","['Can the authors provide a more detailed proof of Theorem 1?', 'How does the proposed method compare to other neural operator models in terms of computational complexity?', 'Can the authors include more intuitive explanations and visualizations to improve clarity?', 'Can you provide more detailed explanations and justifications for the choice of Pade approximation and multiwavelet transform?', 'How does your method compare to traditional methods and other recent neural operator models in more detail?', 'Can you clarify the choice of hyperparameters and the setup of baseline models in your experiments?', 'Can the authors provide more detailed descriptions and diagrams to improve clarity, especially in the methodology section?', 'How does the proposed method compare with other state-of-the-art methods in epidemic forecasting beyond Seq2Seq?', 'Can the authors provide more extensive validation of the theoretical contributions through additional experiments?', 'Can the authors provide additional ablation studies and comparisons with more traditional and state-of-the-art methods?', 'Can the authors improve the clarity of the paper by simplifying the technical jargon and mathematical notations?', 'Can more details on hyperparameter settings, code, and data availability be provided to enhance reproducibility?', 'Can the authors provide more intuitive explanations or visualizations for the complex mathematical concepts introduced?', 'How does the performance of the proposed method vary with different choices of polynomial degrees in the Pade approximation?', 'Are there any specific limitations or scenarios where this method might not perform well?']","['The paper does not clearly discuss the limitations of the proposed method, particularly in terms of scalability and applicability to other types of differential equations.', 'The paper should address the clarity of the technical sections and provide more detailed experimental setups to enhance reproducibility.', 'The paper should discuss the potential negative societal impacts of the proposed method, especially in the context of epidemic forecasting.', 'There is a need for a more diverse set of baseline comparisons to validate the performance claims comprehensively.', 'The main concern is the clarity of the presentation and the depth of experimental validations. Addressing these issues in the rebuttal period would be crucial.']",False,2,2,2,4,4,"['The paper addresses a significant problem in solving IVPs with non-linear operators.', 'The proposed use of Pade approximation for exponential operators in a neural network context is novel.', 'Theoretical analysis of gradient boundedness provides some theoretical backing.', 'Comprehensive experiments on both synthetic and real-world datasets.']","['The novelty of the proposed method is somewhat incremental, relying heavily on combining existing techniques in a new way.', 'The theoretical claims, particularly regarding gradient boundedness, need more detailed and rigorous proofs.', 'The clarity of the paper is hampered by overly dense mathematical exposition and lack of intuitive explanations.', 'Experimental results, while promising, need more thorough statistical analysis and comparison to a broader set of baselines.', 'The paper does not clearly discuss the limitations of the proposed method, particularly in terms of scalability and applicability to other types of differential equations.', 'The practical implications and reproducibility of the results are not emphasized enough. More details on hyperparameter settings, code, and data availability are needed.']",3,2,2,3,Reject
_PHymLIxuI,"The paper proposes CrossFormer, a vision transformer architecture that introduces Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA) to address the limitations of existing vision transformers in handling multi-scale features. The paper presents comprehensive experimental results demonstrating the superiority of CrossFormer across various vision tasks including image classification, object detection, instance segmentation, and semantic segmentation.","['Can the authors provide more implementation details or code snippets for CEL and LSDA to enhance reproducibility?', 'Are there any specific limitations or edge cases where CrossFormer may not perform as well as other models?', 'Can the authors provide more details on the autoencoder aggregator used in the CEL?', 'How does the performance of the proposed CrossFormer change with different configurations of the DPB?', 'Can the authors provide more qualitative examples to illustrate the effectiveness of the CEL and LSDA?', 'Can the authors provide more details on the novelty of CEL and LSDA compared to existing methods like CoaT and CViT?', 'What are the potential limitations or failure cases of the proposed methods?', 'Can the authors discuss the computational overhead introduced by CEL and LSDA and its impact on real-world applications?', 'Can the authors provide further justification or exploration for the specific configurations chosen for CEL and LSDA?', 'What are the computational and training requirements for CrossFormer compared to other state-of-the-art models?']","['The paper could better address potential limitations or edge cases where CrossFormer may not perform optimally compared to other models.', 'The clarity of some components and additional ablation studies could further strengthen the paper.', 'The paper should address the potential limitations and failure cases of the proposed methods. Additionally, the computational overhead and its impact on real-world applications should be discussed.', 'The dense technical content could be made more accessible to readers through additional explanations or simplifications.']",False,3,3,3,7,5,"['The introduction of Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA) is novel and effectively addresses the limitations of existing vision transformers in handling multi-scale features.', 'Extensive experimental evaluation across multiple vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation, showcasing the versatility and superiority of CrossFormer.', 'Detailed ablation studies and comparisons with state-of-the-art models provide strong support for the proposed methods.', 'The introduction of Dynamic Position Bias (DPB) enhances positional encoding flexibility, accommodating variable image sizes.']","['The implementation details of CEL and LSDA, while generally clear, could be further elaborated to enhance reproducibility.', 'Some sections, particularly parts of the methodology, could benefit from more detailed explanations or visualizations to aid in understanding.', 'The novelty of CEL and LSDA should be more clearly distinguished from existing methods like CoaT and CViT.', 'Potential computational overhead and its impact on real-world applications should be discussed.']",4,2,2,4,Accept
Xg47v73CDaj,"The paper proposes a novel neural network architecture, ParNet, which uses parallel subnetworks to reduce depth while maintaining high performance. The authors demonstrate that a network with a depth of just 12 layers can achieve competitive accuracy on benchmarks such as ImageNet, CIFAR-10, CIFAR-100, and MS-COCO. The architecture is shown to be suitable for parallel processing, leading to lower latency and faster inference.","['Can you provide more details on the training procedure, especially the learning rate schedules and any regularization techniques used?', 'What is the rationale behind choosing specific configurations for the parallel subnetworks in ParNet? How were these configurations optimized?', 'Can you provide more comparisons with other state-of-the-art architectures beyond ResNets?', 'Can the authors provide more theoretical insights into why parallel subnetworks are effective replacements for depth?', 'What are the specific training times and computational resource requirements for ParNet compared to traditional deep architectures like ResNet?', 'Can the authors provide more ablation studies on the number of parallel subnetworks and other activation functions?', 'Can the authors provide a theoretical explanation for why parallel subnetworks can achieve similar performance to deep networks?', 'Could the authors include more detailed ablation studies to isolate the impact of each component, such as the SSE block and the choice of activation functions?', 'Are there any plans to release the code and implementation details to ensure reproducibility?', 'Can the authors provide more details on how parallel substructures are optimized?', 'Are there additional ablation studies that explore the impact of different architectural choices in ParNet?', 'How does ParNet compare with other state-of-the-art models beyond ResNets?', 'Can the authors provide more theoretical analysis or justification for why ParNet achieves high performance despite its low depth?', 'How does ParNet compare to other non-deep architectures in more varied benchmarks?', 'Could the authors provide more concise explanations for the architectural details and scaling rules?']","['Potential limitations include the scalability of the architecture to even larger datasets or different domains outside of image classification. Additionally, the effectiveness of ParNet on tasks requiring high depth for feature extraction remains to be seen.', 'The paper should also discuss the potential negative societal impacts of faster and more efficient models, such as misuse in surveillance or other privacy-invasive applications.', 'The paper does not adequately address the limitations of the proposed architecture, such as the potential increase in parameters and computational overhead due to parallel subnetworks.', 'The lack of detailed ablation studies weakens the validation of the architectural choices.']",False,2,2,2,4,4,"['The paper addresses the significant problem of reducing the depth of neural networks while maintaining performance. This is particularly relevant for applications requiring low latency.', 'The proposed ParNet architecture introduces a novel use of parallel subnetworks, which is an interesting and innovative approach to network design.', 'The empirical results are strong, showing that ParNet can achieve competitive accuracy on multiple benchmarks with significantly reduced depth.', 'The paper includes a detailed analysis of the scaling rules for ParNet, providing insights into how to increase performance without increasing depth.']","['The clarity of the paper could be improved. Some sections, especially those describing the architecture and the training procedure, are difficult to follow.', 'The reproducibility of the results is questionable. The paper mentions that code will be open-sourced, but it is not currently available, making it hard to verify the findings.', 'The novelty of the approach is somewhat limited. While the use of parallel subnetworks is interesting, it is not entirely new and has been explored in other contexts.', 'The paper lacks a thorough comparison with other state-of-the-art methods beyond ResNets. It would be beneficial to see how ParNet compares with other recent architectures like EfficientNet, Vision Transformers, etc.', 'The paper lacks a strong theoretical foundation to explain why parallel subnetworks can replace deep sequential layers effectively.', 'More detailed ablation studies are needed to isolate the impact of each component of the proposed architecture.', 'The paper does not adequately discuss the limitations of the proposed architecture, such as the potential increase in parameters and computational overhead due to parallel subnetworks.', 'The paper does not thoroughly discuss potential limitations or negative societal impacts. It would be beneficial to address the scalability concerns and potential biases in the datasets used.']",3,2,2,3,Reject
oxC2IBx8OuZ,The paper proposes a novel framework called Continual Federated Learning (CFL) to address the issue of time-varying heterogeneous data in federated learning (FL). It extends the theoretical analysis of client drift to include time drift and provides a unified framework for approximating local objective functions over time. Theoretical analysis shows that CFL achieves faster convergence rates than FedAvg. Extensive experiments validate these theoretical findings.,"['Can you provide more details on the assumptions made in the theoretical analysis?', 'How does the framework perform on more diverse datasets, such as those from different domains or with different types of heterogeneity?', 'Can the clarity of the theoretical analysis section be improved, particularly in explaining key equations and assumptions?', 'Can the authors provide more details on the approximation methods and experimental setup?', 'Are there any ethical considerations or potential societal impacts of this work?', 'Can the authors provide more details on how different approximation methods affect the performance?', 'Can the authors elaborate more on the calculation of Hessian matrices for the regularization method?', 'Can the authors include more qualitative analysis to illustrate the practical implications of the proposed approach?', 'Can the authors provide more details on the approximation methods and the steps involved in the CFL algorithms?', 'Can the authors include additional ablation studies on the various approximation techniques and their impact on performance?', 'Could you provide more details on the implementation of the regularization and core set methods?', 'Can you include additional ablation studies to show the impact of different approximation methods and hyperparameters?', 'Would you be able to provide more visualizations and qualitative analyses to illustrate the practical differences between CFL and other methods?']","['The paper does not thoroughly explore the impact of different types of heterogeneity, such as data distribution or client participation. This could be addressed in future work.', 'The experiments are limited to a few datasets, which may not fully capture the performance of the framework in real-world scenarios.', 'The paper lacks a discussion on the potential negative societal impacts and ethical considerations of the proposed CFL framework.', 'The main limitations are related to the clarity and presentation of the methodology and results. Addressing these could significantly improve the paper.', 'Additional ablation studies on the various approximation techniques and their impact on performance would be beneficial.']",False,3,3,4,7,4,"['Addresses a novel and important problem in federated learning: time-varying heterogeneous data.', 'Provides a novel CFL framework with rigorous theoretical analysis.', 'Extensive empirical validation on various datasets demonstrates the practical effectiveness of the proposed CFL framework.', 'Demonstrates superior performance of CFL methods over state-of-the-art FL baselines.']","['The clarity of certain sections, particularly the theoretical analysis, could be improved. Some equations and assumptions are not well explained.', 'The experiments are limited to a few datasets (CIFAR10, CIFAR100, Fashion-MNIST). More diverse datasets would strengthen the validation of the framework.', 'The impact of different types of heterogeneity (e.g., data distribution, client participation) is not thoroughly explored.', 'Lacks certain ablation studies that could further substantiate the claims.', 'Ethical considerations and potential societal impacts are not discussed.']",4,3,3,4,Accept
ULfq0qR25dY,"The paper introduces the maximum n-times coverage problem, a generalization of the multi-set multi-cover problem, and proposes two algorithms: NTIMES-ILP and MARGINALGREEDY. This problem is particularly relevant for vaccine design, aiming to maximize population coverage. The proposed solutions are evaluated on synthetic data and real-world vaccine design tasks, demonstrating superior performance compared to existing methods.","['Can the authors provide more detailed comparative analysis with related set cover problems?', 'What are the theoretical performance bounds for MARGINALGREEDY?', 'Can the authors clarify the notation and improve the overall readability of the paper?', 'What are the justifications for the choice of datasets and hyperparameters in the experiments?', 'Can the authors provide more details on the implementation of the NTIMES-ILP and MARGINALGREEDY algorithms?', 'How do the proposed methods handle cases with very large numbers of elements and overlays, especially in terms of computational efficiency?', 'Can the authors provide more theoretical insights into the performance guarantees of the proposed algorithms?', 'Could the authors simplify and clarify the dense mathematical formulations, particularly for readers who may not be experts in ILP or greedy algorithms?', 'Can additional ablation studies be conducted to evaluate the impact of different parameters and the choice of the ILP solver?', 'Could the authors briefly discuss any ethical considerations related to the use of computational methods in vaccine design?']","['The paper does not thoroughly validate the theoretical contributions and lacks transparency in the experimental setup.', 'The clarity of the methodological explanation needs improvement.', 'The practical scalability of NTIMES-ILP for very large datasets remains a concern.', 'Potential negative societal impacts, such as the over-reliance on computational methods without sufficient experimental validation, should be considered.']",False,3,3,3,6,4,"['The problem addressed is novel and relevant, particularly in the context of vaccine design.', 'The proposed algorithms, NTIMES-ILP and MARGINALGREEDY, are innovative and show promising results.', 'Extensive experimental validation, including comparisons with 29 existing vaccine designs.', 'The paper includes a thorough theoretical analysis, proving that the n-times coverage function is not submodular.']","['Lacks detailed comparative analysis with closely related set cover problems.', 'Theoretical performance bounds for the proposed algorithms are not thoroughly validated.', 'Dense and sometimes inconsistent notation, making the paper hard to follow.', 'Experimental setup lacks transparency, especially in the choice of datasets and hyperparameters.', 'The clarity and organization of the methodology section could be improved.', 'The paper could benefit from additional ablation studies to better understand the contributions of different components of the algorithms.']",4,3,3,4,Reject
KTPuIsx4pmo,"The paper presents a novel approach to meta-imitation learning that leverages video demonstrations from humans to train robots. The proposed method uses a new generative model, Action-awareness CycleGAN (A-CycleGAN), combined with a self-adaptive meta-learning framework, to translate human videos into robot demonstrations and train the meta-policy in an imagined latent space. The approach aims to reduce the labor associated with collecting robot demonstrations and aligns more closely with human imitation behavior.","['Can you provide more details on the architecture and training process of the inverse dynamic model integrated with A-CycleGAN?', 'How does the adaptive loss mechanism compare with other potential metrics or methods for evaluating the quality of translated data?', 'Can you provide more experimental results or analysis to demonstrate the impact of the adaptive loss mechanism?', 'How were the training and test tasks selected and prepared? More details on the experimental setup would be helpful.', 'Can the authors include more ablation studies to show the impact of each component of their proposed method?', 'Can you provide more details on the architecture and training process of A-CycleGAN?', 'How are the success criteria defined in the real-world experiments?', 'What additional quantitative metrics can be provided to strengthen the evaluation?', 'Have you considered any ethical concerns related to the potential misuse of this technology?', 'Can the authors provide more details on the autoencoder aggregator?', 'Can the authors conduct additional ablation studies on modulation functions and types of aggregators?', 'Can the authors provide more visualization cases for qualitative analysis?']","['The primary limitation is the reliance on the quality of translated videos, which may vary depending on the scene complexity. Addressing this variability through more robust metrics or methods could further strengthen the approach.', 'The authors should address the potential limitations of their approach in terms of scalability to more complex tasks and environments.', 'The societal impact of enabling robots to learn from human demonstrations should be discussed, particularly regarding privacy and ethical considerations.', 'The clarity of the paper needs improvement, especially regarding the architecture and training process of A-CycleGAN. More detailed explanations and robust quantitative evaluations are needed.', 'The paper could benefit from more detailed explanations and additional ablation studies to further validate the proposed method.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed approach. It would be beneficial to include this in the final version.']",False,3,2,3,5,4,"['The problem tackled by the paper is highly relevant and practical, addressing the significant data collection burden in meta-imitation learning.', 'The introduction of A-CycleGAN is novel, aiming to bridge the human-robot domain gap by learning action-awareness representations from human demonstrations.', 'The self-adaptive mechanism to evaluate and prioritize high-quality translated data is a thoughtful addition that aims to enhance the training process.', 'The paper provides comprehensive experiments, including both simulated and real-world tasks, to validate the effectiveness of the proposed approach.']","['The description of the inverse dynamic model and its integration with the A-CycleGAN could be clearer. More details on the exact architecture and training process would help in understanding its contribution.', 'The adaptive loss mechanism, while described, could benefit from additional theoretical justification or more detailed experimental analysis to demonstrate its impact.', 'The evaluation of translated data quality using SSIM and Brenner gradient is interesting, but it would be beneficial to compare this approach with other potential metrics or methods to validate its effectiveness.', 'The clarity of the methodology is lacking in some sections. The description of A-CycleGAN, particularly the integration of the inverse dynamic model, is complex and could benefit from further elaboration.', 'The experimental setup is not fully detailed, especially concerning the selection and preparation of training and test tasks. More information on hyperparameters and training conditions is needed.', 'The paper would benefit from more extensive ablation studies to isolate the contributions of individual components such as the inverse dynamic model and the adaptive loss mechanism.', 'The robustness of the results could be questioned due to the limited number of tasks and environments tested. More diverse tasks and larger-scale experiments would strengthen the conclusions.', 'The paper relies heavily on qualitative results. More robust quantitative analysis and comparisons are needed.', 'Ethical concerns related to potential misuse of the technology are not addressed.']",3,3,2,3,Reject
jJWK09skiNl,The paper proposes a method for generalized zero-shot detection (gZSD) using a modified YOLOv5 architecture on the YCB Video dataset. The authors introduce a novel attribute labeling method and a new dataset split to facilitate the detection of unseen objects in flexible manufacturing environments.,"['How does the proposed method compare with existing methods on other datasets or benchmarks?', 'Can the authors provide more ablation studies to understand the impact of the attribute labeling method and the modified YOLOv5 architecture?', 'What is the rationale behind the chosen attribute labeling method, and how does it compare with alternatives such as using semantic vectors?', 'Can the authors provide a more detailed theoretical analysis of the proposed modifications to YOLOv5?', 'Can the authors clarify the experimental setup and provide a more systematic evaluation of the results?', 'How does the proposed method compare to existing zero-shot detection approaches in terms of performance?', 'What are the potential ethical concerns and limitations of deploying this system in real-world industrial settings?', 'Can the authors provide more details on the network modifications and the loss functions used?', 'How does the proposed method compare with other recent zero-shot detection approaches?', 'Can the authors provide more detailed experimental results and ablation studies to substantiate their claims?', 'Can the authors provide more detailed explanations of the attribute prediction mechanism and the specific modifications made to YOLOv5?', 'What are the reasons for selecting specific unseen objects from the YCB Video Dataset?', 'How does the proposed method compare to other state-of-the-art zero-shot object detection models in terms of precision and recall?']","['The paper does not adequately address the limitations of the proposed method, particularly in terms of generalization to other datasets or environments.', 'Potential negative societal impacts, such as biases introduced by the attribute labeling method, are not discussed.', 'The major limitations are the lack of detailed analysis and rigorous experimental validation.', 'The dataset split and the generalization of the method to other datasets or environments should also be addressed.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed work. It would be beneficial for the authors to discuss how the method could be further improved or where it might fail.']",False,2,2,2,3,4,"['Addresses a relevant and practical problem in robotic vision for flexible manufacturing.', 'Utilizes a well-known and performant object detection framework (YOLOv5) and adapts it for zero-shot detection.', 'Proposes a novel attribute labeling method and a new dataset split for the YCB Video dataset.']","['Lacks a thorough comparison with existing zero-shot detection methods, particularly those using different datasets.', 'Insufficient ablation studies to understand the impact of individual components, such as the attribute labeling method and the modified YOLOv5 architecture.', 'The justification for the chosen attribute labeling method and some architectural choices is weak and lacks comparison with alternatives.', 'The experimental setup, particularly the choice of unseen objects, seems somewhat arbitrary and may lead to biased results.', 'The clarity of the technical explanation, especially in the methodology section, is lacking in parts, making it difficult to follow.', 'The paper lacks detailed theoretical analysis and rigorous experimental validation.', 'The empirical results are limited and do not convincingly demonstrate the effectiveness of the proposed approach.', 'The paper does not address potential ethical concerns or limitations of the proposed method.']",2,2,2,3,Reject
bUAdXW8wN6,"The paper proposes Domain Invariant Adversarial Learning (DIAL), a method that combines Domain Adversarial Neural Networks (DANN) with adversarial training to improve both robustness and standard accuracy. The method is evaluated on multiple datasets, showing significant improvements over existing methods.","['Can the authors provide more details on the integration of the domain classifier?', 'Are the improvements statistically significant?', 'What is the computational overhead introduced by the proposed method?', 'How is the reversal-ratio parameter chosen and adjusted during training?', 'Can the authors provide more details on the hyperparameter settings and the architectures used in their experiments?', 'How does the domain classifier specifically contribute to the overall robustness and natural accuracy? Can its impact be isolated and analyzed?', 'Are there any limitations or potential drawbacks of using domain-invariant representations in adversarial training?', 'Can the authors provide more detailed ablation studies to isolate the contributions of the domain classifier and other components?', 'Could the authors clarify the mathematical notations and provide more intuitive explanations of the architecture?', 'Is there a theoretical justification or analysis that supports the claim that domain invariance leads to improved robustness and accuracy?', 'How do the results vary with different network architectures?', 'Can the method handle adversarial examples generated by more sophisticated attacks beyond PGD and CW?']","['The paper lacks clarity in some sections, particularly in the integration of the domain classifier.', 'The novelty may not be substantial enough for a top-tier conference.', 'The computational overhead of the proposed method, particularly the domain classifier, should be discussed.', 'Potential limitations or drawbacks of using domain-invariant representations in adversarial training should be addressed.', 'The potential negative societal impacts, such as the increased computational cost and environmental impact, should be discussed more thoroughly.']",False,3,2,3,5,4,"['Addresses an important problem in adversarial training: the trade-off between robustness and standard accuracy.', 'Combines DANN with adversarial training in a novel way to enforce domain-invariant feature representation.', 'Extensive experiments on multiple datasets (MNIST, SVHN, CIFAR-10, CIFAR-100) demonstrating improvements in both robustness and accuracy.', 'Includes ablation studies, transfer learning experiments, and evaluations against unforeseen attacks and corruptions.']","['The novelty of combining DANN and adversarial training may not be substantial enough.', 'Some sections, particularly the description of the domain classifier and its integration, lack clarity and detail.', 'It is not clear if the improvements are statistically significant and reproducible.', 'The paper does not explore the computational overhead introduced by the proposed method.', 'The theoretical justification for why domain invariance should improve robustness and accuracy is not thoroughly discussed.', 'The presentation of results is somewhat confusing, with cluttered tables and insufficient ablation studies.']",3,3,2,4,Reject
j-63FSNcO5a,"The paper introduces Disentanglement via Contrast (DisCo), a framework for learning disentangled representations by leveraging pretrained generative models. The authors propose using a Navigator to provide traversal directions in the latent space and a Δ-Contrastor to model image variations based on the target representations. DisCo incorporates an entropy-based domination loss and a hard negatives flipping strategy to achieve state-of-the-art disentanglement performance across GAN, VAE, and Flow models.","['Can the authors provide more details on the limitations of their approach?', 'Could you elaborate on the choice of hyperparameters and architectural details?', 'Is there a theoretical justification or comparison with other contrastive learning methods?', 'Can you provide more details on the impact of hyperparameters and different components of the DisCo framework?', 'How does DisCo handle potential negative societal impacts or ethical concerns?', 'Can the authors provide more details about the autoencoder aggregator and its role in the proposed framework?', 'What is the performance of the proposed model with different types of aggregators?', 'Can the authors provide additional qualitative results to support the claims?']","['The paper does not clearly articulate the limitations of the proposed approach, which is crucial for understanding the contexts in which the method might fail or underperform.', 'The paper does not discuss potential negative societal impacts or ethical concerns explicitly, which is important for responsible AI research.', 'The clarity of certain sections needs improvement, and additional ablation studies on different components are necessary.']",False,3,3,3,6,4,"['Novel approach leveraging pretrained generative models.', 'Comprehensive experimental evaluation demonstrating state-of-the-art performance.', 'Introduction of innovative techniques like entropy-based domination loss and hard negatives flipping strategy.', 'Addresses the important problem of disentangled representation learning.', 'Proposes a well-motivated approach with comprehensive experimental validation.']","['Lack of clear articulation of limitations.', 'Sparse details about the implementation and hyperparameters.', 'Need for more theoretical justification and comparison with existing methods.', 'Extensive and dense presentation that can be hard to follow.', 'Limited ablation studies on certain components such as the modulation function and different types of aggregators.', 'No discussion on potential negative societal impacts or ethical concerns of the approach.']",4,3,3,4,Accept
L1L2G43k14n,"The paper explores the relationship between the flatness of the loss landscape and the generalization performance of deep neural networks, presenting the Bayesian prior as a more robust predictor of generalization. It provides empirical evidence showing that this measure correlates well with generalization across different datasets and optimizers, while flatness measures do not consistently do so.","['Can the authors provide more visualizations of the empirical results to enhance understanding?', 'Are there any potential limitations or negative societal impacts that were not discussed in the paper?', 'Can the authors provide more details on the computational complexity and practical implementation of calculating log P(f) using GPs?', 'How do the proposed methods perform on additional datasets and architectures beyond those tested?', 'Can the authors clarify the theoretical derivation of the non-uniform convergence bound and how it directly supports their empirical findings?']","['The paper could discuss potential limitations and negative societal impacts in more depth.', 'The main limitation is the focus on a limited set of datasets and architectures, which may affect the generalizability of the results.', 'The complexity of calculating the proposed measure (log P(f)) may limit its practical application.']",False,3,2,3,5,4,"['Addresses a fundamental question in deep learning regarding generalization.', 'Proposes a novel approach using the Bayesian prior as a predictor.', 'Comprehensive experimental evaluation with multiple datasets, architectures, and optimizers.', 'Technically sound and well-supported claims.']","['Some sections are mathematically dense and might be challenging for readers not familiar with the topic.', 'Limited discussion on potential limitations and negative societal impacts.', 'Could benefit from more visualizations to aid understanding of empirical results.', 'The empirical validation could benefit from more diversity in datasets and architectures.', 'The clarity of the paper suffers from dense and sometimes unclear explanations, particularly in the theoretical sections.', 'The practical implementation details of calculating the log P(f) using GPs are not thoroughly explained, which may hinder reproducibility.']",3,3,2,3,Reject
yV4_fWe4nM,"The paper 'Deep Fair Discriminative Clustering' addresses the problem of ensuring group-level fairness in deep clustering algorithms. The authors propose a novel approach that formulates the fairness objective as an integer linear programming (ILP) problem, which is efficiently solved due to the total unimodularity of the constraint matrix. This ILP solver is then integrated into a discriminative deep clustering framework, allowing the model to learn fair representations while clustering. The experimental results on various datasets demonstrate that the proposed method outperforms state-of-the-art fair clustering algorithms in terms of both clustering performance and fairness.","['Can the authors provide more details on the network architectures and hyper-parameters used in the experiments?', 'Can the authors conduct additional ablation studies to investigate the impact of different network architectures and hyper-parameters on the performance?', 'Can the authors expand the discussion on the limitations and potential negative societal impacts of the work?', 'Can you provide more details about the autoencoder aggregator and its role in the proposed method?', 'How does the choice of modulation function impact the performance of the proposed method?', 'Can you include additional ablation studies to investigate the impact of different components and parameters in the proposed method?', 'Can you provide a clearer explanation and more details on the ILP formulation and how it is integrated into the deep learning pipeline?', 'Could you discuss the computational complexity and provide more detailed runtime analysis of your method?', 'Can you include more visualizations and qualitative results to better illustrate the clustering outcomes?']","['The clarity of the method presentation needs improvement.', 'Additional ablation studies are necessary to validate the choices made in the method.', 'The discussion on limitations and potential negative societal impacts is brief and should be expanded.', 'The computational complexity and runtime analysis of the proposed method should be discussed in more detail.']",False,3,3,3,6,4,"['The problem of fairness in deep clustering is important and timely.', 'The approach of using ILP for fairness constraints and integrating it into a deep clustering framework is novel.', 'The paper provides extensive experimental results, including novel settings such as predictive clustering and flexible fairness constraints.', 'The theoretical analysis of the approach, including the proof of total unimodularity, adds rigor to the work.']","['The presentation of the method is somewhat unclear in sections 4.1 and 4.2, making it difficult to follow the exact steps of the algorithm.', 'The paper would benefit from additional ablation studies to further validate the choices made in the method, such as the impact of different network architectures or hyper-parameters.', 'The discussion on the limitations and potential negative societal impacts of the work is brief and could be expanded.', 'Details on the implementation, such as the autoencoder aggregator, are somewhat sparse and could benefit from further elaboration.', 'The computational complexity and runtime analysis of the proposed method should be discussed in more detail.', 'More visualizations and qualitative results would enhance the understanding of the clustering outcomes.']",4,3,3,4,Reject
9rKTy4oZAQt,"The paper proposes a novel risk-sensitive policy gradient method for reinforcement learning (RL), named C3PO, inspired by Cumulative Prospect Theory (CPT). The method optimizes a distributional objective that allows for different utility and weight functions to modulate risk sensitivity. The approach is evaluated on the OpenAI Safety Gym environments, demonstrating improved performance in handling risk and achieving better outcomes compared to traditional PPO and constrained PPO methods.","['Can the authors provide more details on the derivation of the policy gradients and the variance reduction techniques? A step-by-step explanation would be helpful.', 'How does the performance of C3PO vary with different types of utility and weight functions? Detailed ablation studies would be beneficial.', 'Would the proposed method generalize well to other types of environments beyond the OpenAI Safety Gym? Can the authors provide additional experimental results on more diverse environments?', 'Can the authors provide more detailed implementation steps for the proposed algorithm, particularly focusing on the variance reduction techniques?', 'How does the performance of the proposed method vary with different values of the shaping constant η?', 'Can additional baselines be included in the experiments to better contextualize the performance gains of the proposed method?']","['The empirical analysis is somewhat limited in scope, and the results may not generalize to other types of environments without further validation.', 'The clarity of the paper could be improved, particularly in the technical derivations.', 'The paper does not sufficiently discuss the limitations of the proposed method, particularly in terms of its generalizability to other environments and tasks.', 'There is little discussion on the potential negative societal impacts, such as the ethical implications of deploying risk-sensitive reinforcement learning agents in real-world applications.']",False,3,3,3,5,4,"['The integration of Cumulative Prospect Theory into policy gradients is an innovative idea, offering a new approach to risk-sensitive reinforcement learning.', 'The method allows for flexible specification of risk profiles through utility and weight functions, enabling tailored agent behaviors based on distributional outcomes.', 'The empirical results show promising improvements in performance and risk management, particularly in safety-critical environments like the OpenAI Safety Gym.']","['The clarity of the paper is lacking in several sections, particularly in the derivation of the policy gradients, variance reduction techniques, and implementation details.', 'The empirical validation is limited to a specific set of environments, raising questions about the generalizability of the proposed method.', 'The paper lacks detailed ablation studies to isolate the impact of individual components of the algorithm.', 'The sensitivity of the method to different hyperparameters, particularly the shaping constant η, is not thoroughly explored.', 'The discussion of limitations and potential negative societal impacts is insufficient.']",3,3,3,4,Reject
lY0-7bj0Vfz,"The paper proposes a novel prototype-based memory modulation module called Memory Concept Attention (MoCA) to improve few-shot image generation. Inspired by findings in the visual cortex of macaque monkeys, the module uses prototype memory priors to modulate the image synthesis process. The proposed method is integrated into the generator of a GAN and tested on various datasets, demonstrating improved image synthesis quality and robustness against noise.","['Can the authors provide more details on the computational and memory overhead introduced by the MoCA module?', 'How does the proposed method compare with other state-of-the-art few-shot image generation methods beyond self-attention mechanisms?', 'Can the authors provide more insights into the trade-offs between the increased model complexity and performance gains?', 'Can the authors provide more detailed explanations and visual examples regarding the autoencoder aggregator and the update mechanism for the prototype memory?', 'How does the model ensure it is not merely memorizing the training images? Can more extensive evaluations or visualizations be provided to address this concern?', 'Can the authors conduct additional ablation studies to investigate the necessity and effectiveness of each component of the proposed MoCA mechanism?']","['The paper does not thoroughly discuss the computational and memory overhead introduced by the MoCA module.', 'The generalization of the method to a wider range of datasets is not fully explored.', 'The primary limitation is the potential for overfitting or memorization, which is not thoroughly addressed.', 'The clarity of the methodological details is lacking, making it difficult to fully understand and reproduce the proposed approach.']",False,3,3,3,5,4,"['Novelty: The idea of using prototype memory priors for modulating image generation is novel and inspired by biological findings.', 'Effectiveness: The proposed method shows significant improvements in image synthesis quality across multiple datasets.', 'Robustness: The approach improves the robustness of the model against noise.', 'Comprehensive Experiments: The paper includes extensive experiments, including ablation studies, to validate the effectiveness of the proposed method.', 'Clarity: The paper is generally well-written and easy to follow, with clear explanations of the methodology and experiments.']","['Limited Baselines: The paper primarily compares the proposed method with self-attention mechanisms. It would benefit from comparisons with other state-of-the-art few-shot image generation methods.', 'Memory Overhead: The introduction of a memory module may increase computational and memory overhead, which is not thoroughly discussed.', 'Complexity: The proposed method adds complexity to the model, and the paper does not provide a detailed analysis of the trade-offs between complexity and performance gains.', 'Generalization: The experiments are mainly focused on a few specific datasets. It would be beneficial to test the method on a more diverse set of datasets to evaluate its generalization capabilities.', 'Clarity: The explanation of the autoencoder aggregator and memory update mechanism lacks clarity and detail.', 'Potential Overfitting: Potential overfitting or memorization issues are not thoroughly investigated.']",3,3,3,4,Reject
R8sQPpGCv0,"The paper presents a method called Attention with Linear Biases (ALiBi) to enable transformer models to extrapolate to longer input sequences than those seen during training. ALiBi biases query-key attention scores with a penalty proportional to their distance, allowing models to handle longer sequences efficiently. The method is tested on various datasets, showing improvements in training speed and memory usage compared to existing positional encoding methods.","['Can the authors provide more theoretical insights into why ALiBi works well for sequence length extrapolation?', 'How does the method perform on tasks beyond language modeling, such as machine translation or text classification?', 'Could the authors include more detailed ablation studies, especially varying the choice of slopes and other hyperparameters?', 'What are the limitations of ALiBi in terms of generalization to other domains and tasks?', 'Can the authors provide more detailed analysis on how ALiBi mitigates the early token curse?', 'Could the explanation of the geometric sequence used for the slopes in ALiBi be expanded and clarified?']","[""The method's applicability to tasks beyond language modeling is not demonstrated."", 'Potential limitations in terms of generalization to other domains are not discussed.', ""The analysis of the method's theoretical foundations is lacking."", 'The paper needs more detailed ablation studies and theoretical analysis to fully justify the choice of slopes in ALiBi.', 'The qualitative analysis is limited, and more examples or visualizations would help in understanding the improvements.']",False,4,3,4,7,5,"['Addresses the practical issue of sequence length extrapolation in transformers.', 'The proposed method, ALiBi, is simple to implement and does not require additional parameters.', 'Empirical results demonstrate improvements in training speed and memory usage.', 'Achieves strong performance on large-scale datasets and models.', 'Comprehensive experimental validation showing improvements in training speed, memory usage, and perplexity across different datasets and model sizes.', 'Clear and well-organized presentation of the method and results.']","['The originality of the method is limited; similar concepts have been explored in prior works.', 'The theoretical underpinnings of the method are not deeply explored.', 'Ablation studies and comparisons with other state-of-the-art models are limited.', 'Some implementation details and parameter choices are not clearly explained.', 'The practical benefits, while notable, are incremental rather than transformative.', 'The paper lacks theoretical analysis or proofs regarding why ALiBi works better for extrapolation compared to other methods.', 'More qualitative analysis, such as visualizations or specific examples showing the benefits of ALiBi, would make the improvements more tangible.']",3,4,3,4,Accept
EHaUTlm2eHg,"The paper proposes a novel reinforcement learning method called Policy Gradients Incorporating the Future (PGIF) that leverages future trajectory information during training to improve credit assignment and performance in both online and offline RL tasks. PGIF uses an information bottleneck to prevent over-reliance on this privileged information. The method is evaluated across various domains, showing significant improvements over existing baselines.","['Can you provide a more detailed analysis of the computational overhead introduced by the backward RNNs or transformers?', 'How does the performance of PGIF scale with increasing trajectory lengths and more complex environments?', 'Have you observed any instances of overfitting due to the use of future trajectory information, and if so, how do you mitigate it?', 'Can the authors provide more detailed ablation studies, especially concerning the importance of the variational information bottleneck and the choice of auxiliary losses?', 'Can the authors clarify the structure and role of the autoencoder aggregator in the methodology?', 'What are the hyperparameter settings and training procedures used in the experiments?', 'What specific strategies could be employed to mitigate the potential biases introduced by using future information in offline RL settings?']","['The paper does not thoroughly address potential overfitting issues that might arise from conditioning on future trajectory information.', 'The scalability of the method to very long trajectories and complex environments is not deeply analyzed.', 'The primary limitation is the potential bias introduced by using future information, which may affect the learning process, especially in offline RL settings with sub-optimal datasets. The paper acknowledges this but does not provide concrete mitigation strategies.']",False,3,2,3,5,4,"['The paper introduces an innovative approach that leverages future trajectory information without the need to predict it explicitly, addressing a fundamental challenge in RL.', 'The approach is versatile and can be applied to various RL algorithms and environments, demonstrating wide applicability.', 'Comprehensive experimental results across different tasks and settings show the effectiveness of PGIF.']","['The methodology section lacks clarity, particularly regarding the implementation of latent variable models and the information bottleneck.', 'The paper lacks detailed ablation studies and comparisons with state-of-the-art methods.', 'The computational overhead introduced by the method, especially the use of backward RNNs or transformers, is not discussed in detail.', 'The scalability of the method to very long trajectories and complex environments is not deeply analyzed.', 'The potential for overfitting due to the use of future trajectory information is a concern that needs to be addressed.', 'The experimental results could benefit from more robust statistical analysis to strengthen the claims.', 'The potential biases introduced by using future information, especially in offline RL settings, need more concrete mitigation strategies.']",3,3,2,3,Reject
Fj1Tpym9KxH,"The paper proposes Smooth Domain Adversarial Training (SDAT), which improves domain adversarial training by focusing on smooth minima regarding task loss while keeping the adversarial loss unchanged. The approach is theoretically motivated and empirically validated across several datasets and domain adaptation tasks, including classification and object detection.","['Could you provide more details on the Hessian analysis and its implications for the smoothness of the loss landscape?', 'How does the choice of ρ (smoothness parameter) affect the generalization bound and practical performance?', 'Can you include more variations in the smoothing techniques in the ablation studies to provide a broader comparison?', 'Could you clarify the hyperparameter tuning process for different datasets in more detail?', 'Can the authors provide more intuitive explanations and visualizations for the theoretical analysis presented in Section 4?', 'In the object detection experiments, what is the impact of smoothing only the classification loss versus smoothing both classification and regression losses? Can the authors provide a detailed ablation study on this?', 'Can the authors compare their method with more recent baselines?']","['The choice of ρ (smoothness parameter) is crucial and not fully explored or explained.', 'The impact of smoothness on different components of the loss could be more comprehensively analyzed.', 'The paper does not discuss potential negative societal impacts of the work.']",False,3,3,3,6,4,"['Addresses a significant issue in domain adversarial training, highlighting the different impacts of smoothness on task loss and adversarial loss.', 'The proposed SDAT method is theoretically motivated and supported by a generalization bound.', 'Extensive experiments on multiple datasets, including Office-Home, VisDA-2017, and DomainNet, demonstrate the empirical effectiveness of the proposed method.', 'The paper includes practical applications beyond classification, such as object detection, which shows the generality of the approach.']","['The explanation of the Hessian analysis and the implications on smoothness could be more detailed and clearer.', 'The theoretical analysis, while sound, could benefit from additional discussion on how the choice of ρ (smoothness parameter) affects the generalization bound.', 'Some experimental details, such as hyperparameter tuning for different datasets, are missing or insufficiently detailed.', 'The ablation studies are thorough but could be expanded to include more variations in the smoothing techniques to strengthen the conclusions further.', 'The clarity of the presentation could be improved, especially in the sections explaining the theoretical contributions and the practical implementation of SDAT.']",3,3,3,4,Reject
k7-s5HSSPE5,"The paper proposes a method called Importance-Weighted Domain Alignment (IWDA) for unsupervised cross-lingual transfer, focusing on representation alignment and class prior shift correction. The method is evaluated on tasks like sentiment analysis, named-entity recognition, and textual entailment using models like mBERT and XLM-R. Extensive experiments demonstrate the effectiveness of IWDA, especially under large prior shifts.","['Can the authors provide more details on the implementation of IWDA, particularly the adversarial training and importance weight estimation?', 'What are the effects of varying the hyperparameters of IWDA on performance?', 'Can the authors include more ablation studies to dissect the contributions of different components of IWDA?', 'How does IWDA compare with other state-of-the-art methods in cross-lingual transfer?', 'Could the authors provide more details on the choice of hyperparameters and any tuning strategies used?', 'Can you elaborate on the theoretical underpinnings of the impact of class prior shifts?']","['The paper could benefit from a discussion on the potential limitations and negative societal impacts of IWDA. For example, how does the method perform on languages with very limited resources?', 'The implementation details should be clarified to ensure reproducibility.', 'The complexity and stability of the optimization procedures used in IWDA need more thorough investigation.']",False,3,3,3,5,4,"['Addresses significant issues in cross-lingual transfer, such as class prior shift and feature representation alignment.', 'Proposes a novel method (IWDA) that combines importance-weighted domain alignment with prior shift correction.', 'Comprehensive experiments on multiple NLP tasks validate the effectiveness of the proposed method.', 'The paper provides a detailed analysis of the factors affecting cross-lingual transfer, which is insightful.']","['The methodology section lacks clarity, especially regarding the implementation details of IWDA, which could hinder reproducibility.', 'Insufficient ablation studies to fully understand the contributions of various components of IWDA.', 'Limited discussion on the potential limitations and negative societal impacts of the proposed method.', 'Some conclusions are based on empirical observations without strong theoretical underpinning, particularly regarding the exact mechanisms of prior shift impacts.']",3,3,3,3,Reject
SVwbKmEg7M,"The paper proposes a novel method for unsupervised neural machine translation using generatively pre-trained language models, specifically GPT-3. The method involves three steps: few-shot amplification, distillation, and backtranslation, leveraging GPT-3's zero-shot translation capabilities. The approach is tested on the WMT14 English-French benchmark and achieves state-of-the-art results.","['Can you provide more details on the distillation process and how it impacts the final performance?', 'Have you tested the method on languages or domains other than English-French? If so, what were the results?', 'Can you include more ablation studies to explore the effects of different components and hyperparameters on the final performance?', 'How does the method perform with smaller, less resource-intensive models?', 'Can the authors provide more details on the ethical considerations and potential biases of using GPT-3?', 'How scalable and generalizable is the approach to other language pairs?', 'Can the authors provide more details on the computational costs and efficiency of the proposed method?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How feasible is this method for smaller organizations or researchers without access to large-scale models like GPT-3?']","['The potential limitations and applicability of the method to other languages or domains are not thoroughly discussed.', 'The paper lacks detailed ablation studies to explore the impact of different components and hyperparameters.', 'The reliance on large pre-trained language models like GPT-3 raises concerns about accessibility and computational costs.', 'The paper does not adequately address the potential limitations and negative societal impacts of the proposed method.', 'The approach might not be feasible for all research groups due to the resource requirements.']",True,3,3,3,5,4,"['The approach is novel and leverages the strength of large generative language models for unsupervised translation tasks.', 'The method significantly reduces the computational and data costs associated with few-shot prompting at test time.', 'Empirical results demonstrate state-of-the-art performance on the WMT14 English-French benchmark, with impressive BLEU scores.', 'The proposed method is well-motivated and addresses a significant challenge in unsupervised machine translation.']","['The paper would benefit from more detailed explanations of certain steps, particularly the distillation process and its impact on model performance.', 'There is a lack of ablation studies to thoroughly explore the effects of different components and hyperparameters on the final performance.', 'The potential limitations and applicability of the method to other languages or domains are not adequately discussed.', 'The paper could be clearer in presenting the technical details and experimental setups to ensure reproducibility.', 'The method heavily relies on GPT-3, which is resource-intensive and not widely accessible.', 'Ethical concerns regarding the biases present in large-scale language models like GPT-3.', 'Potential limitations in the scalability and generalizability of the approach to other language pairs or domains.']",3,3,3,4,Reject
nK7eZEURiJ4,The paper proposes a theoretical framework for distributional reinforcement learning (RL) and introduces the Sinkhorn distributional RL algorithm. It provides a comprehensive theoretical analysis and demonstrates competitive performance on Atari games.,"['Can the authors provide more detailed derivations and explanations for the theoretical results?', 'Can the authors include more baselines in the experimental evaluation for a fair comparison?', 'Can the authors discuss the limitations and potential negative societal impacts of the proposed method?', 'Can the authors provide more intuitive explanations or examples to help understand the theoretical constructs presented in the paper?', 'How does the proposed Sinkhorn distributional RL algorithm perform on a more diverse set of benchmarks beyond Atari games?', 'Can the authors better articulate the practical implications and advantages of their theoretical contributions?']","['The clarity of the theoretical sections needs improvement.', 'The experimental evaluation could be more extensive.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts.', 'The dense mathematical proofs and derivations may limit accessibility for some readers.', 'The paper lacks a discussion on the limitations and potential negative societal impacts of the approach.', 'The empirical validation is limited and needs to be more comprehensive.']",False,3,3,3,5,4,"['Comprehensive theoretical analysis of distributional RL.', 'Novel Sinkhorn distributional RL algorithm.', 'Demonstrated competitive performance on Atari games.', 'Addresses an important issue in reinforcement learning and provides a novel theoretical framework.', 'Theoretical insights are well-supported with detailed proofs.']","['The clarity of the theoretical sections could be improved.', 'Experimental evaluation could be more extensive and include more baselines.', 'Insufficient discussion of limitations and potential negative societal impacts.', 'The paper is dense and may be challenging to follow for readers not deeply familiar with the theoretical aspects of RL.', 'The empirical evaluation is limited to a few Atari games, which is insufficient to robustly validate the claims made in the paper.', 'The paper does not provide sufficient details on the implementation of the proposed algorithm, which makes reproducibility challenging.']",3,3,3,4,Reject
SvFQBlffMB,"The paper proposes Pseudo-KD, an instance-specific label smoothing technique that aims to bridge the performance gap between label smoothing (LS) and knowledge distillation (KD) while maintaining the efficiency of LS. The method involves a two-stage optimization problem to learn the optimal smoothing function. Experimental results on image classification and natural language understanding tasks demonstrate that Pseudo-KD outperforms label smoothing and is competitive with knowledge distillation.","['Can you provide more details on the bi-level optimization problem and its solution?', 'Could you include more ablation studies to analyze the impact of different hyperparameters and components?', 'How sensitive is the method to different choices of α and β?', 'Can the authors provide more details on the hyperparameter tuning process?', 'Are there any additional ablation studies to validate the proposed method?', 'How does the method perform on other benchmarks or practical applications?', 'Can the authors provide more detailed explanations or derivations for some of the optimization steps?', 'What are the practical guidelines for choosing the hyper-parameters α and β? How sensitive is the method to these settings?', 'Can the authors include more recent and related works in the comparison to highlight the unique contributions of Pseudo-KD?', 'How does the performance of Pseudo-KD vary with different types of aggregators or modulation functions?', 'Can the authors include comparisons with more recent methods in knowledge distillation and label smoothing?', 'What are the specific hyperparameters used in the experiments, and how were they chosen?', 'Can you provide more in-depth analysis or insights into why Pseudo-KD performs better than LS and comparably to KD?']","['The paper would benefit from a clearer explanation of the bi-level optimization problem and its solution.', 'More comprehensive ablation studies are needed.', 'The complexity of the method and the lack of detailed explanation may hinder reproducibility.', 'The practical significance and generalizability of the method are not thoroughly demonstrated.', 'The paper should address the sensitivity of the proposed method to hyper-parameter settings in more depth.', ""The clarity of key mathematical derivations needs to be improved to ensure the method's reproducibility."", 'The main limitations include the need for clearer explanations and more exhaustive ablation studies.', 'The authors should also address the potential impact of hyperparameter choices on the performance of Pseudo-KD.']",False,3,2,3,5,4,"['Addresses a practical and relevant problem in training efficient models.', 'Proposes a novel method that unifies LS and KD.', 'Demonstrates effectiveness across various datasets and models, with improvements over LS and competitive performance with KD.', 'The approach offers computational efficiency by eliminating the need for pre-trained models, making it practical for real-world applications.']","['The formulation and solution of the bi-level optimization problem could be clearer.', 'More detailed ablation studies are needed to understand the impact of different components and hyperparameters.', 'The theoretical justification for the method could be strengthened.', 'Complexity of the proposed method may hinder implementation and reproducibility.', 'Mathematical derivations could be better explained for clarity.', 'Practical impact and generalizability of the method are not thoroughly discussed.']",3,3,2,3,Reject
uVXEKeqJbNa,"The paper introduces the Stiffness-Aware Neural Network (SANN) to improve learning Hamiltonian systems, particularly those with stiff dynamics. It uses a Stiffness-Aware Index (SAI) to classify time intervals, allowing for different integration strategies and resampling to balance training data. The method is validated on complex systems like the three-body problem and billiard model, showing significant improvements over existing methods.","['Could you provide more details on the autoencoder aggregator used in your method?', 'What would be the performance impact of using different types of aggregators or modulation functions?', 'Can you provide additional qualitative analyses or case studies to further support your findings?', 'Have the authors explored the impact of different step sizes and integrators on the performance of SANN?', 'What are the limitations of the proposed method, and are there any potential negative societal impacts that need to be considered?']","[""The method's reliance on SAI might be sensitive to certain types of noise or data variability, which should be explored further."", 'The computational overhead introduced by the resampling technique and step size adaptations is not discussed.', 'The authors should be more upfront about the limitations of their approach, including the sensitivity to hyperparameters and the potential computational overhead introduced by the resampling technique.']",False,3,2,3,5,4,"['Addresses a critical issue in learning Hamiltonian systems: stiff dynamics.', 'Introduces a novel and effective metric, Stiffness-Aware Index (SAI), to classify time intervals for better training.', 'Comprehensive experiments with significant improvements over state-of-the-art methods.', 'Potential for extension to other types of stiff dynamical systems.']","['Lack of detailed explanation for the autoencoder aggregator, making it hard to reproduce.', 'More ablation studies are needed to validate various choices in the method, such as different types of aggregators and modulation functions.', 'Limited qualitative analysis; more case studies and visualizations would strengthen the results.', ""The paper's clarity could be improved, especially in the methodology section."", 'The computational overhead introduced by the resampling technique and step size adaptations is not discussed.']",3,3,2,4,Reject
sTNHCrIKDQc,"The paper proposes novel methods for clustering and testing network-valued data using graphons. It introduces a graph distance based on sorting-and-smoothing graphon estimators and presents two clustering algorithms: Distance-based Spectral Clustering (DSC) and Similarity-based Semi-Definite Programming (SSDP). The paper also extends the application of the proposed graph distance to graph two-sample testing, providing theoretical guarantees and empirical validation.","['Can the authors provide more qualitative analysis and additional ablation studies to strengthen the paper?', 'Can the authors improve the clarity of the explanation of assumptions and the autoencoder aggregator?', 'Can the authors discuss more on the practical implications and potential negative societal impacts of the proposed methods?', 'How does the proposed method compare with other recent methods in the literature?', 'Can the authors provide a detailed discussion on the computational complexity of the proposed methods?', 'What are the potential limitations of the proposed methods, and how can they be adapted to relax the assumptions?']","['The methods are heavily reliant on certain assumptions that may not always hold in real-world scenarios. The paper should discuss potential limitations and how the proposed methods can be adapted or extended to relax these assumptions.', 'The paper addresses its limitations well but could benefit from more discussion on the practical implications and potential negative societal impacts of the proposed methods.']",False,3,3,3,5,4,"['The use of graphons for clustering and testing networks is innovative and addresses a current gap in the literature.', 'The theoretical analysis is thorough, with detailed proofs of consistency and performance guarantees.', 'Comprehensive empirical validation, including experiments on simulated and real datasets.', 'The proposed methods show significant improvements over existing methods in both accuracy and scalability.']","['Some proofs are lengthy and could benefit from conciseness.', 'The clarity of certain sections, such as the explanation of assumptions and the autoencoder aggregator, needs improvement.', 'More qualitative analysis and additional ablation studies could strengthen the paper.', 'The practical implications and potential negative societal impacts of the proposed methods need more discussion.', 'The paper lacks a detailed comparison with other recent methods in the literature.', 'Scalability analysis lacks discussion on computational complexity.', 'Theoretical analysis heavily relies on certain assumptions that may not hold in real-world scenarios.']",4,3,3,4,Reject
yztpblfGkZ-,"The paper introduces BankGCN, a novel graph convolutional network architecture that uses adaptive filter banks to capture diverse spectral characteristics of graph data. BankGCN decomposes multi-channel signals into subspaces, applying adaptive filters to each subspace. This approach aims to address the limitations of existing message passing GCNs and spectral GCNs, which often focus on low-frequency features and can overfit due to a lack of shared schemes between filters. The paper validates the proposed method through extensive experiments on various node and graph classification tasks.","['Can the authors provide a more detailed comparison with existing spectral methods in terms of theoretical analysis?', 'How does the proposed method scale with larger datasets and complex graph structures?', 'Can the authors clarify the mathematical derivations and provide more intuitive explanations for the filter bank and subspace projection?', 'How does BankGCN compare with other methods that address the limitations of MPGCNs and spectral methods?', 'Can you provide more intuitive explanations for the filter bank and signal decomposition?', 'What are the computational complexity and scalability implications of BankGCN?', 'Can you provide ablation studies to understand the impact of different components of the proposed method?', 'Can the authors provide a more detailed explanation of the subspace projection process, with examples or visualizations to aid understanding?', 'How does the computational complexity of BankGCN compare to that of other state-of-the-art methods? Can the authors provide a detailed analysis?', 'Can the authors provide more detailed hyperparameter settings and implementation details to facilitate reproducibility?']","['The paper does not adequately address the scalability issues and potential limitations of the proposed method.', 'The significance of the improvements in the experimental results is not well-justified.', 'The paper does not adequately discuss the potential downsides of the proposed method, such as computational complexity or scalability issues.', 'The potential negative societal impacts are not addressed.', 'The paper lacks detailed ablation studies to understand the contributions of each component of BankGCN.', 'The explanations of the subspace projection and filter design are not very clear and could be improved.']",False,3,2,3,4,4,"['Addresses the limitation of existing MPGCNs and spectral GCNs in handling multi-channel signals with diverse spectral characteristics.', 'Proposes an adaptive filter bank to capture various spectral components of graph data.', 'Extensive experiments on multiple datasets demonstrating the performance of the proposed method.', 'The proposed method shows strong performance improvements, especially on heterophilic graph datasets where traditional GCNs struggle.']","['The novelty of the proposed method over existing spectral methods like ChebNets and ARMA is not convincingly demonstrated.', 'The theoretical contributions and justifications for the proposed method are not robust.', 'The paper is densely written and difficult to follow, especially in the mathematical derivation sections.', 'Potential limitations and scalability issues of the proposed method are not adequately addressed.', 'The significance of the improvements shown in the experimental results is not well-justified in practical terms.', 'The paper lacks a strong comparative analysis with existing methods.']",3,3,2,3,Reject
FqKolXKrQGA,The paper introduces a novel approach to infer the structure of network games from observed equilibrium actions without requiring knowledge of the utility functions. The proposed method uses a transformer-like architecture to learn the mapping from actions to network structure. Experimental results on synthetic and real-world data show that the method outperforms existing approaches in various scenarios.,"['Could you provide more details about the autoencoder aggregator?', 'Have you considered experimenting with different types of aggregation functions or modulation functions?', 'Can you provide additional visualizations of the network structures inferred by your method?', 'Can the authors provide a more detailed explanation of the novelty of the transformer-like architecture?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors improve the clarity and organization of the paper, especially in terms of mathematical notation?', 'Can you provide more details on the encoder and decoder components of the model?', 'What is the impact of different hyperparameters on the model performance?', 'Can you conduct more ablation studies to isolate the contributions of different model components?', 'Can you provide more detailed justifications for the design choices in your architecture, such as the specific layers and hyperparameters used?', 'How does the proposed method handle the issue of non-uniqueness of the learned network? Can you provide more insights or potential solutions for this problem?', 'Can you include additional ablation studies to better understand the contribution of each component of your architecture?', 'Can you clarify and elaborate on the potential negative societal impacts of your work?', ""What are the implications of the model's complexity on its scalability and practical applicability?""]","['The paper lacks detailed explanations for some of its components and could benefit from further ablation studies to validate the choice of design decisions.', 'The paper does not address the limitations and potential negative societal impacts of the proposed method. It would benefit from a dedicated section discussing these aspects.', 'The current work is limited to static games and networks. Extending the approach to dynamic games and networks would be an interesting future direction.', 'The method does not guarantee the uniqueness of the learned network structure.', 'The potential negative societal impacts of the work are not discussed in detail. This is important to consider, especially given the potential applications in social sciences.']",False,3,2,3,4,4,"['Addresses a significant and practical problem in network games.', 'Proposes a novel transformer-like architecture that accounts for the symmetries of the problem.', 'Demonstrates superior performance over existing methods on both synthetic and real-world datasets.']","['The paper could benefit from additional ablation studies, particularly investigating the choice of modulation functions and aggregators.', 'Some components, such as the autoencoder aggregator, are not clearly explained and could use more detailed descriptions.', 'The qualitative analysis could be strengthened by providing additional visualization cases.', 'The novelty of the transformer-like architecture could be better elaborated and highlighted.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed method.', 'The clarity and organization of the paper could be improved. Some sections, especially those involving mathematical notation, are difficult to follow.', 'The real-world dataset results could be better contextualized with more comparative analysis.']",3,3,2,3,Reject
34mWBCWMxh9,"The paper proposes spatial smoothing as a method to improve the accuracy, uncertainty estimation, and robustness of Bayesian Neural Networks (BNNs) and deterministic neural networks. By adding blur layers to the models, the authors aim to stabilize feature maps and flatten the loss landscape, leading to better performance across various benchmarks. The paper provides both empirical results and theoretical explanations, framing prior works like global average pooling and pre-activation as special cases of spatial smoothing.","['Can the authors provide more intuitive explanations and better structure for the theoretical sections?', 'Can additional ablation studies be conducted to isolate the effects of different components of the proposed method?', 'How does the proposed method compare to other ensemble methods and anti-aliasing techniques in terms of computational overhead and performance?', 'Can the authors provide a more detailed explanation of the blur operation and its implementation? Specifically, how are the blur layers integrated into the existing neural network architectures?', 'Can the authors validate their empirical results on a wider range of datasets and architectures?', 'Can the authors provide more rigorous mathematical backing for their theoretical explanations?', 'Can the authors improve the clarity and organization of the paper, possibly by simplifying some sections?', 'Can the authors provide detailed information on the experimental setup and hyperparameters to ensure reproducibility?']","['The paper does not sufficiently address potential limitations, such as the computational overhead introduced by spatial smoothing and its applicability to real-time systems.', 'The societal impact of this work is not discussed.', 'The potential for over-smoothing important features is not addressed.']",False,2,2,2,3,4,"['The concept of spatial smoothing as an ensemble technique is novel and interesting.', 'The paper provides comprehensive empirical results demonstrating the effectiveness of the method on CIFAR and ImageNet datasets.', 'Theoretical insights are provided to explain the observed improvements, relating them to loss landscape smoothing and feature map variance reduction.', 'The proposed method is simple to implement and can be integrated into existing models with minimal modifications.']","[""The paper's clarity and organization need improvement. The dense presentation and lack of clear structure make it difficult to follow."", 'Some theoretical claims, such as those related to the sharpening and flattening of the loss landscape, could be more rigorously justified.', 'Additional ablation studies isolating the effects of different components of the proposed method would strengthen the claims.', 'The paper could do more to distinguish its contributions from related work in ensemble methods and anti-aliasing techniques.', 'The novelty of the contributions is questionable. The method appears to be a straightforward application of existing techniques (e.g., blurring) rather than a fundamentally new approach.', 'The empirical validation is not entirely convincing. While the results show improvements, they are not substantial enough to justify the claims.', 'The paper does not address ethical considerations or potential negative societal impacts of the proposed method.']",2,2,2,2,Reject
ZaVVVlcdaN,"The paper proposes FedChain, a framework that combines local and global update methods in federated learning to achieve near-optimal communication cost and fast convergence. The authors provide both theoretical analyses and empirical evaluations to demonstrate the effectiveness of the proposed framework.","['Can the authors provide more empirical evaluations on different datasets and in various federated learning scenarios?', 'Can the authors clarify and provide more intuitive explanations for the theoretical analyses?', 'How does FedChain perform in real-world federated learning applications with highly heterogeneous data and limited communication?', 'Can the authors provide more details on the experimental setup and hyperparameter tuning?', 'How does FedChain compare with newer baseline methods that were not considered?', 'Can the authors include detailed ablation studies to isolate the contributions of individual components of FedChain?']","[""The framework's novelty and practical impact need further validation."", ""The empirical evaluations could be more diverse, and the paper's clarity could be improved."", ""The paper doesn't discuss the practicality of implementing FedChain in real-world systems."", 'There is no discussion on potential negative societal impacts or ethical considerations.']",False,3,3,3,5,4,"['Addresses a significant problem in federated learning: balancing communication cost and convergence speed.', 'Provides a novel framework that combines the strengths of local and global update methods.', 'Theoretical analyses are comprehensive and support the claimed improvements.', 'Empirical evaluations on multiple datasets show promising results.']","['The paper is dense and challenging to follow, affecting its clarity.', ""The novelty of the proposed method isn't sufficiently distinguished from existing work."", 'Empirical evaluations are limited to specific datasets and settings, lacking broader applicability.', 'Lacks a comprehensive comparison with a broader range of baseline algorithms.', 'Does not include detailed ablation studies to isolate the contributions of individual components of the proposed framework.', 'Practical impact and adoption in real-world applications require further validation.']",3,3,3,4,Reject
YJ1WzgMVsMt,"The paper proposes the LOGO algorithm, which integrates TRPO with offline demonstration data to improve RL in sparse reward settings. The algorithm alternates between a policy improvement step and a policy guidance step, using the demonstration data to guide initial exploration. Theoretical analysis and extensive experiments on benchmark environments and real-world robot tasks demonstrate the effectiveness of LOGO.","['Can the authors provide more detailed explanations on the theoretical derivations, especially in Section 3.2?', 'How does the performance of LOGO vary with different decay strategies for the guidance parameter δk?', 'Can the authors provide additional ablation studies to analyze the impact of each component of the LOGO algorithm?', 'Can the authors provide more detailed mathematical derivations and clarify the methodology?', 'Could the authors perform additional ablation studies to explore the sensitivity of different components of the algorithm?', 'Can the authors provide more thorough implementation details, especially for the practical aspects of the algorithm?', 'Can you provide more detailed explanations or examples of the adaptive update rule for δk and its impact on learning performance?', 'How does the LOGO algorithm scale with the complexity of the environment, particularly in high-dimensional state spaces?', 'Can you elaborate on the limitations of LOGO in terms of computational requirements and potential failure cases?', 'How does the proposed method compare to AWAC in a more detailed manner?', 'Can the authors clarify the training process of the discriminator in the presence of incomplete state information?', 'Are there plans to test the algorithm in a more diverse set of environments?']","['The assumption that the behavior policy offers a positive advantage over the initial learning policy might not always hold. This should be discussed in greater detail.', 'The clarity of some sections, especially those involving theoretical derivations, could be improved.', 'The comparison with existing methods, such as AWAC, could be more comprehensive to highlight the novelty and advantages of the proposed approach.', 'The paper would benefit from a clearer explanation of the training process for the discriminator in the presence of incomplete state information.', 'Additional ablation studies are needed to understand the sensitivity of the algorithm to various hyperparameters.']",False,3,3,3,5,4,"['Addresses the significant problem of sparse rewards in RL.', 'Innovative approach combining TRPO with offline demonstration data for guided exploration.', 'Provides theoretical performance guarantees.', 'Comprehensive experiments on benchmark environments and real-world tasks.', 'Strong performance improvements over state-of-the-art methods.']","['Dense and challenging to follow for readers not familiar with TRPO and related RL concepts.', 'Assumption that the behavior policy offers a positive advantage might not hold in all scenarios.', 'More detailed ablation studies needed to analyze the necessity and impact of each component of the LOGO algorithm.', 'Limited comparison with more recent algorithms and a broader set of baselines.', 'Clarity of mathematical derivations and some parts of the methodology could be improved.', 'Implementation details, particularly practical aspects, could be more thorough.']",3,3,3,4,Reject
kG0AtPi6JI1,"The paper introduces a new setting called latent domain learning, where models are trained across multiple visual domains without access to domain annotations. The authors propose a sparse adaptation strategy called Sparse Latent Adapters (SLA) to dynamically adapt feature representations to instances from multiple domains. The method is evaluated on benchmarks like Office-Home, PACS, and DomainNet, showing significant improvements over existing approaches. The paper also explores applications on fairness and long-tailed recognition problems.","['Can the authors provide more details on the implementation and computational complexity of the SLA method?', 'How sensitive is the performance of the proposed method to the choice of the number of latent domains (K)?', 'Can the authors discuss the potential limitations and failure cases of the proposed approach?', 'How does the proposed method handle cases where the latent domains are not clearly distinguishable?', 'Can the authors provide more detailed ablation studies to understand the contributions of individual components of the proposed method?', 'Can the authors provide a clearer explanation of the autoencoder aggregator and its role in the overall framework?']","['The choice of hyperparameters and the impact of each component of the proposed method need further exploration.', 'The paper could benefit from additional ablation studies and a deeper exploration of the impact of the number of latent domains (K).', ""The evaluation on real-world tasks such as fairness and long-tailed recognition, while interesting, could be expanded to provide a more comprehensive understanding of the method's applicability."", 'Potential negative societal impacts, such as biases in latent domain identification, should be discussed.']",False,3,3,3,6,4,"['Addresses a highly relevant and practical problem of learning without domain labels.', 'Proposes an innovative method (SLA) that shows significant improvements over baseline models.', 'Comprehensive experimental setup with evaluations on multiple datasets.', 'The paper is well-organized and clearly written, making it easy to follow the methodology and results.']","['The choice of hyperparameters, especially the number of latent domains (K), is not fully explored.', 'The clarity of some sections, particularly the mathematical formulation, could be improved.', 'More ablation studies are needed to understand the impact of each component of the proposed method.']",4,3,3,4,Accept
o9DnX55PEAo,"The paper proposes a method for cross-architecture distillation where knowledge from large pretrained language models (PreLMs) like BERT is distilled into more efficient order-aware matrix embeddings, specifically a bidirectional CMOW/CBOW-Hybrid model. The paper introduces enhancements such as bidirectional embeddings, a two-sequence encoding scheme, and per-token representations to facilitate this distillation. Experimental results on the GLUE benchmark demonstrate competitive performance, particularly in efficiency and speed.","['Can the authors provide more detailed ablation studies specifically isolating the impact of bidirectional embeddings and DiffCat encoding?', 'Could the authors elaborate on the steps taken to ensure the reproducibility of their results?', 'Can the authors provide a clearer and more detailed description of the bidirectional CMOW/CBOW-Hybrid model and its components?', 'How does the proposed method compare with state-of-the-art models in terms of both performance and efficiency? Detailed configurations and hyperparameters should be provided.', 'What are the limitations and potential negative societal impacts of the proposed approach?', 'How does the proposed method compare with more recent distillation techniques beyond those mentioned, such as those using more sophisticated loss functions or data augmentation strategies?', 'How do the hyperparameters affect the performance of the proposed model?', 'Can you compare your method more directly with recent works in distillation and model compression?']","['The paper could benefit from clearer explanations and better structuring to ensure that the methods and results are easily understandable.', 'Reproducibility remains a potential issue given the complexity of the proposed methods.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed approach. A more detailed discussion is necessary.', 'The paper needs to address the clarity of the methodology and provide more thorough ablation studies to isolate the effects of the proposed components. Additionally, comparisons with more recent distillation methods would strengthen the evaluation.', ""The paper does not fully explore the impact of different hyperparameters and configurations on the model's performance."", 'The clarity of the paper is lacking in some areas, making it difficult to fully understand the novel contributions.']",False,2,3,3,4,4,"['The paper addresses a significant problem of model efficiency and deployability in resource-constrained environments.', 'Introduction of bidirectional CMOW and two-sequence encoding scheme is innovative and shows promising results.', 'Comprehensive experiments on the GLUE benchmark, including comparisons with state-of-the-art models like ELMo and DistilBERT.']","['The clarity of the paper could be improved. Dense sections and complex methodology may hinder comprehension.', 'Ablation studies are not comprehensive enough to isolate the contributions of each component (e.g., bidirectional component, DiffCat encoding).', 'Reproducibility is a concern due to the complexity of the described methods. More detailed guidance and possibly code snippets would be beneficial.', 'The novelty of the bidirectional CMOW/CBOW-Hybrid model is not convincingly established. It is unclear how it significantly advances beyond existing models.', 'The experimental results, while extensive, do not provide a clear and thorough comparison with state-of-the-art methods. Key details are missing, such as the specific configurations and hyperparameters used.', 'The paper lacks a detailed analysis of the limitations and potential negative societal impacts of the proposed approach.']",3,2,3,3,Reject
68n2s9ZJWF8,The paper presents a novel offline reinforcement learning method called Implicit Q-Learning (IQL). The key idea is to use expectile regression to estimate the value of the best actions in a state without directly querying the Q-function. This avoids querying out-of-sample actions and addresses the trade-off between policy improvement and distributional shift. The paper demonstrates state-of-the-art performance on the D4RL benchmark and shows strong fine-tuning capabilities.,"['Can the authors provide more detailed ablation studies to isolate the impact of different components of the method?', 'How does the performance of IQL vary with different values of the expectile parameter τ?', 'Can the authors clarify the computational efficiency claims and compare them directly with other methods?', 'What are the limitations of the proposed method, and how can they be addressed in future work?', 'Can the authors discuss the potential negative societal impacts of the proposed method and how they plan to mitigate them?', 'Can the authors provide more details on the experimental setup, particularly the hyperparameters used?', 'Can the authors include additional ablation studies to further validate the contributions of each component of the method?', 'What are the potential limitations and negative societal impacts of this work?', 'Can you provide more detailed proofs and theoretical explanations for the proposed method?', 'Can you elaborate on the hyperparameter choices and experimental setup in more detail?', 'Can the authors provide more details on the implementation of expectile regression?', 'What are the performance implications of varying the expectile parameter τ?', 'How does the method perform on RL tasks with high-dimensional action spaces?']","['The choice of the expectile parameter τ and the potential challenge of optimizing larger expectiles are limitations.', 'Potential negative societal impacts are not explicitly discussed.', 'The discussion on limitations and potential negative societal impacts is lacking. The authors should address this in the rebuttal period.', 'The clarity of the explanation regarding the core method, especially expectile regression, needs improvement.', 'Additional ablation studies are necessary to understand the impact of different components and hyperparameters.']",False,3,3,4,7,4,"['Innovative approach using expectile regression to avoid querying out-of-sample actions.', 'Comprehensive evaluation on a variety of tasks showcasing the effectiveness of the method.', 'Method is simple to implement, computationally efficient, and integrates well with existing algorithms.', 'Addresses a critical issue in offline RL, namely the trade-off between policy improvement and distributional shift.', 'Comprehensive theoretical analysis supporting the method.', 'State-of-the-art performance on the D4RL benchmark.', 'Strong fine-tuning capabilities with online RL.']","['Lack of detailed ablation studies to isolate the contributions of different components.', 'Some sections, particularly the technical details, are difficult to follow and could be better explained.', 'The limitations and potential negative societal impacts of the proposed method are not adequately addressed.', 'The clarity of the paper could be improved, particularly in the description of the experimental setup and results.', 'Theoretical foundations could benefit from more detailed proofs and explanations.', 'The method may not generalize well to all types of RL problems, particularly those with high-dimensional action spaces.']",4,3,3,4,Accept
z7DAilcTx7,"This paper presents a novel approach to adversarial training by framing it as a distributional robustness optimization (DRO) problem using the ∞-Wasserstein distance. It leverages optimal transport theory and entropic regularization to derive a practical algorithm for training robust classifiers. The proposed method uses Langevin Monte Carlo sampling to generate adversarial examples, purportedly resulting in faster training and more robust models compared to traditional methods like PGD.","['Could you provide more details on the hyperparameter tuning process and the experimental setup?', 'Have you compared your method with other state-of-the-art adversarial training techniques beyond PGD?', 'Can you include more ablation studies to understand the contribution of each component of your method?', 'Can the authors provide more diverse datasets and attack types in the experiments?', 'Could the authors clarify the potential limitations and negative impacts of their proposed method?', 'Can the authors provide more intuitive explanations or visualizations to help understand the theoretical connections between adversarial training, DRO, and optimal transport?', 'What is the performance of the proposed method when applied to different network architectures beyond those tested in the paper?']","['The paper could benefit from more comprehensive comparisons with other state-of-the-art methods.', 'More details on the experimental setup and hyperparameter tuning would enhance reproducibility.', 'Ablation studies are necessary to validate the contributions of different components of the proposed method.', 'The paper does not sufficiently address the potential limitations and negative impacts of the proposed method.']",False,3,2,3,5,4,"['The paper addresses a critical issue in machine learning: adversarial robustness. The problem is highly relevant and practical.', 'The proposed method builds a strong theoretical foundation by connecting adversarial training with DRO and optimal transport.', 'The use of Langevin Monte Carlo sampling introduces a novel and efficient way to generate adversarial examples.', 'The paper shows impressive empirical results, particularly in terms of speed-up and robustness improvements over PGD on MNIST and CIFAR-10.']","['The paper is dense and difficult to follow, particularly in the theoretical sections.', 'The empirical evaluation is limited to MNIST and CIFAR-10, and comparisons with other state-of-the-art adversarial training methods are lacking.', 'Insufficient details on hyperparameter tuning and experimental setup could hinder reproducibility.', 'There is a lack of ablation studies to understand the contribution of each component of the proposed method.', 'The paper does not adequately discuss the potential limitations and negative societal impacts of the proposed method.']",4,3,2,3,Reject
EcGGFkNTxdJ,"The paper presents two new algorithms, Heterogeneous-Agent Trust Region Policy Optimisation (HATRPO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO), for multi-agent reinforcement learning (MARL). These algorithms aim to provide a monotonic improvement guarantee in MARL settings without requiring parameter sharing among agents. The authors justify their approaches with theoretical proofs and validate them with experiments on Multi-Agent MuJoCo and StarCraftII benchmarks.","['Can the authors provide more detailed proofs for the theoretical claims made in the appendices?', 'How do the results change if the order of agent updates in HATRPO is fixed instead of random?', 'Is there any additional insight into why the proposed methods perform significantly better on Multi-Agent MuJoCo compared to SMAC?', 'Can the authors provide more ablation studies to analyze the impact of different components of HATRPO/HAPPO?', 'How do the proposed methods perform compared to other recent MARL algorithms not included in the comparisons?', 'Can the authors provide more detailed explanations and clarifications on some of the key derivations and assumptions in the theoretical sections?', 'Can the authors include additional ablation studies to analyze the impact of different components of HATRPO and HAPPO?', 'Would it be possible to compare the proposed methods with a broader range of baselines, including recent advancements in MARL?', 'Can the authors provide more intuitive explanations and possibly visual aids for Lemma 1 and Proposition 2?', 'How do HATRPO and HAPPO scale with the number of agents and state/action space size?', 'Can the authors discuss any potential limitations or failure cases observed during experimentation?', 'Can the authors provide a more detailed explanation or a simplified version of the methodology to improve clarity?', 'Would additional experiments on more challenging environments help to better demonstrate the capabilities of the proposed methods?']","['The paper acknowledges that the SMAC benchmark might not be sufficiently challenging to showcase the full benefits of HATRPO and HAPPO.', 'The reliance on random order updates in HATRPO could be a limitation in some scenarios.', 'The practical implications of the limitations of parameter sharing and the need for heterogeneity in agent policies could be further explored.', 'The potential negative societal impacts of deploying MARL systems in real-world scenarios are not addressed in detail.', 'The paper does not sufficiently address the scalability and computational complexity of the proposed methods.']",False,3,3,4,7,4,"['The paper addresses a significant gap in MARL by proposing methods that guarantee monotonic improvement without parameter sharing.', 'Theoretical proofs and lemmas are provided to support the proposed methods.', 'Extensive empirical evaluation on challenging benchmarks demonstrates the effectiveness of the methods.', 'The multi-agent advantage decomposition lemma and sequential policy update scheme are novel and well-justified.']","['Some of the theoretical proofs, especially those in the appendices, could be more detailed and transparent.', 'The paper could benefit from additional ablation studies to further validate the necessity of the proposed components.', 'The experimental results on SMAC are somewhat less convincing due to the apparent sufficiency of parameter sharing in those tasks.', 'Certain sections are dense and might be difficult for readers to follow without a deep background in the subject.', 'The empirical comparison lacks diversity in the types of tasks and environments tested.', 'No discussion on the computational complexity and scalability of the proposed methods.']",4,3,3,4,Accept
3pZTPQjeQDR,"The paper investigates the impact of Byte-Pair Encoding (BPE) vocabulary size on the memorization capabilities of Transformer models. The authors demonstrate that larger BPE vocabularies lead to increased memorization across various tasks and architectures. This finding holds even when controlling for the number of learned parameters. The study uses three experimental setups: learning random labels, membership inference attacks, and training data recovery.","['Can the authors provide more detailed explanations for the role of sequence length reduction in memorization?', 'Could the authors conduct additional ablation studies to further isolate the effects of different factors, such as embedding size and attention mechanisms?', 'How do the findings relate to the trade-offs between memorization and generalization? Can the authors discuss this aspect in more detail?', 'How do the findings generalize across different Transformer architectures and other NLP tasks?', 'What are the practical implications of these findings for applications where memorization is either desirable or undesirable?', 'Can the authors discuss the broader ethical implications of increased memorization in NLP models in more depth?']","['The paper addresses the limitations of the study to some extent, but additional clarity on the potential negative societal impacts of increased memorization (e.g., data leakage) would be beneficial.', 'The paper could explore a wider range of Transformer architectures and datasets to ensure the findings are broadly applicable.', 'A more thorough discussion on the balance between memorization and generalization would be beneficial.']",False,3,2,3,5,4,"['The paper addresses an important and underexplored area in NLP: the factors influencing memorization in Transformer models.', 'The experimental setups are comprehensive, covering different aspects of memorization and using multiple Transformer architectures.', 'The findings have practical implications for both enhancing task-specific performance and mitigating data leakage risks.', 'The paper provides a clear demonstration that BPE vocabulary size significantly affects memorization, which can inform hyper-parameter choices in practice.']","['The paper lacks clarity in some sections, making it difficult for readers to follow the experimental procedures and results.', 'Some explanations for the observed phenomena, such as the role of sequence length reduction, are not sufficiently detailed.', 'The paper could benefit from additional ablation studies to further isolate the effects of different factors on memorization.', 'There is limited discussion on the potential trade-offs between memorization and generalization, which is an important aspect of model performance.', 'The exploration is limited to a few Transformer architectures and datasets; broader experimentation could provide more generalizable insights.', 'The broader ethical implications of increased memorization are not adequately discussed.']",3,3,2,3,Reject
AJO2mBSTOHl,The paper proposes integrating Tractable Approximate Gaussian Inference (TAGI) with Deep Q-Learning to address uncertainty in neural network parameters without relying on gradient descent optimization. The method demonstrates comparable performance to backpropagation-trained networks while reducing the number of hyperparameters.,"['How does TAGI compare to other Bayesian methods in terms of computational efficiency and scalability?', 'What is the impact of the various hyperparameters on performance?', 'How robust is the method across different types of environments and tasks?', 'Can the authors provide more detailed mathematical derivations for the TAGI method and its integration with Q-learning?', 'How does TAGI compare with other state-of-the-art methods on a broader range of benchmarks?', 'What are the computational trade-offs between TAGI and traditional backpropagation methods?', 'Can the authors discuss the limitations and potential drawbacks of the TAGI approach more thoroughly?']","['The computational cost of TAGI compared to gradient-based methods is mentioned but not deeply analyzed.', 'The paper does not adequately discuss the limitations and potential drawbacks of the TAGI approach, which is crucial for understanding its applicability.', 'The clarity of the paper could be improved by simplifying the mathematical formulations and notational complexity.', 'The slower training times compared to backpropagation may limit practical applicability.']",False,2,2,2,4,4,"['Addresses a significant problem in reinforcement learning by leveraging TAGI, which avoids gradient descent.', 'Provides a comprehensive theoretical foundation and thorough explanation of integrating TAGI with Q-learning.', 'Promising experimental results demonstrating comparable or better performance on various benchmarks, including Atari games.', 'Reduces the number of hyperparameters, simplifying model tuning.']","['Insufficient experimental evidence to support the claims.', 'Poor writing and organization, making it difficult to follow the key ideas.', 'Lack of thorough comparison with existing methods.', 'Impact and significance of the method are not convincingly demonstrated.', 'Clarity of the mathematical formulation, especially around the TAGI method and its integration with Q-learning, could be improved.', 'Computational efficiency of TAGI compared to backpropagation methods is not convincingly demonstrated, especially considering the slower training times reported.']",3,2,2,3,Reject
YevsQ05DEN7,"The paper investigates the phenomenon of dimensional collapse in contrastive self-supervised learning and proposes a novel method, DirectCLR, to address it. The authors provide both theoretical and empirical evidence to show that dimensional collapse exists in contrastive methods, and that DirectCLR can mitigate this issue by directly optimizing the representation space without the need for a trainable projector.","['Can the authors provide more details on the choice and impact of the hyperparameter d0?', 'Could the authors include more ablation studies to dissect the contributions of different components of DirectCLR?', 'Can the authors provide more empirical evidence on different datasets or tasks?', 'Could the authors clarify some of the more complex mathematical proofs for better accessibility?', 'Can you provide more intuitive explanations for the theoretical results, particularly for readers who may not be experts in the field?', 'Have you considered the limitations of DirectCLR? If so, please elaborate on them.']","['The paper could be further improved with additional ablation studies and a more detailed exploration of the hyperparameters.', 'The paper primarily focuses on ImageNet, which may limit the generalizability of the proposed method.', 'The theoretical contributions, while sound, are somewhat incremental.', 'The paper does not provide a detailed discussion of potential limitations and negative societal impacts of DirectCLR.', 'The clarity of the theoretical sections could be improved to enhance understanding.', 'The theoretical complexity of the paper may limit its accessibility to a broader audience.']",False,3,3,3,5,4,"['The paper addresses a significant problem in the domain of self-supervised learning, namely dimensional collapse in contrastive learning methods.', 'The proposed method, DirectCLR, is novel and effectively avoids the use of a trainable projector, simplifying the learning process.', 'The theoretical analysis is comprehensive and well-supported by empirical evidence.', 'The experimental results on ImageNet are compelling, showing that DirectCLR outperforms SimCLR with a trainable linear projector.']","['The paper could benefit from additional ablation studies to further dissect the components and dynamics of DirectCLR.', 'Some of the mathematical derivations and proofs are dense and could be more clearly presented for better understanding.', 'The impact of different choices for the hyperparameter d0 could be explored in more detail.', 'Empirical evidence is limited to ImageNet, and the generalizability of the method to other datasets or tasks is not demonstrated.', 'The paper lacks a detailed discussion on the limitations of DirectCLR and potential negative societal impacts.']",3,3,3,4,Reject
6Q52pZ-Th7N,The paper introduces Pseudo-Labeled Auto-Curriculum Learning (PLACL) for semi-supervised keypoint localization. PLACL uses reinforcement learning (RL) to automatically generate a dynamic curriculum for pseudo-label selection and proposes a cross-training strategy to mitigate confirmation bias. Extensive experiments on multiple benchmark datasets demonstrate significant improvements over state-of-the-art methods.,"['Can the authors provide more details about the autoencoder aggregator?', 'How does the computational cost of the RL-based curriculum search process scale with larger datasets?', 'Can the authors provide more ablation studies and visualizations of pseudo-labeled samples?']","['The main limitations are related to the complexity and scalability of the RL-based curriculum search process. Additionally, the clarity of some methodological details could be improved. The authors should address these concerns in the rebuttal period.']",False,3,3,4,7,4,"['The problem of semi-supervised keypoint localization is relevant and practical.', 'The use of RL for dynamic curriculum generation and the cross-training strategy are innovative and well-motivated.', 'Extensive experiments on multiple datasets show significant improvements over state-of-the-art methods.', 'The method is model-agnostic and can be applied to different keypoint localization networks.']","['The complexity of the RL-based curriculum search process and its scalability to larger datasets could be a concern.', 'The clarity of some methodological details, especially related to the autoencoder aggregator, could be improved.', 'More ablation studies and additional visualizations of pseudo-labeled samples would strengthen the paper.']",4,3,3,4,Accept
XJFGyJEBLuz,"The paper introduces Born Again Neural Rankers (BAR), a novel approach to improve ranking performance in Learning to Rank (LTR) problems using knowledge distillation (KD). The method involves a listwise distillation framework and a transformation function for teacher scores, resulting in significant performance improvements over state-of-the-art models on multiple datasets. The paper also provides theoretical insights into why the method is effective.","['Can the authors provide more details on the practical implications of the added complexity?', 'How generalizable is the proposed method to other types of ranking problems and datasets?', 'Can the theoretical explanations be simplified or clarified further?', 'Can the authors provide more detailed hyperparameter settings and training protocols to aid in reproducibility?', 'Could the theoretical explanations be clarified with more intuitive examples or diagrams?', 'How does BAR compare to existing KD methods in terms of computational efficiency and training time?', 'Can the authors provide more detailed ablation studies, particularly focusing on the contributions of the teacher score transformation and the listwise distillation?', 'Can the methodology section be clarified, potentially with more intuitive explanations or diagrams?', 'Can you provide more details on the choice of hyperparameters for the teacher score transformation function?', 'How does the method perform on other types of ranking datasets, beyond the current benchmarks?', 'Can the authors provide more rigorous theoretical justifications for their methods?', 'Can the authors conduct more comprehensive ablation studies and sensitivity analyses?', 'Can the authors discuss the potential limitations and negative societal impact of their approach?']","['The added complexity of the method might limit its practicality.', 'The method might be too tailored to specific types of ranking problems and datasets.', 'The paper could provide more detailed hyperparameter settings and training protocols for reproducibility.', 'The theoretical parts of the paper could be clarified with more intuitive explanations.', 'The complexity and density of the methodology section, as well as the need for more detailed ablation studies, are key limitations.', 'The theoretical justifications are not entirely rigorous and may not generalize well.', 'The ablation studies and sensitivity analyses are not comprehensive enough.', 'There is no discussion on potential limitations and negative societal impact.']",False,3,3,3,6,4,"['The paper introduces a novel approach (BAR) that effectively applies Born Again Networks concepts to ranking problems.', 'Theoretical contributions that provide insights into why the method works better than existing approaches.', 'Strong empirical validation with significant performance improvements over state-of-the-art models on multiple datasets.']","['The proposed method introduces additional complexity, which might limit its practicality.', 'The approach may be tailored too specifically for certain types of ranking problems and datasets.', 'Some sections, especially those explaining the theoretical underpinnings, could be clearer.', 'The paper lacks detailed hyperparameter settings and training protocols, which are crucial for reproducibility.', ""More detailed comparisons with existing methods, beyond just empirical results, would strengthen the argument for BAR's novelty and effectiveness."", 'Theoretical justifications are somewhat forced and not entirely rigorous.', 'Ablation studies and sensitivity analyses could be more comprehensive.', 'Lacks discussion on potential limitations and negative societal impact.']",3,3,3,4,Reject
u7UxOTefG2,The paper critically examines the suitability of Bayesian Neural Networks (BNNs) for out-of-distribution (OOD) detection. It argues that common architectural choices in BNNs do not necessarily lead to good OOD detection and emphasizes the importance of function space priors. The paper combines theoretical analysis with empirical experiments to demonstrate the limitations and potential trade-offs between generalization and OOD detection.,"['Can the authors provide more intuitive explanations or visualizations for the theoretical arguments presented in the paper?', 'What practical steps can be taken to improve OOD detection in BNNs based on the findings of this study?', 'Have the authors considered testing their hypotheses on more complex, real-world datasets to validate their theoretical claims?', 'How can the insights from low-dimensional experiments be applied to high-dimensional problems?', 'Are there any concrete methods or guidelines that practitioners can use to improve OOD detection in BNNs based on the insights provided in the paper?', 'Would additional ablation studies on different architectures and datasets alter the conclusions drawn in the paper?']","['The paper could be more accessible to a broader audience with clearer explanations and more intuitive examples.', 'The practical implications of the findings are not fully explored, and more real-world validations are needed.', 'The primary limitation is the focus on low-dimensional problems and synthetic datasets, which may not fully represent the challenges of real-world applications.']",False,3,3,3,6,4,"['The paper addresses a critical and timely issue in machine learning: the efficacy of BNNs for OOD detection.', 'It provides a thorough theoretical analysis supported by empirical experiments.', 'The paper emphasizes the importance of function space priors, which is a novel and valuable perspective.', 'The experiments are comprehensive, covering various architectures and showing consistent results.']","['Some sections of the paper could be clearer, particularly the theoretical explanations.', 'The generalizability of the results to real-world high-dimensional data is not fully established.', 'Further ablation studies and experiments on more diverse datasets could strengthen the conclusions.', 'The paper could benefit from a more detailed discussion on the practical implications of the findings for real-world applications.']",3,3,3,4,Reject
30nbp1eV0dJ,"The paper provides tight lower bounds for differentially private empirical risk minimization (DP-ERM) in both approximate-DP and pure-DP settings. The authors introduce novel techniques, including the biased mean property for fingerprinting codes and the use of the ℓ2 loss function, to achieve these results. The paper addresses significant gaps in the current literature and advances the understanding of the theoretical limits of DP-ERM.","['Could the authors provide more intuitive explanations or examples to make the dense theoretical content more accessible?', 'Are there any specific applications or scenarios where the introduced techniques, such as the biased mean property for fingerprinting codes, could be particularly useful?', 'Can the authors provide some practical experiments or case studies to demonstrate the applicability of their theoretical results?', 'What are the potential limitations or negative societal impacts of the proposed techniques, and how can they be mitigated?', 'What are the practical implications of these tighter lower bounds for real-world applications of DP-ERM?']","['The paper could be more accessible if the authors provided additional intuitive explanations and examples.', 'The paper primarily focuses on theoretical contributions and lacks practical validation. Including experiments or discussing practical scenarios could enhance the impact of the work.', 'The paper does not adequately address potential limitations and negative societal impacts. Including a discussion on these aspects would strengthen the paper.']",False,3,3,3,6,4,"['The paper addresses a highly relevant and important topic in the field of differential privacy.', 'The authors introduce novel techniques, such as the biased mean property for fingerprinting codes and the use of the ℓ2 loss function, which could be of independent interest.', 'The results are significant and advance the understanding of the theoretical limits of DP-ERM.', 'The paper includes detailed proofs and logical flow, demonstrating a high level of technical proficiency and thoroughness.']","['The paper is dense and may be challenging to follow for readers not deeply familiar with the topic.', 'Some proofs and explanations could benefit from additional clarity and detail to make them more accessible.', 'Lacks practical experiments and discussions on the real-world applicability of the results.', 'Insufficient discussion on the potential limitations and negative societal impacts of the work.']",4,3,3,4,Reject
AJAR-JgNw__,"The paper proposes DEPTS, a novel deep learning framework for periodic time series (PTS) forecasting. DEPTS includes an expansion module for modeling complex dependencies and a periodicity module for capturing diversified periods. The paper presents extensive experimental results on synthetic and real-world datasets, demonstrating significant improvements over state-of-the-art models.","['Can the authors provide more empirical evidence to justify the necessity and effectiveness of the parameter initialization process?', 'Can the authors simplify the explanations of the expansion and periodicity modules for better clarity?', 'Can the authors provide more detailed analysis and discussion on the ablation studies to highlight the impact of different components on the overall performance?', 'Can the authors provide theoretical justification for the decoupled formulation and the triply residual expansions?', 'Can the authors include more detailed descriptions and visual aids for the expansion and periodicity modules?', 'Can the authors conduct more comprehensive ablation studies, such as varying the number of layers in the expansion module and different types of periodic functions?', 'What are the computational efficiency and scalability considerations of the proposed model on larger datasets?', 'Can the authors provide more rigorous mathematical proofs for their claims?', 'What is the justification for the methodological choices made in the design of DEPTS?', 'Can the authors provide more intuitive explanations or visualizations for the initialization of periodic coefficients using DCT?', 'Are there any limitations or scenarios where DEPTS might not perform well?', 'How does DEPTS perform compared to other recent methods not discussed in the paper?']","['The primary limitations are the complexity of the model and the need for clearer explanations and justifications for various components and processes. The paper should also address the robustness of the parameter initialization strategy.', 'The current version of the paper lacks detailed explanations and validations for some of the critical processes, such as the initialization of the periodicity module.', 'The clarity of the paper needs improvement to ensure better reproducibility and understanding of the proposed methods.', 'The paper should address the limitations related to the clarity of core components, computational complexity, and the depth of ablation studies.', ""The paper lacks rigorous mathematical proofs and detailed explanations of the model's inner workings. The authors should address these concerns to improve the technical soundness and clarity of the paper."", 'The paper could discuss specific scenarios where DEPTS might not perform well or where the assumptions made by the model might not hold.']",False,3,3,3,5,4,"['Addresses a highly relevant issue in time series forecasting, particularly for periodic time series.', 'Novel architecture combining an expansion module and a periodicity module.', 'Comprehensive experimental results demonstrating significant improvements over state-of-the-art models.', 'Innovative parameter initialization strategy using Discrete Cosine Transform.', 'Provides interpretability by differentiating between local momenta and global periodicity in forecasts.']","['Complexity of the model and its components needs clearer explanations and justifications.', 'Parameter initialization process requires more empirical evidence to prove its necessity and effectiveness.', 'Ablation studies, while extensive, could benefit from more detailed analysis and discussion.', 'Lacks theoretical justification for the design choices and formulations.', 'High computational complexity and scalability concerns are not addressed.', 'The clarity and organization of the paper could be improved, particularly in describing the methodology and experiments.', 'The significance of the results is not consistent across all datasets, and the improvements over baselines like N-BEATS are not always substantial.']",3,3,3,4,Reject
Uxppuphg5ZL,The paper proposes a novel approach to learned physical simulation using constraint-based methods rather than explicit forward models. It leverages Graph Neural Networks (GNNs) as the constraint function and uses gradient descent as the constraint solver. The model demonstrates competitive performance across various physical domains and showcases the ability to generalize to more solver iterations at test time and incorporate hand-designed constraints.,"['Could the authors provide more details on the auto-differentiation in JAX and the exact hyperparameters used?', 'Can the authors include more comprehensive ablation studies, particularly concerning the choice of GNN architecture versus MLPs and varying the number of solver iterations?', 'What are the potential limitations and computational costs of scaling the approach to very large systems or higher-dimensional problems?', 'How does the proposed method compare to non-GNN approaches or traditional simulation methods?']",['The paper could benefit from better clarity and more comprehensive ablation studies. The scalability and computational costs of the approach for very large systems are not thoroughly discussed.'],False,3,3,3,6,4,"['Novel approach using constraint-based methods in learned physical simulation.', 'Utilizes Graph Neural Networks (GNNs) to represent constraint functions, leveraging the compositional nature of physical systems.', 'Demonstrates the ability to generalize to more solver iterations and incorporate hand-designed constraints.', 'Extensive experimental validation across multiple challenging physical domains, showing competitive or better performance compared to state-of-the-art simulators.']","['The paper is dense and sometimes challenging to follow. Specific details about the implementation, such as auto-differentiation in JAX or the exact hyperparameters used, could be more clearly explained.', 'The ablation studies could be more comprehensive, particularly concerning the choice of GNN architecture versus MLPs, varying the number of solver iterations, and the impact of different solver techniques.', 'The scalability of the approach to very large systems or higher-dimensional problems is not thoroughly discussed.', 'Comparisons with non-GNN approaches or traditional simulation methods are lacking, which could provide a more comprehensive understanding of the advantages and limitations of the proposed approach.']",3,3,3,4,Reject
3PN4iyXBeF,"The paper presents Amortized Implicit Gradient Optimization (AmIGO), an algorithm for bilevel optimization problems that leverages a warm-start strategy and provides a unified theoretical framework for convergence analysis. The paper demonstrates that AmIGO achieves better complexity compared to existing methods and is validated through extensive experiments on synthetic and real-world tasks.","['Can the authors provide more insights into the choice and tuning of hyperparameters?', 'How does AmIGO perform on larger and more diverse real-world datasets?', 'Can the authors provide more details on the experimental setup and hyperparameter choices?', 'What is the impact of varying the number of iterations and batch sizes in the experiments?', 'How does the method perform in very high-dimensional or highly non-convex settings?', 'Can the authors provide more practical insights into the implementation of AmIGO?', 'How does the complexity of the theoretical framework impact the usability of the algorithm in real-world applications?', 'Can the authors discuss potential limitations or scenarios where AmIGO may not perform well?']","[""The algorithm's dependence on hyperparameters and the need for extensive tuning might limit its practical applicability."", 'The paper could be clearer in its explanations, particularly in the theoretical sections.', 'Additional ablation studies are needed to understand the impact of various algorithmic choices.', 'The complexity of the theoretical analysis may limit the accessibility and practical implementation of the proposed method.', 'Potential limitations and scalability issues under very high-dimensional or highly non-convex settings.']",False,4,3,4,8,5,"['Addresses an important and practical problem in bilevel optimization.', 'Introduces a novel algorithm with a warm-start strategy.', 'Provides a robust theoretical framework for convergence analysis.', 'Demonstrates effectiveness through extensive experiments.', 'Comprehensive experimental validation with synthetic and real tasks.']","['The paper is highly technical and dense, which might make it difficult for some readers to follow.', 'The experimental validation could benefit from additional real-world datasets.', ""The algorithm's performance is highly dependent on the choice of hyperparameters."", 'Comparisons with related work may not be entirely fair due to differing assumptions or problem settings.', 'Potential limitations and scalability issues in very high-dimensional or highly non-convex settings are not thoroughly discussed.']",4,4,3,4,Accept
Ih7LAeOYIb0,The paper introduces the Iterative Memory Network (IMN) for long sequential user behavior modeling in recommender systems. IMN addresses the limitations of RNNs and self-attention mechanisms by using a memory-triggered iterative update process that models both intra-sequence and target-sequence dependencies. The framework achieves O(L) complexity and is scalable to long sequences. The proposed method demonstrates significant performance improvements over state-of-the-art models on public and industrial datasets.,"['Can the authors provide more details about the autoencoder aggregator?', 'What is the performance of the proposed model with different types of aggregators?', 'Can more qualitative cases be provided to enhance the analysis?', 'Can the authors provide more details about the Memory Enhancement Module and its role in the IMN framework?', 'What is the impact of different types of aggregation functions and modulation functions on the performance of the IMN framework?', 'Can the authors include more qualitative analysis and visualizations to better illustrate the effectiveness of the proposed method?', 'Can you provide a more detailed explanation of the iterative memory update process and the role of multi-way attention?', 'What is the impact of the Memory Enhancement module on the overall performance?', 'Can you include more ablation studies to analyze the contribution of each component of the proposed method?', 'How does the performance of IMN vary with different distance metrics used in the multi-way attention mechanism?', 'What are the computational resource requirements for training and deploying IMN in smaller-scale systems?', 'How does IMN perform with different hyperparameters and configurations? Can you provide more analysis on this?', 'Can you share more insights into the deployment and scalability of IMN in different industrial settings?']","['The clarity of the encoder layer and the autoencoder aggregator needs improvement.', 'Additional ablation studies could provide deeper insights into the impact of different design choices.', 'The complexity of the method should be better explained, and potential computational resource limitations should be discussed.', 'The paper could provide more insights into the impact of different hyperparameters and real-world deployment.']",False,3,3,3,6,4,"['Addresses a critical problem in long sequential modeling for recommender systems.', 'IMN offers an efficient solution with O(L) complexity, making it scalable for long sequences.', 'The experimental results on both public and industrial datasets show significant improvements, with a notable 7.29% CTR increase in a real-world deployment.', 'The paper provides a detailed comparison with state-of-the-art methods and includes an ablation study to validate the contributions of different components.', 'The iterative memory update mechanism combined with multi-way attention is a novel method for handling long sequences in recommender systems.']","['The encoder layer and the autoencoder aggregator are not clearly explained and could benefit from more detailed descriptions.', 'Certain sections of the paper, particularly those describing the Memory Enhancement Module and the ablation studies, lack clarity and could benefit from more detailed explanations.', 'More ablation studies are needed to understand the impact of different design choices, such as modulation functions and types of aggregators.', 'The qualitative analysis is limited to single visualizations per task; more cases would enhance the robustness of the analysis.', 'The complexity of the proposed method may hinder its reproducibility and understanding.']",3,3,3,4,Accept
7Bc2U-dLJ6N,"The paper proposes SGEM, Stochastic Gradient with Energy and Momentum, an optimization algorithm designed to improve convergence rates and stability in non-convex stochastic optimization problems. It builds upon the AEGD method by incorporating momentum, thereby combining the advantages of both energy-based and momentum-based techniques. The authors provide theoretical analysis demonstrating energy stability and convergence rates, and empirical validation on deep learning tasks.","['Can the authors provide more intuitive explanations or visualizations to help understand the theoretical results?', 'Would it be possible to include experiments on a wider variety of tasks or datasets to better demonstrate the practical benefits of SGEM?', 'Can the authors provide clearer and more detailed explanations of the theoretical proofs?', 'How does SGEM perform compared to other modern optimization algorithms beyond the ones tested?', 'Can the authors include additional ablation studies to isolate the impact of energy and momentum components?', 'Can the authors provide more detailed explanations and justifications for the assumptions made in the theoretical sections?', 'Are there additional benchmarks or datasets where SGEM has been tested? More diverse evaluations would strengthen the empirical claims.', 'How does SGEM perform in comparison to other recent optimization methods not considered in this paper?', 'Can the authors provide more details on the autoencoder aggregator?', 'Could the authors include more detailed ablation studies to isolate the contributions of different components of SGEM?']","['The paper does not adequately discuss the limitations of SGEM, particularly in scenarios where it might not perform as well as other optimization methods.', 'The potential negative societal impact of the work is not addressed.', 'The complexity and clarity of the theoretical analysis need improvement.', 'Empirical results should cover a broader range of baselines and include more ablation studies.', 'The clarity of the paper could be improved, as some sections are difficult to follow.', 'Additional ablation studies and comparisons with more recent optimization methods would strengthen the evaluation.', 'The paper should discuss more thoroughly the limitations of SGEM, including potential pitfalls in practical applications and scenarios where it may underperform.']",False,3,2,2,4,4,"['The integration of energy and momentum in SGEM is a novel approach that addresses issues in existing optimization methods.', 'The theoretical analysis is thorough, covering energy stability, convergence rates, and regret bounds.', 'Empirical results on standard deep learning benchmarks show that SGEM improves convergence speed and generalization performance compared to other methods.']","[""The paper's theoretical sections are dense and may be difficult for practitioners to follow."", 'The practical implications of the method could be better demonstrated with more varied experiments beyond standard benchmarks.', 'The clarity of the methodology section could be improved, particularly in explaining the relationship between energy and momentum in SGEM.', 'Theoretical proofs are complex and may lack clarity.', 'More comprehensive empirical evaluation against a wider range of baselines is needed.', 'The paper is dense and could benefit from clearer explanations and structure.', 'Experimental results are limited to a few benchmarks, and the comparisons with other state-of-the-art methods are not exhaustive.', 'The contributions, while novel, are somewhat incremental and do not significantly advance the state-of-the-art.', 'The improvements over existing methods like AEGD and SGDM are not sufficiently substantial to warrant high impact.']",3,3,2,3,Reject
rTAclwH46Tb,"The paper proposes Eigencurve, a novel learning rate scheduler for SGD on quadratic objectives with skewed Hessian spectrums. Theoretical analysis and empirical results demonstrate its potential for achieving minimax optimal convergence rates. The paper also introduces practical schedulers inspired by this theory.","['How robust is the proposed method to deviations from the skewed Hessian spectrum assumption?', 'Can the authors provide empirical results on a broader range of tasks?', 'How does the overhead of estimating the Hessian spectrum compare to the benefits of using Eigencurve?', 'How sensitive is Eigencurve to the accuracy of the estimated eigenvalue distribution?', 'Can the authors provide more insights into how the practical schedules inspired by Eigencurve compare to other common schedules in a broader range of settings?']","['The paper could be more accessible with additional explanatory text in dense mathematical sections.', 'Practical utility might be constrained by the computational overhead of estimating the Hessian spectrum.', 'The reliance on accurate eigenvalue distribution estimation might limit the applicability of the proposed method in some practical scenarios.', ""The method's applicability may be limited to settings where the Hessian spectrum is skewed and can be accurately estimated."", 'The method is primarily validated on quadratic approximations, which may not fully represent the complexity of real-world tasks.']",False,3,3,3,5,4,"[""Introduces a novel concept of using Hessian's eigenvalue distribution for learning rate scheduling."", 'Provides rigorous theoretical analysis to support the proposed method.', 'Empirical results show significant improvements over existing schedulers on image classification tasks.', 'Theoretical proofs show that Eigencurve can achieve optimal convergence rates under certain conditions.', 'Introduction of simplified practical schedules inspired by Eigencurve has significant practical implications.']","['Assumes a skewed Hessian spectrum, which may not always be true in practice.', 'Limited empirical evaluation across different types of tasks.', 'Estimating the Hessian spectrum can be computationally expensive, which may offset the benefits.', ""The paper's clarity is lacking; the notations and proofs are dense and not well-explained."", 'Connection to practical applications is weak; the simplified learning rate schedules are not thoroughly investigated.']",4,3,3,4,Reject
ZumkmSpY9G4,"The paper proposes a novel generative framework to tackle the logits bias problem in online class-incremental learning (CIL). Instead of using a softmax classifier, the authors employ a nearest-class-mean (NCM) classifier for inference and train the model using a Multi-Similarity (MS) loss, which is shown theoretically to optimize the feature space in a generative way. The paper also introduces a hybrid loss combining the MS loss with a Proxy-NCA (PNCA) loss to improve the model's ability to learn new data. Extensive experiments on various benchmarks demonstrate the efficacy of the proposed method in reducing catastrophic forgetting and outperforming state-of-the-art replay-based methods.","['Can you provide more details on the implementation of the autoencoder aggregator?', 'How does the hybrid loss function specifically combine the MS loss and the Proxy-NCA loss?', 'Have you considered other types of generative classifiers or different combinations of loss functions in your ablation studies?', 'Can you provide more detailed ablation studies on the impact of MS loss and PNCA loss individually?', 'How robust are the theoretical assumptions in practical scenarios?', 'Can you clarify the detailed mechanism of the NCM classifier and the hybrid loss function?', 'Have the authors considered testing their method on more varied datasets to validate its generalizability?', 'Could the authors improve the clarity of the theoretical derivations and provide more detailed explanations of the algorithm?', ""Would it be possible to include more qualitative analysis, such as visualizations of the feature space, to better illustrate the method's effectiveness?"", 'Can the authors provide more details on the training procedure, including the selection of hyperparameters?', 'How should one choose the weight of the Proxy-NCA loss in practice?', 'Can the authors provide some qualitative analysis or visualizations of the learned feature space to give more insights into the effectiveness of the proposed method?']","['The paper could benefit from more detailed explanations of certain components and improved clarity in the presentation of the theoretical analysis and experimental setup.', ""The paper's reliance on theoretical assumptions needs more empirical validation."", 'The impact of the hybrid loss components is not thoroughly explored.', 'Certain sections lack clarity and could benefit from more detailed explanations.', 'The complexity of the proposed method might limit its practical implementation.', 'More detailed explanations of certain components and additional experiments on varied datasets could enhance the paper.', 'The paper needs more comprehensive ablation studies to fully understand the impact of different components.', 'The clarity of some sections should be improved for better readability and understanding.', 'The main limitation is the additional complexity introduced by the hybrid loss function. The paper should discuss the computational overhead and provide guidelines for choosing the weight of the Proxy-NCA loss.']",False,3,2,3,6,4,"['Addresses an important and practical issue in online CIL: the logits bias problem in softmax classifiers.', 'The proposed generative framework is novel and includes a well-justified theoretical analysis.', ""Extensive experiments on multiple benchmarks, including newly introduced task-free datasets, demonstrate the method's superiority over state-of-the-art methods."", 'The hybrid loss combining generative and discriminative objectives is a sound approach to enhance learning from new data.']","['The paper lacks detailed explanations of some components, such as the implementation of the autoencoder aggregator and the exact nature of the hybrid loss function.', 'The clarity of the paper could be improved, particularly in the sections describing the theoretical analysis and the experimental setup.', 'The theoretical assumptions and their practical implications need more rigorous validation.', 'Ablation studies on the impact of different components (e.g., MS loss, PNCA loss) are insufficient.', 'The complexity of the proposed method might be a barrier to its practical implementation.']",4,3,2,4,Reject
MkTPtnjeYTV,"The paper investigates the memorization power of ReLU neural networks, presenting an optimal construction for memorizing N points with O(√N) parameters. The study extends to networks with bounded depth and bit complexity, providing both upper and lower bounds that are optimal up to logarithmic factors.","['Can the authors provide more detailed explanations or visual aids to clarify the dense parts of the proofs?', 'Are there any practical implications or examples that could be included to demonstrate the application of the theoretical results?', 'Can the authors provide any empirical validation for their theoretical claims?', 'How does the practical implementation of networks with such high bit complexity look like?', 'Are there recent advancements in the field that could be integrated into the discussion?']","['The paper primarily focuses on theoretical analysis, which may limit its immediate practical impact. Including practical examples or implications could enhance the relevance of the results.', 'The reliance on weights with large bit complexity may limit practical implementations. Additional empirical validation could strengthen the paper.']",False,3,2,4,6,4,"['Addresses a fundamental and significant problem in neural network theory.', 'Provides novel and optimal constructions for memorizing data with ReLU networks.', 'Theoretical analysis is rigorous and thorough, with detailed proofs.', 'Explores various aspects, including bit complexity and bounded depth networks.']","['Some parts of the proofs are dense and difficult to follow.', 'The presentation could be improved with more detailed explanations and visual aids.', 'Certain notations and steps in the proofs are not immediately clear and require further elaboration.', 'There is no empirical validation of the theoretical claims.', 'Focuses heavily on theoretical aspects, which might limit practical relevance.']",4,3,2,4,Accept
hOaYDFpQk3g,"The paper introduces LightWaveS, a distributed solution for efficient multivariate time series classification (MTSC) that leverages wavelet scattering transformation and feature selection. The method aims to address the high inference times and redundancy of features in existing methods like ROCKET and MINIROCKET. LightWaveS achieves significant speedup during inference while maintaining comparable accuracy, making it suitable for deployment in edge computing environments.","['Can you provide more details on the wavelet scattering process and the specific choices made during feature selection?', 'How do the different components of the method contribute to its overall performance? Detailed ablation studies would be helpful.', 'Have you considered any ethical implications or potential negative societal impacts of your work? If so, please elaborate.', 'How does LightWaveS perform in scenarios with different data characteristics, such as varying numbers of channels or different noise levels?', 'Can you provide more details on the autoencoder aggregator and its role in the feature extraction process?', 'How does the proposed framework compare with other state-of-the-art MTSC methods in terms of computational complexity and scalability?', 'Why were specific wavelets chosen, and how do different wavelets impact performance?', 'What is the impact on accuracy when further reducing the number of features?', 'Are there scenarios where the proposed method may not perform as well, and what are the potential trade-offs?']","['The paper lacks clarity in explaining some key aspects of the method, particularly the wavelet scattering process and feature selection.', 'More detailed ablation studies are needed to understand the contribution of different components.', 'The novelty of the method is somewhat limited, as it builds on existing techniques without substantial theoretical advancements.', 'The paper does not sufficiently address the potential limitations of LightWaveS, such as its performance on datasets with very different characteristics from those tested.', 'Ethical considerations and potential negative societal impacts are not addressed.']",False,3,2,3,5,4,"['Addresses a relevant and practical problem in MTSC, particularly for edge computing.', 'Achieves substantial inference speedup (9x to 65x compared to ROCKET) while maintaining comparable accuracy.', 'Distributed nature allows it to scale well with the number of channels and nodes.', 'Comprehensive experimental results covering accuracy, training time, and inference speed across multiple datasets.', 'The method is grounded in wavelet theory, adding to the interpretability of the results.']","[""The clarity of the method's description can be improved, particularly in explaining the wavelet scattering process and feature selection."", 'More detailed ablation studies could be provided to understand the impact of different components of the method.', 'The theoretical contribution is limited; the method mainly extends existing techniques with incremental improvements.', 'Ethical considerations and potential negative societal impacts are not discussed.']",3,3,2,4,Reject
7MV6uLzOChW,"The paper presents a novel approach to conditional image generation by leveraging pre-trained variational auto-encoders (VAEs). The method aims to reduce training times and improve sample diversity by using an existing pre-trained model. The authors demonstrate the effectiveness of the proposed method on various image completion tasks, including inpainting and edges-to-photos.","['Can the authors provide more ablation studies to evaluate the impact of each component of the proposed method?', 'Can the authors clarify the explanation of the autoencoder aggregator and other complex components?', 'What are the potential negative impacts and ethical considerations related to the use of the proposed method in medical imaging?', 'Can the authors provide more details on the architecture of the pre-trained models and how they compare to the baselines?', 'Could the authors elaborate on the choice of hyperparameters and their impact on the results?']","['The paper does not adequately address the limitations and potential negative societal impacts of the proposed method.', 'There is a lack of thorough evaluation of the proposed method through ablation studies.', 'The method relies on the availability of high-quality pretrained models, which may not always be available.']",False,3,3,3,5,4,"['The paper addresses the significant issue of long training times for VAEs by leveraging pre-trained models.', 'The proposed method shows competitive results with GANs while avoiding mode-dropping behavior.', 'The application of the method to Bayesian optimal experimental design in medical imaging is an interesting and potentially impactful use case.']","['The paper lacks sufficient ablation studies to thoroughly evaluate the impact of each component of the proposed method.', 'The explanation of the autoencoder aggregator and some other components is not clear, making the paper difficult to follow.', 'The ethical considerations of the proposed method, especially in the context of medical imaging, are not thoroughly explored.', 'The paper could benefit from more detailed discussions on the limitations and potential negative impacts of the proposed approach.', 'Some important experimental details, such as the exact architecture of the pre-trained models and how they compare to the baselines, are missing.']",4,3,3,4,Reject
vcUmUvQCloe,"The paper introduces joint Shapley values, an extension of the traditional Shapley values to measure the joint contribution of sets of features to a model's predictions. The authors extend Shapley's axioms to sets of features and prove the uniqueness of joint Shapley values. The paper includes theoretical proofs and practical examples to illustrate the utility of the proposed method.","['Can the authors provide more intuitive explanations or visualizations to help understand the mathematical derivations and proofs?', 'How do joint Shapley values compare in computational efficiency with existing interaction indices like the Shapley-Taylor index?', 'Can the authors provide more real-world examples or datasets to validate the practical significance of joint Shapley values?', 'Can the authors provide more details on the computational complexity and how it scales with the number of features?', 'Are there any specific real-world applications where the joint Shapley values have been tested extensively?']","['The computational complexity of joint Shapley values might limit their applicability to large datasets or models with many features. The paper should address this limitation and potentially propose ways to mitigate it.', 'The paper does not discuss potential negative societal impacts, such as misuse in biased or unfair decision-making processes. Although this might not be directly relevant, a brief discussion would be beneficial.']",False,3,3,3,5,4,"['The extension of Shapley values to measure joint feature importance is novel and could provide valuable insights, especially in cases where feature interactions are significant.', 'Theoretical proofs supporting the uniqueness and properties of joint Shapley values are rigorously presented.', 'The practical applications in both game theory and ML attribution problems are well-explained and demonstrate the utility of the proposed method.']","['The clarity of the mathematical formulations and proofs could be improved. Some derivations and notations are hard to follow and might confuse readers unfamiliar with the topic.', 'The paper may not sufficiently differentiate from existing interaction indices like the Shapley-Taylor index, which also measures feature interactions. The practical significance and computational efficiency of joint Shapley values over these existing methods need further elaboration.', 'The experiments, while comprehensive, could benefit from more extensive real-world applications. The chosen datasets are somewhat limited in scope, and additional datasets could provide a more robust validation of the proposed method.', 'The complexity of the proposed method may limit its scalability and practical applicability in larger datasets or more complex models.']",3,3,3,4,Reject
fHeK814NOMO,"The paper proposes an approach to automatically adjust the learning rate during training by treating it as a trainable parameter. The method, called Trainable Learning Rate (TLR), is evaluated on several benchmarks including MNIST, CIFAR10, CIFAR100, and ImageNet, and is compared against state-of-the-art optimizers such as Adam, SLS, and SPS.","['Could the authors provide more detailed explanations of the algorithms, especially the Efficient variant?', 'What are the theoretical guarantees of the proposed method?', 'Could the authors provide more experiments to understand the limitations and potential failure modes of the proposed approach?', 'Can the authors provide a clearer explanation of the second-order gradient derivation?', 'How does the proposed method compare to a wider range of state-of-the-art optimizers?', 'What are the potential limitations or negative societal impacts of the proposed method?', 'How does the method perform on other types of tasks beyond image classification, such as natural language processing?', 'Could you provide more details about the autoencoder aggregator?', 'Have you considered testing different modulation functions and types of aggregators?']","['The paper does not adequately address the limitations and potential failure modes of the proposed approach.', 'Theoretical analysis is limited and does not provide guarantees for the method.', 'The robustness of the method is not fully convincing, especially considering the sensitivity to different hyperparameters and settings.', 'The method does not provide a convergence guarantee for non-convex loss functions.', 'There is a reliance on the second-order gradient, which may be computationally intensive in certain settings.', ""The method may suffer from 'short-horizon bias,' where the learning rate decreases too quickly, leading to suboptimal minima.""]",False,2,2,2,4,4,"['Addresses an important problem in machine learning: automatic adjustment of learning rate during training.', 'Proposes a novel approach to treat the learning rate as a trainable parameter.', 'Evaluated on several benchmarks and compared against state-of-the-art optimizers.', 'Claims robustness to initial learning rate and batch size settings.']","['The clarity of the exposition could be improved, especially in the detailed explanation of the algorithms.', 'The paper lacks a thorough theoretical analysis of the proposed method.', 'Limited range of experiments to understand the limitations and potential failure modes of the proposed approach.', 'The experimental results, while promising, are not significantly better than existing methods to justify the additional complexity.', 'The novelty of the approach is limited, as adaptive learning rates have been explored in prior works.', 'The paper does not adequately explain the practical implications of the proposed method, such as its impact on training time and resource consumption.', 'The robustness of the method is not fully convincing, especially considering the sensitivity to different hyperparameters and settings.']",3,2,2,3,Reject
rqolQhuq6Hs,"The paper introduces a novel theoretical framework for understanding the dynamics of Stochastic Gradient Descent (SGD) by deriving a stochastic differential equation (SDE) with additive noise through a random time change. This leads to a novel escape-rate formula from local minima, which depends on the logarithmized loss barrier height rather than the absolute loss barrier. The work highlights the importance of flat minima with low effective dimensions and provides experimental validation to support the theoretical findings.","['Can the authors provide additional empirical results to further validate the escape rate formula in different settings?', 'Please elaborate on the potential limitations and societal impacts of the proposed framework.', 'Can the authors provide more detailed justifications or numerical validations for the approximations used in the derivations?', 'How do the results generalize to other types of loss functions beyond the mean-square loss and cross-entropy loss?', 'Can the clarity of the experimental setup and the derivation process be improved for better comprehension?', 'Have the authors considered testing the proposed framework on more diverse datasets and architectures to verify its generalization?', 'Can the authors provide additional experimental verification for the isotropic-noise approximation within the n-dimensional subspace?', 'Can the authors provide more practical examples or applications of their theoretical results?', 'How can the proposed framework be integrated into existing machine learning workflows?', 'Can the authors provide additional explanations or diagrams to clarify the derivation of the stochastic differential equation (SDE) with additive noise?', 'How generalizable are the findings to different types of neural networks and loss functions beyond the mean-square loss? Additional experiments on other architectures and datasets would be beneficial.', 'The paper mentions that the relation N ∝ L(θ) holds in more general loss functions. Can the authors provide more detailed experimental verification for this claim, particularly for loss functions other than the mean-square loss?']","['The paper briefly mentions some approximations and their justifications but could provide more detailed discussions.', 'The reliance on approximations and assumptions may limit the generality of the results.', 'Clarity in the presentation of complex mathematical derivations and experimental setups needs improvement.', 'The paper relies on several key approximations that need further validation. The clarity of the presentation could be improved to make the paper more accessible to a broader audience.', 'The technical complexity might limit accessibility and reproducibility. The practical implications and broader applicability are not fully explored.', 'The paper could benefit from explicitly discussing the potential limitations of the assumptions and approximations made in deriving the theoretical results. For instance, how do these assumptions hold up in practical scenarios with different neural network architectures and datasets?']",False,3,3,4,7,4,"['The paper introduces the novel concept of a logarithmized loss landscape.', 'The escape rate formula offers a new perspective on the preference of SGD for flat minima.', 'Theoretical developments are well-supported by both analytical derivations and experimental results.', 'The paper provides a comprehensive examination of the implications of the derived formulas.', 'The introduction of the logarithmic loss landscape and the corresponding SDE with additive noise is novel and provides new insights into SGD dynamics.', 'The paper addresses an important aspect of machine learning by explaining the implicit bias of SGD towards flat minima with low effective dimensions.']","['Some sections are mathematically dense and could benefit from additional explanations.', 'The empirical validation, while adequate, could be more extensive to cover a broader range of scenarios.', 'The paper does not discuss potential limitations or negative societal impacts in detail.', 'The paper relies on several approximations and assumptions, which might limit the generality of the findings.', 'Clarity in the presentation of mathematical derivations and experimental setups could be improved for broader accessibility.', 'Some experimental results, particularly those involving the cross-entropy loss, show less clear proportionality between noise strength and loss.', 'The paper could benefit from more clarity in the presentation, especially in the theoretical sections. Some of the derivations and approximations are not sufficiently explained.', 'The experimental validation, while comprehensive, could include more diverse datasets and architectures to strengthen the generalization of the results.', 'Some assumptions and approximations, such as the isotropic-noise approximation within the n-dimensional subspace, need further experimental verification.']",4,3,3,4,Accept
sBT5nxwt18Q,"The paper introduces Critical Classification Regions (CCRs) to enhance post-hoc, nearest-neighbor explanation-by-example methods in XAI. The proposed CCRs highlight important regions in both test and training images, showing where the model learned specific features. The method is evaluated through computational experiments and a controlled user study, demonstrating its effectiveness in improving user trust in model predictions.","['Can the authors provide more details on the computation of CCRs, particularly for the latent-based methods?', 'How does the proposed method compare with LIME in more detail?', 'What steps can be taken to reduce the computational inefficiencies of the SP-CCR method?', 'Can the authors elaborate on the user study results, specifically the impact of CCRs on user trust and understanding?', 'Could the authors provide more detailed pseudocode or flowcharts to illustrate the algorithm for computing CCRs?', 'Could the authors conduct additional ablation studies to isolate the impact of different components of the method, such as the choice of activation maps or the size of the CCRs?']","['The paper should include a more detailed comparison with existing methods like LIME to strengthen the evaluation.', 'Computational inefficiencies need to be addressed, particularly for the SP-CCR method.', 'The user study results should be more thoroughly discussed to clarify their implications.', 'The main limitation is the lack of clarity in the algorithm description, which makes it difficult to reproduce the results.']",False,2,2,3,4,4,"['Addresses an important problem in XAI by improving nearest-neighbor explanations.', 'Introduces a novel concept of Critical Classification Regions (CCRs).', 'Conducts comprehensive experiments, including both computational and user studies.', 'Demonstrates practical applicability with a user-friendly Python library.']","['Some methodological details are unclear, particularly in the computation of CCRs.', 'Limited comparison with other existing methods like LIME.', 'Potential computational inefficiencies, especially with the SP-CCR method.', 'User study results are somewhat ambiguous and need further elaboration.', 'Insufficient ablation studies to understand the contribution of each component of the proposed method.']",3,3,2,3,Reject
49A1Y6tRhaq,The paper 'LINKING EMERGENT AND NATURAL LANGUAGES VIA CORPUS TRANSFER' aims to bridge emergent languages from communication games with natural languages. It proposes a novel corpus transfer approach to pre-train models on emergent language corpora for downstream natural language tasks like language modeling and image captioning. The paper also introduces a new metric to evaluate emergent languages based on translation to natural language captions.,"['Can the authors provide more details on the autoencoder aggregator used in the methodology?', 'How does changing the type of aggregator or modulation function affect the performance of the proposed method?', 'Can the authors provide additional qualitative examples to support their claims?', 'Can the authors provide more detailed explanations of the technical components, including the architecture and training process of the emergent communication game?', 'How does the proposed approach compare with other state-of-the-art methods in terms of computational efficiency and scalability?', 'Can the authors provide more ablation studies to isolate the effects of different components, such as the impact of different pre-training corpus sizes and the influence of the new metric on transferability?', 'Can the authors provide more detailed explanations of the hyperparameters and experimental setup?', 'How does the proposed method compare with a broader range of baselines, particularly in the image captioning task?', 'Can the authors provide more detailed ablation studies to justify the choices made in the system design?', 'Have you tested the robustness of the proposed metric across different emergent communication setups?', 'How generalizable are the findings to other emergent communication frameworks or tasks?']","[""The paper needs more clarity in its methodology, particularly about the autoencoder aggregator. Additionally, further ablation studies could strengthen the paper's claims."", 'Potential negative societal impacts are not discussed, which should be considered given the potential applications of this research.', 'The paper lacks clarity in crucial parts, which makes it hard to fully assess the robustness of the results.', 'The paper does not discuss potential negative societal impacts or ethical considerations related to the use of emergent languages. Also, the limitations regarding the scalability and generalizability of the proposed method are not adequately addressed.', 'The paper should include more details about the hyperparameter tuning process and explore the robustness of the proposed metric across different setups and tasks.']",False,3,2,3,5,4,"['The paper addresses an important problem of linking emergent languages with natural languages, which has been a gap in the field.', 'The proposed corpus transfer approach is novel and showcases significant benefits in low-resource settings for tasks like language modeling and image captioning.', 'The introduction of a new metric for evaluating emergent languages based on their translation to natural language captions is a valuable contribution.', 'The paper provides comprehensive experiments, including comparisons with other corpora, ablation studies, and qualitative analyses.']","['The paper could benefit from additional ablation studies, such as varying the types of aggregators or exploring different modulation functions in the emergent communication game.', 'The methodology section could be clearer, especially regarding the details of the autoencoder aggregator.', 'The qualitative analysis, while useful, would be more convincing if more cases were provided.', 'The novelty of the approach might be questioned as it builds on existing techniques of corpus transfer and emergent communication but does not introduce fundamentally new concepts.', 'The experimental setup, while extensive, could benefit from more detailed ablation studies to isolate the effects of different components of the proposed approach.', 'The paper lacks clarity in several sections, making it difficult to follow the proposed methodology and experimental setup.', 'The reproducibility of the results is questionable due to the insufficient implementation details provided.']",3,3,2,4,Reject
9W2KnHqm_xN,"The paper proposes a SpatioTemporal aware Embedding framework (STEP) inspired by the entorhinal-hippocampal system in the mammalian brain, aimed at improving successive Points of Interest (POI) recommendation. The framework integrates spatiotemporal context graphs to capture spatial and temporal dependencies and demonstrates state-of-the-art performance on two benchmark datasets.","['Could the authors provide more details on the grid-cell encoder and its implementation?', 'What are the impacts of different hyperparameters on the performance of the proposed model?', 'Can the authors provide more detailed ablation studies to isolate the contributions of each component of the framework?', 'Can you provide more detailed explanations about the construction of the spatiotemporal context graph and the specific embedding learning process?', 'How does your method compare with other recent advanced spatiotemporal embedding techniques in terms of novelty and effectiveness?', 'What are the potential limitations and societal impacts of your proposed method?', 'Can you provide more details on the neural network architectures and training procedures?', 'How does the method scale with larger datasets?', 'Can you include more detailed ablation studies to highlight the contributions of different components of the model?', 'Can the authors provide more detailed explanations of the loss functions used in the spatiotemporal model?', 'How do the hyperparameters influence the performance of the proposed method, and what were the exact settings used for the experiments?', 'Can the authors discuss the scalability of the proposed method in larger datasets or real-world applications?', 'Can the authors provide more detailed descriptions of the spatiotemporal model and context graph construction, including the mathematical formulations and algorithms used?', 'How does the proposed method perform on additional datasets or other spatiotemporal tasks beyond POI recommendation and traffic flow prediction?', 'Can the authors compare their method with more recent state-of-the-art spatiotemporal recommendation methods?']","['The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the proposed method. For instance, the scalability of the model is not addressed, nor are the potential ethical issues related to spatiotemporal data usage.']",False,2,2,2,3,4,"['The biological inspiration for embedding space representation is unique and intriguing.', 'The proposed method shows promising results, outperforming several baselines on benchmark datasets.', 'The spatiotemporal context graph construction is a novel approach to capture both spatial and temporal dependencies jointly.', 'The method avoids using private user data, addressing privacy concerns.']","['The clarity of the methodology section is a major concern, making it difficult to follow the exact steps and implementations of the proposed framework.', 'The evaluation lacks robustness, with limited datasets and no thorough ablation studies.', 'The novelty of the proposed method compared to other advanced spatiotemporal embedding techniques is not clearly illustrated.', 'The paper does not adequately discuss the limitations of the proposed approach or potential negative societal impacts.', 'No insights into computational complexity or scalability, crucial for real-world applications.']",3,2,2,3,Reject
p98WJxUC3Ca,The paper proposes a discrepancy-based active learning strategy for domain adaptation using a localized discrepancy distance. It builds on the concept of discrepancy distance to restrict the maximization over the hypothesis class to a localized class of functions performing accurate labeling on the source domain. The authors derive generalization error bounds and propose a practical K-medoids algorithm that scales to large datasets. Experimental results show that the proposed algorithm performs competitively against other state-of-the-art active learning techniques.,"['Can the authors provide more detailed ablation studies, including the impact of different modulation functions and types of aggregators?', 'Could you clarify the implementation and role of the autoencoder aggregator in the method?', 'Can you provide additional qualitative examples to support your claims about the effectiveness of the proposed method?', 'Can you provide more detailed derivations of the theoretical bounds?', 'Could you elaborate on the implementation details of the accelerated K-medoids algorithm?', 'How does the proposed method scale to datasets larger than those tested in the experiments?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How robust are the results to violations of the Lipschitz assumption or variations in the loss function?', 'Can the authors include more diverse datasets and additional baselines in their experiments to strengthen the empirical validation?']","['The paper should include more comprehensive ablation studies to evaluate the importance of different components.', 'The autoencoder aggregator needs a clearer and more detailed description.', 'The assumptions made for the theoretical results might not hold in more general settings, which could limit the applicability of the proposed bounds.', 'The empirical validation, while promising, could benefit from more diverse datasets and additional baselines.', 'The paper does not thoroughly discuss the potential limitations and negative societal impacts of the proposed method. It would be beneficial to include a section addressing these aspects.']",False,3,3,3,6,4,"['The paper addresses a significant issue in active learning: domain adaptation under domain shift.', 'The theoretical framework of localized discrepancy is novel and provides tighter bounds for the target risk.', 'The proposed K-medoids algorithm is practical and scales well to large datasets.', 'Comprehensive experiments, including comparisons to state-of-the-art methods, demonstrate the effectiveness of the approach.']","['The paper lacks detailed ablation studies to investigate the impact of different components and parameters of the proposed method.', 'The description of the autoencoder aggregator is unclear and needs more detail.', 'The qualitative analysis provided in figures is limited, and additional cases would strengthen the paper.', 'Some parts of the paper, especially the theoretical sections, are dense and hard to follow, which affects the overall clarity.', 'Details about the implementation of the accelerated K-medoids algorithm are insufficient, which could hinder reproducibility.', 'The scalability of the proposed method to extremely large datasets (larger than those tested) is not thoroughly discussed.', 'Potential limitations and negative societal impacts of the proposed method are not adequately addressed.']",3,3,3,4,Reject
Gx6Tvlm-hWW,"The paper proposes a new method for conformal prediction that aims to limit the number of false positives in the prediction sets. This is achieved by calibrating a threshold on a set function, trained via DeepSets, that estimates the number of false positives in a candidate set. The method is evaluated on tasks including drug discovery, object detection, and entity extraction, demonstrating its effectiveness in reducing false positives while maintaining high true positive rates.","['Can the authors provide more details on the training process for the DeepSets model? Specifically, how were the hyper-parameters chosen, and what were the convergence criteria?', 'How does the computational complexity of the proposed method compare to existing methods? Are there specific scenarios where the method may become infeasible due to high computational cost?', 'Can the authors provide a more detailed comparison with the baselines, ensuring that all methods were tuned to the same extent and evaluated under comparable conditions?', 'What is the impact of the maximum number of considered labels (B) on the performance of the method? Can the authors provide a sensitivity analysis to justify the choice of B?', 'Can the authors provide more details on the choice of neural network architectures used for the set function F?', 'What is the impact of different hyperparameters on the performance of the proposed method?', 'Can the authors provide more ablation studies to show the importance of different components of their method?', 'How does the method generalize to other domains beyond the ones tested?', 'Can the authors discuss the practical considerations for choosing k in more detail?']","['The paper should discuss the potential computational complexity and practical limitations of the proposed method in more detail.', 'The explanation of the training process for the DeepSets model needs to be more comprehensive.', 'The choice of baselines and the fairness of comparisons should be elaborated upon.', ""The method's dependence on the accurate estimation of the set function and the choice of k may limit its applicability in some domains. Additionally, the greedy selection strategy for the output set may not always be optimal.""]",False,3,3,3,7,4,"['Addresses a significant practical challenge in conformal prediction by controlling the number of false positives.', 'Theoretical contributions are well-founded, providing rigorous false positive control.', 'The approach is evaluated across diverse and significant applications, including drug discovery and object detection.', 'The use of DeepSets to model false positives in sets is innovative and leverages recent advances in set-based neural networks.', 'Comprehensive experiments across multiple domains demonstrate the effectiveness of the approach.']","['The computational complexity of the proposed method, especially with the nested set constructions, may be high. This could limit its practicality for large-scale applications.', ""The training process for the DeepSets model and its integration with the overall framework is not entirely clear. More details are needed on the training procedure, hyper-parameter choices, and the model's convergence."", 'Comparisons with baselines may not be entirely fair. For example, it is unclear if all methods were tuned to the same extent or if simpler methods were given the same level of attention.', 'The explanation of certain methodological steps, such as the choice of the maximum number of considered labels (B) and its impact on performance, is somewhat lacking. Further justification and sensitivity analysis would be valuable.', 'The paper could benefit from additional ablation studies to explore the impact of different components and hyperparameters.', 'The clarity of some sections, especially the theoretical proofs, could be improved for better readability.']",4,3,3,4,Accept
lu_DAxnWsh,The paper proposes a method to improve the performance of neural networks on System 2 tasks by using intermediate steps. The authors argue that neural networks struggle with tasks that require multi-step reasoning and show that guiding the training process through intermediate computations can help. They demonstrate this with a 1-layer 1-head Transformer on binary addition tasks and show that the network can learn the task if intermediate steps are provided.,"['Can the proposed approach be generalized to more complex tasks beyond binary addition?', 'Are there alternative architectures or methods that could handle System 2 tasks without strong supervision?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'Can the authors provide more detailed explanations for the autoencoder aggregator and the role of the intermediate steps?', 'How does the approach compare with existing methods like Neural Turing Machines and Universal Transformers?', 'Can the authors provide more examples of complex tasks where their approach is beneficial?', 'How does the approach scale with more complex tasks and larger datasets?', 'Can the theoretical exposition be simplified or clarified further for better understanding?']","['The generalizability of the findings to more complex tasks needs further exploration.', 'Potential limitations and negative societal impacts are not thoroughly discussed.', 'The scalability of the approach to more complex tasks and larger datasets is not thoroughly explored.', 'The theoretical exposition, while thorough, is quite dense and may benefit from additional clarification or simplification.']",False,3,3,3,5,4,"['Addresses an important problem of extending neural network capabilities to System 2 tasks.', 'Provides a theoretical foundation showing that a 1-layer 1-head Transformer can compute any finite function with enough intermediate steps.', 'Empirical results support the hypothesis, demonstrating that a Transformer can learn binary addition only with strong supervision.', 'Includes comprehensive experiments and analyses, including visualizations of attention patterns and comparisons of different supervision regimes.']","['Focuses primarily on a simple task (binary addition), which may limit the generalizability of the findings.', 'Lacks exploration of alternative architectures or methods that could potentially handle System 2 tasks without strong supervision.', 'Could benefit from more detailed discussions on potential limitations and negative societal impacts.', 'Clarity of some sections, particularly the theoretical proof, could be improved.']",3,3,3,3,Reject
HfUyCRBeQc,"The paper introduces selective ensembles, a method to mitigate prediction and feature attribution inconsistencies in machine learning models by using hypothesis testing to determine when to abstain from making a prediction. The method aims to provide probabilistic guarantees on prediction consistency across different runs and is validated both theoretically and empirically across multiple datasets.","['Can you provide more details about the autoencoder aggregator and its role?', 'How does the modulation function impact the results, and could it be simplified?', 'Can the authors provide more practical guidelines and examples for deploying selective ensembles in real-world scenarios?', 'Can the authors discuss the potential negative societal impacts of abstention in high-stakes decisions in more detail?', 'How does the method perform in scenarios with highly imbalanced datasets or different types of noise?', 'Can the authors provide additional ablation studies to explore the impact of different parameters on the performance of selective ensembles?', 'Are there any practical limitations to the approach that should be considered when applying it in real-world scenarios?', 'How does the method perform on larger-scale and more diverse datasets beyond the ones evaluated in the paper?', 'How does the performance of selective ensembles vary with different values of α and ensemble sizes in more diverse datasets?', 'Can the method be effectively scaled and implemented in real-time applications where computational resources are limited?', 'How would selective ensembles perform in tasks beyond classification, such as regression or multi-label classification?', 'Can you provide more details on the choice of hypothesis testing methods and their impact on the performance of selective ensembles?', 'How does the computational overhead of training and using selective ensembles compare to standard ensembling methods?', 'Can you discuss the practical implications of deploying selective ensembles in real-world applications, particularly in terms of computational resources and latency?']","['The paper could benefit from additional ablation studies to explore the impact of different components and further clarify certain sections.', ""The method's practical implications and limitations are not deeply discussed."", 'Potential negative societal impacts of abstention in high-stakes decisions are not fully addressed.', 'The limitations regarding the dependency on ensemble size and abstention threshold should be more explicitly discussed.', 'The computational overhead and practical deployment aspects of selective ensembles are not thoroughly discussed.']",False,3,3,3,7,4,"['Addresses a significant issue in model predictions and feature attributions, especially in high-stakes applications.', 'Novel application of hypothesis testing to ensembling with theoretical guarantees for consistency.', ""Comprehensive experiments demonstrating the method's effectiveness across multiple datasets."", 'Theoretical proofs supporting the claims.']","['Additional ablation studies are needed to explore the impact of different components and parameters.', 'Some sections, particularly the autoencoder aggregator and modulation function, lack clarity.', 'The paper is dense and could benefit from clearer summarization and visualization of experimental results.', 'The practical guidelines for deploying selective ensembles in real-world scenarios are limited.', 'Potential negative societal impacts of abstention in high-stakes decisions are not fully addressed.']",3,3,3,4,Accept
8e2vrVvvaeQ,"The paper investigates the underlying principles behind the success of indiscriminate data poisoning attacks, suggesting that linear separability of perturbations is a key factor. It demonstrates this through empirical analysis and synthetic perturbations. The paper also proposes using pre-trained feature extractors as a defense mechanism against these attacks.","['Can the authors provide more detailed comparisons with related work that has explored the importance of linear features in adversarial attacks?', 'What are the broader implications of the findings for future attack and defense strategies?', 'Could the synthetic data generation method be extended or improved to explore other dimensions of data poisoning attacks?', 'Can you provide more details on how the synthetic data is generated and how it compares computationally to the advanced attacks?', 'How generalizable are your findings across different types of models and datasets beyond those tested in the paper?', 'Can you test your proposed defense mechanism against white-box attacks to validate its robustness in more adversarial settings?', 'Can the authors provide more theoretical support for the claim that linear separability is the key factor for the success of indiscriminate poisoning attacks?', 'How applicable is the synthetic data generation method in real-world scenarios?', 'Can the authors provide more detailed comparisons with existing methods and further validate the proposed defense mechanism?']","['The paper does not sufficiently explore the broader implications of the findings.', 'The proposed defense mechanism using pre-trained models lacks novelty.', 'The applicability of the synthetic data generation method in real-world scenarios is questionable.', 'The proposed defense mechanism needs further validation and exploration.', 'The main limitation of the work is the lack of thorough testing under white-box attack scenarios, which could potentially compromise the effectiveness of the proposed defense mechanism.', 'The clarity of the explanation of methodologies, particularly around synthetic perturbation generation, needs improvement.', 'More ablation studies and rigorous testing under varying conditions are needed to validate the robustness and generalizability of the findings.']",False,2,2,3,4,4,"['The paper addresses an important and timely issue in the field of machine learning security.', 'The empirical analysis linking linear separability to the success of poisoning attacks is novel and provides valuable insights.', 'The proposed defense mechanism of using pre-trained feature extractors is a practical approach.']","['The novelty of the main contribution is limited. The importance of linear features in adversarial attacks has been explored in prior work.', 'The synthetic data generation approach, while validating the hypothesis, does not delve deeply into broader implications or new countermeasures.', 'The clarity of the presentation could be improved. Some sections are densely technical and challenging to follow.', 'The proposed defense mechanism using pre-trained models lacks novelty and has not been tested against white-box attacks.', 'The claim of linear separability lacks comprehensive theoretical support.', 'Comparative analysis with existing methods is limited and lacks depth.']",3,2,2,3,Reject
O476oWmiNNp,"The paper addresses the problem of oversmoothing in deep Vision Transformers (ViTs) by analyzing it through the Fourier domain. It introduces two techniques, AttnScale and FeatScale, to reweight the low-pass and high-pass components of the attention and feature maps, respectively. These techniques are shown to mitigate the oversmoothing issue and improve the performance of ViTs.","['Can the authors provide more detailed ablation studies to explore the impact of different components of AttnScale and FeatScale?', 'Can the methodology be further simplified or clarified, especially the steps involving the decomposition and reweighting of Fourier components?', 'Can the authors provide more details on the theoretical derivations, especially the proofs, to improve clarity and understanding?', 'What are the potential limitations or failure cases of AttnScale and FeatScale?']","['The paper could benefit from additional ablation studies and clearer explanations of some methodological steps.', 'The paper should address the theoretical gaps and assumptions more clearly to strengthen the validity of the proposed methods.', 'More comprehensive ablation studies are needed to fully understand the contributions of different components.', 'The paper should address the clarity of the theoretical sections and provide more comprehensive experiments to validate the proposed techniques.']",False,3,3,3,6,4,"['Original approach using Fourier domain analysis to address the oversmoothing problem in deep ViTs.', 'Comprehensive theoretical analysis and empirical validation.', 'Proposed techniques are efficient and can be easily integrated into existing ViT architectures.', 'Significant performance improvements demonstrated across multiple ViT variants.']","['Additional ablation studies could enhance the understanding of the impact of different components of the proposed methods.', 'Some parts of the methodology are complex and could be better explained for clarity.', 'Theoretical justifications have some gaps and assumptions that are not clearly addressed.', 'The paper lacks clarity in some sections, making it difficult to follow the theoretical arguments and the implementation details of the proposed methods.', 'The empirical evaluation is somewhat limited, with modest performance gains and a lack of diversity in benchmarks and ablation studies.']",3,3,3,4,Reject
JLbXkHkLCG6,"The paper presents two novel methods, Pixel Sinkhorn Imitation Learning (P-SIL) and Pixel Discriminator Actor Critic (P-DAC), for imitation learning from visual data in continuous control tasks. These methods use representations from RL encoders to compute imitation rewards, enabling agents to achieve expert-level performance on tasks in the DeepMind control suite. The paper includes extensive experiments and ablation studies to evaluate the effectiveness of the proposed methods.","['Can the authors provide more details on the implementation of P-SIL and P-DAC, particularly the training process and hyperparameters?', 'How do the proposed methods compare with other state-of-the-art methods in imitation learning from visual data?', 'What are the potential limitations and ethical concerns of the proposed methods?', 'Can the authors provide more details on the autoencoder aggregator used in their methods?', 'Can the authors conduct additional ablation studies on the modulation function and different types of aggregators?']","['The paper does not thoroughly address the potential limitations and ethical concerns of the proposed methods. It would be helpful to discuss these aspects in more detail to provide a balanced evaluation.', 'The clarity of the paper could be improved, particularly in explaining the autoencoder aggregator and including more ablation studies on the modulation function and aggregators.']",False,3,2,3,5,4,"['Addresses an important and challenging problem in imitation learning from visual data for continuous control tasks.', 'The proposed methods, P-SIL and P-DAC, are novel and well-motivated.', 'The paper includes extensive experiments and ablation studies, providing a comprehensive evaluation of the methods.', 'The authors provide an easy-to-use implementation, promoting reproducibility and further research in the area.']","['The explanations of the implementation details for the proposed methods could be clearer.', 'The paper lacks comparisons with other state-of-the-art methods in imitation learning from visual data.', 'There is limited discussion on the potential limitations and ethical concerns related to the proposed methods.', 'Some sections, particularly on experimental setup and hyperparameters, lack clarity.', 'Evaluation metrics are limited primarily to episodic return and Wasserstein distance.']",3,3,2,3,Reject
UTTrevGchy,"The paper proposes the InfoMax Termination Critic (IMTC) algorithm to autonomously learn diverse and reusable temporally extended actions, known as options, in reinforcement learning. The core idea is to maximize mutual information (MI) between options and state transitions to enhance the diversity of options, making them more reusable. The algorithm derives a scalable approximation to optimize termination conditions of options using gradient ascent. The paper demonstrates through experiments that IMTC improves the diversity of learned options and their reusability in various tasks.","['Can the authors provide more details on the implementation of the autoencoder aggregator?', 'What is the impact of different modulation functions on the performance of the proposed method?', 'Can the authors provide additional visualizations of the learned options for more diverse cases?', 'Can the authors provide more details about the replay buffer and how it affects the learning process?', 'Could the authors conduct additional ablation studies to investigate the impact of different modulation functions or types of aggregators?', 'Can the authors provide more qualitative examples and visualizations to better demonstrate the learned options?', 'Can the authors provide more detailed explanations and visualizations of the theoretical derivations to improve clarity?', 'How does IMTC compare with more recent state-of-the-art methods in option discovery and reinforcement learning?', 'What are the potential limitations of IMTC, and how might it impact society negatively?', 'Please provide more detailed explanations of the autoencoder aggregator and the practical implementation of the algorithm.', 'Can you provide additional cases or examples in Figure 3 to enhance the analysis?', 'Can you further explore or justify the assumption that the empirical distribution of options is independent of termination conditions?']","['The paper does not adequately discuss the limitations of the proposed method. For example, the reliance on mutual information maximization might lead to learning options that are diverse but not necessarily useful for specific tasks.', 'Potential negative societal impacts of the work are not addressed. For example, the use of reinforcement learning in critical applications without proper safeguards could lead to unintended consequences.', ""The paper's complexity and lack of clarity in some sections make it difficult to follow and understand fully. Additional ablation studies and qualitative analyses would help to strengthen the paper's contributions."", 'The main limitations are the need for more detailed explanations of certain aspects and the further exploration or justification of certain assumptions.']",False,3,2,3,5,4,"['Innovative Approach: The use of mutual information maximization for learning diverse options is a novel and interesting approach.', 'Scalable Solution: The proposed method derives a scalable approximation for mutual information maximization, making it practical for complex domains.', 'Comprehensive Experiments: The paper provides extensive experiments demonstrating the effectiveness of IMTC in different scenarios, including reward-free settings and task adaptation.', 'The problem of learning diverse and reusable options in reinforcement learning is well-motivated and relevant.', 'The practical implementation details, including the use of PPO and advantage estimation methods, are clearly described.', 'The paper provides detailed implementation details and supplementary materials, which enhance reproducibility.']","['Clarity: The paper is difficult to follow in several sections, particularly in the derivation of gradients and the explanation of the implementation details. More clarity and better organization would significantly improve readability.', 'Ablation Studies: While the paper includes some ablation studies, it would benefit from more comprehensive investigations, such as the impact of different components and hyperparameters on performance.', 'Limitations and Negative Societal Impact: The paper does not adequately discuss the limitations of the proposed method and its potential negative societal impacts. A more thorough discussion would be beneficial.', 'The paper makes strong claims about the reusability and diversity of options learned by IMTC without sufficient empirical evidence across a broader range of tasks and environments.']",3,3,2,3,Reject
CgV7NVOgDJZ,"The paper presents Guided-TTS, a TTS system that uses untranscribed speech data by employing an unconditional diffusion probabilistic model guided by a phoneme classifier. This method allows utilizing large amounts of untranscribed speech data, which is often more readily available, and achieves competitive performance compared to existing TTS models that require paired data.","['Can the authors provide more details on the architecture and training process of the phoneme classifier and duration predictor?', 'What is the performance impact of different components of the proposed method? More ablation studies would be helpful.', 'Have the authors considered comparing their method with more recent and diverse TTS models?', ""Can the authors provide additional experiments to demonstrate the method's robustness and generalizability to different languages and datasets?"", 'Can the authors provide more details on the norm-based guidance method and its impact on the generated speech quality?', 'How does the model perform with different architectures for the phoneme classifier and duration predictor?', 'What are the potential limitations of the proposed approach, and how can they be mitigated?', 'How do the authors address the potential ethical concerns related to the misuse of TTS technology, particularly when dealing with untranscribed data?']","['The paper should include more detailed explanations of the phoneme classifier and duration predictor components.', 'Further ablation studies and comparisons with more baselines are needed to strengthen the findings.', ""The method's robustness and generalizability to different languages and datasets should be explored."", 'The authors should discuss potential limitations such as the dependency on a large multi-speaker dataset for training the phoneme classifier and the impact of errors in the phoneme classifier on the generated speech quality.', 'The ethical implications of using untranscribed speech data, especially in terms of privacy and data ownership, should be addressed.']",True,3,3,4,6,4,"['The paper addresses a significant practical issue in TTS by proposing a method to utilize untranscribed speech data.', 'The use of an unconditional diffusion probabilistic model guided by a phoneme classifier is a novel approach.', 'The experimental results demonstrate that the proposed method achieves competitive performance with existing TTS models.', 'Comprehensive experiments, including MOS and ASR metrics, validate the effectiveness of the proposed method.']","['The explanation of some components, such as the phoneme classifier and duration predictor, lacks detail. More information on their architecture and training process is needed.', 'Further ablation studies are required to evaluate the impact of different components of the proposed method.', 'The comparison with baselines could be extended to include more recent and diverse TTS models.', ""The method's robustness and generalizability to different languages and datasets should be explored further."", ""The paper's clarity can be improved, particularly in the explanation of the norm-based guidance and the training process for the phoneme classifier and duration predictor."", 'The ethical considerations are not adequately addressed, especially concerning the potential misuse of TTS technology.']",4,3,3,4,Reject
o_HsiMPYh_x,"The paper proposes Average Thresholded Confidence (ATC), a method to estimate model accuracy on out-of-distribution (OOD) data using unlabeled data from the target domain. The method learns a threshold on the model’s confidence scores using source validation data and applies it to the target domain. The paper evaluates ATC across various datasets and architectures, demonstrating its effectiveness compared to existing methods.","['Please provide more detailed experiments and discussions on scenarios where ATC fails to estimate the target accuracy accurately.', 'Investigate alternative methods to calibration that might be more robust or feasible in different settings.', 'Conduct more thorough ablation studies to better understand the contributions of each component of the method.', 'Can the authors provide more details on the threshold selection process and its implementation?', ""Could additional ablation studies be conducted to analyze the impact of different score functions and temperature scaling on ATC's performance?"", 'What are the specific limitations and failure cases of ATC beyond the toy model illustration?', 'Can you provide more detailed explanations for the theoretical proofs and the implementation details of the baselines?', 'How does the method perform on datasets with novel populations, and are there any potential ways to improve its performance in these cases?', 'Can the authors provide more details on the autoencoder aggregator and its role in the method?', 'How does the method perform with different thresholding strategies or score functions?', 'Can the authors provide more statistical analysis of the results, such as confidence intervals or hypothesis testing?']","['The method may fail on certain types of distribution shifts, and the paper lacks detailed analysis and experiments on these failure cases.', 'The reliance on post-hoc calibration may not always be feasible or reliable in practice.', 'The assumption that the same threshold works well across different types of shifts might not hold universally. More discussion on the limitations and the conditions under which this assumption holds would be beneficial.', 'The paper does not fully address the theoretical justification for some aspects of the method.', 'There are still large estimation errors on datasets with novel populations.', 'The reliance on confidence scores may not always generalize well to different model architectures or datasets.']",False,3,3,3,7,4,"['Addresses a significant and practical problem in machine learning.', 'Introduces a novel method leveraging confidence scores to estimate accuracy on OOD data.', 'Comprehensive evaluation across multiple datasets and types of distribution shifts.', 'Provides theoretical foundations and insights into the problem.', 'Well-written and clearly structured.']","['Limited analysis on failure cases where ATC might not work.', 'Dependency on post-hoc calibration, which may not always be feasible or reliable.', 'Assumption that the same threshold works well across different types of shifts might not be universally valid.', 'Lack of ablation studies to isolate the contributions of different components of the method.', 'Some theoretical aspects could be more rigorously justified.', 'The paper could benefit from more detailed explanations in some sections, especially the theoretical proofs and the implementation details of the baselines.', 'Results are reported with standard deviations, but more statistical analysis could strengthen the claims.']",3,3,3,4,Accept
LhObGCkxj4,"The paper introduces a new theoretical framework for global convergence in finite-sum optimization, specifically addressing the training of deep neural networks (DNNs). The approach involves a novel composite formulation and algorithmic framework, supported by bounded style assumptions. The theoretical contributions include convergence proofs and complexity bounds.","['Can the authors provide any initial empirical results or practical implementation details?', 'How do the assumptions made in the paper translate to practical scenarios in deep learning?', 'How do the non-standard bounded style assumptions compare to more traditional assumptions in machine learning?', 'Can the authors clarify the practical implications of their theoretical results?', 'Can the authors provide more intuitive explanations or visualizations to clarify the complex mathematical derivations presented in the paper?']","['The major limitation is the lack of empirical validation, which makes it difficult to assess the practical impact of the proposed methods.', 'Additionally, the assumptions made in the theoretical analysis may not always hold in real-world scenarios, and the paper does not discuss the potential implications if these assumptions are violated.']",False,2,2,2,3,4,"['Novel composite formulation for analyzing machine learning minimization problems.', 'New algorithmic framework with two methods for approximating solutions.', 'Strong theoretical contributions, including convergence proofs and complexity bounds.', 'Addresses a significant problem in the optimization of deep neural networks, particularly the challenge of non-convex loss surfaces.']","['Lack of empirical validation and practical implementation details.', 'No experimental results to demonstrate the effectiveness of the proposed methods.', 'The assumptions made, such as bounded style assumptions, may not always be practical.', 'The presentation is dense and difficult to follow, particularly in the sections on the theoretical framework and assumptions.']",3,2,2,3,Reject
0SiVrAfIxOe,"The paper presents a novel approach for optimizing the control of additive manufacturing processes using reinforcement learning. The authors propose a custom numerical model that simulates the deposition process qualitatively, allowing for efficient training of control policies in simulation. These policies are then transferred to physical hardware with minimal sim-to-real gaps. The approach shows significant improvements over baseline controllers in both simulated and physical environments.","['Can the authors provide more detailed explanations of the methodology, particularly the custom numerical model?', 'What are the statistical significances of the ablation studies provided?', 'How generalizable is the proposed approach to other types of additive manufacturing processes or materials?', 'Can the authors expand on the related work to better contextualize their contributions?', 'Please provide more details on the autoencoder aggregator.', 'Can you include additional ablation studies with different modulation functions and types of aggregators?', 'Can you provide more case studies in the qualitative analysis?', 'How were the specific hyperparameters chosen for the RL algorithm, and what impact do they have on the performance?', 'Can the authors include more qualitative analysis to better illustrate the improvements brought by the proposed method?', 'How does the proposed method compare with other reinforcement learning approaches for similar control tasks?', 'What are the potential limitations of the approach when scaling to more complex deposition processes or different materials?']","['The generalizability of the proposed model to other types of additive manufacturing processes or materials is not clear.', 'Statistical significance of the ablation studies is not discussed, which is crucial for validating the results.', 'The clarity of the explanation of the numerical model and the data-driven noise distribution needs improvement.', 'The choice of hyperparameters and their impact on the performance are not thoroughly discussed.', 'Potential negative societal impacts, such as the environmental footprint of the additional hardware required for in-situ monitoring, should be addressed.']",False,3,2,3,5,4,"['Addresses a critical challenge in additive manufacturing by proposing a closed-loop control system.', 'Novel use of reinforcement learning with a custom numerical model for sim-to-real transfer.', 'Extensive empirical validation, including comparisons with baseline controllers and ablation studies.', 'Potential for significant practical applications in manufacturing industries.']","['The methodology section lacks clarity and could benefit from more detailed explanations.', 'Ablation studies are provided, but their statistical significance and detailed results are not thoroughly discussed.', 'Potential limitations regarding the generalizability to other types of additive manufacturing processes or materials are not adequately addressed.', 'The paper could benefit from a more thorough discussion of related work to better contextualize its contributions.', 'The choice of specific hyperparameters and their justification in the context of the RL algorithm are not thoroughly discussed.', 'The presentation could be more organized to enhance the readability of the paper.']",3,3,3,4,Reject
Fza94Y8VS4a,"The paper investigates the evolution of uncertainty in learning-in-games systems using differential entropy. It demonstrates that differential entropy increases linearly with time in various game settings, including MWU and OMWU in zero-sum and coordination games. The paper provides rigorous theoretical proofs and applies the framework to multiple game settings.","['Could you provide more step-by-step explanations for the key mathematical derivations to improve clarity?', 'Are there any plans to conduct more extensive empirical validations of the theoretical findings?', 'How do you envision these theoretical insights being applied in real-world ML systems? What practical changes might be necessary?', 'Can the authors provide more intuitive explanations or visual aids to help readers understand the key concepts and results?', 'Have the authors considered additional game settings or learning algorithms in their empirical analysis to further validate their theoretical findings?']","['The paper could benefit from clearer explanations of the mathematical derivations and more extensive experimental validation. Additionally, discussing the practical implications of the findings would be beneficial.', 'The empirical simulations are somewhat limited in scope and could benefit from additional experiments.', 'The results are derived under specific assumptions that may not hold in all real-world scenarios.']",False,3,3,3,6,4,"['The paper introduces a novel perspective by analyzing uncertainty in learning-in-games via a distribution over initial conditions rather than individual trajectories.', 'It applies the framework to multiple scenarios, demonstrating its robustness and broad applicability.', 'The paper provides rigorous proofs and leverages differential entropy to quantify uncertainty, which is a significant theoretical contribution.', 'The connection to volume analysis and Lyapunov chaos is insightful and enhances the understanding of the results.']","['The paper is mathematically dense and may be challenging to follow for readers not deeply familiar with the topic. Some sections could benefit from additional explanations and step-by-step derivations.', 'The paper lacks extensive experimental validation. While it provides some simulations, more empirical results would strengthen the claims.', 'The practical implications of the findings are not fully explored. It would be beneficial to discuss how these insights could be applied to real-world ML systems and what changes might be necessary for practical use.', 'The presentation could be improved by providing more intuitive explanations and visual aids to help readers grasp the key concepts.']",4,3,3,4,Reject
aYAA-XHKyk,"The paper introduces the Regrouping CPE (ReCPE) method for class-prior estimation in positive-unlabeled (PU) learning. The method aims to address the issue with existing methods that rely on the irreducibility assumption, which is often violated in practice. ReCPE constructs an auxiliary probability distribution to ensure the assumption is always valid, improving the estimation accuracy of class-prior. The paper provides theoretical analysis and empirical results on both synthetic and real-world datasets to validate the effectiveness of the proposed method.","['Could you provide more details on the selection process for the hyper-parameter p and its impact on different datasets?', 'Can you include more ablation studies to validate the robustness of the proposed method under various scenarios?', 'Could the authors clarify and elaborate on the practical implementation steps for ReCPE in more detail?', 'Can the authors provide more discussion on how to choose the hyper-parameter p and its robustness?', 'Can the authors clarify the practical scalability of the method, especially for large datasets?', 'Can the authors provide additional experimental results showing the impact of different p values on real-world datasets?']","['The paper does not sufficiently address the practical challenges in implementing the proposed method, such as hyper-parameter selection and its impact on different datasets.', 'The clarity of the explanations, particularly in the theoretical justification and practical implementation sections, could be improved.', 'The method introduces a hyper-parameter p, which controls the size of the set to be copied from the unlabeled sample to the positive sample. The selection of this hyper-parameter might be dataset-specific and requires careful tuning.', 'The method assumes that a small set of samples can be selected from the unlabeled data that are most similar to the positive class and dissimilar to the negative class, which might not always be straightforward.']",False,3,3,3,6,4,"['Addresses a significant issue in PU learning by eliminating the need for the irreducibility assumption in class-prior estimation.', 'The Regrouping CPE (ReCPE) method is novel and theoretically well-justified.', 'Comprehensive empirical evaluations on synthetic and real-world datasets demonstrate the effectiveness of the proposed method.', 'The paper provides theoretical insights into the estimation bias and convergence properties of the proposed method.']","['The clarity of the paper could be improved, especially in the sections explaining the practical implementation and theoretical justifications.', 'The practical implications of the theoretical contributions are not entirely clear. For instance, the selection of the hyper-parameter p and its impact on different datasets could be better explained.', 'The paper could benefit from additional ablation studies to further validate the robustness of the proposed method under various scenarios.', 'The practical applicability and scalability of the method are not fully explored.']",3,3,3,4,Reject
2sDQwC_hmnM,"The paper 'ZEROFL: Efficient On-Device Training for Federated Learning with Local Sparsity' addresses the constraints of compute, memory, and energy on federated learning (FL) nodes by introducing ZeroFL, a framework that leverages sparsity to accelerate on-device training. The work presents a detailed study on the effects of introducing sparsity during FL, proposes various local sparsification strategies, and evaluates the framework on multiple datasets.","['How does the proposed ZeroFL framework compare to other state-of-the-art FL methods in terms of computational efficiency and model performance?', 'Can the authors provide more detailed explanations and visualizations of the sparsification process and the impact of different masking ratios?', 'What are the potential limitations and negative impacts of introducing high levels of sparsity in federated learning, especially regarding model fairness and biases?', 'Can the authors provide more details on the autoencoder aggregator and its role in the framework?', 'How do the proposed masking strategies compare to other possible approaches for sparsification in FL?', 'Can the authors include more qualitative visualizations to better illustrate the impact of sparsity on model performance?', 'What is the rationale behind the chosen values for rmask, and why do larger masking ratios not show a clear advantage?']","['The paper should address the potential negative impacts of sparsity on model fairness and biases, as well as the limitations related to different application scenarios.', 'The clarity of the paper needs improvement, particularly in the explanation of some methods and the visualization of results.', 'More comprehensive ablation studies are needed to fully understand the impact of different components of the proposed framework.', 'Potential negative societal impacts are not discussed in detail, which could be important given the privacy-sensitive nature of Federated Learning.', 'The paper does not extensively discuss the trade-offs between communication savings and model accuracy.', 'There is a lack of clarity in the experimental setup, particularly regarding the specifics of the datasets and hyperparameters used.']",False,2,2,2,4,4,"['Addresses a critical and practical issue in federated learning related to resource constraints on edge devices.', 'Proposes a novel framework, ZeroFL, that applies sparsity to accelerate on-device training in FL.', 'Provides a comprehensive experimental evaluation on multiple datasets, showing the effectiveness of the approach.', 'Introduces several local sparsification strategies and compares their performance, offering insights into their relative benefits.']","['The novelty of the proposed techniques compared to existing sparsity methods in FL is not well-established.', 'The methodology section lacks clarity in some parts, particularly in explaining the sparsification process and the role of masking ratios.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts, such as the impact of sparsity on model fairness and biases.', 'More detailed ablation studies and comparisons with other state-of-the-art methods are needed to solidify the claims.', 'The explanation of the autoencoder aggregator is not very clear and could benefit from further elaboration.', 'The experimental results, while promising, do not demonstrate groundbreaking improvements.']",3,3,2,3,Reject
mF122BuAnnW,"The paper proposes a novel method called Localized Randomized Smoothing to enhance the robustness of multi-output classifiers against adversarial attacks. The method captures the soft locality of models by using different smoothing distributions for different outputs. The paper provides a thorough theoretical foundation, extensive experimental validation, and comparisons with existing methods.","['Can the authors provide more details on the selection process for smoothing distributions?', 'How can the method be adapted for models that are not softly local?', 'What are the potential limitations of the method, and how can they be addressed?', 'Can the authors provide more details on how to identify softly local models in practice?', 'Can the authors include ablation studies for various choices of smoothing parameters and their impact on performance?', 'How does the method perform against different types of adversarial attacks beyond the ones considered?', 'Can the authors provide empirical validation of the theoretical guarantees against state-of-the-art adversarial attacks?', 'What are the potential limitations and computational overhead of the proposed approach?', 'Can you provide more details on the choice of smoothing distributions and how they were determined for different tasks?', 'Have you considered alternative approaches for parameter tuning, and how do these compare to the chosen method?', 'How does the method scale with larger models and datasets?', 'Can the authors provide more clarity on the assumptions made regarding the relevance of different input regions?', 'Are there practical examples where the proposed method fails or does not provide significant benefits over existing methods?', 'How does the method perform on other types of multi-output tasks and models?', 'Can the authors discuss potential limitations and negative societal impacts in more detail?']","['The method assumes softly local models, which may not be applicable to all types of multi-output classifiers.', 'The selection of smoothing distributions requires a priori knowledge or assumptions.', 'The paper lacks a thorough discussion on the scalability and generalizability of the proposed method.', 'There is no detailed analysis of potential limitations and negative societal impacts.']",False,3,2,3,6,4,"['Novel approach of localized smoothing to capture soft locality.', 'Comprehensive experimental setup and detailed comparisons with baselines.', 'Clear explanation of the methodology and derivation of the collective certificate.', 'Extensive theoretical foundation and experimental validation.']","['Assumes softly local models, which may limit applicability to certain types of classifiers.', 'Requires a priori knowledge or assumptions for selecting smoothing distributions.', 'Some aspects, such as the selection process for smoothing distributions, could be explained in more detail.', 'Handling of potential limitations could be addressed more thoroughly.', 'The clarity of the paper could be improved, especially in the sections explaining the methodology and the experimental setup.', 'Lacks detailed ablation studies for various choices of smoothing parameters and their impact on performance.', 'Robustness against different types of adversarial attacks beyond the ones considered is not explored.', 'The theoretical guarantees provided are somewhat weak without empirical validation against state-of-the-art adversarial attacks.', 'Potential limitations and computational overhead of the proposed approach are not discussed in detail.']",3,3,2,3,Reject
fRnRsdc_nR7,"The paper introduces Noise-FGSM (N-FGSM), a single-step adversarial training method that aims to prevent catastrophic overfitting by using stronger noise and removing perturbation clipping. The authors provide extensive empirical evidence showing that N-FGSM can match or surpass the performance of state-of-the-art methods like GradAlign while being three times faster.","['Can the authors provide a more detailed theoretical justification for the effectiveness of stronger noise and removing clipping in preventing catastrophic overfitting?', 'Can the authors provide more details on the autoencoder aggregator and its role in the proposed method?', 'Could the authors conduct additional ablation studies, including the impact of different noise distributions on the performance of N-FGSM?']","['The paper does not provide a detailed theoretical explanation for the observed empirical results.', 'The clarity of some explanations could be improved, and more comprehensive ablation studies are needed to fully understand the impact of different components.']",False,3,3,3,6,4,"['Addresses a significant problem in adversarial training: catastrophic overfitting in single-step methods.', 'N-FGSM demonstrates strong empirical performance across multiple datasets and architectures, often surpassing state-of-the-art methods.', 'The proposed method is computationally efficient, achieving a 3x speed-up compared to GradAlign.', 'Comprehensive set of experiments and comparisons with existing methods, providing thorough empirical validation.']","['Lacks detailed theoretical justification for why stronger noise and removing clipping prevent catastrophic overfitting.', 'Some components, such as the impact of the autoencoder aggregator, are not explained in sufficient detail.', 'Ablation studies could be more comprehensive, exploring different types of noise distributions and their impact on performance.', 'Clarity of explanations in some sections could be improved, with more detailed descriptions and clearer presentation of key concepts.']",3,3,3,3,Reject
mZsZy481_F,"The paper proposes FROB, a model for few-shot classification and Out-of-Distribution (OoD) detection that aims to improve robustness through self-supervised learning and boundary sample generation. The approach combines a generative model for boundary sample generation with a discriminative model for classification, enhancing performance with self-supervised learning and Outlier Exposure (OE).","['Can the authors provide more intuitive explanations and visualizations for the self-supervised learning mechanism and the loss functions?', 'How does FROB compare with additional benchmarks beyond those already considered?', 'Can the authors conduct more ablation studies to isolate the impact of each component of the model?', 'Can the authors provide more detailed explanations of the self-supervised learning mechanism and the boundary generation process?', 'How does FROB differentiate itself from existing methods in OoD detection and adversarial robustness?', 'Can the authors provide additional ablation studies to isolate the impact of different components of FROB?', 'Can you provide more details on the architecture of the generative model used in FROB?', 'How does the self-supervised learning mechanism work in detail?', 'Can you clarify the differences between FROB and existing methods in more detail?', 'Can you provide more qualitative results or visualizations to better illustrate the effectiveness of FROB?', 'Can the authors provide a clearer and more detailed explanation of the self-supervised learning methodology and the generation of low-confidence samples?', 'How does FROB compare with a broader set of baseline methods in terms of robustness and performance?', 'Can the authors provide theoretical justifications for the chosen heuristics and parameter settings?', 'Can the authors provide more detailed descriptions of the generator model and the specific optimization techniques used?', 'What is the exact impact of the self-generated boundary (O(z)) on the performance metrics? Can an ablation study be provided?', 'How were the hyperparameters chosen for the experiments? Can a detailed description of the experimental setup be provided?']","['The paper could benefit from a clearer presentation of the methodology and more intuitive explanations for the self-supervised learning mechanism. Additional ablation studies and comparisons with more diverse benchmarks are also needed.', 'The paper does not adequately address ethical considerations and potential negative societal impacts, which is important given the application domains mentioned.', 'The paper does not adequately address the clarity issues, making it difficult for readers to fully grasp the methodology and contributions. Additionally, the incremental nature of the improvements over existing methods is not well-justified.', 'The reliance on specific heuristics and parameter choices without strong theoretical justifications is a significant limitation.', 'The paper should address the lack of clarity in the methodology section and provide more details on the experimental setup to improve reproducibility.', 'An ablation study to isolate the contributions of different components of the model is needed.']",False,2,2,2,3,4,"['The combination of generative and discriminative models to address few-shot OoD detection is novel.', 'The paper addresses a significant problem in improving the robustness of few-shot models against adversarial attacks and unseen anomalies.', 'Comprehensive experimental evaluation on multiple datasets, including CIFAR-10, SVHN, and CIFAR-100, with various metrics like AUROC, AAUROC, and GAUROC.']","['The explanation of the methodology, especially the mathematical formulations and the self-supervised learning mechanism, lacks clarity and could be more intuitive.', 'The paper needs better contextualization of its contributions against existing methods like GOOD, ACET, and CCC.', 'Additional ablation studies and comparisons with more diverse benchmarks would strengthen the claims.', 'The practical applicability of the method in real-world scenarios needs further validation.', 'The originality of the work is questionable, as it appears to combine existing techniques without clear novel contributions.', 'The experimental results are fragmented and lack depth in analysis, making it difficult to assess the effectiveness of the proposed model.', 'Insufficient ablation studies to isolate the impact of different components of the model.', 'Ethical considerations and potential negative societal impacts are not addressed.', 'The novelty of the approach is not well-highlighted, and it seems like an incremental improvement over existing methods.', 'Some key details, such as the architecture of the generative model and the specifics of the self-supervised learning mechanism, are missing or insufficiently explained.', 'The writing style is convoluted, with several grammatical errors and awkward phrasing that detracts from the overall readability.', 'The methodological soundness is questionable, with reliance on heuristics and specific parameter choices without strong theoretical justifications.']",2,2,2,3,Reject
K47zHehHcRc,"The paper introduces the notion of interventional consistency in autoencoders and develops a training scheme to enhance it. The authors propose a novel architectural module called the explicit causal latent block (XBlock) that distinguishes between noise and structure in the latent space, aiming to improve modularity and robustness under interventions. They present empirical evidence on MNIST and CelebA datasets using standard autoencoders, variational autoencoders (VAE), and structural autoencoders (SAE).","['Can you provide more clarity on the mathematical formulations, especially the definitions of interventional consistency?', 'How do the proposed methods perform on other datasets beyond MNIST and CelebA?', 'Can you provide more ablation studies to understand the contribution of each component, especially the XBlock and consistency training?', 'Can the authors provide more details on the autoencoder aggregator?', 'Could the authors conduct additional ablation studies on different types of aggregators and modulation functions?', 'How does the proposed method compare with other state-of-the-art methods in causal representation learning?', 'Can the authors provide more intuitive explanations and visualizations to make the mathematical formulations more accessible?', 'What are the specific differences and advantages of the proposed method compared to the baselines? A more detailed analysis would be helpful.']","['The paper acknowledges the complexity of the proposed methods and the need for more comprehensive experiments. Additionally, the applicability of the methods to more diverse datasets should be explored.', 'The societal impact of the work is not discussed in detail.', 'The paper does not provide a comprehensive analysis of the limitations of the proposed method. Potential limitations include the reliance on relatively simple datasets and the complexity of the mathematical formulations.']",False,2,2,3,4,4,"['The paper addresses an important problem in representation learning: the robustness and modularity of learned representations.', 'The introduction of interventional consistency is novel and well-motivated.', 'The proposed XBlock module is a creative approach to separating noise and structure in the latent space.', 'Comprehensive experiments are conducted on MNIST and CelebA datasets, with various autoencoder architectures.']","['The paper is densely written and some sections are difficult to understand, especially the mathematical formulations.', 'The experimental results are mainly limited to MNIST and CelebA datasets, which may not fully demonstrate the generalizability of the proposed methods.', 'The proposed methods add significant complexity to the autoencoder architecture, which may hinder practical applicability.', 'The paper could benefit from more ablation studies to understand the contribution of each component, especially the XBlock and consistency training.', 'Insufficient comparison with other state-of-the-art methods in causal representation learning.', 'The societal impact of the work is not discussed in detail.']",3,3,2,3,Reject
F0v5uBM-q5K,"The paper introduces Power-Aware Neural Networks (PANN), a framework to reduce the power consumption of deep neural networks (DNNs). It presents methods like switching to unsigned arithmetic and removing multipliers, aiming for power-efficient DNNs while maintaining accuracy. The framework can be applied post-training and during training to achieve high efficiency.","['Can the authors provide more details on the potential limitations and assumptions of their power consumption models?', 'Can the authors discuss the societal impact of reducing power consumption in DNNs?', 'Can the authors provide more practical insights into the hardware requirements for the proposed methodology?', 'How do the assumptions about input distributions impact the generalizability of the power consumption models?', 'Are there specific deployment scenarios where the proposed method may not be applicable?', 'Can the authors discuss potential hardware implementation challenges and how they could be addressed?', 'How does the approach generalize across different DNN architectures and applications?', 'Can the authors provide additional ablation studies to better understand the impact of different components of their approach?', 'Can you provide more details on the process of converting a pre-trained network to use unsigned arithmetic?', 'How does the PANN approach affect the computational complexity and latency of the network during inference?', 'What are the potential limitations or drawbacks of using PANN, especially in real-world deployment scenarios?', 'Can you provide more details on the process of switching to unsigned arithmetic and how it impacts different layers of the network?', 'Could you include additional ablation studies to isolate the contributions of switching to unsigned arithmetic and the multiplier-free design?', 'How does the proposed method perform on different hardware architectures, and are there any specific hardware configurations that benefit more from PANN?']","['The paper does not sufficiently discuss the limitations and assumptions underlying the power consumption models. This could affect the generalizability of the results.', 'The societal impact of reducing power consumption in DNNs, such as environmental benefits, should be addressed to provide a broader context for the work.', 'The paper should discuss more about the practical implications and hardware requirements for implementing the proposed methodology.', 'The paper should discuss potential hardware implementation challenges and provide more ablation studies to understand the impact of different components of the approach.', 'The paper does not fully address the potential increase in computational complexity or latency due to the use of additions instead of multiplications.', 'More experiments on different types of models and datasets would provide a better understanding of the generalizability of the approach.', ""The paper should address the potential trade-offs between power savings and other performance metrics such as latency and memory footprint. Additionally, the impact of different hardware architectures on the method's performance should be explored.""]",False,3,3,3,6,4,"['Addresses a critical issue of power consumption in DNNs, which is important for deploying them on resource-limited devices.', 'Proposes novel techniques such as switching to unsigned arithmetic and removing multipliers, which are well-supported by theoretical analysis and simulations.', 'Comprehensive experiments validating the proposed methods, including comparisons with state-of-the-art quantization methods.']","['The clarity and organization of the paper could be improved. Some sections are dense and difficult to follow, which hampers understanding.', 'Potential limitations and assumptions in the power consumption models are not discussed in sufficient detail.', 'The novelty of some ideas, such as switching to unsigned arithmetic, may not be sufficiently groundbreaking.', 'The societal impact of reducing power consumption in DNNs is not adequately addressed.', 'Requires specific hardware support, which may not be available in all deployment environments.', ""The approach may have varying effectiveness across different DNN architectures and applications, which isn't fully explored."", 'Additional ablation studies could help in understanding the impact of different components of the approach.']",3,3,3,4,Reject
ChKNCDB0oYj,"The paper proposes a novel mistake-driven image classification method that focuses on augmenting underperforming classes using FastGAN for data generation, combined with Progressive SpinalNet and Sharpness-Aware Minimization. The method demonstrates competitive performance on multiple datasets, achieving state-of-the-art results in some cases.","['Can the authors provide more details on the implementation and training specifics of the GAN used?', 'What are the reasons for the lower performance on CIFAR-10 compared to other datasets?', 'Can the authors include more detailed comparisons with other GAN techniques?', 'Please provide more visualizations and analysis of the generated samples and their impact on the model performance.', 'How does the heuristic choice of the number of worst-performing classes to augment affect the overall performance and what sensitivity analysis has been conducted?', 'Can the authors provide more details on the specific configurations and hyperparameters used in the experiments?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can additional ablation studies be conducted to isolate the contributions of each component more effectively?']","['The paper lacks clarity in several methodological aspects and could benefit from more detailed explanations and visualizations.', 'Potential bias from the heuristic choice of the number of worst-performing classes to augment needs further investigation.', ""The method's performance on small-sized images is questionable based on CIFAR-10 results."", 'The combination of techniques may not generalize well to other domains without further validation.', 'Potential computational cost of training multiple class-specific GANs, even if the GAN is lightweight.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed method. For instance, the computational cost and feasibility of applying this approach to real-world tasks need more discussion.', ""The method's dependency on the choice of GAN and model configurations should be highlighted as a potential limitation."", 'The paper does not address the potential risks of generating biased or misleading samples with GANs.']",True,2,2,2,4,4,"['Addresses the practical problem of imbalanced performance among classes in image classification.', 'Combines several recent techniques (FastGAN, Progressive SpinalNet, SAM) in a novel way.', 'Provides extensive experimental evaluation with ablation studies on multiple datasets.', 'Achieves state-of-the-art results on several datasets.']","['Lack of detailed explanation on the implementation and training specifics of the GAN.', 'Underperformance on CIFAR-10 raises questions about general applicability.', 'Comparisons with other GAN techniques are not comprehensive.', 'More detailed visualization and analysis of generated samples and their impact are needed.', 'Potential bias from the heuristic choice of the number of worst-performing classes to augment is not thoroughly discussed.', 'The clarity of the methodology and experimental setup could be improved, particularly regarding the specific configurations and hyperparameters used.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed approach.']",2,3,2,3,Reject
nhN-fqxmNGx,"The paper provides a theoretical comparison of six variable selection methods (Lasso, Elastic Net, SCAD, forward selection, thresholded Lasso, and forward-backward selection) using Hamming error as a performance metric. It derives convergence rates and phase diagrams under the assumption that the regression coefficients are drawn from a two-point mixture and the Gram matrix is block-wise diagonal.","['Can you provide more details on the derivations, especially those related to the phase diagrams?', 'How do the theoretical results translate into practical recommendations for researchers using these variable selection methods?', 'Can the authors discuss the limitations of their theoretical assumptions and how they might affect real-world applications?', 'Can the authors provide more intuitive explanations of the theoretical results?', 'Can the authors include experiments on real-world datasets to validate their theoretical findings?', 'What is the computational complexity of each method? How do they compare in terms of runtime and scalability?', 'Can the authors discuss the choice of tuning parameters in more detail?']","['The theoretical assumptions, such as the block-wise diagonal structure of the Gram matrix, may not hold in all real-world scenarios.', 'The practical implications of the findings are not fully addressed, which limits the impact of the work.', 'The paper does not address the computational complexity of each method, which is important for understanding their practical applicability.', 'The experiments are limited to synthetic data; real-world data experiments would strengthen the paper.']",False,3,3,3,5,4,"['Addresses a significant problem in high-dimensional data analysis.', 'Provides a thorough theoretical comparison of different variable selection methods.', 'Uses Hamming error as a metric, which is relevant for practical applications.', 'Derives convergence rates and phase diagrams, offering deep insights into the performance of each method.']","['The clarity of the paper could be improved; some derivations and theoretical results are difficult to follow.', 'The novelty is limited, as the paper mainly extends existing methods rather than introducing a novel approach.', 'The practical implications of the findings are not discussed in depth.', 'The experimental section is limited and does not include real-world datasets.', 'The assumptions (e.g., block-wise diagonal Gram matrix) may limit practical applicability.']",3,3,3,4,Reject
mRc_t2b3l1-,"The paper investigates the limiting dynamics of deep neural networks trained with stochastic gradient descent (SGD). It proposes a continuous-time model for SGD, examines the dynamics in linear regression, and extends the findings to deep neural networks using theoretical tools from statistical physics. The study provides empirical validation using standard architectures and large-scale datasets.","['Can the authors provide insights or preliminary results on how the theory extends to more complex models and tasks beyond standard architectures and datasets?', 'How robust are the key findings when the assumptions on the loss landscape and gradient noise are relaxed or modified?', 'Can the authors provide additional ablation studies to isolate the contributions of individual components?', 'Can the authors clarify the mathematical notations and provide more intuitive explanations for the results?']","['The paper assumes a quadratic approximation of the loss at the end of training and proportionality between the Hessian and the gradient noise covariance. The applicability of these assumptions in more complex settings needs further exploration.', 'The empirical validation is limited in scope, and more extensive experiments across different architectures and datasets would strengthen the claims.', 'The paper could benefit from a more detailed discussion on the practical implications of the findings for training neural networks.']",False,3,3,3,6,4,"['Theoretical novelty: Introduces a comprehensive framework for understanding the limiting dynamics of SGD in deep neural networks.', 'Empirical validation: Supports theoretical findings with experiments on standard architectures and large-scale datasets.', 'Interdisciplinary approach: Leverages concepts from statistical physics to deepen understanding.', 'Comprehensive experiments: Covers a wide range of architectures and hyperparameters.']","['Strong assumptions: Relies on assumptions that may not hold universally, such as quadratic loss at the end of training and proportionality between the Hessian and gradient noise covariance.', 'Complexity: Dense theoretical content may be challenging for some readers.', 'Limited empirical scope: Mainly focuses on standard architectures and datasets, lacking diversity in tasks and models.', 'Clarity issues: Extensive mathematical notations and dense content may hinder understanding for a broader audience.']",3,3,3,4,Reject
-3Qj7Jl6UP5,"The paper explores the application of magnitude vectors for images, focusing on edge detection and adversarial robustness. It introduces a novel algorithm to speed up the computation of magnitude vectors and provides theoretical justifications for its utility in these applications.","['Can you provide more detailed information on the hyperparameters used in the experiments?', 'How does the speed-up algorithm compare in different scenarios and datasets beyond the ones tested?', 'Can the authors provide more detailed and rigorous experimental validation, especially for the adversarial robustness experiments?', 'Can the authors compare the magnitude-based edge detection method with a broader range of edge detection algorithms and provide quantitative results?', 'Can the authors provide more details and validation for the speed-up algorithm, including a comprehensive error analysis?', 'How does the magnitude-based method perform against more sophisticated adversarial attacks beyond FGSM?', 'Can the authors provide more intuitive explanations for the theoretical sections?', 'How does the proposed magnitude vector compare to other baseline methods in edge detection and adversarial robustness?', 'Can the authors provide more comprehensive experiments and comparisons?', 'How can the reproducibility of the proposed methods be ensured?', 'Can the authors provide more ablation studies to compare the proposed method with existing edge detection and adversarial robustness methods?', 'Can the authors provide a more detailed analysis of the adversarial robustness results?', 'Can the authors improve the clarity of the theoretical explanations?', 'Can the authors provide more rigorous mathematical proofs for their theoretical claims?', 'How does the proposed method compare quantitatively with other state-of-the-art edge detection and adversarial robustness techniques?', 'Can more comprehensive ablation studies be conducted to validate the effectiveness of the proposed approach?']","['The practical applications explored do not show significant improvements over existing methods.', 'The noise in the magnitude-based edge detection is a significant limitation that needs to be addressed.', 'The experimental validation needs to be more comprehensive and rigorous.', 'The clarity and organization of the paper can be improved.', 'The paper lacks a clear connection between theoretical claims and empirical results.', 'The robustness evaluation methodology is unconventional and may not provide a fair assessment.', 'The paper does not adequately discuss the potential limitations and societal impacts of the proposed method. For example, how does the method perform on different types of images or datasets? Are there any ethical concerns regarding the use of this method in real-world applications?', 'The paper does not fully address the limitations of the proposed approach, such as potential scalability issues with the speed-up algorithm for extremely large images.', 'The potential negative societal impacts of the work are not discussed.']",False,2,2,2,3,4,"['Theoretical foundation on magnitude vectors is robust and well-explained.', 'Innovative application of magnitude vectors to images, especially for edge detection and adversarial robustness.', 'Introduction of a speed-up algorithm for computing magnitude vectors, addressing a significant computational challenge.']","['Empirical results are not particularly strong or compelling.', 'Edge detection with magnitude vectors is noisier compared to the Canny detector.', 'The practical impact of the proposed applications is limited.', 'The paper is dense and may not be accessible to all readers.', 'Lack of detailed information on implementation and hyperparameters in the empirical sections.', 'Experimental validation, especially for edge detection and adversarial robustness, lacks depth and clarity.', 'Adversarial robustness experiments need more rigorous testing against a broader range of attacks and comparison with more sophisticated defense mechanisms.', 'Details of the speed-up algorithm could be more thoroughly explained and validated.', 'Theoretical justifications are not well-connected to the empirical results.', 'The relationship between magnitude vectors and their applications is not convincingly established.', 'Evaluations are not comprehensive, especially for adversarial robustness.', 'Reproducibility might be hindered due to the complexity of the proposed methods.', 'Potential limitations and societal impacts are not adequately discussed.']",3,2,2,3,Reject
alaQzRbCY9w,"The paper proposes a novel optimization algorithm called Stochastic Model Building (SMB), which adapts both the step size and search direction using second-order information. This method aims to enhance the convergence rates and robustness of Stochastic Gradient Descent (SGD). The authors provide a thorough convergence analysis and extensive experimental validation, demonstrating the advantages of SMB over existing methods like SGD, Adam, and SLS.","['Can you provide additional experimental results, especially for larger models, to ensure statistical significance?', 'How does your method compare to the very latest adaptive optimization methods not covered in your experiments?', 'Can the authors clarify the implementation details of the model building steps and their computational overhead?', 'Why does the convergence analysis focus on SMBi rather than the original SMB method?', 'Can you provide more clarity on the construction of the quadratic model?', 'How does the proposed method perform on a wider range of tasks beyond image classification?']","['Theoretical convergence guarantees are provided for a modified version of SMB (SMBi), which can perform well against other methods but consistently underperforms the original SMB method. This begs for a convergence analysis for the original SMB method.', 'The complexity and potential computational overhead of the algorithm need to be addressed.', 'The clarity of some methodological aspects should be improved.', 'The robustness claims need further validation across diverse architectures and datasets.']",False,3,2,3,4,4,"['The problem addressed is highly relevant in the field of optimization for machine learning.', 'The proposed method is novel and incorporates second-order information to enhance the optimization process.', 'The paper provides thorough convergence analysis and theoretical grounding.', ""The experimental results demonstrate the method's improved performance and robustness compared to well-known optimization methods.""]","['The paper is dense and may be difficult for readers to fully grasp without a deep understanding of optimization techniques.', 'The experimental section, while comprehensive, could benefit from additional repetitions for large models to ensure statistical significance.', 'The paper lacks a direct comparison to very recent adaptive optimization methods, which could provide a better benchmark for the proposed approach.', 'The practical utility of the proposed method is questionable given the additional computational overhead introduced by the model building steps.', 'The clarity of the presentation needs improvement, particularly in explaining the model building steps and their implementation details.']",3,3,2,4,Reject
TKrlyiqKWB,"The paper introduces the Concept Subspace Network (CSN), a neural network architecture that generalizes specialized classifiers to produce a unified model capable of learning multi-concept relationships. CSNs use prototype-based representations and allow for encoding relationships between concepts in a flexible manner. The paper presents experiments showing that CSNs perform comparably to state-of-the-art methods in fair classification, hierarchical classification, and even in tasks requiring both fairness and hierarchy.","['Can the authors provide more detailed explanations and examples of the training procedure and the calculation of alignment between subspaces?', 'Can the authors conduct additional ablation studies to isolate the effects of different components of the CSN architecture?', 'What are the potential limitations and negative societal impacts of using CSNs, particularly in terms of bias and fairness?', 'Can the authors discuss the ethical considerations of combining fairness and hierarchical classification in a single model in more detail?', 'Can the authors provide a more rigorous theoretical analysis of the CSN model?', 'Have the authors considered varying the number of prototypes or the dimensionality of the concept subspaces in their experiments?']","['The paper does not adequately address potential limitations or negative societal impacts of the proposed method. The use of prototypes might lead to issues with bias or fairness in certain applications, and the ethical considerations of combining fairness and hierarchical classification in a single model are not fully explored.', 'The primary limitation is the lack of theoretical analysis. The empirical results are strong, but a deeper theoretical understanding would strengthen the contribution.', 'Additional experiments varying the number of prototypes and subspace dimensions could provide more insights into the robustness of the model.']",False,3,2,3,5,4,"['The idea of a unified model capable of learning and reconciling multiple concept relationships is novel and has potential applications in various domains.', 'The use of prototype-based representations for interpretability is a strong point and builds on existing work in a meaningful way.', 'The paper presents thorough experimental comparisons with state-of-the-art methods, showing comparable or better performance.']","['The methodology section is dense and sometimes unclear, especially regarding the training procedure and the calculation of alignment between subspaces. More detailed explanations or illustrative examples would be helpful.', 'The experiments are comprehensive but could benefit from additional ablation studies to isolate the effects of different components of the CSN architecture.', 'The paper does not adequately discuss potential limitations or negative societal impacts of the proposed method. For example, the use of prototypes might lead to issues with bias or fairness in certain applications.', 'The ethical considerations of combining fairness and hierarchical classification in a single model are not fully explored. There could be unintended consequences of enforcing concept relationships in certain contexts.', 'The paper lacks a rigorous theoretical analysis to explain why the proposed model performs well.']",3,3,2,3,Reject
w8HXzn2FyKm,"The paper proposes a novel multi-agent linear stochastic approximation algorithm that relaxes the assumption of doubly stochastic matrices, making it more practical for real-world applications. It provides rigorous finite-time error bounds for both constant and time-varying step-sizes and introduces a push-type distributed stochastic approximation algorithm for scenarios requiring uni-directional communication.","['Can the authors provide more examples or simulations to illustrate the practical applications of their method?', 'How does the proposed method perform in real-world scenarios compared to existing methods?', 'How practical are the assumptions, especially Assumption 6, in real-world applications?', 'Can you provide more intuition behind the choice of absolute probability sequences for the stochastic matrices?', 'How sensitive are the results to the assumptions, particularly Assumption 6 regarding the existence of the limit of the absolute probability sequence?']","['The paper requires a solid understanding of stochastic approximation and multi-agent systems, which may limit its accessibility to a broader audience.', 'The finite-time bounds involve several constants that are well-defined but difficult to compute in practice.', 'The assumptions, particularly Assumption 6, might be restrictive in practical scenarios.', 'The complexity involved in computing the constants for the finite-time bounds may hinder practical implementation.']",False,3,3,3,5,4,"['Addresses a significant gap in the literature by considering stochastic matrices instead of doubly stochastic matrices.', 'Provides comprehensive theoretical contributions, including finite-time error bounds for both constant and time-varying step-sizes.', 'Introduces a novel push-type distributed stochastic approximation algorithm, which is well-suited for scenarios with uni-directional communication.']","['The presentation is dense and could benefit from better organization and clarity, especially in the theoretical sections.', 'The practical implications and potential applications of the proposed methods are not discussed in detail.', 'The notation and mathematical rigor make the paper difficult to follow for a broader audience.', 'The paper lacks experimental validation to demonstrate the empirical performance and applicability of the proposed algorithms.']",3,3,3,4,Reject
e-JV6H8lwpl,"The paper introduces a novel method for nonlinear system identification and model predictive control using deep neural networks with a bottleneck layer. This method extends traditional subspace methods used for linear systems to nonlinear systems, providing a theoretically grounded approach. An illustrative example of a cascaded tanks system is used to demonstrate the method's effectiveness.","['Can you provide more details on the autoencoder aggregator?', 'How does the method perform on more complex or real-world datasets?', 'Can you provide additional ablation studies to understand the impact of different model components and hyperparameters?', 'Can you provide more rigorous proofs for the theoretical claims, especially regarding the observability and predictability of the state using the bottleneck structure?', 'How does the proposed method compare quantitatively with other state-of-the-art nonlinear system identification methods in terms of prediction accuracy and computational efficiency?', 'Could you expand the experimental validation to include more complex and diverse nonlinear systems to demonstrate the generality and robustness of the method?', 'Can the authors provide a more detailed explanation of the neural network architecture, including the choice of hyperparameters?', 'How does the method perform under different noise and disturbance conditions? Additional empirical results would be helpful.', 'Can the authors compare their method with other state-of-the-art techniques in nonlinear system identification and model predictive control?']","['The paper lacks comprehensive experimental validation on more complex datasets.', 'There is a need for additional ablation studies to understand the impact of different components and hyperparameters.', 'The paper does not adequately address the limitations of the proposed method, such as its scalability to high-dimensional systems or its performance in the presence of significant noise.', 'There is no discussion on the potential negative societal impacts of using neural networks in critical control systems, which should be considered given the increasing reliance on AI in safety-critical applications.']",False,2,2,2,4,4,"['The paper tackles an important problem in nonlinear system identification and model predictive control.', 'The proposed method is theoretically grounded and extends existing subspace methods for linear systems to nonlinear systems.', 'The use of a neural network with a bottleneck layer to capture the state of the system is innovative.', ""The illustrative example provides a clear demonstration of the method's utility and effectiveness.""]","['The clarity of some sections, particularly the theoretical explanations, could be improved.', 'The experimental validation is limited to a single illustrative example. Additional experiments on more complex or real-world datasets would strengthen the paper.', 'Theoretical claims lack rigorous proof and are based on strong assumptions that are not well-justified. More rigorous proofs are needed, especially regarding the observability and predictability of the state using the bottleneck structure.', 'Insufficient comparison with existing state-of-the-art methods in both the theoretical and experimental sections. Quantitative comparisons in terms of prediction accuracy and computational efficiency are necessary.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed method.', 'There are insufficient ablation studies to understand the impact of different components and hyperparameters of the model.']",3,2,2,3,Reject
ZWykq5n4zx,"The paper addresses the problem of obtaining high-probability generalization bounds for uniformly stable randomized learning algorithms, particularly focusing on SGD with time-decaying learning rates. It proposes a confidence-boosting technique that leverages subbagging to achieve these bounds, providing a novel theoretical contribution.","['Can you provide empirical validation of the theoretical results to demonstrate their practical utility?', 'Can you include more intuitive explanations and practical implications of your theoretical findings?', 'How does the proposed method compare with other state-of-the-art techniques in terms of computational complexity and performance?', 'What are the practical implications and potential applications of these improved bounds in real-world machine learning tasks?', 'Are there any practical limitations or scenarios where the proposed method may not be effective?']","['The paper primarily focuses on theoretical contributions and lacks empirical validation, which could limit its practical impact.', 'The clarity of the mathematical notation is also a concern.']",False,3,2,3,6,4,"['The paper tackles an important problem in the field of generalization bounds for randomized learning algorithms.', 'The proposed confidence-boosting technique is novel and theoretically sound.', 'The paper provides rigorous proofs and substantial theoretical analysis.', 'The results improve upon existing bounds, particularly for SGD with time-decaying learning rates and deterministic algorithms.']","['The paper is highly technical and could benefit from more intuitive explanations and practical implications.', 'The experiments section is lacking; the theoretical results should be complemented with empirical validation.', 'The clarity could be improved to make the paper more accessible to a broader audience.', 'The practical implications and potential applications of the results are not thoroughly discussed.']",3,3,2,3,Reject
3mgYqlH60Uj,"The paper proposes a reinforcement learning approach that incorporates biomechanical cumulative fatigue to generate more natural and symmetric locomotion. The authors introduce a Normalized Cumulative Fatigue (NCF) model based on the Three Compartment Controller (3CC) model. The approach aims to improve the quality of simulated locomotion by considering cumulative fatigue over time, making it more computationally efficient and adaptable to various characters and environments without the need for motion capture data, finite state machines, or morphological specifications.","['Can the authors provide more details on the autoencoder aggregator used in the model?', 'What is the impact of different types of modulation functions on the performance of the proposed method?', ""How does the choice of aggregator affect the model's performance?"", 'Can the authors provide more qualitative examples and visualizations of the locomotion tasks to better illustrate the effectiveness of your method?', 'What are the effects of different hyperparameter settings on the performance of the proposed approach?', 'Can the authors discuss the potential limitations and broader applicability of their approach?', 'Are there any potential ethical implications or negative societal impacts associated with the proposed approach?']","['The NCF model, while useful, is not verified for isokinetic tasks such as locomotion from a biomechanical perspective. Further studies with real participants are needed.', 'The paper primarily focuses on symmetry, and extensions to other methods and features are yet to be explored.', 'The clarity of certain sections needs improvement, and more detailed ablation studies are required. Additionally, the paper lacks sufficient qualitative examples and visualizations to illustrate the effectiveness of the proposed method.', 'The paper should include more comprehensive ablation studies and hyperparameter sensitivity analyses to validate the robustness and generalizability of the proposed approach.', 'The clarity and structure of the methodology section need improvement to make it more accessible to readers.', 'The paper should discuss potential limitations and broader applicability of the approach, as well as potential ethical implications and negative societal impacts.']",False,3,2,3,4,4,"['The problem addressed is significant and relevant to the field of reinforcement learning and computer animation.', 'The proposed NCF model is novel and simplifies the implementation of cumulative fatigue, making it computationally efficient.', 'The paper includes thorough experiments and evaluations in different environments, showing the effectiveness of the proposed method.', 'The approach does not rely on motion capture data or pre-defined specifications, making it broadly applicable.']","['The paper requires more detailed explanations, especially regarding the autoencoder aggregator and some components of the NCF model.', 'The clarity of the paper can be improved, particularly in the methodology section.', 'Additional ablation studies would enhance the quality of the paper. Specifically, exploring the impact of different modulation functions and types of aggregators.', 'The paper could benefit from more qualitative analyses and visualizations to support the claims.', 'Potential limitations and broader applicability of the approach are not adequately discussed.', 'The paper does not address potential ethical implications or negative societal impacts of the proposed approach.']",3,3,2,3,Reject
z7p2V6KROOV,"The paper extends the WILDS benchmark to include unlabeled data for several datasets, allowing evaluation of unsupervised adaptation methods. It assesses various state-of-the-art methods and finds limited success in leveraging unlabeled data to improve out-of-distribution performance.","['What are the specific reasons for the limited success of the evaluated methods on WILDS 2.0?', 'Are there any insights or proposed next steps to improve the efficacy of unsupervised adaptation methods?', 'Can the authors provide more detailed ablation studies to understand the impact of different components?', 'Why did some methods, such as CORAL, not perform well? Can the authors provide a deeper analysis?', 'Can you provide more details on the methodology for incorporating the unlabeled data?', 'How do you plan to address the mixed performance of the benchmarked methods?', 'Can you elaborate on the potential limitations and negative societal impacts of your work?']","['The paper does not propose any new methods or significant theoretical advancements.', 'The limited success of existing methods raises concerns about their practicality, but the paper does not offer solutions.', 'The paper could better address the limitations of the methods evaluated, particularly those that did not perform well.', 'There is a lack of in-depth analysis of failure cases, which could provide insights for future improvements.', 'The paper does not address potential limitations and negative societal impacts in detail. For example, the use of sensitive datasets like CIVILCOMMENTS-WILDS requires a more thorough discussion on the ethical implications.']",False,3,2,3,5,4,"['Addresses a practical problem by extending an existing benchmark with unlabeled data, which is more representative of real-world scenarios.', 'Provides comprehensive experiments across multiple datasets and methods.', 'Maintains consistency with the original WILDS benchmark, allowing for direct comparison.', 'Includes an open-source package for reproducibility.']","['The contributions seem incremental rather than groundbreaking.', 'Experimental results show limited improvement with current state-of-the-art methods, yet the paper does not propose new methods to address these shortcomings.', 'The paper is quite lengthy and could be more concise for better clarity and impact.', 'The methodology for incorporating unlabeled data could be described more clearly.', 'The analysis of why certain methods failed is lacking in depth.', 'The paper does not address potential limitations and negative societal impacts in detail.']",3,3,3,3,Reject
3Li0OPkhQU,"The paper introduces a semi-supervised learning algorithm for CNNs that leverages labeled and unlabeled data to construct data-driven features and a linear classifier. Theoretical analysis ensures efficient learning under certain distributional assumptions, and empirical results on MNIST and Fashion MNIST datasets demonstrate the approach's viability.","['Can the authors provide more insight into the practical implications of the assumptions made, particularly Lipschitz continuity and boundedness?', 'How feasible is the algorithm in practice, considering the dependencies on covering numbers and clustering complexity?', 'Do the authors have plans to test the algorithm on more diverse and complex datasets beyond MNIST and Fashion MNIST?', 'Can the authors provide more details on the clustering algorithm used in the unsupervised stage?', 'How does the proposed algorithm compare with state-of-the-art semi-supervised methods on more complex datasets?', 'Can the authors justify the choice of parameters used in the experiments?', 'How sensitive is the performance of the proposed method to the size of the dictionary (N) and the patch embedding radius (τ)?']","['Theoretical assumptions may not always hold in practical scenarios, and the practical feasibility of the algorithm is not fully addressed.', 'The complexity of the algorithm, particularly the clustering stage, may pose challenges for large-scale datasets.', 'The empirical evaluation is limited to a few datasets, which may not fully demonstrate the generalizability of the proposed method.']",False,3,2,3,5,4,"['Addresses a crucial problem in deep learning: the efficient learning of CNNs.', 'Provides strong theoretical guarantees for the proposed algorithm.', 'Novel approach of leveraging data-dependent features.', 'Empirical validation on standard datasets supports the theoretical findings.']","['Theoretical assumptions, such as Lipschitz continuity and boundedness, may not always hold in practical scenarios.', 'Practical challenges of the algorithm, like dependencies on covering numbers and clustering complexity, need better discussion.', 'The scope of experiments is limited to standard datasets; more diverse datasets could enhance the understanding of practical applications.', 'The paper is dense and could benefit from better organization and clarity.', 'Lacks detailed ablation studies to understand the impact of different components of the proposed method.']",3,3,2,3,Reject
D1TYemnoRN,"The paper proposes a novel theoretical framework linking the length of optimization paths in gradient flow to generalization performance. The key idea is that shorter optimization paths indicate better generalization. The authors provide theoretical proofs and apply their framework to underdetermined linear regression, kernel regression, and overparameterized two-layer ReLU neural networks.","['Can the authors provide more empirical results on real-world datasets to support their theoretical claims?', 'Can the authors simplify some of the dense proofs and derivations for better clarity?', 'How does this framework compare to existing work on implicit bias in optimization and generalization?', 'Can the authors provide more intuitive explanations for the key concepts and results, especially the Uniform-LGI condition?', 'What are the practical implications of the proposed framework for training deep neural networks?', 'How generalizable are the results beyond the specific assumptions made (e.g., subgaussian entries, specific initialization methods)?']","['The authors should discuss the practical implications of their framework more extensively, including how it can be applied in real-world scenarios.', 'The paper could benefit from a more thorough comparison to existing literature on related topics, such as implicit bias.', 'The limitations regarding empirical validation and practical implications are discussed. The assumptions made might limit the generality of the results.', 'The potential negative societal impacts of the work should be addressed.']",False,3,3,3,5,4,"['The idea of linking optimization path length to generalization is innovative and addresses a critical aspect of machine learning.', 'Theoretical analysis is thorough, including definitions, lemmas, and proofs to support the claims.', 'The framework is applied to different models, demonstrating its broad applicability.', 'The paper provides a comprehensive set of references, situating the work within the broader literature.']","['The empirical validation is limited and may not convincingly support the theoretical claims. More extensive experiments on real-world datasets are needed.', 'Some proofs and derivations are dense and could benefit from clearer exposition.', 'The practical implications of the framework are not fully explored. It is unclear how practitioners can directly apply these insights to improve model training.', 'The connection to existing literature on implicit bias and optimization-generalization could be more deeply explored to highlight the novelty.', 'The theoretical analysis relies heavily on specific conditions and assumptions, which may limit the generality of the results.']",3,3,3,4,Reject
CVfLvQq9gLo,"The paper 'ARTEMIS: Attention-Based Retrieval with Text-Explicit Matching & Implicit Similarity' introduces a novel approach for image retrieval using both image and text queries. It leverages two independent modules, Explicit Matching (EM) and Implicit Similarity (IS), guided by lightweight attention mechanisms. The method achieves state-of-the-art results on several benchmarks without heavy pre-training or large architectures.","['Please provide more details about the autoencoder aggregator.', 'Can you include additional ablation studies on different types of aggregators and modulation functions?', 'Can you provide more detailed explanations and visualizations of the attention mechanisms to better understand their role?', 'What are the potential ethical considerations and negative societal impacts of your work, and how do you plan to address them?', 'How does the method perform with more complex or ambiguous text queries?']","['The paper could benefit from additional ablation studies and improved clarity in certain sections.', 'The reliance on text modifiers may limit the applicability of ARTEMIS in scenarios where such modifiers are unavailable or unreliable.', 'The paper does not address the potential biases and ethical concerns related to the use of text-based image retrieval.']",True,3,2,3,7,4,"['Addresses a relevant and practical problem in image retrieval by integrating text and image modalities.', 'Proposes innovative attention mechanisms for Explicit Matching and Implicit Similarity.', 'Computationally efficient without relying on heavy pre-training or large architectures.', 'Comprehensive experiments on multiple datasets demonstrate the effectiveness of the approach.']","['Additional ablation studies on different types of aggregators and modulation functions would enhance the paper.', 'Clarity could be improved, especially regarding the autoencoder aggregator.', 'Qualitative analysis could be strengthened with more cases and detailed explanations.', 'The paper does not adequately discuss ethical considerations and potential negative societal impacts.']",3,3,3,4,Reject
xRK8xgFuiu,"The paper proposes a novel algorithm for causal discovery that leverages Cholesky factorization of the covariance/precision matrix. The authors claim the algorithm has better time and sample complexities compared to previous methods. They provide theoretical guarantees and evaluate the algorithm on synthetic and real-world datasets, demonstrating its efficiency and effectiveness.","['Can you provide a clearer explanation of the algorithm steps, particularly how the permutation and the matrix updates are performed?', 'How do the assumptions about noise variances being larger for child variables hold in practice, and can you provide empirical evidence for this?', 'Why are certain state-of-the-art methods not included in the comparisons, and how does your method perform against them?', 'Can you provide more results on a wider variety of real-world datasets to better support the claims of the paper?', 'Can the authors provide more detailed steps in their theoretical proofs to improve clarity?', 'Why do certain baseline methods perform significantly worse in some cases? A deeper discussion would be beneficial.', 'What are the practical limitations of the proposed method, especially regarding the assumptions for exact DAG recovery?', 'Can the authors summarize their extensive experimental results more concisely or provide more visual comparisons to improve readability?', ""Can the authors provide more practical insights or intuitive explanations of the algorithm's behavior?"", 'What are the potential limitations or drawbacks of the proposed method?', 'Are there any negative societal impacts or ethical concerns associated with this research?', 'Can the authors provide more details on how the method could be extended to non-linear SEM models?', 'What are the potential limitations of the proposed method, and how can they be addressed in future work?', 'Can the authors provide more intuitive explanations or examples to help readers better understand the algorithm and its theoretical guarantees?']","['The paper needs to address the lack of clarity in the methodology and provide more comprehensive theoretical explanations.', 'More extensive comparisons with state-of-the-art methods are necessary to validate the performance claims.', 'The paper should discuss more thoroughly the assumptions under which the algorithm guarantees exact recovery and the implications if these assumptions are violated.', 'Potential negative societal impacts of misidentifying causal relationships due to incorrect assumptions or insufficient data should be considered.', 'The paper should discuss in more detail the limitations of assuming a linear SEM model and the challenges involved in extending the method to non-linear models.']",False,3,2,3,4,4,"['The proposed algorithm has a novel approach, leveraging Cholesky factorization, which is interesting and potentially impactful.', 'Theoretical guarantees are provided for the exact recovery of the DAG structure under certain assumptions.', 'Experimental results on synthetic and real-world datasets show promising performance in terms of efficiency and effectiveness.']","['The clarity of the methodology is lacking. The explanation of the algorithm steps, particularly in Sections 2.2 and 2.3, is quite dense and may be difficult for readers to follow.', 'The theoretical guarantees are not fully explained, and some assumptions are not well justified. For example, the assumption of noise variances being larger for child variables needs further clarification.', 'The comparison with state-of-the-art methods is limited. While some comparisons are made, the paper does not benchmark against all relevant methods, and it is unclear how the proposed method fares against the very latest techniques.', 'The experiments on real-world datasets are relatively limited. More diverse datasets and more extensive evaluations would strengthen the claims.', 'The paper assumes a linear SEM model, which may limit its applicability to real-world scenarios where non-linear relationships are common.', 'The potential limitations and negative societal impacts are not thoroughly addressed.']",3,3,2,4,Reject
T_uSMSAlgoy,"The paper introduces a novel Tree-based Decoder-Centric (TDC) algorithm to identify latent holes in the latent space of Variational Auto-Encoders (VAEs) for text generation. The approach focuses on the decoder network, addressing limitations of existing encoder-centric methods. The paper provides theoretical unification of existing latent hole indicators, extends the analysis to the text domain using the Wasserstein distance, and offers an in-depth empirical analysis to examine the impact of latent holes on VAE performance, their vacancy, and distribution.","['Could the authors provide more details on the autoencoder aggregator?', 'Can the authors conduct additional ablation studies, such as investigating different modulation functions and types of aggregators?', 'Could the authors provide more visual examples to support the qualitative analysis?', 'Can the authors provide more details on the implementation of the TDC algorithm, particularly the dimension reduction step and the metrics used?', 'How does the performance of the TDC algorithm compare to other potential dimension reduction techniques?', 'Would it be possible to include more ablation studies varying the parameters and components of the TDC algorithm?', 'Could the authors provide more detailed explanations and possibly diagrams to make the TDC algorithm easier to follow?', 'Will the authors make the code available before the acceptance to facilitate reproducibility checks?']","['The paper could be clearer in its methodological explanations. Additionally, more baseline comparisons and earlier code availability would strengthen the paper.', 'The societal impact of the work could be elaborated upon, especially considering the use of VAEs in sensitive applications such as natural language generation.']",False,3,3,3,6,4,"['The paper addresses a significant and underexplored issue of latent holes in the latent space of VAEs, particularly for text generation.', ""The proposed TDC algorithm is novel and highly efficient for identifying latent holes, focusing on the decoder, which directly impacts the model's output quality."", 'Comprehensive empirical analysis is provided, investigating the impact of latent holes on text generation performance, their vacancy, and distribution.', 'The paper demonstrates strong correlations between the density of latent holes and VAE performance, providing valuable insights into the latent space structure.', 'The theoretical unification of two existing indicators for latent hole identification is a valuable contribution.']","['The clarity of the paper is lacking, particularly in the description of the algorithm and its components.', 'More detailed ablation studies are needed to solidify the claims.', 'The qualitative analysis would benefit from more examples.', 'The paper could benefit from additional baseline comparisons to strengthen its claims.', 'The code is not available during the review process for verification.']",3,3,3,4,Reject
SN2bkl9f69,"The paper presents a novel approach to text-to-image synthesis, introducing three key components: Multi-Tailed Word-level Initial Generation (MTWIG), Spatial Dynamic Memory (SDM), and Iterative Multi-Headed Mechanism (IMHM). The proposed MSMT-GAN shows significant improvements over the state-of-the-art on the CUB dataset and competitive performance on the COCO dataset.","['Can the authors provide more detailed explanations and visualizations for the Spatial Dynamic Memory (SDM) and Iterative Multi-Headed Mechanism (IMHM) components?', 'Can the authors include additional ablation studies to analyze the effects of different kernel sizes and aggregators in the MTWIG stage?', 'How does the proposed method perform on other datasets beyond CUB and COCO?', 'Can the authors discuss potential negative societal impacts, such as misuse of synthetic image generation?', 'What are the specific hyperparameters used in the experiments, and how were they chosen?', 'Can the authors provide more details on the computational cost and complexity of the proposed methods?']","['The paper does not discuss potential negative societal impacts, such as misuse of synthetic image generation.', 'The complexity and computational cost of the proposed methods are not thoroughly discussed.']",False,3,3,3,5,4,"['Addresses important limitations in existing text-to-image synthesis methods.', 'Introduces novel components such as MTWIG, SDM, and IMHM.', 'Shows significant improvements on the CUB dataset.', 'Comprehensive experiments and ablation studies.']","['The proposed method is complex, and the explanations of key components, especially SDM and IMHM, are not sufficiently clear.', 'Additional ablation studies are needed to fully validate the effectiveness of the proposed components.', 'The improvements on the COCO dataset are less pronounced, raising questions about the generalizability of the proposed method.', 'The paper does not discuss potential negative societal impacts or ethical considerations.', 'Lack of detailed explanations regarding the experimental setup, hyperparameters, and training settings hinders reproducibility.']",3,3,3,4,Reject
6ya8C6sCiD,"The paper proposes a novel architecture called symbolic mapping to help multi-agent systems learn a compositional and symmetric language. The idea is to evolve the language from simple tasks to more complex ones, using symbolic mapping as a foundational component. The experiments show that symbolic mapping aids in language learning and vocabulary expansion.","['Can the authors provide more detailed ablation studies to evaluate the impact of different components of the symbolic mapping architecture?', 'How does the symbolic mapping perform compared to other state-of-the-art methods in emergent communication?', 'Can the authors provide more examples and visualizations of the learned language to illustrate its compositionality and symmetry?', 'Can the authors provide more details on the experimental setup, including hyperparameters and training protocols?', 'What are the potential limitations and broader societal impacts of this research?', 'Are there any ethical concerns related to the proposed multi-agent systems and emergent communication?']","['The clarity of the paper needs significant improvement. Many sections are difficult to understand, and the methodology is not always clearly explained.', 'The experiments are not sufficiently comprehensive. More thorough ablation studies and comparisons with state-of-the-art methods are needed.', 'The paper does not adequately discuss the limitations of the proposed approach, such as its scalability to larger agent communities and more complex tasks.', 'The potential ethical concerns of using symbolic mapping in multi-agent communication should be addressed, especially in real-world applications.']",False,2,2,3,4,4,"['The paper addresses an important and challenging problem in multi-agent reinforcement learning: emergent communication and language learning.', 'The proposed symbolic mapping architecture is novel and has the potential to improve language properties like compositionality and symmetry.', 'The experimental framework is well-designed, including both simple and complex tasks to evaluate the effectiveness of the proposed method.']","['The paper lacks clarity in several sections, making it difficult to follow the overall methodology and results.', 'The experimental results are not sufficiently comprehensive. Additional ablation studies and comparisons with more baselines would strengthen the paper.', 'The impact of symbolic mapping on vocabulary expansion is not thoroughly analyzed. More detailed experiments and analysis are required.', 'The potential limitations and ethical concerns of the proposed approach are not adequately discussed.', 'Limited clarity and details on experimental setup, hyperparameters, and training protocols.']",3,2,2,3,Reject
1gEb_H1DEqZ,"The paper proposes a novel pre-training approach for language models, named PROPHET, which aims to enhance logical reasoning capabilities by using facts and logical graphs. The approach introduces three novel pre-training tasks: logical connectives masking, logical structure completion, and logical path prediction. The model is evaluated on various NLP benchmarks, showing improvements in tasks requiring logical reasoning.","['Please provide more details on how facts are extracted and logical graphs are constructed.', 'Can you include a more thorough ablation study to isolate the contributions of each component of your method?', 'How does your approach compare with other recent approaches that aim to enhance the reasoning capabilities of language models?', 'Can the authors provide more detailed explanations and examples of the fact extraction and logical graph construction process?', 'What are the computational requirements and scalability of the proposed method?']","['The paper lacks clarity in explaining the methodology, particularly in the extraction of facts and construction of logical graphs.', 'The experimental validation is not thorough, and the novelty is limited.', ""The paper does not sufficiently address the potential limitations and ethical considerations of the proposed approach. The reliance on external tools for fact extraction and logical graph construction may introduce biases or errors, which could impact the model's performance and fairness.""]",False,2,2,2,4,4,"['The idea of using facts and logical graphs for pre-training is interesting and has the potential to improve the logical reasoning abilities of language models.', 'The paper addresses a critical issue in NLP by focusing on enhancing logical reasoning capabilities in pre-trained language models.', 'The proposed pre-training tasks are well-motivated and target specific aspects of logical reasoning.', 'The paper provides a comprehensive set of experiments across different benchmarks to evaluate the proposed model.']","['The explanation of how facts are extracted and logical graphs are constructed is vague and lacks detail, making it hard to assess reproducibility.', 'The experimental validation is not entirely convincing. The paper lacks a thorough ablation study and does not compare with other recent approaches that enhance reasoning capabilities.', 'The novelty of the pre-training tasks is somewhat limited, as they are extensions or variations of existing techniques. The paper needs to better position itself within the existing literature and clearly highlight its unique contributions.', 'The methodology and pre-training details lack clarity, and some experimental choices are not well justified.', 'The paper does not adequately address potential limitations and ethical considerations, such as the reliance on external tools that may introduce biases or errors.']",3,2,2,3,Reject
qyTBxTztIpQ,"The paper presents CrowdPlay, a framework for collecting large-scale human demonstration data using crowdsourcing to advance research in imitation learning and offline reinforcement learning. The contributions include a crowdsourcing pipeline compatible with OpenAI Gym environments, a large dataset of human demonstrations in Atari 2600 games, and a detailed study of incentive mechanisms.","['How does the performance of AI agents trained using CrowdPlay data compare to those trained with synthetic data?', 'Can you provide more details on the technical challenges faced during the development of the pipeline and how they were overcome?', 'What are the specific metrics used to evaluate data quality, and how are they calculated?', 'How do the incentive mechanisms impact the behavior of participants, and what are the long-term effects of different incentive schemes?', 'Can you provide more details on how the real-time feedback mechanisms were implemented and their impact on participant behavior?', 'How do you plan to address the potential biases in the collected data, especially given the varied demographics and incentive structures?', 'What are the broader implications and potential applications of the CrowdPlay dataset beyond Atari 2600 games?', 'How do the authors address the variability in human performance when evaluating offline RL algorithms?', 'What measures are in place to ensure the ethical treatment of participants, especially in terms of fair compensation?', 'Can the authors provide more details on the technical implementation of the dataset engine and the real-time statistics engine?', 'How do the authors plan to address the unbalanced nature of some parts of the dataset in future work?', 'Can the authors elaborate on the ethical considerations and measures taken to ensure fair compensation and participant treatment?']","['Potential biases introduced by different recruitment channels need more discussion.', 'More depth needed in addressing ethical considerations around fair compensation.', ""The dataset's unbalanced nature and the need for more ablation studies on incentive structures and data quality metrics."", 'The variability in human performance could impact the quality and consistency of the dataset.', 'The effectiveness of the incentive structures in ensuring high-quality data is questionable.']",False,3,3,3,6,4,"['Innovative use of crowdsourcing for offline RL and IL data collection.', 'Extensive dataset with multimodal and multi-agent data.', 'Detailed study of incentive mechanisms and their impact on data quality.', 'Highly extensible framework that integrates well with existing RL environments.', 'Potential to significantly impact research in offline RL and imitation learning.']","['Lacks a thorough comparison with existing datasets.', 'Insufficient technical details on the pipeline and data quality control mechanisms.', 'Could benefit from additional ablation studies on incentive mechanisms.', 'Clarity and organization could be improved.', 'Concerns about data quality due to variability in human performance and incentive structures.', 'Potential ethical concerns related to fair compensation and participant exploitation.']",3,3,3,4,Accept
hxitw01k_Ql,"The paper investigates the impact of different memory architectures on learning performance in a POMDP setup, specifically focusing on a two-hypothesis testing problem. It compares Random Access Memory (RAM) and Memento Memory, showing that Memento Memory can achieve competitive performance despite its simplicity. The paper provides both theoretical analysis and empirical results.","['Can you provide rigorous proofs for the theoretical claims made in the paper?', 'Can you expand the empirical evaluation to cover more scenarios and validate the generality of the findings?', 'Can the authors provide more detailed explanations for some of the theoretical derivations, particularly those in Sections 3 and 4?', 'Can the authors extend the empirical evaluation to include more complex POMDPs and compare with additional baseline methods?', 'What are the practical implications of the findings? How can these insights be applied to more complex reinforcement learning tasks?', 'Can the clarity of the paper be improved by reducing technical density and providing more intuitive explanations?', 'How do the results generalize to more complex POMDPs?', 'Can the authors clarify the practical implications of their theoretical results?', 'Could the authors provide more details on how the empirical experiments were conducted?', 'What are the potential limitations and broader implications of these findings?']","['The paper does not provide rigorous proofs for its theoretical claims, which weakens its contributions.', 'The empirical results are limited and do not sufficiently validate the findings.', 'The study is limited to a very simple POMDP setup, which may not generalize well to more complex problems.', 'The empirical results are limited and computationally expensive.', 'The paper does not thoroughly discuss the practical limitations of the proposed memory architectures in real-world applications.']",False,2,2,2,4,4,"['Addresses an important problem of learning in POMDPs.', 'Explores the impact of memory architectures on learning performance.', 'Provides both theoretical analysis and empirical results.', 'Proposes novel insights into the performance of different memory architectures.']","['Theoretical claims are based on conjectures and lack rigorous proofs.', 'Empirical results are not comprehensive enough to support the generality of the findings.', 'The paper is dense and difficult to follow, particularly in the theoretical sections.', 'The practical significance of the findings is not well-established.', 'The problem setup is very simple, limiting the applicability of the results.', 'The paper does not adequately discuss the limitations and potential negative societal impacts of the work.']",3,2,2,2,Reject
RftryyYyjiG,The paper proposes a method for compressing pre-trained language models (PLMs) using tensor decomposition techniques. The authors introduce novel decomposition and reconstruction protocols to achieve significant parameter reduction and faster inference times while maintaining competitive performance on benchmarks like GLUE.,"['Can the authors clarify the detailed steps and configurations used in the tensor decomposition process?', 'How does the proposed method compare with other state-of-the-art compression techniques beyond those mentioned?', 'Can the authors provide a more detailed analysis of hardware configurations and their impact on the reported speed improvements?', 'Can the authors provide more visual aids or simplified explanations for the tensor decomposition methods and protocols?', 'Could the authors elaborate on the practical steps for integrating and deploying these compressed models in real-world applications?', 'How does the proposed method compare with other tensor decomposition techniques in terms of efficiency and effectiveness?', 'Have the authors considered testing the proposed methods on other types of PLMs beyond BERT?', 'How well does the method generalize to other types of models and tasks beyond those tested in the paper?']","['The complexity of the proposed method may limit its accessibility and reproducibility.', 'The paper lacks a thorough exploration of the ethical implications of the proposed work, particularly regarding its environmental impact.', 'The paper needs to improve the clarity of its explanations and provide a stronger theoretical foundation.', 'More comparisons with alternative techniques and evaluations on diverse datasets are necessary.', ""Further exploration of the method's generalizability to other models and tasks would be beneficial.""]",False,3,2,3,4,4,"['Addresses a significant problem related to the computational cost and carbon footprint of large-scale PLMs.', 'Proposes a novel approach using tensor decomposition to compress models effectively.', 'Provides empirical results showing competitive performance and improved inference speed.', 'The approach is shown to be orthogonal and complementary to existing compression methods like knowledge distillation.']","['Complex methodology with insufficient clarity, which may hinder reproducibility.', 'Limited comparison with a broader range of existing compression methods and alternative tensor decomposition techniques.', 'Speed improvement claims lack detailed hardware configuration analysis.', 'Insufficient theoretical foundation for the proposed methods.', 'Dense writing and difficult-to-follow sections, particularly in the methodology.', 'Need for more extensive evaluations on diverse datasets and PLMs.', 'Concerns about the generalizability of the method to other types of models and tasks beyond those tested in the paper.']",3,3,2,3,Reject
jNB6vfl_680,"The paper introduces a pruning technique combining Global Magnitude Pruning (GP) with a Minimum Threshold (MT) to prevent over-pruning. The method achieves state-of-the-art (SOTA) performance on various architectures and datasets, including ResNet-50 and MobileNet-V1 on ImageNet. The primary contribution is showing that GP, combined with a simple MT mechanism, is sufficient to achieve high performance without the need for complex pruning strategies.","['Can the authors provide a more detailed explanation of the autoencoder aggregator?', 'What is the theoretical justification for the effectiveness of GP and MT?', 'Can more recent pruning techniques be included in the comparative analysis?', 'How does the method perform on other complex architectures beyond those tested?', 'What are the limitations of the proposed method in real-world applications?', 'Can you provide more details on how the Minimum Threshold (MT) is determined and implemented?', 'How does the proposed method compare with more complex pruning techniques like reinforcement learning-based pruning in terms of both accuracy and computational cost?', 'What is the impact of different hyperparameters on the efficacy of the proposed method?', 'Can the authors explore ways to reduce the FLOPs while maintaining the performance gains?', 'Can you include additional visualizations to explain the pruning process and the impact of MT on different layers?']","['The paper lacks a theoretical foundation for its empirical results.', 'Reproducibility could be enhanced with more detailed instructions.', 'The method may not generalize well to all types of neural network architectures.', 'The simplicity of the modification might limit its impact compared to more sophisticated pruning techniques.', 'Higher FLOPs compared to some layer-wise baselines.']",False,3,3,3,6,4,"['The proposed method is simple and easy to implement.', 'Achieves state-of-the-art performance on multiple datasets and architectures.', 'Comprehensive ablation studies are provided to isolate the effects of GP and MT.', 'Shows generalization across different neural network architectures and datasets.', 'Open-source code provided for reproducibility.']","['The novelty is limited as magnitude-based pruning is not new.', 'The paper could be clearer in explaining some concepts, particularly the autoencoder aggregator and the exact mechanism of MT.', 'Lacks theoretical analysis to explain why GP and MT work so effectively.', 'Limited comparative baselines; could include more recent pruning techniques.', 'Reproducibility could be improved with more detailed instructions.', 'Higher FLOPs compared to some layer-wise baselines.']",2,3,3,3,Reject
Ih0iJBSy4eq,"The paper proposes reinforcement learning algorithms for finding Stackelberg-Nash Equilibria (SNE) in general-sum Markov games with leader-controlled state transitions. It introduces optimistic and pessimistic variants of least-squares value iteration for online and offline settings, respectively, and provides theoretical guarantees for sublinear regret and suboptimality.","['Can you provide empirical results to validate the theoretical claims?', 'How practical is the assumption of access to an oracle for solving multiple-follower matrix games?', 'Can the authors clarify and simplify the explanation of the algorithms, particularly the pessimistic and optimistic variants of least-squares value iteration?', 'What are the limitations of the proposed methods when the assumptions, such as leader-controlled transitions, are not strictly met?', 'How do the proposed methods compare with existing state-of-the-art methods?']","[""The paper's clarity could be improved, especially for readers not deeply familiar with the topic."", 'The practicality of the oracle assumption for solving matrix games with multiple followers needs to be addressed.', 'The paper does not adequately address the practical limitations and potential impacts of the assumptions made.', 'The lack of empirical results raises concerns about the applicability and robustness of the proposed methods.']",False,3,2,3,5,4,"['Addresses a significant and novel problem in multi-agent reinforcement learning.', 'Proposes new RL algorithms with theoretical guarantees for both online and offline settings.', 'Provides rigorous theoretical analysis, demonstrating sublinear regret and suboptimality bounds.', 'Incorporates function approximation for handling large state spaces.']","['The paper is dense with technical details, which can hinder clarity.', 'Lacks empirical experiments to validate theoretical claims.', 'Assumes access to an oracle for solving matrix games with multiple followers, which may not be practical.', 'No comparative analysis with existing state-of-the-art methods.']",3,3,2,3,Reject
N0n_QyQ5lBF,"The paper introduces a novel task of unsupervised vision-language (VL) grammar induction and proposes a method called CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all constituents. The proposed method leverages contrastive learning and multi-level fusion to achieve fine-grained alignment and improve performance. The paper introduces a new evaluation metric, CCRR, and demonstrates improvements over state-of-the-art methods on Flickr30k Entities and MSCOCO datasets.","['Can the authors provide more details on the autoencoder aggregator and the feature extraction process?', 'Can more qualitative examples be provided to strengthen the analysis?', 'Can the authors conduct more extensive ablation studies to isolate the effects of individual components?', 'How does the method generalize to other datasets or tasks beyond the ones tested?', 'What are the ethical considerations and potential negative societal impacts of your work?']","['The paper lacks clarity in certain components and could benefit from more extensive ablation studies.', 'Ethical considerations and potential negative societal impacts are not discussed.', ""The method's complexity and detailed mathematical formulations might affect its clarity.""]",True,3,2,3,5,4,"['The task of unsupervised VL grammar induction is novel and relevant.', 'The proposed method, CLIORA, effectively leverages contrastive learning and multi-level fusion.', 'The introduction of the new evaluation metric, CCRR, adds value.', 'Comprehensive experiments show improvements over state-of-the-art methods.']","['The clarity of certain components, such as the autoencoder aggregator and the specific details of the feature extraction process, is lacking.', 'The paper could benefit from more extensive ablation studies to isolate the effects of individual components.', 'Ethical considerations and potential negative societal impacts of the work are not discussed.', 'Some experimental results, particularly the qualitative analyses, could be more comprehensive.', ""The method's complexity might hinder reproducibility and practical application.""]",3,3,2,3,Reject
HiHWMiLP035,"The paper proposes E[2]CM, an early exit mechanism for neural networks that leverages class means without requiring gradient-based training. This method is particularly suitable for low-power devices and edge computing. The authors demonstrate the effectiveness of E[2]CM through comprehensive experiments on CIFAR-10, CIFAR-100, KMNIST, and MNIST datasets, showing significant improvements in computational efficiency while maintaining accuracy. The method is also extended to unsupervised learning tasks.","['Can the authors provide more details on the threshold optimization process using binary search?', 'What is the computational overhead introduced by E[2]CM in terms of FLOPs and memory usage?', 'How does E[2]CM perform on other datasets not included in the experiments?', 'Can the authors provide more examples or case studies for the unsupervised learning extension?', 'Can the authors provide more details on the autoencoder aggregator?', 'What is the performance of the proposed model with different types of aggregators and modulation functions?', 'Can more visualization cases be provided in the qualitative analysis?', 'What are the performance implications if the class means are calculated less frequently, e.g., every few layers instead of every layer?', 'Can the authors discuss the potential impact of E[2]CM on adversarial robustness? Are there any known limitations in this regard?', 'Can the authors provide more details about the autoencoder aggregator used in the experiments?', 'What is the impact of different types of aggregators on the performance of E[2]CM?', 'Can the authors include more qualitative analyses and visualizations in the rebuttal period to strengthen their claims?', 'Can the authors provide more details on how they selected the hyperparameters and the thresholds for the early exit?', 'What are the specific computational overheads introduced by the proposed method?', 'How does the method scale to larger datasets and models?']","[""The method's dependence on the quality of class means, which might not be robust across different datasets."", 'Potential issues with memory overhead due to storing class means for each layer, especially in large models.', 'The use of fixed thresholds may not generalize well across different datasets and models.', 'The paper does not discuss the potential impact on adversarial robustness and how E[2]CM might be affected by adversarial attacks.', 'There is no discussion on the memory footprint of storing class means and whether this could be a limitation in resource-constrained environments.', 'The potential computational overhead and scalability to larger datasets and models are not thoroughly discussed.', 'The paper does not adequately address potential negative societal impacts.']",False,3,3,3,5,4,"['The proposed method is novel and does not require gradient-based training, making it suitable for low-power devices.', 'E[2]CM shows promise in both supervised and unsupervised learning settings.', 'The method can be easily integrated with existing early exit mechanisms to improve performance.', ""Comprehensive experiments are conducted on multiple datasets and models, showcasing the method's effectiveness.""]","['The paper lacks clarity in its explanation of some technical details, particularly the binary search for threshold optimization and the exact computational overhead involved.', 'The comparison with other methods under a fixed training budget could be more comprehensive, including more recent advancements.', 'The experiments on unsupervised learning are less detailed compared to the supervised learning experiments, raising questions about the generalizability of the results.', 'The paper does not provide a thorough analysis of potential limitations and failure cases of the proposed method.', 'Certain aspects of the methodology, such as the autoencoder aggregator, are not described in enough detail.', 'The paper could benefit from more qualitative analyses and visualizations to strengthen the claims made.', 'The experimental results could be more comprehensive, including additional baselines and scenarios.']",3,3,3,4,Reject
GQd7mXSPua,The paper introduces a meta-learning approach for predicting class-specific covariance matrices using an attentive set encoder and proposes an energy-based inference procedure for better uncertainty calibration and out-of-distribution detection. The method is validated through comprehensive experiments on benchmark datasets.,"['Can the authors provide more details about the autoencoder aggregator?', 'Can the authors perform additional ablation studies, such as investigating different modulation functions and types of aggregators?', 'Can you provide more details about the set encoder architecture and the specific hyperparameters used in the experiments?', 'How does the performance change with different numbers of rank factors in the covariance matrices?', 'How sensitive is the model to the choice of the set encoder architecture?', 'Can the authors provide more convincing empirical validation of the proposed energy-based inference procedure?', 'Can you provide more detailed explanations and derivations for the key mathematical formulations?', 'Can you include more qualitative results to better understand the behavior of the model?', 'Can you conduct more extensive ablation studies to investigate the impact of different components of the model?']","['The clarity of the paper could be improved, and additional ablation studies are needed to fully understand the contribution of each component.', 'The paper does not adequately discuss the computational cost of the proposed method and its applicability to real-world scenarios. It would be helpful to include a discussion on these aspects.', 'The evaluation and comparisons could be more extensive.', 'More detailed ablation studies are needed to understand the impact of different components.']",False,3,3,3,5,4,"['Addresses a significant issue in meta-learning: task heterogeneity.', 'Proposes a novel approach for meta-learning class-specific covariance matrices.', 'Comprehensive experiments and comparisons with various baselines.', 'Detailed analysis and discussion of results.']","['The explanation of the methods, especially the autoencoder aggregator, lacks clarity.', ""Additional ablation studies could enhance the understanding of the model's components."", 'Qualitative analysis would benefit from more visualization cases.', 'The paper is dense and could benefit from better organization and clarity.', 'Some sections are difficult to follow, and the notations are inconsistent.', 'The presentation of experimental results is scattered and could be more structured.', 'Lacks sufficient details for reproducibility.', 'Does not adequately discuss the limitations and potential negative societal impacts.']",3,3,3,4,Reject
vr39r4Rjt3z,"The paper proposes two architectural modifications, Masked Highway Connection (MHC) and Layer-Wise Normalization (LWN), to reduce catastrophic forgetting in neural networks during continual learning. The authors demonstrate these modifications' effectiveness through extensive experiments across several datasets and continual learning scenarios.","['Can you provide more detailed explanations and visual aids to clarify the architecture and implementation of MHC and LWN?', 'Can you conduct additional ablation studies to isolate the contributions of each component?', 'Can you provide more qualitative analysis to support the quantitative results?', 'Can you discuss potential limitations and negative societal impacts of the proposed methods?', 'How do different values of K in MHC affect performance?', 'Can the authors compare their methods with more existing techniques that also focus on architectural modifications?', 'Have you tested the proposed methods on non-image datasets to validate their generalizability?']","['The paper needs more clarity in explaining the architectural modifications and their implementation. Additionally, the paper could benefit from more ablation studies and qualitative analysis. Potential limitations and negative societal impacts are not sufficiently addressed.', 'The primary limitation is the lack of clarity and detail in the explanation of the proposed architectural modifications. Another limitation is the narrow focus on image datasets, which could limit the perceived generalizability of the methods. Finally, the ablation studies provided are not thorough enough to isolate the specific contributions of MHC and LWN.']",False,3,3,3,5,4,"['The paper addresses the critical problem of catastrophic forgetting in continual learning.', 'The proposed architectural modifications are novel and theoretically grounded.', 'Extensive experiments show the effectiveness of the proposed methods across multiple datasets and settings.', 'The methods are compatible with existing continual learning techniques, enhancing their performance.']","['The paper lacks clarity in explaining the architecture and implementation details of MHC and LWN. More visual aids and detailed explanations are needed.', 'The paper could benefit from additional ablation studies to better understand the contributions of each component.', 'There is a need for more qualitative analysis to support the quantitative results.', 'The paper does not sufficiently address potential limitations and negative societal impacts.', 'The evaluation is primarily focused on image datasets, which raises concerns about the generalizability of the findings.', 'The paper compares its results with baseline methods but lacks a thorough comparison with the latest state-of-the-art methods.']",3,3,3,4,Reject
EhYjZy6e1gJ,"The paper 'PICO: Contrastive Label Disambiguation for Partial Label Learning' introduces a novel framework to address the challenge of partial label learning (PLL) by combining contrastive learning with a prototype-based label disambiguation strategy. The method, termed PiCO, aims to produce closely aligned representations for examples from the same classes and facilitate label disambiguation. The paper provides extensive experiments demonstrating that PiCO outperforms state-of-the-art approaches in PLL and achieves results comparable to fully supervised learning. The theoretical contributions are justified from an expectation-maximization (EM) algorithm perspective.","['Can you provide more details on the prototype-based label disambiguation algorithm, especially the moving-average style formula and its impact on the training process?', 'How does the choice of data augmentation techniques affect the performance of the contrastive learning module?', 'Have you compared your method with other noise-robust learning frameworks outside the PLL domain?', 'Can the authors provide more details about the autoencoder aggregator used in the prototype-based label disambiguation?', 'Can the authors conduct additional ablation studies to explore the impact of different components, such as the modulation function and types of aggregators?', 'What is the impact of different types of aggregators and modulation functions on the performance of PiCO?', 'How does the method perform under different data generation processes, such as non-uniform label flipping probabilities?', 'Have you considered the applicability of your method to tasks other than image classification? If so, what were the findings?']","['The paper could benefit from a clearer description of the proposed algorithms and their integration. Additionally, a more thorough comparison with a broader set of baseline methods would strengthen the claims.', 'The clarity of the paper can be improved by providing more details about the autoencoder aggregator and conducting additional ablation studies.', 'The robustness of the method under different data generation processes needs more exploration.', 'The paper does not explore the applicability of PiCO to tasks beyond image classification, which limits the generalizability of the proposed method.', 'The theoretical justifications could be expanded with more accessible explanations to benefit a broader audience.']",False,3,4,4,7,4,"['The paper addresses a significant problem in PLL with a novel approach that combines contrastive learning and prototype-based label disambiguation.', 'Extensive experimental evaluation demonstrates significant improvements over state-of-the-art methods on multiple datasets.', 'The theoretical justification using the EM algorithm perspective is sound and adds depth to the contribution.', 'The paper is well-written and organized, making the methodology and theoretical insights clear.']","['The explanation of the prototype-based label disambiguation and its integration with contrastive learning could be clearer. Specifically, more details on the algorithmic steps and hyperparameter choices would be beneficial.', 'The paper lacks a thorough comparison with methods outside the immediate PLL domain that might handle label noise or ambiguity differently.', 'Some ablation studies are missing, such as the effect of different types of data augmentations used in contrastive learning.', 'The robustness of the proposed method under different data distributions and noise levels could be explored further.', 'The applicability of the proposed method to tasks beyond image classification is not explored.']",3,3,4,4,Reject
OCgCYv7KGZe,"The paper proposes Auto-Encoding Inverse Reinforcement Learning (AEIRL), which models the reward function as an auto-encoder to improve robustness and scalability in IRL. The method uses the reconstruction error of the auto-encoder as the reward signal, which is more informative compared to the binary logistic loss used in existing methods. Extensive experiments show that AEIRL outperforms state-of-the-art methods in the MuJoCo environments, especially in the presence of noisy expert demonstrations.","['Can you provide more details on the architecture of the auto-encoder used in AEIRL?', 'How does the choice of the reconstruction error (e.g., mean square error vs. other metrics) impact the performance of AEIRL?', 'Can you include more ablation studies to dissect the contributions of different components in the method?', 'How does AEIRL perform on tasks beyond MuJoCo environments?', 'Can you provide more detailed theoretical justification for using auto-encoder reconstruction error as a reward signal?', 'How does the performance of AEIRL vary with different types of noise in expert demonstrations?', 'Can you provide additional qualitative results, such as visualizations of the learned policies or comparisons of state-action distributions?', 'What are the computational costs associated with training the auto-encoder in AEIRL?', 'How does AEIRL handle extremely noisy data, and what are its limitations in such scenarios?']","['The paper should address the clarity of the auto-encoder architecture and provide more detailed ablation studies.', 'It should also consider the potential limitations of AEIRL in different types of tasks or environments.', 'The paper does not adequately address the limitations of the proposed method or its potential negative societal impacts. For example, how does the method handle extremely noisy data, and what are the computational costs associated with the auto-encoder training?']",False,3,2,3,5,4,"['The use of auto-encoders for reward modeling in IRL is a novel and interesting approach.', 'The method demonstrates robustness to noisy expert demonstrations, a significant improvement over existing methods.', 'Extensive experiments on various MuJoCo tasks validate the effectiveness of the proposed approach.', 'The paper includes detailed ablation studies and comparisons with state-of-the-art methods.']","['The clarity of the paper could be improved, particularly in explaining the auto-encoder architecture and the training process.', 'More detailed ablation studies are needed to understand the impact of different components, such as the choice of auto-encoder and the specific reconstruction error used.', 'The paper could benefit from additional qualitative analysis and visualizations to better illustrate the improvements of the proposed method.', 'The theoretical justification for using auto-encoder reconstruction error as a reward signal is not well-developed.', 'The experiments, while extensive, lack diversity in tasks beyond MuJoCo environments, which may limit the generalizability of the results.', 'There is insufficient analysis of the limitations and potential negative societal impacts of the proposed method.']",3,3,2,3,Reject
LtKcMgGOeLt,"The paper 'When Vision Transformers Outperform ResNets Without Pre-training or Strong Data Augmentations' explores the use of a sharpness-aware minimizer (SAM) to improve the performance of Vision Transformers (ViTs) and MLP-Mixers. The authors provide comprehensive experiments and analysis, showing that SAM leads to substantial improvements in both accuracy and robustness without the need for large-scale pre-training or strong data augmentations.","['Can the authors provide more details on the specific configurations of SAM used in the experiments?', 'How does the performance of SAM compare to other regularization techniques when applied to ViTs and MLP-Mixers?', 'Can the authors include more real-world application scenarios to demonstrate the practical impact of their findings?', 'What are the practical implications of the 2x computational overhead of SAM in real-world applications?', 'Could the authors provide more in-depth analysis on why SAM works better for ViTs and MLP-Mixers compared to ResNets?', 'What are the potential negative societal impacts of the proposed method?']","['The increased computational cost due to SAM, as it requires an additional round of forward and backward propagation.', 'The effectiveness of SAM diminishes as the training dataset becomes larger, indicating a need for further optimization in large-scale scenarios.', 'The paper lacks detailed ablation studies on the impact of different SAM perturbation strengths on various architectures.', 'The potential negative societal impacts of the proposed method are not discussed.']",False,3,3,3,6,4,"['The application of SAM to ViTs and MLP-Mixers is novel and provides significant improvements.', 'Comprehensive experimental evaluations across various tasks, including supervised, adversarial, contrastive, and transfer learning.', 'Detailed analysis of loss landscapes and Hessian matrices to support the findings.', 'The results show that ViTs can outperform ResNets of similar size and throughput, which is valuable for the research community.']","['The paper could benefit from additional ablation studies, particularly regarding the effects of different SAM parameters and configurations.', 'Some sections involving mathematical formulations are not very clear and could be better explained.', 'The computational overhead of SAM (approximately 2x) is a significant limitation that is not thoroughly addressed in the paper.', 'The paper is dense and complex, which may make it less accessible to readers not deeply familiar with the subject.']",3,3,3,4,Accept
zz9hXVhf40,The paper examines various design choices in offline model-based reinforcement learning (MBRL) and proposes a novel evaluation protocol to compare different uncertainty penalties. The authors demonstrate that selecting key hyperparameters using Bayesian Optimization can lead to significant performance improvements.,"['Can the authors provide additional ablation studies to explore the impact of different design choices in more detail?', 'Can the authors improve the clarity of the methodology, especially regarding the use of hyperparameters and Bayesian Optimization?', 'Can the authors provide more details on the implementation differences between their code and the code from previous works (e.g., MOPO, MOReL)?', 'Can the authors provide more detailed hyperparameter settings and implementation details to improve the reproducibility of the experiments?']","['The paper lacks detailed ablation studies to fully explore the impact of different design choices.', 'The clarity of the methodology, especially regarding the use of hyperparameters and Bayesian Optimization, could be improved.', ""The paper should provide more details on the implementation differences between the authors' code and the code from previous works (e.g., MOPO, MOReL)."", 'There are concerns about the reproducibility of the experiments due to the lack of detailed hyperparameter settings and implementation details.', 'The computational cost of Bayesian Optimization and implementation challenges in resource-constrained environments are not discussed.', 'The paper primarily focuses on specific benchmarks and does not explore a wider range of environments, which might limit the generalizability of the results.']",False,3,3,3,6,4,"['Addresses an important issue in offline MBRL: the selection of uncertainty penalties and key hyperparameters.', 'Proposes a novel evaluation protocol that provides valuable insights into the effectiveness of different design choices.', 'Provides comprehensive experimental results, including comparisons with state-of-the-art methods and detailed analysis of the impact of different hyperparameters.', 'Demonstrates significant empirical improvements using Bayesian Optimization.']","['The paper could benefit from additional ablation studies to explore the impact of different design choices in more detail.', 'The clarity of the methodology, especially regarding the use of hyperparameters and Bayesian Optimization, could be improved.', ""The paper should provide more details on the implementation differences between the authors' code and the code from previous works (e.g., MOPO, MOReL)."", 'There are concerns about the reproducibility of the experiments due to the lack of detailed hyperparameter settings and implementation details.']",3,3,3,3,Accept
bsycpMi00R1,"The paper proposes a new gradient dynamics, Natural Hidden Gradient (NHG), designed for Hidden Convex-Concave (HCC) games, including GANs. The authors present global convergence results and analyze the dynamics under Fisher information geometry. Experimental results on synthetic data and GANs are provided.","['Can the authors provide more detailed experimental results, possibly on more complex and real-world datasets?', 'Can the authors clarify and elaborate on the practical implications of Assumption 2?', 'How does the proposed NHG dynamics scale with larger models and datasets? Are there any observed limitations?', 'Can the authors provide more intuitive explanations and diagrams to enhance the clarity of the theoretical sections?', 'Are there plans to extend the empirical validation to more complex and larger-scale experiments?', 'How do the authors address the scalability issues mentioned in the discussion section, particularly the tensor pseudo-inversion step?', 'Can the authors provide more detailed discussion on the practical implications and limitations of the proposed NHG dynamics?', 'How does the proposed approach compare with existing methods in more extensive experimental settings?', 'Can the authors provide more examples and visualizations to aid understanding of the concepts and results?', 'Can the authors provide more extensive empirical evaluations, especially on larger datasets and more complex models?', 'How can the computational feasibility of NHG dynamics be improved for large-scale applications? Are there any heuristic approaches or approximations that can be applied?']","['The paper could benefit from a more extensive experimental evaluation on real-world datasets to better demonstrate the practical applicability and scalability of the proposed method.', 'The clarity of the methodology section needs improvement for better comprehension.', 'The scalability of NHG dynamics to large neural networks remains a significant limitation. While the paper acknowledges this, it does not provide a concrete solution.', 'The empirical evaluation is limited, serving as a proof-of-concept rather than a thorough validation of the proposed method.']",False,3,3,3,6,4,"['The paper addresses an important problem in game-theoretic formulations in ML, specifically the convergence in non-convex non-concave games.', 'The proposed NHG dynamics are novel and the theoretical analysis is comprehensive, providing global convergence guarantees.', 'The paper includes experimental results that demonstrate the proposed method’s potential benefits.']","['The experimental section is limited and may not convincingly demonstrate the practical applicability of NHG dynamics in real-world scenarios.', 'The clarity of the paper, especially in the methodology section, could be improved to make it more accessible to a broader audience.', 'Some theoretical assumptions and conditions (e.g., Assumption 2) are not practically verified or discussed in detail, which might limit the real-world applicability.', 'The paper is very dense and mathematically complex, which might limit its accessibility to a broader audience.', 'The empirical validation is limited and mainly serves as a proof-of-concept. More extensive experiments on real-world datasets and larger models would strengthen the paper.', 'There is a lack of discussion on the practical implications and scalability of the proposed method, particularly for large-scale neural networks.']",3,3,3,3,Reject
WN2Sup7qLdw,"The paper proposes Multi-Resolution Continuous Normalizing Flows (MRCNF), an enhancement of Continuous Normalizing Flows (CNFs) by incorporating a multi-resolution strategy. This approach aims to achieve comparable likelihood values with significantly fewer parameters and less training time. The key contributions include a multi-resolution transformation that does not add to the log-likelihood cost and the introduction of MRCNF for efficient image generation and density estimation.","['Can the authors provide more detailed ablation studies to isolate the contributions of the multi-resolution transformation and the use of CNFs?', 'Could the authors clarify the implementation details of the autoencoder aggregator and the multi-resolution noise?', 'Can the authors provide more visual examples of generated samples and compare their quality with those from state-of-the-art methods?', 'What are the detailed empirical results supporting the claims about reduced training time and computational efficiency?', 'Could the authors provide more details on the specific architectural choices for the CNFs at each resolution level?', 'How does the visual quality of the generated images compare to other models, especially GANs, in terms of metrics like FID or human evaluation?', 'How does the proposed model perform on other datasets, and are there any limitations observed in these cases?', 'Can the authors clarify the derivation of the transformation matrix M and its implications on the overall model performance?', 'What are the limitations of the proposed method, and how can they be addressed in future work?', 'Can the authors provide more extensive validation on higher resolution datasets?', ""How does the unimodular transformation impact the model's performance on OoD detection compared to standard CNFs?"", 'Could the authors expand on the architectural details and hyperparameters used?']","['The current evaluation primarily focuses on bits-per-dimension (BPD) and does not thoroughly assess the quality of generated samples, which is crucial for generative models.', 'The paper could be clearer in explaining the implementation details of some components, which might affect reproducibility.', 'The paper mentions that the visual quality of generated images is not the primary focus, which might limit its applicability in tasks where high-quality image generation is crucial.', 'The approach may require complex implementation and tuning of multiple CNFs, which could be a barrier for practical adoption.', 'The societal impact of the work is briefly mentioned, but more detailed discussion on the ethical implications and potential misuse of the technology would be beneficial.', 'The focus on low-resolution datasets limits the generalizability of claims regarding higher resolutions.', 'The OoD detection section could be more robust and thorough.']",False,3,3,3,5,4,"['The introduction of multi-resolution in CNFs is novel and addresses some limitations of existing models.', 'The proposed method shows promise in reducing the number of parameters and training time while maintaining comparable performance.', 'The paper provides a solid theoretical foundation and the derivation of a unimodular transformation that preserves volume and range.']","['The paper lacks detailed ablation studies to isolate the contributions of each component of the proposed method.', 'Some explanations, particularly regarding the autoencoder aggregator and the multi-resolution noise, are not very clear.', 'The paper could benefit from a more thorough analysis of the quality of generated samples, including more visual examples and comparisons with state-of-the-art methods.', 'Claims about training time and computational efficiency need more empirical evidence.', 'The clarity of some sections, particularly the mathematical derivations and the transformation matrix, could be improved for better readability and understanding.', 'The experimental results focus primarily on log-likelihood (BPD) and do not provide as much insight into the visual quality of generated images compared to other generative models like GANs.', 'The novelty of the approach may be limited as it builds incrementally on existing methods like WaveletFlow and CNFs.', 'The results, while promising, lack comprehensive comparative studies (e.g., ablation studies) to fully validate the impact of each design choice.', 'The paper does not fully address the potential limitations of the proposed method, such as its applicability to different types of image datasets or the impact of the transformation matrix M on performance.']",3,3,3,3,Reject
ExJ4lMbZcqa,"The paper 'Learning Audio-Visual Dereverberation' introduces a novel method for speech dereverberation by leveraging visual information about the environment. The authors propose an end-to-end approach called VIDA, which integrates a Visual Acoustics Network (VAN) and a multi-modal UNet for dereverberation. The paper also presents a new dataset combining audio-visual data in 3D environments and demonstrates significant improvements over baseline models in speech enhancement, recognition, and speaker verification tasks.","['Can the authors provide more details on the architecture and training of the Visual Acoustics Network (VAN)?', 'How does the performance of the proposed method vary with different hyperparameters?', 'Can the authors conduct more extensive ablation studies to evaluate the impact of different components of the VAN?', 'What are the potential failure cases of the proposed method?', 'How does the proposed model handle cases where the visual information is partially or completely occluded?', 'What measures are in place to address potential ethical concerns regarding the use of visual data for audio processing?']","['The paper does not discuss the limitations of the proposed method, such as its performance in extremely reverberant environments or with highly occluded visual scenes.', 'The impact of different room materials and geometries on the performance of the method is not explored.', 'Potential ethical concerns related to the use of visual data for audio processing are not sufficiently addressed.']",True,3,2,3,6,4,"['The integration of visual information for audio dereverberation is a novel and impactful idea, addressing a significant challenge in speech enhancement.', 'The proposed VIDA model shows substantial improvements over state-of-the-art audio-only models across multiple tasks.', 'The creation of a new dataset that combines audio-visual data in realistic 3D environments is a valuable contribution to the community.', 'The approach demonstrates potential applications in various fields, such as teleconferencing, assistive hearing devices, and video indexing.']","['The paper lacks clarity in the methodological details, particularly regarding the Visual Acoustics Network (VAN) and its integration with the UNet.', 'More extensive ablation studies are needed to isolate the contributions of different components of the VIDA model.', 'The real-world data used for evaluation is limited in size and diversity, which raises concerns about the generalization of the results.', 'The paper does not address potential limitations and failure cases of the proposed method.', 'Potential ethical concerns related to the use of visual data for audio processing are not sufficiently addressed.']",4,3,2,4,Reject
xtZXWpXVbiK,"The paper proposes the FlOw-based Recurrent BElief State model (FORBES), which incorporates normalizing flows into variational inference to learn flexible belief states for POMDPs. This approach aims to overcome the limitations of Gaussian approximations in existing methods. The paper demonstrates the effectiveness of FORBES through experiments on visual-motor control tasks and a digit writing task, showcasing improved performance and sample efficiency.","['Can the authors provide more details on the autoencoder aggregator and its role in the model?', 'What is the impact of varying the number of layers in the normalizing flow on the performance?', 'Can the authors justify the choice of normalizing flow type and its configurations more thoroughly?', 'Can the authors provide additional ablation studies to validate the necessity and impact of each component, particularly the choice of normalizing flow and alternative aggregation methods?', 'Can the authors provide more qualitative examples, especially in the form of visualizations, to strengthen the claims regarding the superiority of the proposed method?', 'Can the authors provide more detailed derivations of the mathematical expressions, particularly those related to the ELBO?', 'Could the authors clarify the architecture of the networks used in their experiments and provide more details on hyperparameters?', 'Can the authors include additional ablation studies to better understand the impact of the different components of FORBES?', 'Are there any potential ethical implications or societal impacts of this work that the authors have considered?', 'Could you provide more details on the hyperparameter selection process and specific configurations used in the experiments?', 'Can you clarify the computational complexity and scalability of FORBES compared to existing methods?']","['The clarity of the paper could be improved by providing more detailed explanations of the components and their interactions.', 'The paper could benefit from additional ablation studies to fully understand the impact of different components and hyperparameters.', 'Details about the network architecture and hyperparameters are somewhat sparse, which may hinder reproducibility.', 'Theoretical contributions could be better highlighted, especially in comparison to existing methods regarding computational complexity and scalability.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,6,4,"['The paper addresses a significant limitation in current POMDP solutions by introducing a more flexible belief state representation.', 'The use of normalizing flows to capture complex belief distributions is novel and well-motivated.', 'The experimental results are comprehensive, including ablation studies and comparisons with state-of-the-art methods.', 'Theoretical contributions are provided, supporting the proposed method.']","[""The paper's clarity could be improved, especially in the explanation of the model components and their interactions."", 'The necessity and impact of certain components, such as the specific type of normalizing flow used, are not fully justified.', 'Some parts of the methodology, like the autoencoder aggregator and its specific implementation details, are underexplained.', 'Additional ablation studies, e.g., varying the number of layers in the normalizing flow, could strengthen the evaluation.', 'Details about the network architecture and hyperparameters are somewhat sparse, which may hinder reproducibility.', 'Theoretical contributions could be better highlighted, especially in comparison to existing methods regarding computational complexity and scalability.']",4,3,3,4,Reject
-29uFS4FiDZ,The paper proposes a method to distill multiple word senses from a pre-trained language model (BERT) using a two-stage process. The method aims to improve non-contextual word embeddings' performance in handling polysemy by leveraging BERT's contextual information. The approach involves extracting a distribution over word senses from BERT and transferring this information to multi-sense embeddings in a skip-gram-like framework. The paper demonstrates state-of-the-art or competitive performance on contextual word similarity and word sense induction tasks and shows the benefits of the multi-sense embeddings in a downstream task (topic modeling).,"['Can the authors provide more details on the autoencoder aggregator used in the model?', 'How does the performance change when using different types of aggregators?', ""Can the authors give more examples and visualizations to illustrate the multi-sense embeddings' effectiveness?"", 'What is the impact of varying the number of senses per word on the performance of the proposed model?', 'How does the performance of the proposed model change if a smaller, more resource-efficient contextual model than BERT is used?', 'Could the authors include more ablation studies to highlight the contributions of various components of the proposed method?', 'What are the contributions of each component (e.g., attention mechanism, knowledge distillation) to the overall performance? Detailed ablation studies would be helpful.', 'How does the proposed method compare with other state-of-the-art multi-sense embedding methods in terms of computational efficiency and scalability?']","['The paper could expand the discussion on potential limitations, such as the computational cost of training the BERT model initially and its impact on resource-constrained systems.', 'The authors should also discuss any potential negative societal impacts of their work, although none are immediately apparent.', 'The over-reliance on BERT for training might limit the applicability in truly resource-constrained environments.', 'Potential negative societal impacts, such as biases in sense embeddings inherited from BERT, are not addressed.']",False,3,2,3,5,4,"['Addresses the practical problem of polysemy in non-contextual embeddings, which is significant for resource-constrained systems.', 'The proposed method for transferring contextual information from BERT to multi-sense embeddings is novel and well-motivated.', 'Comprehensive experimental evaluations demonstrating the effectiveness of the proposed method on several benchmarks.', 'The downstream application in topic modeling highlights the practical utility of the multi-sense embeddings.']","['Certain sections, particularly the detailed methodology and the autoencoder aggregator, could be clearer to aid reproducibility.', 'The paper could benefit from additional ablation studies, such as experimenting with different types of aggregators and modulation functions.', 'More qualitative examples and visualizations could strengthen the argument and provide better insights into how the model handles polysemy.', 'The novelty of the approach might be questioned as it builds heavily on existing work on knowledge distillation and multi-sense embeddings.', 'The paper does not adequately address the limitations and potential negative societal impacts of their work.']",3,3,2,3,Reject
TNxKD3z_tPZ,"The paper proposes a novel method to estimate the generalization error of neural networks using Persistent Homology (PH) without the need for a validation set. By analyzing the PH diagram distances between consecutive neural network states, the authors claim that the method correlates with validation accuracy across several datasets and models.","['Can the authors provide more details on the exact computation of PH distances?', 'How does the method scale with larger models and datasets? Are there any potential optimizations to improve scalability?', 'Can the authors provide more intuitive explanations and visual aids to make the methodology clearer?', 'What theoretical justifications or insights can be provided to explain the observed correlation between PH distances and generalization?', 'How does this method compare to other existing techniques for estimating generalization error without a validation set?']","['The method is computationally demanding and may not scale well to larger models.', 'The empirical validation is limited to relatively small datasets and models.', 'The clarity of the paper needs significant improvement.']",False,2,2,2,4,4,"['The use of Persistent Homology to estimate generalization error is novel and addresses a significant problem in machine learning.', 'The potential to estimate generalization without a validation set could have practical implications.', 'Empirical results show a high correlation between PH distances and validation accuracy across multiple datasets and architectures.']","['The paper lacks clarity in several methodological aspects, such as the computation of PH distances.', 'The empirical validation is limited to relatively small models and datasets, raising concerns about the generalizability of the findings.', 'The method is computationally intensive, which may limit its practical applicability.', 'The paper is difficult to follow due to dense mathematical descriptions and lack of intuitive explanations and visual aids.']",3,2,2,3,Reject
AS0dhAKIYA0,"The paper proposes a method to enhance the interpretability of Machine Reading Comprehension (MRC) models by using Semantic Role Labeling (SRL) to capture predicate-argument relations. The approach involves creating semantic role relation tables that integrate entity names to establish semantic relationships between sentences. Experiments on the HotpotQA dataset demonstrate the method's performance and stability, even with limited training data.","['Can the authors provide a more detailed explanation of the methodology, including the construction and use of semantic role relation tables?', 'How does the performance of the proposed method compare to state-of-the-art MRC models on the HotpotQA dataset?', 'Can the authors conduct additional ablation studies to evaluate the contributions of different components of the proposed method?', 'How generalizable is the proposed method to other datasets or domains that may not have well-defined semantic roles or entity names?', 'What specific aspects of the method lead to the claimed performance improvements?', 'Have the authors conducted a thorough comparison with more recent and relevant baselines?', 'What specific steps are taken to ensure the interpretability claims are valid and reliable?']","[""The main limitations are the complexity and lack of clarity in the methodology, the absence of comparisons with state-of-the-art techniques, and the reliance on predefined semantic roles and entity names, which may affect the method's generalizability."", 'The potential negative societal impacts, such as biases in the SRL toolkits or the interpretability of the model in different contexts, are not discussed.']",False,2,2,2,3,4,"['The paper addresses the important issue of interpretability in MRC models, which is crucial for real-world applications.', 'The use of SRL to capture predicate-argument relations is a novel approach to improving the interpretability of MRC models.', 'The proposed method shows stable performance even with a small amount of training data, which is valuable for low-resource scenarios.']","['The methodology is complex and not clearly explained, making it difficult for readers to fully understand the approach.', 'The experimental results are not compared to state-of-the-art techniques, making it hard to assess the effectiveness of the proposed method.', 'The paper lacks comprehensive ablation studies to thoroughly evaluate the contributions of different components of the method.', 'The proposed approach relies heavily on predefined semantic roles and entity names, which may limit its generalizability to other datasets or domains.', 'The paper is not well-organized, and there are grammatical issues and typos.', 'The practical impact of the method is questionable given the marginal performance gains.']",2,2,2,2,Reject
qTHBE7E9iej,"The paper introduces Hierarchical Latent Mixtures of Skills (HeLMS), a novel approach for learning transferable motor skills using a three-level hierarchy of discrete and continuous latent variables. The method is evaluated on various manipulation tasks, demonstrating improved sample efficiency and performance in transfer scenarios, including new tasks, unseen objects, and state-to-vision policies.","['Can the authors provide more details on the network architectures and training procedures?', 'Have the authors considered applying the method to other domains beyond manipulation tasks?', 'Can the authors provide additional ablation studies to further dissect the contributions of different components?', 'Can the authors provide more detailed explanations and possibly some simplifications to make the methodology section more accessible?', 'Can the authors compare their method with more recent baselines to provide a more comprehensive evaluation?', 'Can the authors include some real-world experiments to strengthen the claims of real-world applicability?']","['The paper lacks some details on the network architectures and training procedures.', ""The method's applicability to other domains beyond manipulation tasks is not discussed."", 'The paper focuses on simulated environments, which limits the claims of real-world applicability.', 'The methodology section is dense and sometimes difficult to follow.']",False,3,3,3,6,4,"['Novel approach combining discrete and continuous skill representations.', 'Comprehensive experimental evaluation on multiple transfer scenarios.', 'Detailed analysis of the learned skills and their benefits.', 'Addresses a significant problem in reinforcement learning and robotics: learning reusable and adaptable skills.', 'Well-organized and clearly written, making the methodology and results easy to follow.']","['The paper could benefit from additional ablation studies to further dissect the contributions of different components.', 'Some details about the network architectures and training procedures could be more clearly presented.', ""The method's applicability to other domains beyond manipulation tasks is not discussed."", 'The paper is dense and sometimes difficult to follow, especially in the methodology section.', 'The choice of baselines is reasonable, but it would be beneficial to include more recent methods for a more comprehensive comparison.', 'The paper focuses on simulated environments. Including some real-world experiments would significantly strengthen the claims of real-world applicability.']",3,3,4,4,Accept
vEIVxSN8Xhx,"The paper proposes a novel log-polar space convolution (LPSC) method, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. This method aims to increase the receptive field while maintaining the number of parameters. The authors show that LPSC can be implemented with conventional convolution via log-polar space pooling and can be applied in any network architecture to replace conventional convolutions. Experimental results on different tasks and datasets demonstrate the effectiveness of the proposed LPSC.","['Can the authors provide a more thorough theoretical analysis of why the proposed LPSC method works better than existing methods?', 'Can the authors provide a detailed ablation study on the choice of hyperparameters?', 'Can the authors improve the clarity of the explanation of the log-polar space pooling and the implementation details?', 'Can the authors address the potential negative societal impacts and limitations more adequately?', 'How does the memory and runtime complexity of the proposed method compare to other advanced convolution methods in practical scenarios?', 'Can the authors provide more detailed ablation studies on the influence of hyperparameters and comparisons with other advanced convolution methods?', 'Can the authors provide more visualizations or qualitative analysis of the learned LPSC kernels?']","['The paper does not provide a detailed ablation study on the choice of hyperparameters, which is crucial for understanding the robustness and applicability of the method.', 'The potential negative societal impacts and limitations are not adequately addressed.', 'The implementation via log-polar space pooling incurs significant memory overhead and runtime complexity, which may hinder practical adoption.', 'The paper does not compare the proposed method with more recent state-of-the-art methods in detail, which could provide a better context of its effectiveness.']",False,3,2,3,5,4,"['The proposed LPSC method is a novel approach to increase the receptive field of convolutional layers without significantly increasing the number of parameters.', 'The method naturally encodes local spatial structures and can potentially capture dependencies between long-distance spatial positions more effectively.', 'The paper provides empirical results on multiple datasets and tasks, demonstrating the effectiveness of the proposed method.']","['The theoretical analysis of why the proposed method works better than existing methods is lacking.', 'The empirical improvements are not substantial enough to justify the added complexity and hyperparameters.', 'The paper does not provide a detailed ablation study on the choice of hyperparameters, which is crucial for understanding the robustness and applicability of the method.', 'The clarity of the paper could be improved, particularly in the explanation of the log-polar space pooling and the implementation details.', 'The potential negative societal impacts and limitations are not adequately addressed.', 'The implementation via log-polar space pooling incurs significant memory overhead and runtime complexity, which may hinder practical adoption.', 'The paper does not compare the proposed method with more recent state-of-the-art methods in detail, which could provide a better context of its effectiveness.']",3,3,2,3,Reject
BduNVoPyXBK,"The paper proposes Feature Attending Recurrent Modules (FARM), a novel architecture designed to learn perceptual schemas that facilitate generalization in deep reinforcement learning. The approach aims to address generalization across three distinct task structures: spatial and temporal compositions of object motions, active perception of 3D objects, and memory-retention of goal information over sequences of object configurations. The authors provide extensive experiments to demonstrate the effectiveness of FARM compared to other recurrent architectures.","['Can the authors provide more details on how the baselines were tuned? Were the hyperparameters and architectures of baselines optimized to the same extent as FARM?', 'Can the authors conduct a more detailed ablation study to isolate the effects of dynamic feature attention and multiple recurrent modules?', ""Can the authors explain why the generalization results in the 'Keybox' task are not significantly better than the baselines?"", 'Can the authors provide a more detailed comparison with RIMs and AAA, specifically highlighting the novel contributions and differences of FARM?', 'What are the theoretical foundations underlying the proposed feature attention mechanism? How does it enhance generalization compared to spatial attention?', 'Can the authors provide additional details on the implementation of the observation encoder and the modules’ update functions?', 'How robust is FARM to changes in hyperparameters? Can the authors provide a sensitivity analysis?', 'What are the limitations of FARM? Are there specific scenarios where it may not perform well?']","['The paper does not adequately address the limitations of the proposed method or discuss potential negative societal impacts.', 'A detailed discussion on the computational complexity and scalability of FARM compared to the baselines is missing.', 'The complexity of the FARM architecture might limit its applicability in environments with limited computational resources.']",False,3,3,3,6,4,"['The paper tackles the important problem of generalization in deep RL, which is a critical issue for real-world applications.', 'The proposed FARM architecture is novel, particularly the use of dynamic feature attention and multiple recurrent modules.', 'The experiments are comprehensive, covering diverse task environments and providing both qualitative and quantitative evaluations.', 'The paper is well-written and clearly organized, making it easy to follow the technical details and experimental results.']","['The evaluation methodology has some concerns. The comparison with baselines might not be entirely fair as the hyperparameters and architectures used for baselines might not be fully optimized.', 'The paper lacks a detailed ablation study on the impact of different components of the FARM architecture. For example, the effect of dynamic feature attention independently from multiple recurrent modules is not thoroughly explored.', ""Some of the generalization results, especially in the 'Keybox' task, are not significantly better than the baselines, raising questions about the consistency of the proposed method."", 'The distinction from related works (e.g., RIMs, AAA) is not sufficiently clear. More explicit differentiation and justification are needed.', 'Lacks detailed theoretical analysis supporting the proposed method. The empirical results are promising but additional theoretical foundations would strengthen the paper.', 'The clarity of the methodology section could be improved. Some parts are ambiguous and may hinder reproducibility.', 'The impact of different hyperparameters and the robustness of the method under different settings is not thoroughly explored.']",3,3,3,4,Reject
AypVMhFfuc5,"The paper presents FrugalMCT, a framework for efficiently selecting and combining multi-label classification APIs based on budget constraints. The approach aims to optimize both accuracy and cost by learning the strengths and weaknesses of different API combinations and selecting the best combination for each data point. The authors validate their approach using real commercial APIs across various tasks, demonstrating significant cost reductions and accuracy improvements.","['Can the authors provide more detailed comparisons with other state-of-the-art methods in multi-label classification?', 'Could the methodology be explained in more detail, particularly the choices behind the accuracy predictor and label combiner?', 'What are the limitations of the proposed approach in practical settings with larger scales?', 'How is the base service selected, and what impact does this choice have on the overall performance?', 'Can the authors discuss any limitations or potential pitfalls of the proposed method?', 'What are the potential limitations or failure cases of FrugalMCT?', 'How does the approach perform with limited training data?', 'Could the authors provide more details on the feature generation process for the accuracy predictor?', 'How does the complexity of the framework impact its practical implementation?', 'Can the authors include more ablation studies to evaluate the impact of different components in the framework?', 'How does the label combiner work in more detail, particularly when dealing with conflicting predictions?']","['The approach may struggle with scalability in very large datasets or with many APIs.', ""The accuracy predictor's performance is crucial, but its limitations are not thoroughly discussed."", 'The trade-offs between accuracy and cost are not fully explored in varied real-world conditions.', 'The reliance on a large amount of training data may limit the applicability of the approach in scenarios where such data is not available.', 'The clarity of the paper could be improved, particularly in the methodology sections.', 'More comprehensive ablation studies are needed to fully understand the impact of different components of the framework.']",False,3,2,3,5,4,"['Addresses a relevant and practical problem in the context of MLaaS.', 'Proposes a novel extension of existing work (FrugalML) to handle multi-label classification tasks.', 'Demonstrates significant cost reduction and accuracy improvements in empirical evaluations.', 'Provides a theoretically grounded online algorithm for API selection with provable performance guarantees.']","['The paper lacks a thorough comparison with a wide range of state-of-the-art baselines.', 'The methodology is not always clearly explained, making it difficult to follow.', 'The originality is somewhat limited as it builds on existing work without substantial innovation.', 'Experimental validation could be more robust, with more datasets and varied conditions.', 'The approach relies on a substantial amount of training data, which may not always be available for all applications.', 'The complexity of the framework might pose challenges for practical implementation.']",3,3,2,4,Reject
XWODe7ZLn8f,"The paper presents C3-GAN, a novel method combining InfoGAN with contrastive learning for unsupervised fine-grained class clustering. The method aims to learn a clustering-friendly embedding space by optimizing a contrastive loss, while also leveraging a scene decomposition technique for better feature learning without human annotations. Experimental results show state-of-the-art performance on four fine-grained image datasets, and the method also alleviates mode collapse in GANs.","['Can the authors provide more intuitive explanations in the methodology section?', 'How do different hyperparameters (e.g., number of clusters, temperature in contrastive loss) affect the performance?', 'Can the authors discuss potential limitations or failure cases of C3-GAN?', 'Can you provide more details on how the contrastive loss is implemented?', 'How does C3-GAN compare with other state-of-the-art methods not included in the paper?', 'Can you discuss more about the potential ethical impacts of your method?']","[""The paper does not sufficiently discuss potential limitations or failure cases. It would be beneficial to include these to provide a more balanced view of the method's applicability."", 'The paper could be clearer on the implementation details of the contrastive loss.', 'More discussion on the ethical implications of using generative models is needed.', 'The paper lacks clarity in some sections and does not provide sufficient ablation studies on certain components.', 'The paper does not fully explore the impact of different hyperparameter settings and architectural choices on the performance of C3-GAN.']",False,3,3,3,6,4,"['Addresses an important issue in fine-grained class clustering with a novel approach.', 'Combines the strengths of InfoGAN and contrastive learning effectively.', 'Demonstrates state-of-the-art performance on multiple datasets.', 'Includes detailed ablation studies and additional analyses.', 'Alleviates mode collapse in GANs, improving image synthesis quality.']","['Clarity of the methodology section could be improved.', 'Experiments might benefit from additional baselines.', 'Influence of hyperparameters on performance could be explored in more detail.', 'Insufficient discussion on potential limitations or failure cases.', 'Writing could be more concise and better organized.', 'Ethical considerations of generative models are lightly addressed.']",3,3,3,4,Reject
Yr_1QZaRqmv,"The paper proposes a novel algorithm that uses decision trees to solve Markov Decision Processes (MDPs). The algorithm incrementally disaggregates the state space and solves smaller MDP instances with Linear Programming, aiming to represent the solution policy as a decision tree. The method is particularly tailored for problems with large state spaces but where the solution policy can be represented by a tree-like structure.","['Can the authors provide more experimental results and comparisons with existing methods?', 'Can the authors clarify the implementation details of the decision tree growing strategy?', 'How does the proposed method perform compared to deep learning-based RL methods on larger benchmarks?', 'Can you provide more details on the autoencoder aggregator?', 'What is the performance of your model when changing the type of aggregators?', 'Can you provide additional experimental results with larger MDP instances?', 'Can the authors provide a more detailed comparison with existing state aggregation methods?', 'Is there a theoretical proof of convergence for the proposed algorithm?', 'Can the authors provide clearer explanations and more detailed examples for the mathematical formulations and algorithm descriptions?', 'Can the authors conduct more extensive experiments on diverse and larger datasets?']","['The paper should acknowledge the limitations related to the scalability of the proposed method for very large action spaces.', 'The approach may have scalability issues for extremely large state or action spaces, and it might not be effective for MDPs where the optimal policy does not have a tree-like structure. These limitations should be explicitly discussed.']",False,2,2,2,4,4,"['The approach is novel and offers a human-interpretable representation of the solution policy.', 'The paper provides a thorough computational complexity analysis.', 'The proposed method has potential applications in experience-based RL problems as an alternative to black-box policies.']","['The paper lacks sufficient experimental validation. Only two examples are provided, and comparisons with existing methods are missing.', 'Some methodological details are unclear, such as the exact implementation of the decision tree growing strategy and the autoencoder aggregator.', 'The exposition is dense and could be better organized to improve clarity.', 'Theoretical analysis and proof of convergence for the proposed algorithm are lacking.', 'The paper does not discuss the limitations and potential negative societal impacts of the proposed work.']",3,2,2,3,Reject
XVPqLyNxSyh,"The paper introduces a methodology for discovering spurious and core visual features in image classification tasks with minimal human supervision. The authors use neural features from a robust model to identify these features and create activation maps to localize them. The approach is validated through Mechanical Turk studies and applied to the Imagenet dataset, resulting in the Salient Imagenet dataset. This dataset provides core and spurious masks for a large number of images, which can be used to evaluate the sensitivity of trained models to these features.","['How well does the approach generalize to other datasets and models?', 'Can you provide more details on the potential biases in the Mechanical Turk studies and how they were mitigated?', 'What are the limitations of the proposed method in identifying spurious features?', 'How does the method handle non-spatial spurious signals, such as those related to gender or race?']","['The paper should discuss potential biases in the Mechanical Turk studies and how they were addressed.', 'A detailed analysis of the limitations of the proposed method in identifying spurious features is needed.', 'Scalability and generalization to other datasets and models should be explored.', 'The approach may not be effective for non-spatial spurious signals, such as those related to gender or race.']",False,3,3,3,6,4,"['Addresses a critical issue in deep learning: reliance on spurious features.', 'Novel methodology using neural features from a robust model.', 'Creation of the Salient Imagenet dataset, a valuable resource for the community.', 'Comprehensive experiments validating the approach.', 'Minimal human supervision required, making it scalable.']","['Reliance on neural feature importance might miss complex failure modes.', 'Mechanical Turk studies could be subject to human bias, and the paper does not discuss how this bias is mitigated.', 'Scalability and generalization to other datasets and models are not thoroughly explored.', 'The paper lacks a detailed analysis of the limitations of the proposed method in identifying spurious features.', 'The approach may not be effective for non-spatial spurious signals, such as those related to gender or race.']",3,3,3,4,Reject
8la28hZOwug,"The paper proposes Prototypical Contrastive Predictive Coding (ProtoCPC), a method combining knowledge distillation and contrastive learning. The method is applied to three distillation tasks: supervised model compression, self-supervised model compression, and self-supervised learning via self-distillation. Extensive experiments show that ProtoCPC outperforms several baselines, including KD and CRD, on CIFAR-100 and ImageNet.","['Can you provide more details on how ProtoCPC differs from existing methods beyond CRD and KD, specifically in the context of self-supervised learning?', 'Please elaborate on the rationale behind using the SK operator and its advantages over traditional softmax.', 'Could you include more ablation studies to clarify the contributions of each component in ProtoCPC?', 'Can the authors provide a more detailed explanation of the mathematical derivations and the relationship to existing methods?', 'What are the specific contributions of different components of ProtoCPC in the overall performance?', 'Can you clarify the implementation details for readers not familiar with contrastive learning and knowledge distillation?', 'What are the limitations and potential negative societal impacts of ProtoCPC?']","['The paper does not discuss potential limitations or negative impacts of the proposed method, which is crucial for a comprehensive evaluation.', 'The paper does not discuss the ethical considerations and potential societal impacts of the proposed method.', 'There is a need for a more detailed ablation study to understand the impact of different components of ProtoCPC.']",False,3,2,3,4,4,"['Addresses a relevant problem in knowledge distillation and self-supervised learning.', 'Combines knowledge distillation and contrastive learning innovatively.', 'Comprehensive experiments covering multiple datasets and tasks.', 'Achieves state-of-the-art performance in several benchmarks.']","['The methodology section is dense and lacks clarity, making it difficult to follow.', 'Insufficient discussion on the novelty compared to existing methods beyond CRD and KD.', 'Lacks a broad range of baseline comparisons, especially in self-supervised learning.', 'Additional ablation studies and clearer result presentations are necessary.', 'Potential impacts and limitations, including ethical considerations, are not discussed.']",3,3,2,3,Reject
okmZ6-zU6Lz,"The paper investigates the controllability of large-scale networked dynamical systems using coarse summaries of network structures. It introduces two methods: a model order reduction (MOR) approach and a learning-based approach, both of which are theoretically analyzed and empirically validated. The contributions include theoretical bounds on the approximation error and extensive simulations to validate the theoretical findings.","['Can the authors provide more intuitive explanations or examples to make the theoretical analysis more accessible?', 'What are the practical limitations of the proposed approaches in real-world applications?', 'Can the authors elaborate on the potential negative societal impacts mentioned in the ethics statement?', 'Can the authors provide more extensive experimental validation using real-world datasets to demonstrate the practical applicability of the proposed framework?', 'Could the authors elaborate on the computational complexity of the proposed methods and their feasibility in large-scale applications?', 'How do the proposed methods perform in scenarios with different levels of noise in the coarse summaries?', 'Can the authors provide more intuitive explanations or visualizations to help readers understand the complex mathematical formulations presented in the paper?', 'Can the authors provide more concrete guidelines on when to use the MOR-based approach versus the learning-based approach?', 'How robust are the proposed methods to deviations from the assumed stochastic block model structure?', 'Can the authors include additional real-world case studies to demonstrate the practical applicability of their methods?']","['The paper mentions potential negative societal impacts and ethical considerations but does not explore them in detail. A more thorough discussion on these aspects is needed.', 'The assumptions regarding the availability of stochastic block model parameters and the synchronization of community structures may not always hold in real-world scenarios. Addressing these limitations and discussing potential solutions or alternatives would strengthen the paper.']",False,3,3,3,5,4,"['Addresses a novel and significant problem in networked dynamical systems.', 'Provides rigorous theoretical analysis and error bounds.', 'Includes extensive empirical validation through simulations.']","['The exposition is dense and may be difficult to follow for readers not familiar with the subject matter.', 'Practical applicability and limitations of the methods are not sufficiently discussed.', 'Potential negative societal impacts should be elaborated in more detail.', 'The paper lacks a discussion on the computational complexity of the proposed methods.', 'Limited experimental validation using real-world datasets.']",3,3,3,4,Reject
DrZXuTGg2A-,"The paper proposes new interactive shuffle protocols for stochastic convex optimization, leveraging a noninteractive protocol for summing vectors with bounded ℓ2 norm. These protocols achieve improved loss guarantees for various convex loss functions, addressing a significant gap in the existing literature.","['Can you provide empirical validation of the proposed protocols?', 'How do the protocols perform under various levels of user honesty?', 'What are the computational and communication costs associated with the protocols?', 'Can you provide more intuitive explanations or examples for the complex proofs?']",['The paper lacks discussion on the practical implementation and potential limitations of the proposed methods.'],False,3,2,3,6,4,"['Addresses a critical gap by extending shuffle privacy to stochastic convex optimization.', 'Combines vector summation protocols with SCO techniques for improved loss guarantees.', 'Theoretical contributions are well-supported by rigorous proofs.']","['Lacks empirical validation to assess practical impact.', 'Some sections, particularly the proofs, are difficult to follow and could benefit from additional explanations or examples.', 'Does not adequately address potential limitations such as computational overhead and communication costs.']",4,3,2,3,Reject
EMxu-dzvJk,"The paper 'GRAND++: GRAPH NEURAL DIFFUSION WITH A SOURCE TERM' proposes a novel GNN architecture that incorporates a source term into the diffusion process to address the over-smoothing issue and improve performance with limited labeled data. Theoretical guarantees are provided, and extensive experimental validation is conducted, demonstrating significant improvements over existing methods, particularly in low-labeling rate regimes.","['Can the authors provide more details on the implementation of the autoencoder aggregator?', 'Can the authors conduct additional ablation studies to investigate the impact of different components of the proposed architecture?', 'Can the authors provide more visualizations and examples in the qualitative analysis to support their claims?', 'Could the authors provide more detailed hyperparameter settings and implementation details to enhance reproducibility?', 'Can the authors provide a clearer explanation of key concepts and the intuition behind them?', 'What are the computational costs and efficiency of GRAND++ compared to other GNN models?']","['The main limitations are related to the clarity of the paper and the need for additional ablation studies. The authors should address these concerns in the rebuttal period.', 'The paper does not discuss potential limitations or failure cases of the GRAND++ model. It would be beneficial to address these aspects to provide a balanced view of the proposed approach.', 'Potential negative societal impacts of the work are not discussed. The authors should consider addressing this in the final version.']",False,3,3,4,7,4,"['The introduction of a source term to the diffusion process is a novel and theoretically sound approach to mitigate over-smoothing.', 'Extensive experimental validation is provided, including comparisons with existing GNN architectures and ablation studies.', 'The paper demonstrates significant improvements over existing methods, particularly in low-labeling rate regimes.', 'Solid theoretical foundation with proofs and propositions supporting the claims.', 'Comprehensive evaluation across several datasets, including large-scale benchmarks.']","['The paper could benefit from more detailed ablation studies to further investigate the contributions of different components of the proposed architecture.', 'Some methodological details, such as the implementation of the autoencoder aggregator, are not entirely clear and could be better explained.', 'The mathematical formulation and theoretical proofs are dense, making the paper less accessible to readers without a strong mathematical background.', 'Lacks detailed hyperparameter settings and implementation details, which could hinder reproducibility.', 'The paper could provide more details on the computational complexity and efficiency of GRAND++ compared to other models, especially in large-scale settings.']",4,3,3,4,Accept
DIjCrlsu6Z,"The paper proposes a method to construct orthogonal classifiers in non-linear settings, with applications in style transfer, domain adaptation, and fairness. It introduces the concept of orthogonal random variables and classifier orthogonalization, providing theoretical justifications and empirical results demonstrating the method's effectiveness.","['Can the authors provide more detailed explanations and examples for the theoretical definitions and proofs?', 'What are the limitations of the proposed method, especially the subtraction method for constructing orthogonal classifiers?', 'Can the authors include ablation studies to show the impact of different types of classifiers and varying hyperparameters?', 'How does the proposed method compare with more recent and diverse baselines?', 'Can the authors provide more details on the experimental setups, particularly the hyperparameters and architectures used?', 'How does the method handle cases where the full classifier fails to capture all relevant features due to simplicity bias?', 'Can the authors discuss any potential limitations or negative societal impacts of their method, especially in fairness applications?', 'Can the authors simplify the theoretical discussions and provide more intuitive explanations for better understanding?', 'Can the authors demonstrate the practical impact of the method through more diverse and real-world experiments?']","['The paper relies on the assumption that the full classifier captures all relevant features, which may not hold in practice due to simplicity bias.', 'The dependency on the full classifier means the method might not be applicable in all scenarios.', 'The potential negative societal impacts, particularly in fairness applications, are not discussed.', 'The clarity of the explanations, especially in the theoretical sections, needs improvement.', 'More thorough experimental comparisons and ablation studies are needed to solidify the claims.']",False,3,3,3,6,4,"['Addresses an important problem of controlling orthogonal directions in machine learning tasks, which has practical relevance in fairness, style transfer, and domain adaptation.', 'Introduces a novel concept of orthogonal classifiers for various applications.', 'Provides thorough theoretical justifications and empirical validations.', 'Demonstrates significant potential applications in fairness, style transfer, and domain adaptation.']","['The theoretical sections, particularly the definitions and proofs, are not very clear and could benefit from more detailed explanations and examples.', 'The empirical validation could be more robust, with missing comparative baselines and ablation studies.', 'Some experimental setups lack detail, making it difficult to fully assess the validity of the results.', 'The paper does not thoroughly discuss the limitations of the proposed method or its potential negative societal impacts, particularly in the context of fairness applications.']",3,3,3,4,Reject
89W18gW0-6o,"The paper proposes enhancements to the FOCAL algorithm for offline meta-reinforcement learning (OMRL) by incorporating intra-task attention mechanisms and inter-task contrastive learning objectives. Theoretical analysis and empirical results are provided to demonstrate the superior performance and robustness of the proposed method, named FOCAL++, compared to state-of-the-art baselines.","['Can the authors provide more intuitive explanations and visual aids to help understand the theoretical sections?', 'Can the authors clarify the experimental setup and provide more details on hyperparameters for better reproducibility?', 'Can the authors include more detailed ablation studies on the sensitivity of hyperparameters and the impact of each component?', 'Can the authors provide a more thorough comparison with other state-of-the-art methods beyond FOCAL?', 'Have you considered testing the approach in environments other than continuous control?']","['The paper could benefit from clearer explanations and better presentation of theoretical sections.', 'More detailed ablation studies and sensitivity analyses would strengthen the empirical validation.', 'The evaluation is primarily based on synthetic benchmarks, and the applicability of the proposed method to real-world problems is not extensively discussed.']",False,3,3,3,6,4,"['Addresses a crucial problem in OMRL with significant potential impact.', 'Novel use of attention mechanisms and contrastive learning in the offline meta-RL setting.', 'Strong theoretical analysis supporting the proposed methods.', 'Comprehensive empirical validation across multiple benchmarks.', 'Thorough ablation studies to show the contributions of each component.']","['The paper is dense and somewhat difficult to follow, especially the theoretical sections.', 'Clarity of the experimental setup and hyperparameters could be improved for better reproducibility.', 'More detailed ablation studies on the sensitivity of hyperparameters and the impact of each component are needed.', 'Lack of thorough comparison with other state-of-the-art methods beyond FOCAL.', 'Focuses heavily on continuous control environments; effectiveness in other types of environments could be explored.']",4,3,3,4,Accept
Z0XiFAb_WDr,"The paper introduces LARC, a dataset augmenting ARC tasks with natural language instructions to facilitate human and machine communication. It analyzes linguistic aspects of these natural programs and evaluates program synthesis methods.","['Can the authors provide more details on the methodology used for the experimental evaluation?', 'How does the performance of the proposed method compare to other state-of-the-art methods in a more controlled setting?', 'Can the authors clarify the choice of baselines and provide a more comprehensive comparison?', 'Can the authors provide more details on the autoencoder aggregator?', 'What are the performance implications of changing the type of aggregators?', 'Can the authors provide more qualitative examples and visualizations of the tasks and solutions?', 'Can the authors provide more details on the ablation studies, particularly focusing on the impact of different components of the proposed approach?', 'Could the authors elaborate on the workings of the bandit algorithm and the neural models used for program synthesis?', 'What are the main reasons for the failure cases in the evaluation, and how can these be addressed in future work?']","['The paper does not adequately address the limitations of the proposed approach, particularly in terms of scalability and generalizability.', 'There is a lack of discussion on the potential negative societal impacts of the work.', 'The proposed DSL is complex and the challenges associated with it are not fully resolved.', 'The evaluation of program synthesis techniques is limited to a few models. A broader range of models and more detailed analysis would strengthen the findings.']",False,2,3,3,5,4,"['The paper addresses an important problem in AI: bridging the gap between human and machine communication.', 'It introduces a novel dataset (LARC) that can be valuable for multiple research communities.', 'The linguistic analysis provides insights into how humans use language to describe procedural tasks.']","['The originality is moderate, as the concept of using natural language for program synthesis is not entirely new.', 'The experimental evaluation has significant gaps, particularly in the methodology and the choice of baselines.', 'Some sections of the paper are difficult to follow, affecting the overall clarity.', 'The complexity of the proposed DSL and associated challenges are not fully resolved.', 'Lacks sufficient ablation studies and detailed explanations of certain components, such as the autoencoder aggregator.']",3,2,3,3,Reject
PilZY3omXV2,"The paper proposes CoST, a contrastive learning framework for time series forecasting that disentangles seasonal and trend representations. The method uses time and frequency domain contrastive losses to learn these representations and shows significant improvements over state-of-the-art methods on multiple benchmarks.","['Can the authors provide more details about the choice of data augmentations and their impact on the performance?', 'What is the effect of different modulation functions in the contrastive loss?', 'Can the authors include more qualitative visualizations to support their empirical findings?', 'Can the authors provide more theoretical justification for why contrastive learning is effective for disentangling seasonal and trend components?', 'What is the computational complexity of the proposed method compared to traditional end-to-end approaches?']","['The clarity of the paper can be improved, and additional ablation studies would be valuable.', 'The paper does not thoroughly address the computational complexity of the proposed method. Understanding the computational trade-offs is crucial for practical applications.', 'The paper could benefit from more qualitative analyses to provide deeper insights into the effectiveness of the disentangled representations.']",False,3,3,3,7,4,"['Addresses a key issue in time series forecasting: handling non-stationarity by learning disentangled representations.', 'Introduces a novel framework combining time and frequency domain contrastive learning.', 'Empirical results show significant improvements over state-of-the-art methods.', 'The framework is shown to be robust to different choices of backbone encoders and downstream regressors.', 'The paper includes thorough ablation studies to validate the contributions of different components of the proposed framework.']","['The paper could benefit from additional ablation studies, especially regarding the choice of data augmentations and the components of the contrastive loss.', 'More details on the implementation and the autoencoder aggregator would enhance clarity.', 'Qualitative visualizations are limited; more cases would strengthen the empirical evidence.', 'The paper lacks a discussion on the computational complexity of the proposed method compared to traditional end-to-end approaches.']",3,3,3,4,Reject
lkQ7meEa-qv,"The paper introduces Neural Acoustic Fields (NAFs), an implicit representation designed to capture the acoustic properties of scenes. NAFs leverage local geometric features to improve the generalization of impulse responses to novel emitter-listener locations. The method demonstrates potential in applications such as sound source localization and cross-modal learning.","['Can the authors provide more detailed ablation studies to investigate the impact of various components of the proposed method?', 'How does the reliance on local geometric features affect the robustness of NAFs in more complex or varied scenes?', 'Can the authors provide additional experiments on different datasets to validate the generalizability of NAFs?', 'Can the authors provide more details on the theoretical underpinnings of Neural Acoustic Fields and how they ensure the fidelity of the captured acoustic properties?', 'What measures have been taken to address potential negative societal impacts, particularly in terms of privacy concerns?', 'Can the authors provide more clarity on the implementation details, specifically the training procedure and hyperparameters?', 'What are the limitations of the proposed method, and how do the authors plan to address them in future work?', 'Can the authors provide more details on the autoencoder aggregator used in the model?', 'How does the performance change with different types of modulation functions, and can you explore reducing the number of gating parameters in Eq. 10?']","['The paper does not adequately address how the reliance on local geometric features might impact the robustness and generalizability of the method in more complex or varied scenes.', 'More detailed ablation studies and additional experiments on different datasets are needed to fully validate the approach.', 'The authors need to address the limitations regarding the clarity of the methodology and the robustness of the experimental validation.', 'Potential negative societal impacts, such as privacy concerns related to sound source localization, should be discussed.']",True,2,2,3,4,4,"['The paper tackles an important and under-explored problem in modeling scene acoustics using neural implicit representations.', 'The use of local geometric features to condition the model and improve generalization is innovative and shows promise.', 'Experimental results demonstrate the potential of NAFs in various applications such as sound source localization and enhancing visual representations with sparse data.']","['The paper lacks clarity in several sections, making it difficult to understand the methodology and the implementation details fully.', 'The experimental results, while promising, are not sufficiently thorough. More baselines and ablation studies are needed to validate the robustness of the proposed method.', 'The complexity of the proposed method may hinder reproducibility and practical application. The paper could benefit from a more detailed theoretical analysis to support the empirical results.', 'There is insufficient discussion on the limitations of the proposed method and its potential negative societal impacts, such as privacy concerns in surveillance applications.']",3,2,2,3,Reject
kj0_45Y4r9i,"The paper proposes Clustering by Discriminative Similarity (CDS), a method for learning discriminative similarity measures for clustering. It introduces CDSK, a clustering algorithm based on the CDS framework, which leverages discriminative similarity derived from kernel functions. The authors provide thorough theoretical analysis and experimental validation on various datasets.","['Can the authors provide more details on the practical implementation of the CDSK algorithm, including hyperparameter choices and computational complexity?', 'How does CDSK compare to more recent clustering methods not included in the experiments?', 'Can the authors provide more intuitive explanations for their theoretical contributions?', 'Can the authors add more detailed ablation studies and comparisons?']","['The paper is dense with theoretical content, which may be challenging for some readers.', 'More practical implementation details and comprehensive comparisons are needed.', 'The clarity of the paper needs improvement to make it accessible to a broader audience.', 'More experiments and ablation studies are required to validate the practical applicability of the method.']",False,2,2,2,3,4,"['Addresses the critical problem of constructing effective similarity measures for clustering.', 'Provides thorough theoretical foundations, including generalization error bounds and connections to kernel density classification.', 'The concept of using discriminative similarity for clustering is novel and theoretically sound.']","['Theoretical content is dense and may be challenging for readers not well-versed in statistical learning theory.', 'Details on the practical implementation of the CDSK algorithm, including hyperparameter choices and computational complexity, could be expanded.', 'Comparison to other clustering methods could be more comprehensive, including more recent advances.', 'The connection between the theoretical framework and the practical implementation needs more clarity.', 'Experimental section lacks depth and detailed ablation studies.']",3,2,2,3,Reject
-3yxxvDis3L,The paper investigates the convergence properties and sample complexity of SGD under highly dependent data. It proposes using periodic subsampling and mini-batch updates to improve SGD's performance. Theoretical results are validated through numerical experiments on a convex quadratic optimization problem.,"['Can you provide more empirical validation on diverse datasets?', 'What are the practical computational costs associated with the proposed methods?', 'Can you discuss any limitations or potential drawbacks of your methods?', 'Can you provide more details on the computational overhead associated with mini-batch SGD compared to standard SGD?', 'How would the results generalize to non-convex optimization problems, which are common in deep learning?', 'Can you provide more real-world examples or datasets to validate your theoretical findings?', 'Can you provide more intuition and practical guidance on how to select the subsampling period r and mini-batch size B in practice?', 'How do your methods perform on more diverse datasets and different types of dependencies (e.g., temporal, spatial)?', 'Can you elaborate on the computational overhead introduced by the proposed methods?', 'Can you provide more intuitive explanations or visual aids to help understand the theoretical results?', 'How do these findings translate to real-world applications beyond the specific experimental setup provided?']","['The paper could better address practical implementation aspects, such as computational costs and specific use cases.', 'The practical impact of the proposed methods is under-explored due to limited empirical validation.', 'The clarity of the paper could also be improved.', ""The paper's focus is on convex optimization problems with Lipschitz continuity, which may limit its applicability to more complex machine learning models like deep neural networks."", 'The computational cost of the proposed methods, particularly mini-batch SGD, is not thoroughly explored.', 'The main limitation is the lack of practical guidance and extensive experimental validation. The theoretical results are strong but may not be easily applicable without further context.']",False,3,2,3,5,4,"['Addresses a practical and important issue in machine learning regarding dependent data.', ""Proposes novel techniques (periodic data-subsampling and mini-batch SGD) to improve SGD's performance over dependent data."", 'Thorough theoretical analysis supported by comprehensive proofs and lemmas.', 'Empirical validation supports theoretical findings.']","['The paper is dense and could benefit from more intuitive explanations and visual aids to improve clarity.', 'Empirical validation is limited to a specific quadratic optimization problem; more diverse and real-world datasets would strengthen the results.', 'The practical implications and potential computational costs of the proposed methods are not discussed in depth.', 'More discussion on the limitations and potential drawbacks of the proposed methods would provide a balanced perspective.']",3,3,2,3,Reject
BkIV7EOXkSs,The paper investigates the implicit regularization properties of the Bregman Proximal Point Algorithm (BPPA) and Mirror Descent (MD) on linearly separable data. It provides theoretical analyses demonstrating that both algorithms achieve non-trivial margins that depend on the condition number of the distance-generating function. The paper also extends these findings to MD and provides non-asymptotic convergence analyses.,"['Can you provide more extensive experimental validation on diverse datasets?', 'Can you include more intuitive explanations and diagrams in the theoretical sections?', 'Can you conduct detailed ablation studies to isolate the contributions of different components?', 'What are the practical implications of your theoretical findings for real-world applications?']","['The paper could benefit from more extensive experiments and clearer explanations.', 'The empirical section, while useful, could be expanded to provide more comprehensive validation.', 'The reliance on mathematical notations makes the paper less accessible to a broader audience.', 'There is limited discussion on the computational complexity and efficiency of the proposed methods.']",False,3,3,3,5,4,"['Addresses an important problem in optimization and machine learning.', 'Provides rigorous theoretical analyses with non-asymptotic convergence results.', 'Extends findings to both BPPA and MD, showing the generality of the results.', 'Demonstrates the impact of divergence choices on the solution quality.']","['The paper is dense and could benefit from clearer explanations and more intuitive diagrams.', 'Experimental validation is limited to synthetic data and a single real-world dataset.', 'Lacks detailed ablation studies to isolate the contributions of different components.', 'Practical implications for real-world applications are not thoroughly explored.']",3,3,3,4,Reject
yhCp5RcZD7,"The paper introduces implicit displacement fields (IDF), a new method for representing detailed 3D geometry. Inspired by displacement mapping, the method decomposes a surface into a smooth base surface and a displacement field along the base's normal directions. This disentanglement leverages a frequency hierarchy in neural implicit representations, particularly using SIRENs. The approach enhances geometric detail representation and enables detail transfer between shapes without explicit correspondence mapping.","['Can the authors provide more detailed explanations and visualizations of the network architecture and training strategies, particularly how the frequency parameters are determined?', 'How does the method perform in scenarios where shapes are not pre-aligned? Are there plans to address this limitation in future work?', 'Could the authors include additional ablation studies to analyze the influence of different architectural choices and hyperparameters?', 'Can the authors provide more details on the necessity and process of pre-aligning shapes for detail transfer?', 'What would be the impact of changing the hyperparameters ωB and ωD on the final results?', 'Can the authors provide additional ablation studies to isolate the effects of different components of the proposed architecture?']","[""The method's reliance on pre-aligned shapes for detail transfer limits its applicability in more general scenarios. Addressing this limitation in future work, possibly with automated alignment or sparse correspondences, would enhance its utility."", 'More detailed explanations and visualizations of the network architecture and training strategies would improve clarity and understanding.', 'The robustness of the method under noisy or sparse input data could be further evaluated.']",False,3,3,3,6,4,"['The paper addresses a significant challenge in 3D geometry representation by proposing an innovative method to disentangle high-frequency details from low-frequency base shapes.', 'The use of implicit displacement fields is a novel extension of traditional displacement mapping into a continuous domain, which is theoretically grounded.', ""The paper includes extensive experimental validation, demonstrating the method's superiority in detail representation and transfer tasks."", 'The approach is versatile, applicable to various tasks in 3D geometry, and the code and data are made available for reproducibility.']","['The clarity of certain technical sections could be improved, particularly the explanations around the network architecture and training strategies.', 'The paper could benefit from more detailed ablation studies to analyze the impact of different components and hyperparameters in the proposed method.', ""There is a reliance on pre-aligned shapes for detail transfer, which might limit the method's applicability in more general scenarios without alignment."", 'The robustness of the method under different conditions, such as noisy or sparse input data, needs more comprehensive evaluation.']",4,3,3,4,Accept
AkJyAE46GA,"The paper investigates if pretrained models can be effective active learners, especially in resolving task ambiguity. The authors propose an active learning approach using pretrained models with uncertainty sampling and demonstrate that these models achieve higher accuracy with fewer labels compared to random sampling. The study is conducted across several datasets with issues such as spurious correlations, latent minority groups, and domain shifts.","['Can the authors provide more details on the choice of hyperparameters and their impact on the results?', 'How does the proposed method perform when applied to other types of tasks not considered in this study?', 'Can the authors discuss the potential limitations and failure cases of their approach in more detail?', 'Would different acquisition functions (e.g., entropy sampling) perform better or worse compared to the least confidence heuristic used in this study?', 'Can the authors provide additional ablation studies to investigate the effects of different components and settings?', 'Can the authors provide more detailed descriptions of certain methods, such as the autoencoder aggregator?', 'Can the authors provide more visualizations to strengthen the qualitative analysis?', 'How does the performance of the proposed method change with different sizes of pretrained models and pretraining datasets?', 'Can the authors include additional baselines to compare the proposed approach against other active learning strategies and model architectures?']","['The method requires a human in the loop for data acquisition, which can increase the training time and cost.', 'The reliance on pretrained models limits the applicability of the method to domains where such models are available and effective.', 'The method may not perform well in highly noisy labeling environments or when there is significant label noise.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed approach. It would be helpful to discuss these aspects in more detail.']",False,3,3,3,4,4,"['The paper addresses the important issue of task ambiguity, which is highly relevant in machine learning applications.', 'The proposed method is simple yet practical, eliminating the need for a validation set in data-scarce settings.', 'Comprehensive experiments are conducted across various datasets, and the results are well-documented and analyzed.', 'The potential of pretrained models to improve active learning outcomes is convincingly demonstrated.']","['The paper lacks detailed ablation studies on different acquisition functions and the impact of various pretrained models.', 'There is insufficient discussion on the limitations and potential failure cases of the proposed method.', 'The paper could benefit from more clarity on the experimental setup, particularly regarding hyperparameter choices and implementation details.', 'The generalizability of the proposed method to other types of tasks beyond the ones considered in this study is not well explored.', 'The methodology lacks novelty, primarily relying on standard uncertainty sampling.']",3,3,3,3,Reject
mfwdY3U_9ea,"The paper introduces IGEOOD, a method for OOD detection leveraging the Fisher-Rao distance to measure dissimilarity between probability distributions. The method is applicable in BLACK-BOX, GREY-BOX, and WHITE-BOX scenarios and shows competitive performance against state-of-the-art methods on various datasets and neural network architectures.","['Can the authors provide a more detailed comparison of Fisher-Rao distance with other metrics like KL divergence?', 'Can the authors present additional ablation studies to further validate the choice of Fisher-Rao distance?', 'Can the authors improve the clarity of the mathematical derivations and provide more intuitive explanations?', 'Can you provide more intuitive explanations or visual aids for the complex concepts, particularly the derivation and application of the Fisher-Rao distance?', 'Are there any specific hyperparameter settings or procedural steps that are crucial for reproducing the results?', 'Can the authors provide more details on the computational complexity of the method, especially in the WHITE-BOX setting?', 'What are the exact hyperparameters used, and how sensitive is the method to these choices?', 'Can the authors elaborate on the impact of different components (e.g., the choice of layers used) on the final performance?', 'How does the proposed method fundamentally differ from existing methods using Fisher-Rao distance?', 'Can the authors provide a detailed algorithmic breakdown of IGEOOD?', 'What is the statistical significance of the improvements observed in the empirical results?']","['The complexity of the method and the mathematical derivations can be a barrier to understanding and implementation.', 'The performance improvements, while present, may not be significant enough in some benchmarks to justify the added complexity.', ""The paper's complexity might limit its accessibility to a broader audience."", 'The computational cost of the method, particularly in the WHITE-BOX setting, is a concern.', 'The clarity of the presentation needs improvement to ensure reproducibility and wider adoption.', 'The novelty is not well established.', 'The empirical analysis should include statistical significance tests.']",False,3,2,3,5,4,"['The use of Fisher-Rao distance for OOD detection is novel and theoretically sound.', 'The method is flexible, applicable to any pre-trained model, and works under different levels of access to the model.', 'Comprehensive experiments are conducted across different settings (BLACK-BOX, GREY-BOX, and WHITE-BOX) and datasets.']","['The mathematical derivations, particularly for the Fisher-Rao distance, are complex and may be difficult for readers to follow.', 'The paper could benefit from additional ablation studies, particularly comparing Fisher-Rao distance against other distance metrics like KL divergence.', 'The performance improvements, while notable, might not be substantial enough in some cases to justify the complexity of the method.', 'The clarity of the presentation, especially in the methodological sections, needs improvement.', 'Reproducibility might be challenging without clear and detailed hyperparameter settings and procedural steps.', 'The computational complexity, particularly in the WHITE-BOX setting, is not thoroughly discussed.', 'The novelty of using Fisher-Rao distance for OOD detection is not well-established, as similar approaches exist.', 'The empirical results lack clarity on the statistical significance of the improvements over baselines.']",3,3,2,3,Reject
6hTObFz_nB,"The paper proposes a novel approach to safety-aware deep reinforcement learning called latent shielding. This method leverages internal representations of the environment to predict and avoid unsafe states, eliminating the need for a pre-defined model of the environment. The key contributions include the introduction of a Safety Recurrent State-Space Model (SRSSM) and a shield introduction schedule to balance exploration and safety during training. Experimental results demonstrate improved adherence to safety specifications and competitive performance compared to previous methods.","['Can the authors provide more detailed ablation studies to understand the impact of different components of the proposed method?', 'How does the weighting term α in the loss function affect the training process and final performance?', 'What are the potential ethical implications of allowing agents to initially enter unsafe states during training?', 'Can the authors provide more detailed descriptions of the SRSSM architecture and the shield introduction schedule?', 'What is the impact of different architectures for the SRSSM on the performance of the proposed method?', 'How does the method generalize beyond the Dreamer framework to other model-based RL approaches?', 'Can the authors provide more detailed experimental results to better understand the variance observed in the results?']","['The paper does not provide a detailed discussion on the ethical implications of the proposed approach. This is particularly important given the potential real-world applications where safety is a critical concern.', 'The current evaluation is limited to relatively simple environments, which may not fully demonstrate the potential of the proposed method.', 'The clarity of the paper can be improved to make it more accessible to a broader audience.', 'More detailed ablation studies and comparisons are needed to fully validate the proposed method.', 'The method relies heavily on the Dreamer framework, which may limit its generalizability.', 'The high variance in experimental results suggests that the method may not be robust across different settings.']",True,3,3,3,5,4,"['Addresses an important problem in reinforcement learning: ensuring safety in high-dimensional, complex environments without handcrafted models.', 'The introduction of latent shielding and the integration of SRSSM for safety-aware RL is novel and well-motivated.', 'Comprehensive experimental evaluation across different environments demonstrates the effectiveness of the proposed approach.', 'The concept of a shield introduction schedule to facilitate learning is an interesting addition that is empirically validated.']","['The clarity of the explanation regarding the implementation of the SRSSM and ABPS could be improved. The paper is dense, and understanding the detailed mechanics of the proposed methods is challenging.', 'The ablation studies are not comprehensive. Specifically, the impact of various components of the proposed approach (e.g., the weighting term α in the loss function, different shield introduction schedules) is not thoroughly investigated.', 'The potential ethical implications of the approach are not discussed. Given that the method involves the possibility of agents initially entering unsafe states, there could be significant ethical concerns if applied to real-world scenarios.', 'The evaluation is limited to relatively simple environments and lacks experiments in more complex, real-world scenarios.', ""The experimental results show high variance, suggesting that the method's robustness may be an issue.""]",3,3,3,3,Reject
0d1mLPC2q2,"The paper explores the interplay between Knowledge Distillation (KD) and Data Augmentation (DA), presenting new observations about KD's ability to exploit DA more effectively than Cross-Entropy (CE) loss. The authors propose new DA schemes specifically tailored for KD, such as TLmixup and TLCutMix, and validate their findings through extensive experiments on CIFAR-100, Tiny ImageNet, and ImageNet datasets.","['Can the authors provide more ablation studies to explore the modulation functions and different types of aggregators?', 'Could the clarity of the autoencoder aggregator be improved with more detailed explanations?', ""Can the authors provide more qualitative analysis cases to strengthen the paper's claims?"", 'Can the authors provide more detailed implementation details for TLmixup, TLCutMix, and TLCutMix+pick?', 'How do the proposed methods perform in real-world applications or on other datasets not covered in the paper?', 'Can the authors provide an analysis of why TLCutMix+pick does not always lead to improvements?', 'Can the authors provide a more detailed theoretical analysis to support the empirical findings?', 'What is the justification for choosing TLmixup, TLCutMix, and TLCutMix+pick over other possible DA methods?', 'What are the computational costs associated with the proposed DA schemes compared to standard KD methods?', 'Can the authors provide more detailed descriptions of the hyperparameters and training protocols used in their experiments to ensure reproducibility?', 'What potential biases might be introduced by the proposed DA schemes, and how can they be mitigated?']","['The paper could be clearer in explaining the autoencoder aggregator, and additional ablation studies are needed to explore different modulation functions and aggregators.', 'The paper does not thoroughly explore the real-world applicability of the proposed methods, and potential limitations in practical scenarios are not discussed.', 'The analysis of why certain methods do not always lead to improvements is limited, which could be addressed in future work.', 'The paper lacks a thorough theoretical analysis to support the empirical findings.', 'The justification for choosing the specific DA methods is not well-discussed.', 'The paper does not sufficiently discuss the increased computational cost and potential biases introduced by the proposed DA schemes.']",False,3,3,4,6,4,"['The paper addresses an underexplored aspect of KD, focusing on its interplay with DA.', 'The proposed framework and DA schemes (TLmixup, TLCutMix, TLCutMix+pick) are novel and tailored for KD.', 'Comprehensive experiments validate the effectiveness of the proposed methods, showing state-of-the-art performance.', 'The paper provides a clear explanation of why KD benefits more from DA compared to cross-entropy loss, supported by empirical evidence.']","['The paper could benefit from additional ablation studies to explore the modulation functions and aggregators in more detail.', 'The clarity of the autoencoder aggregator could be improved with more detailed explanations.', 'Some sections, particularly those explaining the implementation details of the proposed methods, lack clarity and could benefit from more detailed explanations.', 'The paper does not explore the real-world applicability and potential limitations of the proposed methods in practical scenarios.', 'The theoretical explanation for why KD can exploit DA more effectively than CE loss is heuristic and lacks rigorous mathematical backing.', 'The improvements reported in the experimental results, while statistically significant, are not always substantial.']",3,3,3,4,Reject
e-IkMkna5uJ,"The paper investigates the spectral bias phenomenon in neural networks used for image classification. It introduces two methodologies: label smoothing and linear interpolation, to measure the frequency components of functions learned by these models. The experimental results reveal that spectral bias is present in modern image classification networks, with larger models learning high frequencies faster and regularization techniques affecting the frequency content in different ways. The paper also explores the relationship between image frequency and function frequency.","['Can the authors provide more detailed explanations of the label smoothing and interpolation methodologies?', 'What are the practical implications of the findings on spectral bias for real-world applications?', 'Have the authors considered additional ablation studies to validate the robustness of their methodologies?', 'Can the authors provide more details on the linear interpolation method and how it measures function smoothness?', 'What are the specific hyperparameters used in the experiments?', 'Have the authors tested their methodologies on more complex datasets beyond CIFAR-10?']","['The paper does not clearly address the potential limitations and negative societal impacts of the proposed methodologies.', 'There is a lack of clarity in some methodological details, which could impact the reproducibility of the results.', 'The study primarily focuses on CIFAR-10 and does not test the methodologies on more complex datasets.', 'The impact of the proposed methodologies on practical applications is not well explored.', 'The computational expense of the label smoothing method might limit its practical applicability.', 'The study primarily focuses on image classification; the findings might not generalize to other types of tasks.']",False,3,2,3,5,4,"['Addresses a significant and timely problem in understanding why deep learning models generalize well.', 'Introduces novel methodologies for measuring spectral bias in multi-class classification and through linear interpolation.', 'Comprehensive experimental results demonstrate the impact of various training interventions on the frequency of learned functions.', 'The findings provide valuable insights into the effects of model size, regularization, and data augmentation on spectral bias.']","['Some methodological details, particularly in the label smoothing and interpolation methodologies, are not clearly explained.', 'The practical implications of the findings are not always clearly demonstrated.', 'Additional ablation studies are needed to validate the robustness of the proposed methodologies.', 'The study focuses on CIFAR-10, a relatively simple dataset, and does not test the methodologies on more complex datasets.', 'Reproducibility might be challenging due to the complex experimental setup and lack of detailed guidance.']",3,3,2,3,Reject
Zk3TwMJNj7,"The paper investigates the directional bias of Stochastic Gradient Descent (SGD) in the context of kernel regression, showing that SGD with annealing step size converges towards the largest eigenvalue of the gram matrix, which helps in generalization. Theoretical results are supported by experiments, including applications to neural networks.","['Can the authors discuss the applicability of the diagonal dominance assumption in more detail?', 'Could the authors provide more intuitive explanations and visual aids to help readers understand the theoretical sections?', 'Are there plans to extend the experimental validation to more datasets and network architectures?', 'Could the practical implications of the theoretical findings be further elaborated?', 'Can you provide more details on the specific constants used in the theoretical proofs?', 'Have you considered other types of kernels or data distributions in your analysis?', 'Could the authors provide more details on the autoencoder aggregator used in the experiments?', 'Can the authors include additional ablation studies to investigate the impact of different modulation functions and aggregators?', 'Would the authors be able to provide more comprehensive qualitative analysis with additional visualizations?']","['The paper should discuss the limitations of the diagonal dominance assumption and its impact on the generalizability of the results.', 'The main limitation is the limited scope of experimental validation. The authors should consider expanding the experiments to include more datasets and models. Additionally, the practical implications of the findings need to be more thoroughly explored.', 'The clarity of the paper needs improvement, particularly in explaining the methodology. Additional ablation studies are required to further validate the results.']",False,3,3,3,5,4,"['Addresses an important problem in understanding the implicit bias in SGD.', 'Provides novel theoretical insights into the directional bias of SGD.', 'The concept of directional bias is well-explored theoretically and is a novel extension to nonparametric settings.', 'Theoretical contributions are well-founded with detailed mathematical proofs.', 'The results have potential implications for understanding the generalization properties of SGD in deep learning.']","['Assumptions such as the diagonal dominance of the gram matrix may limit the applicability of the results.', 'Theoretical sections are dense and may be difficult to follow for some readers. More intuitive explanations and visual aids are needed.', 'Experimental validation is limited; more extensive experiments across different datasets and network architectures could strengthen the evidence.', 'The practical implications of the theoretical findings are not fully explored.', 'The clarity of presentation could be significantly improved, with more intuitive explanations and visual aids to help readers grasp the core ideas.']",3,3,3,3,Reject
rrWeE9ZDw_,"The paper proposes a method for autonomously learning object-centric abstractions in reinforcement learning tasks. These abstractions are designed to be transferable between tasks that share common object types, thereby improving sample efficiency. The approach is demonstrated on several domains, including Blocks World, a 2D crafting domain, and Minecraft tasks. The method involves partitioning options into subgoal options, learning preconditions and effects, and generating a lifted, typed model that can be instantiated for specific tasks.","['Can the authors provide more details on the feature selection procedure and the clustering approach used in the methodology?', 'How does the proposed method compare with other existing methods for learning transferable abstractions in reinforcement learning?', 'Can the authors include additional ablation studies to isolate the contributions of different components of the method?', 'What are the potential limitations and failure modes of the proposed approach, and how can they be mitigated?', 'How sensitive is the approach to the choice of clustering and classification algorithms?', 'Can the authors provide a more detailed comparison with other state-of-the-art methods in terms of sample efficiency and planning performance?', 'What are the limitations of assuming that objects can be individuated in all environments?', 'How do the proposed abstractions compare with existing methods in terms of performance metrics?', 'Can the authors provide more detailed evaluation metrics for the success of the learned abstractions?', 'How does the proposed method compare to state-of-the-art approaches in terms of computational efficiency?']","['The paper does not adequately address potential limitations and failure modes of the proposed approach, such as the impact of noisy data or suboptimal clustering.', 'The assumption that objects can be individuated may not hold in all environments, potentially limiting the applicability of the approach.', 'The paper does not address potential negative societal impacts, such as the misuse of autonomous agents in harmful contexts.', ""The method's scalability to very large numbers of objects and tasks is not thoroughly addressed.""]",False,3,2,3,6,4,"['The problem of improving sample efficiency in reinforcement learning by leveraging object-centric abstractions is well-motivated and practical.', 'The proposed method is novel in its approach to learning object-centric abstractions that can be transferred between tasks.', 'The paper includes comprehensive experimental evaluations on multiple domains, demonstrating the effectiveness of the proposed method.', 'The use of PPDDL for representing learned abstractions allows for the use of existing task-level planners, which is a practical and valuable contribution.']","['The paper lacks a detailed comparison with existing methods for learning transferable abstractions, making it difficult to gauge the relative performance improvements.', 'Some parts of the methodology, such as the feature selection procedure and the clustering approach, are not explained in sufficient detail, which may hinder reproducibility.', 'The experimental results could benefit from additional ablation studies to isolate the contributions of different components of the method.', 'The paper does not adequately address potential limitations and failure modes of the proposed approach, such as the impact of noisy data or suboptimal clustering.', ""The paper's clarity could be improved, particularly in the detailed implementation and pseudocode sections.""]",3,3,2,4,Reject
DIsWHvtU7lF,"The paper proposes a novel compositional physics-aware neural network model (FINN) designed to learn spatiotemporal advection-diffusion processes. FINN integrates neural networks with physical knowledge from PDEs, demonstrating strong generalization capabilities beyond initial and boundary conditions. The model outperforms traditional ML models and state-of-the-art physics-aware models on synthetic datasets and a real-world contamination-diffusion problem.","['Can the authors provide more intuitive explanations and visual aids to clarify the proposed methodology?', 'Can additional ablation studies and sensitivity analyses be included to validate the robustness of the model?', 'Can the authors provide more detailed implementation steps and parameter settings to improve reproducibility?', 'Were the hyperparameters for baseline models optimized to the same extent as for FINN? If not, can the authors provide a more rigorous comparison?', 'Can the authors provide additional real-world scenarios to demonstrate the generalization ability of FINN?']","['The complexity and clarity of the methodology need improvement. Reproducibility is a concern due to the lack of detailed implementation steps and parameter settings.', 'The scalability of the model to larger datasets is a potential concern.', 'More detailed architectural and training information would be beneficial.']",False,3,3,4,7,4,"['The combination of neural networks and physical knowledge is novel and addresses the problem of generalization over different initial and boundary conditions.', 'The experimental results are comprehensive, covering multiple equations and comparing against state-of-the-art models.', 'The model shows superior performance in terms of accuracy and generalization, even with fewer parameters.', 'Model interpretability is enhanced by allowing the extraction of learned functions.']","['The methodology section is complex and could benefit from more intuitive explanations and visual aids to enhance understanding.', 'Additional ablation studies and sensitivity analyses would help validate the robustness of the proposed model.', 'Reproducibility is a concern due to the lack of detailed implementation steps and parameter settings. The paper should provide more information to facilitate replication of the results.', 'The comparison with baseline models, particularly PINN and PhyDNet, could be more rigorous. It is not clear if the hyperparameters for these baselines were optimized to the same extent as for FINN.', 'The real-world application is limited to a single scenario, which may not be sufficient to demonstrate the generalization ability of FINN across diverse real-world problems.']",4,3,3,4,Reject
Ivku4TZgEly,"The paper 'Exploring Unfairness in Integrated Gradients Based Attribution Methods' identifies limitations in the Integrated Gradients (IG) method and proposes a new method called Integrated Certainty Gradients (ICG). The authors show that IG can produce misleading attributions due to its sensitivity to the choice of baseline and the input-output landscape. ICG addresses these issues by incorporating certainty information into the model training, which helps to avoid the identified failure modes.","['Can the authors provide more detailed explanations and diagrams to clarify the methodology, especially the process of incorporating certainty information?', 'Can the authors conduct additional ablation studies to isolate the contributions of different components of the proposed ICG method?', 'How does the proposed ICG method compare to other existing methods that also aim to improve attribution fairness?', 'How practical is the proposed method in real-world scenarios given the additional complexity in training and use of certainty information?', 'Can the authors provide more empirical results on diverse datasets to demonstrate the generalizability of ICG?']","['The paper could benefit from additional explanations and diagrams to improve clarity. More ablation studies are needed to isolate the contributions of different components of the proposed method.', 'The additional complexity introduced by the proposed method in terms of training and certainty information may limit its practicality in some scenarios.', 'The potential limitations and negative societal impacts of the proposed method are not adequately discussed.']",False,3,3,3,5,4,"['The paper addresses an important and timely problem in the field of model interpretability, focusing on the fairness of attribution methods.', 'The proposed ICG method is a novel approach that incorporates certainty information into the model training, which is an interesting idea.', 'The experimental results are extensive, covering multiple scenarios and comparing various baseline methods.', 'The theoretical foundation is robust, clearly identifying the axiomatic weaknesses in IG that lead to unfair attributions.']","['The methodology section is complex and could benefit from clearer explanations and diagrams to help readers understand the proposed approach.', 'The paper lacks certain critical comparisons and ablation studies that would help to isolate the contributions of different components of the proposed method.', 'The novelty of the proposed method needs to be evaluated against existing methods that also aim to improve attribution fairness.', 'The proposed method introduces additional complexity in training and the use of certainty information, which may not be practical in all scenarios.', 'The potential limitations and negative societal impacts of the proposed method are not adequately discussed.']",3,3,3,3,Reject
rdBuE6EigGl,"The paper proposes a modification to recurrent neural network architectures by adding a direct connection between the input and the output, bypassing the recurrent layer. This modification aims to improve performance in sequence modeling tasks, particularly in natural language processing. The authors conduct experiments on the Penn Treebank and WikiText-2 datasets and report improved perplexity scores.","['Can the authors provide a more detailed theoretical explanation for why the direct connection improves performance?', 'How does the proposed modification compare with other similar approaches in the literature?', 'Can the authors discuss potential limitations and negative societal impacts of their work?', 'Can the authors provide more details on the implementation and hyperparameter settings used in the experiments?', 'How does the dual connection affect the training time and computational complexity of the models?', 'Can the dual connection be extended to more complex architectures like transformers?', 'Are there any scenarios where the dual architecture does not provide significant improvements?']","['The paper does not adequately address potential limitations, such as the scalability of the proposed approach to larger datasets or more complex tasks.', 'The authors should discuss the potential negative societal impacts of their work, particularly in the context of large-scale language models.', 'The increased complexity due to the dual connection might lead to overfitting in some cases.', ""The dual architecture's applicability to other types of sequence data (e.g., time series) is not explored.""]",False,3,3,2,4,4,"['The modification is simple and can be easily integrated into existing RNN architectures.', 'The experimental results show consistent improvements across different models and datasets.', 'The paper includes detailed experiments and analyses, covering both validation and test datasets.']","['The idea of adding a direct connection is not fundamentally novel and has been explored in various forms in other works.', 'The theoretical motivation and explanations for why the direct connection improves performance are insufficient and lack depth.', ""The paper's clarity can be improved, particularly in explaining the experimental setup and the specific contributions of the work."", 'There is insufficient detail on the implementation and hyperparameter settings, making it difficult to reproduce the results.', 'The experiments are confined to language modeling tasks, limiting the generalizability of the results.', 'The paper does not adequately discuss potential limitations and ethical concerns associated with the proposed approach.']",2,3,3,3,Reject
q2ZaVU6bEsT,"The paper proposes a novel methodology for improving tiny object detection via a feature pyramid network that incorporates context augmentation (CAM) and feature refinement (FRM). Additionally, a data augmentation method called copy-reduce-paste is introduced to enhance the training process by increasing the contribution of tiny objects. The approach shows improved detection performance on the VOC dataset, outperforming several state-of-the-art methods.","['Can the authors provide more details about the autoencoder aggregator and the exact architecture used in the feature refinement module?', 'How does the proposed method perform on other datasets beyond PASCAL VOC?', 'What are the potential negative societal impacts of the proposed method?', 'Can you provide more theoretical justification for the design choices in CAM and FRM?', 'What are the specific implementation details for the copy-reduce-paste data augmentation method?', 'Can the authors provide more qualitative results and visualizations of detected tiny objects?', 'How does the proposed method compare with more recent state-of-the-art techniques beyond those listed in the paper?']","['The paper does not discuss potential limitations or negative societal impacts of the proposed method.', 'Theoretical analysis is limited, and there are concerns about the robustness of the claims made.', 'The ablation studies are insufficient to comprehensively validate the contributions of the individual components (CAM, FRM, and copy-reduce-paste).', 'Potential overfitting due to the data augmentation technique, which may alter the data distribution.', 'The computational overhead introduced by the proposed modules (CAM and FRM) is not discussed.']",True,2,2,2,4,4,"['Addresses an important problem in object detection: the detection of tiny objects.', 'Proposes a novel combination of context augmentation and feature refinement.', 'Experimental results show significant improvements over state-of-the-art methods.']","['Lack of clarity in the description of the methods, particularly the autoencoder aggregator and the feature refinement module.', 'Insufficient theoretical analysis to support the claims made about the proposed methods.', 'Limited diversity in the experimental validation; only one dataset (PASCAL VOC) is used.', 'No discussion on the potential negative societal impacts and ethical considerations of the proposed approach.', 'The paper is poorly organized and difficult to follow.']",2,2,2,3,Reject
V7eSbSAz-O8,"The paper presents a benchmarking framework for evaluating the robustness of ML and DL models in classifying SARS-CoV-2 spike protein sequences. It introduces methods for perturbing sequences to simulate sequencing errors and evaluates the performance of various models using these perturbed sequences. The paper finds that DL models are generally more robust to these errors compared to traditional ML models, and that k-mer based representations are more robust than one-hot encodings.","['Can you provide a more detailed explanation of the experimental setup, including the parameters used for generating adversarial examples and training the models?', 'What is the justification for the choice of k-mer length (k=3) and other hyperparameters?', 'Can you discuss the evaluation metrics used and their relevance to the problem in more detail?', 'How do your results compare with state-of-the-art methods in the field?', 'Have you considered the ethical implications and potential negative societal impacts of your work?']","['The paper lacks clarity in the experimental setup and justification for hyperparameter choices.', 'The results section is not well-organized, making it difficult to follow the key findings.', 'There is a lack of comparison with state-of-the-art methods.', 'Ethical considerations and potential negative societal impacts are not adequately addressed.']",False,2,2,2,3,4,"['Addresses a critical and timely issue in the analysis of SARS-CoV-2 sequences, focusing on the robustness of ML and DL models to sequencing errors.', 'Introduction of methods to perturb sequences in ways that mimic real sequencing errors is a valuable contribution.', 'Comprehensive evaluation of several ML and DL models, providing useful insights into their robustness.']","['Lacks a clear and detailed explanation of the experimental setup, particularly the parameters used for generating adversarial examples and training the models.', 'Insufficient justification for the choice of k-mer length (k=3) and other hyperparameters.', 'Evaluation metrics and their relevance to the problem are not adequately discussed.', 'Results section is not well-organized, making it difficult to follow the key findings and their implications.', 'Lack of comparison with state-of-the-art methods in the field, which would provide a better context for the contributions of this work.', 'Ethical considerations and potential negative societal impacts are not adequately addressed.']",2,2,2,2,Reject
GlN8MUkciwi,The paper presents a novel approach to video-text retrieval by incorporating user comments through a Context Adapter Module (CAM). The method aims to filter relevant information from comments to improve retrieval performance. The authors demonstrate the effectiveness of their approach through extensive experiments on multiple datasets.,"['Can the authors provide more details and ablation studies on the modulation function and different types of aggregators?', 'Can the authors explain the autoencoder aggregator in more detail?', 'Can the authors provide additional qualitative examples in the rebuttal period?', 'Can the authors provide more details on the training process of the Context Adapter Module (CAM) and how it integrates with the existing models?', 'Did the authors consider other configurations or types of attention mechanisms in the CAM?', 'What are the potential limitations and negative societal impacts of this approach?', 'How does the proposed method handle irrelevant or adversarial comments? Are there any mechanisms in place to mitigate the impact of such comments?', 'Can the authors provide a more detailed analysis of the failure cases and propose potential solutions?']","['The paper needs to address the clarity of the methodology and provide more comprehensive ablation studies.', 'It should also discuss the ethical implications and potential negative societal impacts in more detail.', 'The potential biases introduced by user comments and the filtering mechanism need more attention.']",True,3,3,3,5,4,"['The use of user comments for video-text retrieval is a novel and practical idea.', 'The hierarchical attention mechanism effectively filters relevant information from comments.', 'Extensive experiments demonstrate the effectiveness of the proposed method.']","['The paper lacks detailed ablation studies, particularly concerning the modulation function and different types of aggregators.', 'The autoencoder aggregator is not clearly explained, which limits understanding.', 'More qualitative examples in the analysis would strengthen the paper.', 'The explanation of the training process for the Context Adapter Module (CAM) lacks clarity, particularly how it integrates with the existing models.', 'Potential limitations and negative societal impacts are not thoroughly discussed.', 'The novelty of the method is questionable, as it primarily extends existing transformer-based models with an additional attention mechanism for comments.', 'The potential for the method to be misled by irrelevant or adversarial comments is a significant issue.']",4,3,3,3,Reject
1-YP2squpa7,"The paper introduces a novel approach to training deep neural networks using a variant of Belief Propagation (BP) called focusing BP (fBP). This method aims to identify and exploit highly entropic regions in the loss landscape, which are expected to generalize better. The authors present a Posterior-as-Prior (PasP) update scheme to adapt this algorithm for mini-batch training on GPUs. The empirical results show that fBP can achieve competitive performance with SGD, particularly on sparse networks and in continual learning tasks.","['Can the authors provide more rigorous theoretical analysis to support their claims?', 'Can the authors expand the empirical evaluation to include a wider range of tasks and datasets?', 'Could the authors clarify the derivations and algorithmic details to make the paper more accessible?', 'What are the theoretical guarantees of the method, particularly regarding convergence?', 'Can the authors include additional ablation studies to isolate the contributions of different components of the method?', 'How does the performance of BP-based methods vary with different initialization strategies?', 'Can the authors compare their methods to a broader range of baselines, including more recent variants of SGD and other optimization techniques?']","['The main limitation of the paper is the lack of rigorous theoretical analysis and the limited empirical evaluation. The authors should address these points to make a stronger case for their method.', 'The complexity and extensive notation of the method may limit its accessibility and understanding. Additional ablation studies are needed to isolate the contributions of different components.']",False,2,2,3,4,4,"['The paper proposes a novel and creative approach to training deep neural networks using focusing BP.', 'The authors adapt the approach for mini-batch training on GPUs, making it feasible for large datasets.', 'The empirical results show promise, particularly in the context of sparse networks and continual learning tasks.', 'The Posterior-as-Prior (PasP) update scheme is an innovative adaptation of BP for mini-batch training on GPUs.']","['The theoretical foundation for the method is not rigorously developed.', 'The empirical evaluation is not comprehensive enough to demonstrate the superiority of fBP over SGD in a wide range of tasks.', 'The paper is dense and some sections could benefit from more clarity and conciseness.', 'The novelty of the approach is somewhat incremental as it mainly involves applying existing BP techniques in a new context.', 'The significance of the results is not well-established due to limited experimental validation and comparisons.']",3,2,2,3,Reject
hfU7Ka5cfrC,"This paper presents a hypergradient-based hyperparameter optimization method that supports arbitrary continuous inputs in a differentiable weight update formula. It aims to improve computational efficiency by requiring only one training episode and no restarts. The method performs competitively on various datasets, including UCI datasets, Fashion-MNIST, Penn Treebank, and CIFAR-10, using a one-layer MLP, LSTM, and ResNet-18, respectively.","['Can the authors provide more details on the choice and tuning of meta-learning rates?', 'How does the proposed method compare to other state-of-the-art hyperparameter optimization techniques in terms of performance and computational cost?', 'Can the authors discuss potential limitations and failure cases of the proposed method?', 'Can the authors provide more detailed ablation studies to better understand the impact of different components and hyperparameters of their method?', 'How does the proposed method handle overfitting, especially when using high-dimensional hyperparameter spaces?', 'Can the authors clarify the implementation of the autoencoder aggregator and provide more details on its impact on the results?', ""Can the authors provide more qualitative analysis and visualization of the results to better understand the method's performance?""]","['The paper does not adequately address potential limitations and failure cases of the proposed method. The authors should discuss scenarios where the method might not perform well and provide a more balanced evaluation.', 'The societal impact and ethical considerations section is well-explored but could benefit from more concrete examples and potential mitigation strategies.']",False,3,2,3,5,4,"['The method extends existing hypergradient-based optimization techniques to a broader class of hyperparameters, including learning rates and momentum factors.', 'The approach is theoretically motivated, with a convergence argument and derivation based on the implicit function theorem.', ""The empirical results demonstrate competitive performance across multiple datasets and models, showing the method's general applicability and robustness."", 'The method is computationally efficient, requiring only 2-3x more time than vanilla training.']","['The clarity of the methodology could be improved. The approximations and assumptions made during the derivation need to be better justified and explained.', 'The experimental setup lacks some crucial baselines, such as other state-of-the-art hyperparameter optimization techniques, making it challenging to assess the true performance improvements.', 'The paper does not provide enough detail on the implementation specifics, such as the choice of meta-learning rates and how they were tuned.', 'Potential limitations and failure cases of the proposed method are not adequately discussed. The authors should provide a more balanced evaluation, including scenarios where the method might not perform well.']",3,3,2,3,Reject
dLTXoSIcrik,"The paper addresses the issue of overfitting to importance weights in offline policy optimization by proposing a new algorithm, POELA (Policy Optimization with Eligible Actions). The authors identify a unique overfitting problem in optimizing the importance-weighted return and introduce a constraint on the policy class to mitigate this issue. Theoretical justifications and empirical evaluations on healthcare datasets demonstrate the effectiveness of the proposed method.","['Can the authors provide more details on the experimental setup and the parameters used in the experiments?', 'How does the proposed method compare with other state-of-the-art offline RL algorithms not included in the current experiments?', 'Can the authors provide more detailed ablation studies to understand the impact of different components of the algorithm, such as the modulation function and different types of aggregators?', 'Can the authors provide a clearer explanation of the autoencoder aggregator?', 'Can the authors provide more qualitative analysis cases to strengthen their findings?']","['The paper does not sufficiently address the limitations of the proposed method, particularly in terms of scalability and applicability to other domains beyond healthcare.', 'Potential negative societal impacts of the proposed method are not discussed.']",False,3,3,3,6,4,"['The paper tackles a relevant and well-motivated problem in offline reinforcement learning.', 'The proposed POELA algorithm introduces a novel approach to address the overfitting issue by imposing constraints on the policy class.', 'Theoretical justifications for the proposed method are provided, including proofs and mathematical analysis.', 'Empirical evaluations on both simulated and real-world healthcare datasets show promising results, indicating the effectiveness of the proposed method.']","['The clarity of the mathematical exposition and theoretical justifications could be improved to make it more accessible to readers.', 'The experimental setup and parameter choices are not described in sufficient detail, making it difficult to fully assess the validity of the experiments.', 'More ablation studies and comparisons with additional baselines would strengthen the empirical claims.', 'The paper could benefit from a more comprehensive discussion of related work and how the proposed method fits within the broader context of offline RL.']",3,3,3,3,Reject
-dzXGe2FyW6,"The paper introduces Equalized Robustness (ER), a new fairness objective designed to ensure fair model robustness against unseen distribution shifts across different data groups. It also proposes a novel algorithm called Curvature Matching (CUMA), which enforces ER by minimizing the maximum mean discrepancy (MMD) distance between loss curvature distributions of different groups. Experiments on three popular datasets demonstrate that CUMA achieves superior fairness in robustness against distribution shifts without sacrificing overall accuracy or in-distribution fairness.","['Can the authors provide more detailed explanations or visualizations for the one-shot power iteration method and its practical implementation?', 'How sensitive is the CUMA method to different hyperparameters and noise levels?', 'Can the authors explore the generalizability of CUMA to other types of distributional shifts or different datasets?', 'Can the authors provide more intuitive explanations for the mathematical formulations?', 'How does ER relate to existing fairness and robustness metrics?', 'Can the authors include more comprehensive experimental comparisons?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How does the method perform under other types of distribution shifts, such as domain adaptation scenarios?', 'Can the authors provide more details on the computational efficiency and scalability of the one-shot power iteration method?']","['The paper could benefit from providing more detailed practical implementation guidelines for the proposed methods.', 'Further ablation studies on the sensitivity of the proposed method to hyperparameters and noise levels would strengthen the paper.', 'The paper lacks a thorough discussion on the limitations of the proposed method.', 'Potential negative societal impacts are not addressed.', 'The paper focuses mainly on additive noise as a form of distribution shift, which may not fully capture the variety of real-world scenarios.', 'The computational overhead of the proposed method is not thoroughly discussed, which could impact its practical applicability.']",False,3,3,3,5,4,"['Addresses a significant and practical problem in machine learning fairness under distributional shifts.', 'Introduces a novel fairness metric (ER) and a method (CUMA) to achieve this fairness.', 'Comprehensive experiments demonstrate the effectiveness of the proposed method.', 'Maintains both in-distribution fairness and robustness under distribution shifts.']","['The practical implementation details of certain methodologies, such as the one-shot power iteration method, could be clearer.', 'Further ablation studies could be conducted to investigate the sensitivity of the proposed method to various hyperparameters.', 'The generalizability of the proposed method to other types of distributional shifts or different datasets could be further explored.', 'Lacks clarity in several sections, particularly in mathematical formulations.', 'Experimental setup and comparisons could be more comprehensive.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'The computational complexity and scalability of the proposed method, especially the one-shot power iteration method, are not thoroughly discussed.']",4,3,3,4,Reject
m8uJvVgwRci,"The paper presents a new paradigm called Weak Indirect Supervision (WIS) for synthesizing training labels from indirect supervision sources with mismatched output spaces. It introduces a probabilistic model, PLRM, to handle the mismatched output spaces and provides theoretical guarantees for the model's distinguishability and generalization. The empirical evaluations on text and image classification tasks, as well as a commercial advertising system, demonstrate the potential and effectiveness of the proposed approach.","['Can the authors provide more detailed ablation studies to analyze the impact of different components of the PLRM model?', 'Are there stronger baselines or additional datasets that can be used for comparison?', ""Can the clarity of the PLRM model's explanation be improved, possibly with more visual aids or step-by-step descriptions?"", 'Can the authors provide more details about the autoencoder aggregator used in the experiments?', ""What is the impact of different modulation functions and aggregators on the model's performance?"", 'Can the authors provide more details on the construction and selection of ILFs? How sensitive is the model to the quality and type of ILFs used?', 'How does the performance of the PLRM model change with varying sizes of the label graph?', 'Can the authors include a more detailed discussion on the computational complexity of the proposed method?', 'Can the authors provide additional ablation studies to evaluate the impact of different components of the model?', 'Can the authors provide more detailed descriptions of the autoencoder aggregator and other components?', 'Can the authors expand the qualitative analysis to include more examples and cases?', 'Can the authors provide more intuitive explanations or examples to enhance the clarity of the theoretical parts?', 'What are the practical limitations when applying PLRM to real-world datasets with more complex label structures?']","['The major concerns are the clarity of the paper and the need for more detailed empirical evaluations. Addressing these concerns could significantly improve the quality of the paper.', 'The scalability of the approach with respect to the number of ILFs and the size of the label graph is not thoroughly discussed.', 'The generalizability of the proposed method to other domains and types of data is not well established.', 'The paper does not fully address the potential limitations of the proposed method, such as its reliance on the quality and availability of label relations and the high variance in experimental results. It would be helpful to discuss these limitations and potential ways to mitigate them.', 'The major limitation is the complexity and clarity of the paper. The authors need to simplify the presentation and provide more intuitive explanations to make the paper more accessible.']",False,3,2,3,5,4,"['The paper addresses a practical and important problem in machine learning: creating training sets from weak, indirect supervision sources.', 'The proposed probabilistic model (PLRM) is novel and theoretically grounded.', 'Empirical evaluations on both academic datasets and a real-world application demonstrate the effectiveness of the approach.', 'The paper provides a new notion of distinguishability and a sanity test for ensuring the distinguishability of unseen labels.']","['The clarity of the paper, particularly the explanation of the PLRM model, could be improved.', 'The empirical evaluations could benefit from more detailed ablation studies and comparisons with stronger baselines.', 'The theoretical contributions need more empirical backing to demonstrate their practical relevance.', 'The paper is dense and complex, making it hard to follow.', 'Some components of the model, such as the autoencoder aggregator, are not described in sufficient detail.', 'The qualitative analysis could be expanded to include more examples and cases.', 'The experimental results show high variance, raising concerns about the general robustness of the proposed method.']",4,3,2,3,Reject
ckZY7DGa7FQ,"The paper proposes a novel framework called Belief Fine-Tuning (BFT) to improve belief state modeling in partially observable Markov systems. BFT leverages approximate dynamic programming to fine-tune belief models during inference, thereby increasing their accuracy. The method is demonstrated on the cooperative card game Hanabi, showing significant improvements in belief quality and downstream decision-time planning performance.","['Can the authors provide more details on the implementation of the autoencoder aggregator used in BFT?', 'How does the performance of BFT change with different hyperparameters and model architectures?', 'Can you provide more qualitative examples to illustrate the practical implications of BFT?', 'What are the computational costs associated with fine-tuning during inference, especially in large state spaces?', 'Can the authors provide more details on the generalizability of BFT to other domains?', 'What are the potential limitations of BFT, and how might they impact its applicability to other domains?']","['The paper does not adequately address the limitations of the proposed method and its potential negative societal impact. The authors should provide a more thorough discussion on these aspects.', 'The computational cost of fine-tuning during inference could be high, especially in large state spaces. The paper does not fully address this potential limitation.', 'The generalizability of the approach to domains other than Hanabi is not explored in the paper.']",False,3,3,3,6,4,"['The idea of fine-tuning belief state models at inference time is novel and leverages approximate dynamic programming.', 'The experimental results show significant improvements in belief model accuracy and downstream decision-making performance.', 'The paper addresses a significant issue in belief state modeling by introducing an inference-time improvement framework.']","['The paper lacks clarity in some sections, particularly in the detailed implementation of the BFT algorithm.', 'The experiments are primarily focused on Hanabi, which may limit the generalizability of the results to other domains.', 'More extensive ablation studies are needed to validate the robustness of the proposed method.', 'The authors did not adequately address possible limitations and potential negative societal impact of their work.']",3,3,3,4,Reject
e6MWIbNeW1,"The paper proposes an Inductive Graph Partitioning (IGP) framework aimed at balancing the quality and efficiency of graph partitioning tasks across multiple graphs. The approach involves training a dual Graph Neural Network (GNN) on historical graph snapshots to capture system properties, which is then generalized to new graphs for fast, high-quality online graph partitioning without additional optimization.","['Can the authors provide more details on the impact of each component of the model through ablation studies?', 'How does the model handle the negative transfer observed in the transferring test?', 'Can the authors discuss potential societal impacts and ethical considerations of their method?', 'How does the model perform on extremely large graphs, and what are the scalability limitations?', 'Can the authors provide more real-world applications and less reliance on synthetic benchmarks?', 'Could the methodology section be clarified, particularly the details of the dual GNN structure and optimization processes?', 'What are the potential limitations and negative societal impacts of this work?']","['The paper does not discuss potential negative societal impacts or ethical considerations. This is an important aspect that should be addressed to understand the broader implications of the proposed method.', 'The paper should address the limitations more explicitly, particularly concerning the scalability and computational complexity of the proposed method. Additionally, the potential negative impacts of any assumptions made (e.g., availability of historical graph data) should be discussed.']",False,2,3,2,5,4,"['The paper addresses an important problem of balancing quality and efficiency in graph partitioning, which is NP-hard.', 'The proposed dual GNN structure and the use of permutation invariant label information are innovative.', 'The method can handle graphs with non-fixed numbers of nodes and clusters.', 'Extensive experiments and comparisons with various state-of-the-art methods, including both synthetic and real-world datasets, show the competitiveness of the proposed approach.']","['The paper is complex and dense, making it difficult to follow. The clarity could be significantly improved.', 'The ablation studies are not comprehensive enough. More details on the impact of each component of the model would be beneficial.', 'Some of the experimental results, particularly the transferring test, show significant quality declines, which question the robustness of the model.', 'The potential societal impacts and ethical considerations of the proposed method are not discussed.', 'Potential scalability issues when dealing with extremely large graphs or real-time applications.', 'Heavy reliance on synthetic benchmarks; more real-world applications could strengthen the validation.']",3,3,3,3,Reject
QNW1OrjynpT,"The paper investigates the memory retrieval capabilities of neural language models, specifically comparing transformers and LSTMs. It evaluates how well these models can recall previously seen tokens under various conditions, such as the number of tokens, their semantic coherence, and the length of intervening text. The study finds that transformers can retrieve verbatim tokens and their order robustly, whereas LSTMs exhibit more gist-like memory over shorter distances.","['Could you provide more details on the setup and results of the intervening text experiments?', 'Have you considered testing other types of language models or additional architectural variations of LSTMs?', 'Can the authors provide more justification for the specific experimental designs chosen?', 'Have potential enhancements to LSTM architectures been considered in the comparison?', 'How do the findings align with or diverge from existing literature on memory in neural networks?', 'When will the code repository be made available?', 'Can you provide more details on the specific hyperparameters and configurations used for the transformers?', 'Would it be possible to include comparisons with other models or configurations?']","['The paper mainly focuses on transformers and LSTMs, and it could be enriched by including other models or variations.', 'The clarity of the methodology and results sections could be improved.', 'The study is limited by its focus on basic transformer and LSTM models, without considering architectural enhancements that could improve performance.', 'The paper would benefit from additional control experiments to validate the robustness of the findings.', 'The primary limitation is the lack of immediate code availability for reproducibility.']",False,3,3,3,5,4,"['The problem addressed is highly relevant and practical in the field of language modeling.', 'The paper provides a comprehensive set of experiments that thoroughly evaluate the memory capabilities of the models.', 'The results are significant, showing clear differences between transformers and LSTMs in terms of memory retrieval.', 'The conclusions drawn are well-supported by the experimental data.']","['Some sections of the paper could be clearer, particularly in the methodology and results discussion.', 'Additional ablation studies could strengthen the findings, such as varying the number of layers in LSTMs or testing other types of language models.', 'The paper could benefit from a more detailed explanation of certain experimental setups and results.', 'Methodological choices lack clear justification, particularly in experimental design.', 'Comparison between transformers and LSTMs could be more nuanced, considering potential enhancements to LSTM architectures.', 'Significance of findings needs better contextualization within the broader literature.', 'Reproducibility is not fully ensured as the code repository is not yet available.']",3,3,3,4,Reject
R332S76RjxS,"The paper provides a global convergence theory for gradient descent in over-parameterized implicit neural networks with ReLU activation functions. It demonstrates that with appropriate scaling of the weight matrix and random initialization, the gradient descent method converges to a global minimum at a linear rate. The theoretical contributions are supported by rigorous mathematical proofs, and the work addresses a significant gap in the theoretical understanding of implicit neural networks.","['Can the authors provide more empirical validation to demonstrate the practical applicability of the theoretical findings?', 'How do the assumptions regarding initialization and data impact the applicability of the proposed theory in real-world scenarios?', 'Can the authors provide more intuition and high-level explanations of the key steps in the mathematical proofs to enhance readability?', 'Can the authors provide more comprehensive experimental validations on a wider range of datasets?', 'What are the practical implications of the theoretical findings? How can they be applied in real-world scenarios?', 'Can the authors elaborate on the potential limitations of the proposed approach?']","['The paper assumes specific conditions regarding initialization and data that may not always hold in practice. Additionally, the empirical validation is limited, and the mathematical proofs are dense, which may hinder understanding for a broader audience.', 'The practical implications and limitations of the theoretical results are not thoroughly discussed.']",False,3,3,4,6,4,"['Theoretical contributions are significant and well-founded, providing a rigorous analysis of convergence in implicit neural networks.', 'The paper addresses an important problem in the field of deep learning, particularly in understanding the behavior of implicit neural networks.', 'The mathematical proofs are thorough and detailed, demonstrating a deep understanding of the subject matter.', 'The approach of using over-parameterization to ensure convergence is novel.']","['The empirical validation is limited and does not comprehensively demonstrate the practical applicability of the theoretical findings.', 'Some key concepts and assumptions are not clearly explained, making the paper less accessible to a broader audience.', 'The assumptions regarding initialization and data may not always hold in real-world scenarios, which is not sufficiently discussed.', 'The mathematical proofs, while thorough, are dense and may be challenging for readers who are not experts in this area. More intuition and high-level explanations would enhance readability.']",4,3,2,3,Accept
V3C8p78sDa,"The paper investigates the effects of scaling up data, model size, and training time on the transfer learning performance of upstream and downstream tasks. It conducts a large-scale meta-study involving more than 4800 experiments on Vision Transformers, MLP-Mixers, and ResNets, and proposes a power law model to capture the nonlinear relationship between upstream and downstream performance. The study reveals that downstream performance saturates as upstream accuracy improves and provides insights into the factors influencing this saturation.","['Can the authors provide more details on the implementation of the autoencoder aggregator?', 'Could the authors conduct additional ablation studies to explore the robustness of the proposed methods, particularly the impact of different hyper-parameters and architectural choices?', 'Could you provide more theoretical justification for using a power law model to predict downstream performance?', 'Can you include more details on the hyper-parameters used in the experiments and their impact on the results?', 'How robust are the findings across different settings? Can you provide additional experiments to validate this?', 'Can the authors provide more detailed explanations of the reasons behind the observed saturation behavior in downstream performance?', 'Can the authors provide more detailed information on the experimental setup and hyperparameters to improve reproducibility?', 'Can the authors discuss the potential limitations and ethical considerations of the proposed approach, particularly in terms of the computational and environmental costs of large-scale training?', 'How generalizable is the proposed power law model to other domains or tasks outside of image recognition?', 'How does the proposed power-law model compare to other existing models in terms of predictive accuracy?']","['The potential lack of clarity in some methodological details and the need for additional ablation studies to explore the robustness of the proposed methods.', 'The complexity of the study may make it challenging to reproduce the results, and the paper could provide more detailed information on the experimental setup and hyperparameters.', 'The generalizability of the proposed model to other domains needs further discussion.', 'The findings are somewhat intuitive and might not offer groundbreaking insights.', 'The paper could include more discussions on the potential limitations and ethical considerations of the proposed approach, particularly in terms of the computational and environmental costs of large-scale training.']",False,3,3,3,6,4,"['The paper addresses an important and practical problem in transfer learning, particularly the diminishing returns of scaling.', 'The large-scale meta-study and controlled experiments provide strong empirical evidence for the findings.', 'The proposed power law model to predict downstream performance based on upstream accuracy is novel and well-supported by the data.', 'The paper includes a thorough analysis of the impact of hyper-parameters and architectural choices on transfer learning performance.']","['Some methodological details, such as the implementation of the autoencoder aggregator, are not clearly explained.', 'Additional ablation studies could further validate the robustness of the proposed methods and findings.', 'The paper could benefit from more detailed qualitative analysis and visualization of the results to enhance understanding.', 'The theoretical justification for using a power law model could be clearer.', 'The generalizability of the proposed model to other domains or tasks is not thoroughly discussed.', 'The findings are somewhat intuitive and might not be groundbreaking.']",3,3,3,3,Reject
EVqFdCB5PfV,"The paper introduces DOCHOPPER, a model that iteratively attends to different parts of long, hierarchically structured documents to answer complex questions. The model utilizes a hierarchical attention mechanism and updates queries in the embedding space, achieving state-of-the-art results on multiple QA datasets while being significantly more efficient at inference time.","['Can the authors provide more detailed explanations of the query updating mechanism and the mixing step?', 'How were the hyperparameters tuned for each dataset, and were there any dataset-specific adjustments made?', 'Can the authors provide more insights into the lower performance on the HybridQA dataset and discuss potential improvements?', ""Could the authors include additional qualitative analyses and error analyses to help understand the model's limitations better?"", 'Can you provide more details on how DOCHOPPER handles different document structures and adapts to various dataset specifics?', 'Could you include more comprehensive ablation studies to better understand the contributions of each component?', 'How do the training and inference times scale with document length?', 'What are the potential limitations and challenges of applying DOCHOPPER in real-world scenarios?', 'Can the authors provide more clarity on the query update mechanism? How does it compare to traditional concatenation-based methods in terms of interpretability?', 'How does DOCHOPPER handle cases where the hierarchical structure of the document is more complex than the two levels considered?', 'Can the authors provide more examples of failure cases and discuss the potential limitations of the model?', 'Can the authors provide more details about the implementation of the autoencoder aggregator and modulation function?', ""Would it be possible to include more qualitative analysis and visualizations to support the model's effectiveness?""]","[""The main concerns revolve around the clarity of the methodology and some unexplained aspects of the experimental setup. Addressing these issues would strengthen the paper's contributions."", 'The paper could benefit from more comprehensive ablation studies and further explanations regarding the scalability of training and inference times. Additionally, a discussion on potential limitations and challenges in real-world applications would be useful.', ""The paper does not adequately address the potential limitations and failure cases of the proposed model. A discussion on these aspects would be valuable for understanding the boundaries of the model's applicability."", 'While the paper addresses several limitations, more clarity on the implementation of certain components and additional qualitative analysis would strengthen the work.', ""The paper needs additional clarity on the implementation details and more qualitative examples to illustrate the model's approach.""]",False,3,3,3,7,4,"['Novel hierarchical attention mechanism for handling long, structured documents.', 'Efficient query updating in the embedding space, making the model faster than previous approaches.', 'Empirical results demonstrate state-of-the-art performance on three QA datasets.', 'Comprehensive experiments, including ablations, validate the effectiveness of the proposed approach.', 'Addresses a significant and practical problem in QA over long documents.', 'Well-organized and thorough explanation of methodology and experiments.', 'The approach is efficient at inference time, reducing computation costs significantly.']","['The methodology section could benefit from clearer explanations, particularly regarding the query updating mechanism and the mixing step.', 'Some aspects of the experimental setup, such as the tuning of hyperparameters and the handling of various dataset-specific details, need further clarification.', ""The performance on the HybridQA dataset is notably lower than the state-of-the-art, which raises questions about the model's adaptability to different types of data."", ""The paper would benefit from additional qualitative analyses and more detailed error analysis to understand the model's limitations better."", 'Some details about handling different document structures and dataset specifics are unclear.', 'Ablation studies could be more comprehensive.', 'More explanation needed on training and inference time scalability.', 'Potential limitations and real-world application challenges are not discussed in depth.', 'The explanation of the model, especially the attention and query update mechanism, could be clearer. The paper is dense and hard to follow in some sections.', 'The paper lacks an in-depth discussion on the limitations and potential failure cases of the proposed model.', 'The implementation details of the autoencoder aggregator and modulation function are not fully clear.', 'The paper could benefit from more qualitative analysis and visualizations to support its claims.']",3,3,3,4,Accept
3ILxkQ7yElm,"The paper introduces a novel scene representation called the environment field, which encodes reaching distances between any position in a scene and a goal along a feasible trajectory. This representation is learned using neural implicit functions from discretely sampled training data. The approach is applied to agent navigation in 2D mazes and human trajectory prediction in 3D indoor environments, demonstrating competitive or superior performance against several baseline techniques.","['Can the authors provide more details on the implementation and training of the conditional VAE?', 'Could the authors offer more insights into the failure modes of their approach and how these might be mitigated?', 'Can the authors provide more detailed comparisons with a broader range of state-of-the-art methods?', 'Can the authors clarify the training process for the implicit function?', 'Can the authors provide more extensive ablation studies to better understand the contributions of different components?', 'Have you considered other architectures or variations of implicit functions, and how do they compare with the proposed method?', 'Can you include more qualitative results and visualizations to demonstrate the effectiveness of the method in different scenarios?', 'How does the proposed method perform in comparison to other state-of-the-art path planning and trajectory prediction methods in more diverse settings?']","['The paper would benefit from a more explicit discussion of its limitations, particularly in terms of the scalability of the approach to very large and complex environments.', 'Potential failure cases, such as those involving complex human motions not well-suited to the generated trajectories, should be discussed more thoroughly.', 'The main concern is the clarity of the methodology and the reproducibility of the experiments. The paper should address these issues and provide a more detailed discussion of potential limitations and failure cases.']",False,3,3,3,6,4,"['The concept of an environment field that encodes reaching distances using implicit neural functions is novel and compelling.', 'The method is shown to be effective for both agent navigation in 2D mazes and human trajectory prediction in 3D scenes.', 'Extensive experiments and ablation studies are provided to demonstrate the efficacy of the proposed approach.', 'The paper leverages neural implicit functions to learn a continuous field from discretely sampled data, which is a strong methodological contribution.']","['Certain sections, particularly those describing the conditional VAE and trajectory alignment processes, are dense and could benefit from more detailed explanations.', 'The evaluation lacks a thorough discussion on the limitations and potential failure modes of the proposed approach.', 'The clarity of some methodological details could be improved to make the paper more accessible to a broader audience.', 'Experimental comparisons lack thorough evaluation against a wider range of state-of-the-art methods.', 'Ablation studies are limited and do not thoroughly explore the contributions of different components.', 'The paper could benefit from additional qualitative results to further demonstrate the effectiveness of the proposed method in various scenarios.']",4,3,3,3,Reject
ccWaPGl9Hq,"The paper presents a novel theoretical framework for Deployment-Efficient Reinforcement Learning (DE-RL), focusing on minimizing the number of policy deployments while maintaining high performance. It provides information-theoretic lower bounds for deployment complexity in linear MDPs and proposes algorithms that achieve optimal deployment efficiency.","['Can the authors provide more details and practical examples of how the reachability coefficient νmin is calculated?', 'How do the proposed algorithms perform in more complex environments beyond linear MDPs?', 'Can the authors include more experimental results to validate the theoretical claims, especially in diverse and practical RL settings?', 'Can the paper be made more accessible by reducing the reliance on dense mathematical formalism and improving the clarity of explanations?', 'How do the proposed methods scale with the size of the state and action spaces in real-world applications?', 'Are there plans to extend the DE-RL framework to other types of MDPs or function approximations?']","['The paper does not provide sufficient experimental validation to support the theoretical claims.', 'The clarity of the theoretical explanations needs improvement to make the paper more accessible to a broader audience.', 'The reliance on linear MDPs may limit the generalizability of the results to more complex RL environments.']",False,3,3,3,6,4,"['The paper introduces a novel and relevant concept of deployment efficiency in reinforcement learning, addressing a practical need in real-world applications.', 'It provides a rigorous theoretical framework for DE-RL, including information-theoretic lower bounds for deployment complexity.', 'The proposed algorithms are theoretically sound and achieve near-optimal deployment efficiency.', 'The framework is flexible and can potentially be extended to other settings, such as Safe DE-RL and Sample-Efficient DE-RL.']","['The paper is dense with theoretical details, making it difficult for readers to follow without a strong background in RL and information theory.', 'The experimental validation is limited, and additional experiments are needed to demonstrate the practicality and effectiveness of the proposed algorithms.', 'Clarifications are needed regarding the assumptions made in the theoretical analysis, especially concerning the reachability coefficient and its practical implications.', ""The practical scenarios mentioned in the introduction (e.g., healthcare, robotics) are not backed up by corresponding experiments, reducing the paper's immediate practical impact.""]",4,3,3,4,Reject
BlyXYc4wF2-,"The paper presents two novel algorithms, MACPO and MAPPO-Lagrangian, for safe multi-agent reinforcement learning (MARL). These algorithms combine constrained policy optimization with multi-agent trust region learning to ensure both reward maximization and safety constraint satisfaction. The authors also introduce a new benchmark suite, Safe Multi-Agent MuJoCo, to evaluate their methods.","['Can the authors provide more detailed ablation studies to highlight the contribution of each component of their methods?', 'Can the authors clarify the mathematical formulations and derivations in the paper, particularly in the sections describing the algorithms?', 'Have the authors considered testing their methods in more diverse and challenging environments beyond the Safe Multi-Agent MuJoCo suite?', 'Can the authors provide more intuitive explanations and step-by-step derivations for the theoretical results in Sections 3 and 4?', 'Can the authors provide more details on the hyperparameter tuning process and the computational resources used in the experiments?', 'Have the authors considered comparing their methods with other state-of-the-art safe MARL methods beyond the proposed algorithms and the baseline MARL methods?', 'Can the authors provide more practical implementation details, especially for the duality-based optimization and backtracking line search steps in MACPO?', 'How does the Safe Multi-Agent MuJoCo benchmark compare to existing benchmarks or real-world scenarios?']","['The paper is quite complex, and some sections lack clarity. The authors should consider simplifying the presentation and providing more detailed explanations for the key components of their methods.', 'The proposed methods might be difficult to implement and reproduce due to their complexity. Providing detailed pseudocode and implementation guidelines would be beneficial.', 'The experimental validation is limited to the MuJoCo environment; more diverse environments and tasks would strengthen the validation.', 'The paper does not adequately address the limitations of the proposed methods. For example, it would be helpful to discuss potential scalability issues, the impact of the number of agents on performance, and any assumptions made in the theoretical guarantees.']",False,3,3,3,6,4,"['Addresses a significant and practical problem in MARL: ensuring safety constraints while optimizing policies.', 'Proposes novel algorithms (MACPO and MAPPO-Lagrangian) with theoretical guarantees for monotonic improvement in reward and satisfaction of safety constraints.', 'Introduces a new benchmark suite, Safe Multi-Agent MuJoCo, which is valuable for the research community.', 'Provides comprehensive experimental results demonstrating the effectiveness of the proposed methods.']","['The paper lacks detailed ablation studies, which would help in understanding the contribution of each component of the proposed methods.', 'Some sections of the paper are dense and challenging to follow, particularly the mathematical formulations and derivations.', 'The experimental validation is limited to the MuJoCo environment; more diverse environments and tasks would strengthen the validation.', 'The paper does not include a comparison with other state-of-the-art safe MARL methods beyond the proposed algorithms and the baseline MARL methods.', 'Limited practical implementation details, especially for the duality-based optimization and backtracking line search steps in MACPO.']",3,3,3,4,Reject
Dup_dDqkZC5,"The paper proposes 'AutoBot', a novel model based on latent variable sequential set transformers for joint multi-agent motion prediction. It leverages temporal and social multi-head self-attention mechanisms to generate scene-consistent trajectories and is evaluated on datasets like nuScenes, Argoverse, TrajNet++, and Omniglot, showing competitive results.","[""Can the authors provide more insights into the design choices for the autoencoder aggregator and its role in the model's performance?"", 'How does the model handle potential data imbalances or rare events in the trajectory datasets?', ""Could the authors share more qualitative examples of the model's predictions on different datasets?"", 'Can the authors provide more detailed ablation studies on the impact of various hyperparameters and architectural choices?', ""How does the model's performance scale with an increasing number of agents or prediction horizons?"", 'Can the authors provide a more explicit comparison of computational efficiency and model complexity with baseline methods?', 'How well does the model generalize to other datasets and domains beyond nuScenes and Argoverse?', 'Can the authors provide a more thorough comparison of the unique contributions, such as the use of learnable seed parameters, with baseline methods?']","['Relies on a perceptual pipeline for input data, which may not capture all entities in real-world scenarios.', 'Memory limitations could restrict the number of sets processed simultaneously.', 'Future work plans are mentioned but lack concrete steps for addressing the limitations.', 'Potential societal impacts, especially concerning autonomous driving, should be discussed more thoroughly.']",False,3,3,3,6,4,"['Introduces a novel combination of temporal and social multi-head self-attention mechanisms for multi-agent trajectory prediction.', 'Shows strong empirical results on challenging benchmarks.', 'Provides thorough theoretical analysis of permutation sensitivity and extensive ablation studies.', 'Model is computationally efficient, trainable on a single GPU within reasonable timeframes.']","['Lacks detailed explanations for some architectural choices, such as the autoencoder aggregator.', 'Could benefit from additional qualitative examples to showcase model predictions across diverse scenarios.', 'Ablation studies, while comprehensive, could explore more variations in modulation functions and aggregators.', 'Clarity of some sections could be improved, particularly regarding training objectives and latent variable use.', 'Potential overemphasis on specific datasets (nuScenes and Argoverse) without sufficient evidence of broader generalization to other domains.', 'Limitations and potential negative societal impacts need more thorough discussion.']",3,3,3,4,Reject
x4tkHYGpTdq,"The paper proposes Dually Sparsity-Embedded Efficient Tuning (DSEE) for fine-tuning large pre-trained language models efficiently. DSEE leverages both unstructured and structured sparsity to achieve parameter- and resource-efficiency. Extensive experiments demonstrate the effectiveness of DSEE across various models (BERT, GPT-2, DeBERTa) and datasets, showing significant improvements in computational and memory efficiency without sacrificing performance.","['Can the authors provide more details about the autoencoder aggregator?', 'What is the impact of using different modulation functions and types of aggregators?', 'Can the authors provide more visualizations and examples in the qualitative analysis?', 'How does the choice of rank r in the low-rank decomposition affect the performance across different datasets?', 'Can you provide more ablation studies on the impact of different hyperparameters, such as the learning rate and the sparsity levels?', 'What are the potential limitations of DSEE when applied to even larger models like GPT-3 or different types of tasks?']","['The main limitations are the potential complexity of implementing the proposed method and the need for additional ablation studies to fully understand the impact of different components and settings.', 'The paper should discuss the potential limitations of applying DSEE to larger models and different types of tasks.', 'More extensive ablation studies on the impact of different hyperparameters are needed.', 'The paper should consider the potential negative societal impacts of deploying highly compressed models in various applications.']",False,3,2,3,5,4,"['Addresses a critical issue in NLP related to the efficiency of fine-tuning large pre-trained models.', 'Introduces a novel approach that combines unstructured and structured sparsity for efficient fine-tuning.', 'Demonstrates significant improvements in parameter- and resource-efficiency while maintaining competitive performance.', 'Provides comprehensive experimental results across multiple models and datasets, including ablation studies and sensitivity analyses.', 'Detailed comparative analysis with state-of-the-art methods, showing the superiority of DSEE in various scenarios.']","['Some sections lack clarity, particularly the details of the autoencoder aggregator and certain parts of the methodology.', 'Additional ablation studies are needed to explore the impact of different modulation functions and types of aggregators.', 'Potential complexity in implementing the proposed method might hinder its adoption.', 'More visualizations and examples in the qualitative analysis would strengthen the empirical evidence.', 'Combines existing techniques (sparsity and low-rank updates) rather than introducing fundamentally new ideas.', 'The presentation of results and comparisons in the experimental setup lacks clarity.']",3,3,2,4,Reject
Rupm2vTg1pe,"The paper introduces the Infinite Contextual Graph Markov Model (ICGMM), which extends the Contextual Graph Markov Model (CGMM) using Hierarchical Dirichlet Processes (HDP) to automatically adjust the complexity of each layer. The model is evaluated on eight graph classification tasks, showing competitive performance against supervised methods. A novel approximated inference procedure is proposed to improve scalability.","['Can the authors provide more details on the inference procedure, particularly the approximations used?', 'How would the model handle edge features if they were to be included?', ""What are the theoretical impacts of the approximations on the model's guarantees?"", 'Can the authors provide more intuitive explanations or visual aids to better understand the integration of Hierarchical Dirichlet Processes into the model?', 'How does the approximated inference procedure impact the performance compared to the exact method across different datasets?', 'Can the authors provide more details on the practical implementation and potential limitations of the proposed method?']","['The paper does not account for edge features, which could limit its applicability.', 'The scalability improvements are based on approximations, which may impact the theoretical guarantees.', 'The complexity of the method and the clarity of its presentation are major concerns.', 'The impact of the approximated inference procedure on performance needs more detailed analysis.']",False,3,3,4,5,4,"['Addresses an important issue in graph learning: automatic selection of layer sizes and hyper-parameters.', 'The use of HDP in the CGMM framework is novel and theoretically grounded.', 'Competitive performance against end-to-end supervised methods.', 'Extensive and reproducible experimental setup.']","['Lacks clarity in some methodological explanations, particularly the inference procedure.', 'Scalability improvements are based on approximations, potentially impacting theoretical guarantees.', 'Does not account for edge features, limiting applicability to certain graph types.', 'The paper is dense and might be difficult to follow for readers not familiar with Bayesian nonparametrics and graph neural networks.']",4,3,3,4,Reject
RB_2cor6d-w,"The paper proposes APSyn, an adversarial program synthesizer, to generate multi-patch adversarial attacks that are targeted and have minimal L2 distortion. The approach combines enumerative synthesis and numerical optimization to search for optimal patch parameters. The evaluation covers multiple datasets, including MNIST, Fashion-MNIST, CIFAR-10, and ImageNet, demonstrating high success rates and better generalization compared to the C&W attack.","['Can the authors provide a clearer explanation of the optimization process?', 'How does APSyn compare to the C&W attack in more detail?', 'What are the potential negative societal impacts of this work?', 'Can the authors explore ethical considerations in more depth?', 'Can the authors provide more details on the implementation of the gradient estimation for discrete variables?', 'How does the method handle cases where patches overlap significantly? Are there any constraints or additional steps taken to ensure optimal placement?', 'Can the authors provide more examples or case studies demonstrating the practical execution of these attacks in real-world scenarios?']","['The methodology section requires more clarity, particularly the optimization process.', 'The paper should include a more detailed comparison with existing methods and discuss the potential negative societal impacts and ethical considerations.', 'The complexity of the method may affect reproducibility and practical implementation.', 'The evaluation could be more comprehensive, including comparisons with other state-of-the-art physical adversarial attacks.']",True,3,2,3,5,4,"['Addresses a significant problem of making physical adversarial attacks imperceptible.', 'Innovative use of enumerative synthesis and numerical optimization.', 'Extensive evaluation on multiple datasets.', 'Shows promising results with high success rates and low L0 distortion.']","['The explanation of the methodology, especially the optimization process, is not very clear.', 'Comparisons with existing methods like the C&W attack could be more thorough.', 'Lacks a detailed discussion on potential negative societal impacts.', 'Ethical considerations are not deeply explored.', 'The explanation of the gradient estimation for discrete variables is not very clear.', 'The practical implications and robustness of the proposed attacks in real-world scenarios are not thoroughly evaluated.']",4,3,2,4,Reject
0uZu36la_y4,"The paper proposes Class-Focused Online Learning (CFOL) to improve the worst class performance in adversarial training. It uses a bandit algorithm to adaptively sample from an adversarial distribution over classes, aiming to minimize the worst class error. The paper provides theoretical convergence guarantees and extensive experimental results demonstrating the effectiveness of CFOL across multiple datasets.","['Can you provide more details on the implementation of the autoencoder aggregator?', 'How sensitive is CFOL to the choice of hyperparameters? Can you provide more insights into the hyperparameter tuning process?', 'Can you provide more detailed pseudo-code or diagrams to better illustrate the integration of CFOL into existing training setups?', 'What is the impact of the proposed method on the clean accuracy?', 'Can you conduct more ablation studies to understand the contribution of different components, such as the choice of mixing parameter γ and step-size η?', 'Can the authors clarify the novel contributions of CFOL compared to existing methods like LCVaR more explicitly?', 'Can the theoretical justifications be simplified or supplemented with more intuitive explanations?', 'What are the practical trade-offs between improving the worst class performance and the average performance?', 'Have the authors considered any potential ethical concerns related to their method?', 'Can you discuss the computational overhead introduced by CFOL in more detail?']","['The method primarily focuses on the worst class performance, which might not be suitable for all applications. The trade-off between average and worst class performance needs to be carefully considered.', 'The paper does not fully explore the limitations of CFOL, such as its performance under different attack scenarios and its computational overhead.', 'The theoretical assumptions made for the convergence guarantees might not hold in all practical scenarios, potentially impacting the reliability of the results.', 'Potential negative societal impacts are not discussed, even though adversarial robustness is a critical aspect of security in AI systems.']",False,3,2,3,6,4,"['Addresses a significant issue in adversarial training: the non-uniform class accuracy.', 'Introduces a novel method using a bandit algorithm to learn an adversarial distribution over classes.', 'Provides theoretical convergence guarantees.', 'Comprehensive experimental evaluation across multiple datasets showing significant improvement in the worst class accuracy.']","['The clarity of the presentation, particularly the explanation of the CFOL algorithm, needs improvement.', 'More ablation studies are needed to thoroughly evaluate the impact of different components of the proposed method.', 'The implementation details, particularly those concerning the integration of CFOL into existing setups, could be more comprehensive.', 'The paper does not adequately discuss the potential limitations and negative societal impacts of the proposed method.']",3,3,2,3,Reject
AAeMQz0x4nA,"The paper proposes Explicit Credit Assignment joint Q-learning (ECAQ), a novel approach to address the credit assignment problem in multi-agent reinforcement learning. ECAQ leverages deep neural networks to optimize the assignment of credits amongst agents, demonstrating superior performance in challenging environments like StarCraft II and cooperative navigation. The method combines temporal difference learning with a novel criterion for optimizing joint Q-values, aiming to improve both performance and interpretability.","['Can you provide more details about the Consistency Network and Transformation Network?', 'Have you considered any other types of aggregation functions for the weighting vectors?', 'Could you include more ablation studies to show the impact of each component in your model?', 'How does ECAQ compare with other advanced methods like Qatten, QTRAN++, and QPLEX in terms of fitting non-monotonic payoffs and overall performance?', 'Can you elaborate on the ethical concerns mentioned in the paper and propose potential solutions to address these issues?', 'How does your method scale with a significantly larger number of agents?', 'What is the rationale behind the specific choice of baselines for comparison?', 'Can you provide more detailed ablation studies and sensitivity analyses?']","['The paper does not provide sufficient details on how to reproduce the experimental results, which could be critical for validating the method.', 'There is a lack of discussion on potential negative societal impacts, especially considering the ethical concerns of sacrificing certain agents for maximizing the global reward.', ""The method's reliance on deep neural networks implies a 'black box' problem, which could be mitigated by providing more interpretability tools and analyses."", 'The method may not perform well in non-monotonic payoff scenarios due to the non-negativity constraints on the Transformation Network and weighting vectors.']",False,3,2,3,6,4,"['Addresses a significant issue in multi-agent systems: explicit credit assignment.', 'Proposes a novel method (ECAQ) with both theoretical and empirical validation.', 'Shows superior performance in various challenging tasks compared to advanced baselines.', 'Includes comprehensive experiments and analyses to support the findings.']","['The clarity of the methodology, especially the detailed workings of the Consistency Network and Transformation Network, needs improvement.', 'The paper lacks detailed ablation studies for some components which could help in understanding their specific contributions.', 'The reproducibility of results might be challenging without the exact hyperparameters and configurations used.', 'The originality of the paper is moderate since the concept of explicit credit assignment is not entirely new, even though the specific implementation details are novel.', 'The paper mentions potential ethical issues related to the credit assignment but does not provide a thorough discussion or solutions to address these concerns.']",3,3,2,4,Reject
PGGjnBiQ84G,"The paper proposes a novel approach to learn texture mapping for 3D surfaces, specifically applied to document image unwarping. It introduces a surface parameterization network that is trained using multi-view images and rendering loss, achieving state-of-the-art results in document unwarping tasks. The method utilizes a prior for shape-specific texture mapping and a conformality constraint for realistic paper folds.","['Can you provide more details on the autoencoder aggregator?', 'Have you considered different types of modulation functions and their impact on the results?', 'Can you provide additional visual examples in the qualitative analysis?', 'Can you elaborate more on the loss functions, especially Lz, LE, LF, and LG?', 'What are the potential limitations of the proposed method?', 'How does the method handle variations in document textures and lighting conditions?', 'Can you analyze the results by reducing the number of gating parameters in Eq. 10 by sharing the gate value of each filter in Conv layers?', 'What are the computational requirements for training and inference?']","['High training time and potential societal impacts of texture editing are significant limitations. These should be addressed in more detail to ensure the practicality and ethical considerations of the proposed method.', 'The method may have limited applicability to specific domains like documents and fabrics.']",False,3,3,3,5,4,"['Addresses a significant problem in document unwarping and achieves state-of-the-art results.', 'Integrates texture mapping into the differentiable rendering pipeline, enhancing neural rendering methods.', 'Comprehensive experimental results, including both synthetic and real-world datasets, demonstrate the effectiveness of the proposed approach.']","['The novelty is moderate as it builds on existing methods like NeRF and IDR.', 'Clarity is lacking in several sections, particularly in explaining the autoencoder aggregator and its role in the method.', 'High training time limits practical applicability, making it unsuitable for real-time applications.', 'Additional ablation studies are needed, particularly concerning the choice of modulation functions and the impact of different aggregators.', 'Potential societal impacts of texture editing, both positive and negative, should be more thoroughly discussed.']",3,3,3,4,Reject
xDIvIqQ3DXD,The paper investigates the approximation properties of recurrent encoder-decoder architectures in a linear setting. It establishes universal approximation results and introduces the concept of 'temporal product structure' to explain the approximation capabilities of these architectures. The paper provides rigorous mathematical proofs and numerical illustrations to support its claims.,"['Can the authors provide more practical examples or applications of their theoretical findings?', 'How do the theoretical results translate to real-world sequence-to-sequence tasks?', 'Can the authors provide more intuitive explanations or visualizations to help a broader audience understand the theoretical results?', 'Can the authors conduct more extensive experiments on diverse datasets to validate the theoretical results?']","[""The paper's dense mathematical content might limit its accessibility to a broader audience. Additional explanations or simplifications could help address this limitation."", 'The lack of empirical validation raises questions about the practical applicability of the theoretical findings.']",False,3,2,3,5,4,"['Addresses a fundamental question about the differences between RNNs and encoder-decoder architectures, contributing to a deeper theoretical understanding.', ""Introduces the novel concept of 'temporal product structure' that characterizes the types of relationships that encoder-decoders can efficiently approximate."", 'Provides rigorous mathematical proofs and detailed theoretical analysis.', 'Highlights the practical implications of these theoretical results, particularly in understanding the differences between encoder-decoders and traditional RNNs.']","['The paper is highly theoretical and may be difficult for a broader audience to understand without a strong mathematical background.', 'The practical significance and applications of the theoretical findings are not thoroughly explored.', 'The numerical illustrations, while supportive of the theoretical claims, do not sufficiently demonstrate the practical impact of the findings.', 'The paper does not provide sufficient clarity on how the theoretical insights can be applied to improve practical models.']",3,3,2,3,Reject
NrB52z3eOTY,"The paper introduces KLoS, a novel measure for uncertainty estimation in evidential models, and KLoSNet, an auxiliary network to improve classification confidence. The approach handles both in-distribution and out-of-distribution uncertainties without requiring OOD data during training. Extensive experiments demonstrate the effectiveness of the proposed method across various datasets and architectures.","['Can the authors provide more ablation studies to isolate the contributions of KLoS and KLoSNet?', ""How do different choices for KLoSNet's architecture and hyperparameters affect performance?"", 'Can the paper be revised for better clarity, particularly in the mathematical and experimental sections?', 'Can the authors provide more real-world application examples to validate the proposed method?', 'What measures were taken to prevent overfitting in the training of KLoSNet?']","[""The reliance on evidential models may limit the approach's applicability to certain neural network architectures."", 'The paper could benefit from additional ablation studies and clearer explanations.', 'The complexity of the implementation and training procedures might be a barrier for practitioners.', 'Validation on more real-world applications and datasets would strengthen the impact of the work.', 'The training of KLoSNet using the same training set as the main network might risk overfitting.']",False,3,3,3,5,4,"['Addresses a crucial problem of uncertainty estimation in machine learning.', 'Proposes a novel combination of Kullback–Leibler divergence and evidential models.', 'Comprehensive experimental evaluation across various datasets and architectures.', 'Practical applicability without requiring OOD training data.']","['Moderate originality, primarily extending existing concepts.', 'Clarity issues, with dense mathematical derivations and experimental setups.', 'Lack of detailed ablation studies to isolate the contributions of different components.', 'Reliance on evidential models may limit applicability.', 'Complexity of implementation and training procedures might be a barrier for practitioners.', 'Potential overfitting concerns with the training of KLoSNet.']",3,3,3,4,Reject
rMbLORc8oS,"The paper proposes a novel framework called SemiRetro for retrosynthesis prediction, combining the strengths of template-based and template-free methods. SemiRetro introduces semi-templates and a directed relational graph attention (DRGAT) layer to improve center identification and synthon completion. The approach achieves significant improvements in scalability, accuracy, interpretability, and training efficiency, as demonstrated by experiments on the USPTO-50k dataset.","['Can the authors provide more details on the extraction process of semi-templates?', 'How does the DRGAT layer specifically contribute to the performance improvements? Can this be demonstrated through ablation studies?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'What are the specific contributions of the DRGAT layer compared to existing GNN models?', 'Can the authors perform additional ablation studies to isolate the effects of different components of SemiRetro?', 'Can the authors provide more details on the DRGAT layer architecture and how it differs from standard GAT or R-GCN?', 'How are the semi-templates extracted and what criteria are used to determine their coverage and redundancy?', 'What are the specific hyperparameters used for training the SemiRetro framework, and how were they selected?', 'Can the authors provide more detailed ablation studies to isolate the effect of DRGAT and other components?', 'Could you clarify the implementation details, especially regarding the training process and hyperparameter settings?', 'What are the potential limitations of the proposed method, and how does it perform on datasets other than USPTO-50k?', 'Can you provide more details on the autoencoder aggregator used in the method?', 'Could you conduct ablation studies investigating the impact of different modulation functions and aggregators?', 'Please provide additional qualitative examples to support your claims.']","['The paper should discuss the limitations and potential negative societal impacts of the proposed method in more detail, even if they seem minor, to provide a balanced perspective.', 'The complexity of the proposed approach may limit its practical applicability. The authors should discuss potential ways to simplify the model.', 'The paper lacks sufficient ablation studies to isolate the effects of different components. Additional experiments are needed to understand the individual contributions.', 'The paper does not adequately address the limitations of the proposed approach, such as potential challenges in scaling to larger datasets or different chemical domains.', 'The potential negative societal impacts of the work, such as misuse in drug synthesis, are not discussed.']",False,3,3,3,5,4,"['The idea of combining template-based and template-free methods to leverage their respective strengths is innovative.', 'The introduction of semi-templates significantly reduces redundancy and improves scalability while preserving essential chemical knowledge.', 'The directed relational graph attention (DRGAT) layer enhances the accuracy of center identification, particularly in complex cases where the reaction class is unknown.', 'Comprehensive experiments demonstrate significant improvements over state-of-the-art methods in various metrics.', 'The method achieves better interpretability and training efficiency compared to previous methods.']","['The methodology section lacks clarity in some parts, particularly in the description of the semi-template extraction and the DRGAT layer implementation.', 'The paper could benefit from additional ablation studies to isolate the impact of each component, such as the DRGAT layer and semi-templates.', 'There is limited discussion on the potential limitations and negative societal impacts of the proposed method.', 'The complexity of the proposed approach may limit practical applicability.', 'More details needed on the training process and hyperparameter settings.']",4,3,3,4,Reject
U-_89RnR8F,"The paper proposes a method called Conceptual Counterfactual Explanations (CCE) to explain model mistakes using high-level, human-understandable concepts by combining counterfactual explanations and Concept Activation Vectors (CAVs). The method is validated through extensive experiments, including applications in medical imaging.","['Can the authors provide ablation studies to show the impact of different components of the method?', 'Can the authors clarify the validity constraints and the choice of certain hyperparameters?', 'Can the authors provide additional qualitative examples to strengthen their claims?', 'Can the authors provide more details on how the concept bank is created and maintained?', 'How does CCE compare to other state-of-the-art interpretability methods in diverse scenarios beyond image classification?', 'Can the authors conduct more ablation studies to evaluate the impact of different components of the methodology?', 'Can the authors provide a more rigorous theoretical foundation for the method?', 'How does the method perform on a wider range of datasets and models?', 'Can the authors clarify the notations and terms used in the paper to improve readability?', 'Can you provide more details on how to enhance the concept bank automatically?', 'How does the method perform in domains other than medical imaging, such as text or audio data?', 'Can you include additional visualizations to illustrate how CCE results can be interpreted by non-expert users?', 'How does the computation time for CCE scale with larger datasets or deeper models?']","['The clarity of some parts of the methodology and the lack of ablation studies are significant limitations.', 'The reliance on predefined concepts and domain-specific knowledge is a major limitation.', 'The scalability and generalizability of the method are questionable.', 'The paper does not adequately address the limitations of the method, including its dependency on the quality of the concept bank and its performance on different types of datasets.', 'The potential negative societal impact of the method is not discussed.']",False,3,3,3,6,4,"['Addresses a significant and practical problem in machine learning interpretability.', 'Novel combination of counterfactual explanations and concept activation vectors.', ""Comprehensive experiments demonstrate the method's effectiveness."", 'Method does not require access to training data or model retraining, increasing its applicability.', 'Code is publicly available, enhancing reproducibility.']","['Lacks ablation studies to show the impact of different components and hyperparameters.', 'Some parts of the methodology, particularly the optimization section, could be explained more clearly.', 'Relies on predefined concepts and domain-specific knowledge, which limits scalability and generalizability.', 'Theoretical foundation and rigorous mathematical formulation are lacking.', 'Scalability concerns for larger datasets and deeper models are not fully addressed.']",3,3,3,4,Reject
Qu_XudmGajz,"The paper proposes an improvement to the observation space in Variational Autoencoders (VAEs) by using a low-rank multivariate normal distribution to model spatial dependencies between pixels. This is intended to produce more spatially coherent samples compared to the standard pixel-wise independent distributions. The authors demonstrate the proposed method's effectiveness through experiments on the CELEBA and UKBB datasets, showing improved sample quality and meaningful variations in the generated images.","['Can you provide a more detailed comparison with Dorta et al. (2018) to clearly differentiate your contributions?', 'Can you elaborate on the stability issues and how the entropy constraint helps in mitigating them?', 'Could you provide more details on the implementation of the low-rank parameterization and the entropy constraint?', 'How does the proposed method perform on additional datasets, and with different VAE architectures?', 'Can the authors include more ablation studies to isolate the effects of different components of the proposed method?', 'Have the authors explored other parameterizations for the covariance matrix, and if so, how do they compare to the proposed low-rank parameterization?', 'Can the authors provide more ablation studies, such as varying the rank of the low-rank parameterization or using different architectures for the VAE?', 'How does the proposed model scale with higher-dimensional datasets?', 'Can you compare your method with other advanced VAE variants or generative models?', 'What other methods did you try to stabilize training, and why were they not successful?']","['The paper mentions stability issues during training, which were addressed through pre-training, weight initialization, and an entropy constraint. It would be helpful to have a more detailed discussion of these aspects to understand their impact on the training process.', 'The proposed method introduces additional complexity in the observation space modeling, which might affect computational efficiency. This aspect should be discussed in terms of trade-offs between sample quality and computational cost.', 'The potential negative societal impact of using generative models, such as the creation of misleading or harmful content, should be discussed.']",False,3,2,3,5,4,"['The paper tackles an important issue in VAEs related to the observation space, which is often overlooked.', 'The proposed low-rank multivariate normal distribution for the observation space is a novel approach that addresses the problem of uncorrelated pixel noise.', 'The experimental results show that the proposed method produces more spatially coherent samples compared to standard VAEs.', ""The paper includes a variety of qualitative and quantitative evaluations, including FID scores, interpolation, and interactive editing, which provide a comprehensive assessment of the method's performance.""]","['The paper could benefit from a clearer comparison with closely related works, such as Dorta et al. (2018), to better highlight the novelty and contributions of the proposed method.', 'The explanation of the methodology, particularly the parameterization of the covariance matrix and the entropy constraint, could be made clearer and more detailed.', 'The stability issues encountered during training and the solutions proposed (pre-training, weight initialization, entropy constraint) should be discussed in more depth to provide a better understanding of their impact.', 'The quantitative evaluation is limited to FID scores, which, while standard, may not fully capture the improvements. Additional evaluation metrics and more extensive comparisons would be beneficial.', 'The ablation studies are limited. More experiments isolating the effects of different components of the proposed method would provide a clearer understanding of their contributions.']",3,3,2,4,Reject
GrFix2vWsh4,"The paper investigates the hidden label-marginal biases in Cross-Entropy (CE) and Dice losses used for segmentation tasks, offering a theoretical analysis of these biases. It proposes a novel loss function combining CE with explicit L1 regularization to control the label-marginal bias. The paper validates the theoretical findings through comprehensive experiments across natural and medical image segmentation tasks, showing that the proposed loss function achieves better performance, particularly in handling class imbalance.","['Can the authors provide more details on the implementation of the L1 regularization term?', 'How does the proposed method perform on additional datasets not included in the current experiments?', 'Can more qualitative examples be provided to better illustrate the improvements achieved by the proposed method?', 'Can the authors provide more detailed explanations of the theoretical proofs?', 'Can the authors conduct more extensive ablation studies to further validate the contributions of each component of the proposed method?', 'Can the authors provide more intuitive explanations or visualizations to make the theoretical analysis more accessible?', 'How does the proposed method compare with other state-of-the-art techniques in terms of computational complexity?', 'Have you considered validating your findings on more datasets and backbone networks?', 'How does your proposed solution compare with other regularization techniques?', 'Can the authors provide more clarification on the practical implications and potential limitations of the proposed loss function?']","['The paper does not provide enough details on the implementation and gradient dynamics of the L1 regularization term. Including these details would make the proposed method more understandable and reproducible.', 'The experiments, while comprehensive, are limited to two datasets. Additional experiments on more diverse datasets would help to establish the broader applicability of the proposed method.', 'The clarity of the paper, particularly in the presentation of the theoretical analysis, could be improved. Additionally, more ablation studies would strengthen the validation of the proposed method.', 'The theoretical analysis is dense and may be challenging for some readers.', 'The novelty of the proposed method could be questioned as it combines existing techniques.', 'The paper primarily focuses on the theoretical analysis and does not include a wide range of datasets and backbone networks to validate the generalizability of the proposed method.', 'The novelty of the proposed solution is relatively limited.']",False,3,3,3,5,4,"['Provides a thorough theoretical analysis linking CE and Dice losses, which are commonly used in segmentation.', 'Identifies and explains the hidden label-marginal biases in CE and Dice losses, offering insights into when each loss might be preferable.', 'Introduces a novel loss function combining CE with L1 regularization to explicitly control the label-marginal bias.', 'Presents comprehensive experiments and ablation studies that support the theoretical analysis, demonstrating the effectiveness of the proposed approach.']","['The paper could benefit from a more detailed explanation of the proposed L1 regularization term, including its implementation and impact on the gradient dynamics.', 'While the proposed solution shows improved performance, the experiments could include more diverse datasets to further substantiate the generality of the proposed method.', 'The qualitative visualizations, although helpful, could be expanded to include more examples to better illustrate the improvements in segmentation results.', 'The theoretical proofs could be presented more clearly.', 'Some parts of the paper are dense and may be difficult for readers to follow without a deep background in the theoretical aspects of segmentation losses.', 'The proposed method, while effective, might not be significantly novel as it essentially combines existing techniques (CE and regularization).', 'Limited number of datasets and backbone networks used in experiments, which may affect the generalizability of the findings.', 'The paper could be better organized to improve readability and clarity.']",3,3,3,3,Reject
pzgENfIRBil,"The paper proposes a novel framework, Self-Consistent Gradient-like Eigen Decomposition (SCGLED), to solve approximated Schrödinger equations without relying on domain-specific heuristics. The method is based on gradient-like eigendecomposition methods from streaming k-PCA and aims to handle the self-consistency problem in these equations. The approach shows promising results in terms of precision and efficiency compared to traditional methods.","['Can the authors provide a more detailed explanation of the algorithm, particularly the orthogonalization technique and the updates in Algorithm 2?', 'How sensitive is the method to the choice of hyperparameters such as the learning rate and the damping factor?', 'Can the authors provide a more robust convergence analysis, possibly with theoretical guarantees?', 'How does the method compare with other state-of-the-art approaches in terms of computational complexity?', 'Can the empirical results be presented in a more accessible and digestible format?', ""Can the authors demonstrate the method's performance across a more diverse set of problems?""]","['The paper should address the limitations related to the sensitivity to hyperparameters and the lack of theoretical convergence guarantees.', 'The complexity and accessibility of the paper are major concerns.', 'The potential negative societal impacts of the work, such as computational cost and energy consumption, are not discussed.']",False,3,3,3,4,4,"['The paper addresses a critical challenge in computational physics and quantum mechanics.', 'The proposed method, SCGLED, is innovative and eliminates the need for domain-specific heuristics.', 'Comprehensive experimental validation demonstrates the effectiveness of the method.', 'The method has potential applications in both computational physics and machine learning.']","['The paper lacks clarity in some methodological details, particularly in the description of the algorithm.', 'The convergence analysis is not robust and relies heavily on empirical results.', 'The comparison with state-of-the-art methods could be more thorough.', 'The impact of the choice of hyperparameters is not sufficiently explored.', 'The paper is overly complex and may not be accessible to a broader ML audience.']",3,3,3,4,Reject
Mlwe37htstv,"The paper introduces Wasserstein Policy Optimization (WPO) and Sinkhorn Policy Optimization (SPO) for reinforcement learning, leveraging Wasserstein distance and Sinkhorn divergence respectively as trust region constraints. The paper provides theoretical guarantees for performance improvement and convergence, and empirical results across several environments demonstrate the methods' efficiency and effectiveness.","['Can the authors provide more detailed implementation steps and hyperparameter settings for the experiments?', 'Can additional ablation studies be conducted to analyze the impact of different λ values in SPO and β values in WPO?', 'Are there any practical guidelines for choosing the values of λ and β for practitioners?', 'How can the complexity of deriving the optimal Lagrangian multipliers for WPO be managed in practical implementations?', 'Can the authors provide more details on the choice of hyperparameters and the experimental setup?', 'Can the authors provide more intuition behind the choice of Wasserstein and Sinkhorn divergences over traditional metrics?', 'How sensitive are the results to the choice of hyperparameters, particularly the regularization parameter in SPO?', 'Can the authors provide more detailed explanations of the autoencoder aggregator and the modulation function?', 'What are the impacts of different types of aggregators on the performance of the proposed model?', 'Can the authors provide more visualizations or case studies to strengthen the empirical results?']","['The practical applicability of the proposed methods may be limited by the complexity of computing the Wasserstein distance and Sinkhorn divergence, particularly in high-dimensional spaces.', 'The paper does not sufficiently address the computational overhead introduced by these metrics.', 'The paper should discuss the potential limitations in terms of computational complexity introduced by the Wasserstein and Sinkhorn divergences.', 'A broader discussion on the applicability of the proposed methods to large-scale problems would be beneficial.', 'The major concern is the clarity of the paper and the need for more extensive ablation studies. Addressing these concerns in the rebuttal period would significantly improve the paper.']",False,3,3,3,5,4,"['The paper tackles an important problem in reinforcement learning—stabilizing policy optimization via alternative trust region constraints.', 'The proposed methods, WPO and SPO, are novel and theoretically well-founded.', 'The paper provides comprehensive theoretical analysis, including performance improvement guarantees and convergence proofs.', 'Empirical results on multiple environments show the effectiveness and efficiency of the proposed methods compared to state-of-the-art baselines.']","['The clarity of the paper is lacking, with several complex proofs and theoretical explanations that could be better explained or moved to the appendix.', 'The practical implementation details are sparse, making it difficult to reproduce the results.', 'The paper could benefit from additional ablation studies to further validate the design choices, such as the impact of different values of λ in SPO and the choice of β in WPO.', 'Some sections, particularly the proofs, are dense and may be challenging for readers to follow.', 'The derivation of the optimal Lagrangian multipliers, especially for WPO, appears complex and may not be straightforward for practical implementation.', 'The empirical evaluation, while extensive, could benefit from more diverse tasks to validate the generality of the proposed methods.', 'Incremental novelty compared to existing work in Wasserstein-based policy optimization.', 'Experimental results show only marginal improvements over state-of-the-art methods.']",3,3,3,4,Reject
nKWjE4QF1hB,"The paper proposes a novel modification to the AlphaZero algorithm, introducing a Proof Cost Network (PCN) aimed at solving games quickly rather than just winning. The PCN estimates the proof cost, a heuristic representing the effort required to solve problems. The approach is validated on 15x15 Gomoku and 9x9 Killall-Go, showing that PCN outperforms traditional AlphaZero in solving more problems.","['Can the authors provide more details on the autoencoder aggregator and its role in the methodology?', 'How does the proposed method compare to other state-of-the-art game-solving algorithms beyond AlphaZero?', 'Can the authors discuss the potential limitations and scalability issues of the proposed approach?', 'How well does the proposed approach generalize to other games or domains?', 'What specific modifications were made to the AlphaZero algorithm for it to prioritize solving games quickly?', 'Can the authors include more visual aids and detailed step-by-step explanations to improve clarity?']","['The authors should discuss the limitations related to the computational resources required for training and inference, as well as the potential scalability issues.', 'The paper focuses on specific games, and the generalization to other games or domains is not demonstrated. The paper also lacks comparisons with other state-of-the-art game-solving algorithms, and the practical impact and scalability of the approach remain unclear.']",False,3,2,3,4,4,"['The introduction of the proof cost heuristic and the PCN is innovative and provides a fresh angle on leveraging AlphaZero for game solving.', 'The experiments are thorough and cover different configurations, demonstrating the efficacy of the proposed method.', 'The proposed modifications have practical implications for various applications beyond gaming, such as planning and chemistry.']","['The paper is dense and could benefit from clearer explanations, especially in the methodology section. Some parts are difficult to follow.', 'While the paper compares PCN to AlphaZero, it lacks comparisons with other state-of-the-art game-solving algorithms.', 'Although the authors claim reproducibility, the complexity of the method and the required computational resources might hinder practical reproducibility.', 'The generalization of the approach to other games or domains is unclear, and the paper does not provide sufficient evidence that the method would work well beyond the specific games tested.', 'The potential negative societal impacts and limitations of the approach are not adequately discussed.']",3,3,2,3,Reject
H4EXaI6HR2,"The paper proposes a novel architecture for modeling the cost-to-go function in electrical power systems using a series of neural networks whose parameters are parametric functions of time. The method is shown to outperform the current standard in use, both in terms of the objective function and computational cost.","['Can the authors provide more extensive empirical validation, perhaps comparing with other modern methods?', 'Can the authors clarify the technical implementation details, especially the training procedure and the architecture of the neural networks?', 'Can the authors provide more details on the autoencoder aggregator used?', 'How does the method compare with other state-of-the-art approaches in terms of both performance and computational cost?', 'Can more ablation studies be provided to analyze the impact of different components and design choices?', 'Can the authors provide more details on the specific architecture of the neural networks used?', 'How does the proposed method compare with other state-of-the-art methods in different domains or tasks?', 'Can the authors provide more detailed ablation studies to understand the contribution of each component of the proposed method?', ""Can you improve the clarity of the model's description and the experimental setup to make reproduction easier?"", 'How does the proposed method compare with other advanced machine learning methods in this domain?', 'Please provide more details about the autoencoder aggregator used in your model.', 'Can you include additional ablation studies to isolate the effects of different components of your model?', 'Please provide more comprehensive qualitative analysis and visualizations to support your results.']","['The paper does not address the limitations of its approach in detail, particularly the potential scalability issues and the sensitivity to hyperparameters.', 'The clarity of the paper needs significant improvement along with more comprehensive ablation studies.', 'The evaluation section would benefit from more extensive experimentation and clearer comparisons with other methods.', 'The method is highly specialized for a specific application, which limits its generalizability.', 'The paper does not adequately address potential limitations or negative societal impacts.', 'The need for detailed ablation studies and further analysis of the parametric functions used for network weights.', ""Improving the clarity of the model's description and the experimental setup for better reproducibility."", 'A comprehensive comparison with other advanced machine learning methods is needed.']",False,2,2,2,4,4,"['Addresses a relevant and practical problem in power systems management.', 'Proposes a novel approach by using a series of neural networks with time-dependent parameters.', 'Shows promising results in comparison with the classic Bellman method.', 'Demonstrates practical improvements in both objective function and computational efficiency.', 'Validated on a real-life scenario, showing practical relevance.']","['Lacks rigorous theoretical analysis and more extensive empirical validation.', 'Comparison is only made with the classic Bellman method, which may not be sufficient to establish the superiority of the proposed method.', 'Sections describing the technical implementation could benefit from more detailed explanations and clearer diagrams.', 'The paper lacks clarity in several sections, making it difficult to follow the methodology.', 'There are insufficient ablation studies to analyze the impact of different components of the proposed method.', 'The evaluation, while promising, lacks extensive experimentation and comparisons with other state-of-the-art methods.', 'The presentation of the results could be more detailed and clearer, especially in terms of visual aids and tables.', 'The originality of the approach is limited as using neural networks for dynamic programming is not new.', 'Experimental results lack rigor and comprehensive comparisons with a wide range of baselines.', 'The paper is densely written and lacks clear explanations of key components, making it hard to follow.', 'The significance of the contributions is limited to a specific application, reducing its broader impact.']",3,2,2,3,Reject
WQVouCWioh,"The paper 'DESIGN IN THE DARK: LEARNING DEEP GENERATIVE MODELS FOR DE NOVO PROTEIN DESIGN' presents DARK, a framework for de novo protein design using deep generative models. The method involves training generative models on synthetic sequences to produce novel protein sequences with desired structural properties. The approach is evaluated using state-of-the-art tools like AlphaFold and shows promising results in generating high-quality protein candidates.","['Can the authors provide more details on the autoencoder aggregator?', 'Can the authors include more qualitative examples and visualizations in the rebuttal period?', 'How do the different components of the DARK framework individually contribute to the final results? More ablation studies are needed.', 'How does the greedy hill-climb optimization specifically contribute to the overall performance?', 'Can the authors provide more detailed explanations on how the synthetic sequences are generated and their characteristics compared to natural sequences?', 'How does the performance of DARK compare when using different structure prediction tools, not just AlphaFold?']","['The clarity of the methodology and ablation studies is a concern. The authors should provide more detailed explanations and additional qualitative examples.', ""The paper relies heavily on the accuracy and efficiency of AlphaFold for structure predictions, which could be a limitation if AlphaFold's predictions are not reliable for all synthetic sequences."", 'Potential ethical considerations related to the generation and use of synthetic protein sequences should be briefly discussed.']",False,3,2,4,6,4,"['Addresses a significant and challenging problem in protein design.', 'Introduces a novel framework (DARK) that iteratively trains generative models on synthetic sequences.', 'Comprehensive evaluation using advanced tools like AlphaFold.', 'Demonstrates practical applications and potential for further method development.']","['Methodology and ablation studies lack clarity and detail.', 'More detailed explanations of the autoencoder aggregator and other components are needed.', 'More qualitative examples and visualizations would strengthen the analysis.', 'The paper is densely packed with information, which can hinder clarity and understanding.']",4,3,2,4,Reject
SgEhFeRyzEZ,"The paper provides a theoretical analysis of the Feedback Alignment (FA) algorithm, focusing on convergence guarantees and implicit regularization phenomena for deep linear networks. It covers both continuous and discrete dynamics and suggests initialization schemes to improve learning dynamics.","['Can you provide more intuitive explanations or graphical illustrations to aid understanding?', 'Do you have plans to extend the experiments to non-linear networks?', 'How do your results compare with gradient descent and other alternative algorithms?', 'Can the authors provide more detailed and intuitive explanations for the key mathematical derivations?', 'Are there ways to relax some of the strong assumptions made in the theoretical analysis?', 'Can the experimental validation be extended to include more diverse datasets and neural network architectures?', 'Can the discussion on initialization schemes be expanded with more practical guidelines and analysis?']","['The paper is quite dense and could benefit from more intuitive explanations and graphical illustrations.', 'More extensive empirical validation, especially on non-linear networks, would strengthen the paper.', 'The analysis is limited to linear networks, which are a simplified model compared to the non-linear networks used in practical applications.', 'The impact of the assumptions (e.g., SVD decomposability) on the generality of the results is not thoroughly discussed.']",False,3,2,3,5,4,"['Addresses a relevant and relatively less explored area by providing theoretical analysis of the Feedback Alignment algorithm.', 'Provides rigorous mathematical proofs and convergence guarantees for deep linear networks.', 'Analyzes implicit regularization phenomena and proposes initialization schemes to mitigate negative effects.', 'Includes a comprehensive approach covering both shallow and deep linear networks.']","['The paper is dense with mathematical notations and theorems, making it difficult to follow for a broader audience.', 'The experimental section is limited to synthetic datasets and linear autoencoders, reducing the relevance to real-world applications.', 'Strong assumptions, such as specific initialization schemes, might limit the generality of the results.', 'Lacks a detailed comparison of its results with those from gradient descent and other alternative algorithms.']",3,3,2,3,Reject
WcZUevpX3H3,"The paper proposes FEDPNAS, a personalized neural architecture search algorithm for federated learning. It aims to customize model architectures for each task by learning a base architecture and a personalized component for local tasks. The approach includes a context-aware sampling distribution and a new FL objective inspired by MAML to ensure better fine-tuning capabilities. Extensive experiments on CIFAR-10 and MNIST datasets demonstrate the effectiveness of the approach.","['Can the authors provide more detailed ablation studies, particularly on the modulation function and the impact of different aggregators?', 'Please clarify the implementation details of the autoencoder aggregator.', 'Can more qualitative cases be provided to convincingly demonstrate the impact of FEDPNAS?', 'Can the authors provide a clearer, step-by-step explanation of the FEDPNAS algorithm?', 'How does FEDPNAS specifically advance over existing methods like DSNAS?', 'Can additional datasets be used to further validate the experimental results?', 'Is it possible to simplify the theoretical explanations for better understanding?']","['The paper should improve clarity and provide more comprehensive ablation models to isolate the impact of each component. Addressing these limitations could significantly enhance the quality of the work.', 'The paper should discuss potential limitations related to the computational overhead of the proposed method, especially in low-resource environments typical of FL scenarios.']",False,3,3,3,5,4,"['Addresses an important issue in federated learning: the need for personalized model architectures.', 'Introduces a novel architecture that separates base and personalized components, capturing both common and task-specific information.', 'Comprehensive experiments on CIFAR-10 and MNIST datasets demonstrate the effectiveness of the approach.', 'Theoretical analysis and empirical results are well-presented, showing the effectiveness of the personalized federated learning objective.']","['The paper lacks detailed ablation studies to isolate the impact of each component of the proposed method.', 'Clarity issues: The description of the autoencoder aggregator and some parts of the methodology are not very clear.', 'Limited qualitative analysis: More cases should be provided to convincingly demonstrate the impact of the proposed approach.', 'The novelty and differentiation from existing methods like DSNAS are not clearly articulated.', 'Reproducibility is a concern due to lack of clear, detailed explanations in the main text.']",3,3,3,4,Reject
eSHBmLnD1s8,"The paper proposes a novel two-stage stochastic subsampling method to reduce the volume of high-dimensional data processed by deep learning algorithms. The first stage uses a Bernoulli process for candidate selection, and the second stage employs an autoregressive model with Categorical distributions for fine-grained selection. The method is validated on tasks such as image classification, image reconstruction, function reconstruction, and few-shot classification, showing superior performance to relevant baselines.","['Can the authors provide more details on the autoencoder aggregator and its role in the subsampling process?', 'How does the method handle potential biases in the data, and what measures are in place to ensure fair and unbiased subsampling?', 'Can the authors explore and discuss the performance of the method at extremely low subsampling rates in more detail?', 'What is the impact of different hyperparameters on the performance of the proposed method?', 'Can you include more ablation studies to evaluate the effectiveness of the two-stage subsampling approach comprehensively?', 'Can the authors provide more details about the set functions used in the candidate selection and autoregressive subsampling stages?', 'What is the impact of using different set functions on the performance of the proposed method?', 'Can the authors provide more qualitative examples to illustrate the effectiveness of the method?', 'Can the authors provide more details on the computational overhead introduced by the proposed two-stage process?', 'How does the proposed method perform when applied to other types of high-dimensional data beyond images, such as text or time-series data?', 'Can the authors clarify the practical implications of the architectural choices made in the paper?']","['The paper does not sufficiently address how the method handles potential biases in the subsampling process, which could lead to biased models.', 'The performance degradation at extremely low subsampling rates, while better than baselines, remains a concern and requires further exploration.', 'The proposed method introduces additional computational complexity, which may limit its applicability in some real-world scenarios.', 'The clarity of the presentation and the detailed experimental setup need improvement.', 'The need for additional ablation studies to fully understand the contributions of each component.']",False,3,2,3,4,4,"['The paper addresses a significant problem in deep learning related to processing large volumes of high-dimensional data.', 'The proposed method is novel, employing set-based functions and a two-stage selection process to improve subsampling efficiency.', 'Comprehensive experimental validation on multiple datasets and tasks demonstrates the efficacy of the proposed method.', 'The approach is flexible, generalizing well to different subsampling rates and tasks.']","['The paper could provide more details on the implementation of the autoencoder aggregator, which is not very clear.', 'The clarity of the paper could be improved, particularly in the description of the methodology and the detailed experimental setup.', 'The reliance on specific architectures such as Set Transformer and ANP may limit the generalizability of the method.', ""The method's performance under extremely low subsampling rates, while better than baselines, still shows significant performance degradation."", 'The paper does not adequately address potential biases in the subsampling process and how these might affect the downstream tasks.', 'The complexity of the proposed method is relatively high, which may limit its applicability in real-world scenarios.', 'Additional ablation studies are needed to fully understand the contributions of each component of the proposed method.']",3,3,2,3,Reject
1JN7MepVDFv,The paper investigates the relationship between disentangled representations and multi-task learning using synthetic datasets. It aims to determine whether disentanglement arises naturally in multi-task learning settings and whether using disentangled representations can improve multi-task learning performance. The study employs various disentanglement metrics to evaluate the learned representations.,"['Could you provide more details on the architectures used for the auto-encoder and multi-task models?', 'How do you explain the inconclusive results regarding the practical benefits of disentangled representations in multi-task learning?', 'Can you provide additional ablation studies to strengthen the findings?', 'Can the authors provide more justification for the use of synthetic datasets over real-world datasets?', 'How do the authors plan to validate their findings in real-world scenarios?', 'Can the authors clarify the practical implications of their findings?']","['The reliance on synthetic datasets is a significant limitation, and the paper could discuss more on how this might be addressed in future work.', 'The inconclusive nature of some results should be acknowledged, with potential directions for further investigation.', 'The study is limited by its reliance on synthetic datasets, which may not fully capture the complexity of real-world tasks.', 'The inconclusive results regarding the practical benefits of disentangled representations suggest that further research is needed.', 'The use of synthetic datasets and the lack of real-world validation are significant limitations. The authors should address how they plan to extend their findings to real-world scenarios.', 'The paper does not adequately address the limitations of the empirical study and the potential negative societal impacts are not discussed.']",False,2,2,2,4,4,"['Addresses a significant and novel problem in the field of representation learning.', 'Employs a comprehensive experimental setup with multiple disentanglement metrics.', 'Well-organized and clearly written paper.']","['Reliance on synthetic datasets limits real-world applicability.', 'Some methodological details, particularly regarding the experimental setup, could be elaborated further.', 'Results are somewhat inconclusive, limiting the immediate impact of the findings.', 'The paper lacks a rigorous theoretical foundation connecting disentanglement and multi-task learning.', 'The clarity and organization of the paper are insufficient, making it difficult to follow the experiments and results.', 'The experimental setup and description lack detail, reducing reproducibility.']",2,2,2,2,Reject
8rR8bIZnzMA,"The paper introduces Dynamic Graph Transformer (DGT), a Transformer-based method for dynamic graph representation learning. The method aims to improve robustness against noisy graph data and scalability issues through a temporal-union graph structure and a target-context node sampling strategy. It also proposes two self-supervised pre-training tasks to enhance generalization. The method is evaluated on real-world datasets, showing superior performance compared to state-of-the-art baselines.","['Can the authors provide a more detailed explanation of the spatial-temporal encoding and the integration of these encodings into the Transformer architecture?', 'What is the novelty of the two-tower Transformer architecture compared to existing methods?', 'Can the authors provide more implementation details and hyper-parameter settings to ensure the reproducibility of the results?', 'How do the chosen hyper-parameters impact the performance of the proposed method?', 'Can the authors provide more detailed ablation studies on the impact of spatial-temporal encoding and the two-tower architecture?', 'How does the proposed method compare with continuous-time dynamic graph models?', 'Can the authors simplify or clarify parts of the paper to improve understanding and reproducibility?', ""Can you provide more details on the impact of different hyperparameters on the model's performance?"", 'How does the method scale with larger graphs in a real-world scenario?', 'Can you discuss the applicability of DGT to other types of dynamic graph data?', 'Can the authors provide more detailed explanations and theoretical justifications for the pre-training tasks?', 'How does the two-tower architecture compare to single-tower variants in more detail?', 'Can you include more visualizations or qualitative analyses of the spatial-temporal encoding?', 'Can the authors isolate the impact of temporal connection and spatial distance encodings more clearly in ablation studies?', 'Can you provide more details on the autoencoder aggregator?', 'Can you conduct additional ablation studies, such as the impact of different modulation functions and aggregators?', 'Can you provide more qualitative analysis cases to support your claims?']","['The paper does not discuss the potential limitations of the proposed method, such as the sensitivity to hyper-parameters and the impact of the temporal-union graph structure on different types of dynamic graphs.', 'The clarity and comprehensiveness of the paper need improvement.', 'More detailed ablation studies and comparisons with alternative methods are required.', 'The paper could benefit from a clearer presentation of the methodology and more detailed discussion on the impact of hyperparameters and scalability.', 'The explanation of certain key components, such as pre-training tasks and two-tower architecture, requires more detail and clarity.', 'The paper should provide more qualitative analysis and better isolate the impact of specific encodings.']",False,3,2,3,5,4,"['The paper addresses a relevant problem in dynamic graph representation learning, which is critical for various applications.', 'The introduction of a temporal-union graph structure and a target-context node sampling strategy are innovative approaches to handle scalability and computational complexity.', 'The method includes two complementary self-supervised pre-training tasks, which are theoretically supported to improve generalization ability.', 'Comprehensive experiments on real-world datasets demonstrate the effectiveness of the proposed method.']","['The clarity of the paper is a significant issue. The explanations of the proposed method, especially the spatial-temporal encoding and the two-tower Transformer architecture, are convoluted and hard to follow.', 'The originality of the spatial-temporal encoding and two-tower architecture is questionable. The paper lacks a thorough comparison with other existing graph Transformer methods and does not provide clear evidence of their novelty.', 'The soundness of the proposed method is not well-established. Critical details on the implementation and hyper-parameter settings are missing, making it difficult to assess the reproducibility of the results.', 'The paper does not adequately address the limitations of the proposed method. For instance, the potential impact of the chosen hyper-parameters on the performance is not discussed.', 'Limited ablation studies on the impact of different components of the proposed method.', 'The comparison with continuous-time dynamic graph models is either missing or not sufficiently detailed.', 'The paper could benefit from additional qualitative analysis, such as visualizations or examples of spatial-temporal encoding in action.']",3,3,2,3,Reject
sOK-zS6WHB,"The paper presents a method for embedding fingerprints in generative models, enabling responsible disclosure and traceability of generated content. The method integrates a fingerprint auto-encoder into GANs, allowing for scalable and efficient generation of fingerprinted models while preserving the quality of generated images. The paper provides a comprehensive evaluation of the method's effectiveness, fidelity, and robustness.","['Could you provide more detailed ablation studies to dissect the contributions of different components of the method?', 'How can this method be practically implemented and integrated into existing workflows for generative models?', 'Can the authors provide more details on the architecture and training of the autoencoder aggregator?', 'What are the specific hyperparameters used for the modulation of fingerprints, and how were they selected?', 'Can the authors include more qualitative examples to demonstrate the effectiveness of fingerprints in generated images?', 'How does the proposed method perform with different types of generative models beyond StyleGAN2?', 'Can the authors provide a more detailed discussion on the potential limitations and societal impacts of the proposed method?', 'Could the authors conduct additional ablation studies to better understand the contributions of different components, such as the fingerprint auto-encoder and the modulation layers?', 'Can the authors provide more clarity on the exact implementation of the fingerprint auto-encoder and the training process?', 'How does the proposed method compare to other state-of-the-art methods not included in the current comparisons?']","['The paper should address the limitations of the proposed method in terms of computational efficiency and potential vulnerabilities to adversarial attacks on the fingerprinting mechanism.', 'The societal implications of enabling model attribution should be explored in more depth.', 'The paper needs more clarity on the autoencoder aggregator.', 'Additional ablation studies on the modulation function and type of aggregators are necessary to comprehensively evaluate the method.']",False,3,3,3,6,4,"['Addresses a significant and timely issue of misuse of generative models for creating deep fakes and misinformation.', 'Innovative approach to embedding fingerprints into the model parameters.', ""Comprehensive evaluation of the method's effectiveness, fidelity, and robustness."", 'Thorough experiments to validate the capacity, scalability, secrecy, and immunizability of the proposed solution.', 'Demonstrates significant advantages over existing methods in terms of efficiency and scalability.']","['Could benefit from more detailed ablation studies to further dissect the contributions of different components of the method.', 'Practical implementation and integration into existing workflows could be discussed in more detail.', 'The explanation of the autoencoder aggregator and the modulation of fingerprints could be clearer.', 'The experimental setup, particularly the selection of hyperparameters and the architecture of the autoencoder, lacks detail.', 'The paper lacks a thorough discussion on potential limitations and societal impacts of the proposed work.']",4,3,3,4,Accept
7YDLgf9_zgm,"The paper introduces Recursive Gradient Optimization (RGO) and a virtual Feature Encoding Layer (FEL) to address catastrophic forgetting in continual learning without data replay. The method achieves state-of-the-art performance on several benchmarks, including 20-split-CIFAR100 and 20-split-miniImageNet.","['Can the authors provide more detailed explanations for the mathematical derivations and proofs?', 'Can the authors conduct more ablation studies to isolate the contributions of different components?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How sensitive is RGO to the choice of hyperparameters, and how were these chosen for your experiments?', 'Can you provide more details on the implementation of the FEL? How does it impact the training time?', 'Have you tested RGO on other types of neural network architectures or tasks (e.g., reinforcement learning)?']","['The paper needs to improve clarity and provide more comprehensive evaluations. The dense mathematical derivations and proofs need better explanations.', 'The method assumes over-parameterized networks, which might not always be practical.', 'The importance of network width is discussed but not tested empirically.']",False,3,3,3,5,4,"['Addresses a significant issue in continual learning: catastrophic forgetting.', 'The proposed RGO and FEL are novel and theoretically well-founded.', 'Extensive experiments on multiple benchmarks show that the method achieves state-of-the-art performance.', 'No reliance on extra memory or data replay, making it suitable for resource-constrained environments.']","['The paper lacks clarity in some sections, particularly in the methodology and implementation details, which may hinder reproducibility.', 'Theoretical sections are complex and might benefit from additional clarity and simplification.', 'Additional ablation studies would be beneficial to better understand the contributions of different components, such as the impact of FEL and the choice of projection matrix P.', 'The paper assumes over-parameterized networks, which might not always be practical. This should be discussed in more detail.', 'Experimental setup lacks detailed discussion on hyperparameter tuning.']",3,3,3,4,Reject
WqoBaaPHS-,The paper introduces a novel concept of top-label calibration for multiclass classification and proposes a multiclass-to-binary (M2B) reduction framework. The framework unifies different types of multiclass calibration into binary calibration problems and is instantiated using histogram binning (HB). The authors provide theoretical guarantees and empirical results on CIFAR-10 and CIFAR-100 datasets to demonstrate the effectiveness of their approach.,"['Can the authors provide more justification for the choice of parameters in the binning methods?', 'How does the method perform on more complex datasets with a larger number of classes?', 'What strategies can be used to handle small calibration datasets more effectively?', 'Can the authors provide more intuitive explanations and diagrams to clarify the theoretical contributions?', 'How does the proposed method handle severely imbalanced datasets beyond the theoretical guarantees?', 'Can additional experiments or case studies be provided to show the practical applicability of the method in real-world scenarios with diverse datasets?', 'Can the authors provide more theoretical insights into why top-label calibration is superior beyond empirical validation?', 'How would the proposed methods perform on other models and datasets beyond deep learning and CIFAR?']","['The paper would benefit from a deeper discussion on the implications of using small calibration datasets and potential strategies to mitigate issues arising from limited data.', 'The complexity and density of the paper may hinder accessibility for a broader audience.', 'More detailed empirical evaluations and additional ablation studies could further strengthen the paper.', 'Performance on highly imbalanced datasets may be limited.', 'Relies on a sufficient amount of calibration data.', 'Potential negative impacts in sensitive applications are not thoroughly discussed.']",False,3,3,3,7,4,"['Introduces a novel concept of top-label calibration.', 'Presents a comprehensive M2B reduction framework.', 'Provides strong theoretical foundations and empirical validations.', 'Demonstrates significant improvements in calibration errors over existing methods.', 'Comprehensive empirical results on CIFAR-10 and CIFAR-100 datasets.', 'Theoretical guarantees add robustness to the proposed methods.']","['The paper is dense and difficult to follow, especially in the theoretical sections.', 'Limited discussion on handling small calibration datasets and imbalanced datasets.', 'The choice of parameters in the binning methods could be better justified.', 'More intuitive explanations and visual aids are needed to improve clarity.', 'Evaluation is limited to deep learning models and CIFAR datasets.', 'Lacks detailed theoretical insights beyond empirical validation.']",4,3,3,4,Accept
v-v1cpNNK_v,"The paper introduces NASI, a novel Neural Architecture Search (NAS) algorithm that leverages the Neural Tangent Kernel (NTK) to estimate the performance of neural architectures at initialization, thereby avoiding the need for model training during the search process. This approach aims to significantly improve search efficiency while maintaining competitive performance. The paper claims that NASI is label- and data-agnostic, ensuring the transferability of the selected architectures across different datasets. The empirical validation is conducted on datasets like CIFAR-10/100 and ImageNet.","['Can the authors provide more detailed explanations of the NTK trace norm approximations and their effectiveness?', 'Could the authors include more ablation studies to investigate the impact of different hyperparameters and components of the proposed method?', 'Can the authors improve the clarity of the optimization process and the theoretical foundations to make them more intuitive?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'How does the proposed method compare with other state-of-the-art NAS methods in terms of computational resources required?', 'What is the impact of varying the penalty coefficient and the constraint ν on the final selected architectures?', 'How does NASI perform compared to a more comprehensive set of existing NAS methods, especially in terms of search effectiveness in different types of tasks beyond image classification?']","['The clarity of the paper and the need for additional ablation studies are the main concerns. Addressing these concerns in the rebuttal period could significantly strengthen the paper.', 'The practical validation of the proposed label- and data-agnostic search capabilities requires further exploration.', 'The paper does not thoroughly discuss potential limitations or negative societal impacts. Given the novelty of the approach, it is important to consider these aspects.']",False,3,3,3,6,4,"['The paper introduces an innovative approach to NAS by leveraging NTK, which could significantly enhance search efficiency by avoiding model training.', 'Theoretical grounding is comprehensive, with detailed proofs and justifications provided.', 'Extensive empirical validation is conducted on various datasets, including CIFAR-10/100 and ImageNet, demonstrating the competitive performance of NASI.', 'The paper claims and empirically validates that NASI is label- and data-agnostic under mild conditions, ensuring the transferability of the selected architectures.']","['Certain methodological details, such as the NTK trace norm approximations, are not clearly explained and could benefit from more detailed descriptions.', 'Additional ablation studies are needed to investigate the impact of different hyperparameters and components of the proposed method.', 'The clarity of some sections could be improved, especially in explaining the optimization process and the theoretical foundations in a more intuitive manner.', 'The empirical validation could include more diverse datasets and tasks to further demonstrate the generalizability of the approach.', 'The paper lacks a detailed discussion on the potential limitations and negative societal impacts of the proposed approach.']",4,3,3,4,Reject
rq1-7_lwisw,"The paper introduces a new task, Object Concept Learning (OCL), which aims to push the boundaries of object understanding beyond simple recognition. The authors provide a densely annotated dataset containing categories, attributes, and affordances of objects, along with their causal relations. They propose a baseline model, Object Concept Reasoning Network (OCRN), which leverages causal reasoning to infer the three levels of object concepts and follows the causal relations effectively.","['Can the authors provide more details on the autoencoder aggregator used in the OCRN model?', 'What is the impact of using different types of aggregators in the OCRN model?', 'Can the authors provide more examples and visualizations in the qualitative analysis section?', 'How does the OCRN model handle the potential zero-shot state problem mentioned in the paper?', 'What is the rationale behind the specific design choices in the OCRN model?', 'How do the authors address potential biases in the dataset, and how might these biases affect the results?', 'Can the authors provide more details about the training hyperparameters used for the OCRN model?', 'How does OCRN perform on unseen object categories or states not present in the training data?']","['The paper could benefit from additional ablation studies to fully understand the impact of different components of the OCRN model.', 'There is a need for a more thorough discussion on the potential negative societal impacts of the proposed work.', 'The paper does not address the potential limitations of the OCRN model when applied to unseen object categories or states.', ""The impact of the dataset's long-tail distribution on the model's performance is not thoroughly discussed.""]",False,3,3,3,6,4,"['The proposed task, OCL, addresses a significant gap in object understanding by going beyond simple recognition to include attributes and affordances.', 'The dataset provided is extensive and well-annotated, capturing a wide range of object categories, attributes, and affordances, along with their causal relations.', 'The baseline model, OCRN, introduces causal reasoning into the process of object concept learning, which is a novel and useful approach.', 'Comprehensive experiments are provided, including both quantitative results and qualitative analysis, which demonstrate the effectiveness of the proposed approach.']","['The paper lacks clarity in several sections, particularly in the explanation of the OCRN model and its components, which makes it difficult to fully understand the methodology.', 'Some ablation studies are missing, such as the effect of different types of aggregators and the impact of reducing the number of gating parameters in the modulation function.', 'The qualitative results provided are limited. More examples and visualizations would strengthen the paper.', 'The discussion on potential negative societal impacts is minimal. Given the potential applications in robotics and AI, a more thorough discussion is warranted.', 'Potential biases in the dataset are not adequately addressed, which could affect the generalizability of the results.']",4,3,3,4,Reject
HMJdXzbWKH,"The paper introduces Q-Rex and Q-RexDaRe, novel methods for Q-learning that combine Online Target Learning (OTL) and Reverse Experience Replay (RER) to address convergence and sample complexity issues in linear MDPs and ZIBEL MDPs. Theoretical results demonstrate significant improvements over existing methods.","['Can the authors provide more empirical validation to support the theoretical claims?', 'Can the authors simplify the presentation to make the methods more accessible?', 'Can the authors provide more intuitive explanations for RER and OTL?', 'How do Q-Rex and Q-RexDaRe perform on a wider range of benchmarks, including more complex and high-dimensional environments?', 'What are the potential limitations and negative societal impacts of the proposed methods?', 'How strong are the assumptions made in the theoretical analysis, and how do they affect the generality of the results?', 'Can the authors elaborate more on the practical implementation details, including hyperparameter settings and computational cost?']","['The main limitations are the clarity of the presentation and the robustness of the empirical validation. The authors should consider adding more experiments and simplifying the theoretical exposition.', 'The paper does not adequately address the potential limitations and negative societal impacts of the proposed methods. Additionally, the experimental validation is limited and does not convincingly demonstrate practical benefits.', 'The practical implementation details of the proposed methods, such as hyperparameter settings and computational cost, are not thoroughly discussed.']",False,3,2,3,4,4,"['The paper addresses a critical issue in Q-learning: the gap between practical success and theoretical guarantees.', 'The combination of OTL and RER is innovative and theoretically justified.', 'Comprehensive theoretical analysis provides strong guarantees on sample complexity and convergence.']","['The clarity of the presentation is lacking, making the paper difficult to follow.', 'The experimental section is insufficiently robust to fully support the theoretical claims.', 'The complexity of the methods may hinder practical implementation and adoption.', 'The paper lacks a thorough discussion of the potential limitations and negative societal impacts of the proposed methods.']",3,3,2,3,Reject
aPOpXlnV1T,The paper identifies and addresses a significant issue in the training of neural networks for heteroscedastic uncertainty estimation using the NLL loss. The authors propose a novel β−NLL loss to mitigate the identified issues and validate its effectiveness through extensive experiments on synthetic and real-world datasets.,"['Can the authors provide more detailed ablation studies on the impact of different values of β and comparisons with other potential solutions?', 'Can the authors discuss more on addressing the training instabilities of some baselines (like MM)?', 'Can the authors provide more theoretical justification for the choice of β values?', 'Have the authors considered potential limitations of β−NLL in specific scenarios?', 'Can the authors improve the clarity of the presentation, particularly in the explanation of the β−NLL formulation and its implementation?']","['The necessity to tune the additional hyperparameter β could complicate practical applications.', 'The paper could benefit from more detailed ablation studies and discussions on addressing training instabilities in baselines.', 'The theoretical analysis and explanation of the β−NLL formulation could be improved.']",False,3,3,3,7,5,"['The paper tackles a critical and practical problem in uncertainty estimation with neural networks.', 'The proposed β−NLL loss is novel and provides a clear improvement over the traditional NLL loss.', 'Extensive experiments validate the proposed method across a range of synthetic and real-world tasks.', 'The paper is well-organized and clearly written.']","['The proposed method introduces an additional hyperparameter (β), which requires tuning.', 'More detailed ablation studies on the impact of different values of β and comparisons with other potential solutions would strengthen the paper.', 'The theoretical justification for β−NLL could be elaborated further.', 'The clarity of the presentation could be improved, particularly in explaining the β−NLL formulation and its implementation.']",3,3,3,4,Accept
9Hrka5PA7LW,"The paper addresses the problem of unsupervised continual learning (UCL) by proposing the Lifelong Unsupervised Mixup (LUMP) technique. It demonstrates that UCL is more robust against catastrophic forgetting and generalizes better to out-of-distribution tasks compared to supervised continual learning (SCL). The paper conducts extensive experiments on standard benchmarks like CIFAR-10, CIFAR-100, and Tiny-ImageNet, showing that UCL outperforms SCL in terms of robustness and generalization.","['Can the authors provide more detailed explanations and implementation steps for LUMP?', 'How does the proposed method perform on more complex or high-resolution datasets?', 'Could the authors compare their method with other unsupervised learning approaches beyond SimSiam and BarlowTwins?', 'Can the authors provide more theoretical insights into why UCL is more robust to catastrophic forgetting compared to SCL?', 'How does LUMP perform with different values of λ and α?', 'Can the authors include more ablation studies to show the impact of different components of LUMP?', 'What are the reasons for choosing specific architectures (e.g., ResNet-18) and hyperparameters for the experiments?']","['The paper does not consider high-resolution tasks for continual learning, which limits its applicability to more complex real-world scenarios.', 'The simplicity of the LUMP method may limit its perceived contribution.', 'The impact of the choice of mixing ratios in LUMP is not thoroughly investigated.']",False,3,2,3,6,4,"['Addresses an important and practical problem of unsupervised continual learning.', 'Proposes a novel technique (LUMP) that effectively reduces catastrophic forgetting.', 'Comprehensive experimental evaluation showing the robustness of UCL compared to SCL.', 'Qualitative analyses provide insights into the robustness and effectiveness of UCL methods.', 'Well-motivated with relevant real-world applications where labeled data is scarce.']","['Certain sections lack clarity, particularly the detailed implementation of LUMP and the exact setup for some experiments.', 'Evaluation is limited to specific datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet), which may not generalize to more complex or high-resolution datasets.', 'The comparison with other unsupervised methods could be more extensive.', 'The novelty of the method is somewhat limited, as it primarily extends existing techniques like SimSiam and BarlowTwins to the UCL setting.', 'The paper lacks clarity in its theoretical explanations, particularly in the sections extending SCL methods to UCL.', 'Limited evaluation on high-resolution tasks, which is a crucial aspect of continual learning.']",3,3,2,3,Reject
b30Yre8MzuN,"The paper presents NEUROSED, a novel siamese graph neural network designed to predict subgraph edit distance (SED) and graph edit distance (GED). The approach leverages inductive biases and pair-independent embeddings to enhance accuracy and scalability, outperforming state-of-the-art methods in both accuracy and speed. Extensive experiments on real graph datasets validate the effectiveness of the proposed model.","['Can the authors provide more details on the specific architectural choices, including the rationale behind using the GIN layers and sum-pool function?', 'How does the performance vary if different GNN layers (e.g., GraphSAGE, GAT) or pooling functions (e.g., max-pooling, mean-pooling) are used?', 'Can the authors discuss more on the computational feasibility of generating training data for larger query sizes and any potential strategies to mitigate these challenges?', 'Can more qualitative examples and visualizations be provided, similar to the detailed visualization in Figure 18?', 'Can the authors provide more details on the choice of hyperparameters and how sensitive the model is to these choices?', 'How does NEUROSED handle edge labels, and what is the impact on performance?', 'Can the authors provide more examples or visualizations of the embeddings learned by NEUROSED to illustrate its interpretability?', 'Can the authors provide more details on the choice of the distance function and its potential impact on the results?', 'How does the model perform on more diverse and larger datasets beyond those presented in the experiments?', 'Can the authors clarify the explanation of the neighborhood decomposition technique and its impact on scalability?']","['The ability to handle large query graphs remains a challenge, and more discussion on this limitation would be beneficial.', 'The computational feasibility of generating training data for larger query sizes is a significant concern that needs to be addressed.', 'The need for further empirical validation through additional ablation studies and qualitative analyses.', 'The handling of edge labels is not clearly explained, which could limit the applicability of the approach.']",False,3,3,4,6,4,"['Addresses a significant problem in graph analysis with a novel approach.', 'Provides theoretical guarantees and preserves important properties like the triangle inequality.', 'Extensive experimental validation on diverse datasets, showing significant improvements in accuracy and efficiency.', 'The approach allows for pair-independent embeddings, enabling pre-computation and fast querying.']","['The clarity of the exposition could be improved, especially in the architectural details and experimental setups.', 'The handling of edge labels is not clearly explained, which could impact the generalizability of the method.', 'The performance on larger query sizes and generalizability to unseen larger query sizes could be further explored.', 'Additional ablation studies could be helpful to understand the impact of various components better.']",4,3,3,4,Reject
NH29920YEmj,"The paper proposes a novel Positive and Unlabeled (PU) learning method named P3Mix, which uses a heuristic mixup technique to enhance data augmentation and supervision correction. The method aims to address the decision boundary deviation observed in PU learning by selecting mixup partners from positive instances around the learned PU boundary. Comprehensive experiments are conducted on benchmark datasets such as FashionMNIST, CIFAR-10, and STL-10 to demonstrate the effectiveness of P3Mix over state-of-the-art PU learning methods.","['Can the authors provide more details on the autoencoder aggregator and its implementation?', 'What are the criteria for selecting mixup partners, and how are they determined?', 'Have the authors considered varying the modulation function or using different types of aggregators in the ablation studies?', 'Can you provide more visualizations and examples to illustrate the decision boundary deviation phenomenon?', 'What are the reasons for P3Mix performing better than nnPU+mixup?', 'What are the specific hyperparameter settings used in the experiments?', 'Can you discuss any potential limitations and broader impacts of the proposed method?', 'Have you considered variations in the mixup hyperparameters (such as different values for α) and different settings for the thresholding parameter γ in your ablation studies?', 'What potential limitations or challenges do you foresee in applying P3Mix to other types of weakly supervised learning problems?', 'What are the potential negative societal impacts or ethical considerations of this work?', 'Can the authors elaborate on the choice of datasets and baselines used in the experiments?']","['The paper should address the impact of parameter choices more thoroughly and justify the selected ranges.', 'The authors should provide more clarity and detail in the sections describing the methodology and algorithm steps.', 'The paper does not extensively discuss potential limitations or challenges of the proposed method.', 'Additionally, it does not explore the applicability of the method to other weakly supervised learning scenarios beyond PU learning.', 'The paper lacks a detailed discussion on the potential negative societal impacts and ethical considerations.']",False,3,2,3,5,4,"['The paper tackles an important issue in PU learning, i.e., decision boundary deviation, which is practical and significant.', 'The proposed heuristic mixup technique is novel and provides a new way to achieve data augmentation and supervision correction simultaneously.', 'The paper includes comprehensive experiments on multiple benchmark datasets, demonstrating the effectiveness of the proposed method.']","['The paper lacks clarity in several sections, especially in the description of the heuristic mixup technique and the algorithm steps.', 'More details are needed on the autoencoder aggregator and the selection criteria for mixup partners.', 'The ablation studies are not exhaustive. Additional ablation models such as varying the modulation function and different types of aggregators could provide deeper insights.', 'The sensitivity analysis is somewhat limited, and the choice of parameter ranges seems arbitrary without sufficient justification.', 'The paper does not address potential limitations of the proposed method.', 'There is a lack of discussion on the broader impact and ethical considerations of the proposed approach.']",3,3,2,3,Reject
MqEcDNQwOSA,"The paper proposes a novel k-sub-embedding structure for word embeddings in neural language models to reduce the number of parameters significantly. The method involves using Cartesian products of sub-embeddings to reconstruct the original embeddings, with two proposed allocation methods: random scattering and clustering based on contextual information. The paper evaluates the performance of the proposed embeddings on English and multilingual tasks, showing that the embeddings can be compressed by over 99.9% with minimal performance loss.","['Can the authors provide more detailed ablation studies to understand the impact of different hyperparameters and design choices?', 'Can the authors elaborate on the role and implementation of the autoencoder aggregator?', 'Can the authors provide more qualitative examples and detailed discussions on the visualizations of the k-sub-embeddings?', 'Can the authors provide more detailed mathematical justification for the proposed method?', 'What is the impact of different components of the method on the overall performance?', 'Can the authors provide more detailed error analysis for the experiments?', 'What is the impact of different values of k and M on the performance and parameter reduction?', 'How does the method handle special tokens (e.g., padding, [CLS], [SEP])? Are these tokens treated differently in the sub-embedding allocation?', 'What are the effects of k-sub-embeddings on training time and computational resources? Please provide quantitative results.', 'Can the authors clarify the methodology, particularly the implementation details and experimental setup, to enhance reproducibility?']","['The paper should discuss potential limitations of the proposed approach, such as cases where the compression might not work as effectively, and any negative societal impacts it might have.', 'The performance degradation observed in some benchmarks raises concerns about the robustness of the method.', 'The impact on training time and computational resources is not addressed, which is a critical consideration for large-scale models.', 'More discussion is needed on the potential negative societal impacts, such as biases in compressed embeddings.']",False,2,2,3,4,4,"['The concept of k-sub-embedding is innovative and addresses a crucial problem in neural language models: the high parameter count of embeddings.', 'The proposed methods allow for significant compression of embeddings, reducing storage and computational requirements.', 'Comprehensive experiments on GLUE and XNLI benchmarks demonstrate that the proposed approach maintains competitive performance despite the drastic reduction in parameters.', 'The clustering-based allocation method effectively leverages pretrained models to improve the quality of sub-embeddings.']","['The paper lacks detailed ablation studies to thoroughly investigate the impact of different hyperparameters and design choices on performance.', 'The explanation of the autoencoder aggregator and its role in the proposed methods is unclear and needs more elaboration.', 'The qualitative analysis and visualizations provided are limited. More examples and detailed discussions would strengthen the paper.', 'The paper does not sufficiently address the potential limitations and negative societal impacts of the proposed approach.', 'The mathematical and theoretical justification for the proposed method is lacking in depth.', 'The clarity and organization of the paper need significant improvement.', 'The experimental results show limited improvements, and more ablation studies are needed to understand the impact of various components.', 'The methodology section is not clearly written, making it difficult to reproduce the results. Important details about the implementation and experimental setup are missing or unclear.', 'The paper does not adequately address the impact of the proposed method on training time and computational resources, which are critical factors for large-scale language models.']",3,3,2,3,Reject
A05I5IvrdL-,"The paper presents a theoretical framework for optimizing memoryless stochastic policies in infinite-horizon POMDPs using polynomial optimization techniques. It characterizes state-action frequencies as rational functions and formulates the optimization problem with polynomial constraints, providing bounds on the number of critical points. The approach is demonstrated on a navigation problem in a grid world.","['Can you provide more intuitive explanations and examples to make the paper more accessible?', 'Are there additional experimental results or validations on more complex and realistic problems?', 'Can you discuss the limitations and potential negative societal impacts of your work in more detail?', 'How can practitioners implement the proposed polynomial programming approach in real-world POMDPs?', 'Can you simplify the presentation of the theoretical results to improve clarity?', 'Are there plans to conduct more extensive empirical evaluations on diverse POMDP problems?', 'Is the code for the experiments available to facilitate reproducibility?']","['The paper does not adequately address the limitations and potential negative societal impacts of the work. The authors should provide a more thorough discussion on these aspects.', 'The complexity and density of the mathematical presentation could limit accessibility.', 'The empirical evaluation is limited to a few examples, which may not fully demonstrate the practical impact.']",False,3,2,3,5,4,"['Addresses a significant and challenging problem in POMDP optimization.', 'Provides novel theoretical contributions and detailed derivations.', 'The use of polynomial programming to reformulate the optimization problem is innovative and extends the linear programming framework used for MDPs.']","['The paper is highly technical and may not be accessible to a broader audience, limiting its impact.', 'Clarity is a significant issue; many sections are dense and difficult to follow without extensive background knowledge.', 'The experimental validation is limited to a toy example and a grid world navigation problem, which may not be sufficient to demonstrate the practical applicability of the proposed methods.', 'The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the work.']",3,3,2,3,Reject
h-z_zqT2yJU,"The paper proposes Adaptive Temperature Knowledge Distillation (ATKD) to address the performance degradation issue in knowledge distillation caused by the sharpness gap between teacher and student models. By adaptively adjusting the temperatures of the teacher and student, ATKD aims to reduce this gap and improve student performance. The paper presents a novel sharpness metric and demonstrates the effectiveness of ATKD through extensive experiments on CIFAR-100 and ImageNet datasets.","['Can the authors provide more detailed ablation studies to isolate the contributions of individual components of ATKD?', 'Can the authors clarify the mathematical derivations related to the Taylor expansion and its application to the sharpness gap?', 'What is the computational overhead introduced by adaptive temperature adjustment, and how does it compare to the baseline methods?', 'Can the authors provide more theoretical validation for the sharpness metric and its second-order Taylor expansion?', 'Can the authors provide more details on the autoencoder aggregator?']","['The paper does not provide a detailed analysis of the computational overhead introduced by adaptive temperature adjustment. Understanding the trade-offs between performance improvements and computational costs is essential for practical deployment.', 'More detailed ablation studies could strengthen the empirical validation by isolating the contributions of individual components of ATKD.', 'The clarity of the paper, particularly in the methodology section, needs improvement.']",False,3,3,3,6,4,"['Addresses a significant problem in knowledge distillation: performance degradation with oversized teachers.', 'Proposes a novel sharpness metric to quantify the sharpness of model outputs, which is an interesting contribution.', 'ATKD adaptively adjusts temperatures, which is a practical approach to reducing the sharpness gap and improving student performance.', 'Extensive experiments on CIFAR-100 and ImageNet demonstrate the effectiveness of ATKD, showing significant improvements over state-of-the-art methods.']","['The paper could benefit from more detailed ablation studies to isolate the contributions of individual components of the proposed method.', 'The clarity of some mathematical derivations, particularly the Taylor expansion, could be improved.', 'The paper does not provide a detailed analysis of the computational overhead introduced by adaptive temperature adjustment.', 'The theoretical foundation of the sharpness metric and its second-order Taylor expansion could be more rigorously validated.', 'Some sections of the paper, particularly the methodology, could be clearer and more detailed.']",3,3,3,3,Reject
Ctjb37IOldV,"The paper investigates why dropout improves generalization in neural networks by proposing a Variance Principle. This principle suggests that dropout noise exhibits larger variance in sharper directions of the loss landscape, leading to flatter minima. The study draws empirical parallels between dropout and SGD, showing that both share this variance principle, which contributes to their effectiveness in finding flatter minima. The findings are supported by experiments on multiple datasets and network architectures.","['Can the authors provide more details on the theoretical foundation of the Variance Principle?', 'How sensitive are the results to different hyperparameter settings and network initializations?', 'Can additional ablation studies be conducted to isolate the effects of the dropout rate and learning rate?', 'Can the authors provide more detailed explanations and notations for some of the mathematical formulations?', 'How does the proposed variance principle compare to other explanations for why dropout improves generalization?']","[""The paper's reliance on specific experimental setups and hyperparameters might limit the generalizability of the findings."", 'The clarity of the methodology section needs improvement to ensure reproducibility.', ""Additional theoretical insights would strengthen the paper's contributions.""]",False,3,3,3,5,4,"['Addresses an important problem in understanding how dropout improves generalization.', 'Proposes a novel Variance Principle linking dropout noise to flatter minima.', 'Empirical validation across a variety of datasets and architectures including MNIST, CIFAR-10, CIFAR-100, and ResNet-20.', 'Draws parallels between dropout and SGD, providing a unified perspective.']","['The theoretical contributions are somewhat limited; the paper heavily relies on empirical evidence.', 'The methodology section could benefit from clearer explanations and better organization.', 'Additional ablation studies are needed to fully validate the proposed Variance Principle.', 'The experiments, while comprehensive, might lack robustness due to the reliance on specific setups and hyperparameters.', 'The clarity of the paper could be improved. Some sections are difficult to follow, and the mathematical notations are not always consistent.']",3,3,3,3,Reject
dEwfxt14bca,"The paper introduces a novel approach to exploration in reinforcement learning by proposing mode-switching between exploration and exploitation. The authors investigate different modes, switching mechanisms, and the timescales at which switching makes sense. The proposed method is evaluated on Atari games, showing promising results and detailed analysis. The concept of intra-episodic exploration is particularly highlighted as an effective strategy.","['Could the authors provide more detailed explanations of the methodology and experimental setup?', 'How does the proposed approach generalize to different RL tasks and environments beyond Atari games?', 'What are the potential limitations and ethical concerns associated with the proposed method?', 'How does the reliance on specific hyper-parameters and the tuning process affect the practicality of the approach?']","['The complexity of the methodology and experimental setup may limit reproducibility.', 'The generalizability to other RL tasks and environments is not well-explored.', 'Potential ethical concerns and limitations are not adequately discussed.']",False,3,3,3,5,4,"['The paper addresses a significant challenge in reinforcement learning: the exploration-exploitation trade-off.', 'The introduction of mode-switching and intra-episodic exploration is novel and well-motivated.', 'The experimental setup on Atari games is comprehensive, and the results show promising improvements over traditional methods.', 'Detailed analysis and visualization of exploration behaviors provide valuable insights into the proposed approach.']","['The methodology and experimental setup are complex and may benefit from further clarification and simplification.', 'The generalizability of the proposed approach to other RL tasks and environments is not well-explored.', 'The paper does not adequately discuss the potential limitations and ethical concerns of the proposed method.', 'The reliance on specific hyper-parameters and the tuning process is not thoroughly addressed, which may impact the practicality of the approach.']",3,3,3,4,Reject
XHUxf5aRB3s,"The paper addresses non-stationarity in cooperative multi-agent reinforcement learning (MARL) by introducing a δ-stationarity measurement to explicitly measure and control non-stationarity. The authors propose the Multi-Agent Mirror descent policy algorithm with Trust-region decomposition (MAMT), which uses a Trust-Region Decomposition Network (TRD-Net) based on message passing to estimate joint policy divergence more accurately. Contributions include a formal definition of non-stationarity in MARL, a novel trust-region decomposition scheme, and empirical results demonstrating improved performance over baselines.","['Can the authors provide more detailed explanations and intuitive insights into the key theoretical results, especially the proofs of the main theorems?', 'How does TRD-Net perform with different network architectures or hyperparameters? Are there specific configurations that significantly impact performance?', 'Can you provide more details on the computational overhead of the proposed method?', 'How does your method compare with more recent or stronger baselines in MARL?', 'Can you include more detailed ablation studies to further validate the components of your method?']","['The paper could better address the computational complexity and scalability of the proposed methods.', 'The potential impact of hyperparameter tuning on the performance of TRD-Net could be more thoroughly investigated.', 'The complexity of the proposed methods and the limited ablation studies on key components.', 'The need for clearer explanations and better accessibility of the theoretical parts.', ""The paper's complexity and computational requirements might limit its practicality."", 'More comprehensive ablation studies are needed to better understand the impact of different components.', 'The dense presentation could be a barrier to understanding for some readers.']",False,3,3,3,6,4,"['The problem of non-stationarity in MARL is significant and practical.', 'The introduction of δ-stationarity and the theoretical analysis linking it to KL-divergence is a meaningful contribution.', 'The use of TRD-Net for trust-region decomposition and the empirical results showcasing performance improvements are noteworthy.', 'Comprehensive experiments are conducted in different environments to validate the approach.']","['The clarity of the theoretical exposition is sometimes lacking, especially in the proofs. For instance, the transitions between definitions and theorems could be made more intuitive.', 'There is a strong reliance on empirical validation without enough emphasis on the practical challenges of implementing the proposed methods in real-world settings.', 'The ablation studies, while present, could be more comprehensive. For example, the impact of different network architectures and specific hyperparameters on the performance of TRD-Net is not thoroughly explored.', 'The computational overhead of the proposed method is not adequately discussed.', 'Some of the baselines used for comparison might not be the most current or strong, which could affect the validity of the performance claims.']",3,3,3,3,Accept
pgkwZxLW8b,"The paper proposes Federated Sampled Softmax (FedSS), a method to efficiently train image representation models on decentralized data with a large number of classes using Federated Learning (FL). The approach involves sampling a subset of classes and optimizing a sampled softmax loss to approximate the global full softmax objective, thereby reducing computational and communication costs. The paper empirically demonstrates that FedSS performs on par with full softmax training while requiring significantly fewer parameters.","['Can the authors provide more details on the sampling mechanism and how it ensures unbiased gradient estimation?', 'How does FedSS compare with other FL methods in terms of privacy preservation?', 'What are the potential limitations of FedSS in real-world applications?', 'How does the performance and communication cost change with varying the number of sampled negatives?', 'What additional privacy measures could be implemented to ensure that class labels sent to the server do not compromise client privacy?', 'How does the uniform sampling of negative classes affect the bias in gradient estimation?', 'Can the authors provide more insights into the convergence properties of the proposed method?', 'How sensitive is the performance of FedSS to the choice of hyperparameters such as the number of negative samples?', 'Can the authors discuss the impact of non-IID data distribution on the performance of FedSS?']","['The paper does not adequately discuss potential limitations, such as the impact of non-IID data distribution on FedSS performance.', 'The ethical considerations and potential negative societal impacts of using FedSS in real-world applications are not addressed.', 'The assumption that the label space is known to all clients and the server may not always hold, which can limit the applicability of the proposed method.', 'Potential privacy concerns are not thoroughly addressed. The class labels sent to the server could potentially leak information about the data on the clients.', 'The authors should discuss the potential biases introduced by uniform sampling of negative classes in more detail. Additionally, more extensive ablation studies and theoretical analysis would strengthen the claims made in the paper.']",False,3,3,3,6,4,"['Addresses a critical challenge in Federated Learning related to computational and communication efficiency.', 'Proposes a novel approach (FedSS) for efficient image representation learning on decentralized data.', 'Demonstrates empirical effectiveness with comprehensive experiments on multiple datasets.', 'Shows significant reduction in the number of parameters transferred and optimized, making it suitable for edge devices.']","['The novelty of the method could be questioned as it builds on existing concepts like sampled softmax.', 'The clarity of the methodological explanation, especially around the sampling mechanism and loss formulation, could be improved.', 'The paper could benefit from a more thorough comparison with additional related works in the FL domain.', 'Potential limitations and negative societal impacts are not adequately discussed.', 'The experimental section could benefit from additional ablation studies and more diverse datasets.', 'The paper lacks a rigorous theoretical analysis to support the convergence and performance guarantees of the proposed method.']",3,3,3,3,Reject
s51gCxF70pq,"The paper presents k-Step Latent (KSL), a novel method for improving sample efficiency in reinforcement learning (RL) by enforcing temporal consistency in representations via a self-supervised auxiliary task. The proposed method shows significant improvements in data efficiency and asymptotic performance on the PlaNet benchmark suite compared to several state-of-the-art methods.","['Could the authors provide more detailed descriptions of the training process and architecture to improve clarity?', 'Can the authors include additional ablation studies, particularly on the impact of different modulation functions and the effect of various types of aggregators in the transition model?', 'How do the authors ensure a fair comparison between KSL and other baseline methods?', 'Can the authors discuss potential ways to mitigate the increased computational cost of KSL?', 'Can the authors provide more details about the autoencoder aggregator used in the methodology?', 'Have the authors considered other types of modulation functions or aggregators? If so, what were the results?', 'Can the authors provide additional visualizations or examples in the rebuttal period to further illustrate the effectiveness of the proposed method?', 'How sensitive is KSL to the choice of hyperparameters and architecture?', 'How does KSL perform in more complex environments or with different types of perturbations?']","['The paper does not sufficiently address the potential limitations and negative societal impacts. For instance, the increased computational cost and wall clock time are briefly mentioned but not thoroughly examined.', 'The scalability of KSL to more complex tasks or environments is not thoroughly explored.']",False,3,3,3,7,4,"['KSL introduces a novel auxiliary task that encourages temporally-consistent representations, enhancing sample efficiency for RL agents.', 'The method achieves state-of-the-art performance on the PlaNet benchmark suite, significantly outperforming existing methods like DrQ, RAD, CURL, and SAC-AE.', 'The paper provides extensive empirical evaluation, including an analysis of the learned representations and encoders, which shows the robustness and generalizability of the proposed method.']","['The paper lacks clarity in certain sections, particularly in explaining the architecture and the training details of KSL. More detailed descriptions and visual aids could help.', 'The reproducibility of the results is questionable as the provided pseudocode and the description of hyperparameters are not comprehensive enough.', 'Some ablation studies are missing, such as the impact of different modulation functions and the effect of various types of aggregators in the transition model.', 'The increased computational cost compared to some baselines might limit its practical applicability.']",3,3,3,4,Accept
Rx9luEzcSoy,"The paper proposes the concept of Lottery Image Prior (LIP), inspired by the Lottery Ticket Hypothesis (LTH), to explore if sparse subnetworks in DNN-based image priors can match the performance of the original dense models in various image inverse problems. The study is conducted in two settings: deep image prior (DIP) with untrained DNNs and compressive sensing with pre-trained GANs. The results indicate that LIP subnetworks can be found with different sparsity levels and exhibit high transferability across tasks and datasets.","['Could the authors provide more details on the methodology for finding LIP subnetworks?', 'Have the authors tested the approach on more diverse and complex datasets?', 'What are the impacts of different pruning strategies on the performance of LIP subnetworks?', 'Can the authors provide more details on the iterative magnitude pruning (IMP) process used to find the LIP subnetworks?', 'How are SNIP and random pruning methods implemented and evaluated in this study?', 'What are the practical implications of the LIP hypothesis in terms of computational savings and resource reduction?', 'Can the authors provide more detailed explanations and captions for the figures and visual results?', 'Could you provide more details on the implementation of the pruning process, especially in the multi-image IMP setting?', 'Can you include more diverse baseline comparisons to strengthen your claims?', 'Have you considered the potential limitations and societal impacts of your work?', 'Can the authors provide more details on the specific architectures used in the experiments, including the number of layers and parameters?', 'How were the training procedures for finding LIP subnetworks conducted? Please provide a detailed description of the training steps, epochs, and hyperparameters?', 'Can the authors conduct additional ablation studies to explore the impact of different factors, such as the choice of pruning methods and the number of training iterations, on the performance of LIP subnetworks?']","['The authors should discuss the limitations of their approach, such as its applicability to more complex datasets and different types of image priors.', 'Potential negative societal impacts are not addressed.', 'The paper does not adequately address the potential limitations and societal impacts of the proposed method. This should be considered to provide a balanced view of the work.', 'The paper could explore more ablation studies on different pruning methods and their impact on the performance of LIP. Additionally, a comparison with other structured pruning techniques would strengthen the contributions.', 'The potential negative societal impacts of the work are not addressed, such as the energy consumption and environmental impact of training large DNNs.']",False,3,2,3,5,4,"[""Introduces the novel concept of 'Lottery Image Prior' (LIP)."", 'Comprehensive experiments in two different settings.', 'Demonstrates the high transferability of LIP subnetworks.', 'Addresses an important question about the necessity of heavy parameterization in DNN-based image priors.']","['The methodology for finding LIP subnetworks lacks clarity.', 'Limited evaluation on more diverse and complex datasets.', 'Insufficient analysis of the impact of different pruning strategies.', 'The novelty of applying LTH to image priors is somewhat incremental.', 'The experimental setup for the comparison with other pruning methods like SNIP and random pruning is not well-detailed.', 'The paper does not provide a thorough analysis of the practical implications of the LIP hypothesis.', 'Figures and visual results are not well-explained.', 'Potential limitations and societal impacts are not adequately addressed.']",3,3,2,3,Reject
ab7lBP7Fb60,"The paper introduces FPFL, an algorithm to enforce group fairness in private federated learning by extending the modified method of differential multipliers (MMDM). The paper aims to address fairness degradation in federated learning with differential privacy, providing a solution applicable to neural networks trained with stochastic gradient descent. The approach is tested on the Adult and FEMNIST datasets, demonstrating its ability to mitigate unfairness introduced by private federated learning.","['Can the authors provide a more rigorous theoretical justification for the adaptation of MMDM to PFL?', 'How were the hyperparameters chosen, and why were these values selected?', 'Can the authors compare their results with a broader range of baselines, including those from recent literature on fairness in federated learning?', 'Can the authors provide a more in-depth analysis of the results, particularly in the context of federated learning with differential privacy?', 'How does the proposed method handle varying levels of differential privacy noise?', 'Can you provide more details on the scalability of FPFL to larger models and datasets?', 'Have you considered additional baselines or datasets to further validate the robustness of your results?', 'Have the authors considered alternative aggregation techniques in the federated setting?', 'Can the authors include additional ablation studies to further validate their approach?']","['The sensitivity of FPFL to DP noise is acknowledged but not adequately addressed or mitigated.', 'Potential ethical concerns arising from fairness enforcement algorithms in federated settings are not discussed.', 'The paper could benefit from more detailed explanations of certain algorithmic components.', 'Additional ablation studies would strengthen the experimental validation.', 'Exploration of alternative aggregation techniques in the federated setting is limited.']",False,3,2,3,4,4,"['Addresses a significant and timely issue by combining fairness and privacy in federated learning.', 'Proposes a novel extension of the modified method of differential multipliers (MMDM) to the federated learning setting.', 'Provides experimental results showing the effectiveness of the proposed method in mitigating unfairness.']","['The paper is difficult to follow, particularly in its mathematical notations and explanations.', 'The adaptation to PFL is not rigorously justified, lacking sufficient theoretical backing.', 'The experimental setup is limited to two datasets, which may not be sufficient to generalize the findings.', 'The choice of hyperparameters and the lack of comparison with a broader range of baselines are weaknesses.', 'The impact of differential privacy noise on performance and fairness is not deeply explored.']",3,3,2,3,Reject
KeBPcg5E3X,"The paper proposes ContraLORD, a method that combines contrastive learning with latent optimization to learn disentangled representations in generative models. The method is evaluated on ten benchmarks and shows promising results in both disentanglement and linear classification tasks.","['Can you provide more details on the autoencoder aggregator and its role in the method?', 'How does your method compare to more recent baselines in the field of disentanglement?', 'Can you provide more qualitative examples to demonstrate the effectiveness of your method?', 'Can the authors provide more detailed explanations of the methodological components, particularly the encoder pre-training and contrastive loss functions?', 'Can the authors include more comprehensive ablation studies to verify the contribution of each component of ContraLORD?', 'What are the specific hyperparameter settings and architecture details for the generator and encoders?', 'How does the method handle potential negative societal impacts?', 'What is the impact of different modulation functions and types of aggregators on the performance?', 'Can the authors provide additional visualizations or examples in the qualitative analysis?']","['The paper does not sufficiently address potential limitations, such as computational complexity and scalability of the proposed method.', 'The potential ethical concerns related to the use of disentangled representations in real-world applications are not discussed.']",False,2,2,2,4,4,"['The combination of contrastive learning and latent optimization is an interesting approach.', 'Extensive experiments are conducted on a wide range of benchmarks.', 'Promising results in terms of both disentanglement metrics and linear classification accuracy.']","['The novelty of the approach is not entirely clear given the existing literature on contrastive learning and disentanglement.', 'Lack of detailed ablation studies to thoroughly investigate the contributions of different components.', 'Certain components, such as the autoencoder aggregator, are not clearly explained.', 'The experimental results could benefit from additional baselines for a more comprehensive comparison.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed method.']",3,2,2,3,Reject
neqU3HWDgE,"The paper introduces a novel approach for unsupervised disentanglement using tensor product representations on a torus, named T8-VAE. This method maps the latent space to unit circles (S1) rather than the conventional Gaussian-distributed latent spaces in VAEs. The approach aims to effectively capture the generative factors, and the paper demonstrates its advantages through extensive experiments on various datasets.","['Can you provide more theoretical justification for the use of the torus structure?', 'Could you include additional ablation studies to show the impact of different components and hyperparameters on the performance?', 'How does the proposed method scale with datasets containing a larger number of generative factors?', 'Can the authors provide more detailed theoretical justification for choosing the torus structure over other compact manifolds?', 'Can the authors provide additional visual aids and more intuitive explanations for the methodological details and the connection to quantum physics?', 'Have the authors performed statistical tests to validate the significance of their experimental results?', 'What is the impact of different hyperparameter settings on the performance of the proposed method?', 'Can the authors discuss in more detail the limitations of their approach, particularly regarding scalability and non-compact data representations?']","['The theoretical justification for the torus structure needs more clarity.', 'More ablation studies are needed to understand the impact of different components and hyperparameters.', 'The scalability of the method to datasets with many generative factors is not thoroughly validated.', 'The practical implications and potential limitations of the proposed method are not thoroughly discussed.', 'The applicability of the method to non-compact data representations remains unclear and should be discussed in more detail.']",False,3,3,3,5,4,"['The use of a torus structure in the latent space is novel and well-motivated.', 'Extensive experiments demonstrate the effectiveness of the proposed method compared to existing VAE variants.', 'The paper introduces a new metric, the DC-score, which combines disentanglement and completeness.', 'The theoretical foundation is robust, drawing from quantum physics concepts to justify the use of the torus structure.', 'The paper provides code for reproducibility, which is a strong positive.']","['The theoretical justification for using the torus structure is not thoroughly elaborated and needs more clarity.', 'Several sections, particularly the mathematical justifications and the connection to quantum physics, are dense and could benefit from more detailed explanations.', 'More ablation studies are needed to understand the impact of different components and hyperparameters on the performance.', 'The scalability of the method to datasets with a large number of generative factors is questionable and not thoroughly addressed.', 'The practical implications and potential limitations of the proposed method are not thoroughly discussed.']",4,3,3,3,Reject
DYaFB19z1ig,"The paper presents Self-Distribution Distillation (S2D), a novel approach to efficiently estimate uncertainties in deep learning models by integrating ensemble training and distribution distillation into a single model. It also introduces Hierarchical Distribution Distillation (H2D) for further efficiency in deployment. The methods are evaluated on CIFAR-100, LSUN, Tiny ImageNet, and SVHN datasets, showing improvements in accuracy and uncertainty estimation over standard models and some ensemble methods.","['Can the authors provide more detailed explanations and structuring of the proposed method?', 'Can the authors include more ablation studies to isolate the contributions of different components?', 'How does the performance of S2D compare to other state-of-the-art methods beyond CIFAR-100?', 'What are the potential negative societal impacts or limitations of the proposed methods?', 'Can the authors provide more details on the specific regularization techniques used and their impact on performance?', 'How does the proposed method perform on tasks other than image classification, such as natural language processing or speech recognition?', 'Can the authors provide more comprehensive visualizations in the qualitative analysis section?']","['The clarity and detailed explanations of the proposed method are lacking.', 'More ablation studies are needed to isolate the contributions of different components.', 'The novelty of the hierarchical distribution distillation (H2D) is not well justified.', 'No discussion on the potential negative societal impacts or limitations of the proposed methods.', 'The impact on real-world deployment scenarios, especially in terms of computational resources, should be addressed.']",False,3,3,3,5,4,"['Addresses a critical need for efficient uncertainty estimation in safety-critical applications.', 'Proposes a potentially impactful method that combines ensemble methods and distribution distillation.', 'Demonstrates the approach on multiple datasets, showing improvements in accuracy and uncertainty estimation.']","['The clarity of the proposed method and its implementation is lacking. The paper needs more detailed explanations and better structuring.', 'The experimental results, while promising, do not thoroughly convince due to limited comparisons and potential overfitting to CIFAR-100.', 'There is a need for more ablation studies to isolate the contributions of different components.', 'The novelty of the hierarchical distribution distillation (H2D) is not well justified; it seems like a straightforward extension of existing methods.', 'No discussion on the potential negative societal impacts or limitations of the proposed methods.']",3,3,3,4,Reject
8in_5gN9I0,"The paper introduces data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles in graph streams. The algorithms leverage a 'heavy edge' oracle, trained via machine learning techniques, to improve space complexity in the adjacency list and arbitrary order models. The paper provides both theoretical and empirical results, demonstrating improvements over classical algorithms in terms of space complexity and efficiency.","['Can the authors provide more intuitive explanations or visualizations for the proposed algorithms? This would help in understanding the dense theoretical sections.', 'Could the experimental section include a wider variety of graph datasets to demonstrate the general applicability of the methods?', 'How robust are the proposed methods under different noise models? Additional experiments would help validate this aspect.', 'Can the authors elaborate on the practical implementation details, especially concerning the training of the heavy edge oracle and its real-time application?']","['The primary limitation is the clarity and accessibility of the content. The paper could benefit from more intuitive explanations and visual aids to make complex sections more understandable.', 'Additional experiments on robustness under noise and diverse datasets would strengthen the empirical validation.']",False,3,2,3,5,4,"['The paper addresses a significant problem in graph analytics, enhancing the efficiency of triangle and four-cycle counting in graph streams.', 'The use of machine learning-based oracles to predict heavy edges is a novel and relevant approach, potentially applicable to a broader range of graph problems.', 'Theoretical analysis is thorough, providing bounds and guarantees for the proposed algorithms.', 'Empirical results show promising improvements over state-of-the-art algorithms, validating the practical applicability of the proposed methods.']","['The clarity of the paper is a concern. Several sections, particularly those describing the algorithms and theoretical proofs, are dense and hard to follow. More intuitive explanations and visual aids would help.', 'Experimental analysis, while comprehensive, could benefit from more detailed comparisons with additional baselines. The choice of datasets could be expanded to include more diverse types of graphs.', 'The robustness of the proposed methods under different noise models is not extensively validated. More experiments showing the performance under various noise conditions would strengthen the claims.', 'The practical implementation details, such as the training of the heavy edge oracle and its integration in real-time streaming scenarios, are not sufficiently detailed.']",3,3,2,3,Reject
u6sUACr7feW,"The paper 'DPP-TTS: Diversifying Prosodic Features of Speech via Determinantal Point Processes' proposes a novel text-to-speech (TTS) model that utilizes Determinantal Point Processes (DPPs) to diversify prosodic features of speech. This model, named DPP-TTS, includes a prosody diversifying module (PDM) that enhances prosodic expressiveness by sampling diverse prosodic features based on a learned DPP kernel. The paper demonstrates that the model can generate speech with richer prosody compared to state-of-the-art models while maintaining naturalness.","['Can the authors provide more details on the autoencoder aggregator used in the model?', 'What is the effect of different types of aggregators on the performance of the proposed model?', 'Can the authors include more visualizations and qualitative analyses to provide better insights into the prosodic variations generated by the model?', 'Can you provide more details on the architecture of the Prosody Diversifying Module (PDM)?', 'Have you considered other types of aggregators in your model, and how do they impact the performance?', 'Can you provide more qualitative examples or visualizations of the prosodic features generated by DPP-TTS?', 'Can you provide more details on the implementation of the prosody diversifying module (PDM)?', 'Have you conducted any ablation studies on the key components and hyperparameters of the model? If so, please provide the results.', ""Can you explain the choice of certain hyperparameters and their impact on the model's performance?"", 'How is the kernel matrix for the DPP constructed in practice? Can the authors provide more mathematical details?', 'What is the impact of different hyperparameters on the performance of the model? Can the authors provide a more detailed ablation study?', 'Can the authors provide more objective evaluation metrics to support their claims of improved prosody diversity?', 'Have the authors considered the potential limitations and negative societal impacts of their method?', 'How does the performance of the model change with different values of the smoothing parameter γ in Soft-DTW?', 'Can the authors include more ablation studies exploring variations in the PDM architecture?']","['The clarity of the paper can be improved, particularly in the explanation of the autoencoder aggregator and the methodology.', 'The paper could include more ablation studies to isolate the contributions of individual components.', 'The lack of clarity and detailed explanations in some sections makes it difficult to fully understand and evaluate the proposed methods.', ""Absence of comprehensive ablation studies on key components and hyperparameters hinders the assessment of the model's robustness and effectiveness."", 'The paper does not adequately address the limitations of the proposed method. For example, the computational complexity of DPPs and the potential negative impacts on naturalness for extreme values of diversity control are not discussed.', 'The paper should discuss potential limitations, such as the scalability of the model to different languages or dialects, and the impact of large-scale datasets on training time and performance.']",False,3,2,3,5,4,"['The paper addresses an important issue in TTS: the lack of prosodic diversity.', 'The proposed use of DPPs for prosody diversification is novel and well-motivated.', 'The experimental results show that DPP-TTS improves prosody diversity without sacrificing naturalness, as evidenced by side-by-side comparisons and MOS scores.', 'The paper is comprehensive, covering a wide range of experiments and evaluations, including human evaluations and additional metrics such as inference speed.']","['The explanation of the autoencoder aggregator and some parts of the methodology are not very clear.', 'Additional ablation studies could further validate the effectiveness of individual components of the model.', 'The paper could benefit from more detailed visualizations and explanations in the qualitative analysis section.', 'The paper lacks sufficient details on the implementation of the PDM and how exactly it integrates with the TTS model.', 'The explanation of the kernel construction and the use of Soft-DTW for measuring similarity is not very clear. More mathematical rigor and clarity are needed.', 'The evaluation metrics used in the experiments are limited. More objective measures, such as standard deviation of pitch and duration across different test samples, would strengthen the claims.', 'The paper does not sufficiently address potential limitations and negative societal impacts of the proposed method.']",3,3,2,3,Reject
e8JI3SBZKa4,"The paper proposes a method for kernel similarity matching using Hebbian neural networks, aiming to learn non-linear features directly rather than relying on random Fourier features. The method involves deriving and minimizing an upper bound for the sum of squared errors between output and input kernel similarities, resulting in a 1-layer recurrent neural network with correlation-based learning rules. The approach is validated on the half moons and MNIST datasets.","['Can the authors provide more details on the mathematical derivations, especially the steps leading to the correlation-based upper bound?', 'How does the proposed method scale with increasing input dimensionality and dataset size?', 'Can the authors provide a more detailed analysis of the convergence properties of the gradient descent ascent algorithm?', 'Can the authors provide more intuition behind the theoretical derivations, especially for readers who may not be familiar with advanced kernel methods?', 'What strategies can be employed to mitigate the convergence issues reported?', ""What are the practical implications of the method's performance degradation with higher output dimensionality? Are there ways to mitigate this issue?"", 'What are the potential limitations and negative societal impacts of the proposed method?', 'How does the proposed method compare with existing methods in a broader range of datasets and tasks?', 'Can the authors provide more insights into the sensitivity of the algorithm to learning rates?', 'Are there any strategies to improve the convergence of the proposed method?', 'Can the authors provide additional experiments to demonstrate the robustness of their method across different datasets and settings?']","['The paper should discuss the computational efficiency and scalability of the proposed method, particularly for large-scale datasets.', 'The authors should address the potential limitations of the method, including its performance degradation for high-dimensional outputs and the sensitivity to learning rate choices.', ""The method's sensitivity to hyperparameters and learning rates is a limitation that needs further investigation."", 'The performance degradation with increasing output dimensionality is a concern that should be addressed or mitigated.', 'The scalability and practical implications for large-scale problems are not thoroughly discussed, which is important for real-world applications.']",False,2,2,2,4,4,"['The paper introduces a novel approach by directly learning non-linear features for kernel similarity matching using Hebbian principles.', 'The proposed method is biologically inspired, adhering to online and local synaptic update rules, which are relevant for creating brain-like learning algorithms.', 'The theoretical derivations are rigorous and extend existing methods in a meaningful way.', 'The empirical evaluations on benchmark datasets provide initial validation of the proposed method.']","['The paper lacks clarity in several sections, particularly in the mathematical derivations and the experimental setup.', ""The empirical results, while extensive, do not convincingly demonstrate the superiority of the proposed method over all baselines, especially for high-dimensional outputs where the method's performance degrades."", 'The convergence of the proposed gradient descent ascent algorithm is treated as an empirical issue without sufficient theoretical guarantees or detailed empirical evaluation of convergence properties.', ""The method's sensitivity to hyperparameters and learning rates is mentioned but not thoroughly investigated."", 'The practical applicability of the method is limited due to the reported sensitivity to hyperparameters and convergence issues.', 'The paper does not adequately address potential limitations and the broader impact of the proposed method, such as computational efficiency and scalability.']",3,2,2,3,Reject
inSTvgLk2YP,"The paper presents MeshInversion, a method for single-view 3D textured mesh reconstruction using generative priors encapsulated in a pre-trained GAN. The approach aims to improve reconstruction quality by searching for a latent space in the 3D GAN that best matches the target mesh based on a single image. Key contributions include the Chamfer Texture Loss and Chamfer Mask Loss to address misalignment and information loss during rendering.","['Can the authors provide more comprehensive comparisons with a broader set of baselines to validate their method?', 'Can the authors include more detailed ablation studies to better understand the impact of each proposed component, particularly the Chamfer losses?', 'Can the authors clarify the details and provide more illustrations for the Chamfer Texture Loss and Chamfer Mask Loss?', 'Can the authors provide more details on the pre-training process of the GAN?', 'How does the method perform on more diverse datasets or categories outside of CUB and PASCAL3D+?', 'Could the authors include more ablation studies to explore the contributions of different model components?', 'How does the Chamfer Texture Loss handle high-frequency textures, and what are the values for the parameters εs, εa, and α?', 'Can you provide more details about the pre-training stage of the GAN, specifically the preparation of pseudo ground truths?', 'How robust is the approach to inaccuracies in camera pose estimation? Can the authors provide more experiments or analysis on this aspect?']","['The paper does not thoroughly validate the generalizability and robustness of the proposed method across a wider range of objects and conditions.', ""The explanations and illustrations for the Chamfer losses are not sufficiently detailed, which may affect the reader's understanding."", ""The method's complexity and potential reproducibility challenges should be addressed."", 'The generalization to other categories or more diverse datasets needs further exploration.', 'The reliance on accurate camera pose estimation can be a limitation, as inaccuracies in pose estimation can adversely affect the reconstruction quality. Further exploration of this aspect is recommended.']",False,3,3,3,6,4,"['Innovative use of GAN inversion to exploit generative priors for 3D mesh reconstruction.', 'Proposes novel Chamfer Texture Loss and Chamfer Mask Loss to handle misalignment and discretization issues.', 'Shows promising results on CUB-200-2011 and Pascal3D+ datasets.', 'Comprehensive experimental results demonstrating state-of-the-art performance.', 'Good generalization to occlusions and less common shapes.']","['Limited comparison with a broader set of baselines, reducing the strength of the experimental validation.', 'Ablation studies are insufficient to fully understand the impact of each proposed component.', 'Certain sections, especially around the Chamfer losses, are not clearly explained and could benefit from more detailed illustrations.', 'Generalizability and robustness across a wider range of objects and conditions are not thoroughly validated.', ""The method's complexity, involving multiple steps and components, might hinder reproducibility."", 'Evaluation focused mainly on qualitative results; more quantitative comparisons would be beneficial.']",3,3,3,4,Reject
0lSoIruExF,"The paper proposes methods to incorporate user-item similarity into hybrid neighborhood-based recommendation systems. It introduces techniques to estimate user interests from interactions and integrates these into the baseline estimate for improved accuracy. The proposed system is evaluated using the MovieLens 20M dataset, showing some improvements in RMSE and MAE metrics.","['What are the theoretical justifications for the chosen hyperparameters and optimization techniques?', 'How do the proposed methods compare with more advanced state-of-the-art techniques?', 'Can the clarity of the methodology be improved with more consistent notation and structured explanations?', 'Can the authors provide more details on the practical implementation of the proposed user-item similarity integration?', 'What are the potential limitations or challenges of the proposed approach, especially in terms of computational complexity and scalability?', 'Can the authors conduct additional experiments on different datasets or scenarios to demonstrate the robustness and generalizability of the proposed system?', 'Is it possible to provide an ablation study to highlight the contribution of each component of the proposed approach?', 'How do the authors plan to address the ethical concerns related to user privacy?', 'Could you provide more details on the autoencoder aggregator?', 'Can you elaborate on the methodology for characterizing user preferences?']","['The paper does not discuss the limitations of the proposed methods or their potential negative societal impacts.', 'The evaluation is limited to a single dataset, and additional experiments on different datasets or scenarios are needed to demonstrate the robustness of the approach.', 'The increased computational complexity of the proposed methods and the need for further details on the autoencoder aggregator and user preference characterization.']",False,2,2,2,4,4,"['Addresses a relevant and practical problem in recommendation systems.', 'Proposes novel methods to represent user preferences and incorporate them into neighborhood-based models.', 'Comprehensive experiments with thorough analysis.']","['Limited novelty, as many elements are well-studied in the literature.', 'Lacks sufficient theoretical grounding and justification.', 'Modest improvements in experimental results, lacking comparison with more advanced techniques.', 'Clarity issues, with convoluted descriptions and inconsistent notation.', 'Lack of discussion on limitations and potential negative societal impacts.', 'The computational complexity of the proposed methods is increased, and scalability concerns are not convincingly addressed.']",2,2,2,2,Reject
4lLyoISm9M,"The paper proposes Range-Net, a deterministic two-stage neural optimization approach for Singular Value Decomposition (SVD) that aims to provide high precision and low memory requirements. The method is claimed to be fully interpretable and to satisfy the Eckart-Young-Mirsky (EYM) tail-energy lower bound with machine precision. The approach is evaluated on several datasets and compared with the state-of-the-art streaming Randomized SVD method, SketchySVD.","['Can the authors provide more intuitive explanations and visualizations of the proposed method to enhance clarity?', ""How does the method's performance vary with different oversampling parameters in SketchySVD? Can this be analyzed in more detail?"", ""Can the authors provide additional empirical validation for the claim that the method's performance is independent of the streaming order of samples?"", 'Can the authors provide more detailed explanations of the Range-Net architecture and the training process?', 'What specific hyperparameters were used in the experiments, and how were they chosen?', 'Can additional ablation studies be provided to justify the design choices and to test the robustness of Range-Net?']","['The paper should more clearly address the limitations of the proposed method, especially in terms of computational complexity and potential failure cases.', 'Potential negative societal impacts are not discussed, which should be included for a comprehensive evaluation.', 'The clarity of the paper could be improved, especially in the theoretical explanations.', 'Additional ablation studies could provide more insights into the contributions of each component of Range-Net.']",False,3,3,3,6,4,"['Addresses an important problem in big data applications where memory efficiency and accuracy are critical.', 'Provides deterministic results with high precision, which is a significant advantage over existing randomized methods.', ""Theoretical guarantees are provided for the method's performance."", 'Comprehensive numerical experiments are conducted on various datasets, including real-world applications.']","['The paper is very dense and challenging to follow, especially for readers not deeply familiar with SVD and matrix decomposition.', 'The theoretical analysis needs to be more clearly connected to the empirical results.', 'The comparison with existing methods such as SketchySVD needs to be more robust.', ""Some claims, such as the method's independence from the streaming order of samples and exact memory requirements, need further empirical validation."", 'Lacks detailed descriptions of the experimental setup and hyperparameters used.', 'Additional ablation studies are needed to justify the design choices.']",3,3,3,4,Reject
g4nVdxU9RK,"The paper proposes Rewardless Open-Ended Learning (ROEL), an algorithm that combines unsupervised reinforcement learning with the POET framework to teach agents a diverse set of complex skills without predefined rewards. The approach leverages mutual information for skill discovery and aims to generate increasingly complex and novel behaviors. The method is tested on the bipedal walker environment, demonstrating the ability to learn diverse and general skills.","['Can the authors provide a more detailed explanation of the skill-dynamics network and its role in ROEL?', 'Could the qualitative analysis include more examples to better illustrate the effectiveness of ROEL?', 'Can the authors provide more detailed explanations of the mutual information-based reward function and its implementation?', 'What is the impact of using different types of aggregators in the proposed method?', 'Can the authors provide more visualizations and examples of the skills learned by the agents in the qualitative analysis?', 'Can the authors provide a more detailed theoretical justification for the derivation of the reward function from mutual information?', 'Can the authors improve the organization of the paper, especially the sections explaining the POET framework and its integration with the unsupervised learning component?', 'Can the authors provide more rigorous and statistically significant experimental results to support their claims?', 'Can the authors compare their approach with a broader set of state-of-the-art methods in unsupervised RL and open-ended learning?', 'Can the authors address the limitations and potential negative societal impacts of their approach?']","['The paper does not adequately address the limitations and potential negative societal impacts of the proposed approach. The authors should discuss these aspects in more detail.', 'The practical applicability and generalization capability of the approach are not sufficiently demonstrated.']",False,3,3,3,4,4,"['Novel combination of open-ended learning and unsupervised reinforcement learning.', 'Comprehensive experimental setup that demonstrates the effectiveness of the approach.', 'Potential to significantly impact the field by enabling training without predefined rewards.', 'Addresses a significant problem in reinforcement learning: the challenge of defining effective reward functions.']","['The explanation of the skill-dynamics network and its role in ROEL could be clearer.', 'Qualitative analysis could include more examples to strengthen the claims.', 'Needs more discussion on potential limitations and ethical considerations.', 'Lacks sufficient theoretical justification for some claims, particularly the derivation of the reward function from mutual information.', 'The paper is not well-organized, making some sections difficult to follow.', 'Experimental results lack rigor and comprehensive quantitative analysis.', 'Insufficient comparisons with other state-of-the-art methods in unsupervised RL and open-ended learning.', 'Methodology section is underdeveloped and lacks clear, step-by-step explanations of the approach.']",3,3,3,3,Reject
6PlIkYUK9As,"The paper proposes a novel subset selection method for deep learning that integrates diversity, uncertainty, and balancing constraints using matroids. The approach aims to select informative and diverse subsets of data that allow for training models with similar performance to those trained on the full dataset, thus reducing computational and labeling costs. The method is evaluated on standard datasets like CIFAR-10, CIFAR-100, ImageNet, and a long-tailed dataset, CIFAR-100-LT.","['Can the authors provide more details on the autoencoder aggregator and its impact on performance?', 'How does the method perform in comparison to more recent subset selection techniques?', 'Can the authors discuss potential societal impacts and limitations of their approach?', 'Can you provide more detailed ablation studies to understand the contribution of each component?', 'Can you verify the theoretical guarantees provided in the paper?', 'What is the impact of different modulation functions on performance?', 'How does the method perform with different types of aggregators?', 'Can the authors provide more details on the scalability of their method to very large datasets?', 'Could the authors clarify the mathematical formulations and proofs to improve readability?', 'Would the authors consider conducting more detailed ablation studies and comparisons with additional baseline methods?', 'How does the performance change with different choices of λ parameters in the objective function?', 'Can additional ablation studies be provided to isolate the impact of the triple-clique term and the balancing constraints separately?']","['The paper lacks a detailed discussion on the potential limitations of the proposed method, such as its applicability to other types of data beyond image classification and the impact of different network architectures.', 'The scalability of the method to very large datasets or more complex models is a potential limitation.', 'The dense presentation of mathematical formulations and proofs might hinder readability for some readers.', 'The paper lacks detailed ablation studies and broader comparisons with baseline methods.', 'The paper does not fully explore the impact of different hyperparameters on the performance.']",False,3,2,3,6,4,"['Addresses a practical and significant problem in deep learning.', 'Introduces a novel combination of submodular optimization with matroid constraints.', 'Demonstrates strong empirical performance on multiple datasets.', 'Provides theoretical guarantees for the proposed greedy algorithm.', 'The use of matroids for balancing constraints is a novel approach.', 'The triple-clique based diversity function is an interesting addition.', 'The experimental results show significant data savings without loss in performance.', ""Comprehensive experiments on multiple datasets, including long-tailed ones, demonstrating the method's effectiveness.""]","['The autoencoder aggregator is not clearly explained, impacting reproducibility.', 'Clarity of the mathematical formulation and some experimental settings could be improved.', 'Potential societal impacts and limitations of the method are not sufficiently discussed.', 'Some ablation studies and comparisons with more recent methods could strengthen the validation.', ""The method's complexity might limit its scalability to very large datasets or more complex models."", 'The presentation of the method, especially the mathematical formulations and proofs, is dense and might be difficult for some readers to follow.', 'The novelty is somewhat limited as it builds heavily on existing work in submodular optimization and active learning.']",3,3,2,3,Reject
EFSctTwY4xn,"The paper proposes an adaptive federated meta-learning (AFML) framework to address the challenge of non-IID data in personalized federated learning. The authors introduce an adaptive trade-off theorem to balance the optimality and adaptability of the global model, aiming to improve the quality of personalized models on individual devices. Extensive experiments on CIFAR-100 and Shakespeare datasets demonstrate the effectiveness of the proposed approach.","['How sensitive is the AFML framework to the choice of hyperparameters?', 'Can the authors provide more intuitive explanations or visualizations of the theoretical concepts, such as the adaptive trade-off theorem?', 'How does the AFML framework perform on other datasets or in different federated learning settings, such as those with more severe data heterogeneity?', 'Can the authors provide more details on the implementation of the adaptive trade-off theorem?', 'Have the authors considered comparative ablation studies to isolate the impact of individual components of AFML?']","['The authors should discuss potential limitations of their approach, such as computational overhead and scalability to larger datasets or more diverse non-IID scenarios.', 'The societal impact of federated learning, especially in terms of privacy and security, should be addressed.', 'The clarity of the paper needs improvement, particularly in the methodology and mathematical derivations sections.', 'The empirical validation should be more robust, with additional experiments to back up the theoretical claims.']",False,3,2,3,6,4,"['Addresses a significant problem in federated learning: handling non-IID data.', 'The proposed AFML framework is novel and aims to balance the optimality and adaptability of the global model.', 'Comprehensive experiments validate the effectiveness of the proposed approach, showing improvements over existing methods.']","['The theoretical parts of the paper, including the adaptive trade-off theorem, are complex and might be challenging for practitioners to fully grasp and implement.', 'Some sections, especially those involving the mathematical formulations, lack clarity and could benefit from more detailed explanations.', 'The experiments are limited to CIFAR-100 and Shakespeare datasets, which may not be representative of all possible non-IID scenarios in federated learning.', 'Lack of comparative ablation studies to isolate the impact of individual components of the proposed framework.', ""Over-reliance on theoretical assumptions without sufficient empirical backup. The theorem's practical implications need more thorough empirical validation.""]",3,3,2,4,Reject
5o7lEUYRvM,The paper introduces a function-space variational inference (fVI) approach for Bayesian deep learning classification models. It leverages Dirichlet predictive priors to enhance uncertainty quantification and adversarial robustness. The method is applicable to various BNN representations without altering the model architecture. Extensive experiments on image classification tasks demonstrate improved performance and robustness.,"['Can the authors provide more detailed ablation studies to validate the impact of different components, such as the Dirichlet MLE estimation?', 'How does the choice of Dirichlet prior parameters affect the performance of the proposed method?', 'Can the authors discuss potential strategies to mitigate the computational complexity of the Dirichlet MLE estimation?', 'Can you provide more details on the Dirichlet MLE approximation and its computational aspects?', 'How does your method compare against other state-of-the-art Bayesian methods with different priors?', 'Can the authors provide a more detailed mathematical formulation and derivation of the proposed Dirichlet KL estimator?', 'What are the computational requirements and potential bottlenecks of the proposed method, especially for large-scale datasets?', 'Can the authors provide more detailed comparisons and analysis of the performance improvements, particularly in the CIFAR experiments?', 'Can the authors provide more detailed explanations and derivations for some of the mathematical concepts introduced?', 'What are the implications of the performance difference between CIFAR10 and CIFAR100 under adversarial attacks?', 'Could the authors include more ablation studies on the choice of Dirichlet prior parameters and the impact on different neural network architectures?', 'Can you provide more intuitive explanations and visual aids for complex concepts like the variational implicit process and Dirichlet KL divergence estimation?', 'Have you considered additional ablation studies with different prior concentration parameters or other hyperparameters?', 'Can you include comparisons with a broader range of state-of-the-art methods and more real-world applications to demonstrate the impact of your approach?']","['The paper addresses the limitations and potential negative societal impacts adequately. However, the authors should consider discussing the computational complexity and potential trade-offs in more detail.', 'The paper should improve its clarity, particularly in the methodology and experimental setup. Additionally, a broader empirical comparison with state-of-the-art methods is necessary to justify the contributions.', 'The paper does not sufficiently address the computational feasibility and potential bottlenecks of the proposed method. Additionally, a detailed discussion on the limitations and failure cases is missing.', 'The clarity of mathematical derivations and explanations could be improved.', 'Performance under adversarial attacks in high-dimensional settings like CIFAR100 is not as strong.', 'A more detailed analysis of potential drawbacks and how they might be mitigated would be beneficial.']",False,3,3,3,5,4,"['Addresses an important issue in Bayesian deep learning: uncertainty quantification.', 'Proposes a novel function-space variational inference method leveraging Dirichlet predictive priors.', 'The approach is versatile and can be applied to various BNN architectures without modifying them.', 'Extensive experiments with different models and datasets validate the effectiveness of the approach.', 'Demonstrates significant improvements in uncertainty quantification and adversarial robustness.']","['Potential scaling issues with high label dimensionality affecting the performance.', 'The need for more detailed ablation studies to validate the impact of different components.', 'The computational complexity of the proposed method, especially with Dirichlet MLE estimation, might be high.', 'Limited discussion on the choice of Dirichlet prior parameters and their impact on performance.', 'Lacks clarity in several sections, particularly in methodology and experimental setup.', 'Empirical evaluation does not compare against a wide enough range of state-of-the-art methods.', 'The novelty is somewhat incremental, building on existing methods without a significant theoretical breakthrough.', 'Mathematical derivations and explanations could be clearer and more accessible.', 'Performance on CIFAR100 under adversarial attacks is not as strong as on CIFAR10.']",3,3,3,4,Reject
i2baoZMYZ3,"The paper 'Continuous Control with Action Quantization from Demonstrations' (AQuaDem) presents a novel method for discretizing continuous action spaces in reinforcement learning using human demonstrations. This approach aims to simplify the exploration problem by creating a finite set of plausible actions from demonstrations, enabling the use of discrete-action deep RL algorithms. The method is evaluated in three setups: RL with demonstrations, RL with play data, and Imitation Learning, showing significant performance improvements.","['Can you provide detailed ablation studies to understand the contribution of each component?', 'Could you clarify the details of the autoencoder aggregator?', 'Can the authors provide additional ablation studies to explore the effect of varying the number of candidate actions and comparing different discretization methods?', 'Could the authors discuss the sensitivity of the method to hyperparameters, particularly the temperature parameter in the loss function?', 'What are the broader implications and potential limitations of the method in other types of RL problems or environments?', 'Can more detailed explanations and visualizations be provided to support the claims made in the paper?', 'How does the proposed method scale for environments with higher-dimensional action spaces?', 'Can you provide more details on the neural network architecture and training procedure?']","['The main limitation is the lack of detailed ablation studies to understand the contribution of each component.', 'The paper could benefit from a clearer presentation of the autoencoder aggregator.', 'Potential negative societal impacts are not discussed, which is important for methods involving human data.', ""The method's scalability for higher-dimensional action spaces is not fully explored.""]",False,3,3,3,6,4,"['Addresses the curse of dimensionality in continuous action spaces using a novel approach.', 'Comprehensive experiments demonstrate significant performance improvements and sample efficiency.', 'Handles multimodal demonstrations effectively, which is a common scenario in human data.', 'Clear and well-organized presentation of the methodology, experiments, and results.']","['Lack of detailed ablation studies to understand the contribution of each component.', 'Some aspects of the presentation could be clearer, particularly the details of the autoencoder aggregator.', 'The sensitivity of the method to hyperparameters, particularly the temperature parameter in the loss function, could be discussed more deeply.', 'More detailed explanations and visualizations required to support the claims.']",3,3,3,4,Accept
hjlXybdILM3,"The paper introduces SimpleBits, a method to simplify inputs by minimizing their encoding bit size using a pre-trained generative model. This simplification process retains task-relevant information and aids in neural network understanding. The method is evaluated in three scenarios: per-instance simplification during training, dataset condensation, and post-training simplification. The proposed method shows promise in removing superfluous information, retaining task performance with condensed datasets, and providing insights into misclassification reasons.","['Could the authors provide more details on the optimization process and network architectures used?', 'How does SimpleBits compare with other input simplification or interpretability methods?', 'Can the authors evaluate SimpleBits on additional datasets to strengthen their claims?', 'Can the authors provide more details on the computational cost of the proposed method?', 'What are the potential negative impacts or limitations of the SimpleBits method?', 'Have you considered additional baselines or ablation studies to further validate the effectiveness of SimpleBits?']","['The main limitations are the clarity of the methodology section and the need for broader evaluation on more diverse datasets.', 'The computational cost and complexity of the method are not discussed, which could be a significant limitation.']",False,3,3,3,5,4,"['The paper addresses a relevant problem in machine learning: understanding neural network behavior through input simplification.', 'The proposed approach, SimpleBits, is novel and leverages generative models in a unique way to simplify inputs.', 'Comprehensive experiments are conducted, including qualitative and quantitative analysis, across multiple settings.']","['The methodology section, particularly the optimization details and network architectures, could be more clearly explained.', 'Additional baselines and ablation studies are needed to further validate the claims made in the paper.', 'The evaluation is conducted on a limited set of datasets; broader validation on more diverse datasets could strengthen the claims.', 'The computational cost and complexity of the method are not discussed, which could be a significant limitation.']",3,3,3,4,Reject
pWBNOgdeURp,The paper introduces a novel approach to pruning deep neural networks using Koopman operator theory. It proposes new pruning algorithms that unify magnitude and gradient pruning methods under a Koopman framework. The authors provide theoretical justifications and preliminary experimental results to support their claims.,"['Can the authors provide more comprehensive experimental results to validate the effectiveness of Koopman-based pruning compared to existing methods?', 'How does the computational complexity of Koopman-based pruning compare to traditional pruning methods?', 'Could the authors elaborate on the practical implementation details of Koopman mode decomposition in the context of large-scale neural networks?', 'How does the proposed method compare with other state-of-the-art pruning techniques not discussed in this paper?', 'Can the authors simplify and provide more intuitive explanations of some of the theoretical concepts for better understanding?', 'How does the proposed method perform on state-of-the-art architectures like BERT or GPT-3, which have significantly more parameters than ResNet-20?']","['The paper does not adequately address the scalability of the proposed methods to larger neural networks.', 'The empirical results are not sufficient to demonstrate the practical significance of the proposed methods.', 'The potential negative societal impacts are not discussed, although they are not immediately apparent in the context of this work.']",False,2,2,2,4,4,"['The paper introduces a novel application of Koopman operator theory to neural network pruning.', 'The theoretical framework provides a new perspective on the relationship between different pruning methods.', 'The authors provide a detailed explanation of the Koopman mode decomposition and its relevance to pruning.']","['The experimental validation is limited to simple architectures and datasets (MnistNet on MNIST and ResNet-20 on CIFAR-10). More extensive experiments on diverse architectures and datasets are needed.', 'The paper is densely written and may be difficult to follow for readers not well-versed in dynamical systems theory.', 'Important practical details about the implementation of the proposed methods are not adequately discussed in the main text.', 'The significance of the proposed methods in practical scenarios is not convincingly demonstrated.', 'Comparisons with state-of-the-art pruning methods are not comprehensive enough. More detailed comparisons, including recent sophisticated methods, are necessary.', 'The computational complexity and scalability of the proposed methods are not thoroughly addressed.']",3,2,2,3,Reject
iLHOIDsPv1P,"The paper introduces the PAC-Bayes Information Bottleneck (PIB) framework to explore the generalization capabilities of neural networks through the information stored in weights (IIW). It provides a theoretical foundation using PAC-Bayes bounds and proposes an efficient approximation method for IIW. The empirical results demonstrate the universality of the IIW measure across different activation functions, architectures, and noise levels.","['Can the authors provide more robust validation for the approximations used, particularly the FIM and influence functions?', 'What is the computational overhead introduced by the proposed method in comparison to standard training methods?', 'Can the practical scalability of the method be demonstrated in larger real-world datasets?', 'Could the authors provide more intuitive explanations and clearer derivations to improve the accessibility of the theoretical content?']","['The approximations used for the FIM and influence functions might not be robust enough. More empirical validation and discussion are needed.', 'The paper could benefit from more intuitive explanations and clearer derivations to improve accessibility.']",False,3,2,3,6,4,"['Theoretical novelty in combining PAC-Bayes bounds with Information Bottleneck.', 'Comprehensive empirical validation across various settings (activation functions, architectures, noise levels, etc.).', 'The method provides a new perspective on the generalization problem in neural networks.']","['The paper is densely packed with theoretical content, making it less accessible to practitioners.', 'The robustness of the approximations, especially the Fisher Information Matrix (FIM) and influence functions, needs further validation.', 'The practical implications and scalability of the method in real-world applications require more exploration.', 'Potential computational overhead introduced by the proposed method is not thoroughly discussed.']",3,3,2,3,Reject
0q0REJNgtg,"The paper proposes a novel Retrieval-Augmented Reinforcement Learning (R2A) framework that augments traditional RL agents with a retrieval process to leverage past experiences more effectively. This approach aims to improve sample efficiency, task-specific performance, and mitigate the limitations of parametric models in RL. The paper presents extensive experiments on Atari games, a multi-task offline RL environment, and the BabyAI environment to validate the proposed method.","['Could you provide more details on the computational complexity and runtime of the R2A method compared to traditional RL methods?', 'How does the retrieval process scale with the size of the retrieval dataset?', 'Can the proposed method be generalized to other types of environments or tasks beyond those presented in the experiments?', 'How does the retrieval process handle situations where the relevant past experiences are not present in the dataset? Is there a fallback mechanism?', 'Can you provide additional ablation studies to better understand the impact of different components and hyperparameters of the retrieval process?', 'How do you address potential ethical concerns or limitations of the proposed method, particularly in terms of data privacy and the potential for biased retrievals?']","['The paper addresses some limitations but does not sufficiently discuss the potential negative societal impacts or ethical considerations of implementing such a complex RL framework.', 'The method introduces additional computational complexity, which needs to be justified with clearer runtime analysis.', 'Parameter tuning and sensitivity analysis are not thoroughly discussed, which could be important for practical applications.']",False,3,3,3,5,4,"['The introduction of a retrieval process to augment RL agents is novel and addresses significant limitations in traditional RL methods.', 'The paper provides extensive experimental results, including evaluations on Atari games, a grid-world robotic manipulation environment, and BabyAI, demonstrating the effectiveness of the proposed method.', 'The ablation studies are thorough and provide insights into the contributions of different components of the R2A framework.']","['The paper is complex and might be difficult to follow for readers not deeply familiar with RL and the specific architectures used.', 'The computational complexity of the proposed method is high, which might limit its practical applicability.', 'The generalizability of the method to other types of environments or tasks is not thoroughly explored.', 'The paper could benefit from clearer explanations of some technical details, particularly the retrieval process and its integration with the agent process.', 'The novelty of some components, such as the use of attention mechanisms and slot-based memory, may be questioned as they have been explored in other contexts.', 'The paper lacks a thorough discussion of potential limitations and negative societal impacts of the proposed method.']",3,3,3,4,Reject
kQ2SOflIOVC,The paper proposes a novel approach to few-shot learning in histology images by combining contrastive learning (CL) and latent augmentation (LA). The proposed method aims to improve generalization and label efficiency by leveraging unsupervised learning techniques. The authors conduct extensive experiments on three histology datasets to demonstrate the effectiveness of their approach.,"['Can the authors provide more details on the choice of clustering methods and the specific settings for latent augmentation?', 'How do the results generalize to other domains beyond histology images?', 'Can the authors clarify the impact of different data augmentation techniques on the performance of the proposed method?', 'Please provide more details about the autoencoder aggregator.', 'Can you conduct additional ablation studies on the modulation function?', 'Could you provide more qualitative visualizations and examples?', 'What are the potential limitations and failure cases of the proposed methods?', 'How does the choice of hyperparameters affect the performance of the proposed method?', 'Can you provide more empirical evidence to support the observed generalization gap between contrastive learning and supervised models?']","['The paper primarily focuses on histology images, and it is unclear how the proposed method would perform on other types of images.', 'The densely written methodology section may be difficult to follow for some readers.', 'The paper could benefit from more clarity in certain sections and additional ablation studies.', 'More discussion on potential negative societal impacts and ethical considerations is needed, especially in medical applications.', 'The generalization gap between CL and supervised models is observed empirically without strong theoretical backing.']",False,3,3,3,6,4,"['The combination of contrastive learning and latent augmentation is novel and addresses a relevant problem in histology image analysis.', 'Extensive experiments are conducted on multiple datasets to validate the proposed method.', 'The paper provides a comprehensive analysis of the results and includes several ablation studies to support the effectiveness of the proposed method.', 'The problem tackled is significant and underexplored in the context of histology images.', 'The paper provides a new dataset and benchmarks for the community.']","['The paper is densely written and may be difficult to follow for readers who are not familiar with the specific methodologies used.', 'Some experimental details and choices need further justification, such as the specific settings for latent augmentation and the choice of clustering methods.', 'The generalization of the results to other domains beyond histology images is not clearly demonstrated.', 'Additional ablation studies and clarifications could further strengthen the paper.', 'More qualitative visualizations and examples could enhance the understanding of the results.', 'The empirical explanations for the observed generalization gap between CL and supervised models need further validation.', 'Inadequate comparison with related work, which could affect the novelty claim.']",3,3,3,4,Reject
gCmCiclZV6Q,"The paper proposes using pre-trained language-vision models like CLIP to automate the curation of large-scale vision datasets by identifying offensive content. The method leverages the implicit knowledge of these models to detect various types of offensive images, including those depicting violence, pornography, and derogatory symbols. The approach is demonstrated on the ImageNet-ILSVRC-2012 dataset.","['How do the authors plan to mitigate the biases inherent in the pre-trained models used for detecting offensive content?', 'Can the authors provide more details on the process of prompt-tuning and the criteria for choosing specific prompts?', 'What are the limitations of the proposed method in terms of false positives and false negatives in detecting offensive content?', 'How does your approach generalize across different cultural contexts and social norms?', 'Have you evaluated your approach on datasets other than ImageNet? If so, can you share the results?', 'Can the authors provide more details on the prompt-tuning process and how the optimal prompts were selected?', 'Can the authors discuss any observed biases in the pre-trained models and how they plan to mitigate them?', 'What measures are in place to handle false positives and false negatives generated by the model?', 'Can the authors provide more examples of offensive content detected by the model that were missed by previous methods?']","['The reliance on pre-trained models that may carry their own biases is a significant limitation. Additionally, the paper does not provide a comprehensive strategy for mitigating these biases.', 'The method may produce false positives and false negatives, which could limit its practical applicability in a real-world setting.', 'The approach may not generalize well across different cultures or social norms.', ""The potential biases in the pre-trained model and the subjectivity of what constitutes 'offensive' content are significant limitations that should be addressed in the paper."", 'The reliance on a specific dataset (SMID) for tuning the pre-trained model may limit the generalizability of the approach.']",True,3,3,3,5,4,"['Addresses a crucial and timely issue related to ethical concerns in large-scale vision datasets.', 'Utilizes state-of-the-art pre-trained models to automate a process that is typically tedious and error-prone.', 'Provides comprehensive experiments and qualitative analyses demonstrating the effectiveness of the proposed method.']","['The approach relies on pre-trained models that may themselves be biased, and the paper does not provide a robust methodology for addressing these biases.', 'The novelty is somewhat limited as it primarily applies existing models (CLIP) to a new task rather than introducing fundamentally new techniques.', 'Certain methodological details, such as the process of prompt-tuning and choice of specific prompts, are not thoroughly explained.', 'The method may not generalize well across different cultures or social norms.', 'The evaluation could benefit from additional metrics to better understand the trade-offs between precision and recall.', 'The paper lacks a detailed evaluation of the ethical implications of using pre-trained models for such a sensitive task.']",3,3,3,3,Reject
xS8AMYiEav3,"The paper proposes REASSURE, a novel methodology for repairing neural networks with ReLU activation functions. The approach leverages the continuous piecewise linear (CPWL) nature of ReLU networks to construct localized patch networks that correct buggy inputs while preserving the overall functionality of the network. The paper provides theoretical guarantees of soundness, completeness, minimality, and locality, and demonstrates the effectiveness of the approach through empirical evaluations.","['Can the authors provide more details on the construction and optimization of the patch networks, especially the LP formulation?', 'What are the specific implementation details of the support networks?', 'Can the empirical evaluation be extended to include more benchmarks and comparisons to other methods, particularly on more complex datasets?', 'How does the proposed method scale to very large networks and high-dimensional inputs? Can the authors provide additional experiments and discussions on this aspect?']","['The methodology may require further validation on a wider range of benchmarks and in different application domains.', 'The paper could benefit from more detailed explanations of certain aspects to improve clarity.', 'The approach is currently limited to ReLU-based networks, which may restrict its applicability.', 'Scalability concerns due to the complexity and additional parameters introduced by the patch network need to be addressed.']",False,3,3,3,6,4,"['Novel approach leveraging the CPWL nature of ReLU networks for localized repairs.', 'Strong theoretical guarantees of soundness, completeness, minimality, and locality.', 'Comprehensive experiments demonstrating the effectiveness of the proposed methodology.', 'Addresses a critical issue in neural network deployment, particularly in safety-critical applications.']","['Some aspects of the methodology, such as the construction and optimization of patch networks, could be explained in more detail, particularly the LP formulation and its computational complexity.', 'The empirical evaluation could be more comprehensive with additional benchmarks and comparisons to a broader range of existing methods, including more complex datasets.', 'Implementation details of the support networks are not thoroughly explained, which could hinder reproducibility.', 'The scalability of the proposed method to very large networks and high-dimensional inputs is not fully explored, raising concerns about its practical applicability.']",3,3,2,4,Accept
OqHtVOo-zy,The paper proposes a method to estimate the instance-dependent Bayes label transition matrix using deep neural networks. This matrix helps in building a statistically consistent classifier that can handle label noise effectively by leveraging the transition from Bayes optimal labels to noisy labels.,"['Can you provide more details on the theoretical guarantees and assumptions behind the collection of distilled examples?', 'How does the proposed method compare to existing state-of-the-art methods in terms of computational efficiency and scalability?', 'Could you clarify the hyperparameter settings and implementation details to ensure reproducibility?', 'Can the authors provide more details about the architecture of the autoencoder aggregator used in the methodology?', 'Please clarify the process and rationale behind the choice of distillation threshold.', 'Can the authors conduct additional ablation studies to explore the impact of different aggregators and modulation functions?', 'Can the authors provide a more detailed theoretical explanation of why Bayes optimal labels have less uncertainty and how this simplifies the transition matrix estimation?', 'How does the proposed method perform under different types of noise, such as symmetric and asymmetric noise?', 'Can the authors include more ablation studies to demonstrate the contributions of different components of their method?', 'Can the authors provide more detailed analysis on the potential biases introduced by the distilled examples?', 'How does the proposed method compare with more recent methods dealing with instance-dependent noise?', 'Can the authors provide additional ablation studies to understand the contribution of each component of the proposed method?', 'Can the authors provide more details on the methodological approach, specifically the design of the Bayes label transition network?', 'What are the potential limitations and negative societal impacts of the proposed method?']","['The main limitation is the lack of a thorough discussion on the theoretical guarantees and assumptions behind the distilled examples, as well as the clarity of the methodology.', 'The paper needs to address concerns about the clarity of the methodology and provide additional ablation studies to substantiate the claimed benefits.', 'The paper does not adequately address the potential limitations of the proposed method, such as its dependency on the quality of the distilled dataset and the potential bias introduced by the distillation process.', ""The main limitation is the potential biases introduced by the distilled examples, which could affect the robustness of the Bayes label transition matrix estimation. Additionally, the method's applicability to different types of label noise and its scalability need further exploration."", 'The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the proposed method. This should be addressed in future revisions.']",False,2,2,2,4,4,"['Addresses a relevant and challenging problem in the field of machine learning.', 'The approach of using Bayes optimal labels to reduce the uncertainty in the transition matrix is novel.', 'Provides extensive experimental results on both synthetic and real-world datasets, demonstrating the effectiveness of the proposed method.']","['Explanation of the methodology could benefit from more clarity, particularly the collection of distilled examples and the training process of the transition network.', 'The theoretical guarantees and assumptions behind the distilled examples are not thoroughly discussed.', 'Lacks details on the implementation and hyperparameter settings, which are crucial for reproducibility.', 'Comparison with state-of-the-art methods is not comprehensive enough, particularly in terms of how the proposed method integrates with or improves upon existing approaches.', 'Important details about the autoencoder aggregator and the overall architecture are missing.', ""The method's novelty is somewhat limited, as it builds on existing concepts of transition matrices and does not introduce fundamentally new techniques."", 'Theoretical foundation of estimating the Bayes label transition matrix is not well-explained. Key assumptions and the rationale behind them are missing.', ""The method's robustness to different types of noise and its generalizability to other datasets are not well-demonstrated."", 'Potential biases in the collected distilled examples are not thoroughly analyzed.', 'Some mathematical formulations and explanations lack clarity.', 'Limited discussion on limitations and societal impacts.']",3,2,2,3,Reject
oTQNAU_g_AZ,"The paper proposes DAIR, a novel method for bimanual robot manipulation tasks that introduces a disentangled attention mechanism as intrinsic regularization. This method aims to address two fundamental issues: domination, where one robot performs most of the tasks while the other remains idle, and conflict, where robots interfere with each other’s workspace. The paper evaluates DAIR on five diverse bimanual manipulation tasks and demonstrates that it improves performance, sample efficiency, and safety by reducing conflicts and domination.","['Can the authors provide more details on the disentangled attention mechanism and the intrinsic regularization loss function?', 'How does the choice of the hyperparameter λ impact the performance across different tasks?', 'Can the authors justify the choice of baselines and provide more details on the specific configurations of the environments?', 'Can the authors provide a deeper theoretical analysis of why DAIR works?', 'Can the authors perform more extensive ablation studies to explore the sensitivity of the algorithm to various hyperparameters and architectural choices?', 'Could you clarify the network architecture and the specific role of state encoder functions in the policy and Q-function networks?', 'How robust is the proposed method to variations in hyperparameters, particularly the regularization coefficient λ?', 'Have you considered extending the proposed method to scenarios with more than two robots or more complex interactions?', 'Can the authors provide more detailed ablation studies on alternative regularization methods?', 'Can the authors clarify the implementation details and the specific contributions of each architectural component?', 'Can the authors provide more details on the implementation of the autoencoder aggregator?', 'Can the authors provide additional visualizations to strengthen the qualitative analysis?']","['The paper lacks detailed analysis of the impact of the hyperparameter λ on different tasks. Additionally, more ablation studies could strengthen the claims regarding the effectiveness of the proposed method.', 'The clarity of the explanation of the disentangled attention mechanism and the intrinsic regularization loss function needs improvement.', ""The primary limitation is the lack of theoretical insights into the working of DAIR. Additionally, more extensive ablation studies are needed to explore the algorithm's sensitivity to different settings."", 'Another limitation is the focus on tasks with only two robots. Extending the method to handle more robots or more complex interactions could be a valuable future direction.', 'The paper does not provide detailed ablation studies on alternative regularization methods, which could strengthen the validation of the proposed method.', 'There are some clarity issues regarding the implementation details and the specific contributions of each architectural component.']",False,3,2,3,5,4,"['Addresses important issues of domination and conflict in bimanual robot manipulation tasks, which are often overlooked.', 'Introduces a novel disentangled attention mechanism that provides intrinsic regularization for robots to focus on different sub-tasks.', 'Comprehensive experimental evaluation on five diverse bimanual manipulation tasks, showing significant improvements in performance and safety.', 'Detailed analysis and visualizations of the attention mechanism, providing insights into the behavior of the robots.']","['The method’s clarity can be improved, especially in the explanation of the disentangled attention mechanism and the intrinsic regularization loss function.', 'The hyperparameter λ used for balancing the regularization term is fixed, and its impact on different tasks is not thoroughly analyzed.', 'The experimental setup, including the choice of baselines and the specific configurations of the environments, needs more detailed justification and explanation.', 'While the results are promising, more ablation studies could strengthen the claims. For example, varying the number of interaction regions or exploring different attention mechanisms.', 'The paper lacks a deeper theoretical analysis of why DAIR works, relying mostly on empirical results.', 'The explanation of the network architecture and the state encoder functions is somewhat unclear and could benefit from more detailed descriptions.', 'The impact of the proposed method on tasks with more than two robots or more complex interactions is not explored.']",3,3,3,3,Reject
KSSfF5lMIAg,The paper proposes model-agnostic interpretability methods for Multiple Instance Learning (MIL). It aims to identify key instances within a bag and determine which class each key instance supports or refutes. The proposed methods are evaluated on several datasets and compared against existing inherently interpretable MIL models.,"['Can the authors provide more detailed discussions on potential failure cases and limitations of their methods?', 'How do the proposed methods perform on larger and more complex datasets not covered in the experiments?', 'Can the authors provide more detailed explanations and possibly diagrams for the autoencoder aggregator and the MILLI method?', 'Could additional ablations be conducted to investigate the effect of different modulation functions and aggregators?', 'Can the authors provide more visual examples of interpretability outputs to strengthen their qualitative analysis?']","['The authors should address potential failure cases and limitations more thoroughly.', 'The incremental nature of the contributions limits the overall impact.', 'The main limitations are the clarity regarding certain methodological components and the absence of some ablation studies.', 'The computational expense of the proposed methods is a concern, especially for large datasets.']",False,2,2,2,4,4,"['Addresses a significant problem in MIL, focusing on the interpretability of models.', 'The proposed model-agnostic interpretability methods are novel and can be applied to any MIL model.', 'Comprehensive experiments are provided, including comparisons with existing methods and evaluations on multiple datasets.']","['The novelty of the methods seems incremental, building on existing interpretability techniques.', 'The technical robustness of the methods is not entirely convincing, with limited discussion on potential failure cases and limitations.', 'Some sections, especially the methodology, require more clarity and simplification.', 'The paper lacks some ablation studies that could further validate the effectiveness of the proposed method components.', ""More visual examples and qualitative analyses would strengthen the paper's claims, particularly in the interpretability outputs.""]",3,2,2,3,Reject
on54StZqGQ_,"The paper introduces degradation attacks on certifiably robust neural networks, demonstrating that such attacks can force these networks to reject non-adversarial inputs, thus degrading their utility. The paper empirically shows the efficacy of these attacks on state-of-the-art defenses such as GloRo Nets and randomized smoothing. It also discusses potential defenses, including training with a doubled robustness radius and considering the input manifold.","['Can the authors provide more detailed pseudo-code or algorithmic descriptions for the proposed degradation attacks?', 'How do the proposed defenses, particularly the M-membership oracle, perform in practical settings? Are there any preliminary results or theoretical justifications for their effectiveness?', 'Can the authors provide more comprehensive empirical validation across different datasets and model architectures?', 'Can the methodology and experimental setup be explained in more detail for better clarity?', 'What are the theoretical conditions under which degradation attacks succeed? Can the authors provide a more rigorous analysis?']","['The reliance on an M-membership oracle for one of the proposed defenses may not be practical or feasible in many real-world scenarios.', 'The paper could benefit from more comprehensive empirical validation.', 'The clarity of the methodology and experimental setup needs improvement.', 'The defensive strategies proposed are relatively straightforward and may not fully address the issue.']",False,3,2,2,5,4,"['Addresses a critical gap in the robustness of neural networks by identifying a novel type of attack.', ""Provides a thorough empirical evaluation demonstrating the attack's effectiveness on advanced models like GloRo Nets and Randomized Smoothing."", 'The concept of degradation attacks is novel and highlights a critical vulnerability in certifiably robust models.']","['The novelty of the degradation attacks is somewhat incremental, as it builds on existing adversarial attack methodologies.', 'The proposed defenses, especially the one involving an M-membership oracle, are not fully developed or evaluated, leaving some open questions about their practical implementation and efficiency.', 'Some parts of the paper, particularly the explanation of the degradation attack algorithms, could benefit from clearer and more detailed descriptions.', 'The empirical validation could be more comprehensive, covering a wider range of datasets and model architectures.', 'There is a lack of theoretical analysis to support the empirical findings.']",3,3,3,3,Reject
R3zqNwzAVsC,The paper introduces a post-processing method called the Ethical Module to mitigate gender bias in pre-trained face recognition models. The method uses a shallow neural network trained with a von Mises-Fisher loss to adjust the embeddings of a pre-trained model. The paper also introduces new fairness metrics (BFRR and BFAR) and evaluates the methodology on standard face recognition datasets.,"['Can you provide more justification for the chosen fairness metrics BFRR and BFAR? How do they compare to standard metrics in the literature?', 'How does the von Mises-Fisher loss compare to other loss functions commonly used in bias mitigation?', 'What are the potential biases introduced by the gender classifier used for labeling the dataset? How might this affect the results?', 'Can you provide more details on the reproducibility of your experiments, including specific hyperparameter settings and code availability?', 'Could the authors provide more details on the implementation of the Ethical Module, particularly the configurations of the shallow MLP?', 'How does the method perform on other types of biases (e.g., racial bias)?', 'Can the authors include more ablation studies to show the impact of different design choices in the Ethical Module?', 'How does the proposed method compare with a broader set of baselines in terms of both fairness and performance?', 'Can the authors provide more details on the hyperparameter tuning process and the specific configurations of the Ethical Module?', 'How robust are the results to potential biases introduced by the private gender classifier used for ground-truth labels?']","['The potential biases introduced by the gender classifier need to be discussed in more detail.', 'The choice of fairness metrics is non-standard and may require further validation.', 'The focus on gender bias is a limitation, and the broader implications should be discussed in more depth.', 'The potential negative societal impacts of the Ethical Module, such as unintended biases introduced during training, should be addressed.', ""The method's generalizability to other types of biases and broader applications is not fully explored.""]",False,2,2,2,4,4,"['Addresses a critical and relevant problem of bias in face recognition models.', 'Proposes a novel and interpretable method using the von Mises-Fisher loss.', 'Emphasizes computational efficiency and stability, making it practical for real-world applications.', 'Includes extensive experiments on standard datasets to validate the approach.']","['The choice of fairness metrics, while explained, could be better justified. The metrics BFRR and BFAR are not standard and may require further validation.', 'The interpretability and effectiveness of the von Mises-Fisher loss in this context are not thoroughly explored. It would be beneficial to compare it with other existing methods in more detail.', 'The method relies on gender labels obtained from a private classifier, which could introduce additional biases. The paper should discuss this potential limitation more explicitly.', 'The reproducibility of the experiments is promised but not guaranteed. The paper should provide more details on the implementation and hyperparameter settings.', 'The novelty of applying the von Mises-Fisher loss in this specific context is not clearly established.', 'The robustness of the method across different types of biases (beyond gender) and its generalizability to other tasks are not sufficiently demonstrated.', 'Some sections, particularly the implementation details and experimental setup, could be written more clearly for better reproducibility.', 'The paper could benefit from additional ablation studies to explore the impact of different design choices in the Ethical Module.']",3,2,2,3,Reject
BGvt0ghNgA,"The paper proposes a novel method called Lipschitz-constrained Skill Discovery (LSD) for unsupervised skill discovery in reinforcement learning. LSD aims to learn diverse and dynamic skills by maximizing a Lipschitz-constrained objective, leading to larger traveled distances in state space. The method also enables zero-shot goal-following tasks using the learned state representation. The paper demonstrates LSD's effectiveness through extensive experiments on various MuJoCo environments, showing improvements in skill diversity, state space coverage, and performance on downstream tasks compared to existing methods.","['Can the authors provide more details about the implementation of the autoencoder aggregator?', 'What is the performance of the proposed model with different modulation functions and aggregators?', 'Can the authors provide a clearer explanation of the Lipschitz constraint and its implementation in the proposed method?', 'How does the proposed method compare with other regularization techniques that could address the same limitation?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide a more rigorous theoretical justification for the proposed method?', 'How does the proposed method perform in a broader range of tasks beyond the specific MuJoCo environments tested?', 'Can the authors clarify the implementation details of the autoencoder aggregator and other key components to ensure reproducibility?', 'Can you provide additional empirical evidence supporting the effectiveness of the Lipschitz constraint in other environments or settings?', 'Could you clarify the mathematical formulation and provide more step-by-step derivations to enhance understanding?', 'Can the authors provide more details on the derivation of the LSD objective, particularly the decomposition in Equation (5)?', 'What is the impact of different types of aggregation methods and modulation functions on the performance of the proposed method?', 'Can the authors provide more visualizations and examples of the discovered skills to better illustrate their behavior?', 'Can the authors discuss in more detail the potential limitations and scenarios where the Lipschitz constraint might not be effective?']","['The paper could benefit from additional ablation studies to explore the impact of different choices in the implementation.', 'The clarity of the paper can be improved, particularly in explaining key components and providing more qualitative examples.', 'The potential limitations and negative societal impacts of the proposed method are not adequately discussed. The authors should consider including a discussion on these aspects to provide a more balanced view of the proposed method.', 'The clarity and reproducibility of the paper are hampered by insufficient explanation of key components and implementation details.', 'The paper briefly mentions that the Lipschitz constraint might not be effective in environments where it is not semantically meaningful, such as control from pixel observations. More discussion on this limitation and potential solutions would be valuable.']",False,3,3,3,5,4,"['The proposed Lipschitz-constrained objective is novel and addresses the limitations of existing MI-based skill discovery methods.', 'LSD discovers more dynamic and diverse skills without the need for manual feature engineering.', 'The learned state representation function enables zero-shot goal-following tasks, which is a significant advantage.', 'Comprehensive experimental results on various MuJoCo environments demonstrate the effectiveness of LSD.']","['The paper lacks clarity in explaining certain aspects, such as the detailed implementation of the autoencoder aggregator.', 'Additional ablation studies could enhance the quality of the paper, particularly in exploring different modulation functions and aggregators.', 'The qualitative analysis could be improved by providing more cases to support the claims.', 'The theoretical justification for the proposed method is weak, and the paper lacks a rigorous theoretical analysis to support its claims.', 'The impact and significance of the proposed method are not convincingly demonstrated, with limited evidence of its applicability to a broader range of tasks.', 'The paper does not sufficiently address potential negative societal impacts and ethical considerations, which are important for autonomous systems research.']",3,3,3,3,Reject
1XdUvpaTNlM,"The paper proposes Batch Whitening Channel Pruning (BWCP), a probabilistic channel pruning method for CNNs that uses batch whitening to stochastically discard unimportant channels. The method aims to maintain the network's learning capacity while exploring a larger network space. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate the effectiveness of BWCP compared to existing methods.","['Can the authors provide more clarity on the batch whitening process and how it specifically enhances the pruning process?', 'How does BWCP compare with other recent probabilistic pruning methods in more detail?', 'Can the authors provide more detailed empirical validation, including comparisons with more recent state-of-the-art methods?', 'Can the authors clarify the practical implementation details and computational overhead during training?', 'Can you provide more details on the autoencoder aggregator and clarify its role in the method?', 'What is the performance of the proposed model when changing the type of aggregators?', 'Can you conduct additional ablation studies on the modulation function?']","['The paper does not sufficiently address the potential limitations of the proposed method, such as its scalability to larger networks or its impact on different types of tasks.', 'The societal impacts of using such a pruning method, especially in critical applications, are not discussed.', 'The method requires setting regularization parameters to achieve different levels of pruning, which can be a drawback in practical applications.', 'The potential impact of the proposed method on different classes and fairness is not discussed.']",False,2,2,2,3,4,"['The idea of using batch whitening for channel pruning is novel and interesting.', 'The method allows for stochastic pruning, which maintains the learning capacity of CNNs during training.', 'Extensive experiments on multiple datasets (CIFAR-10, CIFAR-100, ImageNet) with various architectures demonstrate the potential of BWCP.']","['The paper lacks clarity in explaining the theoretical underpinnings and methodology, making it challenging to reproduce the results.', 'The originality of the method is questionable as it builds on existing probabilistic pruning techniques without a significant leap.', 'The empirical validation is insufficient. The results provided do not convincingly demonstrate the superiority of the proposed method over existing methods.', 'The method introduces additional complexity in training, which might limit its practical applicability.', 'Potential limitations and ethical concerns, such as the fairness of pruning across different classes, are not adequately addressed.']",2,2,2,2,Reject
cpstx0xuvRY,"The paper provides an information-theoretic analysis of the generalization error for iterative semi-supervised learning (SSL) algorithms. By focusing on a binary Gaussian mixture model (bGMM), the authors derive theoretical bounds on the generalization error and validate them through experiments on MNIST and CIFAR datasets. The results suggest that the generalization error decreases with more pseudo-labelling iterations but eventually saturates.","['Could you provide more detailed explanations and intuition behind the key theoretical results?', 'Can you include more comprehensive ablation studies to understand the impact of different components of your theoretical framework?', 'What are the practical implications of your theoretical bounds? Are there any limitations or scenarios where they might not hold?', 'How does the proposed method perform on other datasets beyond MNIST and CIFAR?', 'Can you discuss the potential limitations and societal impacts of your work, specifically in terms of biases introduced by pseudo-labeling?']","['The paper should better address the practical implications and limitations of the theoretical bounds derived.', 'More detailed ablation studies are needed to understand the impact of different components and assumptions.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed method.', 'A more thorough discussion would be beneficial for understanding the broader implications of the work.']",False,3,2,3,4,4,"['The paper tackles an important and practical problem in semi-supervised learning.', 'It provides a novel theoretical framework to analyze the generalization error using information-theoretic principles.', 'The theoretical findings are supported by empirical results on benchmark datasets.']","['The clarity of the mathematical derivations and theoretical explanations could be improved.', 'The paper lacks comprehensive ablation studies to understand the impact of various components and assumptions.', 'There is insufficient discussion on the practical implications and limitations of the theoretical bounds.', 'The empirical validation could be more robust, including more datasets and varied experimental settings.', 'Potential limitations and societal impacts are not adequately discussed.']",3,3,2,3,Reject
Wm3EA5OlHsG,The paper presents a novel transformer-based architecture called Scene Transformer for predicting the trajectories of multiple agents in autonomous driving scenarios. The model uses a scene-centric approach and employs a masking strategy inspired by language models to handle various motion prediction tasks. The proposed approach achieves state-of-the-art performance on the Argoverse and Waymo Open Motion datasets.,"['Can the authors provide more ablation studies on the choice of transformer configurations and the impact of different masking strategies?', 'What are the potential ethical considerations and societal impacts of deploying the proposed model in real-world autonomous driving scenarios?', 'Can the authors provide more detailed ablation studies to validate the impact of the factored attention mechanism and other design choices?', 'Can the authors clarify the implementation details of the masked sequence modeling approach and its advantages over traditional methods?', ""Can the authors provide more qualitative examples to illustrate the model's performance in different scenarios?""]","['The paper could improve by including more ablation studies on various aspects of the model.', 'The ethical considerations of deploying such models in real-world scenarios should be discussed in more detail.', 'The paper could be more transparent about the potential limitations of the proposed approach, such as its computational complexity and scalability to larger datasets or more complex scenarios.']",False,3,3,3,6,4,"['The paper addresses a significant challenge in autonomous driving by proposing a unified architecture for joint and marginal motion prediction.', 'The use of a transformer-based architecture is innovative and leverages recent advances in language modeling.', 'Comprehensive experiments and comparisons with state-of-the-art methods demonstrate the efficacy of the proposed model.', 'The model achieves state-of-the-art performance on challenging datasets like Argoverse and Waymo Open Motion Dataset.', 'The masked sequence modeling approach allows for flexible conditioning on different types of information, enabling various prediction tasks.']","['The paper lacks ablation studies on the choice of transformer configurations and the impact of different masking strategies.', 'The clarity of the paper could be improved. Some sections are dense and hard to follow, particularly the detailed descriptions of the architecture and loss functions.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed approach.', ""The presentation of the results could be more comprehensive, with additional qualitative examples and analysis to better illustrate the model's capabilities and limitations.""]",3,3,3,4,Reject
-uZp67PZ7p,"The paper proposes a novel MARL approach to inventory management, introducing shared-resource stochastic games and a Context-aware Decentralized PPO (CD-PPO) algorithm. This method addresses the complexities arising from shared resources among agents, such as warehouse spaces, and aims to improve computational efficiency and policy effectiveness in inventory management scenarios.","['Can the authors provide more detailed explanations and clearer formulations of the mathematical models and algorithms?', 'What is the impact of each component of the CD-PPO algorithm on the overall performance? More ablation studies are needed.', 'How does the approach scale to even larger environments beyond the tested scenarios?', 'What are the potential limitations and societal impacts of the proposed method?']","['The paper does not adequately discuss the scalability of the approach for very large-scale problems.', 'The potential negative societal impacts, such as job displacement due to automation in inventory management, are not addressed.']",False,3,3,3,5,4,"['The paper addresses a real and practical problem in inventory management, which is significant in supply-chain operations.', 'The introduction of shared-resource stochastic games and the CD-PPO algorithm is novel and well-motivated.', 'The approach leverages a unique structure in the problem (shared resources), providing a potentially more efficient learning process.', 'The paper includes extensive experimental evaluation, comparing CD-PPO with state-of-the-art MARL algorithms and traditional inventory management policies.']","['The clarity of the paper is an issue. The presentation of the methodology, especially the mathematical formulation and algorithmic steps, can be improved for better understanding.', 'The experiments, while extensive, do not fully validate the proposed approach. More ablation studies are needed to thoroughly understand the impact of different components of the CD-PPO algorithm.', 'There is a lack of discussion on the scalability of the approach beyond the tested environments, especially for very large-scale problems.', 'The limitations section is weak. The paper does not adequately address potential limitations and societal impacts of the proposed method.']",3,3,3,4,Reject
vgqS1vkkCbE,The paper introduces Value Function Spaces (VFS) as a novel state abstraction method for hierarchical reinforcement learning (HRL). The VFS framework aims to improve long-horizon task performance by using value functions of low-level skills to create a skill-centric state representation. The paper demonstrates the efficacy of VFS in both model-free and model-based RL settings and shows significant performance gains and zero-shot generalization capabilities.,"['Can the authors provide more details on the autoencoder aggregator?', 'What is the impact of different aggregation methods on the performance of VFS?', 'Can the generalization experiments be extended to more diverse environments?', 'Can the authors provide more detailed implementation steps for VFS to enhance reproducibility?', 'How would the performance be affected if the pre-specified skills were optimized or adapted during training?', 'Can the authors conduct additional ablation studies to isolate the contributions of individual components within the proposed framework?', 'Can the authors clarify how the value functions are computed and updated during training?', 'Have the authors tested the robustness of VFS in different environments beyond the ones presented in the paper?', 'Are there any potential limitations or ethical considerations associated with the proposed method?']","['The paper could benefit from more detailed ablation studies and explanations of certain implementation details.', 'The generalization experiments could be more comprehensive.', 'The paper heavily relies on pre-specified skills and does not explore their optimization or adaptation during training.', 'There is a potential lack of clarity in the methodological description, particularly concerning the implementation of VFS.', 'The paper does not address the discovery or training of low-level skills, which could be a limitation for practical applications.', 'The robustness of the empirical results needs to be validated across more diverse tasks and environments.', 'The primary limitation is the lack of methodological detail, which impedes reproducibility.', 'The paper also lacks a comprehensive set of comparisons with a broader range of baselines.']",False,3,3,3,6,4,"['The introduction of VFS is novel and addresses an important problem in HRL.', 'Empirical evaluations demonstrate significant performance improvements and generalization capabilities.', 'The paper is well-organized and clearly written, making it easy to follow.', 'Comprehensive experimental validation across different environments, demonstrating significant performance improvements.', 'The approach shows robust zero-shot generalization capabilities, an important property for real-world applications.']","['The paper lacks detailed ablation studies for certain choices, such as the impact of different aggregation methods.', 'Some aspects of the implementation, particularly for the autoencoder aggregator, are not well-explained.', 'The generalization experiments could be more comprehensive, including more diverse environments.', 'The methodology lacks clarity in some parts, particularly the implementation details of VFS, which could hinder reproducibility.', 'The paper does not address the optimization or adaptation of pre-specified skills during training.', 'There is a lack of thorough ablation studies to isolate the contributions of individual components within the proposed framework.', 'Potential limitations and ethical considerations of the proposed method are not adequately addressed.']",3,3,3,4,Accept
2DJn3E7lXu,"The paper presents a comprehensive evaluation of 18 different hardware metric predictors in the context of Neural Architecture Search (NAS). It evaluates these predictors on ten different combinations of metrics, devices, network types, and training tasks. The study finds that MLP models are particularly promising and demonstrates that using fast and inaccurate prediction models can be more beneficial than accurate but slow live measurements under a time budget.","['Can the authors provide additional ablation studies to explore the impact of different modulation functions and types of aggregators?', 'Can the description of the autoencoder aggregator be clarified further?', 'Can more examples or cases be included in the qualitative analysis to enhance the visualization?', 'Can the authors provide more detailed justifications for the chosen datasets and metrics?', 'Can the authors simplify some of the explanations, especially regarding the experimental setups and predictor models, to improve clarity?', 'Can you provide more details on the hyper-parameter tuning process and how it was standardized across different predictors?', 'How do you ensure the generalizability of your results to other datasets or tasks beyond those specifically tested in this study?', 'Can you elaborate on how the simulation methodology might differ from real-world NAS applications and the potential impact of these differences?', 'Could you discuss potential ethical implications of using hardware metric predictors in NAS?', 'Can you provide more specific use-cases or scenarios where certain predictors might be more advantageous?']","['The primary limitation is the clarity in some sections and the need for additional ablation studies to strengthen the findings.', 'The study does not address potential biases introduced by the chosen datasets. Additionally, the generalizability of the results to other datasets or tasks is not thoroughly discussed.', 'The simulation methodology, while useful, may not fully represent the complexities of real-world NAS applications.', ""The paper's clarity could be improved to make it more accessible. Additionally, more detailed justifications for the chosen datasets and metrics would strengthen the experimental design.""]",False,3,3,3,7,4,"['Addresses a novel and important issue in the field of NAS: the evaluation of hardware metric predictors.', 'Comprehensive evaluation covering 18 different predictors and multiple datasets, providing a robust comparison.', 'Findings provide practical insights that can guide researchers in choosing appropriate predictors for NAS, particularly highlighting the effectiveness of MLP models.', 'Simulations and real-world evaluations add depth to the study, making the results more reliable.', 'Provides actionable recommendations for improving NAS results.']","['The paper could benefit from additional ablation studies, particularly in understanding the impact of different modulation functions and types of aggregators.', 'Some sections, particularly the description of the autoencoder aggregator, could be clearer.', 'The visualization and qualitative analysis could be enhanced by providing more examples or cases.', 'The paper is dense and sometimes difficult to follow, especially regarding the experimental setups and justifications.', 'More detailed explanations and justifications for the chosen datasets and metrics would improve clarity.', 'The discussion on the limitations of the study is minimal, particularly regarding potential biases introduced by the chosen datasets and the generalizability of the results to other datasets or tasks.', 'The simulation methodology, while useful, may not entirely capture the complexities of real-world NAS applications.']",3,3,3,4,Accept
aBAgwom5pTn,"The paper introduces DYHPO, a dynamic gray-box hyperparameter optimization method that uses Bayesian Optimization with a deep kernel Gaussian Process (GP) to model learning curve dynamics and a multi-budget acquisition function. DYHPO aims to efficiently allocate budgets across configurations, addressing the issue of poor rank correlation in existing multi-budget HPO methods. The method is evaluated on 50 datasets across tabular, image, and NLP tasks, showing significant improvements over state-of-the-art baselines.","['Can the authors provide more details on the hyperparameter settings for the deep kernel GP, such as the architecture of the neural network used in the kernel and the specific values of hyperparameters?', 'How sensitive is DYHPO to the choice of kernel and the architecture of the neural network used in the kernel?', 'Can the authors elaborate on the specific steps for updating the surrogate model and acquisition function in DYHPO?', 'How does the proposed acquisition function differ from existing multi-fidelity acquisition functions?', 'What are the potential limitations of DYHPO, and how might it impact society negatively?', 'Can the authors justify the choice of baselines and the experimental setup in more detail?', 'How does DYHPO compare with Freeze-Thaw Bayesian optimization and other similar multi-fidelity techniques in terms of both performance and computational efficiency?', 'Could the authors include more visualizations that break down the performance of DYHPO across individual datasets?', 'What is the computational overhead introduced by the deep kernel GP, and how does it compare to other methods?']","['The paper addresses the limitations and potential negative societal impacts adequately. However, the lack of detailed hyperparameter settings and sensitivity analysis could be a limitation for practical implementation and reproducibility.', 'The paper should discuss the potential computational overhead of training the deep kernel GP in more detail and how it compares to other methods in terms of practical efficiency.', 'The novelty in comparison to existing methods needs to be more clearly articulated.', 'Additional ablation studies are needed to fully understand the impact of the deep kernel and other design choices.']",False,3,3,3,6,4,"['DYHPO addresses a critical issue in gray-box HPO by modeling learning curve dynamics and dynamically allocating budgets.', 'The proposed method shows significant empirical improvements over state-of-the-art baselines, demonstrated through extensive experimentation on diverse datasets.', 'The use of a deep kernel GP to capture learning dynamics is novel and effective.', 'The paper is well-structured and clearly written, making the methodology and results easy to follow.']","['The paper lacks detailed hyperparameter settings for the deep kernel GP and other components, which are crucial for reproducibility.', 'The impact of the choice of kernel and other design choices (e.g., the architecture of the neural network used in the kernel) on the performance of DYHPO is not thoroughly discussed.', 'Some parts of the methodology, such as the specific steps for updating the surrogate model and acquisition function, could be elaborated further.', 'The novelty of the surrogate model and acquisition function is not entirely clear from the description.', 'Limited discussion on the potential limitations and negative societal impact.', 'The choice of baselines and experimental setup need clearer justification.', 'The results section could benefit from additional visualizations and breakdowns of performance across more individual datasets to provide a clearer picture of where DYHPO excels.', 'The paper lacks a detailed discussion on the computational overhead introduced by fitting the deep GP kernel, which could be significant in practice.']",3,3,3,3,Reject
SsPCtEY6yCl,"The paper investigates the uncomputability and inapproximability of partition functions in energy-based sequence models (EBMs) with expressive parametric families. It demonstrates that for such models, the partition functions can be uncomputable and inapproximable, leading to undecidable model selection and parameter estimation problems. The paper provides theoretical proofs to support these claims and discusses potential palliative measures that involve trade-offs between expressiveness and computability.","['Can the authors provide more detailed practical examples or case studies?', 'Are there ways to simplify some of the explanations to make the paper more accessible?', 'How do these theoretical results impact current real-world applications of energy-based sequence models?', 'Can the authors provide more intuitive explanations or examples to illustrate the practical implications of their theoretical findings?', 'How do the theoretical results impact the current use of EBMs in real-world applications? Are there specific scenarios or models where these findings are particularly relevant?', 'Can the authors expand on the discussion of palliative measures and provide more practical guidance for practitioners?', 'Are there any potential practical applications or scenarios where the theoretical findings could be directly applied?']","['The paper is highly theoretical and dense, which may limit its accessibility and practical impact. The authors could improve clarity and provide more practical context.', 'The major limitations of the paper are its theoretical nature and the complexity of the arguments, which may limit its accessibility to a broader audience.', 'The potential negative societal impact of the work is not directly addressed, but it is not immediately apparent given the theoretical focus.', 'The paper is primarily theoretical and does not include empirical validation, which limits the practical applicability of the findings.', 'The complexity of the proofs and theoretical constructs may make the paper less accessible to a broader audience.']",False,3,3,3,6,4,"['Addresses a critical theoretical issue in energy-based sequence models.', 'Provides rigorous proofs demonstrating the uncomputability and inapproximability results.', 'Explores practical alternatives with computable partition functions, balancing expressiveness and feasibility.', 'Theoretical rigor and depth in proving the uncomputability and inapproximability of partition functions.']","['The paper is dense and may be difficult for readers without a strong theoretical background.', 'Lacks detailed practical examples or case studies to illustrate the real-world implications of the theoretical results.', 'Could benefit from additional clarifications or simplified explanations to improve accessibility.', 'The clarity of the presentation could be improved, especially in explaining the implications of the theoretical results for practical machine learning applications.', 'The discussion of palliative measures is somewhat brief and could be expanded to provide more practical guidance.', 'Lack of empirical validation or practical examples to illustrate the theoretical findings.']",4,3,3,3,Reject
RxplU3vmBx,"The paper introduces Cost-Free Incremental Learning (CF-IL), a method to address catastrophic forgetting in incremental learning scenarios without additional memory or auxiliary networks. The key contribution is the Memory Recovery Paradigm (MRP), which synthesizes past exemplars from the learner network, thereby reducing memory and computational overhead. The method is evaluated on CIFAR-10 and Tiny-ImageNet datasets, showing competitive performance compared to state-of-the-art methods.","['Please provide more details about the memory recovery process and the constraints applied during model output generation.', 'Can the authors provide additional ablation studies to explore the impact of variances in the memory recovery paradigm and the parameters used?', 'How does the choice of the dynamic confusion matrix and the Dirichlet distribution parameters impact the performance of the proposed method?', 'Can the authors evaluate the proposed method on additional datasets or more complex scenarios to demonstrate its generalizability and robustness?', 'Can the authors provide more visualizations and examples of the synthesized transfer set to better understand its quality and effectiveness?']","['The paper does not discuss potential limitations or negative societal impacts of the proposed method.', 'The generalizability of the proposed method to other datasets or more complex scenarios is not thoroughly evaluated.', 'The qualitative analysis provided in Figures 2 and 3 includes only a single visualization per task. More cases should be provided to strengthen the analysis.']",False,3,3,3,5,4,"['The idea of synthesizing past exemplars without additional memory or networks is novel and potentially impactful.', 'The method reduces memory and computational overhead, which is crucial for real-world applications.', 'The experimental results on CIFAR-10 and Tiny-ImageNet demonstrate competitive performance compared to state-of-the-art methods.']","['The paper lacks clarity in the detailed implementation of the memory recovery paradigm, particularly the process of generating and refining output vectors.', 'Insufficient ablation studies to explore the impact of different components and parameters of the proposed method.', 'Limited evaluation on diverse datasets, which may not fully demonstrate the robustness and scalability of the approach.', 'The paper does not provide a detailed discussion on the potential limitations and negative societal impacts of the proposed method.', 'The experimental comparisons are not exhaustive, and some state-of-the-art methods are not included in the benchmarks.']",3,3,2,3,Reject
PgNEYaIc81Q,"The paper introduces a dataset called ComPhy for physical reasoning from videos, focusing on intrinsic properties like mass and charge that are not directly observable. It also proposes a new model, Compositional Physics Learner (CPL), that outperforms existing baselines on the ComPhy dataset.","['Can you provide more details on the architectural choices and training procedures for the physical property learner (PPL) and dynamic predictor?', 'Can you discuss the limitations and potential negative societal impacts of your proposed approach?', 'Why were the specific evaluation metrics chosen for the experiments, and how do they compare to other possible metrics?', ""Can you provide more qualitative analysis of the model's performance, including detailed examples of correct and incorrect predictions?"", 'Can the authors provide more details on the dataset creation process and the specific challenges involved?', 'How does the proposed CPL model differ from existing neural-symbolic reasoning frameworks?', 'Can the authors provide more insights into the potential broader applications of their approach?', 'Can you provide a clearer explanation of the CPL framework, possibly with additional diagrams?', 'How do the authors address potential biases in the ComPhy dataset?', 'Can you include more ablation studies to demonstrate the effectiveness of each component of CPL?', 'Can the authors provide more details about the autoencoder aggregator?']","['The paper does not discuss the limitations and potential negative societal impacts of the proposed approach.', 'The explanation of the CPL framework is unclear in some sections, and additional ablation studies are needed to isolate the contributions of different components.', 'The practical significance of the tasks and the proposed approach is unclear, as they seem highly specialized and not easily generalizable to broader applications.']",False,2,3,3,5,4,"['The dataset addresses an important and challenging problem in physical reasoning by focusing on intrinsic properties that are not directly observable.', 'The proposed model, CPL, is well-designed and shows significant improvements over existing baselines.', 'The paper provides comprehensive experiments and ablation studies to demonstrate the effectiveness of CPL.']","['The explanation of the physical property learner (PPL) and dynamic predictor could be more detailed, particularly in terms of their architectural choices and training procedures.', 'The paper lacks a thorough discussion of the limitations and potential negative societal impacts of the proposed approach.', 'The evaluation metrics used for the experiments are not fully justified, and it is unclear why certain metrics were chosen over others.', ""The paper does not provide enough qualitative analysis of the model's performance, such as detailed examples of correct and incorrect predictions."", 'The novelty of the proposed method compared to existing works is not well-established; it appears to borrow heavily from existing neural-symbolic approaches.', 'The practical significance of the tasks and the proposed approach is unclear, as they seem highly specialized and not easily generalizable to broader applications.']",3,3,3,3,Reject
qI4542Y2s1D,"The paper presents FILM, a modular approach for embodied instruction following (EIF) that builds a semantic map and uses a semantic search policy for exploration. FILM achieves state-of-the-art performance on the ALFRED benchmark, significantly outperforming previous methods. The approach does not rely on expert trajectories or low-level instructions, although leveraging low-level language can further improve performance.","['Can you provide more details on the impact of different pre-trained models used for depth prediction and instance segmentation?', 'How does the performance of FILM vary with different types of semantic search policies?', 'What are the computational requirements for training and deploying FILM, and how do they compare to previous methods?', 'Can the authors provide more details about the autoencoder aggregator?', 'What is the performance of the proposed model with different types of aggregators?', 'Can the authors analyze the results by reducing the number of gating parameters in Eq. 10 by sharing the gate value of each filter in Conv layers?', 'Can the authors provide more visualization cases in the qualitative analysis?', 'Can the authors provide more details on the design choices for the semantic search policy?', 'How does the choice of grid size in the semantic search policy affect the performance?', 'Can the authors clarify the pre-training process for the depth and segmentation models and their potential impact on generalizability?', 'How does the method handle dynamic environments and more complex tasks beyond those in the ALFRED benchmark?', 'Could the authors clarify the exact process of semantic mapping and how it is integrated with the search policy?']","['The reliance on pre-trained models for specific tasks may limit the generalizability of the approach to new environments or tasks.', 'The complexity and resource requirements for training and deploying FILM may pose challenges for practical applications.', ""The method's performance heavily relies on the accuracy of the semantic mapping module. Any failure in this module may significantly impact the overall performance."", 'The paper does not thoroughly explore the robustness of each module independently. More ablation studies are needed to validate the contributions of each component.', 'Potential limitations in real-world applications, such as handling dynamic environments and more complex tasks, are not thoroughly discussed.']",False,3,3,3,6,4,"['The modular design effectively separates different functionalities, improving transparency and interpretability.', 'Significantly outperforms previous methods on the ALFRED benchmark, demonstrating the effectiveness of the approach.', 'The use of a semantic search policy for exploration is novel and improves the efficiency of navigation.', 'Comprehensive experiments and ablation studies are provided to validate the contributions of different modules.']","['The reliance on pre-trained models for depth prediction and instance segmentation may limit the generalizability of the approach.', ""The method's complexity makes it challenging to reproduce without extensive resources."", 'The paper could benefit from additional ablation studies to further isolate the contributions of individual components, such as different types of semantic search policies and the impact of various pre-trained models.', 'Certain methodological choices, such as the specific design of the semantic search policy, need further clarification.', 'The paper could improve in terms of clarity, particularly in the explanations of the semantic mapping and search policy modules.']",3,3,3,4,Accept
uy602F8cTrh,"The paper proposes CausalDyna, a Dyna-style reinforcement learning algorithm that enhances generalization by using counterfactual data augmentation. Structural Causal Models (SCMs) are used to model state dynamics, allowing the generation of counterfactual scenarios to improve policy training. Evaluations on the CausalWorld robotic environment show improved performance over state-of-the-art methods.","['Can you provide more details about the model architecture, hyperparameters, and implementation specifics?', 'How robust is the counterfactual reasoning? Can you provide additional evidence or experiments?', 'Can you include more detailed visualizations and explanations to make the results easier to interpret?', 'Can you provide more empirical evidence and broader comparisons to support the generalization claims?', 'How does the performance of CausalDyna vary with different ratios of counterfactual property generation?', 'Can the authors discuss any potential limitations or negative societal impacts of their approach in more detail?', 'Could additional ablation studies be conducted to isolate the impact of each component of CausalDyna?', 'Are there more qualitative examples or visualizations that can be provided to further validate the experimental results?']","['The paper does not sufficiently detail the methodology, making it hard to assess the robustness and effectiveness of the proposed approach.', 'The results, though promising, need more empirical evidence and comparisons to be fully convincing.', 'The dependency on the quality of the world model is a significant limitation. If the world model does not accurately capture the environment dynamics, the generated counterfactual episodes may not be reliable.', 'The lack of comprehensive ablation studies makes it difficult to understand the contribution of each component of the proposed method.']",False,3,3,3,5,4,"['Addresses the important issue of generalization in reinforcement learning.', 'Innovative application of SCMs for modeling object properties in robotic manipulation tasks.', 'Promising experimental results showing improvements in sample efficiency and generalization.']","['The methodology section lacks detail about the model architecture, hyperparameters, and implementation specifics.', 'Unclear integration of SCMs and robustness of counterfactual reasoning.', 'Figures and tables are cluttered and hard to interpret; more detailed explanations and visualizations are needed.', 'Insufficient empirical evidence to comprehensively support the generalization claims; more experiments and broader baseline comparisons are needed.', 'The paper lacks comprehensive ablation studies to thoroughly evaluate the impact of different components of the proposed method.', 'The dependency on the quality of the world model is a critical limitation that should be emphasized more in the paper.']",3,3,2,3,Reject
iaqgio-pOv,"The paper introduces model-agnostic local explanations for similarity learners through feature-based and analogy-based methods. The feature-based method uses Mahalanobis distance for interpretable feature attributions, while the analogy-based method identifies diverse analogous pairs to uncover latent factors influencing the model's predictions. The efficacy of these methods is demonstrated through qualitative examples, quantitative evaluations, and a user study.","['Can you provide more details on the design and results of the user study to strengthen the claims?', 'How does the approach compare with existing methods in terms of computational complexity and scalability?', 'Can you clarify the process of perturbation generation for feature-based explanations?', 'Can the authors provide more details on the analogy closeness function and how it was designed?', 'How were the participants for the user study selected? Were they representative of the intended end-users?', 'Can the authors provide more details on the hyperparameter tuning process for the proposed methods?', 'What is the computational cost of the proposed methods, and how does it compare to existing methods?', 'Can the authors provide more detailed examples or guidelines for implementing the analogy-based explanations?', 'How does the feature-based method compare to other local explanation methods like LIME in more diverse settings?', 'What are the potential limitations of the proposed methods, and how do they affect practical applicability?', 'Can the authors provide additional ablation studies to validate the choice of Mahalanobis distance and the impact of various perturbation strategies?', 'How do the analogy-based explanations integrate with feature-based explanations, and can this integration be improved for better interpretability?', 'Can the authors provide a more detailed analysis on the user study results, particularly on why certain explanations were preferred by the participants?', 'Could you provide more details on the computational complexity of the proposed methods and suggest ways to mitigate it for large datasets?', 'Can you include additional ablation studies to investigate the impact of different hyperparameters and variations in the methods?', 'Could you clarify the explanation of the Mahalanobis distance and the analogy-based method to improve readability?']","['The practical utility and interpretability of analogy-based explanations need more rigorous evaluation.', 'The user study results are not convincingly significant and need more detailed reporting.', 'The paper does not provide enough details on the computational cost and scalability of the proposed methods.', 'The explanation of the analogy-based method could be clearer, particularly the components of the analogy closeness function.', 'The user study could be more robust in terms of participant selection and the representativeness of the intended user base.', 'The paper should provide more analysis of the results and discuss potential limitations of the proposed methods.', 'More comparisons with state-of-the-art methods and ablation studies could strengthen the claims.', 'The paper acknowledges the limitations and potential risks associated with post-hoc explanations, such as faithfulness to the black box and privacy/security risks. However, the computational complexity and the need for additional ablation studies are areas that need further attention.']",False,3,2,3,5,4,"['Addresses an under-explored area in explainable AI: explanations for similarity learners.', 'Proposes a novel analogy-based explanation method, which provides diverse analogous pairs to uncover latent factors.', 'Provides comprehensive qualitative and quantitative evaluations, including a user study.', 'The methods are model-agnostic and can be applied to various types of data, including tabular and text data.', 'Proves the submodularity of the analogy objective function, ensuring efficient search for analogies.']","['Practical utility and interpretability of analogy-based explanations need more rigorous evaluation.', 'User study results are not convincingly significant, and more details on the study design and results could strengthen the claims.', 'Lacks thorough comparison with existing methods in terms of computational complexity and scalability.', 'Clarity of the methodology, particularly the perturbation generation for feature-based explanations, could be improved.', 'The quantitative evaluations lack some details, such as the choice of hyperparameters and how they were optimized.', 'The paper would benefit from more extensive ablation studies to understand the contribution of each component of the proposed methods.']",3,3,2,3,Reject
JmU7lyDxTpc,The paper investigates the phenomenon of epoch-wise double descent in neural networks using a linear teacher-student model and tools from statistical physics. The authors derive closed-form expressions for the generalization error dynamics and validate these findings through numerical simulations and experiments on real-world neural networks.,"['Can the authors provide more intuitive explanations or visual aids to help understand the mathematical derivations, particularly for readers less familiar with statistical physics?', 'How robust are the findings to variations in the assumptions about the modulation matrix F and the noise model?', ""Can the authors compare their model's performance against other existing models that address double descent, possibly in different settings or datasets?"", 'What practical recommendations for training deep neural networks can be derived from this work?', 'Can the authors provide more details on the limitations of the linear teacher-student model and how these limitations might affect the generalizability of their findings to more complex neural networks?', 'Can the experimental validation be extended to other architectures and datasets to strengthen the empirical support for the theoretical results?']","['The linear teacher-student model and specific assumptions made may limit the generalizability of the findings to more complex neural networks.', 'The paper would benefit from a broader discussion on practical implications and more extensive empirical validation.', 'The teacher-student model may not capture all the complexities of deep neural networks, potentially limiting the applicability of the theoretical findings.']",False,3,3,3,5,4,"['The paper addresses a significant and less-explored aspect of neural network generalization: epoch-wise double descent.', 'The theoretical framework developed is robust, providing closed-form expressions for generalization dynamics.', 'The theoretical findings are validated through both numerical simulations and experiments with real-world neural networks.', 'The use of the replica method from statistical physics to derive exact analytical expressions for the generalization error is a strong theoretical contribution.']","['The clarity of the paper is compromised due to the dense mathematical derivations and the requirement for a strong background in statistical physics.', 'The linear teacher-student model may oversimplify the complex dynamics of deep neural networks, potentially limiting the generalizability of the findings.', 'The practical implications of the theoretical results are not fully explored.', 'The experimental validation on real-world networks is limited to a single architecture (ResNet-18) and a single dataset (CIFAR-10).']",3,3,3,3,Reject
ZC1s7bdR9bD,"The paper presents a novel algorithm for attributing model uncertainties in Bayesian models using path integrals combined with in-distribution curves. The method aims to produce meaningful and interpretable attributions by leveraging counterfactual fiducials and ensuring desirable properties such as completeness and implementation invariance. The approach is validated on multiple benchmark datasets, demonstrating its effectiveness compared to state-of-the-art methods.","['Can the authors provide more intuitive explanations and visual aids in the methodology section?', 'What is the impact of different choices of fiducial points on the attributions?', 'How does the choice of VAE architecture affect the performance of the proposed method?', 'Can the authors provide a clearer explanation of the optimization process for constructing the in-distribution curve?', 'How does the method compare with more recent uncertainty attribution methods that might be directly optimized for this purpose?', 'Are there ways to simplify the methodology without significantly compromising its performance?', 'Can the authors provide clearer mathematical explanations and derivations?', 'How does the proposed method compare to existing methods in more detail?', 'Can the authors provide more informative visualizations and comparisons in the experiments?', 'What are the potential societal impacts and limitations of the proposed method?', 'How does this approach fundamentally differ from and improve upon existing methods like integrated gradients and CLUE?', 'Can the authors expand their experimental validation to include more diverse applications beyond image datasets?', 'Is there any availability of code or supplementary materials to ensure reproducibility?', 'Can the authors provide more details on the computational complexity and scalability of the proposed method?', 'How do the authors ensure that the fiducial points and the paths remain in-distribution?', 'Can the authors provide more quantitative metrics for the evaluation and discuss the statistical significance of the results?', 'What are the potential limitations or failure cases of the proposed method?']","['The method involves a two-stage optimization process which might be computationally expensive.', 'The complexity of setting up the experiments might pose challenges for reproducibility.', 'Some parts of the methodology section are dense and could benefit from clearer explanations.', 'The paper does not adequately address the potential societal impacts and limitations of the proposed method.', 'Limited experimental validation and marginal improvements over existing methods.', 'The paper does not adequately discuss the potential failure cases or scenarios where the method may not perform well.', 'There is a lack of detailed explanation on the computational complexity and scalability of the method.']",False,2,2,2,4,4,"['The introduction of path integrals and in-distribution curves for uncertainty attribution is novel and addresses a relevant problem in Bayesian machine learning.', 'The method is theoretically sound, ensuring properties like completeness and implementation invariance.', 'Comprehensive experimental evaluation on multiple benchmark datasets, comparing the proposed method with state-of-the-art approaches.', 'Produces sparse and easily interpretable attributions, which are crucial for practical applications.']","['The method involves a two-stage optimization process, which might be computationally expensive and complex to implement.', 'Some parts of the methodology section are dense and could benefit from clearer explanations and more intuitive descriptions.', 'Lack of ablation studies to show the impact of different components of the proposed method, such as the choice of fiducial points and the effect of the VAE architecture.', 'The comparison is mainly against standard attribution methods that may not be directly optimized for uncertainty attribution.', 'The complexity of the method might make it harder for others to reproduce the results, despite the authors providing a link to the source code.', 'Experimental validation is limited to a few image datasets; more diverse applications are needed.', 'Potential societal impacts and limitations are not adequately addressed.']",3,2,2,3,Reject
qnQN4yr6FJz,The paper proposes a hybrid generative-discriminative approach for handling incomplete features using variational inference. The method leverages a new variational approximation and a variance reduction technique to achieve this. The empirical results show that the proposed method performs well compared to existing methods.,"[""Can the authors provide more detailed explanations and visual aids to improve the paper's clarity?"", ""Can the authors conduct more comprehensive experiments to validate the method's effectiveness across various datasets and real-world conditions?"", 'What are the potential limitations and negative societal impacts of the proposed method?', 'What is the performance of the proposed model with different types of aggregators?', 'Can you provide more qualitative analysis cases to support the experimental results?']","['The paper does not adequately address potential limitations and negative societal impacts of the proposed method.', 'The complexity and potential computational cost of the proposed method could be limiting factors for its practical application.', 'Additional ablation studies are required to validate the effectiveness and robustness of the proposed method.']",False,3,2,3,5,4,"['Addresses a significant problem in machine learning: handling incomplete data.', 'The proposed hybrid method combines generative and discriminative approaches, which is innovative and effective.', 'The introduction of a new variational approximation and variance reduction technique is a notable contribution.', 'Empirical results demonstrate the effectiveness of the proposed method.']","['The paper is not clearly written, with dense mathematical notations and insufficient explanations making it difficult to follow.', ""The empirical validation is limited to a few datasets and does not convincingly demonstrate the method's practical utility."", 'The paper lacks a thorough discussion of potential limitations and negative societal impacts, which is crucial for responsible AI research.', 'The complexity and potential computational cost of the proposed method could be limiting factors for its practical application.']",3,3,2,3,Reject
HuaYQfggn5u,"The paper proposes FedBABU, a federated learning algorithm that decouples the model into a body (extractor) and a head (classifier), updating only the body during federated training. The head is fine-tuned during personalization. The paper claims that this approach improves the representation power of the global model and enhances personalization capabilities. Extensive experiments are conducted to validate the effectiveness of the proposed method.","['Can the authors provide more theoretical insights into why updating only the body improves representation power?', 'Have the authors considered conducting additional ablation studies to explore the impact of different components of the model and training process?', 'Would the proposed method generalize well to other types of data (e.g., text, time-series)?', 'Can you clarify the experimental setup and provide more details for reproducibility?', 'What are the potential failure modes and limitations of the proposed method?', 'How does your method compare to other state-of-the-art personalized federated learning methods in terms of computational efficiency and scalability?', 'Can you provide more details on the choice of hyperparameters for the body and head during training? How sensitive is the performance to these hyperparameters?', 'Have you considered other applications beyond image classification? How do you expect FedBABU to perform on other types of tasks?', 'Can you provide more detailed explanations and diagrams for the FedBABU algorithm to improve clarity?', 'Could you explore the impact of different hyperparameters and initialization methods in more detail?', 'Can you provide more analysis on the role of orthogonality in head initialization and its impact on performance?']","['The paper lacks a detailed discussion on the potential limitations and negative societal impacts of the proposed method. It would be beneficial for the authors to address these aspects in the paper.', 'The impact of fixing the head during federated training might vary depending on the specific characteristics of the dataset and task.', 'The paper should acknowledge the limitations of focusing primarily on image classification tasks and the potential challenges in extending the approach to other domains.', 'The paper could discuss potential limitations such as scalability to very large datasets, communication overhead, and applicability to other types of data (e.g., text or time-series).']",True,3,3,3,6,4,"['The paper tackles an important problem in federated learning: improving the global model while ensuring effective personalization.', 'The proposed method, FedBABU, is novel in its approach of decoupling the model into a body and a head and updating only the body during federated training.', 'Comprehensive experiments are conducted, comparing FedBABU with several existing methods across different datasets and settings.', 'The paper provides both quantitative and qualitative analyses, including t-SNE visualizations, to support its claims.', 'The inclusion of various baselines and ablation studies adds robustness to the experimental validation.']","['The paper could benefit from additional ablation studies to explore the impact of different components of the model and training process.', 'The explanation of why updating only the body improves representation power could be more detailed, including more theoretical insights.', 'The experiments are mostly conducted on image classification tasks; additional experiments on other types of data (e.g., text, time-series) could strengthen the generalizability of the findings.', 'Potential limitations and negative societal impacts of the proposed method are not discussed in detail.', 'The paper lacks clarity in several sections, making it difficult to follow and reproduce the results.', 'There are ethical concerns regarding the use of non-private data for server updates, which might violate the core principles of federated learning.']",3,3,3,3,Reject
YmONQIWli--,The paper proposes an efficient SDE solver with adaptive step sizes tailored for score-based generative models. The solver aims to accelerate data generation while maintaining or improving sample quality compared to the Euler-Maruyama method. It requires only two score function evaluations per step and rarely rejects samples. The authors claim that their method generates data 2 to 10 times faster than EM while achieving better or equal sample quality.,"['Can you provide more detailed implementation steps for the proposed solver?', 'What are the theoretical justifications for the choice of specific parameters in the algorithm?', 'Can the authors provide more theoretical analysis on the convergence and stability of the proposed method?', 'How does the proposed method compare to other state-of-the-art techniques not considered in this paper?', 'Can the authors clarify some of the notations and explanations in the methodology section?', 'Can you provide more details on how the adaptive step size parameters were chosen?', 'Could you conduct additional ablation studies to investigate the impact of different norms and hyperparameters?', 'How does the proposed method perform on other types of data and tasks beyond continuous-time image generation models?', 'Is there any overhead introduced by the adaptive step sizes that might affect the performance comparison?', 'Can the authors provide detailed hyperparameter settings and make the code available to ensure reproducibility?']","['The paper could benefit from a more diverse set of datasets for evaluation to demonstrate the generalizability of the proposed method.', 'Some theoretical aspects, such as the choice of specific parameters in the algorithm, need stronger justification.', 'The paper lacks sufficient theoretical analysis and empirical validation. Further theoretical work on convergence and stability is needed.', 'Additionally, more empirical comparisons with state-of-the-art methods on a wider range of datasets would strengthen the paper.', 'The paper could benefit from a clearer discussion of the limitations and potential negative societal impacts of the proposed method.', ""More ablation studies could provide a deeper understanding of the method's components."", 'The experiments are limited to continuous-time image generation models, and the potential overhead of adaptive steps is not fully accounted for.']",False,3,2,3,5,4,"['Addresses a critical bottleneck in score-based generative models: the speed of data generation.', 'Well-motivated approach that leverages adaptive step sizes effectively.', 'Comprehensive experiments demonstrate improvements in both speed and sample quality.', 'Does not require step size tuning, simplifying its applicability.']","['Lacks clarity in some technical aspects, particularly the implementation details of the proposed solver.', 'The theoretical justification for some choices in the algorithm could be more robust.', 'Limited diversity in the datasets used for evaluation; primarily image datasets are considered.', 'The proposed method is somewhat incremental, mainly adapting existing techniques for a specific application.', 'Lacks sufficient theoretical analysis, particularly regarding the convergence and stability of the proposed method.', 'Empirical results could benefit from more comparisons with state-of-the-art methods and a wider range of datasets.', 'Some sections, especially the methodology, could be clearer. The notation and explanations are sometimes difficult to follow.', 'More ablation studies are needed to understand the impact of different components of the proposed method.', 'The potential limitations and negative societal impacts of the proposed method are not well discussed.', 'The paper lacks detailed hyperparameter settings and code availability, which could hinder reproducibility.']",3,3,2,3,Reject
4jUmjIoTz2,The paper proposes a novel method—Collaborate to Defend against Adversarial Attacks (CDA[2])—for improving adversarial robustness. The framework involves learning multiple sub-models that collaborate by minimizing their vulnerability overlap and selecting the best-performing sub-model based on a posterior probability density (PPD) head. The experimental results show that CDA[2] outperforms various ensemble methods against both white-box and black-box adversarial attacks.,"['Can the authors provide more details on the implementation of the PPD head and the surrogate loss?', 'Have the authors considered any simplifications to make the methodology easier to understand and implement?', 'How does CDA[2] perform compared to other state-of-the-art adversarial defense methods not mentioned in the paper?', 'Can the authors elaborate on the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide more detailed explanations of the theoretical proofs and algorithmic steps?', 'Could additional ablation studies be included to analyze the impact of each component of the proposed approach?', 'Can the methodology and experimental setup be elaborated further for better clarity?', 'How does the proposed method perform on other datasets beyond CIFAR10?', 'Can the authors include additional ablation studies to isolate the contributions of different components of CDA[2]?', 'How does the collaboration framework perform with different types of aggregation methods?', 'Could the authors include more visualizations to demonstrate the behavior of the collaboration framework in different scenarios?']","['The complexity of the proposed framework might limit its practical applicability.', 'The paper does not adequately address potential issues with the scalability and computational complexity of the proposed method, especially when applied to larger datasets and more complex models.', 'The paper discusses some limitations, such as the potential for increased complexity in training and the necessity of designing a dedicated mechanism for collaboration. However, it could delve deeper into the potential drawbacks and how they might be mitigated.']",False,3,2,3,5,4,"['The paper addresses an important problem in machine learning: adversarial robustness.', 'The proposed collaborative framework is novel and theoretically sound.', 'The experimental results demonstrate significant improvements over state-of-the-art methods in both white-box and black-box settings.']","['The methodology might be complex to implement and understand.', 'The paper lacks clarity in some sections, such as the exact mechanism of the PPD head and the surrogate loss.', 'More comprehensive ablation studies could further strengthen the claims.', 'The theoretical proofs provided in the appendix are not well integrated into the main text, making it challenging to follow the logical flow of the arguments.', 'The experiments are limited to CIFAR10 and a synthetic XOR problem, raising concerns about the generalizability of the approach to other datasets and more complex tasks.']",3,3,2,4,Reject
q9zIvzRaU94,The paper proposes a novel method called State-Dependent Causal Inference (SDCI) for causal discovery in non-stationary time-series data. The method models non-stationarity by conditioning on an underlying state variable and uses a probabilistic deep learning approach to infer causal relationships. The paper includes comprehensive experiments on synthetic data to demonstrate the effectiveness of the method.,"['Can you provide more details about the implementation of the autoencoder aggregator?', 'Have you considered evaluating the proposed method on real-world datasets? If so, what are the results?', 'Can you provide a more detailed theoretical justification for the SDCI method?', 'Could you clarify the technical choices in the implementation, especially regarding the encoder and decoder structures?', 'Can the authors provide more intuitive explanations and examples of the proposed method?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors discuss the potential impact of latent confounders on the proposed method?']","['The major concern is the lack of clarity in the implementation details and the absence of evaluation on real-world data. Addressing these concerns could strengthen the paper.', 'The paper assumes no latent confounders, which is a strong assumption and limits the applicability of the method to real-world data.', 'The paper does not discuss potential limitations and negative societal impacts of the proposed method. It would be beneficial for the authors to address these points to provide a more comprehensive evaluation of their work.']",False,3,3,3,5,4,"['Addresses a significant and complex problem in causal discovery.', 'Proposes a novel method that extends existing approaches to handle state-dependent dynamics.', 'Provides comprehensive experiments on synthetic data to demonstrate effectiveness.']","['The paper lacks clarity in some sections, particularly in the implementation details of the autoencoder aggregator and other technical choices.', 'Theoretical justification for the proposed method is not robust enough; more formal analysis is needed.', ""The experimental validation is limited to synthetic datasets. More diverse and realistic datasets are needed to better demonstrate the method's effectiveness."", 'The paper does not sufficiently address the limitations of the proposed method and potential negative societal impacts.']",3,3,3,3,Reject
JV4tkMi4xg,"The paper introduces NN+MILP, a novel framework for discrete black-box optimization using piecewise-linear neural networks as surrogate models and mixed-integer linear programming (MILP) to optimize the acquisition function. The approach provides optimality guarantees and can handle complex combinatorial constraints effectively. The authors demonstrate the effectiveness of NN+MILP through comprehensive experiments on various benchmarks, including synthetic tasks and real-world applications.","[""Can the authors provide more detailed explanations of the MILP formulation for neural networks and the practicalities of the MILP solver's implementation?"", 'Can the authors improve the labeling and descriptions of figures and tables in the experimental section for easier interpretation?', 'Can the authors provide additional experiments on larger-scale problem instances to demonstrate the scalability of the proposed approach?', 'How does the proposed NN+MILP framework compare with other state-of-the-art methods using different surrogate models or optimization techniques?', ""Can the authors conduct more ablation studies on the choice of surrogate model and optimization settings to provide deeper insights into the framework's performance?""]","['The main limitation is the computational overhead of MILP, which the authors acknowledge and suggest future work to improve scalability.', 'The scalability to very large problem instances remains a concern and needs further exploration.', 'Limited comparison with other state-of-the-art methods using different surrogate models or optimization techniques.']",False,3,3,3,7,4,"['The combination of piecewise-linear neural networks and MILP for optimizing the acquisition function is novel and interesting.', 'The framework provides optimality guarantees and can handle complex combinatorial constraints effectively.', 'Comprehensive experimental results demonstrate the effectiveness of NN+MILP compared to state-of-the-art methods.', 'The paper addresses potential limitations and ethical concerns adequately.', 'Clear writing and detailed methodology, making the work reproducible.']","['Scalability to very large problem instances remains a concern; additional experiments on larger-scale problems would be beneficial.', ""Some parts of the paper could benefit from clearer explanations, especially the detailed MILP formulation for neural networks and the practicalities of the MILP solver's implementation."", 'Limited comparison with other state-of-the-art methods using different surrogate models or optimization techniques.', ""More ablation studies on the choice of surrogate model and optimization settings could provide deeper insights into the framework's performance.""]",4,4,3,4,Accept
pC00NfsvnSK,"The paper introduces Generalized Similarity Functions (GSF), a new framework for improving zero-shot generalization in offline reinforcement learning (RL). The method uses contrastive learning to train an RL agent to aggregate observations based on the similarity of their expected future behavior, quantified using generalized value functions (GVFs). The authors evaluate GSF on the newly proposed offline Procgen benchmark and show that it outperforms state-of-the-art RL and representation learning baselines.","['Could you provide more implementation details on how GVFs are calculated and integrated into the overall framework?', 'Have you considered any optimization techniques or approximations to reduce the computational complexity of calculating GVFs for each POMDP?', 'Can you provide additional ablation studies to understand the impact of different components of the GSF framework, such as the choice of the cumulant function and the number of quantile bins?', 'How would the GSF framework perform on other benchmarks beyond the offline Procgen dataset?', 'Can the authors clarify the choice of hyperparameters and the design of cumulant functions?', 'Can the authors provide more comprehensive implementation details to ensure reproducibility?', 'What are the specific limitations of the proposed method, and how do the authors plan to address them in future work?', 'Can the authors discuss potential negative societal impacts of their work?']","['The paper could benefit from more detailed explanations of the methodology, especially the implementation details of GVFs.', 'Additional ablation studies are needed to better understand the impact of different components of the proposed method.', 'The computational complexity of calculating GVFs for each POMDP may limit the scalability of the approach.', 'The paper should include more detailed ablation studies and experiments across various benchmarks to better establish the robustness and general applicability of the GSF framework.', 'The paper does not adequately address limitations related to the choice of hyperparameters and the design of cumulant functions, which are crucial for the proposed method.', 'The paper does not discuss potential negative societal impacts of the work.']",False,3,2,3,4,4,"['Addresses a critical challenge in RL: zero-shot generalization in offline settings.', 'Proposes a novel framework using generalized value functions to quantify future behavior similarities.', ""Comprehensive experimental validation on the offline Procgen benchmark, showing the method's effectiveness."", ""Theoretical analysis providing insights into the method's properties and the impact of hyperparameters.""]","['Insufficient details on the implementation of GVFs and the overall framework.', 'Limited ablation studies to understand the importance and impact of different components of the proposed method.', 'Potentially high computational complexity due to the need for calculating GVFs for each POMDP, which may not be feasible for very large datasets.', 'The empirical validation is limited to the offline Procgen benchmark. Additional benchmarks and practical applications would strengthen the findings.', 'The clarity of the paper is a concern. The dense mathematical formulations make it difficult to follow, and key details are not adequately explained.', 'Reproducibility is an issue. Although the paper mentions that source code is attached, more comprehensive implementation details and hyperparameter settings are needed.', 'The paper does not adequately discuss potential negative societal impacts of the work.']",3,3,2,3,Reject
LOz0xDpw4Y,"The paper proposes an optimization method using dynamic programming to find the likelihood-optimal inference time schedules for Denoising Diffusion Probabilistic Models (DDPMs). This method is efficient, applicable to any pre-trained DDPM, and does not require retraining. The authors demonstrate that their method can reduce the number of refinement steps significantly while maintaining high sample quality.","['Can the authors provide more details on the sensitivity of the method to the number of Monte Carlo samples used in the dynamic programming table?', 'Could the authors include more qualitative examples to illustrate the differences in sample quality across different stride schedules?', 'What are the potential limitations of the proposed method in terms of generalizability to other types of generative models or datasets?', 'Can the authors provide more details on the computational efficiency and scalability of the dynamic programming algorithm?', 'How generalizable is the method to other datasets and models beyond those tested in the paper?', 'What are the potential limitations of the proposed approach, and how could they impact its broader applicability?', 'Can the authors provide more details or visualizations to clarify the theoretical proofs and the workings of the dynamic programming approach?', 'How does the choice of ELBO reweighting scheme affect the balance between negative log-likelihood and FID scores?', 'Can additional ablation studies be provided to show the impact of various components of the method?', 'Can you provide more detailed explanations or pseudocode for the dynamic programming algorithm to enhance clarity?', 'Have you explored other weightings of the ELBO in more detail, and how do they impact FID scores and sample quality?', 'What are the potential limitations or failure cases of your method, especially in scenarios with very high-dimensional data?', 'Can the authors provide more details about the autoencoder aggregator and its role in the method?', 'How does the choice of modulation functions (e.g., sigmoid, tanh) impact the performance?', 'Can the authors include more ablation studies to analyze the impact of different components and choices within the method?']","[""The method's reliance on the decomposability of the ELBO might limit its applicability to other types of generative models that do not share this property."", 'The impact on FID scores and sample quality should be further investigated, especially in scenarios where reweighting the ELBO may not be feasible.', 'The paper should include a discussion on potential limitations and broader applicability of the method. Additionally, more details on the computational efficiency and scalability of the dynamic programming algorithm would be beneficial.', ""The clarity of the paper could be improved in some sections, and additional ablation studies could provide further insights into the method's components."", 'The focus on likelihood optimization sometimes leads to lower sample quality, as indicated by worse FID scores. This issue is acknowledged but not fully addressed in the main body of the paper.']",False,3,3,3,5,4,"['The proposed method addresses a significant bottleneck in DDPMs by optimizing the inference time schedule, potentially reducing computational costs.', 'The approach is novel and leverages the decomposability of the evidence lower bound (ELBO) in DDPMs.', 'Extensive experiments on CIFAR10 and ImageNet 64x64 demonstrate the effectiveness of the method in reducing the number of refinement steps with minimal loss in sample quality.', 'The method is efficient and does not introduce additional hyperparameters.']","['The paper lacks detailed ablation studies to understand the sensitivity of the proposed method to various factors such as the number of Monte Carlo samples used to compute the dynamic programming table.', 'The clarity of some sections, especially the explanation of the dynamic programming algorithm and its implementation, could be improved.', 'The qualitative analysis with sample images could be expanded to include more examples and comparisons across different strides.', 'The discussion on the potential impact on FID scores is somewhat limited and relies on reweighting the ELBO, which might not be the most principled approach.', 'The experiments, while promising, are limited to specific datasets and pre-trained models, which might affect the generalizability of the results.', 'Reproducibility is dependent on the release of the code, which is promised but not provided at the time of review.']",3,3,3,4,Reject
DBOibe1ISzB,"The paper 'SIT: SIMULATION TRANSFORMER FOR PARTICLE-BASED PHYSICS SIMULATION' introduces a novel Transformer-based model, SiT, for particle-based physics simulation. The model utilizes interaction tokens to capture rich semantics of particle interactions and abstract tokens for material-specific representations. The proposed approach addresses the limitations of existing GNN-based methods, leading to superior performance and generalization across various environments, including fluid, rigid, and deformable objects.","['Can the authors provide more details on the implementation and training settings to enhance reproducibility?', 'Could the authors expand the ablation studies to include more variations and detailed analysis?', 'Additional visualizations and qualitative results in the main paper would be helpful. Can the authors include more of these?', 'Can you provide more intuitive explanations or visualizations for the interaction and abstract tokens and their roles within the Transformer architecture?', 'How did you choose the baselines for comparison, and were there any other methods considered but ultimately not included? Why?', 'Could you provide additional ablation studies to explore the impact of varying the number of attention heads or the depth of the network?', 'What are the potential broader applications and limitations of SiT outside the tested environments?']","['The primary concern is the clarity around implementation details and training settings. Additionally, more extensive ablation studies and visualizations would be beneficial.', 'The paper does not adequately discuss the broader implications of the work, including potential applications and limitations outside the tested environments. This discussion could provide valuable context for the contributions of the paper.']",False,3,2,3,6,4,"['Introduction of interaction and abstract tokens is novel and addresses key limitations in existing GNN-based methods for particle-based simulation.', 'Comprehensive experiments demonstrating superior performance and generalization capabilities.', 'The model achieves better performance with fewer parameters compared to existing methods.', 'The paper covers diverse environments, showcasing the versatility and robustness of the proposed method.']","['The implementation and training details could be clearer and more accessible. For instance, details on hyperparameter settings, training duration, and computational resources used are not sufficiently provided.', 'Ablation studies are provided but could be expanded to include more variations and detailed analysis, such as the impact of varying the number of attention heads or the depth of the network.', 'More visualizations and qualitative results in the main paper would strengthen the argument, rather than relegating these to appendices.', 'The paper is dense and difficult to follow in places, especially in sections dealing with technical details. Specific sections such as the methodology and the description of the Transformer architecture could benefit from more intuitive explanations or diagrams.', 'The paper lacks a discussion on the broader implications of the work, including potential applications and limitations outside the tested environments. This discussion could provide valuable context for the contributions of the paper.']",3,3,2,3,Reject
Tubzedlc4P,"The paper introduces a novel framework for point cloud data analysis using Riemannian geometry and statistical manifolds, leveraging the Fisher information metric. This approach aims to provide advanced geometric tools for measuring distances, angles, volumes, and derivatives within point cloud data. The framework is demonstrated through two autoencoder case studies: interpolating between 3D point clouds and optimizing latent space coordinates.","['Can the authors provide more detailed explanations of the theoretical concepts to improve the clarity of the methodology?', 'Can the authors include experiments that evaluate the scalability and computational efficiency of the proposed framework?', 'What are the limitations and potential negative societal impacts of the proposed work?', 'Can the authors address ethical considerations related to their work?', 'Can the authors provide a clear statement on the reproducibility of the results?', 'Can the authors provide more details about the autoencoder architecture and the training process?', 'How do different kernel functions impact the performance and stability of the proposed method?', 'Can the authors provide additional ablation studies to explore the impact of different hyperparameters and kernel functions?', 'How does the proposed method scale with larger point clouds or more complex datasets?']","['The paper does not discuss the limitations and potential negative societal impacts of the proposed work. The authors should consider including a thorough discussion on these aspects.', 'The method assumes point clouds consist of exactly n distinct points, which may not always hold in real-world scenarios.', 'The computational feasibility of the proposed method, especially concerning the info-Riemannian metric, needs more exploration.']",False,3,2,3,5,4,"['The paper addresses a significant problem in point cloud data analysis.', 'The use of the Fisher information metric to create a Riemannian structure is innovative and theoretically sound.', 'The mathematical formulations are rigorous and well-founded.', 'The proposed framework has potential applications demonstrated through case studies.']","['The paper is densely written and difficult to follow, especially for readers not well-versed in differential geometry and information theory.', 'The experimental validation is limited; more case studies and ablation studies are needed.', 'The clarity of the mathematical exposition and implementation details could be improved.', 'The practical implications and performance benefits are not thoroughly discussed.', 'The paper does not adequately address limitations, potential negative societal impacts, and ethical considerations.']",3,3,2,3,Reject
bTteFbU99ye,"The paper introduces a methodology to evaluate the estimation performance of neural language models (LMs) on rare events by using generative models trained on natural data as artificial languages. These artificial languages allow for exact computation of sequence probabilities, enabling a detailed comparison of LM estimates to true probabilities. The study uncovers systematic underestimation of sequence probabilities by LMs, particularly for less probable sequences, and overestimation of ill-formed sequences.","['How do the findings compare with other evaluation metrics or benchmarks for language models?', 'Can the methodology be extended to more closely mimic the complexities of natural language?', 'Can the authors provide more details on how the artificial languages are generated and justify their representativeness of natural language distributions?', 'How do different model architectures and hyperparameters affect the underestimation and overestimation tendencies observed in the experiments?', 'Can the authors clarify the steps taken to ensure the robustness and generalizability of their findings across different generative models and artificial languages?', 'How do the authors ensure that the artificial languages generated by the Transformer LM are representative of natural language distributions?', 'Can the authors provide more clarity on the perturbation process and how the sequences are evaluated under different perturbation levels?', 'Have the authors considered using different models or configurations for the ground truth to test the robustness of their findings?', 'Are there any practical methods or strategies that could mitigate the underestimation of rare sequences identified in this study?', 'Can the authors clarify the potential limitations of using artificial languages for evaluating language models?', 'Can you discuss the practical implications of your findings for real-world applications such as machine translation or text generation?', 'Have you considered any potential solutions or mitigations for the underestimation and overestimation issues identified?', 'How do you think the use of artificial languages impacts the generalizability of your findings to natural languages?']","['The artificial nature of the ground-truth models and the lack of comparison with other benchmarks limit the practical application of the findings.', 'The use of artificial languages, while innovative, may not fully capture the complexities of natural language distributions.', 'The study does not propose or explore potential methods to address the identified issues, such as underestimation of rare sequences.', 'The ethical implications of using artificial languages for evaluation are not discussed, which is important given the potential impacts on model development and deployment.']",False,3,3,3,4,4,"['Novel approach to evaluate LMs using artificial languages with exact sequence probabilities.', 'Comprehensive experiments with both LSTM and Transformer architectures.', 'Detailed analysis of estimation errors across training time, data quantity, and perturbations.', 'Addresses a critical issue in language modeling: the estimation of probabilities for rare sequences.']","['Artificial ground-truth models may not fully capture the complexities of natural language.', 'Lack of comparison with other evaluation metrics or benchmarks to contextualize findings.', 'Limited discussion on practical implications and potential improvements for LMs based on results.', 'The paper lacks clarity in several sections, making it difficult to follow the methodological details and understand the implications of the results.', 'The choice of artificial language generation and its representativeness of natural language distributions could be better justified and elaborated.', 'The experiments could be more robust by including more variations in the generative models and artificial languages to ensure the generalizability of the findings.', 'No discussion on the potential limitations and ethical implications of the proposed evaluation methodology.']",3,3,3,3,Reject
dIVrWHP9_1i,"The paper proposes G-Mixup, a novel graph data augmentation method that mixes graphons (graph generators) of different classes to generate synthetic graphs. This approach aims to enhance the generalization and robustness of Graph Neural Networks (GNNs). The method includes estimating graphons for each class, mixing these graphons, and generating synthetic graphs based on the mixed graphons. Theoretical analysis and empirical results demonstrate the effectiveness of G-Mixup in improving the performance and robustness of GNNs on various datasets.","['Can the authors provide more details on the implementation of graphon estimation and the generation of synthetic graphs?', 'How sensitive is G-Mixup to different hyperparameters, such as the number of nodes in the generated graphs or the value of λ?', 'Can the authors clarify any assumptions made in the theoretical analysis and how these might impact the generalizability of the results?', 'How does G-Mixup compare with other graph data augmentation methods like GraphAug and GraphMix?', 'Can the authors provide more intuitive explanations and visualizations of the graphon estimation and mixing process?', 'Have the authors tested the proposed method on more diverse datasets beyond those presented?', 'What are the potential limitations and societal impacts of G-Mixup?', 'Can the authors provide more details on the computational complexity and scalability of G-Mixup?', 'How does G-Mixup perform under different types of adversarial attacks and noise conditions?', 'Can the authors provide more intuitive explanations and examples for the theoretical guarantees?', 'Can the authors provide more detailed ablation studies to understand the contribution of each component?', 'Can the authors include more recent and advanced graph augmentation techniques in the comparison?', 'Can the authors simplify the theoretical proofs or provide a more intuitive explanation?', 'Can the authors provide more detailed implementation details or pseudocode for better reproducibility?', 'Can the authors discuss potential negative societal impacts of their work?']","['The paper could provide more detailed implementation guidelines to ensure reproducibility.', 'Some assumptions in the theoretical analysis need further clarification.', 'The paper lacks detailed ablation studies.', 'Theoretical proofs are complex and not easily understandable.', 'Limited comparison with more recent graph augmentation techniques.', 'Some parts of the methodology are not very clear.', 'The method relies on accurate graphon estimation, which may introduce complexity and potential inaccuracies.', 'The paper lacks a detailed discussion on the limitations and potential pitfalls of the proposed approach.', 'Additional ablation studies are needed to explore the impact of different hyperparameters and graphon estimation methods.']",False,3,3,3,7,4,"['The idea of using graphons for mixing graph data is novel and addresses the challenges posed by the irregular, unaligned, and non-Euclidean nature of graph data.', 'Theoretical analysis provides a solid foundation for the proposed method, ensuring that the synthetic graphs preserve key characteristics of the original graphs.', 'Extensive experiments on multiple datasets and GNN architectures show substantial improvements in performance and robustness.', 'The paper addresses an important problem in graph data augmentation.']","['The implementation details of graphon estimation and the generation of synthetic graphs could be elaborated further to facilitate reproducibility.', 'The paper could benefit from additional ablation studies to understand the impact of different hyperparameters and choices in the G-Mixup method.', 'Some aspects of the theoretical analysis, such as the assumptions made, could be clarified further.', 'Theoretical proofs are complex and may not be easily understandable.', 'Limited comparison with more recent and advanced graph augmentation techniques.', 'Some parts of the methodology, especially the implementation details, are not very clear.', 'No discussion on potential negative societal impacts.']",3,3,3,4,Reject
FFGDKzLasUa,"The paper proposes a novel model-agnostic meta-learning approach using deep networks with stochastic local winner-takes-all (LWTA) activations. This method introduces stochasticity and sparsity in the learned representations, which is claimed to enhance generalization and reduce model size. The approach is evaluated on standard benchmarks, showing improved accuracy and efficiency compared to existing methods.","['Can the authors provide more details on the variational Bayes treatment and the specific implementation steps?', 'How does the choice of the number of blocks and units per block affect the performance?', 'Can the authors provide more ablation studies to analyze the impact of different components of their model?', 'Can the authors provide more details on the autoencoder aggregator and its role in the proposed method?', 'How does the approach scale to larger datasets and more complex tasks?', 'Can the authors discuss the impact of different hyperparameters on the performance of the model?', 'How were the hyperparameters (e.g., Gumbel-Softmax temperature, weight priors) selected, and how sensitive is the performance to these choices?', 'What are the qualitative differences between the proposed method and other state-of-the-art methods in terms of learned representations?', 'What is the computational overhead during prediction with increased sample size B?']","[""The model's complexity and the specific scenarios where the approach may not be as effective should be addressed."", 'The scalability of the approach to larger datasets and more complex tasks is not discussed.', 'The potential negative societal impacts of the method are not addressed.', 'The paper lacks a thorough discussion of its limitations and potential negative societal impacts.']",False,3,3,3,6,4,"['The use of stochastic LWTA units for model-agnostic meta-learning is a novel and significant contribution.', 'Comprehensive experimental evaluation showing improved performance on several standard benchmarks.', 'The approach results in a reduced model size, which is a practical advantage.']","['The paper could benefit from clearer explanations of the variational Bayes treatment and implementation details.', 'More detailed ablation studies and analysis of the design choices would strengthen the paper.', 'The practical impact on real-world applications remains to be demonstrated.', 'The explanation of the autoencoder aggregator is not very clear and needs more detail.', 'The impact of different types of modulation functions and aggregators is not fully explored in the ablation studies.', 'The computational overhead during prediction, especially with increased sample size B, is a concern that needs more discussion.']",4,3,3,4,Reject
ahi2XSHpAUZ,"The paper proposes WEAKM3D, a method for weakly supervised monocular 3D object detection that leverages 2D detections to segment LiDAR point clouds and use these as weak supervision. The method introduces novel loss functions to handle challenges like alignment ambiguity and unevenly distributed LiDAR points. Extensive experiments on the KITTI dataset show that WEAKM3D outperforms some fully supervised methods.","['Can the authors provide more details about the autoencoder aggregator used in the method?', 'What would be the impact of using different modulation functions or aggregators on the performance of the proposed method?', 'Can the authors provide more qualitative examples, especially failure cases, to better understand the limitations of the method?', 'Have you considered evaluating the method on other datasets or with more varied baselines to comprehensively assess its performance?', 'Can the authors provide more implementation details for the geometric alignment and ray tracing losses?', 'How does the method perform in scenarios with very sparse or noisy LiDAR data?', 'Can the authors expand on the clustering and filtering process for object-LiDAR-points?']","['The method relies on pre-trained 2D detectors and LiDAR point clouds, which may limit its applicability in scenarios where such data is not available.', 'The complexity of the loss functions and the handling of faraway and small objects with sparse LiDAR points are not discussed in sufficient detail.', 'The reliance on LiDAR data during training could be a significant limitation in practical scenarios due to the high cost and difficulty of collecting such data.', ""The method's performance under different conditions (e.g., varying object types, occlusions) is not well-explored.""]",False,3,2,3,6,4,"['Addresses a significant problem in monocular 3D object detection by reducing the dependency on expensive 3D box annotations.', 'Proposes novel loss functions and strategies to handle challenges posed by weak supervision, such as alignment ambiguity and unevenly distributed LiDAR points.', 'Experimental results on the KITTI dataset are impressive, showing that the method can outperform some fully supervised methods.', 'Provides a detailed ablation study to validate the effectiveness of each proposed component.']","['The explanation of certain components, such as the autoencoder aggregator and the process of obtaining object-LiDAR-points, is not very clear and could benefit from more detailed descriptions.', 'The complexity of the proposed loss functions might make the approach less accessible to practitioners.', ""While the paper provides a comparison with some fully supervised methods, it would be beneficial to include more varied baselines to comprehensively evaluate the method's performance."", ""The method's limitations, especially in terms of handling faraway and small objects with sparse LiDAR points, could be discussed in more depth."", 'The reliance on LiDAR data for weak supervision contradicts the goal of reducing annotation costs, as LiDAR data collection is also expensive.']",3,3,2,3,Reject
EZNOb_uNpJk,"The paper introduces ClimateGAN, a generative model aimed at creating photo-realistic images of floods on street-level scenes to raise awareness about climate change. The framework consists of two main components: a Masker that predicts flood masks and a Painter that generates water textures conditioned on these masks. The paper also introduces a comprehensive dataset of simulated and real flood images and provides a detailed evaluation of the model's performance.","['Can you provide more details on the architecture and training process of the Masker and Painter components?', 'Have you considered different types of aggregators and modulation functions in your ablation studies?', 'Can you address the ethical considerations and potential negative societal impacts of your work more thoroughly?', 'How does the model generalize to different types of flooding?', 'What are the potential biases introduced by the training data?', 'What is the computational complexity and scalability of the approach?', 'How do the subjective evaluation metrics (error rate, F05 score, edge coherence) correlate with human perception of the generated images?', 'Can the authors provide more robust evidence to suggest that the generated images would indeed lead to increased awareness or behavioral change?', 'What measures are in place to prevent the misuse of generated images?']","['The clarity of the paper needs improvement, especially in the detailed explanation of the components and the training process.', 'Additional ablation studies are needed to explore different variations of the model.', 'Ethical considerations and potential negative societal impacts should be addressed more thoroughly.', 'The evaluation methodology needs to be more robust and well-justified.', 'The generalizability of the model to different types of flooding and potential biases in the training data should be discussed.']",True,2,2,2,4,4,"['The task addressed is socially relevant and could have a significant impact on climate change awareness.', 'The paper introduces a novel framework for generating flood images, leveraging advanced techniques in conditional image synthesis and domain adaptation.', 'A comprehensive dataset of simulated and real flood images is provided, which could be valuable for future research.', 'Thorough evaluation methods are adopted, including both quantitative metrics and human evaluations.']","['The paper lacks clarity in some sections, particularly in the detailed explanation of the Masker and Painter components, as well as the loss functions and ablation studies.', 'The evaluation methodology, particularly the human evaluation and the choice of metrics, is insufficiently robust and not well-justified.', 'Ethical considerations and potential negative societal impacts are not adequately addressed.', 'The generalizability of the model to different types of flooding and potential biases in the training data are not discussed.', 'The significance of the paper is questionable, with insufficient evidence to suggest that the generated images would lead to increased awareness or behavioral change.']",3,2,2,3,Reject
FKp8-pIRo3y,"The paper presents HinDRL, a method combining demonstration-driven reinforcement learning with hindsight goal selection to solve long-horizon dexterous manipulation tasks. The approach leverages task-relevant goal distributions derived from successful demonstrations to guide exploration and improve performance in settings with sparse rewards. The method is evaluated on complex robotic manipulation tasks and shows significant performance improvements over existing baselines.","['Can you provide additional details on the autoencoder aggregator?', 'How do different modulation functions impact the performance?', 'What is the performance impact of changing the type of aggregators used?', 'Please provide more details about the encoder and how it is trained.', 'How does the method perform with different numbers of demonstrations?', 'Can you provide more examples or visualizations to illustrate the process of goal selection?', 'What are the potential limitations of the approach, and how does it generalize to other tasks or domains?', 'What criteria were used to select the hyperparameters for the experiments?', 'Can the authors provide more details on the theoretical foundations of the proposed approach?', 'Can the authors include additional ablation studies to analyze the impact of different goal sampling strategies and the effect of varying the number of hindsight goal samples?', 'Can the authors provide information on the computational complexity and runtime of the proposed method compared to the baselines?']","['The clarity of the methodology section is a concern, particularly around technical details that are crucial for understanding the approach.', 'Additional ablation studies are recommended to explore the impact of different components of the method.', 'The paper should discuss potential limitations in terms of scalability and generalizability to other tasks or domains.', 'The impact of different parameters and the robustness of the method under various conditions should be analyzed in more depth.', 'The paper does not sufficiently address the potential limitations and negative societal impacts of the proposed method. Further discussion on the scalability and generalizability of the method to other tasks and environments would be beneficial.']",False,3,2,3,5,4,"['Addresses a significant problem in RL: long-horizon tasks with sparse rewards.', 'Novel combination of demonstration-driven RL with hindsight goal selection.', 'Comprehensive experimental evaluation on complex tasks with robust baselines.', 'Shows significant performance improvements and efficiency in terms of required demonstrations.']","['Clarity in methodology, particularly around the autoencoder aggregator and representation learning techniques, needs improvement.', 'Additional ablation studies are needed to explore modulation functions and the impact of different types of aggregators.', 'More qualitative examples and visualizations are necessary to strengthen the validity of the results.', 'Lacks a thorough theoretical analysis to support the empirical findings.', 'Limited discussion on the potential limitations, scalability, generalizability, and negative societal impacts of the proposed approach.']",3,3,2,4,Reject
GugZ5DzzAu,"The paper proposes enhancements to the MARINA method for distributed non-convex optimization by introducing correlated compressors and a new class of compressors termed PermK. The authors also introduce a new theoretical concept called Hessian variance, which refines the analysis of MARINA. Theoretical results show significant improvements in communication complexity, especially in the low Hessian variance regime. The paper includes thorough synthetic and practical experiments to validate the theoretical claims.","['Can the authors provide more practical implementation details of PermK compressors?', 'Can the authors include additional experiments on more diverse datasets?', 'Can the authors provide more insights into the practical implications when the Hessian variance is not small?', 'Can the authors clarify the assumptions made in the theoretical analysis and discuss their practical validity in more detail?', 'Can the authors provide additional clarifications or simplified explanations for the theoretical proofs?', 'Are there any practical examples or case studies that can illustrate the real-world applicability of the proposed methods?']","['The paper could be clearer in presenting key theoretical concepts.', 'Practical implementation details of PermK compressors are somewhat lacking.', 'The experiments could be more diverse.', 'The assumption of small Hessian variance may not hold in all practical scenarios, potentially limiting the applicability of the proposed method.', 'The complexity of the theoretical analysis may limit its accessibility to a broader audience.']",False,3,3,4,6,4,"['Novel extension of MARINA to support correlated compressors.', 'Introduction of Hessian variance offers a refined theoretical analysis.', 'PermK compressors demonstrate potential improvements in communication complexity.', 'Extensive theoretical analysis and empirical validation.']","['Clarity can be improved, especially in presenting key theoretical concepts.', 'Practical implementation details of PermK compressors are underexplored.', 'Experimental section would benefit from more diverse datasets.']",4,3,3,4,Accept
RQ428ZptQfU,"The paper proposes VaDeSC, a deep variational approach to clustering survival data. The method leverages a semi-supervised probabilistic model to uncover latent structures in survival data, addressing both covariates and censored survival times. The approach is validated through comprehensive experiments on synthetic, semi-synthetic, and real-world datasets, showing superior clustering performance and competitive time-to-event prediction capabilities. The application to medical imaging data further highlights its practical utility.","['Can the authors provide more detailed ablation studies, particularly investigating the modulation function and different types of aggregators?', 'Clarify the implementation details of the autoencoder aggregator.', 'Can the authors provide more qualitative examples in the analysis section?', 'Can the authors include more qualitative analyses and visualizations to support the quantitative results?']","['The paper could benefit from additional ablation studies and more clarity on certain implementation details. Providing more qualitative analysis would also strengthen the results.', 'The complexity of the method and datasets used may pose reproducibility challenges.', 'The model requires fixing a number of mixture components a priori.', 'The relationship between raw features and survival outcomes remains unclear.', 'Further directions include improving the interpretability of the model and a fully Bayesian treatment of global parameters.']",False,3,3,3,6,4,"['Addresses a relevant and practical problem in precision medicine.', 'Novel approach combining deep generative models with survival analysis.', 'Comprehensive experimental validation on multiple datasets.', 'Demonstrates practical applicability to medical imaging data.']","['More detailed ablation studies could enhance the quality of the paper.', 'Clarity on the autoencoder aggregator is needed.', 'Additional qualitative analysis of clustering results would be beneficial.', 'The paper is dense with technical details, making it difficult to read and understand.', 'Reproducibility could be a concern due to the complexity of the method and the datasets used.']",3,3,3,4,Reject
5Qkd7-bZfI,"The paper investigates the role of population heterogeneity in emergent communication within neural agent simulations. Specifically, it explores how varying the learning speeds of agents influences the structure and stability of emergent languages in a speaker-listener Lewis Game. The authors demonstrate that heterogeneous populations develop more stable and structured languages compared to homogeneous ones, thereby aligning simulation outcomes with sociolinguistic observations.","['Can the authors provide more details on how potential confounding factors were controlled in the experiments?', 'How generalizable are the findings to other settings or more complex tasks beyond the Lewis Game?', 'Can the authors conduct additional experiments varying other parameters (e.g., network capacity, communication network topology) to further isolate the effects of heterogeneity?', 'Can the authors provide more detailed explanations for the definitions and notations used in the paper?', 'How do the findings translate to more complex, real-world scenarios beyond the Lewis game?', 'Can the authors provide more insights into the connection between training speed asymmetry and human behavior?', 'How do the authors address potential negative societal impacts and ethical considerations of their work?']","['The paper primarily focuses on learning speed as the source of heterogeneity. Other factors such as network capacity or communication topology could also play a significant role and should be investigated.', 'The findings are based on a specific setup (the Lewis Game), and their generalizability to other settings is uncertain.', 'The study is limited to the Lewis Game setting. Extending this work to more complex environments would be valuable.', 'The implications for real-world human behavior are not fully addressed.']",False,3,3,3,5,4,"['Addresses a significant gap in the emergent communication literature by challenging the homogeneity assumption.', 'Provides empirical evidence that heterogeneity in learning speeds can lead to improved language properties.', 'Combines insights from sociolinguistics with computational simulations, contributing to a multidisciplinary understanding of language emergence.']","['The experimental design could benefit from additional baselines and comparisons, such as varying other parameters beyond learning speed to isolate their effects.', 'The clarity of the exposition is lacking in several places, particularly in the description of the experimental setup and the interpretation of results.', 'The significance of the findings is somewhat limited by the specific setup of the Lewis Game. It is unclear how generalizable these results are to other settings or more complex tasks.', 'The paper could benefit from more detailed discussions on potential confounding factors and how they were controlled.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.']",3,3,2,3,Reject
0JzqUlIVVDd,The paper proposes a novel domain adaptation method by leveraging the reverse Kullback-Leibler (KL) divergence to align the representation distributions of the source and target domains. The authors derive a generalization bound for the target loss based on the reverse KL divergence and propose an efficient algorithm that minimizes this term without requiring additional networks or adversarial objectives. Experimental results show that the proposed method outperforms several baseline methods on common domain adaptation datasets.,"['Can the authors provide more detailed ablation studies to understand the contribution of each component of the proposed method?', 'Can the authors clarify the experimental setup, including the hyperparameter tuning process and the evaluation protocol?', 'What are the limitations and potential negative societal impacts of the proposed method?', 'Can the authors provide more details on the practical implementation of the proposed method?', 'How does the method perform on a wider range of datasets and tasks?', 'Can the authors clarify the proofs and provide more intuitive explanations?', 'Can the authors provide more discussion on the limitations and potential failure cases of the proposed method?', 'How does the method perform on more complex and diverse datasets beyond those used in the experiments?', 'Can the authors provide more details on the sampling process for z during training and testing?', 'How does the performance vary with different choices of the representation distribution (other than Gaussian)?', 'Could additional ablation studies be provided to analyze the impact of the forward KL term more thoroughly?', 'Can the authors provide more details on the construction and training of the probabilistic representation network?', 'How does the choice of hyperparameters, such as the regularization coefficient β and the batch size, affect the performance of the proposed method?', 'Can the authors compare their method with state-of-the-art domain adaptation methods that are not limited to marginal alignment techniques?', 'What is the impact of the auxiliary forward KL term on the performance? Can the authors provide more insights into its role?']","['The paper does not adequately address the limitations and potential negative societal impacts of the proposed method. This should be included to provide a more balanced view of the work.', ""The method's effectiveness is dependent on the reverse KL divergence, which may not be universally applicable."", 'There are potential issues with the robustness of the method across different datasets and tasks.', 'The method assumes that the labeling mechanism does not change significantly between the source and target domains, which might not hold in many real-world scenarios.']",False,3,2,3,6,4,"['The paper addresses an important problem in domain adaptation and provides a novel approach using the reverse KL divergence.', 'The theoretical derivation of the generalization bound based on the reverse KL divergence is sound and well-explained.', 'The proposed method is efficient and does not require additional networks or adversarial objectives, which are common in other domain adaptation methods.', 'Comprehensive experiments are conducted on several common domain adaptation datasets, showing that the proposed method outperforms relevant baselines.']","['The paper could benefit from more in-depth ablation studies to better understand the contribution of each component of the proposed method.', 'The clarity of the paper could be improved, especially in the explanation of the proposed algorithm and the experimental setup.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed method.', 'Some of the experimental results show high variance, which raises concerns about the stability and robustness of the proposed method.', 'The originality of using KL divergence for domain adaptation is limited.', 'The practical implementation details are insufficiently detailed, particularly in the proofs and experimental settings.', 'The results, while promising, are not groundbreaking and do not significantly advance the state of the art.', ""The method's robustness across different datasets and settings is not fully convincing.""]",3,3,3,3,Reject
-6me0AsJVdu,"The paper introduces Mutation Validation (MV), a novel method for model validation using mutated training labels. MV aims to assess model fit by retraining models on data with mutated labels and measuring performance changes. The study explores the effectiveness of MV across various datasets and learning algorithms, showing potential advantages over traditional validation methods like cross-validation and test accuracy.","['Can the authors provide a more detailed theoretical justification for the chosen metamorphic relation and the empirical measurement formula?', 'How does the MV approach handle different types of label noise or adversarial attacks on the labels?', 'What is the computational overhead of MV compared to traditional validation methods, especially for large-scale datasets?', 'Can the authors provide a more rigorous theoretical foundation for MV?', 'How does the choice of mutation degree (η) affect the results? Can the authors provide an analysis with different values of η?', 'Can the authors clarify the experimental setup and provide detailed steps for reproducing the results?', 'How does MV compare with other advanced validation methods beyond cross-validation and test accuracy?', 'What are the potential negative societal impacts or ethical considerations of using MV?', 'Is there a way to simplify the explanation of MV and the associated equations for better reader comprehension?', ""Can the authors provide additional experiments or case studies to demonstrate MV's applicability in real-world scenarios?""]","['The paper does not adequately address the potential limitations of the MV approach, such as its robustness to different types of label noise and computational overhead.', 'There is a lack of discussion on potential negative societal impacts, particularly in scenarios where incorrect model validation could lead to significant consequences.', 'The theoretical foundation for MV is weak and needs more rigorous validation.', 'The paper lacks clarity in several parts, making it difficult to follow the methodology and reproduce the results.', 'The stability and repeatability of results need to be demonstrated more convincingly across diverse datasets and model types.']",False,2,2,2,3,4,"['Addresses a significant issue in model validation, particularly the limitations of cross-validation and test accuracy.', 'Proposes a novel and interesting methodology by applying concepts from software testing (mutation testing and metamorphic testing) to model validation.', 'Provides comprehensive experimental results across a variety of datasets and learning algorithms.', 'Demonstrates potential advantages of MV in terms of stability and accuracy in model selection and hyperparameter tuning.']","['The theoretical foundation and justification for the chosen metamorphic relation and measurement formula are not convincingly presented.', 'The clarity of the methodology is a concern; the process of mutating labels and calculating the MV score lacks detailed and precise explanation, which may hinder reproducibility.', 'The experimental results, while extensive, could benefit from additional baselines and comparisons, particularly with more advanced validation techniques beyond standard cross-validation and test accuracy.', ""Potential limitations and negative societal impacts are not adequately discussed. For instance, the approach's robustness to different types of label noise or adversarial label attacks is not thoroughly explored."", 'There is insufficient discussion on the computational overhead of MV compared to traditional methods, which could be a critical factor in practical applications.']",3,2,2,3,Reject
eIvzaLx6nKW,"The paper proposes Multi-Domain Self-Supervised Learning (MDSSL), which aims to enhance self-supervised learning by learning from multiple diverse datasets simultaneously. It introduces a three-level hierarchical loss function that ensures high-quality representations within each domain while promoting distinguishable representations across domains. The paper also presents an iterative clustering-based approach for scenarios where domain labels are unavailable.","['Can the authors provide more details on the clustering and robust clustering approaches?', 'How does the performance of MDSSL vary with different values of λ1 and λ2?', 'What are the potential limitations and negative societal impacts of the proposed method?']",['The paper does not discuss the potential limitations and negative societal impacts of the proposed method in detail.'],False,3,3,3,5,4,"['The problem of multi-domain self-supervised learning is well-motivated and relevant to real-world applications.', 'MDSSL introduces a novel hierarchical loss function that addresses both intra-domain and inter-domain representation learning.', 'The paper provides extensive experimental results demonstrating significant improvements over single-domain and multi-domain SimCLR baselines.', 'The proposed method is shown to be more efficient in terms of training time, memory, and compute resources.']","['The paper lacks clarity in the description of the proposed method, particularly in the clustering and robust clustering approaches.', 'The generalization claims are not thoroughly validated, especially for unseen datasets.', 'The paper does not provide enough ablation studies to understand the impact of different components of the proposed method.', 'There is limited discussion on the potential limitations and negative societal impacts of the proposed method.']",3,3,3,4,Reject
xnYACQquaGV,"The paper proposes Neural-LinUCB, a neural contextual bandit algorithm that decouples deep representation learning from shallow exploration using an upper confidence bound (UCB) approach. The algorithm achieves sublinear regret while being computationally efficient compared to existing neural bandit algorithms. The theoretical analysis is validated with empirical results on real-world datasets.","['Can the authors provide more justification or intuition behind Assumption 4.2?', 'How sensitive is the performance to the choice of hyperparameters like the step size and network width?', 'Can the authors provide more intuitive explanations or visual aids for the complex mathematical sections?', 'How practical are the assumptions, such as Assumption 4.2, in real-world scenarios?', 'What are the implications of the requirement for large network width on the generalizability of the results?', 'Can the authors provide additional empirical comparisons with other baseline algorithms and variants of the proposed algorithm?']","[""The paper's assumptions and conditions, such as Assumption 4.2 and the requirement for large network width, may limit the practical applicability and generalizability of the results. Addressing these assumptions and providing more intuitive explanations could enhance the paper's impact."", 'The paper lacks detailed ablation studies and empirical comparisons. Additionally, the clarity of certain sections needs improvement. Addressing these issues in the rebuttal period would strengthen the paper.']",False,3,3,3,6,4,"['Innovative approach combining deep representation learning with shallow exploration.', 'Theoretical guarantee with a sublinear regret bound.', 'Empirical validation showing improved performance and computational efficiency over existing methods.']","['Certain assumptions, such as Assumption 4.2 and the requirement for large network width, may limit practicality and generalizability.', 'Theoretical analysis, while rigorous, might be dense and challenging for readers not familiar with neural tangent kernels.', 'The paper could benefit from additional ablation studies to analyze the impact of different components of the algorithm.', 'The empirical comparison could be extended to include more baseline algorithms and variations of the proposed algorithm.']",3,3,3,4,Reject
qQuzhbU3Gto,The paper proposes a novel edge-independent graph generative model capable of capturing both heterophilous and homophilous structures using nonnegative embeddings. The model is theoretically validated for its expressiveness and empirically tested on tasks such as multi-label clustering and link prediction.,"['Can the authors provide more detailed explanations and possibly visual aids to clarify the methodology?', 'Could the experimental section be expanded to include more comprehensive evaluations and comparisons with additional baseline methods?', 'Are there any additional ablation studies that could be performed to better understand the contributions of different components of the model?', 'Can the authors provide more details on the computational efficiency of the three-stage optimization process?', 'How does the model scale to larger graphs beyond the datasets evaluated?', 'How does the model perform on extremely large or highly dynamic networks?', 'Can the authors provide more details on the autoencoder aggregator used in the second stage of the algorithm?', ""Could the authors include additional qualitative analysis examples in the rebuttal period to better illustrate the model's performance?"", 'What is the performance of the proposed model when varying the type of aggregators and modulation functions?']","[""The paper's clarity and the explanations of its methodology could be improved."", 'The experimental evaluations could be more comprehensive.', 'The computational efficiency and scalability of the model need more discussion.', ""The model's robustness in extremely large or dynamic networks is unclear.""]",False,3,3,3,7,4,"['Addresses the important problem of capturing heterophilous structures in graph generative models.', 'Provides interpretable nonnegative embeddings.', ""Theoretical results support the model's expressiveness and ability to reconstruct certain classes of graphs."", 'Empirical results show competitive performance in link prediction and clustering tasks.']","['The methodology section is dense and could benefit from clearer articulation and explanation.', 'The experimental section is relatively brief and lacks comprehensive evaluation and comparison with more baseline methods.', 'The paper could include more detailed ablation studies to evaluate the contributions of different components of the model.', 'Computational complexity and scalability of the model are not thoroughly discussed.']",3,3,3,4,Reject
SYuJXrXq8tw,"The paper investigates the use of sparsity in adversarial training to improve robust generalization, reduce robust overfitting, and enhance computational efficiency. The authors propose two methods: Robust Bird (RB) using static sparsity and Flying Bird (FB) using dynamic sparsity. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet with ResNet-18 and VGG-16 architectures demonstrate the effectiveness of the proposed methods.","['Can the authors provide more detailed justifications for the chosen update frequencies and sparsity levels?', 'How do the proposed methods compare to other recent efficient adversarial training methods that were not included in the baselines?', 'Can the authors clarify the impact of the proposed methods on standard accuracy across different datasets and architectures?', 'Can you provide more details on the hyperparameters used and their tuning?', 'Can you provide a more thorough theoretical justification for the proposed methods?', 'What are the potential negative societal impacts and ethical considerations of your proposed methods?', 'Can the authors provide more ablation studies to investigate the impact of different components and hyperparameters on the performance of the proposed methods?', 'Can the authors enhance the explanation of the autoencoder aggregator and other implementation details for better clarity?', 'Can the authors provide more cases and visualizations in the qualitative analysis to support their claims?']","['The paper should discuss the potential limitations and scenarios where the proposed methods might not be effective.', 'The impact on standard accuracy should be clearly presented and discussed.', 'The lack of detailed hyperparameter tuning information impacts reproducibility.', 'The paper does not address potential negative societal impacts and ethical considerations.', 'The paper could benefit from more detailed explanations and ablation studies to strengthen the claims.', 'The clarity of certain sections could be enhanced.']",False,3,2,3,5,4,"['Addresses a significant problem in adversarial training: robust generalization and computational efficiency.', 'Proposes novel methods for introducing sparsity in adversarial training.', 'Extensive experimental validation across multiple datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) and architectures (ResNet-18, VGG-16).', 'Significant improvements in robust generalization gaps and computational savings.']","['The methodological details, especially the rationale behind some choices (e.g., specific sparsity levels, update frequencies), need more thorough explanations.', 'Comparative baselines could be expanded to include more recent and relevant methods in adversarial training.', 'Some parts of the paper are dense and challenging to follow, requiring better organization and clarity.', 'Insufficient details on the hyperparameters and their tuning, which is crucial for reproducibility.', 'Theoretical justification of the proposed methods could be more thorough.', 'Potential negative societal impacts and ethical considerations are not discussed.']",3,3,2,3,Reject
O-r8LOR-CCA,"The paper introduces a novel open-world semi-supervised learning (SSL) setting where the unlabeled test data may contain classes not seen during training. The authors propose ORCA, a deep learning approach with an uncertainty adaptive margin mechanism to handle this problem. ORCA aims to reduce the gap between intra-class variance of seen and novel classes to improve classification accuracy on both. The paper demonstrates that ORCA outperforms several state-of-the-art baselines on multiple image classification and single-cell annotation datasets.","['Can you provide more details on how the uncertainty is estimated and its impact on the adaptive margin?', 'How robust is ORCA when the ratio of unknown classes in the unlabeled data varies significantly?', 'Can you elaborate on the choice of hyperparameters and their sensitivity?', 'Have you considered any other methods or variations for the margin adaptation technique?', 'Why was pretraining and data augmentation not used for the single-cell dataset, and how might this affect the results?', 'Could you provide more details on the uncertainty adaptive margin mechanism? Specifically, how is the margin updated during training?', 'Have you tried different types of aggregators or pretraining methods? What impact do they have on the performance?', 'Can you provide more failure cases or scenarios where ORCA does not perform as well? What are the potential limitations of the approach?', 'Can you provide more visualizations and qualitative examples to illustrate the effectiveness of the proposed method?', 'Could you elaborate further on the implementation details, particularly the estimation of the number of novel classes?']","['The paper lacks detailed discussion on the robustness of ORCA under varying conditions and sufficient implementation details for reproducibility.', 'The evaluation on the single-cell dataset could be improved by including pretraining and data augmentation.', 'The paper could benefit from more detailed ablation studies, especially regarding the adaptive margin mechanism and its impact on different datasets.', 'Clarity in the explanation of the method and additional visualizations or examples would help in understanding the effectiveness and potential limitations of ORCA.']",False,3,3,4,7,4,"['Addresses a relevant and practical problem in semi-supervised learning.', 'Introduces a novel approach (ORCA) with an innovative mechanism (uncertainty adaptive margin).', 'Comprehensive experimental results showing significant improvements over adapted baselines.', 'Well-organized and clearly written paper.', 'Extensive experiments on multiple datasets, including CIFAR-10, CIFAR-100, ImageNet, and a single-cell dataset, demonstrating substantial improvements over baselines.', 'Thorough comparison with various baseline methods, including novel class discovery, robust SSL, and open-set recognition.']","['Evaluation metrics heavily benchmarked against methods not designed for open-world SSL.', 'Insufficient details on implementation aspects, particularly around uncertainty estimation and hyperparameter choices.', 'Ablation studies could be more exhaustive, especially regarding margin adaptation techniques.', 'Robustness of ORCA under different settings of unknown class ratios and noise levels needs more thorough investigation.', 'The evaluation on the single-cell dataset lacks pretraining and data augmentation, which could limit the generalizability of the results to other domains.', 'The clarity of some sections, particularly the description of the uncertainty adaptive margin mechanism, could be improved.']",4,3,3,4,Accept
9u5E8AFudRx,"The paper presents a novel social interaction protocol, Help Me Explore (HME), and an agent architecture named GANGSTR to enhance the learning capabilities of autotelic agents. The HME protocol integrates social interactions with individual learning episodes, while GANGSTR leverages semantic graphs to decompose complex goals into sequences of intermediate sub-goals. The experiments demonstrate the effectiveness of the proposed methods in improving the agent's skill acquisition and goal-reaching capabilities.","['Can the authors provide more details on the implementation of the autoencoder aggregator and its role in the overall architecture?', 'What is the performance of the proposed model when changing the type of aggregators or modulation functions?', 'Can the authors provide more qualitative examples to support their claims, especially in terms of the learned semantic graph and its impact on performance?', 'Can the authors provide more details on the internalization mechanism and its implementation?', 'How is the semantic graph constructed, and what specific steps are involved in this process?', 'Could the authors conduct additional ablation studies to highlight the importance of different components of GANGSTR and HME?', 'Can the authors provide more visualizations of the learned configurations to enhance the qualitative analysis?', 'What are the broader implications and potential limitations of the HME protocol?']","['The paper does not provide sufficient clarity and detail in the methodological sections, which may hinder reproducibility.', 'The potential negative societal impacts of the work are not discussed, although the nature of the work suggests minimal direct negative impact.', 'The paper needs more comprehensive ablation studies and a clearer explanation of certain components.', 'The qualitative analysis is limited and could benefit from more examples and visualizations.', 'There is a lack of discussion on the limitations and potential negative societal impacts of the proposed approach.']",False,2,3,3,5,4,"['The paper addresses a significant issue in the field of autotelic agents: enhancing learning through social interactions.', 'The introduction of the HME protocol is novel and well-motivated.', ""GANGSTR's architecture, which uses semantic graphs, is innovative and shows promising results."", 'Comprehensive experimental results demonstrate the effectiveness of the proposed methods.']","['The clarity of the paper is lacking in several sections, particularly in the detailed description of the methodology and experiments.', 'The paper could benefit from additional ablation studies to better understand the contribution of each component of the proposed method.', 'The significance of the contributions in comparison to existing work is not strongly argued, and the novelty of the approach might be overstated without a thorough comparison to prior art.', 'The internalization mechanism and the construction of the semantic graph are not sufficiently detailed and clear.', ""The qualitative analysis presented in the paper is limited. More examples and visualizations would strengthen the paper's claims."", 'The broader implications and potential limitations of the HME protocol are not adequately discussed.']",3,3,3,4,Reject
EYCm0AFjaSS,"The paper proposes a deterministic initialization scheme called ZerO for residual networks, which initializes the weights with only zeros and ones, augmented with additional skip connections and Hadamard transforms. The method aims to improve reproducibility, allow network training without batch normalization, and achieve state-of-the-art performance on various image classification tasks, including CIFAR-10 and ImageNet.","[""Can the authors provide more detailed theoretical analysis to support the claims about ZerO's effectiveness?"", 'Can the authors clarify the explanation of the Hadamard transform and its role in avoiding training degeneracy?', 'What are the practical implications of the small performance gains achieved by ZerO?', 'What is the impact of additional skip connections on the risk of overfitting?', 'Can the authors include more comprehensive ablation studies to isolate the effects of the Hadamard transform and other components?', 'What are the potential limitations of ZerO in terms of scalability and application to other types of networks or tasks?', 'Are there any existing deterministic initialization methods, and how does ZerO compare to them?', 'Can the authors explore the applicability of ZerO to other types of neural networks?', 'What are the practical implications of the slight performance degradation observed in some experiments?', 'How does ZerO perform on a broader range of datasets beyond CIFAR-10 and ImageNet?', 'Can the authors clarify the technical details and improve the presentation to make the methodology more accessible and reproducible?']","['The paper does not discuss potential limitations of the proposed method, such as its applicability to other types of networks or its performance on tasks beyond image classification.', 'The potential negative societal impacts of the work are not addressed. The authors should discuss any ethical considerations, especially related to reproducibility and fairness in AI.', 'The added complexity of modifying ResNet architectures with extra skip connections and Hadamard transforms might limit the practical adoption of ZerO.']",False,2,2,2,4,4,"['The concept of deterministic initialization with zeros and ones is intriguing and addresses reproducibility issues.', 'The proposed deterministic initialization can improve reproducibility, which is crucial for scientific research and practical applications.', 'The paper includes comprehensive experiments on CIFAR-10 and ImageNet, demonstrating competitive performance with state-of-the-art methods.', 'The method shows potential for training networks without batch normalization, which could simplify the training process and reduce computational overhead.']","['The novelty of the proposed method is limited, as it primarily combines known techniques (skip connections and Hadamard transforms) in a new way.', 'The theoretical justification for the use of Hadamard transforms and additional skip connections, while intuitive, lacks rigorous mathematical analysis.', 'The paper lacks clarity in explaining how the Hadamard transform prevents degeneracy and its detailed impact on training dynamics.', 'The improvement margins in performance are relatively small, which may limit the practical significance of ZerO.', 'The experimental section could benefit from more comprehensive ablation studies to clearly isolate the effects of each component of the proposed method.', 'The paper does not adequately address the limitations and potential negative implications of the proposed approach, particularly in terms of scalability to other architectures and tasks.', 'The paper is difficult to follow due to dense and unclear technical descriptions, making it hard to reproduce the results.']",3,2,2,3,Reject
MTsBazXmX00,"The paper proposes a novel approach to target propagation (TP) using regularized inverses of network layers. This method is compared to traditional gradient back-propagation (BP) in terms of computational complexity and effectiveness for training recurrent neural networks (RNNs) on long sequences. The paper shows that TP can handle certain tasks better than BP, particularly those involving long sequences.","['Can the authors provide more extensive ablation studies to investigate the robustness and limitations of the proposed TP method?', 'How does the proposed TP method perform on a wider range of tasks and datasets beyond those presented in the paper?', 'Can the authors improve the clarity and organization of the paper, particularly the presentation of mathematical formulations?', 'Can you provide more details on how the regularized inversion is implemented, particularly in the context of the experiments?', 'How does the proposed method compare with other TP variants and alternative methods for addressing vanishing/exploding gradients in RNNs?', 'What are the potential limitations and failure cases of your approach?', 'Can you provide more detailed explanations and examples for the regularized inversion process?', 'Have you considered additional datasets or architectures for empirical validation?', 'Can you elaborate further on the relationship between your method and Gauss-Newton methods?', 'Can the authors provide more details on the choice of regularization parameters and the hyperparameter tuning process?', 'Can the authors clarify the mathematical derivations and provide more intuitive explanations where possible?', 'Can the authors include ablation studies to dissect the impact of individual components within the proposed method?', 'How does the proposed method scale to larger, more complex datasets?']","['The paper does not clearly address the limitations and potential negative societal impacts of the proposed method.', 'The experimental validation is limited in scope, focusing mainly on synthetic datasets and specific benchmarks.', 'The paper does not thoroughly discuss the limitations of the proposed method, such as its applicability to other types of neural networks beyond RNNs.', 'More experimental validation on diverse datasets is needed to confirm the general applicability of the method.']",False,3,2,2,5,4,"['The paper addresses an important issue in training neural networks, particularly RNNs, by proposing a theoretically justified variation of TP.', 'The use of regularized inverses is a novel approach that provides a different perspective on TP.', 'The paper provides detailed mathematical formulations and comparisons between TP and BP.', 'The computational complexity analysis is thorough and provides valuable insights into the potential benefits of the method.']","['The practical benefits of the proposed TP method are not clearly demonstrated across all tasks. The results are mixed, with TP outperforming BP in some tasks but not others.', 'The paper is dense with mathematical formulations, which might be difficult for readers to follow. The clarity and organization of the paper could be improved.', 'The significance and impact of the results are questionable. The experiments do not convincingly demonstrate that TP is a superior alternative to BP in general.', ""The paper lacks extensive ablation studies and sensitivity analyses to thoroughly investigate the proposed method's robustness and limitations."", 'The experimental validation is limited to a few datasets and architectures. More diverse and comprehensive experiments are needed to fully establish the benefits of the proposed method.', 'The paper does not adequately discuss potential limitations and failure cases of the proposed method.', 'The notation and mathematical formulation can be confusing at times, and the paper would benefit from a more thorough and clear presentation.', 'There is insufficient discussion on potential limitations and negative societal impacts of the proposed method.']",3,3,2,2,Reject
gjNcH0hj0LM,The paper introduces the Temporal Coherence-based Label Propagation (TCLP) framework for time-series active learning. TCLP leverages the temporal coherence property inherent in time-series data to propagate labels from queried data points to temporally adjacent data points. The proposed method aims to reduce labeling efforts while enhancing classification performance through accurate segment estimation using a quadratic plateau model.,"['Can the authors provide more detailed theoretical analysis on the plateau model parameter optimization?', 'Could the authors include more illustrative examples to explain the plateau model fitting process?', 'What are the performance implications of different types of time-series data on TCLP?', 'Can the authors provide a more detailed theoretical analysis of why TCLP outperforms existing methods?', 'Can more ablation studies be conducted to isolate the contributions of different components of TCLP?', 'How generalizable is the TCLP approach to other types of data or different domains?', 'Can the authors provide more details on the plateau model fitting process, specifically the optimization procedures and the choices of hyperparameters?', 'What is the impact of different modulation functions and types of aggregators on the performance of TCLP?', 'Can the authors provide additional qualitative examples to further illustrate the effectiveness of TCLP?']","['The robustness of the method across different types of time-series data could be explored further.', 'The primary limitations relate to the clarity of the paper and the lack of detailed theoretical analysis and ablation studies.', 'The paper does not discuss the scalability of TCLP to very large datasets or its performance on different types of time-series data. Additionally, potential negative societal impacts are not addressed.', 'The novelty of the method is somewhat incremental, and the theoretical analysis is limited. Improved clarity around the implementation details and further ablation studies could strengthen the paper.', 'The paper acknowledges the sparsity of labeled data points and proposes techniques to handle this. However, the real-world applicability in highly sparse labeling scenarios remains a concern.', 'The computational complexity of TCLP is briefly mentioned but could be more thoroughly analyzed in comparison with other methods.']",False,3,3,3,6,4,"['Addresses the critical issue of labeling cost in time-series data.', 'Introduces a novel label propagation method using a plateau model.', 'Comprehensive experimental evaluation showing significant improvements in classification accuracy.', 'Framework is flexible and can be combined with various query selection strategies.', 'The problem of time-series active learning is well-motivated, addressing a significant challenge in leveraging time-series data effectively.', 'The proposed TCLP framework is innovative, utilizing temporal coherence to propagate labels efficiently within time-series data.', 'Extensive experiments demonstrate the effectiveness of TCLP, showing significant improvements in classification accuracy with minimal label queries.', ""The paper provides a comprehensive comparison with existing label propagation methods, highlighting TCLP's advantages.""]","['The theoretical analysis of the plateau model fitting and parameter optimization could be more detailed.', 'Certain sections, particularly those explaining the plateau model, could be clearer.', 'More illustrative examples and ablation studies would strengthen the paper.', 'The paper lacks a detailed theoretical analysis explaining why TCLP outperforms existing methods.', 'Some sections of the paper are overly complex and could benefit from simplification and more intuitive explanations.', 'The generalizability of the approach to other types of data or different domains is not clear.', 'The methodology section lacks clarity in some parts, particularly in the details of the plateau model fitting and the specific choices of hyperparameters.', 'Potential limitations of the approach, including its scalability and performance on different types of time-series data, are not adequately discussed.']",3,3,3,4,Reject
wu5yYUutDGW,"The paper proposes Boundary-aware Self-Supervised Learning (BaSSL), a novel self-supervised learning framework for video scene segmentation. The approach involves discovering pseudo-boundaries in video sequences using dynamic time warping (DTW) and designing three novel pretext tasks: Shot-Scene Matching (SSM), Contextual Group Matching (CGM), and Pseudo-boundary Prediction (PP). The method achieves state-of-the-art results on the MovieNet-SSeg benchmark.","['Can you provide more details and clarity on the pseudo-boundary discovery method using DTW?', 'Have you considered evaluating the proposed method on other datasets to demonstrate its generalizability?', 'Can you discuss the computational complexity and efficiency of the proposed method in more detail?', 'How do you plan to address the potential overfitting due to longer pre-training?', 'Can you provide more detailed explanations of the pseudo-boundary discovery method and the pretext tasks?', 'Can you include more detailed ablation studies to better understand the contribution of each component of the proposed method?', 'Can you provide more detailed experimental settings and implementation details for reproducibility?', 'Can you provide more details on the implementation of the pseudo-boundary discovery method using DTW? A pseudocode or a more detailed algorithm description would be helpful.', 'The architecture of the contextual relation network (CRN) is not well-explained. Can you provide more details on this component?', 'The paper mentions that the shot encoder is based on ResNet-50, but it is not clear how it is modified or used in the context of this framework. Can you provide more details on this?', 'The results show that BaSSL outperforms other methods, but the paper lacks a detailed analysis of why this is the case. Can you provide more insights into the strengths of BaSSL compared to the baselines?', 'Can you provide more rigorous justification and comparison for the use of pseudo-boundaries?', 'Can you clarify the detailed implementation of the pretext tasks and the overall framework?', 'Can you provide more comprehensive ablation studies and comparisons with state-of-the-art methods?']","['The paper should provide more details on the pseudo-boundary discovery method and conduct more detailed ablation studies on the individual components. The computational complexity and efficiency should also be discussed, along with evaluations on other datasets to demonstrate the generalizability of the proposed method.', 'The main limitation is the complexity of the proposed method, which might make it difficult to implement and reproduce. Additionally, the clarity of the paper could be improved to better explain the methodology and experimental settings.', 'The paper does not adequately address the limitations of the proposed method. For example, the computational cost of the DTW-based pseudo-boundary discovery method is not discussed.', 'The potential negative societal impacts of the work are not mentioned. For instance, the use of large-scale video data for training might raise privacy concerns.']",False,3,3,3,5,4,"['The problem tackled is significant and relevant for video understanding tasks.', 'The proposed pretext tasks are novel and well-designed to address the video scene segmentation problem.', 'Comprehensive experiments and ablation studies demonstrate the effectiveness of the approach.', 'The method achieves state-of-the-art performance on the MovieNet-SSeg benchmark.']","['The pseudo-boundary discovery method using dynamic time warping (DTW) lacks clarity and detailed explanation.', 'More detailed ablation studies on the individual components of the framework are necessary to understand their contributions better.', 'The potential overfitting due to longer pre-training should be addressed and discussed.', 'The computational complexity and efficiency of the proposed method are not discussed in detail.', 'The effectiveness of the proposed method on other datasets should be evaluated to demonstrate its generalizability.', 'The paper lacks clarity in some sections, making it difficult to follow the methodology and reproduce the results.', 'Some critical details, such as the implementation of the pseudo-boundary discovery method and the specific architecture of the contextual relation network, are not well-explained.', 'The novelty of the approach, particularly the use of pseudo-boundaries, needs more rigorous justification and comparison with existing methods.']",3,3,3,4,Reject
qyzTEWWM0Pp,"The paper introduces Multiresolution Equivariant Graph Variational Autoencoders (MGVAE), a hierarchical generative model for graphs that ensures permutation equivariance. MGVAE employs higher-order message passing to encode graphs and learns to partition them into clusters, creating a hierarchy of latent distributions. The model is evaluated on tasks such as molecular graph generation, link prediction, and graph-based image generation, showing competitive results.","['Can the authors provide more detailed explanations and clarifications on the clustering procedure and the higher-order message passing?', 'What are the specific hyperparameter settings used in the experiments? Can the authors provide more details on the experimental setup?', ""How does the model's performance compare to other state-of-the-art methods in terms of computational efficiency?"", 'Can the authors provide more detailed explanations of the model architecture and the training process, including the definitions of all notations used?', 'How does the proposed method distinguish itself from existing hierarchical and equivariant models in the literature?', 'Can the authors provide a detailed description of the experimental setup, including hyperparameter settings, evaluation metrics, and any preprocessing steps?', 'What are the theoretical guarantees of the permutation-equivariance property in the proposed model?', 'How does the model perform on additional benchmark datasets not included in the paper?']","['The paper lacks clarity in several sections, making it challenging to understand and reproduce the work.', 'The clustering procedure and the higher-order message passing are not explained in sufficient detail.', 'The experimental setup and hyperparameter settings are not adequately described.', 'The paper does not thoroughly address the limitations and potential negative societal impacts of the work. It would benefit from a more detailed discussion on these aspects.', 'The paper does not sufficiently address the scalability and practical applicability of the proposed framework in real-world scenarios.', ""The lack of thorough comparisons with state-of-the-art methods in some tasks limits the understanding of the framework's empirical significance."", 'The societal impacts of the method, particularly in the context of molecular generation and drug discovery, are not discussed.']",False,2,2,2,3,4,"['The paper addresses an important problem in graph generation, introducing a novel generative model that ensures permutation equivariance.', 'The proposed MGVAE model employs a hierarchical approach, leveraging multiresolution clustering and higher-order message passing.', 'Extensive experiments are conducted, showing competitive performance on various tasks, including molecular graph generation and link prediction.']","[""The paper's writing is often unclear, making it difficult to understand the contributions and reproduce the results."", 'Some explanations, especially concerning the clustering procedure and the higher-order message passing, lack clarity and detail.', 'The experimental section, while extensive, does not provide sufficient details on the experimental setup and hyperparameter settings.', 'The originality of the proposed method is questionable as it builds heavily on existing concepts such as VAEs, message passing networks, and hierarchical clustering without sufficiently distinguishing itself from prior work.', 'The quality of the experiments is undermined by insufficient details about the implementation, hyperparameter settings, and evaluation metrics. Reproducibility is a significant concern due to the lack of a comprehensive description of the experimental setup.', 'There are no substantial theoretical contributions or proofs provided to support the claims of permutation-equivariance and the benefits of multiresolution learning.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed method.']",3,2,2,3,Reject
ks_uMcTPyW4,"The paper proposes a model-based reinforcement learning framework designed to learn policies that can efficiently acquire necessary features while minimizing costs. This is particularly relevant for real-world applications where acquiring all features may be impractical or expensive, such as in medical diagnosis. The authors introduce a sequential variational autoencoder (VAE) for learning high-quality representations from partially observed states, which helps in optimizing both reward and feature acquisition costs. The framework is evaluated on a control task and a medical simulator, showing significant improvements over conventional baselines.","['Can you provide more details on the VAE architecture and its training process?', 'Have you considered additional domains for evaluation to better demonstrate generalization?', 'Could you provide more detailed ablations and comparisons with other baselines?', 'What is the impact of different hyperparameter settings on the performance of the proposed method?', 'Can the authors include additional ablation studies to isolate the contributions of different components?']","['The paper could benefit from additional clarity in explaining the VAE architecture and its training.', 'The evaluation is limited to two domains, which may affect the generalizability of the proposed method.', 'Further ablation studies are needed to understand the contributions of different components and hyperparameter choices.', 'The potential negative societal impacts, especially in sensitive domains like healthcare, should be addressed.']",False,3,3,3,6,4,"['Addresses a critical real-world problem of high-cost feature acquisition.', 'Introduces a novel approach by leveraging a sequential VAE to handle partially observed states.', 'Comprehensive experiments demonstrate the efficacy of the proposed method.', 'Shows significant improvements over conventional baselines in terms of task reward and feature acquisition efficiency.']","['The clarity of the paper could be improved, especially in explaining the VAE architecture and its training.', 'The evaluation mainly focuses on two domains, which may limit the generalization of the proposed method.', 'Some ablations and comparisons, such as different feature acquisition costs and other baselines, could be more detailed.', 'The impact of different hyperparameters on the performance of the sequential VAE and the RL policies is not thoroughly explored.']",3,3,3,4,Reject
qEGBB9YB31,"The paper introduces a novel approach to saliency by highlighting network parameters responsible for erroneous decisions instead of input features. The authors validate the effectiveness of the method through various experiments, including pruning and fine-tuning salient filters. The paper also presents an input-space saliency counterpart to study the interaction between image features and erroneous network components.","['Can the authors provide more details on the process of standardizing parameter saliency?', 'How does the proposed method compare to other state-of-the-art saliency methods?', 'Can the authors improve the presentation and organization of the experimental results?', 'Can the authors provide additional experiments or evidence to demonstrate the generalizability of the method to non-image data and non-CNN models?', 'What are the key differences and advantages of this method compared to existing gradient-based interpretability methods?']","['The paper primarily focuses on image datasets with CNNs. While the authors mention applicability to other domains, additional experiments are required to substantiate this claim.', ""The method's applicability to different data types and model architectures hasn't been explored."", 'The clarity and presentation of the paper could be improved to make the methodology and results easier to understand.']",False,3,3,3,6,4,"['Novel approach to saliency focusing on network parameters.', 'Robust validation experiments demonstrating practical utility.', 'Comprehensive analysis of nearest neighbors in saliency space, showing semantic similarity.', 'The method can identify semantically similar samples and uncover spurious correlations, making it useful for real-world applications.']","['The methodology could be better explained, particularly the process of standardizing parameter saliency.', 'Lack of comprehensive comparison with existing saliency methods in terms of quantitative metrics.', 'Limited evidence on the generalizability of the method to non-image data and non-CNN models.', 'The paper is dense with information, making it challenging to follow. A more streamlined presentation with clearer explanations would improve readability.', 'More detailed discussions on the limitations and potential negative societal impacts of the work are needed.']",4,3,3,4,Reject
eqaxDZg4MHw,"The paper investigates the generalization gap in visual reinforcement learning through a comprehensive empirical study using procedurally generated video games. It explores methods such as data augmentation, domain confusion, auxiliary tasks, hyperparameter sensitivity, and policy adaptation to understand and address the issue.","['Can the authors provide more detailed explanations and clearer organization for better readability?', 'Are there any novel methods or theoretical contributions that could be highlighted to strengthen the paper?', 'Could the authors provide more detailed explanations and visualizations of the experimental setups?', 'How do the proposed auxiliary tasks compare to other state-of-the-art methods in more diverse environments?', 'Can the authors discuss the potential for automated hyperparameter tuning to improve the practicality of their findings?', 'What are the specific limitations of the current data augmentation techniques, and how can they be addressed?', 'Can the authors provide more theoretical insights or analysis to support their empirical findings?', 'What are the specific justifications for the chosen methodologies and metrics?', 'How significant is the improvement when only fine-tuning specific layers compared to other methods?']","['One major limitation is the lack of novel methods or theoretical contributions. The authors primarily review existing techniques, which limits the significance of the work.', 'The paper should address the limitations regarding the need for manual hyperparameter tuning and the specificity of the findings to certain game environments.', 'The paper does not thoroughly address the limitations of its proposed methodologies. For example, the impact of hyperparameter selection is discussed, but no concrete solutions are offered for automated tuning.', 'The paper lacks theoretical analysis and could benefit from more detailed explanations of the methodologies and metrics.']",False,2,2,2,3,4,"['The paper addresses an important and relevant problem in reinforcement learning: the generalization gap.', 'The empirical study is extensive and covers a wide range of methods.', 'The paper provides valuable insights into the limitations and potential of existing techniques for improving generalization.']","['The clarity of the paper is lacking, with dense sections that could be better organized and more concise.', 'The novelty of the work is limited, as it primarily reviews existing techniques rather than proposing significantly novel methods.', 'The theoretical grounding is weak; the paper does not provide a deep theoretical analysis to support its findings.', 'The significance of the findings may not be strong enough to warrant acceptance in a top-tier venue without stronger theoretical contributions or more innovative solutions.']",2,3,2,2,Reject
hyuacPZQFb0,"The paper proposes ADATIME, a benchmarking suite for evaluating domain adaptation algorithms on time series data. It aims to standardize evaluation schemes, backbone architectures, and model selection strategies. The paper evaluates 10 state-of-the-art methods on 4 datasets across 20 cross-domain scenarios.","['Can you provide more details on the hyper-parameter ranges and the rationale behind their selection?', 'How do you ensure the fairness of the comparison between different UDA methods?', 'What are the primary challenges you observed when adapting visual UDA methods to time series data?', 'Can the authors provide more details on the implementation and rationale behind the autoencoder aggregator?', 'Could additional ablation studies be conducted to further explore the impact of different components of the proposed framework?', 'How does the proposed framework handle potential anomalies in the time series data?']","['The lack of novel contributions in terms of new algorithms or techniques.', 'The unclear justification for some choices in the experimental setup.', 'The clarity of certain sections, such as the descriptions of model selection approaches and the backbone network architectures, could be improved.', 'Some experimental details, including the rationale behind chosen hyper-parameter ranges, are not clearly explained.']",False,3,3,2,5,4,"['Addresses an underexplored area of domain adaptation in time series data.', 'Standardizes the evaluation framework for domain adaptation methods.', 'Provides practical insights into model selection without target domain labels.', 'Comprehensive experiments covering various datasets and scenarios.']","['Lacks detailed explanations of some experimental settings and hyper-parameter choices.', 'Relies heavily on existing methods without proposing novel algorithms.', 'The impact of the findings may be limited due to the absence of significant methodological contributions.', 'Some evaluation metrics and justifications for model selection approaches are not sufficiently clear.', 'The clarity of the paper needs improvement, especially regarding the detailed steps of the proposed framework and the ablation studies.', 'The experimental results, although extensive, could benefit from more in-depth analysis and additional ablation studies to strengthen the findings.']",2,3,3,3,Reject
RjMtFbmETG,"The paper introduces a new soft-greedy operator for reinforcement learning called resmax, which aims to balance exploration and exploitation more effectively than ε-greedy and softmax. The operator uses the suboptimality gap to assign probabilities to actions, avoiding the overemphasis issue of softmax and the complete randomness of ε-greedy. Theoretical proofs and empirical results are provided to support resmax's efficacy.","['Can the authors provide more detailed ablation studies to explore the behavior of resmax in different settings?', 'How does resmax compare to more advanced exploration strategies beyond ε-greedy and softmax?', 'Can the theoretical proofs be presented in a clearer manner, perhaps with more intuitive explanations or visual aids?', 'Can the authors provide more insights into the computational complexity of resmax compared to softmax and ε-greedy?', 'Could the authors conduct additional experiments in more diverse and complex environments to further validate the generalizability of resmax?', 'How does resmax perform in environments with continuous action spaces?', 'What are the computational overheads of using resmax in large-scale RL problems?', 'Can the authors provide more insights into why resmax outperforms the baselines in certain scenarios?']","['The paper does not fully explore the potential negative impacts of using resmax, particularly in more complex environments.', 'The significance of the performance improvement is not fully established, limiting the broader applicability of the proposed operator.', 'The paper needs additional empirical validation in more complex environments to demonstrate the generalizability of resmax.', 'Clarity around the implementation and ablation studies should be improved.', 'The paper does not adequately address the limitations of the proposed method. It would be beneficial to discuss potential drawbacks, such as the impact of highly stochastic rewards or environments with sparse rewards.']",False,3,2,3,5,4,"['The concept of using suboptimality gaps to inform action selection is novel and interesting.', 'The paper provides both theoretical and empirical evidence to support the proposed operator.', 'Resmax shows promising performance improvements over ε-greedy and softmax in certain environments.']","['The theoretical proofs, while rigorous, are dense and could be clearer.', ""The empirical results, although comprehensive, do not fully establish the operator's significance in more complex or real-world scenarios."", ""The ablation studies are limited and do not explore the operator's behavior in diverse settings."", 'The paper lacks a thorough comparison with more recent and advanced exploration strategies in deep reinforcement learning.', 'The computational complexity of resmax compared to other methods like softmax and ε-greedy is not thoroughly discussed.']",3,3,3,3,Reject
UgNQM-LcVpN,"The paper proposes a Modulated Fully Connected Layer (MFCL) inspired by biological neuromodulation to improve neural network robustness against missing and low-quality data. The MFCL adjusts weights based on an additional input representing data reliability. The approach is tested on multiple datasets, including healthcare data, and shows promising results in classification, regression, and imputation tasks.","['Can you provide more details on the modulation network architecture and its integration into the main network?', 'What are the potential limitations or failure cases of the MFCL approach?', 'Can you include more detailed ablation studies to understand the contribution of each component?', 'What is the computational overhead introduced by the modulation layer?', 'Can the authors provide a theoretical justification for the proposed modulation mechanism?', 'How does the proposed method compare statistically to state-of-the-art methods considering comprehensive significance testing?', 'Can the authors include more diverse datasets to demonstrate the generalizability of the approach?', 'How do the authors plan to address potential ethical issues related to bias amplification due to missing data?']","['The paper does not adequately explore the limitations or potential failure cases of the proposed method.', 'More detailed ablation studies would help clarify the contribution of each component of the MFCL.', 'The potential for bias amplification due to missing data is a significant ethical concern that needs thorough examination.', 'The generalizability of the proposed method to datasets beyond healthcare is not fully established.', 'The paper lacks a detailed discussion on the computational overhead introduced by the modulation layer and its impact on training and inference times.']",False,2,3,2,4,4,"['Addresses a significant real-world problem: handling missing and low-quality data in machine learning.', 'Inspiration from biological neuromodulation adds a novel and interesting perspective.', 'Extensive experimentation on various datasets showing the effectiveness of the proposed method.']","['The explanation of the modulation network architecture and its integration into the neural network could be clearer.', 'Lacks a deep dive into the potential limitations or failure cases of the MFCL approach.', 'Some results, particularly the imputation tasks, do not show significant improvements, raising questions about the generalizability of the method.', 'The paper could benefit from more detailed ablation studies to understand the contribution of each component.', 'The experimental setup and baseline comparisons need more detailed justification and explanation.', 'The paper does not adequately address potential negative societal impacts and ethical considerations of its approach.']",3,2,3,3,Reject
kcrIligNnl,"The paper proposes a novel method for generating molecular conformations by directly predicting atom coordinates using a variational auto-encoder (VAE) framework. This approach avoids the limitations of distance-based methods, such as triangle inequality violations. The method iteratively refines conformations and demonstrates superior performance on various benchmark datasets.","['Can the authors provide more details on the handling of molecules with rotatable rings?', 'What are the implications of fixing the variance parameter γ in the VAE framework? How does it affect the model performance?', 'Can the authors provide more comprehensive ablation studies, particularly regarding different components of the model architecture?', 'Can the authors provide additional ablation studies on the impact of the attentive node aggregation and conformation normalization?', 'Can the authors clarify the role and implementation details of the autoencoder aggregator?', 'Can the authors provide more qualitative analyses and visualizations of generated conformations to better illustrate the improvements?', 'How does the model perform on smaller datasets or molecules with fewer heavy atoms?', 'Can you provide more details on the architecture of the encoders and decoders in the main text?', 'How does the method handle symmetric atoms and permutation invariance?', 'Have you considered any ethical implications or potential societal impacts of your work?']","['The paper mentions the limitations of handling molecules with rotatable rings but does not provide a thorough solution or analysis of this issue.', 'The paper could benefit from more detailed explanations and clarity in the methodology section to make it more accessible to readers.', 'The current method does not address the permutation invariance of symmetric atoms, which is mentioned as future work.', 'The paper lacks a detailed discussion on the limitations of the proposed method, such as potential issues with scalability and generalization to larger and more complex molecules.', 'Potential societal impacts of the work are not discussed.']",False,3,2,3,5,4,"['Addresses a significant problem in molecular conformation generation with a novel approach.', 'Avoids the limitations of distance-based methods, such as triangle inequality violations.', 'The use of a VAE framework and a roto-translation invariant loss function is well-founded and appropriate for the task.', 'The method achieves state-of-the-art performance on multiple benchmark datasets, demonstrating its effectiveness and scalability.']","['Lacks clarity in some sections, particularly in the detailed descriptions of the model architecture and the training process.', 'Significant gaps in explaining how the proposed method handles edge cases, such as molecules with rotatable rings.', 'The comparison with baseline methods could be more exhaustive.', 'The ablation study is not comprehensive enough.', 'Does not address ethical considerations or potential societal impacts.']",3,3,2,3,Reject
Ub1BQTKiwqg,"The paper presents a novel method for training sparse neural networks using soft-thresholding of weights during training. The method decouples the weights used in the forward and backward paths, employs soft-thresholding to ensure smooth weight updates, and progressively increases the sparsity ratio during training. The approach aims to reduce the number of training cycles and improve accuracy at high sparsity rates.","['Can you provide more details on the soft-thresholding mechanism and how it is implemented?', 'Could you elaborate on the hyperparameters used in the experiments and how they were chosen?', 'What is the role of the autoencoder aggregator in the method, and how does it impact the results?', 'How does the proposed method perform on other datasets and architectures beyond ResNet-20, VGG-13, and ImageNet?', 'Can the authors include more ablation studies to isolate the effects of different components of their method?', 'What are the potential limitations and negative societal impacts of this approach?', 'How does the method handle the potential instability introduced by the non-persistent pruning?']","[""The paper needs to provide more clarity on the method and the hyperparameters used. Additional ablation studies on the impact of different hyperparameters and components would enhance the paper's quality."", 'The paper does not adequately address the potential limitations and negative societal impacts of the proposed method.', 'The authors should discuss how the method handles potential instability introduced by non-persistent pruning.']",False,2,2,2,4,4,"['The proposed method is novel and addresses the important problem of training sparse neural networks efficiently.', 'The idea of decoupling forward and backward paths with soft-thresholding is interesting and potentially impactful.', 'The method can potentially reduce the number of training cycles, which is computationally beneficial.', 'Comprehensive experiments demonstrate the effectiveness of the method compared to state-of-the-art techniques.']","['The presentation of the method is not very clear, especially the details of the soft-thresholding mechanism and the decoupling of weights in the forward and backward paths.', 'The paper lacks sufficient details on the hyperparameters and the autoencoder aggregator used in the experiments.', 'The experimental validation, while promising, is not comprehensive enough. More ablations and comparisons with a broader set of baselines could strengthen the claims.', 'The paper does not discuss the potential limitations and negative societal impacts of the proposed method.']",3,2,2,3,Reject
BRFWxcZfAdC,"The paper proposes a novel approach to lossy compression under distributional shifts, framing the problem as an optimal transport with an entropy constraint. It explores the trade-offs between compression rate and distortion with and without shared common randomness. The theoretical framework is validated through experiments on image super-resolution and denoising tasks.","['Can you provide more detailed explanations or derivations for the theoretical results, particularly those related to the entropy constraints?', 'How do the proposed methods perform in real-world scenarios with more complex data distributions and noise patterns?', 'Can you include more ablation studies to explore the sensitivity of the methods to different hyperparameters and settings?', 'What are the potential limitations and negative societal impacts of your work?']","['The paper does not extensively discuss the limitations of the proposed methods or their potential negative societal impacts. Addressing these aspects would provide a more balanced perspective.', ""The complexity of the theoretical formulations and the lack of clarity in some sections might limit the paper's accessibility."", 'The practical applications and implications are not fully explored.']",False,3,2,3,5,4,"['The paper addresses an important problem in lossy compression under distributional shifts.', 'The theoretical formulation is novel and provides a new perspective on optimal transport with entropy constraints.', 'The paper demonstrates the practical utility of shared common randomness in improving rate-distortion trade-offs.', 'Comprehensive experimental results validate the theoretical findings, showing the effectiveness of the proposed methods on real-world tasks.']","['The theoretical derivations, especially those related to the entropy constraints and optimal transport, are not always clearly explained and may be difficult for readers to follow.', 'The practical applicability of the proposed methods in real-world scenarios is not thoroughly discussed.', 'Additional ablation studies would strengthen the paper, particularly in exploring the sensitivity of the methods to different hyperparameters and settings.', 'The discussion of potential limitations and negative societal impacts is minimal and should be expanded.']",3,3,2,3,Reject
_ixHFNR-FZ,The paper explores the relationship between adversarial robustness and domain transferability from the perspective of function class regularization. It proposes a theoretical framework to provide sufficient conditions for domain transferability and supports the framework with empirical evidence. The paper challenges the assumption that adversarial robustness necessarily improves domain transferability and provides sufficient conditions under which this might not hold.,"['Can the authors provide more intuitive explanations and justifications for the key assumptions and conditions in the theoretical framework?', 'How do the authors ensure the tightness and validity of the upper bound on the relative domain transferability loss?', 'Can the authors provide more concrete examples or case studies that clearly illustrate the theoretical findings?', 'How do the empirical results specifically support or challenge the theoretical claims presented in the paper?', 'Can more diverse datasets and model architectures be included in the experiments?', 'How can practitioners leverage these theoretical findings in real-world scenarios? What are the practical implications of this work?']","['The paper does not adequately address the limitations of the proposed theoretical framework and the assumptions made.', 'The potential impact of these limitations on the generalizability and applicability of the findings is not discussed.', 'The primary limitation is the clarity of the theoretical sections, which could be challenging for readers to follow. Improving the explanations and providing more visual aids could help.', ""Further ablation studies and discussions on practical implications would enhance the paper's impact.""]",False,2,2,3,4,4,"['Addresses a critical and timely problem in machine learning.', 'Proposes a novel theoretical framework connecting regularization with domain transferability.', 'Provides extensive empirical validation to support theoretical claims.']","['The theoretical framework is complex and somewhat difficult to follow.', 'Assumptions and conditions for the theorems seem overly restrictive.', 'Experiments, while extensive, lack diversity in datasets and models.', 'Clarity and organization of the paper need significant improvement.', 'The connection between the theoretical analysis and the empirical results is not always well-articulated.', 'The paper does not sufficiently discuss the potential limitations and practical implications of its findings.']",3,3,2,3,Reject
C4o-EEUx-6,"The paper introduces Flashlight, a modular and minimalist machine learning library aimed at facilitating rapid prototyping and experimentation for systems researchers. It emphasizes simplicity, modularity, and performance, aiming to reduce the engineering burden on researchers and enable innovation in machine learning tools.","['Can the authors provide more detailed evaluations with varied real-world use cases?', 'Can the authors clarify certain components and improve the clarity of figures?', 'Can you provide more detailed discussion on the limitations and potential negative societal impacts of using Flashlight?', ""Are there any real-world use cases or examples of adoption that can be included to demonstrate the framework's practical impact?"", 'Can you expand the evaluation section to include more diverse benchmarks, such as varied model architectures and tasks?', 'Can the authors provide more detailed ablation studies to investigate the impact of different modular design choices?', 'Could the authors expand on the explanations and provide more examples for the Tensor interface and memory management components?', 'Are there other lightweight frameworks that Flashlight can be compared to?', 'Can the authors elaborate on the potential ethical considerations of developing such a framework?', 'Can the authors provide more in-depth analysis and results on the performance of individual components of Flashlight?', 'How does Flashlight handle real-world applications beyond the provided benchmarks?', 'Are there any limitations or challenges faced during the development and deployment of Flashlight?']","['The paper does not provide a comprehensive evaluation of the library across varied real-world use cases.', 'The paper does not address the limitations and potential negative societal impacts of using Flashlight in sufficient detail.', 'It lacks real-world use cases or examples of adoption, which would enhance the practical relevance of the framework.', 'The evaluation section could be more comprehensive by including a wider range of benchmarks and tasks.', 'The paper does not provide sufficient ablation studies and detailed explanations for some of the design choices, which could impact reproducibility and understanding.', 'The paper lacks extensive experimental validation and could benefit from more real-world use cases.', 'The authors should discuss the limitations of Flashlight, such as potential challenges in scaling for very large models or complex real-world applications.']",False,3,3,3,6,4,"['Addresses a real need for a more modular and lightweight machine learning library.', 'Focuses on simplicity and modularity, which can facilitate rapid prototyping and experimentation.', 'Provides initial performance benchmarks showing competitive results.', 'Includes state-of-the-art models and benchmarks, making it ready for practical use.']","['The concept of a modular machine learning library is not entirely new.', 'The evaluation could be more comprehensive, including more varied real-world use cases and comparisons.', 'Certain components and figures could be explained more clearly.', 'Lacks detailed discussion on limitations and potential negative societal impacts.', 'Some explanations regarding the modular design and interfaces are not sufficiently detailed.', 'Reproducibility might be challenging due to the lack of deeper explanations and examples for certain components.']",3,3,3,4,Reject
TBWA6PLJZQm,"The paper introduces two new benchmark datasets, CIFAR-10N and CIFAR-100N, with human-annotated noisy labels. These datasets aim to bridge the gap between synthetic and real-world noisy labels, providing a more realistic setting for evaluating learning algorithms. The paper also benchmarks various robust learning methods on these datasets and highlights the differences between human and synthetic label noise.","['Can the authors provide more details on the measures taken to ensure the quality and consistency of the annotations collected via Amazon Mechanical Turk?', 'Are there any plans to expand the dataset collection to other domains or larger-scale datasets?', 'What are the potential limitations of the new datasets, and how might they be addressed in future work?', 'How do the findings generalize to other types of data and tasks beyond CIFAR?', 'Could you provide more details on the data collection process and the behavior of workers on Amazon Mechanical Turk?', 'Can you include more ablation studies to understand the impact of different factors on the performance of the methods?', 'Can you provide more qualitative analysis and visualizations to support your findings?']","['The main contribution is the dataset itself, and while it is valuable, it does not introduce new algorithms or theoretical insights.', 'The quality of annotations might vary depending on the workers, which could impact the reliability of the benchmarks.', 'The study is limited to CIFAR datasets, and it is unclear if the findings apply to other data types.', 'The paper does not explore alternative noise models beyond instance-dependent and class-dependent noise.']",False,3,3,3,6,4,"['Addresses a significant gap by providing real-world noisy labels for CIFAR datasets.', 'Comprehensive experimental results and detailed analysis of noise patterns.', 'Publicly available datasets to facilitate future research and benchmarking.', 'Highlights important differences between synthetic and real-world noisy labels, emphasizing the instance-dependent nature of human noise.', 'Offers detailed qualitative and quantitative analyses of noisy labels.']","['Limited novelty in methodological contributions.', 'Potential concerns about the quality and consistency of annotations collected via Amazon Mechanical Turk.', 'The clarity of some sections, particularly the dataset collection process and the detailed statistics, could be improved.', 'Limited exploration of alternative noise models beyond the instance-dependent and class-dependent noise.', 'The paper could benefit from more detailed descriptions of the data collection process and the behavior of workers on Amazon Mechanical Turk.']",3,3,3,4,Accept
6u6N8WWwYSM,"The paper presents ReCo, a novel contrastive learning framework designed to enhance semantic segmentation. ReCo performs pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. The approach is built on top of existing segmentation networks and aims to improve segmentation boundaries and convergence speed. The method shows significant improvements, especially in semi-supervised learning with very few labels.","['Can the authors provide more details on the active sampling strategies used for queries and keys?', 'What is the impact of using different types of aggregators in the representation head?', 'Can the authors provide additional ablation studies to better isolate the contributions of different components of ReCo?', 'Have the authors considered any potential ethical implications of deploying this model in real-world settings?']","['The paper could benefit from additional ablation studies to isolate the contributions of each component of ReCo.', 'The ethical considerations of deploying such a model in real-world applications should be discussed.', 'The methodology section could be clearer, particularly regarding the active sampling strategies and the representation head.', 'The clarity of the explanation of the autoencoder aggregator needs improvement.']",False,3,3,3,6,4,"['The paper addresses a significant problem in semantic segmentation: the need for high-quality annotations and the challenge of learning from limited labeled data.', ""ReCo's novel approach to contrastive learning at a regional level is well-motivated and effectively captures both local and global semantic relationships."", 'The experimental results are comprehensive and show significant improvements over strong baselines, particularly in semi-supervised settings.', 'The method is easy to implement and requires minimal additional memory, making it practical for real-world applications.']","['The clarity of the methodology section could be improved, particularly regarding the details of the active sampling strategies and the representation head.', 'The paper lacks comprehensive ablation studies to isolate the contributions of different components of ReCo. This makes it difficult to understand the importance of each component.', 'The explanation of the autoencoder aggregator is not very clear and could benefit from more detailed descriptions and diagrams.', 'The qualitative analysis could be strengthened by providing more examples and visualizations.', 'The ethical considerations of deploying such a model in real-world applications are not discussed, which is an important aspect to consider.']",3,3,3,4,Reject
t5s-hd1bqLk,"The paper introduces a novel method for conditioning sequence-to-sequence models using dynamically learned activation functions based on conditioning vectors. The approach aims to achieve competitive performance while reducing model size, making it suitable for resource-constrained environments. The authors demonstrate the efficacy of their method on two tasks: personalized sound enhancement (PSE) and personalized ASR (PASR), with evaluations showing comparable or better performance than existing methods with reduced model parameters.","['Can the authors provide more details on the hyperparameter selection process, especially for the initialization of the dynamically learned coefficients?', 'How would the proposed method perform on tasks outside the audio domain, such as image processing or text generation?', 'Can the authors compare their method with a broader range of baselines, including other state-of-the-art conditioning techniques?', 'How does the proposed method perform under different hyperparameter settings?', 'Can the authors provide more detailed ablation studies to validate the effectiveness of the learned activation functions?', 'How does the proposed method compare to baseline methods in terms of computational efficiency and latency in real-world scenarios?', 'Can the authors provide more details on hyperparameter sensitivity?', 'Are there plans to evaluate this approach on other domains beyond audio?', 'Can the authors provide additional ablation studies to isolate the contributions of different components?', 'How does the method perform on other domains, such as image or text-based tasks?', 'Can you provide more details on the process for selecting and initializing the basic activation functions?', 'How does the approach handle cases where the enrollment data is noisy or of poor quality?', 'Can the authors provide a more detailed explanation of the conditioning mechanism and the role of learned activations?', 'What is the impact of different basic activation functions on the performance of the proposed method?', 'Can the authors provide more ablation studies to isolate the impact of different components of the proposed method?']","['The evaluation is limited to audio processing tasks. Future work should explore the method’s applicability to other domains.', 'The choice of hyperparameters and their initialization needs more detailed justification and exploration.', 'The paper does not provide a thorough discussion of the limitations and potential negative societal impacts of the proposed method.', 'The paper does not address potential overfitting to the specific datasets used.', 'The methodology section is dense and could benefit from clearer explanations.', 'The evaluation is restricted to clean enrollment data, which may not always be available in real-world scenarios.', 'The experiments are confined to supervised audio tasks, leaving the applicability to other domains untested.', 'The lack of clarity and additional ablation studies are also limitations that need to be addressed.']",False,3,2,3,5,4,"['The approach of using dynamically learned activation functions for conditioning is novel and addresses a practical need for resource-efficient models.', 'The paper provides thorough evaluations on two relevant tasks (PSE and PASR), showing the efficacy of the proposed method.', 'The authors demonstrate significant parameter reduction compared to traditional concatenation and modulation methods, which is beneficial for deployment on resource-constrained devices.']","['The methodology section could be clearer, particularly concerning the selection and initialization of hyperparameters for the learned activation functions.', 'The comparison is limited to concatenation and modulation methods. It would be beneficial to include more diverse baselines to paint a broader picture of the method’s effectiveness.', 'The evaluation is limited to specific domains (audio processing). The paper would benefit from exploring the applicability of the proposed method in other domains (e.g., image processing, text generation).', 'The novelty of the method is not clearly distinguished from existing approaches, and the claims of parameter reduction and performance improvement are not consistently supported by experimental results.', 'The paper lacks detailed ablation studies and hyperparameter sensitivity analyses, which are crucial for validating the proposed method.', 'The clarity of the paper is compromised by insufficient explanations of key concepts and methodologies.', 'The qualitative analysis is not thorough enough to convincingly demonstrate the advantages of the proposed method.', 'Limitations and potential negative societal impacts are not adequately addressed.']",3,3,2,3,Reject
1L0C5ROtFp,"The paper presents a method for learning counterfactual reasoning in physical processes from raw video data. The method uses a hybrid latent representation combining dense features, 2D keypoints, and additional latent vectors per keypoint. It introduces a new dataset for counterfactual prediction in pixel space and demonstrates the method's performance against strong baselines.","['Can you provide more detailed explanations of the proposed method, especially the architecture and training process?', 'Could you include additional ablation studies to investigate the effectiveness of each component of the proposed method?', 'What are the limitations of the proposed method, and how do you plan to address them in future work?', 'Can you discuss any potential negative societal impacts of your work?', 'Can the authors provide more details on the de-rendering module and the dynamic model? Specifically, how are the keypoints and coefficients integrated into the prediction process?', 'What would be the performance impact of removing the additional coefficients in the hybrid latent representation?', 'Can the authors provide more quantitative metrics for the qualitative results presented in the paper?', 'How does the model perform on other real-world datasets beyond the limited Blocktower IRL experiments?', 'Can the authors provide more details on the implementation and hyperparameter settings to ensure reproducibility?', 'Could the authors clarify the interaction between the dynamic model and latent space projections with more detailed explanations or visual aids?', 'What are the potential ethical considerations and societal impacts of this work?', 'Can the authors provide more details on the training process, particularly how the different components of the model are optimized?']","['The paper should discuss the limitations of the proposed method, such as potential failure cases or scenarios where the method might not perform well.', 'The potential negative societal impacts of the work should be addressed, especially given the focus on counterfactual reasoning.', 'The paper does not sufficiently explore the limitations of their model, especially in terms of generalizability to real-world data.', 'The ethical implications of deploying such a model in sensitive applications are not discussed.', 'The paper does not provide sufficient details on the implementation and hyperparameter settings, which may affect the reproducibility of the results.', 'The lack of ablation studies makes it difficult to understand the contribution of individual components to the overall performance.']",False,3,3,3,6,4,"['Addresses a significant and challenging problem of learning counterfactual reasoning in physics from raw video data.', 'Proposes a novel hybrid latent representation combining dense features, 2D keypoints, and additional latent vectors per keypoint.', 'Introduces a new dataset specifically designed for counterfactual prediction in pixel space.', 'Demonstrates strong performance against relevant baselines in physics-inspired machine learning and video prediction.']","['The clarity of the paper could be improved, especially in explaining the details of the proposed method and the experimental setup.', 'The paper lacks comprehensive ablation studies to thoroughly investigate the effectiveness of each component of the proposed method.', 'There is insufficient discussion on the limitations of the proposed method and potential negative societal impacts.', 'The presentation of results could be more organized, with clearer and more concise figures and tables.', ""The experiments on real-world data are minimal and do not provide a strong validation of the model's applicability outside the synthetic dataset.""]",3,3,3,4,Reject
ZFIT_sGjPJ,"The paper proposes a data-dependent randomized smoothing technique that optimizes the variance of the Gaussian distribution for each input to maximize the certification radius. It also introduces a memory-based certification mechanism to ensure certifiability despite the data-dependent nature of the smoothing. The approach shows significant improvements in certified accuracy on CIFAR10 and ImageNet datasets and is shown to integrate well with existing methods like COHEN, SMOOTHADV, and MACER.","['Can the authors provide more clarity on the computational complexity and scalability of the memory-based certification mechanism?', 'Can the authors include more ablation studies on key parameters like the number of iterations (K) and the number of samples (n) in the optimization process?', 'How does the memory-based certification handle large-scale datasets in terms of computational efficiency?', 'Could there be potential biases introduced by the data-dependent smoothing parameters?', 'Can the authors provide a more detailed analysis of the trade-offs involved in using data-dependent smoothing?', 'Can the authors provide more detailed experiments and analysis on extending the method to other norms, such as ℓ1 certification?']","['The paper does not adequately address the potential computational overhead and scalability issues introduced by the data-dependent optimization and memory-based certification.', 'The lack of ablation studies on key parameters makes it difficult to fully understand the robustness and generalizability of the proposed method.', 'The paper should provide more detailed experiments and analysis on extending the method to other norms, such as ℓ1 certification.']",False,3,3,3,6,4,"['The paper addresses an important issue in randomized smoothing by proposing a data-dependent approach, which is novel and practical.', 'Comprehensive experiments demonstrate the effectiveness of the proposed method, showing significant improvements in certified accuracy on CIFAR10 and ImageNet datasets.', 'The method is shown to be easily integrable into existing frameworks, enhancing their performance without requiring model retraining.']","['The data-dependent optimization and memory-based certification introduce significant computational overhead, which may not scale well with larger datasets and more complex models.', 'The clarity and readability of the paper could be improved, particularly in explaining the autoencoder aggregator and the memory-based certification mechanism.', 'Lack of ablation studies on key parameters such as the number of iterations (K) and the number of samples (n) in the optimization process makes it difficult to fully assess the robustness and generalizability of the proposed method.']",4,3,3,4,Reject
uEBrNNEfceE,The paper proposes an online algorithm for linear-quadratic dual control that guarantees asymptotic optimality in the almost sure sense. The method involves a safe switched control strategy and parameter inference based on the cross-correlation between exploration noise and system output. Theoretical guarantees are provided for parameter inference error and control performance suboptimality gap.,"['How does the proposed method compare to existing robust and adaptive control strategies in more detail?', 'What are the practical implications of the assumptions made in the theoretical analysis?', 'Can more diverse and realistic experiments be conducted to validate the method?', 'Can the authors provide more details on the impact of different noise models on the proposed approach?', 'How does the switching strategy perform in scenarios with varying system configurations and noise characteristics?', 'Can the authors elaborate on the computational efficiency and scalability of the parameter inference algorithm?', 'Can the authors provide more intuitive explanations for the key components of their method, such as the safe switching strategy?', 'What is the impact of different parameters (e.g., the decay rate β) on the performance of the algorithm?', 'Can additional ablation studies be conducted to isolate the contributions of different components of the algorithm?', 'Can the authors provide more details on the autoencoder aggregator and its role in the algorithm?', 'Could the authors include additional ablation studies to show the impact of different components of the proposed method?', 'Can more varied and detailed visualizations be provided to better illustrate the qualitative aspects of the method?']","['The paper needs clearer explanations and more intuitive guidance for the reader.', ""The experimental validation should be expanded to demonstrate the method's applicability in more diverse and realistic settings."", 'The dependency on the stability of the system and the computational overhead of the switching strategy are not thoroughly examined.', 'The paper would benefit from improved clarity and accessibility, particularly in explaining the mathematical proofs and key concepts.', 'Additional empirical validation in various scenarios would strengthen the paper’s claims.']",False,3,2,3,5,4,"['Addresses an important problem in optimal control and reinforcement learning.', 'Proposes a novel safe switching strategy to avoid destabilizing controllers.', 'Theoretical results provide asymptotic convergence guarantees for parameter inference error and control performance.', 'Rigorous theoretical analysis with detailed proofs.', 'Empirical evaluation demonstrates the effectiveness of the proposed strategy.']","['The novelty of the proposed method is not entirely clear compared to existing works.', 'Theoretical contributions are complex and rely on strong assumptions, making them difficult to verify.', ""Experimental validation is weak, with limited demonstration of the method's applicability."", 'The writing is dense and difficult to follow, with a need for clearer explanations and more intuitive guidance.', 'Practical implications of the switching mechanism are not thoroughly discussed.', 'Potential limitations in scenarios with different noise models or system configurations are not addressed.', 'Certain sections of the paper, especially the algorithm descriptions, could be made clearer with more intuitive explanations and visual aids.', 'Ablation studies are lacking, particularly concerning the impact of different parameters and components of the algorithm.']",3,3,2,3,Reject
JGO8CvG5S9,"The paper provides a novel theoretical framework for constrained universal approximation using probabilistic transformer networks. It addresses both convex and non-convex constraints and offers rigorous proofs to support its claims. The work is primarily theoretical, supported by extensive mathematical proofs and some empirical validation.","['Can the authors provide more details on the practical implementation of the proposed probabilistic transformer networks?', 'How does the proposed method compare with existing constrained learning approaches in terms of computational efficiency?', 'Can the authors provide empirical validation of the proposed method?', 'How does the proposed method compare with existing approaches in practical scenarios?', 'Can the authors provide more intuitive explanations and illustrative examples to improve clarity?']","['The paper should discuss potential limitations in the practical application of the proposed methods, including computational complexity and scalability.', 'The primary limitation is the lack of detailed empirical validation. The theoretical results are compelling, but their practical utility is uncertain without thorough empirical comparisons.', 'The paper does not sufficiently discuss the computational complexity and scalability of the proposed methods.']",False,2,2,3,4,4,"['The paper introduces a fresh perspective on the universal approximation with constrained outputs using transformers.', 'The mathematical framework and proof techniques are robust and leverage contemporary tools from metric geometry and optimal transport.', 'This work addresses an essential issue in practical applications where constraints must be respected, such as in finance and geometric deep learning.', 'The theoretical results are comprehensive and well-supported by rigorous proofs.']","['The paper is highly technical and may not be accessible to a broader audience even within the ML community.', 'While the paper mentions an empirical evaluation in the appendix, the main text lacks a detailed empirical section to validate the theoretical findings comprehensively.', 'Some sections could benefit from more intuitive explanations or visual aids to help readers grasp the complex theoretical concepts.', 'The focus on theoretical guarantees without practical experiments raises questions about the generalizability of the results to real-world problems.', 'There is a lack of comparative analysis with existing methods, which would help in understanding the practical advantages and limitations of the proposed approach.']",3,2,2,3,Reject
IEsx-jwFk3g,"The paper presents ReBraiD, a graph neural network model for dynamic brain activity modeling using fMRI and DWI scans. It introduces sample-level adaptive adjacency matrix learning, multi-resolution inner cluster smoothing, and integrated gradients for interpretability. The method shows superior performance in various experiments compared to existing approaches.","['Can the authors provide more details on the process of generating adaptive adjacency matrices?', 'How were the hyperparameters chosen for the ablation studies?', ""Could the authors provide more details about different choices of modulation functions and their impact on the model's performance?"", 'Can the authors elaborate on the design and hyperparameters of the autoencoder aggregator?', 'Could the authors include more visualizations and qualitative analyses to support their claims about interpretability?', 'What is the rationale behind using random adjacency matrices, and how do they compare with more conventional baselines?', 'Can the authors provide additional examples or datasets to validate the robustness of the proposed method?']","[""The paper's density and complexity might limit its accessibility."", 'Some methodological details could be further clarified.', 'The primary limitation is the need for more clarity and additional ablation studies to understand the robustness of the proposed techniques fully.', 'The potential impact on computational resources when scaling to larger datasets could be discussed.']",False,3,2,3,6,4,"['Addresses a significant and complex problem in modeling dynamic brain activities.', 'Innovative use of sample-level adaptive adjacency matrices.', 'Novel multi-resolution inner cluster smoothing approach.', 'Extensive experimental validation and ablation studies.', 'Use of integrated gradients for interpretability provides valuable insights.']","['The paper is dense and challenging to follow for readers not familiar with the domain.', 'The choice of hyperparameters and models in the ablation studies could be better justified.', 'Further elaboration is needed on the process of generating adaptive adjacency matrices.', 'Additional ablation studies are needed to understand the impact of different components.', 'Qualitative analysis could benefit from more visualizations and case studies.']",3,3,3,4,Reject
WLEx3Jo4QaB,"The paper proposes a novel method for condensing large graphs into smaller, highly informative synthetic graphs for training GNNs. The method leverages gradient matching and demonstrates significant improvements over baseline methods on various datasets.","['Can the authors provide more details on the computational overhead of the GCOND framework, especially for very large graphs?', 'How does the performance of GCOND compare to other state-of-the-art methods not included in this study?', 'Can the authors discuss the potential limitations of the proposed method in more detail?', 'Can the authors provide a more detailed explanation of the gradient matching process?', 'What are the impacts of different hyperparameter choices on the performance of GCOND?', 'How do the authors ensure fair comparisons between GCOND and baselines that do not leverage graph structure information?', 'Can the authors discuss potential ethical considerations and societal impacts of their work?', 'Can the authors provide more detailed hyperparameter settings to ensure reproducibility?']","['The paper lacks a thorough discussion on the potential limitations and negative societal impacts of the proposed method.', 'The clarity of the methodology needs improvement, particularly in the optimization process and the parameterization of the condensed graph.', 'Detailed ablation studies on hyperparameter choices are necessary.', ""Theoretical guarantees and detailed ablation studies are critical for understanding the method's robustness and generalizability.""]",False,3,3,3,6,4,"['Addresses a significant computational challenge in training GNNs on large-scale graphs.', 'Proposes a novel approach using gradient matching for graph condensation.', 'Extensive experiments across multiple datasets demonstrate the effectiveness of the proposed method.', 'The method shows good generalizability to different GNN architectures.']","['The methodology section lacks clarity, especially in explaining the gradient matching process.', 'More detailed ablation studies are needed, particularly regarding hyperparameter choices.', 'Theoretical grounding is weak, with limited discussion on why the method works and potential failure cases.', 'Potential ethical considerations and societal impacts are not adequately discussed.', 'Reproducibility is questionable due to the complexity of the method and lack of detailed hyperparameter settings.']",3,3,3,4,Reject
8Wdj6IJsSyJ,"The paper proposes a fully-differentiable model discovery algorithm by integrating neural network-based surrogates with Sparse Bayesian Learning (SBL). It showcases this approach on various datasets, demonstrating its robustness and effectiveness. The paper also introduces Physics Informed Normalizing Flows (PINFs) to directly learn density models from single-particle data.","['Can the authors provide a more detailed explanation of how SBL is integrated into PINNs? A step-by-step example would be beneficial.', 'Are there other baseline methods that could be included in the experimental comparisons to strengthen the claims?', 'Can the authors discuss potential limitations of their approach and any negative societal impacts?', 'Can the authors provide detailed ablation studies to showcase the contribution of each component of the proposed method?', 'How do the chosen hyperparameters impact the performance of the proposed method?']","['The paper does not address potential limitations or negative societal impacts. It would be beneficial for the authors to discuss these aspects to provide a balanced view of the proposed method.', 'The complexity of the proposed method might be challenging for practical implementation.']",False,3,3,3,6,4,"['The integration of SBL with PINNs to create a fully-differentiable model discovery algorithm is novel and well-motivated.', 'The proposed method shows strong performance on various datasets, including Korteweg-de Vries, Burgers, and Kuramoto-Shivashinsky equations.', 'Extending the approach to Physics Informed Normalizing Flows (PINFs) opens new avenues for model discovery from particle data, which is a significant advancement.']","['The clarity of some sections, especially the background on SBL and its integration with PINNs, could be improved. The explanation is dense and may be hard to follow for readers not already familiar with these concepts.', 'The experimental evaluation, while comprehensive, could benefit from additional comparisons with more baseline methods to strengthen the claims of superiority.', 'No discussion of potential limitations or negative societal impacts of the proposed method. Such an inclusion would provide a more balanced view of the work.', 'The paper does not provide detailed ablation studies to showcase the contribution of each component of the proposed method.']",3,3,3,4,Reject
UJ9_wmscwk,"The paper presents GLIE, a Graph Neural Network designed for influence estimation, and extends it to influence maximization through three methods: GLIE-CELF, GRIM, and PUN. The methods aim to address the scalability and efficiency issues in influence maximization, an NP-hard problem. The paper demonstrates competitive results on both synthetic and real-world datasets.","['Can the authors provide rigorous theoretical proof for the submodularity and monotonicity of GLIE?', 'What are the computational overheads for the proposed methods, especially for large graphs?', 'Can the authors clarify the explanation of the PUN method and adaptive full feedback with more examples or diagrams?', 'What are the potential negative societal impacts of influence maximization, and how can they be mitigated?', 'How does the method perform on different types of graphs (e.g., sparse vs. dense)?', 'Can the authors provide more detailed ablation studies to understand the contributions of different components?', 'Can the authors provide more details on the autoencoder aggregator used in GLIE?', 'How does the performance of GLIE-CELF and GRIM compare in terms of computational efficiency for very large-scale graphs?']","['The lack of theoretical proof for submodularity and monotonicity of GLIE.', 'The need for a more detailed discussion on computational overheads and potential negative societal impacts.', 'The computational overhead of GLIE-CELF and GRIM might limit their practical applicability for very large-scale graphs.', 'The paper should address the issue of reproducibility and provide more detailed ablation studies.']",True,2,2,3,4,4,"['Addresses a significant problem in influence maximization with potential real-world applications.', 'Proposes a novel GNN-based approach for influence estimation and maximization.', 'Provides comprehensive experiments on various synthetic and real datasets.']","['Lack of rigorous theoretical proof for submodularity and monotonicity of GLIE.', 'High computational overhead for methods like GLIE-CELF and GRIM.', 'Clarity issues in the presentation, especially for the PUN method and adaptive full feedback.', 'Limited discussion on potential negative societal impacts of influence maximization.', 'Concerns about the reproducibility of the results due to the complexity of the methods and datasets used.']",3,3,2,3,Reject
d2XZsOT-_U_,"The paper introduces a Transformer-based approach for predicting outcomes of pairwise competitions using historical data. Instead of representing players with a scalar skill estimate, it uses embeddings derived from game histories. This approach is tested against datasets from Chess, Baseball, and Ice Hockey and shows superior performance compared to traditional methods like Elo and Glicko.","['Can the authors provide a more detailed description of the training process, including hyperparameter tuning and data preprocessing?', 'How does the model handle the scalability issue with a large number of players?', 'Can the authors include more ablation studies to better understand the contribution of each component of the model?', 'Could you provide a more detailed explanation of the Transformer architecture used, including the number of layers, attention heads, and other hyperparameters?', 'What are the specific computational requirements for training and inference? How does the model scale with larger datasets?', 'Can you include more ablation studies to show the contribution of each component of the model, such as the impact of the history embedding depth?', 'How does the model perform with respect to other deep learning-based approaches not mentioned in the paper?', 'What is the rationale behind the choice of hyperparameters and dataset splits?', 'How does the model handle potential complexities in multi-player games?']","['The paper does not discuss potential limitations of the proposed method, such as its applicability to different types of competitions or scalability.', 'There is no discussion of the potential negative societal impact of using such prediction models.', 'The model does not naturally compute a scalar skill quantity, which could be a limitation for interpretability.', 'The current implementation might be challenging to scale for real-time applications due to the computational complexity of Transformers.', 'The approach may have limited applicability beyond the specific domains tested (Chess, Baseball, Hockey).', ""One major limitation is the lack of a clear theoretical foundation to support the empirical results. Additionally, the model's applicability to multi-player games is not well addressed.""]",False,2,2,3,3,4,"['The paper tackles a practical and relevant problem in ranking and match prediction.', 'Transformer-based architecture offers a fresh perspective on modeling historical data for such tasks.', 'Promising results on multiple datasets indicate potential effectiveness.', 'The approach can quickly adapt to new players with limited history, which is a significant practical advantage.']","[""The paper's explanation of the model architecture, especially the embedding process and how it differentiates from baselines, is not entirely clear."", 'The paper lacks detailed methodological explanations, such as how the network hyperparameters were chosen and the training process specifics.', 'While results are promising, more ablation studies and comparisons with a broader range of baselines would reinforce the claims.', 'The paper does not provide enough details to ensure reproducibility, such as code snippets, parameter settings, or data preprocessing steps.', 'The novelty of using Transformer-based history embeddings is not clearly articulated and may not be sufficiently groundbreaking.', 'Insufficient theoretical analysis to support the empirical findings.', 'The paper does not discuss potential limitations and ethical concerns in detail.']",3,2,2,3,Reject
HHpWuWayMo,"The paper introduces a novel model-based adversarial attack framework, cMBA, for continuous multi-agent reinforcement learning (c-MARL) environments. The attack involves learning dynamics of the environment and generating perturbations to states to misguide agents and reduce team rewards. The paper also explores strategies for selecting victim agents to optimize the impact of the attack. The effectiveness of the approach is demonstrated through experiments on multi-agent MuJoCo tasks.","['Could the authors provide more details on the architecture and training process of the dynamics model?', 'How sensitive is the proposed approach to the choice of target states in different environments?', 'Can the authors include more detailed ablation studies to show the contribution of each component in the attack strategy?', 'What measures were taken to ensure the generalization of the learned dynamics model across different environments?', 'How does the proposed method perform on other standard benchmarks or real-world tasks beyond MuJoCo?', 'Can the authors provide more intuitive explanations or visualizations of the learned dynamics model and its impact on the resulting perturbations?', 'How does the complexity of the dynamics model impact the computational efficiency and scalability of the proposed approach?']","['The paper does not adequately address the limitations regarding the accuracy of the learned dynamics model and its impact on the attack performance.', 'Potential negative societal impacts of the proposed adversarial attacks on c-MARL systems are not discussed.', 'The scalability of the approach to larger and more complex environments or systems was not discussed.']",True,3,2,3,4,4,"['The paper addresses an important and timely problem in the robustness of MARL systems.', 'The proposed model-based attack framework is novel, particularly in its application to continuous action spaces in MARL.', 'The method for selecting victim agents is a valuable addition and is well-motivated.', 'Comprehensive experimental setup with multiple environments and baselines for comparison.']","['The problem formulation and methodology, particularly the dynamics model and victim agent selection process, are not clearly presented.', 'The description of the dynamics model learning process lacks sufficient details, particularly regarding the architecture and training protocol.', 'The paper would benefit from more detailed ablation studies to isolate the impact of different components of the proposed approach.', 'The results, while promising, could be more robust with additional metrics and comparisons to more varied baselines.', 'The practical implications and potential applications of the findings are not thoroughly discussed.', 'The paper does not adequately address the potential limitations and ethical considerations of deploying adversarial attacks in real-world MARL systems.']",3,3,2,3,Reject
WPI2vbkAl3Q,"The paper provides a theoretical analysis of the generalization performance of SGD on structured features, deriving exact expressions for test loss dynamics and validating these on real datasets like MNIST and CIFAR-10. The authors also explore the effects of minibatch size and extend the theory to the more common setting of SGD on a fixed subsampled training set.","['Can the authors provide more intuitive explanations of the key theoretical results?', 'How sensitive are the results to the assumptions made about the feature distributions?', 'Can the theory be extended to other loss functions beyond MSE?', 'Can the authors provide more empirical validation on a wider variety of datasets and model architectures?', 'What are the potential limitations or assumptions in the theoretical framework that could impact its generalizability?', 'Can the authors improve the clarity of the paper, particularly in the presentation of the mathematical derivations?', 'What are the practical implications of your theoretical findings for tuning hyperparameters in real-world applications?']","['The theory is most accurate in the linear and kernel regimes; potential extensions to more complex, nonlinear settings and different types of data distributions should be discussed.', 'The primary limitations are the complexity of the theoretical framework and the need for more extensive empirical validation. The authors should also clarify any assumptions made in the theoretical derivations that could impact the generalizability of the results.']",False,3,3,3,6,4,"['Novel theoretical contributions for understanding SGD dynamics on structured data distributions.', 'Exact expressions for test loss dynamics validated on real datasets.', 'Exploration of the effects of minibatch size and extension to fixed subsampled training sets.']","['Theoretical results are densely presented, making the paper difficult to follow.', 'The impact on practical algorithm design or parameter tuning is not clearly demonstrated.', 'Lack of detailed comparisons with existing methods.', 'Empirical validation is limited to a few datasets and models; more extensive validation could strengthen the claims.']",4,3,3,4,Reject
YZHES8wIdE,"The paper introduces a Generative Planning Method (GPM) for reinforcement learning, aiming to generate multi-step action plans for more efficient exploration. It leverages the benefits of planning while maintaining the simplicity of model-free RL. The method has been empirically validated on several benchmark environments, showing promising results.","['Can the authors provide more details on the plan generator and the value function, particularly the network structures and the training procedures?', 'Could the authors conduct additional ablation studies to isolate the effects of different components of the proposed method?', 'Can more qualitative analyses, such as additional plan visualizations, be provided to better understand the behavior of the proposed method?', 'How does the performance of GPM scale with an increasing number of steps in the generated plans?', 'Can you provide more details on the computational overhead introduced by GPM compared to traditional methods?', 'Can the authors provide more detailed comparisons with other state-of-the-art exploration methods?', 'Can the authors clarify the implementation details of the plan generator and value function, especially in terms of how they handle different types of environments?', 'How does the computational cost of GPM compare to other model-free RL methods, especially in real-time applications like autonomous driving?', 'What are the potential limitations and challenges of GPM, and how can they be mitigated?', 'What are the ethical considerations and societal impacts of applying GPM to real-world tasks, particularly in autonomous driving?']","['The paper should discuss in more detail the limitations of the proposed method and any potential negative societal impacts.', 'The potential computational overhead introduced by multi-step planning is not fully addressed.', 'The complexity of implementing this method might be a barrier to its adoption.', 'The scalability of the approach and its applicability to a broader range of tasks need further exploration.', ""The method's complexity might limit its practical applicability."", 'The paper does not thoroughly discuss the potential negative impacts or limitations of the proposed method.', 'The computational overhead of generating and evaluating plans can be significant and needs to be discussed.', ""The method's scalability to more complex tasks and environments is not thoroughly evaluated."", 'Ethical considerations and societal impacts are not addressed, which is critical for applications in autonomous driving.']",False,3,2,3,5,4,"['The paper addresses the important issue of inefficient exploration in RL by proposing a novel method that generates multi-step action plans.', 'The GPM framework is a unique blend of planning and model-free RL, which is innovative and potentially impactful.', 'Extensive experiments on multiple benchmark tasks demonstrate the effectiveness of the proposed method.', ""The approach offers improved interpretability of the agent's behavior through the generated multi-step plans.""]","['The paper lacks clarity in some methodological details, particularly in the description of the plan generator and the value function.', 'Additional ablation studies are needed to better understand the contributions of different components of the proposed method.', ""The qualitative analyses, such as the plan visualizations, could be more comprehensive to enhance the understanding of the method's behavior."", 'The method introduces additional complexity in terms of network architecture and plan generation.', 'The paper would benefit from a more detailed discussion on the limitations and potential negative societal impacts of the proposed method.', 'Experimental validation is limited; more comprehensive comparisons with a broader range of baselines and environments are necessary.']",3,3,2,3,Reject
o6dG7nVYDS,The paper presents a theoretical framework for domain generalization (DG) using Rademacher complexity to derive generalization bounds. It hypothesizes that DG performance variability can be explained by the empirical risk-predictor complexity trade-off and suggests regularized ERM with leave-one-domain-out cross-validation as a better approach for DG. Empirical results on the DomainBed benchmark support the claims.,"['Can the authors provide more detailed hyperparameter settings and implementation details to enhance reproducibility?', 'How do the theoretical insights and empirical results apply to more complex neural network architectures?', 'Can the authors improve the clarity of the presentation, especially the theoretical sections, to make it more accessible to a general audience?', 'Can the theoretical framework be extended to more complex neural network architectures?', 'How would the proposed approach perform with end-to-end training of neural networks rather than using fixed features?', 'How sensitive are the results to the assumptions made in the theoretical analysis, such as the independence of domains and Lipschitz continuity of the loss function?', 'Can the authors discuss how their theoretical framework can be extended or adapted to account for more complex scenarios where some of these assumptions may not hold?', 'How practical is the proposed model complexity measurement for real-time model selection and tuning in deep networks?', 'Can the authors compare their theoretical bounds with existing bounds more thoroughly?']","['The paper could benefit from more detailed hyperparameter settings and implementation details to enhance reproducibility.', 'Extending the empirical analysis to more complex neural networks would strengthen the findings.', 'The theoretical analysis relies on certain assumptions that may not hold in all practical scenarios, potentially limiting the applicability of the results.', 'The practical implications of the theoretical bound could be discussed in more detail.', 'Potential limitations of the proposed approach in real-world applications are not fully addressed.']",False,3,3,3,5,4,"['Theoretical Contribution: The paper introduces a novel generalization bound for DG using Rademacher complexity, which is a significant theoretical advancement.', 'Empirical Validation: The experiments are well-designed and the results are consistent with the theoretical claims, providing strong empirical evidence.', 'Practical Insights: The paper offers practical advice on model selection strategies, specifically advocating for domain-wise validation over instance-wise validation.']","['Clarity and Presentation: The paper is dense and difficult to follow in some sections. The theoretical proofs, while rigorous, are not easily accessible to a general audience.', 'Limited Scope of Empirical Analysis: The empirical analysis, although thorough, is limited to linear models and shallow neural networks. The applicability to more complex models remains unclear.', 'Reproducibility: The paper lacks detailed hyperparameter settings and implementation details, which could hinder reproducibility.', 'Theoretical Novelty: While the theoretical contributions are valuable, they may not be sufficiently novel or groundbreaking.', ""Focus on Existing Methods: The paper primarily focuses on explaining existing methods' performance rather than proposing a novel algorithm or significant improvement.""]",3,3,3,3,Reject
dtYnHcmQKeM,"The paper proposes the Physics-Informed Neural Operator (PINO), a novel method that combines operator learning with physics-informed neural networks to solve partial differential equations (PDEs). The approach aims to improve convergence rates and accuracy by leveraging pre-trained operator ansatz and test-time optimization. The method is evaluated on several PDEs, showing promising results.","['Can the authors provide more details on the implementation of the neural operator and the test-time optimization process?', 'How does the performance of PINO compare to more recent advancements in PINNs and FNOs?', 'Can the authors include more ablation studies to highlight the contributions of different components of PINO?', 'Can the authors provide more details about the autoencoder aggregator?', 'What is the performance impact of different modulation functions and aggregators?', 'Can the authors include more visualizations for qualitative analyses?', 'How does PINO handle cases where the training data is extremely limited or noisy?', 'Can you discuss the potential limitations of PINO in more detail?']","['The paper does not adequately discuss the limitations of the proposed method, particularly in terms of computational cost and scalability.', 'Potential negative societal impacts are not addressed.', 'The lack of details in the experimental setup may hinder reproducibility and practical application of the method.']",False,3,2,3,5,4,"['The idea of combining operator learning with physics-informed optimization is novel and promising.', 'The proposed method addresses the shortcomings of both PINNs and FNOs by improving optimization and generalization.', 'Experiments show that PINO outperforms existing methods on various PDE problems, demonstrating its effectiveness.', 'Theoretical contributions are well-explained and supported.']","['The paper lacks clarity in the explanation of some methodological details, especially in the implementation of the neural operator and the test-time optimization process.', 'There are limited ablation studies to determine the contributions of different components of the proposed method.', 'The comparison with state-of-the-art methods is not comprehensive, especially with more recent advancements in PINNs and FNOs.', 'Reproducibility of the results may be challenging due to insufficient details about the experimental setup and hyperparameters.', 'The paper does not sufficiently discuss potential limitations and challenges of the proposed method, such as computational complexity and scalability.']",3,3,2,4,Reject
z8xVlqWwRrK,"The paper proposes Event-based Variational Distributions for Exploration (EVaDE) in Model-Based Reinforcement Learning (MBRL). EVaDE introduces three types of event-based convolutional layers to guide exploration, leveraging domain knowledge. The method is tested on 12 Atari games, showing superior performance under interaction constraints.","['Can the authors provide more detailed explanations and visualizations for the methodology?', 'Could the authors conduct additional ablation studies to understand the individual contributions of each component?', 'What are the potential limitations and broader impacts of this approach?', 'Can the authors provide more rigorous theoretical justifications for the proposed noisy event layers?', 'Can the authors clarify the integration of the noisy layers into the neural network architecture with more detailed diagrams or pseudocode?', 'What are the computational overheads introduced by the new layers, and how do they impact the overall training time?']","['The paper could benefit from a more in-depth discussion of potential limitations and broader impacts.', 'The methodology section needs more clarity, particularly in the implementation of the event-based layers.', 'Reproducibility is a concern due to the complex nature of the proposed method.']",False,3,3,3,6,4,"['Addresses a significant problem in reinforcement learning: efficient exploration.', 'Innovative introduction of three types of noisy event-based convolutional layers.', 'Extensive empirical evaluation on a diverse set of Atari games.', 'Strong baseline comparisons and empirical results showing substantial improvements.']","['Clarity of the methodology could be improved; some parts are hard to follow.', 'Missing thorough ablation studies and hyperparameter justifications.', 'Limited discussion on potential limitations and broader impacts of the approach.', 'Theoretical justification for the effectiveness of the variational distributions in exploring useful state-space regions is not sufficiently detailed.', 'Reproducibility might be an issue due to the complexity of the proposed method and insufficient details in some parts of the methodology.', 'The paper lacks a detailed discussion on the computational overhead introduced by the proposed layers.']",3,3,3,4,Reject
ODnCiZujily,"The paper 'DeepSplit: Scalable Verification of Deep Neural Networks via Operator Splitting' introduces a novel method using operator splitting (specifically ADMM) to solve large-scale LP relaxations for neural network verification. It demonstrates significant improvements in scalability and efficiency, providing tighter bounds on worst-case performance for large convolutional networks in image classification and reinforcement learning tasks.","['Can you provide more details on the practical implementation of DeepSplit in real-time systems?', 'How does DeepSplit compare with other recent advanced verification methods not included in the paper?', 'Can the authors provide more detailed ablation studies to highlight the contribution of each component of their approach?', 'How does the method perform on other types of neural network architectures, such as RNNs or Transformers?', 'Can the authors compare their method with non-LP-based verification methods to provide a broader perspective on its effectiveness?', 'Can the authors provide more details on the implementation of the projection operations for various layers?', 'What is the impact of different choices of parameters in the ADMM algorithm?', 'How does the method perform compared to other state-of-the-art verification methods not discussed in the paper?', 'Can you provide more detailed explanations for the mathematical derivations and algorithms, particularly for readers less familiar with advanced optimization techniques?', 'How does the computational complexity and memory usage of your method compare with other state-of-the-art verification methods?', 'Can you provide more theoretical insights into the convergence properties of the proposed ADMM-based approach?', 'What are the practical challenges in implementing the proposed method, and how can they be mitigated?']","['The complexity of the method could pose challenges for implementation and reproducibility.', 'The paper lacks discussion on the practicality of applying the method in real-time or embedded systems.', 'The paper should include more detailed ablation studies and consider generalizability to other neural network architectures and tasks.', 'The clarity of the explanations, particularly in the methodology section, needs improvement.', 'The paper should include a discussion on the potential limitations and negative societal impacts of the proposed method.', 'More ablation studies are needed to understand the contributions of different components of the method.', ""The paper should include more detailed explanations and comparisons to improve clarity and provide a comprehensive understanding of the method's advantages and limitations."", 'The impact of parameter tuning, particularly for the augmentation constant ρ, is not exhaustively explored.', ""The method's applicability to real-world safety-critical applications is not demonstrated or discussed in detail.""]",False,3,3,3,7,4,"['The method scales to large neural networks that prior techniques cannot handle.', 'It leverages GPU acceleration, resulting in significant speedups over commercial-grade LP solvers.', 'The approach provides tighter bounds on worst-case performance, improving certified robustness.', 'The paper includes extensive experiments and comparisons, demonstrating the effectiveness and efficiency of the method.', 'The application of operator splitting methods to neural network verification is novel.', 'The approach is modular and parallelizable, leveraging GPU acceleration for efficiency.']","['The method involves numerous steps and operations, which might complicate implementation and reproducibility.', 'There are limited comparisons with some recent advanced methods in neural network verification.', 'The paper does not discuss the practicality of the method in real-time or embedded systems, which is crucial for safety-critical applications.', 'The paper is dense and could benefit from clearer explanations, especially in the methodology section.', 'Lacks detailed ablation studies to highlight the contribution of each component of their approach.', 'The generalizability of the method to other types of neural network architectures and tasks is not fully explored.', 'Some parts of the methodology are not clearly explained, such as the implementation details of certain projection operations.', 'Limited theoretical analysis on the convergence properties and potential limitations of the method.']",3,3,3,4,Reject
morSrUyWG26,"The paper presents AutoOED, an Automated Optimal Experimental Design platform leveraging multi-objective Bayesian optimization (MOBO). It features a modular framework for easy extension, a novel asynchronous strategy named Believer-Penalizer (BP), and a graphical user interface (GUI) for intuitive use. The platform aims to optimize experiments data- and time-efficiently, and it can control and guide real-world hardware experiments.","['Can the authors provide more details on the technical implementation of the Believer-Penalizer strategy?', 'Have the authors considered other surrogate models or acquisition functions? If so, how do they impact the performance?', 'Can the authors provide more real-world case studies to demonstrate the robustness of the proposed method?', 'Can the authors provide more rigorous evaluations of the Believer-Penalizer (BP) strategy against existing asynchronous optimization methods?', 'Can the authors improve the clarity of the mathematical formulations and algorithm descriptions?', 'Can the authors include more extensive ablation studies and sensitivity analyses to validate the robustness of the proposed methods?']","['The main limitations are the clarity of the paper in explaining the technical details of the BP strategy and the need for more comprehensive ablation studies to evaluate the impact of different components of the method.', 'The paper should include more detailed ablation studies and sensitivity analyses to validate the robustness of the proposed methods and ensure their practical applicability.', 'The clarity of the presentation, especially the mathematical formulations and algorithm descriptions, needs improvement to facilitate better understanding.']",False,3,3,3,4,4,"['The proposed AutoOED platform addresses the practical need for efficient multi-objective optimization in experimental design.', 'The introduction of a novel asynchronous strategy (Believer-Penalizer) is innovative and addresses limitations in existing approaches.', ""The platform's modular structure allows easy integration and development of new MOBO algorithms."", 'The intuitive GUI makes the platform accessible to users with limited coding or machine learning knowledge.', ""Comprehensive experiments demonstrate the platform's effectiveness and robustness on standard benchmarks.""]","['The clarity of the paper in certain sections, especially the technical details of the BP strategy, could be improved.', 'More ablation studies are needed to evaluate the impact of different components of the proposed method, such as the use of different surrogate models and acquisition functions.', 'The robustness of the BP strategy should be further validated through more diverse real-world applications.', 'The presentation of the experiments could be more detailed, with additional visualizations and case studies.', 'The novelty and effectiveness of the BP strategy need more rigorous evaluation against existing asynchronous optimization methods.']",3,3,3,3,Reject
-TSe5o7STVR,"The paper 'NON-PARALLEL TEXT STYLE TRANSFER WITH SELF-PARALLEL SUPERVISION' introduces LaMer, a novel framework for text style transfer that leverages large-scale language models and scene graph-based mining to create roughly parallel data from non-parallel datasets. The framework consists of three main steps: mining roughly parallel sentences, conducting MLE training, and refining the model through reinforced imitation learning. The proposed method is evaluated on three tasks: sentiment transfer, formality transfer, and a newly introduced political stance transfer, showing significant improvements over existing methods.","['Can the authors provide more details about the scene graph-based alignment process?', 'How does the proposed method perform on low-resource datasets?', 'Can the authors provide more information on hyperparameter settings and training procedures to improve reproducibility?', 'Can the authors provide detailed ablation studies to show the individual contributions of each component of the proposed method?', 'How sensitive is the proposed method to the choice of hyperparameters, and how can this sensitivity be mitigated?', 'Can you provide more details about the autoencoder aggregator used in the framework?', 'How do you ensure that the complex architecture does not lead to overfitting?', 'Can you compare LaMer with more state-of-the-art methods for a comprehensive evaluation?', ""What are the effects of varying the hyperparameters on the model's performance?"", 'How does the reliance on the scene graph parser impact the generalizability of the approach across different domains?', 'How does the reinforced imitation learning specifically improve the model performance compared to using MLE alone?', 'What measures can be taken to mitigate the potential risks of generating offensive or politically biased content?']","['The paper does not address the performance of the proposed method on low-resource datasets.', 'There is a lack of clarity in the methodology section, particularly in the explanation of the scene graph-based alignment and imitation learning processes.', 'Reproducibility is a concern due to insufficient details about hyperparameter settings and training procedures.', 'The complexity of the proposed method and the reliance on human evaluations are potential limitations.', 'The current evaluation is limited to English. Extending the framework to other languages could be explored.', 'Reliance on scene graph parser quality and potential ethical concerns regarding generated text misuse.', 'The potential risks of generating offensive or politically biased content are significant and need to be addressed explicitly.']",True,3,3,3,6,4,"['Addresses a significant problem in text style transfer by proposing a novel method to mine parallel sentences from non-parallel datasets.', 'Leverages large-scale language models and scene graphs, which are innovative and show empirical effectiveness.', 'Provides thorough empirical and human evaluations, demonstrating the advantages of LaMer over existing methods.', 'Introduces a new challenging task, political stance transfer, adding to the diversity of text style transfer benchmarks.', 'Comprehensive evaluations on multiple benchmarks demonstrate the effectiveness of the proposed method.']","['The methodology section lacks clarity, particularly in the explanation of the scene graph-based alignment and the imitation learning process.', 'The robustness of the evaluation is questionable due to the limited diversity of datasets used for testing.', 'Reproducibility is a concern as the paper does not provide sufficient details about hyperparameter settings and training procedures.', 'The proposed method relies heavily on pre-trained language models, which may not generalize well to low-resource settings.', 'The complexity of the proposed method and the reliance on human evaluations are potential limitations.', 'Lacks detailed ablation studies to show the individual contributions of each component of the proposed method.', 'Potential ethical concerns regarding the misuse of generated text are noted but could be elaborated further.']",3,3,3,4,Reject
i--G7mhB19P,The paper investigates the inductive biases of natural gradient descent (NGD) compared to Euclidean gradient descent (EGD) in deep linear models and matrix factorization tasks. It explores the invariance properties of NGD and shows through theoretical analysis and experiments that NGD may fail to generalize well in certain overparameterized settings where EGD performs better.,"['Can the authors provide more intuitive explanations and visualizations to help understand the theoretical findings?', 'Can the authors detail the experimental setup, including hyperparameters and implementation specifics, to ensure reproducibility?', 'What are the practical implications of these findings for real-world deep learning applications? Can the authors provide more examples or case studies?', 'How do the findings extend to more complex, non-linear models beyond the linear and matrix completion tasks studied?', 'Given the computational challenges of NGD, are there any approximate methods that might retain some of its desirable properties while being more practical to implement?']","['The paper primarily focuses on linear models and may not fully capture the complexities of NGD in more practical, non-linear deep learning tasks.', 'The clarity of the paper needs improvement, especially in the theoretical sections, to make it more accessible.', 'The computational expense of exact NGD is a significant limitation, which the authors acknowledge. Exploring more practical approximations of NGD could be beneficial.']",False,3,3,3,4,4,"['Addresses an important and underexplored aspect of NGD, particularly its invariance to reparametrization and the resulting implications for generalization.', ""Theoretical analysis is thorough, with well-stated theorems and proofs that provide a deep understanding of NGD's behavior."", 'Experiments validate the theoretical claims, illustrating the practical implications of the differences between NGD and EGD.']","['The paper is difficult to follow due to dense mathematical notation and lack of intuitive explanations.', 'Experimental results are not comprehensive and fail to convincingly demonstrate the practical implications of the theoretical findings.', 'Reproducibility is a concern; the paper lacks sufficient detail in the experimental setup and does not provide enough information on hyperparameters and implementation specifics.', 'Limited exploration of practical aspects of implementing NGD in modern deep learning architectures.', 'Insufficient experimentation with more complex non-linear models and real-world datasets.']",3,3,3,4,Reject
zyrhwrd9EYs,The paper introduces Mixed Confounded Missingness (MCM) and selective imputation to handle missing data in treatment effect estimation. The authors argue that standard imputation techniques either remove necessary information or introduce bias. They propose selectively imputing only certain variables based on MCM to achieve better performance. The paper provides theoretical justification and empirical validation for the proposed method.,"['Can the authors provide more details on the autoencoder aggregator?', 'How does the proposed method perform with different imputation techniques?', 'Can the authors include more datasets and different types of learners in their empirical validation to strengthen their findings?', 'What is the impact of varying levels of missingness on the performance of the proposed method?', 'Can the authors provide more detailed examples or visualizations to clarify the selective imputation strategy?', 'How does the proposed method compare with more advanced imputation techniques like deep learning-based methods (e.g., GAIN)?', 'Are there real-world case studies where the proposed method has been applied? If not, what are the plans for future work in this direction?', 'Can the authors provide more details on the limitations of their proposed method?', 'Are there any potential negative societal impacts of using selective imputation in treatment effect estimation?', 'Have the authors considered different types of modulation functions and aggregators in their experiments?', 'How does the selective imputation method handle cases where the missingness mechanism is not well understood or varies significantly across different datasets?', 'Can the authors clarify the process of synthetic data generation and how it ensures the validity of the experimental results?']","['The paper should include more extensive ablation studies to understand the impact of different components and settings.', 'The empirical validation could be expanded to include more datasets and different types of learners to generalize the findings.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed method. For instance, how might selective imputation perform on real-world datasets with different characteristics than those used in the experiments?', 'The impact of different imputation techniques on the performance of selective imputation could be explored further.']",False,3,3,3,5,4,"['The introduction of MCM is novel and addresses a significant gap in the treatment effect estimation literature.', 'The theoretical framework is well-developed and clearly explains the limitations of existing missing data mechanisms.', 'Selective imputation is a practical and theoretically motivated solution that shows promising results in empirical validation.', 'The paper tackles a real-world problem, making it highly relevant for practitioners in various fields such as medicine and marketing.']","['The empirical validation, while promising, could be more robust. More datasets and different types of learners should be included to generalize the findings.', 'The explanation of the autoencoder aggregator is not very clear and could benefit from additional details.', 'More ablation studies are needed to fully understand the impact of different components of the proposed method. For example, the impact of different imputation techniques and the effect of varying levels of missingness should be explored in more depth.', 'The paper could improve its clarity in some sections, particularly in the methodology and experimental setup. Some explanations are dense and could benefit from simplification.', 'The paper does not sufficiently discuss the limitations of the proposed method, especially regarding its applicability to real-world data. There is also limited comparison with other advanced imputation methods.']",4,3,3,3,Reject
NZQ8aTScT1-,"The paper introduces a theoretical framework for understanding the inductive biases of neural network architectures through the lens of eigenspace restructuring. It proposes that different network topologies restructure the associated eigenspaces in ways that impact the network's ability to learn various types of interactions, characterized by a learning index that combines spatial and frequency components.","['Can the authors provide more empirical validation on diverse datasets or tasks to support their theoretical claims?', 'How can the proposed framework be applied to practical neural network design? Can the authors provide specific examples or guidelines?', 'Can the authors provide more intuitive explanations or visualizations to help readers understand the complex concepts?', 'How generalizable are the empirical results to more complex datasets and architectures?', 'What are the potential negative societal impacts of this work, if any?', 'How do the theoretical results apply to practical, finite-width networks with more commonly used activation functions?', 'Can the authors discuss the limitations of their assumptions and how they might be relaxed in future work?']","[""The paper's dense theoretical presentation may limit its accessibility."", 'Practical validation is limited, making it difficult to assess the real-world applicability of the proposed framework.', 'The assumptions made in the theoretical framework (e.g., infinite-width networks, specific activation functions) may limit the practical applicability of the results.', 'The mathematical density of the paper makes it less accessible to a broader audience.']",False,3,2,3,5,4,"['Addresses an important theoretical question in deep learning: understanding the inductive biases of neural network architectures.', 'Introduces novel concepts such as the learning index to characterize the interactions that neural networks can learn.', 'Theoretical results are rigorously derived and provide deep insights into the workings of neural networks.']","['The paper is dense with theoretical constructs and mathematical notations, making it difficult to follow.', 'The empirical validation is limited, relying heavily on theoretical proofs without sufficient practical experiments on diverse datasets or tasks.', 'The practical implications of the proposed framework for neural network design are not clearly articulated.', 'Highly technical and may be difficult to understand for readers without a strong mathematical background.', 'The assumptions made in the theoretical framework (e.g., infinite-width networks, specific activation functions) may limit the practical applicability of the results.']",3,3,2,4,Reject
IEKL-OihqX0,"The paper introduces a method called Ratio Matching with Gradient-Guided Importance Sampling (RMwGGIS) for learning discrete Energy-Based Models (EBMs). The method aims to address the high computational cost and memory usage of traditional ratio matching by using gradients to guide importance sampling. The proposed method demonstrates significant improvements in both efficiency and effectiveness, particularly for high-dimensional problems.","['Can you provide more rigorous theoretical guarantees for the proposed method?', 'Can you analyze potential drawbacks and limitations of the method in more detail?', 'Can you clarify the derivation and explanation of the method, especially the autoencoder aggregator?', 'Can the authors provide more details on the construction of the proposal distribution and the practical implementation of the RMwGGIS method?', 'Have the authors considered additional baselines for comparison, particularly recent methods in the field?', 'Can the authors discuss the limitations of the proposed method and any potential ethical considerations?', 'Please provide additional ablation studies to justify the use of gradient-guided importance sampling over simpler alternatives.', 'How does RMwGGIS compare with other state-of-the-art methods for discrete EBMs beyond ratio matching?']","[""The method's potential drawbacks and limitations are not adequately discussed. Additionally, the broader impact and utility of the method in real-world tasks need further demonstration."", 'The primary limitation is the clarity and reproducibility of the proposed method. Improving the explanation and providing more detailed experimental settings would greatly enhance the paper.', ""The lack of comparison with a broader range of state-of-the-art methods is another limitation. Including such comparisons would provide a more comprehensive understanding of the method's impact.""]",False,3,3,3,5,4,"['Addresses a significant challenge in learning discrete EBMs.', 'Proposes a novel combination of importance sampling and gradient utilization.', 'Shows promising experimental results on synthetic discrete data and graph generation.', 'Comprehensive theoretical derivation and proofs supporting the proposed method.']","['Lacks rigorous theoretical guarantees for the proposed method.', 'Insufficient analysis of potential drawbacks and limitations.', 'Clarity issues in some sections, particularly in the derivation and explanation of the method.', 'The impact on broader applications is not convincingly demonstrated.', 'Limited comparison with state-of-the-art methods beyond ratio matching.']",3,3,3,4,Reject
ZOcX-eybqoL,"The paper introduces a framework for leveraging logical composition in reinforcement learning to enable an agent to autonomously determine whether a new task can be solved using existing skills or if a task-specific skill should be learned. The framework also allows the agent to learn new tasks faster by generating an estimate of the optimal policy. Theoretical results are provided, and the approach is empirically validated in various domains.","['Can the authors provide more detailed explanations of the extension from deterministic shortest path tasks to discounted and stochastic tasks?', 'How does the proposed method handle real-world scenarios with complex and noisy task structures?', 'Are there any limitations or ethical concerns that the authors have considered, and how do they plan to address them?', 'Can the framework be extended to handle tasks with non-binary goal rewards?', 'What are the specific limitations when applying this approach to more complex environments?', 'Can the authors provide more intuitive explanations or diagrams for the theoretical proofs?', 'Are there plans to test the framework in more complex environments or real-world applications?', 'Can the authors provide more details on how the logical composition framework compares to other transfer learning methods in practical settings?']","['The paper does not fully address the limitations of the proposed method, particularly in real-world scenarios with complex task structures.', 'The clarity of the explanations and proofs could be improved to make the paper more accessible to a broader audience.', 'The framework currently only considers tasks with binary goal rewards. The authors should discuss potential extensions to tasks with non-binary rewards.', 'More details on the experimental setup, including hyperparameters and network architectures, would improve the clarity and reproducibility of the experiments.', ""The reliance on an off-the-shelf RL method for learning goal-reaching tasks may limit the framework's efficiency in environments with high sample complexity.""]",False,3,2,3,7,4,"['The use of logical composition to handle task heterogeneity in lifelong reinforcement learning is a novel and interesting approach.', 'Theoretical results are sound and provide guarantees on the performance of the transferred policy and the number of tasks needed to generalize over a distribution.', 'Empirical evaluations in the PICKUPOBJ and Four Rooms domains effectively demonstrate the benefits of the proposed method.', ""The method enables fast transfer learning and provides interpretable Boolean expressions of the agent's understanding of tasks.""]","['The explanation of the extension from deterministic shortest path tasks to discounted and stochastic tasks could be more thorough.', 'The clarity of the paper could be improved, especially in the technical details and proofs.', 'The paper does not adequately address potential limitations and ethical concerns, such as the applicability to real-world scenarios with complex task structures.', 'More ablation studies could be provided to evaluate the impact of different components of the framework.', 'The framework is limited to tasks with binary goal rewards, which may not cover all real-world scenarios.', 'Additional experimental details, particularly around the network architecture and hyperparameters, would enhance reproducibility.']",4,3,2,4,Reject
hUr6K4D9f7P,The paper introduces Weighted Truncated Adversarial Weight Perturbation (WT-AWP) to improve generalization and robustness in Graph Neural Networks (GNNs). The authors identify a vanishing-gradient issue with existing Adversarial Weight Perturbation (AWP) methods and propose modifications to address this issue. Experimental results demonstrate that WT-AWP consistently enhances both natural and robust generalization across various graph learning tasks.,"['Can the authors provide more detailed explanations and clearer derivations for the theoretical results?', 'Could the authors conduct more detailed ablation studies to isolate the effects of truncation and weighting in WT-AWP?', 'What are the potential limitations and negative societal impacts of WT-AWP?', 'Can you provide more clarity on the derivation of the generalization bound?', 'How does the WT-AWP performance vary with different perturbation layers beyond what is mentioned?', 'Can you offer insights on the practical hyperparameter tuning process for λ and ρ?', 'Can you provide more details about the autoencoder aggregator?', 'Have you considered other types of aggregators?', 'Have the authors considered applying WT-AWP to other neural network architectures beyond GNNs?', 'Have the authors considered the impact of their method on fairness or biases in the model?']","['The paper does not adequately address potential limitations and negative societal impacts of the proposed method. The authors should discuss these aspects in more detail.', 'The complexity introduced by hyperparameter tuning (λ, ρ) needs to be managed for practical adoption.', 'The clarity of the technical details could be improved.']",False,3,3,3,6,4,"['The paper addresses an important problem of generalization and robustness in GNNs, which is critical for many real-world applications.', 'The proposed WT-AWP method offers a novel approach to mitigate vanishing-gradient issues associated with existing AWP methods.', 'Theoretical analysis is provided to justify the use of WT-AWP.', 'Comprehensive experiments show that WT-AWP improves both natural and robust generalization on multiple benchmarks.']","['The clarity of the paper is lacking in several areas. The theoretical derivations and the algorithm description are not always clear and can be hard to follow.', 'The novelty is somewhat limited as it builds on existing AWP methods with incremental modifications. The introduction of truncation and weighting could be seen as a straightforward extension rather than a groundbreaking innovation.', 'The experiments, while comprehensive, could benefit from more detailed ablation studies to isolate the effects of each component of WT-AWP.', 'The paper does not sufficiently discuss the potential limitations and negative societal impacts of the proposed method.', 'The proposed WT-AWP introduces additional complexity in hyperparameter tuning (λ, ρ) which could be a barrier for practical adoption.']",3,3,3,3,Reject
1xXvPrAshao,"The paper introduces the Mutually supErvised Multimodal VAE (MEME), a novel approach to handling multimodal data using mutual supervision. MEME leverages semi-supervised VAEs to combine information between modalities implicitly, avoiding the need for explicit combination of representations. The paper demonstrates MEME's effectiveness on the MNIST-SVHN and CUB datasets, showing improvements over existing methods in terms of cross coherence, latent accuracy, and the ability to handle partially observed data.","['Can the authors provide additional ablation studies to investigate the impact of different numbers of pseudo-samples and the effect of training with only paired data?', 'Can the authors clarify some of the technical details, particularly in the derivation of the objective and the explanation of the mutual supervision mechanism?', ""Have the authors considered empirical validation of the method's generalization to more than two modalities?"", 'Can you provide more detail on the autoencoder aggregator and its role in the framework?', 'Could more qualitative cases be provided to strengthen the analysis?']","['The clarity of the paper could be improved, particularly in the explanation of technical details. Additionally, more ablation studies would help to further validate the effectiveness of the proposed method.', 'The complexity of the method might make it less accessible to some readers. Additionally, there is limited empirical validation for the extension to more modalities.', 'There is limited discussion on potential negative societal impacts or ethical considerations related to the deployment of such models.']",False,3,2,4,6,4,"['The paper presents a novel approach to multimodal VAEs using mutual supervision, which is a significant departure from traditional methods that rely on explicit combination of representations.', 'Comprehensive experiments demonstrate the effectiveness of MEME on both image-image and image-text datasets, outperforming existing methods on standard metrics.', 'The method naturally handles partially observed data, which is a common issue in multimodal datasets, without requiring additional components or modifications.']","['The clarity of the paper could be improved, particularly in the explanation of technical details. Some sections are dense and difficult to follow.', 'Limited ablation studies; additional experiments could further isolate the contributions of each component and investigate the impact of different numbers of pseudo-samples and the effect of training with only paired data.', 'The paper primarily focuses on the bi-modal case, with limited empirical validation for more modalities.', 'Reliance on pseudo-samples for the prior approximation adds extra complexity and potential sensitivity.']",4,3,2,4,Accept
IhkSFe9YqMy,"The paper proposes an experience replay mechanism in deep reinforcement learning, termed Experience Replay More (ERM), which prioritizes transitions containing key states. The method is evaluated using DDPG, TD3, and SAC on various continuous control tasks, showing some performance improvements.","['Can you provide more details on how the key transitions are identified and how the linear sampling distribution is implemented?', 'How does the proposed method compare with other recent advancements in experience replay strategies, beyond the provided baselines?', ""Can you provide more details on how 'key transitions' are identified and why they are critical?"", 'What are the specific hyperparameters used in your experiments?', 'Can you include more statistical analysis of your results, such as confidence intervals?', 'Can you provide more details on how key transitions are identified? What criteria are used to determine these key states?', 'Have you considered other sampling distribution functions besides the linear distribution? How do they compare in performance?', 'Can you include more ablation studies to isolate the impact of each component of the ERM algorithm?', 'Can you provide more theoretical justification for the choice of key transitions and the sampling proportions?', 'How does the AN2N algorithm specifically identify key transitions? More details would be helpful.', 'Have you tested the proposed method in environments other than Mujoco tasks?', 'Can the authors provide a clearer definition and identification method for key states?', 'How does the linear distribution sampling function work in practice? A more detailed explanation is needed.', 'Can the authors discuss the specific contributions of the ERM algorithm to the observed performance improvements in the experiments?']","['The paper does not adequately discuss its limitations, such as the potential overhead of identifying key states and the generalizability of the proposed method to other types of tasks.', 'Potential negative societal impacts are not addressed.', 'The paper should address the limitations related to the identification of key transitions and the potential overfitting to these transitions.', 'Discuss the potential negative societal impacts and ethical concerns of your work.', 'The authors need to clarify the criteria for identifying key transitions and provide more detailed pseudo-code or mathematical formulation for the ERM and AN2N algorithms.', 'The evaluation should be extended to more tasks and include a more thorough analysis of the results. Additional ablation studies are needed to isolate the impact of different components.', 'The paper could benefit from a more detailed theoretical analysis of the proposed methods. Additionally, testing the approach in more diverse environments would help validate its generality.', 'The paper does not clearly address the potential limitations and negative societal impacts of the ERM algorithm.']",False,2,2,2,4,4,"['Addresses a relevant issue in reinforcement learning: improving sample efficiency.', 'The idea of distinguishing key and non-key states is an interesting extension of Prioritized Experience Replay (PER).', 'The concept of prioritizing key transitions in experience replay is novel and adds a new dimension to existing prioritized replay methods.', 'Comprehensive experiments across multiple Mujoco tasks show significant performance improvements.', 'The integration with popular RL algorithms (DDPG, TD3, SAC) demonstrates the versatility of the proposed method.']","['The novelty is limited as it builds on the existing PER framework.', 'The experimental results lack statistical significance and comprehensive comparison with other methods.', 'The paper is poorly organized, making it difficult to follow the methodology and understand the key contributions.', 'The pseudocode and algorithmic descriptions are not clear and could be more detailed.', ""The criteria for identifying 'key transitions' are not well justified or explained."", 'The experimental evaluation lacks details on hyperparameter settings, and the results are not statistically robust (e.g., no confidence intervals).', 'Potential ethical concerns and societal impacts are not discussed.', 'Reproducibility is a concern due to the lack of detailed implementation steps and hyperparameter values.', 'The paper lacks clarity in explaining how key transitions are determined and the exact mechanism of the AN2N and ERM algorithms. The pseudo-code provided is not sufficient for complete understanding.', 'The novelty of the method is limited as it builds on existing concepts like prioritized experience replay and noise addition. The combination of these ideas does not present a significant theoretical advancement.', 'The paper does not provide enough ablation studies to isolate the impact of different components of the proposed method. For example, how does the linear sampling distribution function compare to other sampling strategies?', 'The evaluation is limited to a few Mujoco tasks, and the results are not extensively analyzed. Additional tasks and a more thorough analysis of the results would strengthen the findings.', 'Theoretical justification for the identification and prioritization of key transitions is lacking.', 'Details on the AN2N algorithm and the sampling process could be clearer.', 'Experiments are limited to Mujoco tasks; more diverse environments would strengthen the claims.', 'The definition of key states and the distinction between key and non-key states are not clearly explained.', 'Implementation details of the ERM algorithm, particularly the linear distribution sampling function, are ambiguous.', 'The experimental evaluation lacks thorough discussion, especially on the specific contributions of the proposed modifications to the observed improvements.']",2,2,2,3,Reject
FpKgG31Z_i9,"The paper introduces a novel concept called 'learning rate grafting,' which aims to transfer the implicit step size schedule from one optimizer to another. This technique is proposed to help in understanding the entanglements between adaptive preconditioning rules and learning rate schedules. The authors provide extensive empirical results to show the effectiveness of the method across different tasks and architectures.","['Can the authors provide a stronger theoretical foundation or insights to support the observed phenomena?', 'Can the authors clarify the methodology section, providing more detailed explanations, especially on the grafting process?', 'Do the authors have additional experimental results or analysis to convincingly demonstrate the superiority of the proposed method over existing optimizers?']","['The lack of a strong theoretical foundation makes it challenging to assess the generalizability and robustness of the proposed method.', 'The experimental results are not consistently convincing, which raises concerns about the practical impact of the method.']",False,2,2,2,3,4,"['The concept of learning rate grafting is novel and provides a new perspective on optimizer performance transfer.', 'Comprehensive experimental results cover various tasks and architectures.', 'The method has potential practical applications in simplifying hyperparameter tuning.']","['The paper lacks a strong theoretical foundation or novel theoretical insights, which makes it difficult to generalize the findings.', 'The experimental results, although comprehensive, do not convincingly demonstrate consistent superiority over existing methods.', 'Some explanations, particularly in the methodology section, are vague and could benefit from more detail, making it hard to reproduce the results.', 'The paper fails to provide a clear and significant advancement in the understanding of optimizer performance beyond empirical observations.']",3,2,2,3,Reject
eo1barn2Xmd,"The paper presents SLIM-QN, a stochastic quasi-Newton optimizer designed for training large-scale deep neural networks. SLIM-QN addresses the high computational cost and convergence instability of traditional second-order methods by using a BFGS update rule that approximates the Hessian inverse and introducing momentum and adaptive damping mechanisms. Theoretical analyses and empirical evaluations on various datasets and network architectures are provided to demonstrate the efficiency and effectiveness of SLIM-QN.","['Could you provide more detailed explanations and justifications for the adaptive damping mechanism?', 'How does SLIM-QN compare with other state-of-the-art optimizers not included in the evaluation?', 'Can you provide more detailed hyperparameter settings and implementation details to ensure reproducibility?', 'Can the authors provide more diverse empirical validation on additional datasets and models?', 'How does SLIM-QN perform in terms of memory overhead and computational efficiency compared to other second-order methods?', 'Can the authors provide a more intuitive explanation of the adaptive damping mechanism?', 'Can the authors provide more detailed ablation studies on the effects of different hyperparameters and the impact of the Hessian update frequency?', 'What are the potential limitations of SLIM-QN, especially in the context of very large models?', 'Can the authors compare SLIM-QN with more baselines, including other adaptive methods like Adam and AdaGrad?']","['The paper could be clearer in its explanations and justifications for the proposed methods.', 'Reproducibility is a concern due to the lack of detailed hyperparameter settings and implementation details.', 'The paper does not sufficiently discuss the potential limitations and negative societal impacts of the proposed method.', 'The paper does not discuss the memory overhead due to storing history vectors.', 'The sensitivity of SLIM-QN to hyperparameter tuning is not thoroughly analyzed.']",False,3,2,3,4,4,"['Addresses the important problem of computational cost and convergence instability in second-order optimization methods for DNNs.', 'Introduces a novel combination of momentum and adaptive damping in the context of quasi-Newton methods.', 'Provides rigorous theoretical analysis and convergence guarantees.', 'Includes comprehensive empirical evaluations on a range of datasets and network architectures.']","['The explanation of the proposed method is sometimes unclear and lacks detailed justification, particularly in the adaptive damping mechanism.', 'The novelty of introducing momentum and damping in the context of BFGS may be considered incremental.', 'The empirical evaluation, while extensive, could benefit from more baselines and a clearer comparison with existing methods.', 'The reproducibility of the results is questionable due to the lack of detailed hyperparameter settings and implementation details.', 'The paper does not address potential limitations and negative societal impacts, which is important for a comprehensive evaluation.']",3,3,2,3,Reject
dg79moSRqIo,"The paper presents DISk (Discovery of Incremental Skills), a novel framework for incremental skill discovery in reinforcement learning that addresses the limitations of current methods under non-stationary environments. DISk learns skills sequentially, allowing it to adapt to changing environments without forgetting previously learned skills. The method is evaluated on various MuJoCo environments and demonstrates superior performance in both static and dynamic settings compared to state-of-the-art baselines.","['Can the authors provide more details on the entropy estimation method and how the intrinsic rewards are computed?', 'How does DISk scale with an increasing number of skills or more complex environments?', 'What are the potential negative societal impacts of deploying such a system in real-world scenarios?', 'Can the authors provide more details on the autoencoder aggregator and its role in the framework?', 'Can the authors investigate the impact of different modulation functions and aggregators on the performance of DISk?', 'How does DISk compare with other incremental learning approaches in reinforcement learning beyond the baselines used?', 'Can the authors provide a more detailed theoretical analysis of why the incremental approach works better?', 'Can the authors include more experimental details to improve reproducibility?', 'Have the authors tested the method on a wider range of environments to validate generalizability?']","['The scalability of DISk to more complex environments or a larger number of skills is not thoroughly evaluated.', 'The potential negative societal impacts of deploying such a system are not discussed.', 'The reliance on a fixed skill addition schedule and hand-crafted projection functions could limit the generalizability of the framework.', 'The paper could benefit from more detailed ablation studies and comparisons with other incremental learning methods.']",False,3,3,3,6,4,"['Novel approach to skill discovery that addresses non-stationary environments.', 'Thorough empirical evaluation on multiple environments showing the effectiveness of DISk.', 'Clear motivation and well-defined problem statement.', 'Demonstrates superior performance compared to state-of-the-art methods in both static and dynamic settings.', 'Provides both qualitative and quantitative analysis of the learned skills.']","['The mathematical formulation of the proposed method could be clearer, particularly the entropy estimation and reward formulation.', 'Scalability to more complex environments or a larger number of skills is not thoroughly evaluated.', 'Limited analysis on the effect of different hyperparameters and their tuning.', 'Potential negative societal impacts are not discussed.', 'Insufficient ablation studies to thoroughly validate the design choices and components of the method.', 'Reliance on hand-crafted projection functions and fixed schedules for skill addition, which may not generalize well to all environments.']",3,3,3,4,Reject
DrCsriMQ1o,"The paper proposes a novel method for generating counterfactual explanations using tractable probabilistic models, specifically sum-product networks (SPNs). The approach decouples the objective of perturbing the prediction from maintaining additional constraints on the perturbation, addressing the inefficiencies and complexities of existing methods. The method is evaluated on several datasets, demonstrating advantages in computation speed, success rate, and visual appeal of the generated counterfactuals.","['Can the authors provide more detailed ablation studies on the impact of different hyperparameters and SPN structures?', 'Can the authors improve the clarity of the mathematical formulation and provide more detailed steps for reproducibility?', 'Can the authors validate the approach on additional datasets to demonstrate its generalizability?', 'Can the authors provide a more rigorous theoretical justification for using SPNs in this context?', 'How does the approach scale to more complex and higher-dimensional datasets beyond those tested?', 'Can the authors provide more comprehensive empirical evaluations, including comparisons with a wider range of baseline methods?', 'How does the proposed method perform in terms of robustness to adversarial attacks?', 'What are the potential limitations and negative societal impacts of the proposed method?']","['The main limitations include the lack of detailed ablation studies and the clarity of the mathematical formulation. Additionally, the limited number of datasets used for validation raises questions about the generalizability of the approach.', 'The paper does not sufficiently address the limitations related to scalability and generalizability.', 'The empirical evaluation lacks depth and breadth.', 'The paper does not address potential limitations and negative societal impacts adequately. A more thorough discussion on these aspects would improve the overall quality of the paper.']",False,3,2,3,4,4,"['Introduction of tractable probabilistic models (SPNs) for counterfactual generation.', ""Qualitative and quantitative evidence demonstrating the method's effectiveness in generating realistic and high-likelihood counterfactuals."", 'Significant improvement in computational efficiency compared to existing methods.', 'Comprehensive empirical evaluations on various datasets, including a real-world dataset, add credibility to the proposed approach.']","['Lacks sufficient ablation studies on hyperparameters and SPN structures.', 'Clarity of mathematical formulation and explanation needs improvement for better reproducibility.', 'Limited experiments on additional datasets to validate the generalizability of the approach.', 'Lacks a rigorous theoretical grounding for the use of SPNs in generating counterfactuals.', 'Empirical evaluation is superficial and lacks comprehensive analysis and broader comparisons.', 'Potential issues around scalability and generalizability to more complex datasets are not addressed.', 'The clarity of the paper is somewhat compromised by dense technical jargon and a lack of intuitive explanations for non-expert readers.', 'Potential limitations and negative societal impacts are not adequately addressed.']",3,3,2,3,Reject
UseMOjWENv,"The paper 'MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling' proposes a hierarchical generative model for musical performance that aims to combine realism and control. The hierarchical structure involves notes, performance, and synthesis levels to allow for both high-fidelity audio synthesis and user control over musical attributes. The paper includes quantitative experiments and listening tests to validate its claims.","['Can the authors provide more details on the autoencoder aggregator?', 'What is the impact of using different modulation functions and types of aggregators?', ""Can the authors provide more qualitative examples of the model's output?"", 'Can the authors provide more clarity on the specific contributions of each module in the hierarchical model, particularly the CNN in the DDSP Inference module?', 'How does the model perform with polyphonic recordings or multi-instrument scenarios beyond what is presented?', 'Can the authors discuss any potential ethical implications of the work, particularly in terms of generating realistic audio that could be misused?', 'Can the authors provide more details on the individual components of the model, especially the Expression Generator and Synthesis Generator?', 'How does the model handle polyphonic recordings, and what are the limitations in this context?', 'Can the authors include more ablation studies to demonstrate the contribution of each component in the hierarchy?', 'Can the authors elaborate on how the system could be extended to polyphonic recordings?', 'Could more details be provided on the extraction of expression controls?', 'Can the authors provide more detailed descriptions and diagrams for the model components to improve clarity?', 'What are the potential challenges and solutions for extending this model to polyphonic music?', 'Can the authors include additional ablation studies to isolate the impact of the GAN-based synthesis generator and other key components?']","['The paper requires additional ablation studies to understand the full impact of each component. The clarity of the explanation of certain components also needs improvement.', 'The model is currently limited to monophonic recordings, and the authors suggest future work will explore polyphonic and multi-instrument scenarios. The computational complexity and scalability of the model in real-world applications are also potential concerns.', 'The potential negative societal impact is minimal, but the paper could discuss the implications of its use in automated music creation and its effects on musicianship.']",False,3,3,3,7,4,"['The hierarchical structure provides a novel approach to balancing realism and control in music generation.', 'The use of DDSP for synthesis ensures interpretability and detailed control over musical attributes.', ""Comprehensive experiments, including quantitative and qualitative analyses, demonstrate the model's effectiveness."", 'The potential applications of this work are broad, spanning from music education to professional music production.']","['The clarity of the paper could be improved, especially in the detailed explanation of components like the autoencoder aggregator.', 'Additional ablation studies are needed to fully understand the impact of each component, particularly the modulation function and different types of aggregators.', ""The paper could benefit from more qualitative examples to convincingly demonstrate the model's capabilities."", 'The approach is limited to monophonic recordings and does not extend to polyphonic music, which is a notable limitation for broader applicability.', 'Ethical considerations, particularly regarding the use and potential misuse of generated music, are not addressed.']",3,3,3,4,Reject
kiNEOCSEzt,The paper addresses the issue of preference shifts in recommender systems induced by the RS policies. It proposes a methodology to estimate these shifts using neural networks trained on historical user interaction data and introduces the concept of 'safe shifts' to evaluate and optimize RS policies to avoid undesirable preference changes.,"['Can the authors provide more detailed information on the training process of the neural networks used for preference estimation?', 'How do the authors address potential biases in historical user interaction data?', 'What are the limitations of the proposed methodology when applied to real-world data, and how can these be mitigated?', 'How do the authors plan to address the potential scalability issues of their approach?', 'What are the limitations of the assumptions made about user behavior and preference dynamics?', 'Can the authors provide more detailed ablation studies and comparisons with baselines?', 'How do the authors plan to address the real-world applicability of their simulation-based results?', 'Can the authors elaborate on the ethical considerations of their proposed methodology?', 'What are the computational requirements for implementing the proposed models in a real-world system?', ""How do the authors ensure that the definition of 'safe shifts' does not introduce new biases or ethical concerns?""]","['The primary limitation is the reliance on simulated data for evaluation. It is crucial to validate the methodology on real-world data to ensure its applicability and effectiveness.', 'The assumptions made about user behavior and the choice model may limit the applicability of the results to different contexts.', ""The paper's reliance on simulations is a primary limitation, as it raises questions about the real-world applicability of the methods."", ""The potential biases introduced by defining 'safe shifts' need to be addressed more thoroughly.""]",True,2,2,2,4,4,"['The paper tackles a significant and relevant problem in the field of recommender systems.', 'The approach of using neural network models to estimate user preference dynamics and simulate counterfactuals is novel and well-motivated.', ""The concept of 'safe shifts' provides a practical way to define and measure desirable preference changes."", 'The experimental setup is comprehensive, including simulation environments and evaluation metrics that align with the proposed methodology.']","['The paper lacks clarity in some methodological details, particularly regarding the training of neural networks and handling of user behavior assumptions.', 'The evaluation relies heavily on simulated data, which raises concerns about the applicability and generalizability of the findings to real-world scenarios.', 'There is a need for more detailed discussion on the limitations and potential biases of the proposed methodology.', 'The paper is dense and poorly organized, making it difficult to follow the methodology and its implementation.', 'Insufficient ablation studies and comparisons with baselines to substantiate the claims.', 'Ethical considerations of the proposed methodology are not adequately addressed.']",3,2,2,3,Reject
gLqnSGXVJ6l,"The paper proposes a reinforcement learning approach to solve the Vehicle Routing Problem with Time Windows (VRPTW). It extends existing models by incorporating an attention mechanism and reinforcement learning to dynamically solve VRPTW. The paper presents the model architecture, training process, and experimental results comparing the proposed method with well-known baselines.","['Can you provide more details on the generated instances and the specific parameters used in the experiments?', 'How does the proposed method scale with larger problem sizes?', 'Can you provide more clarity on the encoder and decoder sections?', 'What are the potential limitations and failure modes of the proposed method?', 'How does the performance of the model generalize to real-world VRPTW instances?', 'Can you provide more details on the implementation of the proposed methodology?', 'How does the proposed method perform on real-world datasets?', 'What are the limitations of the proposed approach, and how can they be addressed?', 'Can you discuss the scalability of the method for large-scale instances?', 'Why were only certain baselines chosen for comparison, and how do they relate to the proposed method?', 'Can the authors provide an ablation study to understand the contribution of different components of the model?']","['The paper lacks clarity in some sections, which makes it difficult to fully understand the proposed method.', 'The experimental validation could be more comprehensive to better demonstrate the effectiveness and scalability of the proposed method.', 'The synthetic nature of the dataset is a limitation as it may not accurately represent real-world VRPTW instances. The authors should discuss how the model might perform on real-world data.', ""The paper lacks a detailed discussion of the model's limitations and potential failure modes."", 'The scalability and performance on large-scale instances are not adequately addressed.', 'The lack of comprehensive evaluation and comparison with diverse datasets is a significant limitation.', 'The paper does not discuss potential limitations of the proposed approach, such as scalability to larger instances or sensitivity to hyperparameters. Additionally, potential negative societal impacts are not addressed.']",False,2,2,2,3,4,"['Addresses a significant and challenging problem in combinatorial optimization.', 'Builds upon existing models and incorporates an attention mechanism and reinforcement learning.', 'Experimental results show promising performance compared to well-known baselines.']","['The novelty is limited as it mainly extends existing methods to include time windows.', 'The clarity of the paper could be improved, especially in the encoder and decoder sections.', 'The experimental validation could be more comprehensive, with more details on the generated instances and specific parameters used.', 'The description of the model architecture and the encoding/decoding process lacks sufficient detail, making it difficult to fully understand the implementation.', ""The paper does not provide a comprehensive analysis of the model's limitations or potential failure modes."", 'The synthetic nature of the dataset used for training and testing raises questions about the generalizability of the results to real-world scenarios.', 'The comparison with baselines could be more extensive, including a wider range of methods and problem instances.', 'Experiments are conducted only on synthetic data, with no validation on real-world datasets.', 'Scalability of the proposed method is not thoroughly discussed, especially for large-scale instances.', 'Ethical considerations and limitations are not adequately addressed.']",3,2,2,3,Reject
5XmLzdslFNN,The paper proposes a modular lifelong reinforcement learning (RL) method using neural composition. The method aims to solve complex RL tasks by decomposing them into subproblems and reusing solutions to these subproblems for future tasks. The proposed method leverages accumulated neural components to accelerate learning and prevent forgetting via off-line RL over replayed experiences. The paper also introduces two compositional evaluation domains: a discrete 2-D domain and a realistic robotic manipulation suite.,"['Can the authors provide more ablation studies to investigate the impact of different components and hyperparameters?', 'Can the authors provide more details on the methodological aspects to improve clarity?', 'How does the method scale with respect to the number of modules, and what are the potential limitations in larger-scale settings?', 'Can the authors provide more details on the implementation of the neural modules, including their architecture and training process?', 'Can the authors clarify the methodology for selecting and combining neural modules during the online training phase?', 'What are the potential negative societal impacts of the proposed method? How can these be mitigated?']","['The scalability of the method with respect to the number of modules is a potential limitation. The paper should address how the method can handle a larger number of combinations efficiently.', 'The paper does not provide a detailed discussion on the potential negative societal impacts of the proposed approach.']",False,3,3,3,7,4,"['Addresses a significant challenge in lifelong RL by focusing on functional compositionality.', 'The proposed method of using neural composition to capture the underlying structure of tasks is novel and interesting.', 'Comprehensive empirical evaluations demonstrate the effectiveness of the method in both discrete 2-D tasks and realistic robotic manipulation tasks.', 'The method shows promise in achieving both forward transfer and avoiding catastrophic forgetting.', 'The use of batch RL techniques to prevent catastrophic forgetting is a valuable contribution.']","['The paper could benefit from additional ablation studies to investigate the impact of different components and hyperparameters.', 'Certain sections of the paper, particularly the methodological details, could be clearer.', 'The scalability of the method with respect to the number of modules is a potential limitation that needs to be addressed.', 'The potential negative societal impacts of the approach are not adequately addressed.']",4,3,3,4,Accept
fEcbkaHqlur,"The paper proposes an alternative to traditional target networks in Deep Q-Learning (DQL) by introducing Functional Regularization (FR). This method aims to stabilize training by using up-to-date Q-values and explicitly controlling regularization. The authors present theoretical insights and empirical results demonstrating the efficacy of their approach on various environments, including Atari games and the Four Rooms environment.","['Can you provide more details on the computational overhead introduced by the functional regularizer?', 'How does the proposed method perform on a more diverse set of environments?', 'Can you clarify some of the mathematical derivations and theoretical explanations?', 'Can you provide more details on the sensitivity of the regularization parameter κ and its impact on different environments?', 'How is the functional regularization term computed and updated?', 'Why were other state-of-the-art methods like Rainbow or IQN not included in the comparisons?', 'What are the potential limitations and ethical considerations of the proposed approach?']","['The paper does not thoroughly discuss the computational overhead of the proposed method.', 'The empirical evaluation could be more comprehensive by including a wider range of environments and additional baselines.', 'The lack of detailed ablation studies and clarity on hyperparameter settings are the major concerns.', 'The empirical evaluation could be more diverse to further demonstrate the effectiveness of the proposed method.', 'The paper does not address potential ethical concerns or societal impacts.']",False,3,3,3,5,4,"['Addresses a significant issue in DQL: instability due to fast-changing target Q-values.', 'Proposes a novel functional regularizer with strong theoretical foundations.', 'Comprehensive empirical results show improvements in stability and performance.', 'The problem tackled is relevant and well-motivated.', 'The paper is well-organized and clearly written, making it easy to follow the theoretical foundations and experimental results.']","['Mathematical derivations and theoretical explanations could be clearer.', 'Lacks a detailed discussion on the computational overhead introduced by the functional regularizer.', 'Empirical results could include more diverse environments and additional baselines for comparison.', 'The ablation studies and sensitivity analysis could be more detailed.', 'The choice and tuning of hyperparameters for the functional regularizer (κ) are not well-justified.', 'The paper does not compare the proposed method with other recent state-of-the-art methods in DQL, such as Rainbow or IQN.', 'There is no discussion of potential limitations or ethical considerations related to the proposed approach.']",3,3,3,4,Reject
RMv-5wMMrE3,"The paper proposes Cell2State, a method for embedding single-cell gene expression data into low-dimensional state vectors to predict cell dynamics using barcoded single-cell sequencing data. This method aims to map gene expression profiles to a lower-dimensional space that is predictive of cell state transitions. The authors evaluate their method on a stem cell dataset and synthetic data, demonstrating its utility in clustering, prediction of cell fate, and identification of biologically relevant markers.","['Can the authors provide more details on the choice of kernel function and rank selection for the low-rank optimization?', 'How does the proposed method compare with more recent state-of-the-art methods in single-cell trajectory inference?', 'Could the authors clarify and simplify the presentation of the information-theoretic analysis for a broader audience?', 'Can the authors provide more detailed explanations of the kernelized state embedding method and the assumptions made in the model?', 'How does the method perform on different types of single-cell data beyond the barcoded stem cell dataset used in the paper?', 'Can the authors include additional ablation studies to better understand the contributions of each component of the method?', 'What are the potential limitations of the method in terms of scalability and applicability to various single-cell datasets?', 'Can the authors provide more details about the autoencoder aggregator?', 'Can the authors conduct additional ablation studies to explore the impact of different components and parameters of the proposed method?', 'Can the authors provide more visualizations and interpretations of the results, particularly for the real data experiments?', 'Can the authors provide more detailed theoretical analysis and empirical validation?', ""How does the method's complexity impact its practical applicability?"", 'Can the authors include more intuitive explanations and visual aids to improve clarity?', 'Can the authors perform additional comparisons with recent or diverse methods?']","['The method assumes that the cell state transitions can be captured by a low-rank representation, which may not hold for all types of single-cell data.', 'The method relies on the availability of high-quality barcoded single-cell sequencing data, which may not be feasible for all research settings.', 'The clarity of some methodological details and the need for additional ablation studies are the main limitations.', ""The method's complexity and computational requirements might limit its practical applicability."", ""The lack of detailed theoretical analysis and empirical validation raises concerns about the method's soundness.""]",False,3,3,3,5,4,"['The problem addressed is significant and relevant for the single-cell genomics community.', 'The proposed method is novel, leveraging barcoded single-cell sequencing data to learn state transitions.', 'The paper includes extensive experiments and ablation studies, demonstrating the effectiveness of the proposed method.', 'The method shows strong performance in clustering and prediction tasks, often outperforming baseline approaches.', 'The method provides interpretable results, identifying biologically relevant marker genes and development pathways.']","['The presentation of the method is sometimes unclear, particularly the detailed steps of the algorithm and the justification for specific choices (e.g., kernel function, rank selection).', 'The paper lacks comparison with recent state-of-the-art methods in single-cell trajectory inference and gene expression analysis.', 'The information-theoretic analysis, while interesting, is dense and may be difficult for readers unfamiliar with these concepts to follow.', 'More experimental details, such as hyperparameters and data preprocessing steps, could be provided in the main text rather than the appendix.', ""The method's complexity and computational requirements might limit its practical applicability.""]",3,3,3,4,Reject
DfMqlB0PXjM,"The paper introduces Hierarchical DivNoising (HDN), a hierarchical VAE-based architecture for unsupervised image denoising and artefact removal. The authors demonstrate that HDN learns interpretable multi-scale representations, achieving state-of-the-art results on twelve benchmark datasets and effectively removing artefacts in real-world microscopy data.","['Can the authors provide more details about the autoencoder aggregator and its role in the HDN architecture?', 'What is the impact of different modulation functions (e.g., sigmoid, tanh, Film) on the performance of HDN?', 'Can the authors explore the performance of alternative aggregators and provide more detailed ablation studies on these components?', 'Can you provide more qualitative examples to demonstrate the interpretability of the hierarchical representation?', 'How does the method perform compared to a broader range of unsupervised baselines?', 'What are the contributions of each component of the HDN architecture as shown in ablation studies?']","['The paper lacks a detailed discussion on the limitations of HDN, particularly in handling structured noises in non-microscopy domains. Future work should address this gap and provide more comprehensive evaluations.', 'The clarity of the paper could be improved, particularly around the noise model and the autoencoder aggregator.', 'The paper lacks some ablation studies that could strengthen the validation of their model.']",False,3,3,3,6,4,"['Novel architecture (HDN) that addresses the limitations of previous VAE-based denoisers by incorporating hierarchical latent variables.', 'Comprehensive experimentation across twelve benchmark datasets, showcasing significant improvement over existing methods.', 'Interpretability: The hierarchical nature of HDN allows for insights into the representations learned at different layers, facilitating the removal of structured noise.', 'Effective in both pixel-wise noise removal and structured noise removal without needing paired training data.']","['Clarity: Some methodological details, particularly regarding the autoencoder aggregator and the design choices in the hierarchical structure, are not well-explained.', 'Ablation studies: While several ablation studies are presented, the exploration of the modulation function and alternative aggregators is limited. More comprehensive ablation experiments could strengthen the paper.', 'Limited discussion on limitations: The paper briefly mentions potential limitations in handling structured noises outside microscopy but does not provide sufficient analysis or future directions.', 'The qualitative analysis would be more convincing if more visual examples and comparisons were provided, especially for the structured noise removal task.', 'Reproducibility could be enhanced with more detailed implementation and training information.']",3,3,2,3,Reject
R612wi_C-7w,"The paper presents a Resetting Path Integrator (RPI) model to fuse visual and proprioceptive signals for path integration. The model aims to outperform standard LSTM networks in terms of performance and interpretability by using direct-inverse models to reset its internal state based on visual input, creating stable cognitive maps. Extensive experimental results are provided, showing the advantages of the RPI model over traditional LSTM networks.","['Can you provide more details on the training procedures and hyperparameters used?', 'How do you ensure the reproducibility of your results?', 'Can you elaborate on the generalizability of your model beyond the specific tasks tested?', 'Can the authors provide more detailed explanations and visualizations of the direct-inverse models and the gating mechanism?', 'How does the proposed RPI perform in more complex, real-world environments beyond the two-dimensional simulated environment used in the experiments?', 'Could the authors discuss any potential limitations or negative societal impacts of their approach?', 'Can the authors provide more detailed ablation studies to analyze the impact of different components of the RPI model?', 'How does the RPI model perform in more complex and dynamic environments compared to the controlled setting used in the experiments?', 'Can the authors justify the specific design choices for the gating network and other architectural components?']","['The paper does not adequately address the limitations and potential negative societal impacts of the work. A discussion on the generalizability of the model and potential biases in the experimental setup is needed.', 'The reliance on simulated environments for validation might limit the applicability to real-world scenarios.', 'There could be ethical concerns related to the accuracy and reliability of navigation systems in safety-critical applications.', 'The potential negative societal impacts, such as the misuse of navigation technology in certain contexts, should be discussed.']",False,3,2,3,5,4,"['Addresses a significant problem in spatial navigation and cognitive map formation.', 'Proposes a novel architecture combining direct-inverse models with path integration.', 'Provides extensive experimental results and comparisons with LSTM networks.', 'The RPI model introduces a novel resetting mechanism that fuses visual and proprioceptive sensors, reducing error accumulation over time.', 'The paper provides a comprehensive analysis of the internal representations and the gating mechanism, contributing to the interpretability of the model.']","['The paper lacks clarity in several sections, making it difficult to follow the methodology and experimental setup.', 'The level of detail provided for the training procedures and hyperparameters is insufficient for reproducibility.', 'There is limited discussion on the generalizability of the results beyond the specific tasks tested.', 'The mathematical formulations and the descriptions of the experimental setup are dense and not well-explained.', 'The simplified environment used in the experiments may limit the generalizability of the results to more complex, realistic settings.', 'The impact of hyperparameter choices and training procedures is not thoroughly explored, which could affect the reproducibility of the results.', 'The paper lacks a detailed discussion of potential limitations and negative societal impacts, which is important for a comprehensive evaluation.']",3,3,2,4,Reject
Zq2G_VTV53T,"The paper introduces FastSHAP, a method for estimating Shapley values in real-time using a learned explainer model. FastSHAP leverages a weighted least squares objective derived from Shapley values to train the explainer model without requiring ground truth Shapley values. The method is validated on tabular and image datasets, showing significant speedup and competitive accuracy compared to existing methods.","['Can the authors provide more details on the training process and hyperparameter choices to improve reproducibility?', 'How does FastSHAP handle potential biases introduced by the training data for the explainer model?', ""Can the authors include more qualitative examples of image explanations to better assess the method's reliability?"", 'Can the authors provide more details on the surrogate models and their potential limitations?', 'How does the method perform on different types of models not covered in the experiments?', 'What are the potential biases and overfitting risks in the experimental setup?', 'Can the authors provide more details on the efficiency regularization and normalization steps? How do these steps impact the training and performance of FastSHAP?', ""Can the authors include additional ablation studies to explore the impact of various hyperparameters and training settings on FastSHAP's performance?"", 'Can the authors provide more qualitative examples and detailed explanations of the image datasets to better illustrate the effectiveness of FastSHAP?']","['The paper does not adequately address potential biases introduced by the training data for the explainer model. It would be beneficial to discuss this limitation and any mitigation strategies in more detail.', 'The qualitative analysis of image explanations could be more thorough, including a broader range of classes and more examples.', ""The method's performance on a wider range of datasets and model types is not thoroughly evaluated."", 'The impact of hyperparameter choices on the performance of FastSHAP is not well-explored.', 'The clarity of the presentation, particularly in the methodological sections, can be improved.']",False,3,3,3,5,4,"['The paper addresses a significant computational challenge in Shapley value estimation, which is highly relevant for explaining large, high-dimensional models.', 'The proposed FastSHAP method is novel, leveraging a learned explainer model to provide Shapley value estimates in a single forward pass.', 'Extensive experimental validation is provided, including comparisons with multiple baselines on both tabular and image datasets.', 'The paper demonstrates significant speedup over traditional Shapley value estimation methods, making it suitable for real-time applications.', 'Theoretical grounding with proofs provided for key claims.']","['The paper does not clearly address the potential limitations and negative societal impacts of FastSHAP. For example, the reliance on a learned explainer model may introduce biases if the training data is not representative.', 'Some parts of the methodology, such as the training process and hyperparameter choices, could be explained in more detail to improve reproducibility.', ""The qualitative analysis of image explanations could be more extensive, including more examples and a broader range of classes to better assess the method's reliability."", 'The robustness of the method across a wider range of datasets and model types is not sufficiently validated.', 'The impact of hyperparameter choices on the performance of FastSHAP is not thoroughly explored.', 'More comprehensive ablation studies and comparisons with a broader range of baseline methods are needed.', 'Potential biases and overfitting risks in the experimental setup are not adequately discussed.']",3,3,3,4,Reject
VyZRObZ19kt,"The paper presents a novel framework for learned index structures that dynamically adjusts the error bound parameter (ε) based on local data characteristics. By linking ε to the mean and variance of data localities, the proposed approach aims to achieve a better space-time trade-off. The framework is tested on several state-of-the-art learned index methods and real-world datasets, demonstrating its effectiveness.","['Can the authors provide more details on the initialization and training process of the ε-learner?', 'How sensitive are the results to the choice of the look-ahead data size and the hyperparameter ρ?', 'Can the authors include more qualitative analysis and case studies to illustrate the practical benefits of the dynamic ε adjustment?', 'Can the authors provide more details on the computational overhead of the ε-learner module?', 'How does the ε-learner impact dynamic updates to the index?', 'Can the authors improve the clarity of the mathematical formulations in the methodological sections?', 'Please provide more details on the autoencoder aggregator.', 'Can you conduct additional ablation studies on modulation functions?', 'What are the practical applications or real-world use cases for the proposed method?', 'How does the proposed method generalize to different types of datasets or workloads?']","['The paper should better discuss the limitations of the proposed approach, such as potential computational overheads in highly dynamic environments.', 'The potential impact of the additional hyperparameters on the usability and robustness of the framework should be addressed.', 'The computational complexity of the ε-learner module needs further investigation.', 'The impact on dynamic updates to the index is not discussed.', 'The paper does not discuss the limitations or potential negative societal impacts of the proposed method.']",False,3,2,3,6,4,"['The problem addressed is significant and practical, especially in the context of real-world data retrieval applications.', 'The theoretical analysis linking ε with data characteristics is well-grounded and novel.', 'Extensive experimental evaluation on multiple datasets and learned index methods shows the potential of the proposed approach.', 'The framework is designed to be pluggable, making it easy to integrate with existing learned index methods.']","['The clarity of the methodology, specifically the ε-learner module and the optimization process, needs improvement.', 'The introduction of hyperparameters, such as ρ, and their impact on the results are not thoroughly discussed.', 'The ablation studies provided could be more comprehensive. For example, the impact of different initialization strategies for the ε-learner and the sensitivity of the results to the chosen look-ahead data size should be explored in more detail.', 'While the experiments are extensive, more qualitative analysis and case studies would strengthen the claims.', 'The computational overhead and complexity of the ε-learner module are not thoroughly discussed, which is critical for real-time applications.', 'The impact of the ε-learner on dynamic updates to the index is not addressed, which is important for practical applications.', 'Additional benchmarks against non-learned index structures would provide a more comprehensive performance evaluation.', 'The paper lacks real-world applications or case studies to demonstrate practical significance.', 'The limitations and potential negative societal impacts are not discussed.']",3,3,2,3,Reject
ZDYhm_o8MX,"The paper 'Neural Manifold Clustering and Embedding (NMCE)' proposes a novel approach for manifold clustering using neural networks. The method combines data augmentation with Maximum Coding Rate Reduction (MCR²) to achieve state-of-the-art performance on several benchmarks. The approach is innovative and shows promising results, but there are concerns regarding the clarity of the paper and the lack of detailed ablation studies.","['Can the authors provide a detailed ablation study to understand the contribution of each component?', 'Can the authors clarify the explanation of the TCR objective and its relationship to VICReg?', 'How sensitive is the method to the choice of hyperparameters?', 'What is the impact of different types of data augmentations on performance?', 'Can the authors provide more details on the multistage training process and justify its necessity?', 'What specific data augmentation policies were used in the experiments, and how were they chosen?', 'How does the proposed method compare to existing self-supervised learning methods in terms of feature quality and clustering performance?', 'Can the authors provide more detailed explanations and visualizations for the implementation of constraints via data augmentation?', 'Could the authors conduct more comprehensive ablation studies to validate the contributions of each component?', 'How does the proposed method compare to more recent state-of-the-art methods in manifold clustering on diverse and large-scale datasets?']","['The paper does not provide a detailed ablation study, which makes it difficult to understand the contribution of each component.', 'The sensitivity of the method to hyperparameters and the impact of different types of data augmentations are not thoroughly discussed.', 'The paper lacks clarity in the description of the multistage training process, augmentation policies, and hyperparameter choices, which could affect reproducibility.', 'The paper does not provide a detailed discussion on the limitations and potential negative societal impacts of the proposed method.', 'The paper needs more clarity in the methodology section, particularly around the implementation of constraints and the choice of hyperparameters.', 'Additional ablation studies are needed to isolate the contributions of different components of the method.']",False,3,2,3,6,4,"['The combination of data augmentation and MCR² for manifold clustering is novel.', 'The proposed method outperforms state-of-the-art methods on several benchmarks.', 'The paper provides extensive empirical evaluation on synthetic and real datasets.']","['The paper lacks a detailed ablation study to understand the contribution of each component.', 'The clarity of the paper could be improved, especially the explanation of the TCR objective and its relationship to VICReg.', ""The method's sensitivity to hyperparameters is not thoroughly discussed."", 'The impact of different types of data augmentations on performance is not explored in depth.', 'The methodology, especially the implementation of constraints via data augmentation, lacks detailed explanations and could be clearer.', 'Comparisons to a broader set of recent state-of-the-art methods are lacking, reducing the significance of the results.', 'The evaluation on more diverse and large-scale datasets is necessary to establish the robustness and generalizability of the method.']",3,3,2,3,Reject
ziRLU3Y2PN_,The paper proposes a novel texture synthesis method using wavelet-based models with generalized rectifier non-linearities. This approach aims to bridge the gap between classical wavelet models and modern CNN-based methods. The authors provide a comprehensive set of experiments to demonstrate the effectiveness of their method compared to state-of-the-art models.,"['Can the authors provide more details on the mathematical formulations, especially the generalized rectifier non-linearities and their implementation?', 'How does the proposed method perform in comparison to state-of-the-art CNN-based methods in terms of computational efficiency?', 'Can the authors provide more ablation studies to understand the impact of different components of the proposed method?', 'Can the authors provide a more detailed explanation of the transition from traditional wavelet models to the proposed generalized rectifier model?', 'Could the authors include an ablation study to better isolate the impact of different components of the proposed model?', 'Can you provide more details on the quantitative evaluation metrics used to compare your model with existing methods?', 'Could you clarify the role and implementation of the autoencoder aggregator and the modulation functions?', 'What steps have been taken to rigorously analyze the memorization effect in your model?', 'Can the authors provide more detailed comparisons with a broader range of baseline methods?', 'Can the authors clarify the explanations of key concepts and methodologies, possibly with more illustrative examples?', 'Can the authors provide more intuitive explanations and visual aids to improve the clarity of the mathematical formulations?', 'Can the authors conduct more rigorous ablation studies and comparisons with state-of-the-art methods?', 'Can the authors provide quantitative metrics in addition to visual inspection for evaluating the quality of synthesized textures?']","['The paper lacks clarity in some of the explanations, which could hinder reproducibility.', 'There is a need for more detailed comparisons and analysis of results, especially with CNN-based methods.', 'The paper could benefit from additional ablation studies.', 'The evaluation relies heavily on visual inspection, which can be subjective. More rigorous and quantitative evaluation metrics should be included.']",False,2,2,3,4,4,"['The proposed method is novel and aims to combine the interpretability of wavelet-based models with the performance of CNN-based methods.', 'The paper includes extensive experiments and comparisons with state-of-the-art methods, both qualitative and quantitative.', 'The authors provide a detailed description of their methodology, making it easier to reproduce the results.']","['The clarity of the paper could be improved, especially in the explanations of the mathematical formulations and the experimental setup.', 'Some of the comparisons, especially with CNN-based methods, lack sufficient depth and could benefit from a more detailed analysis of the results.', 'The paper could benefit from additional ablation studies to better understand the contributions of different components of the proposed method.', 'The transition from traditional wavelet models to the proposed generalized rectifier model is not fully explained, leaving some gaps in understanding the novelty of the approach.', ""The explanation of the model's intricacies, particularly the autoencoder aggregator and modulation functions, is somewhat unclear."", 'Relies heavily on visual inspection for evaluation, which can be subjective.', 'The analysis of the memorization effect is not rigorous enough.', 'The impact of the contributions is limited by the narrow scope of the evaluation.']",3,2,2,3,Reject
Czsdv-S4-w9,"The paper introduces DIGAN, a novel video generation framework leveraging implicit neural representations (INRs) to model continuous spatio-temporal dynamics. DIGAN consists of an INR-based generator that separately handles spatial and temporal features and a motion discriminator that identifies unnatural motions using pairs of frames. The model demonstrates state-of-the-art performance across multiple datasets and exhibits various beneficial properties such as long video generation and non-autoregressive generation.","['Can the authors provide more details on the implementation of the autoencoder aggregator and the modulation function?', 'What is the performance impact of different types of aggregators and modulation functions?', 'Can the authors discuss the potential limitations and broader impacts of their work in more detail?', 'Can the authors provide more ablation studies to investigate the impact of individual components?', 'Can the authors explain certain architectural choices in more detail?', 'Can the authors provide more qualitative examples to strengthen the claims?', 'Can you provide more detailed comparisons with additional state-of-the-art video generation methods?', 'Could you elaborate on the design choices for the discriminator and generator in more detail?', 'How does the use of smaller temporal frequencies specifically improve video coherence?', 'What specific measures do the authors propose to mitigate the potential misuse of the video generation technology, particularly in the context of deepfakes?']","['The paper does not adequately discuss potential limitations and negative societal impacts. Given the ethical concerns related to video generation, such as deepfakes, this discussion is crucial.', 'The paper should include more detailed ablation studies, particularly on the impact of temporal dynamics handling.', 'Comparisons with a broader range of baselines would strengthen the validity of the claims.', 'The ethical considerations section needs a more in-depth discussion and concrete proposals for mitigating misuse.']",True,3,3,3,6,4,"['The paper addresses a significant challenge in video generation by proposing a novel approach using INRs, which are compact and continuous.', 'The proposed model outperforms state-of-the-art methods on multiple benchmarks, demonstrating its effectiveness.', 'The paper includes extensive experiments and showcases various intriguing properties of the proposed method, such as long video synthesis and fast inference.', 'The architecture design, especially the separation of spatial and temporal features and the introduction of a motion discriminator, is innovative.']","['The clarity of certain methodological details, such as the implementation of the autoencoder aggregator and the modulation function, could be improved.', 'Additional ablation studies are necessary to further validate the effectiveness of individual components of the proposed architecture.', 'The paper lacks a detailed discussion on the potential limitations and negative societal impacts of the proposed work.']",4,3,3,4,Reject
18Ys0-PzyPI,"The paper introduces a novel reinforcement learning framework called ODITS, which addresses the problem of ad hoc teamwork under partial observability. The framework learns latent variables to represent teamwork situations, which are then inferred from local observations using an information-based proxy encoder. The experimental results demonstrate that ODITS outperforms various baselines in several ad hoc teamwork tasks.","['Can the authors provide more details on the implementation of the autoencoder aggregator used in the proxy encoder?', 'What is the performance of the proposed model with different types of aggregators and modulation functions?', 'Can the authors provide more qualitative results and visualizations to better illustrate the effectiveness of ODITS?', 'How does the proposed framework scale with larger team sizes and more diverse policies?', 'Can the authors perform additional ablation studies to isolate the contribution of each component more clearly?', 'How does ODITS compare with more recent state-of-the-art methods in ad hoc teamwork?', 'What are the justifications for the specific neural network structures used in ODITS? Have alternative architectures been considered?']","['The scalability of the approach to larger team sizes and diverse policies is a concern.', 'The experiments were conducted with relatively small teams and pretrained RL policies, which might not fully represent real-world scenarios.', 'The characterization and quantization of the influence of policy set diversity on performance are not explored.']",False,3,3,3,5,4,"['Addresses a significant and practical problem in multi-agent systems: ad hoc teamwork under partial observability.', ""Proposes a novel framework using latent variables to represent teammates' behaviors."", 'Includes an information-based regularizer to address partial observability, enhancing the adaptability of the autonomous agent.', 'Extensive experimental evaluations demonstrate superior performance of ODITS compared to various baselines.']","['The methodology section is dense and could benefit from clearer explanations, particularly regarding the implementation of the latent variable and proxy encoder.', ""The paper lacks certain ablation studies, such as the impact of different types of aggregators and modulation functions, which could provide a more comprehensive understanding of the framework's effectiveness."", 'Concerns regarding the scalability of the proposed approach to larger team sizes and more diverse policies.', 'The clarity of some sections, especially the mathematical derivations, could be improved.', 'The paper lacks a thorough comparison with the very latest and diverse state-of-the-art methods in ad hoc teamwork and multi-agent reinforcement learning.']",3,3,3,4,Reject
0DcZxeWfOPt,"The paper proposes Model Editor Networks with Gradient Decomposition (MEND) for efficient and localized post-hoc editing of large pre-trained models. MEND leverages low-rank decomposition of fine-tuning gradients to enable scalable and effective model updates using a single input-output pair. Extensive experiments on various large models (T5, GPT, BERT, BART) demonstrate the superiority of MEND over existing approaches.","['Could the authors provide more details on the scalability limits of MEND?', 'Can the authors expand on the potential failure modes of MEND in practical deployment scenarios?', 'Could the ethical considerations section be expanded to discuss potential misuse scenarios in more detail?', 'Can you provide more details on the initialization strategies and their impact on the performance?', 'How does MEND handle cases where the input-output pair is highly ambiguous?', 'Can the authors provide more details on potential methods to improve locality enforcement?', 'How does the method perform with other types of edits, such as reducing toxic outputs or adjusting control policies in different domains?', 'Can the authors provide more details on the initialization and normalization strategies used in the MEND networks?', 'How does MEND perform in scenarios with highly dynamic input distributions, such as those encountered in real-time applications?', 'How does MEND perform compared to more recent baselines not included in the paper?', 'Can the authors elaborate on the potential ethical concerns and how to mitigate risks of misuse?']","['The paper does not elaborate on the scalability limits and potential failure modes of MEND, which could be critical for understanding its practical deployment.', 'While ethical considerations are mentioned, more in-depth discussion on potential misuse scenarios would be beneficial.', 'The paper mentions the potential issue of over-generalization but does not provide a detailed analysis. Addressing this limitation with more experiments or discussions would be beneficial.', 'The practical implications of the proposed method, especially in terms of deployment and real-world challenges, are not extensively discussed. Additionally, while the method is shown to be effective on several large models, its performance on extremely dynamic input distributions remains unclear.', 'The paper acknowledges the limitation in enforcing the locality of edits and suggests future work in this direction. Additional limitations include the reliance on backtranslation for evaluating edit generality and the focus on transformer models.']",False,4,4,4,8,5,"['Addresses a practical and significant challenge in maintaining and updating large pre-trained models.', 'Novel approach leveraging low-rank decomposition of gradients for efficient model editing.', 'Extensive experiments and ablation studies demonstrating the effectiveness and scalability of MEND.', 'Detailed comparisons with existing methods, highlighting the advantages of MEND.']","['The paper could provide more details on the scalability limits and potential failure modes of MEND.', 'Ethical considerations are mentioned, but a more in-depth discussion on potential misuse scenarios could strengthen the paper.', 'Limited discussion on the potential limitations and scenarios where MEND might not perform well.', 'Ablation studies could be more detailed, particularly regarding the impact of different initialization strategies and other design choices.', 'Issues with enforcing locality of edits, leading to potential over-generalization.', 'Certain technical details, such as initialization and normalization strategies, are not fully explained, which may hinder reproducibility.']",4,4,4,4,Accept
mF5tmqUfdsw,"The paper proposes the Zeroth-Order Actor-Critic (ZOAC) algorithm, which combines zeroth-order optimization and first-order policy gradient methods within an actor-critic framework. The goal is to leverage the advantages of both methods, particularly for non-differentiable policies and robustness. Experiments on continuous control benchmarks show that ZOAC outperforms baseline methods.","['Can the authors provide more details on the rollouts collection strategy and its implementation?', 'What are the specific hyperparameters used in the experiments, and how sensitive is ZOAC to these hyperparameters?', 'Could the authors elaborate on the choice of N in the timestep-wise perturbation strategy and its impact on performance?', 'What are the potential limitations of ZOAC in its current form, and how might these be addressed in future work?', 'How does ZOAC perform compared to more recent state-of-the-art methods in RL?', 'Can the authors provide a more thorough ablation study of the components of ZOAC, including different configurations of the timestep-wise perturbations and the critic network?', 'Can the authors provide more empirical evidence for the effectiveness of timestep-wise perturbation compared to episode-wise?', 'How does ZOAC perform on a wider range of tasks, particularly those in real-world applications?', 'Can the theoretical derivations be simplified or made more intuitive for better understanding?']","['The paper does not discuss the limitations of ZOAC, such as its applicability to different environments or the computational cost of the proposed method.', 'Potential negative societal impacts of the work are not addressed.', 'The paper should address the limitations of the proposed method more explicitly, particularly in terms of its applicability to different types of RL problems and its computational complexity.']",False,3,2,3,3,4,"['The combination of zeroth-order and first-order methods in an actor-critic framework is a novel contribution.', 'The paper addresses an important challenge in reinforcement learning by combining zeroth-order and first-order methods.', 'Extensive experiments on a range of continuous control tasks show that ZOAC outperforms baseline algorithms in terms of sample efficiency and final performance.', 'The proposed method introduces a novel rollouts collection strategy and critic network to reduce variance and improve sample efficiency.']","['The clarity of the proposed algorithm needs improvement, especially the description of the rollouts collection strategy.', 'Further details about the implementation of the ZOAC algorithm would be beneficial.', 'The ablation studies provided are not exhaustive; more experiments are required to validate the individual contributions of each component.', 'The paper lacks a discussion on the limitations of the proposed method and potential negative societal impacts.', 'The novelty of the approach is somewhat limited. The idea of combining zeroth-order and first-order methods has been explored in previous works, and the contribution of this paper seems incremental.', 'The experimental setup lacks detailed descriptions, and some important baselines and ablation studies are missing.', 'The theoretical analysis could be more rigorous, particularly in terms of variance reduction and convergence guarantees.']",3,3,2,3,Reject
4l5iO9eoh3f,"The paper proposes a supervised learning framework to solve the Capacitated Vehicle Routing Problem (CVRP) with a fixed fleet size. It introduces a permutation-invariant pooling model and a post-processing step to enhance initial solutions. The approach ensures solutions fit within a fixed fleet size, which is critical for practical applications in logistics. The paper shows competitive results compared to state-of-the-art reinforcement learning approaches.","['Can the authors provide more detailed explanations of the methodology, particularly the embedding layer and information extraction mechanism?', 'How does the proposed approach compare to other supervised learning methods for CVRP, if any exist?', 'Can the authors conduct additional ablation studies to isolate the impact of different components of the proposed method?', 'Can the authors provide more details on the performance of the model without the post-processing step?', 'How does the model handle edge cases where the input data significantly deviates from the training distribution?', 'Can the authors provide more intuitive explanations for the pooling and decoding mechanisms?', 'Can the authors provide a clearer and more concise presentation of the main methodological contributions and the experimental setup?', 'Can the authors highlight and justify the necessity and impact of each modification to the existing architectures more convincingly?', 'Can the authors improve the clarity of the evaluation results and their practical significance?', 'Can the authors discuss the limitations and potential negative societal impacts of the proposed work in more detail?', 'Can the authors provide more visualizations and case studies to enhance the qualitative analysis?']","['The paper does not adequately address the limitations of the proposed approach, such as potential scalability issues and limitations in handling larger datasets.', 'The societal impact of the work is not discussed.', 'The clarity of the paper needs improvement, especially in the model description and post-processing steps.', 'More ablation studies are needed to demonstrate the contribution of different components of the model.']",False,2,2,2,5,4,"['Addresses a practical and important problem in logistics.', 'Introduces a novel supervised learning approach for CVRP.', 'Comprehensive experiments showing competitive results and reduced vehicle usage.']","['The paper lacks clarity in some sections, particularly in the detailed explanation of the methodology.', 'The novelty of the proposed approach is questionable as it extends existing work without substantial theoretical innovation.', 'The experimental evaluation could benefit from additional baselines and ablation studies to isolate the impact of different components of the proposed approach.', 'The reliance on post-processing to repair infeasible solutions suggests that the initial model predictions are often not feasible.', 'The paper does not adequately discuss the limitations and potential negative societal impacts of the proposed work.']",3,3,2,3,Reject
dEOeQgQTyvt,"The paper proposes SEAL, a framework that utilizes a structured energy network (SEN) as a dynamic loss function for training feedforward networks. The goal is to improve the efficiency and stability of structured prediction tasks, particularly in multi-label classification. The paper conducts extensive experiments on multiple datasets to demonstrate the effectiveness of SEAL.","['Can the authors provide a clearer explanation of how the dynamic loss function in SEAL works and how it differs from static approaches?', 'What are the specific advantages of SEAL over existing methods like INFNET and SPENs?', 'Can the authors conduct more comprehensive ablation studies to isolate the effects of different components of SEAL?', 'Can the authors provide more detailed implementation steps for the SEN and the dynamic loss updates?', 'What is the performance impact when varying the number of samples and using continuous versus discrete sampling in the NCE ranking loss?', 'Can the authors include more visualizations to support the qualitative analysis?', 'Can the authors provide more details on the implementation of the autoencoder aggregator?', 'Have the authors considered reducing the number of gating parameters in Eq. 10 by sharing the gate value of each filter in Conv layers?', 'Can the authors provide more theoretical justifications for the observed improvements in performance?']","['The paper does not discuss the limitations of the approach in sufficient detail. For example, how does SEAL perform on tasks other than multi-label classification?', 'Potential negative societal impacts of the work, such as issues related to fairness or bias, are not addressed.', ""The paper's complexity and the need for precise implementation details may affect reproducibility. Additionally, the lack of certain ablation studies leaves some questions unanswered regarding the optimal configuration of the proposed method.""]",False,2,2,3,4,4,"['The idea of using a structured energy network as a dynamic loss function is novel and interesting.', 'The paper provides a thorough experimental evaluation on a range of datasets, including both feature-based and text-based datasets.', 'The proposed SEAL-NCE variant shows significant improvements on certain datasets, indicating the potential of the approach.', 'Comprehensive experiments and analyses are provided.']","['The paper is densely written and difficult to follow, especially the explanation of the dynamic loss function and its advantages over static approaches.', 'The experimental results are mixed, with some datasets showing significant improvements while others do not, raising questions about the general applicability of SEAL.', 'The paper does not sufficiently differentiate its approach from related work like INFNET and SPENs, making it hard to assess the novelty of the contributions.', 'The limitations and potential negative societal impacts of the work are not adequately addressed.', 'The methodology section lacks clarity, especially regarding the implementation details of SEN and the dynamic loss updates.', 'Limited ablation studies on the modulation function and different types of aggregators.', 'The qualitative analysis is insufficient, with only one visualization provided per task.', 'The theoretical foundations of why SEAL should work are not well-explained, leaving some of the results to appear anecdotal rather than systematically justified.']",3,3,2,3,Reject
4Ycr8oeCoIh,"The paper investigates the process of GAN finetuning, focusing on the roles of pretrained generators and discriminators, and provides practical guidelines for selecting pretrained GAN checkpoints. The findings are validated through extensive experiments with the StyleGAN2 architecture and various datasets.","['Can the authors provide more detailed descriptions and explanations for the synthetic experiments?', 'What are the potential limitations of the proposed approach and areas for future work?', 'Can the authors conduct additional ablation studies on the impact of different modulation functions and aggregators?', 'Can the authors provide more qualitative examples to support their analysis?', 'Can you provide more details on the choice of datasets for pretraining and fine-tuning? How were these datasets selected?', 'Could you expand on the methodology used to compute the recall and gradient similarity metrics in the synthetic experiment?', 'Are there any specific limitations or challenges encountered during the experiments that were not discussed in the paper?', 'Can you provide more details or examples on the practical application of the proposed guidelines for selecting pretrained GANs?', 'Have you considered evaluating different types of aggregators or modulation functions in your ablation studies? If so, what were the results?', 'Please clarify the implementation and role of the autoencoder aggregator.']","['The paper does not establish causation in synthetic experiments, showing only correlations.', 'The practical recommendations, while useful, are somewhat intuitive and might not provide a significant advancement in understanding.', 'The paper could benefit from more detailed explanations and additional ablation studies to fully support the claims.', 'The findings are based on the StyleGAN2 architecture, and it is unclear if they generalize to other GAN models.', 'The practical recommendations provided may need further validation across a wider range of datasets and tasks.', 'The clarity of the paper could be improved, and additional ablation studies would enhance the quality of the analysis.']",False,3,3,3,6,4,"['Addresses a relevant and practical problem in GAN training.', 'Provides practical recommendations for selecting pretrained GAN checkpoints.', 'Extensive experiments with both synthetic and real datasets.', 'Offers insights into the roles of pretrained generators and discriminators.']","['Theoretical insights are incremental and somewhat intuitive.', 'Lacks causational evidence in synthetic experiments, showing only correlations.', 'Some critical experimental details are missing or unclear.', 'Limited discussion on limitations and future work.', 'The explanations in some sections are unclear and could be better structured.', 'The paper lacks some ablation studies, particularly on the impact of different modulation functions and aggregators.', 'The qualitative analysis could be more comprehensive, with more examples provided.', 'The presentation of results, especially in tables and figures, could be improved for better readability.']",3,3,3,3,Reject
O5Wr-xX0U2y,"The paper proposes a deep reinforcement learning algorithm for solving risk-averse dynamic decision-making problems using dynamic expectile risk measures. The algorithm extends the Deep Deterministic Policy Gradient (DDPG) to a risk-averse setting, addressing the issues of time-inconsistency in static risk measures. The method is evaluated on synthetic financial market data, demonstrating improved pricing and hedging strategies for financial derivatives.","['Can the authors provide more detailed explanations of the steps involved in the proposed algorithm, especially the training procedure and the update rules?', 'How does the proposed method compare to other state-of-the-art risk-averse DRL methods not considered in the paper?', 'Can the authors provide experimental results on real-world financial data to demonstrate the practical applicability of the proposed method?']","['The paper does not discuss the potential limitations and negative societal impacts of the proposed method. For example, the impact of using synthetic data for validation and the assumptions made in the financial models should be addressed.']",False,3,2,2,4,4,"['Addresses a significant and practical problem in risk-averse decision-making, particularly in financial applications.', 'Novel extension of DDPG to a risk-averse setting using dynamic expectile risk measures.', ""Comprehensive experiments conducted, demonstrating the algorithm's effectiveness on synthetic market data.""]","['Clarity of the methodology section could be improved. Several steps in the algorithm are not clearly explained.', 'Empirical validation is limited to synthetic data. Real-world data experiments would strengthen the claims.', 'Lacks thorough comparison with other state-of-the-art methods. Comparisons are not exhaustive.', 'Does not adequately discuss limitations and potential negative societal impacts.']",3,2,2,3,Reject
tFgdrQbbaa,"The paper provides a theoretical analysis of generalization performance in continual learning using the neural tangent kernel (NTK) framework. It explores the conditions under which sequential training results in positive or negative transfer, focusing on the target similarity and sample sizes. The paper introduces the concepts of self-knowledge transfer and forgetting, supported by both theoretical derivations and empirical validations using synthetic data and common deep learning architectures.","['Can the authors provide more practical insights or potential applications of the theoretical results?', 'Are there plans to extend the empirical validation to more diverse and complex tasks?', 'How do the results in the NTK regime translate to more common deep learning frameworks, especially those that do not strictly adhere to the NTK assumptions?', 'Can the authors provide more intuitive explanations for the key theoretical results?']","['The paper does not discuss the potential limitations of using the NTK regime for theoretical analysis in the context of real-world continual learning scenarios.', 'There is no mention of potential negative societal impacts of the work. Given the focus on learning efficiency and generalization, it would be prudent to consider ethical implications.']",False,3,3,3,5,4,"['Addresses a critical aspect of continual learning by providing a theoretical framework for understanding generalization performance.', 'The use of the NTK regime allows for a rigorous mathematical analysis, leading to insightful results about the conditions for positive and negative transfer.', 'Theoretical claims are supported by empirical experiments, demonstrating their relevance in practical scenarios.', 'Introduces novel concepts such as self-knowledge transfer and forgetting.']","['The practical significance of the theoretical results is not entirely clear. The NTK regime, while useful for theoretical analysis, may not fully capture the complexities of modern deep learning architectures in real-world applications.', 'The clarity of the paper could be improved. Some sections, particularly those involving complex mathematical derivations, are difficult to follow and may benefit from additional explanations or simplifications.', 'The empirical validation is somewhat limited in scope. More extensive experiments across a variety of tasks and architectures would strengthen the paper’s claims.', 'The paper does not adequately address potential limitations and negative societal impacts of the proposed theoretical framework.']",3,3,3,3,Reject
JYQYysrNT3M,"The paper introduces a new approach to reinforcement learning with vectorial rewards, aiming to maximize the expected minimum total reward (ex-post max-min fairness), as opposed to existing methods that maximize the minimum expected total reward (ex-ante max-min fairness). The authors propose an algorithm called Online-ReOpt, which uses a multiplicative weight update method and re-optimization schedule to achieve near-optimality under the ex-post objective. The paper also explores offline variants to reduce the burden of online computation. Theoretical guarantees are provided, and the effectiveness of the proposed methods is demonstrated through experiments in a queuing system.","['Can you provide more details on the scalarization process and the multiplicative weight update method used in the algorithm?', 'Have you considered different learning rates for the multiplicative weight update method? How does the choice of learning rate impact the performance of the algorithm?', 'Can you conduct additional experiments on different reinforcement learning problems to demonstrate the generalizability of the proposed approach?', 'Can the authors provide more details on the implementation of the optimization oracle Λ?', 'Are there any additional baselines that could be included in the experiments to provide a more comprehensive comparison?', 'Can the authors provide more details on the theoretical proofs, especially the derivation of the regret bound in Theorem 1?', 'Can the authors provide more details about the autoencoder aggregator?', 'What is the impact of different modulation functions and aggregators on the performance of the proposed method?', 'Can the authors include more visualizations and examples in the qualitative analysis?', 'How does the proposed method compare with a broader set of baseline algorithms?', 'Can the authors address potential limitations and societal impacts in more depth?']","['The paper should better address the choice of learning rate and its impact on the performance of the algorithm. Additionally, more diverse experiments are needed to demonstrate the generalizability of the approach.', 'The paper does not fully address the potential limitations and drawbacks of the proposed methods. For instance, the dependency on the optimization oracle Λ and the computational burden of the proposed algorithms should be discussed in more detail.', 'The scalability and real-world applicability of the proposed methods need further validation.', 'The lack of clarity in the description of the autoencoder aggregator.', 'The need for more comprehensive ablation studies and comparisons with additional baseline algorithms.', 'The paper does not address potential limitations and societal impacts in depth, which is an important aspect for responsible AI research.']",False,3,2,3,5,4,"['The paper tackles an important problem in reinforcement learning by focusing on ex-post max-min fairness, which is a novel and significant perspective.', 'The proposed Online-ReOpt algorithm and its theoretical analysis are well-founded and show convergence to the optimal solution as the number of time steps increases.', 'The paper provides a thorough comparison between ex-ante and ex-post max-min fairness, highlighting the limitations of existing methods for the ex-post objective.', 'The experiments on a queuing network demonstrate the effectiveness of the proposed algorithms, particularly in terms of ex-post fairness.']","['The clarity of the methodology section could be improved. Some parts, especially the scalarization process and the multiplicative weight update method, are not explained in sufficient detail.', 'The paper lacks sufficient ablation studies to show the impact of different components of the proposed algorithm. For example, the choice of learning rate and the impact of different policy families in the offline variants are not thoroughly investigated.', 'The experimental results, while promising, are limited to a single queuing network scenario. More diverse experiments on different types of problems (e.g., other reinforcement learning benchmarks) would strengthen the conclusions.', 'The paper lacks clarity in some parts, especially in the description of the experiments and the theoretical proofs.', 'More details are needed on the implementation of the optimization oracle Λ and how it is practically realized.', 'The experimental section could benefit from additional baselines and more comprehensive comparisons.', 'The paper would benefit from a more detailed discussion on the limitations and potential drawbacks of the proposed methods.', 'The reliance on an optimization oracle is a significant assumption that needs further justification.', 'Some sections, particularly those detailing the algorithms and theoretical proofs, are dense and could be more accessible.', 'The qualitative analysis could be strengthened by including more visualizations and examples.']",3,3,2,3,Reject
2s4sNT11IcH,The paper proposes a novel global clipping method to improve the convergence and calibration of deep learning models trained with differential privacy (DP). The authors provide a theoretical analysis using the neural tangent kernel (NTK) framework and show that global clipping can improve convergence and calibration while maintaining DP guarantees. Extensive experiments validate the proposed method on various datasets and architectures.,"['Can the authors provide more detailed explanations and clearer notations in the theoretical analysis?', 'Can the authors include additional benchmarks and diverse datasets in the empirical validation?', 'Can the authors provide more detailed implementation details for reproducibility?', 'Can the authors provide additional ablation studies to better understand the impact of different components of the proposed method?', 'Can the authors discuss potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide a clearer explanation and examples of the computational overhead introduced by global clipping?', 'How do the hyperparameters influence the performance of the proposed method?', 'Can the authors elaborate on the real-world impact of improved calibration and convergence?']","['The paper relies heavily on the NTK framework, which may not be applicable to all network architectures and real-world scenarios.', 'The empirical validation is limited to standard datasets; additional benchmarks and diverse datasets are needed.', 'The complexity of the theoretical analysis might limit the accessibility for readers without a strong mathematical background.', 'The empirical results, while extensive, might not fully generalize across all types of datasets.', 'The computational overhead of the proposed method needs to be clearly discussed.']",False,3,2,3,5,4,"['Addresses an important issue in DP deep learning.', 'Proposes a novel global clipping method that improves convergence.', 'Provides a solid theoretical analysis using the NTK framework.', 'Extensive experimental validation on multiple datasets and architectures.']","['Theoretical analysis relies heavily on the NTK framework, which may not be applicable to all network architectures.', 'Empirical validation could benefit from more diverse datasets and additional ablation studies.', 'Clarity of presentation is lacking, particularly in the theoretical sections and the description of the global clipping method.', 'Implementation details are insufficient for reproducibility.', 'Limited discussion on potential limitations, negative societal impacts, and computational overhead.']",3,3,2,4,Reject
6-lLt2zxbZR,"The paper explores the use of pseudo-log-likelihoods (PLLs) and token-normalized PLLs (NormPLLs) for scoring natural language models on common sense reasoning tasks. Using the ALBERT-xxlarge-v2 model, it demonstrates state-of-the-art performance on several datasets, including TimeDial and Winogrande, without fine-tuning. The authors argue that the robustness of their method can be attributed to the compositionality of the model’s representations.","['Can the authors provide more detailed descriptions of the experimental setup and hyperparameter settings used?', 'How does the model perform on tasks other than binary choice, such as multi-choice or open-ended questions?', 'Can the authors validate the robustness claims with additional datasets and different types of perturbations?', 'What are the potential biases introduced by the data processing steps, and how do they affect the results?', 'How can the computational cost be reduced to make the approach more practical?', 'Can the authors discuss any potential negative societal impacts of their work, particularly in terms of robustness and bias?']","['The paper does not provide sufficient details to ensure reproducibility of the results.', 'The evaluation is limited to binary choice tasks, which may not fully capture the model’s capabilities and robustness.', 'The high computational cost and potential biases introduced by data processing are significant concerns.', 'The robustness claims need more empirical support through detailed ablation studies.']",True,2,2,2,4,4,"['The paper addresses an important challenge in NLP: evaluating common sense reasoning without the need for fine-tuning.', 'It demonstrates impressive performance on multiple datasets, showcasing the efficacy of PLLs and NormPLLs.', 'The approach is computationally efficient in terms of model size, offering a practical advantage over larger models.', 'The paper includes a thorough comparison with existing models and methods, highlighting its contributions.']","['The methodology section lacks clarity, making it difficult to fully understand the implementation details.', 'Reproducibility is a concern due to the absence of detailed experimental setup and hyperparameter settings.', 'The evaluation focuses primarily on binary choice tasks, which limits the generalizability of the findings to other types of NLP tasks.', 'The robustness claims are not thoroughly validated with diverse datasets and perturbations.', 'The high computational cost makes the approach impractical for many applications.', 'Potential ethical concerns related to robustness and bias in language models are not adequately addressed.']",2,2,2,3,Reject
cD0O_Sc-wNy,"The paper proposes a novel approach to replay-based continual learning by focusing on scheduling which tasks to replay at different times. The authors use Monte Carlo Tree Search (MCTS) to learn these schedules, and their extensive evaluation shows that this method can significantly improve performance over traditional baselines that do not consider scheduling.","['Can the authors provide more details on the computational efficiency and scalability of the MCTS approach in the context of larger continual learning problems?', 'Do the authors have any theoretical insights or guarantees on the convergence and performance of the proposed scheduling method?', 'Can the authors provide additional visualizations and qualitative analysis of the learned replay schedules to further illustrate their benefits?', 'Could the authors provide more details on how MCTS parameters were chosen and their impact on the results?', 'How does the method perform if the number of tasks increases significantly?', 'Could you provide more detailed explanations and perhaps some examples to clarify the methodology section?', 'How does your method compare to state-of-the-art non-replay-based continual learning methods?', 'Have you considered the scalability of MCTS for larger datasets or more complex tasks?', 'Can the authors provide more details on the specific hyperparameters used for MCTS and the training of neural networks?', 'Could the authors conduct additional ablation studies to better understand the impact of different components of the proposed method?', 'What are the potential limitations of the proposed method in terms of scalability and computational cost?', 'Can the authors provide more qualitative analysis of the learned replay schedules?', 'Can you provide more detailed explanations on how the replay schedule tree is constructed and traversed?', 'What are the computational costs associated with the proposed method, and how do they compare with other baselines?', 'Could you conduct additional ablation studies to isolate the impact of the replay scheduling from the memory selection method?']","['The primary limitations are related to the scalability and computational efficiency of the MCTS approach, and the lack of theoretical guarantees on the performance and convergence of the proposed method.', 'The qualitative analysis of the learned schedules could be more detailed.', 'The paper does not adequately discuss the potential limitations and negative societal impacts of the proposed method. It is important to consider the scalability and computational cost of MCTS in real-world applications.']",False,3,3,3,6,4,"['The paper addresses a practical and relevant problem in continual learning, particularly the timing of task replays.', 'The use of MCTS for learning replay schedules is an innovative application and adds a new dimension to the replay-based continual learning paradigm.', 'The empirical results are comprehensive and demonstrate the effectiveness of the proposed method across multiple benchmark datasets.', 'The method is versatile and can be combined with various memory selection strategies.']","['The explanation of the methodology, particularly the application of MCTS for replay scheduling, is sometimes unclear.', 'There is a lack of theoretical analysis or guarantees on the performance and convergence of the proposed method.', 'The scalability and computational efficiency of using MCTS for this problem, especially for larger and more complex continual learning setups, are not thoroughly discussed.', ""The qualitative analysis of the learned replay schedules is somewhat limited. More visualizations and detailed insights into the replay patterns could enhance the understanding of the method's advantages."", 'The paper lacks thorough ablation studies to understand the contribution of each component of the proposed method.']",3,3,3,4,Reject
dtt435G80Ng,"The paper introduces Centered Symmetric Quantization (CSQ), a method designed to improve the performance of low-bit quantized neural networks by addressing asymmetries in conventional quantization schemes. The authors provide both analytical and empirical evidence to support their claims, and propose an efficient hardware implementation for CSQ. Experiments on CIFAR-10 and ImageNet datasets demonstrate the benefits of CSQ over conventional linear quantization (CLQ) at 2-bit and 3-bit precision.","['How does CSQ compare with other state-of-the-art quantization methods beyond the ones cited in the paper?', 'Can the authors provide more details on the hardware implementation and the experimental setup?', 'How does CSQ fundamentally differ from the similar approaches mentioned in related works?', 'Can the authors provide more theoretical analysis to support the empirical findings?', 'What are the potential limitations of the CSQ method in real-world applications?', 'Can the authors elaborate on the hardware implementation strategy and provide more empirical validation?', 'Can the authors provide more insights into the potential limitations or negative impacts of CSQ, such as effects on network robustness or training stability?', 'How does CSQ perform in scenarios where exact zero representation is crucial? Are there specific applications where CSQ might not be beneficial compared to other quantization methods?', 'Can the authors provide more details on how CSQ integrates with existing hardware architectures, particularly in comparison to other quantization methods?', 'How does CSQ perform on different types of neural networks (e.g., RNNs, transformers) or tasks beyond image classification?']","['The paper does not adequately address its limitations, particularly in terms of the novelty of the proposed method and the comprehensiveness of the evaluation.', 'The primary limitation is the clarity of the methodology, which could hinder reproducibility. Additionally, potential hardware overheads and the exact impact of configurations are not fully explored.', 'No discussion of limitations or potential negative societal impacts is provided.', 'The broader applicability of CSQ is not discussed in detail, leaving questions about its performance in scenarios where exact zero representation is crucial.']",False,3,2,3,5,4,"['The paper addresses an important problem in the field of quantization for neural networks, particularly at very low bit precision.', 'The proposed CSQ method is shown to improve performance over conventional methods at 2-bit and 3-bit precision.', 'The authors provide a detailed analysis and an efficient hardware implementation for CSQ.', 'Experimental results on CIFAR-10 and ImageNet datasets support the claims made in the paper.']","['The novelty of the paper is somewhat limited as the idea of zero-centered quantization has been explored in prior work.', 'The paper could benefit from a more comprehensive evaluation, particularly in comparing CSQ with other state-of-the-art quantization methods beyond the ones cited.', 'The clarity of the paper could be improved, especially in explaining the hardware implementation and some of the experimental details.', 'Theoretical analysis is lacking, particularly regarding the potential limitations of CSQ in practical deployment.', 'The broader applicability of CSQ is not thoroughly discussed, leaving questions about when it might not be beneficial compared to other methods.']",3,3,2,3,Reject
LtI14EpWKH,"The paper proposes tessellated 2D convolution networks (TCNN) as a defense mechanism against adversarial attacks. The core idea is to partition the input image into non-overlapping tiles and process them through separate branches of a CNN. The authors investigate three tessellation schemes: regular, aperiodic, and Mondrian. Experiments on FMNIST and CIFAR-10 datasets show that TCNN offers better robustness against FGSM and PGD attacks compared to conventional CNNs.","['Can the authors provide more detailed explanations and motivations for choosing specific tessellation patterns?', 'Can the authors conduct more comprehensive ablation studies to isolate the contribution of each component?', 'Can the authors test the proposed method on more complex datasets to evaluate its generalizability?', 'Can the authors provide more details on the Mondrian tessellation process and its implementation?', 'Have the authors considered the computational overhead introduced by the tessellation and parallel branches? How does it compare to standard 2D CNNs?', 'How does the proposed method compare with more state-of-the-art defense mechanisms?']","['The paper does not adequately justify the choice of specific tessellation patterns.', 'The experiments are limited to two datasets, which may not generalize well to more complex scenarios.', 'The computational overhead introduced by the tessellation process and parallel branches is not discussed.', 'The impact of different tessellation parameters on the network performance is not fully explored.']",False,2,2,3,4,4,"['The idea of using tessellation as a defense mechanism against adversarial attacks is novel and interesting.', 'The paper covers three different tessellation schemes and provides a comparative analysis.', 'Experimental results show that the proposed TCNN approach improves robustness against well-known adversarial attacks.']","['The clarity of the paper is compromised by poor formatting and a lack of detailed explanations in some sections.', 'The ablation studies are not comprehensive enough to fully understand the contribution of each component.', 'The justification for choosing specific tessellation patterns is insufficient.', 'Experiments are limited to two datasets, which may not generalize well to more complex scenarios.', 'The paper lacks detailed ablation studies to understand the impact of different components of the proposed method.', 'The explanation of the Mondrian tessellation and its implementation is somewhat unclear and could be elaborated further.', 'The paper does not provide sufficient details on the computational overhead introduced by the tessellation process and the parallel branches in the network.', 'The novelty of the approach compared to existing ensemble and partitioning strategies is not fully established.', 'The experimental evaluation could be more thorough, including comparisons with more recent and advanced defense mechanisms.', 'The paper does not explore the potential limitations or negative societal impacts of the proposed method.']",3,2,2,3,Reject
xspalMXAB0M,"The paper proposes a novel boosting algorithm for reinforcement learning, leveraging weak learners to iteratively improve policy performance. The approach uses a variant of the Frank-Wolfe optimization method and recent techniques in boosting with multiplicative approximations. The authors provide sample complexity and running time bounds, claim that their method does not explicitly depend on the number of states, and offer theoretical guarantees for the proposed algorithm.","['Can you provide more intuition and detailed explanation for the extension operator and its role in the algorithm?', 'How does the proposed method compare with existing state-of-the-art reinforcement learning algorithms in practical scenarios?', 'Can you provide experimental results to validate the theoretical claims and demonstrate the performance of the proposed method in real-world applications?', 'What are the potential limitations and negative societal impacts of your proposed method?']",['The paper lacks discussion on limitations and potential negative societal impacts of the proposed method. It would be beneficial to address these aspects to provide a more holistic view of the approach.'],False,2,2,3,4,4,"['The paper addresses a significant problem in reinforcement learning: efficient policy learning in large state spaces.', 'The proposed methodology is novel, combining boosting techniques with reinforcement learning through a non-convex variant of the Frank-Wolfe method.', 'The theoretical analysis is comprehensive, providing sample complexity and running time bounds, as well as global optimality guarantees under certain conditions.']","['The paper is overly complex and not well-organized, making it difficult to follow the methodology and theoretical claims.', 'There is a lack of detailed explanation and intuition behind key steps in the algorithm, particularly the construction and role of the extension operator.', 'The experimental validation is weak. No practical experiments or comparisons with existing state-of-the-art methods are provided, making it hard to assess the real-world applicability and performance of the proposed algorithm.', 'The paper does not discuss potential limitations or negative societal impacts of the proposed method, which is important for a comprehensive evaluation.']",3,2,2,3,Reject
p7LSrQ3AADp,"The paper introduces a framework for characterizing and comparing saliency methods using nine dimensions grouped into three categories: methodology, sensitivity, and perceptibility. It aims to provide a more granular way to assess saliency methods beyond the traditional focus on faithfulness. The framework's utility is demonstrated through practical examples, including the development of 'saliency cards' and a case study in radiology.","[""Can the authors provide a formal evaluation or quantitative assessment of the framework's effectiveness?"", 'Are there other relevant dimensions that were considered but not included in the framework?', ""Can the authors provide empirical validation of the proposed framework's dimensions and their utility in real-world scenarios?"", ""How can 'perceptual correspondence' and other subjective dimensions be quantified in a standardized manner?"", 'Can the authors provide more concrete and objective measures for the dimensions like perceptual correspondence and minimality?', 'How do the authors envision practitioners using this framework in real-world scenarios?', 'Can the authors provide more quantitative validation of the framework using multiple datasets and saliency methods?', 'How can the framework be operationalized for new saliency methods? Are there specific guidelines or steps that can be followed?', 'Can the authors provide more details on how to measure dimensions like perceptual correspondence effectively?', 'How does the proposed framework compare with existing frameworks and evaluation metrics for saliency methods?']","['The framework is mostly descriptive, and while practical examples are provided, there is no formal evaluation or quantitative assessment of its effectiveness.', ""The framework's complexity may hinder its practical application, and the lack of empirical validation raises questions about its effectiveness in real-world scenarios."", 'The framework is highly theoretical and lacks practical validation. There is also a lack of clear, objective measures for some of the dimensions.', 'The framework is primarily descriptive, and its practical utility needs to be validated through empirical studies or real-world applications.', 'Some dimensions, like perceptual correspondence, are challenging to measure and require user studies, which are not provided in the paper.', 'The reliance on qualitative assessments might lead to subjective interpretations.', 'The lack of detailed empirical validation limits the practical utility of the framework.']",False,3,3,3,5,4,"['Comprehensive framework that offers a systematic way to characterize saliency methods.', 'Practical applications are demonstrated, including a case study in a high-stakes domain (radiology).', 'Novel shift from focusing solely on faithfulness to considering multiple dimensions.', 'The framework provides a structured way to evaluate saliency methods, moving beyond the singular notion of faithfulness.', 'The categorization into methodology, sensitivity, and perceptibility is logical and covers a broad range of important characteristics.', ""The use of 'saliency cards' for documentation is a practical contribution that could aid in the standardization and comparison of saliency methods.""]","[""Lack of formal evaluation or quantitative assessment of the framework's effectiveness."", 'Potential gaps in the nine proposed dimensions, which might not cover all relevant aspects.', 'The framework could be overly complex, making it challenging to apply in practice, especially for non-experts.', ""The paper lacks empirical validation of the framework's dimensions and their utility in real-world scenarios."", ""Some dimensions, such as 'perceptual correspondence,' are difficult to quantify and may require subjective interpretation."", ""The framework's dimensions are somewhat abstract and may not be easily applicable or measurable in practical scenarios."", 'The paper lacks a thorough experimental validation of the proposed framework. Most of the validation is qualitative or theoretical.', 'The dimensions such as perceptual correspondence are not well-defined or objectively measurable, which could lead to ambiguity in their application.', 'It is unclear how useful the framework will be in real-world applications without more concrete examples and user studies.']",3,3,3,3,Reject
VFBjuF8HEp,"The paper introduces Differentiable Diffusion Sampler Search (DDSS), a method to optimize fast samplers for pre-trained diffusion models by differentiating through sample quality scores. The proposed approach leverages the reparametrization trick and gradient rematerialization to optimize over a parametric family of few-step samplers, termed Generalized Gaussian Diffusion Models (GGDM). The results show improved sample quality with significantly fewer inference steps compared to existing methods.","['Can the authors provide a clearer explanation of GGDM and its parametrization?', 'How does the method scale with larger models or datasets?', 'What is the impact on training time when optimizing the samplers with DDSS?', 'Can the authors provide more details on the autoencoder aggregator and its role in the framework?', 'What is the impact of using different modulation functions, and can the authors provide results for reduced gating parameters?', 'How does the performance vary with different types of aggregators?', 'Could you provide more details on the computational efficiency of DDSS, especially in terms of memory and time costs?', 'Have you considered applying DDSS to domains beyond image generation to demonstrate its versatility?', 'Can the authors clarify the mathematical derivations in Section 4 and provide more intuitive explanations?', 'Would it be possible to include more qualitative results, such as additional visual samples, to further illustrate the improvements in sample quality?']","['The paper lacks a detailed discussion on potential limitations, such as the scalability of the method and its impact on training time.', 'The paper could benefit from a clearer presentation of complex mathematical formulations.', 'A more detailed discussion on the computational efficiency of the proposed method would be helpful.']",False,3,3,4,6,4,"['The paper addresses a critical issue in diffusion models—high computational cost of generating samples.', 'The proposed DDSS method is novel and leverages differentiable optimization techniques effectively.', 'Comprehensive experiments demonstrate significant improvements in sample quality with fewer inference steps.', 'The approach is compatible with any pre-trained diffusion model, which increases its practical applicability.']","['The explanation of GGDM and its parametrization could be clearer, especially for readers less familiar with diffusion models.', 'The paper could benefit from more detailed ablation studies to thoroughly assess the contributions of each component.', 'Potential limitations, such as scalability to larger models or datasets, and the impact on training time, are not sufficiently addressed.', 'Some experimental results, particularly on larger datasets, need more detailed analysis to ensure robustness.']",4,3,3,4,Accept
jE_ipyh20rb,"The paper proposes FEDPROF, a novel algorithm for optimizing Federated Learning (FL) by profiling and matching data representations to dynamically adjust client participation. The approach aims to mitigate the impact of low-quality and biased data on the training process. Extensive experiments demonstrate the effectiveness of FEDPROF in terms of accuracy, convergence speed, and energy efficiency.","['Can you provide more details on the autoencoder aggregator?', 'Can you include more cases in qualitative analyses?', 'What are the results of the method with different types of aggregators?', 'Can the authors provide a clearer and more detailed explanation of the theoretical proofs?', 'How does FEDPROF compare with other state-of-the-art methods in more detail?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How does the profiling process ensure data privacy and security?', 'Could you provide more details on the representation profiling process, specifically how profiles are generated and matched?', 'What is the impact of different hyperparameters used in the profiling and scoring mechanism?', 'Can you provide an analysis of the fairness implications of your method, particularly in terms of how client selection might bias the results?', 'Can the authors provide more detailed descriptions and examples of the representation profiling process and how it is used in practice?', 'Could the authors clarify the experimental setup, particularly the distribution of noise and specifics of client heterogeneity?', 'How does FEDPROF compare to other state-of-the-art FL methods not included in the paper? Can more baselines be added for comparison?', 'What are the potential negative societal impacts of the proposed method? Are there any limitations that need to be addressed?', 'Can the authors provide more details on the computational overhead of the profiling and client selection process?', 'How does the method perform with real-world data that might not follow the Gaussian distribution assumption?', 'Can the authors compare their method with other robust aggregation techniques in FL?']","['The paper does not adequately address the potential issue of fairness in client selection and its societal impacts.', 'The potential limitations and negative societal impacts of the proposed method are not adequately discussed. Specifically, the risks associated with the profiling process and the ethical implications of adjusting client participation probabilities need to be addressed.', 'The paper could benefit from a more detailed discussion on the limitations of the profiling method, including the computational overhead and potential biases introduced by selective participation.', 'Potential negative societal impacts, such as the exclusion of clients with lower-quality data and the fairness of such exclusions, should be addressed in more detail.', 'The potential negative societal impacts and limitations of the proposed method are not adequately discussed. The authors should address these points to provide a balanced view of their work.', 'The paper should include a more detailed discussion on the limitations of the Gaussian distribution assumption.', 'The authors should provide a more comprehensive comparison with other methods handling low-quality data in FL.']",False,3,2,3,4,4,"['Addresses a critical issue in FL: the impact of low-quality and biased data on the training process.', 'The method of using data representation profiling for client selection is novel.', 'Provides a thorough theoretical analysis, including proofs and convergence guarantees.', 'Extensive experiments demonstrate the effectiveness of the proposed method in terms of accuracy, convergence speed, and energy efficiency.']","['The clarity of the paper is a significant concern, particularly the theoretical analysis and the algorithm description.', ""The method's dependency on the assumption that data representations follow a Gaussian distribution might limit its applicability."", 'Lacks a detailed comparison with other techniques that handle low-quality data in FL, such as robust aggregation methods.', 'The computational overhead introduced by the profiling and client selection process is not thoroughly analyzed.', 'The scalability of the proposed method is not convincingly demonstrated.', 'Potential negative societal impacts and fairness issues arising from selective client participation are not adequately addressed.']",3,3,2,3,Reject
YLglAn-USkf,The paper investigates the zero-shot capabilities of BERT family models by exploring different strategies to enhance performance. Key contributions include the proposal of the Multi-Null Prompt strategy and a thorough empirical evaluation across multiple datasets. The authors also provide a detailed analysis of the limitations of zero-shot prompting.,"['Can the authors provide more details on the implementation of the autoencoder aggregator?', 'What is the performance of the proposed model with different modulation functions?', 'Can the authors provide more case studies and qualitative analysis of the results?', 'How do the proposed methods perform on other NLP tasks beyond text classification?', 'Can the authors conduct additional ablation studies to investigate the impact of different components of the proposed methods?', 'Can the authors provide more qualitative analysis and visualizations to support their findings?', 'How does the proposed method compare with other state-of-the-art zero-shot learning methods?']","['The paper should address more clearly the limitations of the proposed strategies and provide more comprehensive ablation studies.', 'Potential negative societal impacts of large-scale language models should be discussed in more detail.', 'The proposed methods may not generalize well to NLP tasks beyond text classification.', 'The study does not address potential negative societal impacts of deploying zero-shot PLMs in real-world applications.']",False,3,3,3,6,4,"['The paper addresses a timely and important issue of zero-shot learning with pre-trained language models.', 'The proposed Multi-Null Prompt strategy is novel and shows significant improvement over baseline methods.', 'Comprehensive experiments are conducted across various datasets, providing a robust evaluation of the proposed methods.', 'The paper includes detailed analysis and discussion on the limitations of zero-shot prompting, which is valuable for future work.']","['The paper lacks clarity in explaining some methodological details, particularly the implementation of the autoencoder aggregator and the exact nature of some experiments.', 'Additional ablation studies are necessary to fully understand the effectiveness of the proposed strategies, such as different modulation functions and types of aggregators.', 'More qualitative analysis and case studies would make the results more convincing.', 'The paper could benefit from a more detailed discussion on the potential societal impacts and ethical considerations of large-scale language models.']",3,3,3,4,Reject
mFpP0THYeaX,"The paper introduces GIFT (Gradual Interpolation of Features toward Target), a method designed to tackle the problem of domain adaptation when intermediate distributions are not available. GIFT creates virtual samples by interpolating between source and target data, helping the model gradually adapt to the target distribution. The authors provide empirical evidence from synthetic and natural distribution shifts to demonstrate the efficacy of GIFT over iterative self-training.","['Can the authors provide a detailed ablation study on the choice of interpolation coefficients and the effect of different alignment strategies?', 'What is the computational cost of GIFT compared to other self-training methods? Can the authors provide a detailed comparison?', 'Can the authors provide more experiments on diverse and complex real-world datasets to strengthen the claims?', 'How does the choice of alignment method (random vs. cost-based) impact the performance of GIFT in different scenarios?', 'How would GIFT perform on non-image datasets, such as textual data?', 'Can the authors provide more details on the interpolation process, especially the selection of samples and the role of the lambda_scheduler?', 'How does the performance of GIFT vary with different hyperparameters, particularly the step size for interpolation and the confidence threshold?', 'Could the authors compare GIFT with more state-of-the-art domain adaptation techniques to better establish its robustness?']","['The paper does not provide a detailed computational analysis, especially for the cost-based alignment method. Understanding the computational overhead is important for practical applications.', 'The scope of experiments is limited to a few datasets. More diverse and complex datasets would provide stronger support for the claims.', 'The primary limitation is the clarity of the methodology regarding the interpolation process and sample selection. Additionally, the applicability of GIFT to non-image datasets remains unexplored.', 'The paper should discuss the limitations of GIFT in terms of computational complexity and the potential challenges in applying it to other types of data (e.g., textual data).', 'It would be beneficial to include a discussion on the scenarios where GIFT might not perform well, such as when the source and target domains are extremely dissimilar.']",False,3,3,3,6,4,"['Addresses a significant problem in domain adaptation, particularly when intermediate distributions are absent.', 'Proposes a novel approach (GIFT) that creates virtual samples through interpolation, which is shown to be effective.', 'Extensive experiments on synthetic and natural distribution shifts, providing a comprehensive evaluation.', 'Demonstrates clear improvement over iterative self-training, especially when the target distribution lacks diversity.']","['The clarity of the methodological details, particularly regarding the interpolation process and the alignment of source and target samples, can be improved.', 'The paper lacks a thorough ablation study to understand the contribution of each component of the proposed method.', 'The computational cost of GIFT, particularly with cost-based alignment methods, is not thoroughly discussed.', 'The scope of experiments is limited to a few datasets. More diverse and complex datasets would provide stronger support for the claims.', 'Comparative analysis with more state-of-the-art domain adaptation methods is needed to establish the robustness of GIFT.']",3,3,3,4,Reject
q4HaTeMO--y,The paper 'Declarative Nets that are Equilibrium Models' proposes a theoretical equivalence between Deep Declarative Networks (DDNs) and Deep Equilibrium Models (DEQs) by showing that solving a kernelized regularized maximum likelihood estimate in a DDN yields a DEQ architecture. The authors provide a closed-form expression for the DEQ parameters in terms of the kernel and propose an initialization scheme for DEQs that improves training stability and performance.,"['Can you provide more intuition behind the choice of kernels and how they influence the DEQ parameters?', 'While the paper shows improved stability, how does the proposed initialization compare to other advanced initialization methods in practice?', 'Can the authors provide more details on the autoencoder aggregator and its role in the experiments?', 'What is the impact of different types of aggregators and modulation functions on the performance of the proposed model?', 'Can the authors expand on the potential negative impacts and limitations of their proposed methods?', 'Can the authors provide more intuitive explanations and simplify the presentation of the theoretical results?', 'What are the main limitations of the proposed approach, and how might they impact its applicability in different settings?', 'Can the authors discuss the broader implications of their work beyond the specific context of DEQs and DDNs?', 'How does the proposed initialization scheme compare with other advanced initialization schemes in terms of computational cost and performance?', 'Have the authors considered additional baseline comparisons in their empirical evaluation?', 'Can the authors provide more intuitive explanations or visual aids for the complex mathematical derivations?']","['The paper is heavily theoretical and might benefit from more practical evaluations across a variety of tasks and datasets.', 'The clarity of some mathematical sections could be improved for better accessibility.', 'The complexity of the mathematical formulations may limit the accessibility and adoption of the proposed methods.', 'The empirical scope is somewhat narrow, focusing on specific tasks. Broadening this could strengthen the impact.', 'A more thorough discussion on potential negative impacts and ethical considerations would be valuable.']",False,3,3,3,6,4,"['The paper addresses a novel equivalence between DDNs and DEQs, leveraging kernelized models.', 'The theoretical contributions are solid and introduce a new way to interpret DEQs.', 'The paper presents a rigorous theoretical framework, supported by empirical evidence.', 'The proposed initialization scheme shows empirical improvements in training stability and performance.']","['Some proofs and derivations are complex and might benefit from additional clarity.', 'The paper is heavily theoretical and could benefit from more extensive practical evaluations.', 'The clarity of some mathematical sections could be improved for better accessibility.', 'Limited empirical validation and scope of experiments.', 'Insufficient discussion on limitations and broader implications.']",3,3,3,4,Reject
FPCMqjI0jXN,The paper 'DOMINO: Discovering Systematic Errors with Cross-Modal Embeddings' introduces a novel approach for identifying systematic errors in machine learning models using cross-modal embeddings and an error-aware mixture model. The authors also present an evaluation framework for quantitatively assessing slice discovery methods (SDMs). Experimental results demonstrate that DOMINO outperforms existing methods in identifying coherent and underperforming slices across various domains.,"['Can the authors provide more details on the implementation of the error-aware mixture model?', 'Could the authors include additional examples or visual aids to clarify the generation of natural language descriptions?', 'How does the performance of DOMINO vary with different values of the hyperparameter γ in the error-aware mixture model?', 'Can the authors provide a more detailed comparison between the error-aware mixture model and existing methods like Spotlight?', 'How does DOMINO perform in settings where cross-modal embeddings are not available or are of poor quality?', 'Can the authors include more ablation studies to isolate the contributions of different components of DOMINO?', 'Can the authors explain the differences between synthetic and trained models in more detail and their respective impacts on the results?', 'Are there any plans to simplify the evaluation framework for easier implementation by practitioners?', 'Can the authors provide more examples of generated natural language descriptions across different domains in the rebuttal?']","['The paper does not extensively discuss the potential negative societal impacts of using biased embeddings for slice discovery. It would be beneficial to include a discussion on this aspect.', 'The reliance on pre-trained cross-modal embeddings and the potential biases introduced by these embeddings.', 'The computational overhead involved in generating cross-modal embeddings and the potential limitations in scenarios where such data is not readily available should be discussed in more detail.']",False,3,3,4,7,4,"['Addresses the significant issue of systematic errors in machine learning models.', 'Proposes a novel combination of cross-modal embeddings and an error-aware mixture model.', 'Develops a comprehensive quantitative evaluation framework for SDMs.', 'Demonstrates significant improvements over existing methods through extensive experiments.', 'The ability to generate natural language descriptions of discovered slices enhances interpretability.', 'Provides an open-source implementation, promoting reproducibility.']","['Some sections, such as the explanation of the error-aware mixture model and the generation of natural language descriptions, could benefit from further elaboration.', 'More visual aids and diagrams could help clarify the methodology.', 'The paper is dense and could benefit from clearer organization and presentation.', 'The novelty of the error-aware mixture model compared to existing methods like Spotlight is not entirely clear; more detailed comparisons and ablation studies would help.', 'The reliance on cross-modal embeddings may limit the generalizability of the method, especially in domains where such embeddings are not readily available.', 'The method is complex and may be challenging for practitioners to implement without substantial expertise.']",4,3,3,4,Accept
5hLP5JY9S2d,"The paper investigates the relationship between closed-set and open-set performance in classifiers, proposing that improving closed-set accuracy can enhance open-set recognition (OSR) performance. It introduces the Semantic Shift Benchmark (SSB) to better evaluate OSR tasks. Extensive experiments demonstrate that a well-trained closed-set classifier can achieve state-of-the-art OSR performance.","['Can the authors provide a more detailed theoretical explanation for the observed correlation between closed-set and open-set performance?', ""How does the 'Semantic Shift Benchmark' compare to existing benchmarks in terms of difficulty and evaluation robustness?"", 'Can the authors provide more detailed ablation studies to understand the contributions of different components of the proposed method?', 'What are the potential limitations and ethical considerations of the proposed approach?', 'How do the proposed methods compare to other state-of-the-art OSR techniques in terms of computational efficiency?', 'Are there specific scenarios or types of data where the proposed method is likely to underperform compared to other state-of-the-art methods?']","['The paper should address the lack of theoretical insights and provide stronger justifications for the observed empirical results.', 'The practical applicability of the SSB benchmark in real-world scenarios needs further validation.', 'The main limitation is the practical computational feasibility of training complex models on large datasets. The paper should address this issue in more detail to provide a clearer understanding of the trade-offs involved.']",False,3,3,4,7,4,"['Addresses a critical problem in OSR with a novel perspective.', 'Comprehensive experiments demonstrate the correlation between closed-set and open-set performance.', 'Introduction of the Semantic Shift Benchmark (SSB) provides a more nuanced evaluation of OSR performance.', 'Clear empirical evidence and thorough analysis.']","['Theoretical explanations for the observed correlation are weak and not well-developed.', 'Lacks detailed ablation studies to understand the contributions of various components.', 'Limited discussion on the limitations and potential negative societal impacts of the proposed methods.', 'Certain sections could benefit from clearer explanations, particularly the methodology for creating the SSB splits.']",3,3,4,4,Reject
JHXjK94yH-y,"The paper proposes Adversarial Surprise (AS), an unsupervised reinforcement learning method designed for high-dimensional, stochastic environments. It involves an adversarial game between two policies: Explore and Control. The Explore policy seeks out surprising states, while the Control policy aims to minimize surprise, driving the agent to both explore and master the environment. The approach is theoretically validated and empirically demonstrated to outperform state-of-the-art unsupervised RL methods in terms of exploration and zero-shot transfer to downstream tasks.","['Can the authors provide more intuitive explanations or visualizations for the theoretical results?', 'Could the authors elaborate on the architecture and training details of the neural networks used for the Explore and Control policies?', 'What is the impact of different density models on the performance of AS?', 'Could more ablation studies be conducted to analyze the contribution of each component of the proposed method?', 'How sensitive is the method to the choice of the density model?', 'What are the computational costs associated with the proposed method?', 'Are there any additional quantitative metrics that can be provided to support the claims of emergent behaviors and complexity?', 'Can the authors discuss any potential limitations and negative societal impacts of their proposed method?', 'How does the proposed method compare against a broader set of baselines, especially those not mentioned in the current paper?', 'Can the authors clarify the connection between the theoretical results and the empirical findings?', 'Can the authors provide more details on the autoencoder aggregator and clarify the theoretical proofs?', 'Could the authors explain the experimental settings and hyperparameters in more detail?', 'Are there any additional tests planned on different types of environments to further validate the method?']","['The complexity and novelty of the approach may pose challenges for reproducibility and deployment.', 'The theoretical results, while valid, could benefit from more intuitive explanations.', 'The impact of different components of the method should be thoroughly validated through additional ablation studies.', 'The paper does not adequately address the limitations of the proposed method. For instance, how does the method perform in environments with different types of stochastic elements?', 'The potential negative societal impact of the work is not discussed, although it seems limited in this context.']",False,3,3,3,7,4,"['The paper addresses an important issue in unsupervised RL: the balance between exploration and control in high-dimensional, stochastic environments.', 'The proposed adversarial framework between Explore and Control policies is novel and leads to the emergence of complex, meaningful behaviors.', 'The paper provides both theoretical analysis and empirical evidence to support the efficacy of AS, demonstrating significant improvements over state-of-the-art methods.', 'Experiments are conducted on a diverse set of environments, including MiniGrid, Atari, and VizDoom, showcasing the robustness and generality of the approach.']","['The theoretical results, while compelling, could be made more intuitive and accessible to a broader audience.', 'Implementation details, particularly regarding the density model and the specific architecture of the neural networks, are sparse and could benefit from more thorough explanation.', 'Ablation studies are insufficient. More experiments are needed to validate the impact of different components and hyperparameters of the proposed method.', 'The complexity of the approach might pose challenges for reproducibility and practical implementation in real-world scenarios.']",4,3,3,4,Accept
js62_xuLDDv,"The paper 'IS FAIRNESS ONLY METRIC DEEP? EVALUATING AND ADDRESSING SUBGROUP GAPS IN DML' investigates fairness issues in Deep Metric Learning (DML), introduces the finDML benchmark to characterize fairness, and proposes the Partial Attribute De-correlation (PARADE) method to reduce subgroup performance gaps. The study includes comprehensive experiments and analysis with 11 state-of-the-art DML methods.","['Could you provide more details on the autoencoder aggregator?', 'Can you conduct additional ablation studies on the modulation function and different types of aggregators?', 'Could you include more qualitative examples to strengthen the visual analysis of the results?', 'Can the authors provide more clarity on the Fitzpatrick skintone calculation and its potential limitations?', 'How does PARADE compare with other fairness mitigation techniques in areas outside of DML?']","['The paper could benefit from additional ablation studies and improved clarity on certain methodological details. However, these limitations do not significantly undermine the overall contribution.', 'One limitation is the reliance on predefined sensitive attributes, which may not capture all sources of bias. Additionally, while PARADE shows promise, its effectiveness in other domains or with different fairness definitions remains to be explored.']",False,3,3,3,6,4,"['Addresses a significant and timely gap in DML research regarding fairness.', 'Introduces a novel benchmark (finDML) for evaluating fairness in DML.', 'Proposes a promising method (PARADE) that shows effectiveness in reducing subgroup performance gaps.', 'Includes comprehensive experiments and analysis to validate the findings.']","['Additional ablation studies on the modulation function and different aggregators could strengthen the claims.', 'Clarity and detail on certain methodological aspects, such as the autoencoder aggregator, could be improved.', 'More qualitative analysis with additional cases would provide a stronger visual understanding of the results.', 'The paper is dense with technical details, which may require careful reading to fully understand.']",4,3,3,4,Accept
rS9t6WH34p,"The paper presents ObSuRF, a method for decomposing 3D scenes into objects using Neural Radiance Fields (NeRFs). The method infers object-based representations from single images without supervision and uses RGB-D data to improve training efficiency. The approach is evaluated on both 2D and 3D datasets, showing competitive performance.","['Can the authors provide more details about the autoencoder aggregator?', 'Can the authors clarify the derivation of the Poisson process in the context of the proposed method?', ""Can the authors provide additional visual examples to illustrate the method's performance?"", 'Can you provide more detailed runtime comparisons to validate the computational efficiency claims?', 'Would the method work without RGB-D data or with estimated depth information?', 'Can you provide more thorough ablation studies to understand the contributions of each component?']","['The clarity of some sections can be improved, and more details on specific components are needed.', ""The reliance on RGB-D data for training limits the method's applicability."", 'The computational efficiency claims should be validated with more detailed runtime comparisons.', 'The paper could benefit from more thorough ablation studies.']",False,3,3,3,6,4,"['Novel approach to 3D scene decomposition using NeRFs.', 'Creative use of Poisson process for volume rendering.', 'Comprehensive experimental validation on both 2D and 3D datasets.', 'Potentially significant impact for applications in robotics, AR/VR, and autonomous driving.']","['Details about the autoencoder aggregator are not fully clear.', 'Some parts of the paper, such as the Poisson process derivation, could be clarified further.', 'Additional visual examples would strengthen the presentation.', 'Relies on RGB-D data for training, limiting applicability.', 'Needs more detailed runtime comparisons to validate computational efficiency claims.', 'Could benefit from more thorough ablation studies.']",4,3,3,3,Reject
VqzXzA9hjaX,"The paper proposes a novel concept called 'Optimizer Amalgamation,' which aims to combine multiple analytical optimizers into a single, stronger optimizer. The authors present three amalgamation mechanisms (additive, min-max, and optimal choice) and explore stability techniques to reduce variance during the amalgamation process. Extensive experiments demonstrate the effectiveness of the proposed approach across various datasets, architectures, and training settings.","['Can the authors provide more details about the autoencoder aggregator used in the experiments?', 'Could the authors conduct additional ablation studies to investigate the effect of different modulating functions and aggregators?', 'Can the authors provide more details on the choice network architecture?', 'What are the potential limitations in scalability and practical implementation of the proposed methods?', 'Can the authors provide a clearer and more detailed explanation of the three amalgamation schemes?', 'What is the theoretical justification for the proposed amalgamation techniques?', 'Can the authors demonstrate the consistency of their results across multiple runs and different settings?', 'How do the proposed perturbation techniques specifically contribute to the stability of the amalgamation process?', 'Can the authors provide a more detailed ablation study to isolate the effects of each component of the proposed method?', 'What are the computational overheads of the proposed method compared to using a single optimizer?', 'How do the authors propose to address the sensitivity of the amalgamation process to perturbations?', 'Can the authors provide more theoretical analysis of the proposed amalgamation mechanisms?', 'How do the proposed methods compare to other state-of-the-art optimizers not included in the current set of experiments?', 'Can the authors provide more details on the stability techniques and their impact on the amalgamation process?', 'What are the potential limitations and negative societal impacts of the proposed methods?']","['The clarity of the paper could be improved in some sections. Additional ablation studies are needed to fully understand the contributions of each component. A discussion on the potential limitations and societal impacts of the proposed method is also needed.', 'The paper does not thoroughly discuss potential limitations in scalability and practical implementation.', 'There might be challenges in understanding the proposed methods due to the complexity of the paper.', 'The paper should more explicitly discuss the limitations of the proposed approach, including potential issues with scalability and the dependence on the choice of initial optimizers.', 'The potential negative societal impacts of this work are not addressed, although they might be minimal.', 'The paper should include a more detailed ablation study and discuss the computational overheads and stability issues in more detail.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed methods. The authors should address these aspects to provide a more balanced view of their contributions.']",False,3,3,3,5,4,"['The concept of optimizer amalgamation is novel and addresses a significant challenge in machine learning optimization.', 'The paper provides a detailed methodology for amalgamation and stability techniques.', 'Extensive experiments validate the effectiveness of the proposed approach across different datasets, architectures, and training settings.', 'The authors provide their code and pre-trained models, which enhances reproducibility.']","['The paper could benefit from clearer explanations in some sections, particularly regarding the autoencoder aggregator and the specific contributions of each component in the ablation studies.', 'Additional ablation studies are needed to investigate the effect of different modulating functions and aggregators.', 'A more thorough discussion of the potential limitations and societal impacts of the proposed method would be beneficial.', 'The complexity of the paper might make it difficult for some readers to fully understand the proposed methods.', 'Some details, such as the choice network architecture, could be explained more clearly.', 'Potential limitations in scalability and practical implementation are not thoroughly discussed.', 'The methodology and the three proposed amalgamation schemes are not clearly explained, making it difficult to understand the exact process and novelty.', 'The paper lacks a detailed theoretical analysis of why the proposed amalgamation techniques would outperform existing methods.', 'The experiments, while extensive, do not convincingly demonstrate the superiority of the amalgamated optimizers over all baselines across all tasks.', 'The stability improvements with perturbations are not well-justified and seem more like ad-hoc additions rather than integral parts of the methodology.', 'Some important details, such as the exact architectures used for the optimizers and choice networks, are relegated to the appendix, making it harder to evaluate the approach comprehensively.', 'The proposed method is quite complex, and the paper lacks a thorough ablation study to isolate the effects of each component.', 'The stability experiments show that the process is sensitive to perturbations, and there is no clear solution provided.', 'The paper does not discuss the computational overhead of the proposed method compared to using a single optimizer, which could be a significant drawback in practical applications.', 'The theoretical foundations of the amalgamation mechanisms are not sufficiently discussed. The authors should provide more rigorous theoretical analysis.', 'The paper lacks additional baselines, such as other state-of-the-art optimizers, to better contextualize the performance of the proposed methods.']",4,3,3,3,Reject
vdbidlOkeF0,"The paper presents the Scaled Density Ratio Estimator (SDRE), a new method for estimating density ratios between two distributions. SDRE introduces a scaling measure to avoid the density-chasm problem that affects existing methods. The paper provides theoretical justifications and conducts extensive experiments on synthetic and real datasets, showing that SDRE outperforms state-of-the-art methods in various scenarios including density ratio estimation, mutual information estimation, and representation learning.","['Can you provide more details on the potential impact of predefined scaling measures on the generalizability of the method?', 'Is there a possibility to learn the scaling measure instead of predefining it?', ""Can the authors provide more details on the construction of the scaling measure 'm' and how it impacts the performance of SDRE?"", 'How does SDRE compare to state-of-the-art methods in scenarios with both first-order and higher-order discrepancies?', 'Can the authors provide more comparative analysis with other methods in the experimental section?', 'What are the limitations of the proposed method, and how do the authors plan to address them in future work?', 'Can the authors conduct ablation studies to analyze the contributions of different components of SDRE?', 'Can the authors provide more visualization and qualitative analysis of the experimental results?', 'What are the potential limitations or failure cases of the SDRE method?']","[""The predefined scaling measure might limit the method's generalizability."", 'The lack of theoretical bounds on estimation performance is a concern.', 'The paper does not discuss potential limitations or failure cases of the proposed method, which would be valuable for understanding its scope and applicability.', 'The potential negative societal impacts of the proposed method are not thoroughly discussed.']",False,3,3,3,5,4,"['Addresses the critical problem of density-chasm in density ratio estimation.', 'Novel approach of using scaling measures inspired by scaled-Bregman divergences.', 'Comprehensive experimental validation on synthetic and real datasets.', 'Theoretical grounding provided for the proposed method.']","['The paper lacks detailed theoretical bounds on the estimation performance.', 'The scaling measure is predefined and not learned, which might limit the generalizability of the method.', 'Some sections, especially on the construction of scaling measures and the theoretical background, are not very clear and could benefit from better explanations.', 'More ablation studies could strengthen the claims, especially regarding the choice of scaling measures.', 'The paper does not adequately discuss the limitations and potential negative impacts of the proposed method.']",3,3,3,3,Reject
7AzOUBeajwl,The paper proposes a novel approach to text style transfer by addressing the challenge of confounding factors using invariant risk minimization (IRM). The method involves learning invariant classifiers to distinguish style from orthogonal features and using these classifiers to guide a style transfer model. The paper demonstrates significant improvements over existing methods in two experimental settings: sentiment transfer with different punctuation and sentiment transfer across different product categories.,"['Can the authors provide more details about the autoencoder aggregator and its role in the methodology?', 'What is the impact of different hyperparameter settings and components in the proposed method? Additional ablation studies would be helpful.', 'Can the authors discuss the potential societal impacts of their technology, particularly the risks associated with misuse for generating misleading content?', 'Can the authors provide more details on the training procedure and architecture of the IRM-based classifiers?', 'How are the evaluation metrics calculated, and what are their definitions?', 'Can the authors clarify the choice of baselines and justify their comparability?', 'What is the impact of different hyperparameters on the performance of the proposed method?']","['The clarity of certain methodological components needs improvement.', 'More extensive ablation studies are required to solidify the claims.', 'Potential societal impacts should be discussed in greater detail.', 'The clarity of the methodology is lacking, which could hinder understanding and implementation of the proposed method by other researchers.', 'The paper does not thoroughly explore the impact of hyperparameters, which could affect the reproducibility and generalizability of the results.']",False,3,3,4,6,4,"['Addresses a significant and realistic problem in style transfer by considering confounding factors.', 'Innovative use of invariant risk minimization to learn invariant classifiers for style and orthogonal features.', 'Comprehensive experimental evaluation demonstrating substantial improvements over existing methods.', 'Clear presentation of the methodology and results with well-structured experiments.']","['The paper could benefit from more detailed explanations of certain methodological components, such as the autoencoder aggregator and the IRM-based classifiers.', 'Additional ablation studies are needed to investigate the impact of different components and hyperparameters in the proposed method.', 'Potential societal impacts of the technology should be more thoroughly discussed, especially regarding the risk of misuse for generating misleading or harmful content.', 'The clarity of the methodology section could be improved, particularly the description of the invariant classifiers and their integration into the style transfer model.', 'The evaluation metrics and their calculation are not always clearly defined, which raises questions about the robustness of the reported results.']",4,3,3,4,Reject
nsjkNB2oKsQ,"The paper provides a new framework for off-policy reinforcement learning with delayed rewards, addressing the challenges posed by non-Markovian environments. The authors introduce a novel Q-function formulation with theoretical convergence guarantees and an HC-decomposition rule to approximate the Q-function, improving training efficiency and stability. Extensive experiments show that the proposed methods outperform existing approaches.","['Can the authors provide more details and examples to clarify the new Q-function and HC-decomposition framework?', 'How sensitive is the proposed method to the choice of the hyperparameters?', 'Are there any potential limitations or negative societal impacts of this work that have not been discussed?', 'Can you provide more detailed ablation studies to evaluate the impact of different components in the HC-decomposition and regularization terms?', 'Could you clarify the description of the autoencoder aggregator and provide more implementation details?', 'How well do the proposed methods generalize to various real-world scenarios, and can the authors provide more practical validation?']","['The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the proposed approach.', 'The potential negative impacts, such as increased computational complexity due to the HC-decomposition, should be addressed.', 'The clarity and organization of the paper need improvement.', 'Implementation details are somewhat scattered, which might hinder reproducibility.']",False,3,3,3,6,4,"['Addresses an important and practical problem in RL with delayed rewards.', 'Introduces a novel Q-function formulation and HC-decomposition rule.', 'Provides theoretical convergence guarantees.', 'Extensive experimental validation demonstrating superior performance.']","['Some sections explaining complex concepts like the new Q-function and HC-decomposition rule are not very clear and could benefit from additional examples and explanations.', 'The paper could benefit from additional ablation studies and analysis of limitations.', 'The generalizability of the proposed methods to a wider range of tasks and environments is not thoroughly discussed.', 'The practical impact and generalizability of the proposed methods to various real-world scenarios need further validation.', 'The paper does not adequately address the limitations and potential negative societal impacts of the proposed methods.']",3,3,3,4,Reject
2hMEdc35xZ6,"The paper presents Defect Transfer GAN (DT-GAN), a method for generating synthetic defective samples to augment training data for defect detection in industrial settings. The model transfers defect characteristics from one domain to another and generates new defects from random noise. The method addresses the scarcity and imbalance of defective samples in real-world scenarios, improving the performance of defect inspection networks. Extensive experiments on real industrial datasets demonstrate the effectiveness of DT-GAN compared to state-of-the-art methods.","[""Could the authors provide more detailed explanations of the style-content separation and FG/BG disentanglement? How do these components specifically contribute to the model's performance?"", 'Have the authors considered potential negative societal impacts of generating synthetic defective samples? If so, how are these addressed?', 'Can the authors provide more detailed explanations of the architectural components and the training process of DT-GAN?', 'Could the authors conduct additional ablation studies to isolate and evaluate the contribution of each component of the proposed model?', 'Are there any plans to evaluate the practical utility of the generated images in real-world industrial scenarios beyond the reported defect classification tasks?']","['The paper could provide a more detailed discussion on the potential limitations of the proposed method, such as the generalizability to other types of defects or different industrial settings.', 'The paper primarily focuses on synthetic image generation and evaluation using standard metrics (FID and KID). It would be beneficial to include practical evaluations of the generated images in real-world industrial applications.', 'The detailed implementation and training process of DT-GAN could be more clearly described to enhance reproducibility and understanding.', 'Reliance on the availability of a sufficient number of non-defective samples, which might not always be practical.']",False,3,2,3,6,4,"['The problem of data scarcity and imbalance in defect detection is significant and well-motivated.', 'The proposed DT-GAN method is novel and leverages GANs effectively for defect transfer and generation.', 'Comprehensive experimental evaluation on real industrial datasets demonstrates the practical utility of the method.', ""The paper includes both quantitative and qualitative results, providing a thorough analysis of the model's performance.""]","['Some sections of the methodology, particularly the style-content separation and FG/BG disentanglement, could be explained more clearly.', 'The paper could benefit from additional ablation studies to isolate the contributions of different components of the model.', 'Limited discussion on the potential limitations and negative societal impacts of the proposed method.']",3,3,2,3,Reject
uHv20yi8saL,"This paper introduces a novel theoretical analysis that guarantees monotonic improvement for decentralized Proximal Policy Optimization (PPO) in cooperative Multi-Agent Reinforcement Learning (MARL), even under non-stationary transition dynamics. The authors provide a theoretical underpinning for the strong empirical performance of Independent Proximal Policy Optimization (IPPO) and Multi-Agent PPO (MAPPO). They show that the trust region constraint can be enforced by bounding independent ratios based on the number of agents, offering a principled way to perform proximal ratio clipping. Empirical results support the theoretical findings, demonstrating the importance of the trust region constraint and the equivalence of the surrogate objectives in IPPO and MAPPO under certain conditions.","['Can the authors provide more details on the experimental setup and the hyperparameter tuning process?', 'Could the authors perform additional ablation studies to explore the sensitivity of the proposed methods to different hyperparameters?', 'Can the authors provide more intuitive explanations for the key theoretical results?', 'Are there any practical scenarios where the assumptions in the theoretical analysis might not hold?']","['The paper does not adequately address the limitations of the proposed approach. For example, it is not clear how the method would perform in environments other than SMAC or with different types of non-stationarity.', 'Potential negative societal impacts of the work are not discussed.', 'The theoretical analysis relies on certain assumptions that may not always hold in practical scenarios. Additionally, the empirical results could be further strengthened with more ablation studies.']",False,3,2,3,5,4,"['The paper addresses a significant problem in MARL, specifically the challenge of non-stationarity in decentralized policy optimization.', 'The theoretical contributions are robust, providing a new monotonic improvement guarantee and a foundation for proximal ratio clipping in decentralized MARL.', 'The empirical results support the theoretical claims, showing the importance of enforcing a trust region constraint.']","['The clarity of the theoretical exposition could be improved; the proofs and notations are dense and difficult to follow.', 'The empirical validation could be more comprehensive, with additional experiments and ablation studies to explore the sensitivity of the proposed methods.', 'Some assumptions and constraints in the theoretical analysis may be restrictive or not well-justified.']",3,3,2,3,Reject
5FUq05QRc5b,The paper provides a theoretical framework for understanding and improving latent correlation-based deep multiview learning methods such as DCCA and AM-SSL. It presents theoretical guarantees for the extraction of shared components across views and the disentanglement of private components. The paper also includes a finite sample analysis and proposes practical implementation methods.,"['Can the authors provide more intuitive explanations and visualizations for the theoretical concepts, especially for the minimax neural regularizer?', 'Are there plans to release the implementation code and ensure its usability for the broader research community?', 'Can the authors include more extensive empirical validation on diverse and complex real-world datasets, and compare with additional state-of-the-art methods?', 'Can the authors provide more details on the practical implementation of the minimax neural regularizer, including any specific challenges faced and how they were addressed?', 'Could the authors perform additional ablation studies to evaluate the impact of different components of their framework on the performance?', 'How does the proposed method generalize to other types of multiview data beyond the datasets used in the experiments?', 'Can you provide more ablation studies on modulation functions and types of aggregators?', 'Can you elaborate on the autoencoder aggregator for better reproducibility?', 'Can you provide additional qualitative analysis with more visualization examples?']","['The paper focuses heavily on theoretical analysis and might not fully demonstrate practical significance and impact on real-world applications.', 'The clarity of some theoretical concepts could be improved with more intuitive explanations and visualizations.', 'The strong assumptions made in the theoretical analysis may not be fully justified with empirical evidence.', 'The practical implementation details are complex and may not be easily reproducible.', 'The experiments lack sufficient ablation studies and comparisons with additional baselines.']",False,3,3,3,6,4,"['Addresses a significant problem in multiview learning.', 'Provides a novel theoretical framework with strong theoretical guarantees.', 'Includes a finite sample analysis, which is rare in nonlinear mixture identifiability studies.', 'Proposes a practical implementation with a novel minimax neural regularizer.']","['Limited practical significance and impact on real-world applications are demonstrated.', 'The paper is dense with theoretical derivations and could be challenging for readers without a strong background in advanced machine learning theory.', 'Limited empirical validation on diverse and complex real-world datasets.', 'Comparison with existing state-of-the-art methods is limited.', 'Lacks sufficient ablation studies on modulation functions and types of aggregators.', 'Autoencoder aggregator section lacks detail, potentially hindering reproducibility.', 'Additional qualitative analysis with more visualization examples is needed.']",3,3,3,4,Reject
Py8WbvKH_wv,"The paper proposes DRIBO, a novel technique that aims to enhance the robustness and generalization of deep reinforcement learning (DRL) agents by using a multi-view information bottleneck (MIB) approach. The method incorporates temporal structure into the learning process and uses contrastive learning to discard task-irrelevant information. The approach is evaluated on the DeepMind Control Suite and the Procgen benchmark, showing state-of-the-art performance.","['Can the authors provide a clearer explanation of the DRIBO loss function and how it is computed step-by-step?', 'How does the approach fundamentally differ from PI-SAC and DBC in terms of theoretical contributions?', 'Can the authors discuss any potential limitations or negative societal impacts of their work?', 'What is the impact of different types of data augmentation on the performance of DRIBO?', 'Can the authors elaborate on the encoder architecture and its specific contributions to the overall performance?', 'Can the authors provide more intuitive explanations and visualizations to clarify the technical sections?', 'How does DRIBO perform when applied to non-visual RL tasks or tasks with different types of observations (e.g., proprioceptive data)?', 'Can you provide more insights into the choice of hyperparameters for the β scheduler and its impact on the performance?', 'How does the performance of DRIBO compare when using different types of data augmentations?', 'What specific scenarios or types of visual distractions might DRIBO struggle with, and how can the method be potentially improved to handle those cases?']","['The paper does not discuss potential limitations or negative societal impacts in detail. Further discussion on these aspects could strengthen the paper.', 'The clarity of the explanation, particularly the technical details, could be improved to help readers better understand the methodology.', 'The paper should discuss potential limitations of the approach, such as the computational overhead introduced by the MIB objective and the scalability to more complex environments.', 'The potential ethical implications of the work are not discussed. Given the application to RL, it is important to consider any unintended consequences or misuse of robust RL methods.']",False,3,3,3,7,4,"['The paper tackles an important problem in DRL—robustness and generalization to unseen environments.', 'The use of multi-view information bottleneck is innovative and leverages temporal structures in RL, which is a novel approach.', 'Extensive experiments and comparisons with state-of-the-art methods demonstrate the efficacy of the proposed approach.', 'The empirical results show significant improvements in performance on both the DeepMind Control Suite and Procgen benchmarks.']","['The explanation of the methodology, particularly the DRIBO loss function and encoder architecture, is complex and could be clearer.', 'The novelty of the approach over existing methods like PI-SAC and DBC might not be as significant as presented.', 'The paper does not discuss limitations and potential negative societal impacts in detail.', 'While ablation studies are provided, additional analyses could further validate the robustness of the method.']",3,3,3,4,Reject
R11xJsRjA-W,"The paper investigates the relationship between out-of-distribution (OOD) generalization and the privacy of machine learning models, particularly focusing on membership inference (MI) attacks. It explores whether better OOD generalization results in better privacy and if models that learn stable features are more robust to MI attacks. The study includes extensive evaluation on synthetic and real datasets, providing insights that challenge some theoretical assumptions.","['Can the authors provide more clarity on how the metrics for stable features are computed?', 'What is the impact of different modulation functions and aggregators on the results? Can the authors include more ablation studies?', 'Can the authors provide more visualizations for the qualitative analysis to make the findings more convincing?', 'Please provide more detailed explanations of the experimental procedures and metrics.', 'Can you clarify the practical implications of your findings? How can they be applied in real-world scenarios?', 'Can the authors provide more rigorous theoretical explanations?', 'What are the potential negative societal impacts of the proposed methods?', 'Can the authors improve the organization and clarity of some sections?', 'Could you provide more detailed explanations or theoretical foundations for why stable features improve privacy?', 'How do you ensure that the chosen metrics for stable features are robust and generalizable across different datasets?', 'Could you discuss the potential limitations or drawbacks of using MI attack accuracy as a metric for evaluating stable features?', 'Can the authors provide a more detailed and consistent explanation of the metrics used to measure stable features?', 'How do the authors plan to address the inconsistency in empirical results across different datasets?', 'Can the authors clarify how their approach differs significantly from previous work by Tople et al. (2020)?']","['The paper needs to address the clarity of the evaluation metrics and provide additional ablation studies. It would also benefit from more comprehensive qualitative analysis.', 'The study relies heavily on empirical results without a strong theoretical backing.', 'The metrics used for measuring stable features may not be applicable to all types of datasets, limiting the generalizability of the findings.', 'The practical utility of using MI attack accuracy as a metric needs further validation and discussion.']",False,2,2,3,4,4,"['The paper addresses an important and timely topic, bridging the gap between OOD generalization and privacy in ML models.', 'The empirical study is extensive, covering multiple datasets and different domain generalization (DG) algorithms.', 'The results provide new insights, showing that better OOD generalization does not always imply better privacy and highlighting the importance of stable features for membership privacy.']","['The clarity in presenting how metrics for stable features are computed is lacking, making it harder to fully understand some results.', 'The paper could benefit from additional ablation studies to further support the claims and findings, particularly regarding the modulation function and different types of aggregators.', 'Some parts of the paper, especially regarding the evaluation metrics for stable features, need more detailed explanations.', 'The qualitative analysis for certain results could be more comprehensive, providing multiple visualizations to make the findings more convincing.', 'The theoretical explanations could be more rigorous.', 'The paper lacks depth in discussing the limitations and potential negative societal impacts.', 'The novelty might be limited by the fact that it builds heavily on previous work in domain generalization and privacy.', 'The practical implications of the findings are somewhat limited, and the study might benefit from a more detailed discussion of potential applications.']",3,2,2,3,Reject
5xEgrl_5FAJ,"The paper 'BiBERT: Accurate Fully Binarized BERT' presents a novel approach to fully binarize the BERT model. The authors introduce Bi-Attention and Direction-Matching Distillation (DMD) to address information degradation and optimization direction mismatch, respectively. The paper demonstrates significant improvements over existing quantization methods on the GLUE benchmark in terms of both accuracy and efficiency.","['Can you provide more detailed explanations or clearer derivations for some of the theoretical justifications, particularly in the proofs?', 'How does BiBERT compare with other forms of compression that are not specifically designed for binarization?', 'Can you discuss the limitations and potential negative societal impacts of BiBERT in more detail?', 'Can you expand the visualizations of attention patterns to include more cases for a more comprehensive evaluation?', 'Can the authors provide more ablation studies to isolate the contributions of Bi-Attention and DMD separately?', 'Could the authors discuss the computational overhead introduced by Bi-Attention and DMD in more detail?', 'Are there specific scenarios or applications where BiBERT would be particularly beneficial?', 'Could you elaborate on the practical implications and potential limitations of BiBERT in real-world applications?', 'Can you provide more detailed implementation details and the exact computational savings?', 'Have the authors considered the potential negative societal impacts of deploying binarized models, particularly in terms of fairness and bias?']","['The paper needs to improve the clarity of some theoretical justifications and provide a broader comparison with other compression methods.', 'A more detailed discussion on the limitations and potential negative societal impacts of the proposed method is needed.', 'The visualizations of attention patterns should be expanded to include more cases.', 'The computational overhead introduced by the proposed techniques needs to be discussed in more detail.', 'The clarity of the theoretical sections could be improved.', 'Implementation details and explanation of computational savings could be more thorough.']",False,3,3,4,7,4,"['Addresses a significant problem in NLP model deployment by proposing a fully binarized BERT, offering substantial efficiency gains.', 'Introduction of Bi-Attention and DMD as novel contributions that effectively tackle the issues of information degradation and optimization direction mismatch.', 'Extensive experiments on the GLUE benchmark demonstrate the efficacy of the proposed methods, with BiBERT outperforming existing quantized BERT models.']","['The clarity of the presentation could be improved, particularly in the descriptions of the Bi-Attention and DMD mechanisms.', 'Some additional ablation studies and comparisons with alternative binarization techniques could strengthen the empirical validation.', 'The potential negative societal impacts of deploying binarized models, particularly in terms of fairness and bias, are not adequately addressed.', 'Implementation details and computational savings need more thorough discussion.']",4,3,2,4,Accept
iGffRQ9jQpQ,The paper proposes Self-interested Coalitional Learning (SCL) to enhance semi-supervised learning (SSL). SCL constructs a semi-cooperative 'game' between the main SSL task and an auxiliary task for predicting label observability. This approach aims to mitigate over-reliance on labeled data and error accumulation from pseudo-labels. The paper provides a theoretical foundation and demonstrates SCL's effectiveness through comprehensive experiments on classification and regression tasks.,"['Can the authors provide more details on the implementation of the autoencoder aggregator and the discriminator?', 'Could additional ablation studies be conducted to explore the contributions of different components in the SCL framework?', ""Can more qualitative analyses be provided, particularly in Figure 5, to strengthen the paper's claims?"", 'What is the impact of different values of the weight parameter α on the performance of SCL?', 'How does the proposed method scale with larger datasets and more complex models?', 'How does the initial pseudo-labeling process work in practice, especially for regression tasks?', 'Can you elaborate on the potential limitations or downsides of the SCL framework in real-world applications?']","['The paper could be clearer in its explanation of certain components, such as the autoencoder aggregator and the discriminator.', ""Additional ablation studies and qualitative analyses would strengthen the paper's claims and provide a more comprehensive understanding of the proposed method's effectiveness."", 'The paper should discuss potential limitations, such as computational overhead introduced by the additional discriminator and the scalability of SCL to large datasets.', 'The role of the weight parameter α in the SCL framework and its impact on performance could be further analyzed.']",False,3,3,3,6,4,"['The paper addresses the pressing issue of over-reliance on labeled data in semi-supervised learning and aims to mitigate error accumulation from pseudo-labeling.', 'The proposed Self-interested Coalitional Learning (SCL) framework introduces a novel approach by incorporating an auxiliary task for predicting label observability.', 'The theoretical foundation is well-detailed, explaining the connection to loss reweighting on noisy labels.', 'Comprehensive experiments demonstrate the effectiveness of SCL across various tasks, including image classification, label propagation, and data imputation.']","['The paper lacks detailed ablation studies that could provide deeper insights into the contributions of different components.', 'The implementation of the autoencoder aggregator and the discriminator is not sufficiently clear and would benefit from additional details.', 'Although the paper includes qualitative analysis, it would be stronger if more cases were provided, especially in Figure 5.', 'The proposed method could benefit from a more thorough exploration of different modulation functions and aggregators.', 'The clarity of the paper can be improved, particularly in the explanations of the theoretical derivations and the implementation details of the experiments.', 'The practical implications and potential limitations of the approach are not adequately discussed.']",3,3,3,4,Reject
bVT5w39X0a,The paper proposes a novel multi-modal Relational Neural Process (mRNP) that constructs a dependency graph among samples from different modalities to create a distribution over functions. This model aims to overcome limitations of existing generative models by addressing issues like miscalibrated precisions and computational complexities. The introduction of a mixture-of-graphs (MoG) approach allows for better handling of missing modalities and scalable mini-batch optimization. The paper includes both theoretical validations and experimental results that demonstrate the effectiveness of the proposed method.,"['Can the authors provide more intuitive visualizations and explanations for the methodology to make it more accessible?', 'Could the authors elaborate further on the details of the autoencoder aggregator?', ""An ablation study on the modulation function's impact would be useful. Can this be added?"", 'How does the proposed MoG approach compare with other mixture-of-experts or product-of-experts frameworks in terms of theoretical and practical performance?', 'Can the authors provide more insights into the scalability of the proposed method, especially for very large datasets?', 'What are the potential negative societal impacts of the proposed model, and how can they be mitigated?']","[""The main limitation is the paper's clarity, which can be improved by providing more intuitive explanations and visualizations."", ""An ablation study on the modulation function's impact would help validate the robustness of the proposed model."", 'The experimental validation could be more comprehensive, including more datasets and comparisons with a broader range of baselines.']",False,3,3,3,6,4,"['The mRNP model is innovative in using stochastic processes for multi-modal learning, which provides better uncertainty estimates.', 'The mixture-of-graphs (MoG) approach is a novel contribution that addresses issues related to precision miscalibration and computational complexity.', 'Comprehensive experiments on real-world datasets show the effectiveness of the proposed model compared to state-of-the-art methods.', 'The theoretical validations, including proofs of exchangeability and consistency, add robustness to the proposed method.']","['The paper is densely written and could benefit from clearer explanations, especially in the methodology section.', 'Some sections, like the detailed explanation of the autoencoder aggregator, are not very clear and could be elaborated further.', 'While the experimental results are promising, more intuitive visualizations and explanations would help make the contributions more accessible to a broader audience.', 'An ablation study on the impact of the modulation function in the model would be beneficial.']",4,3,3,4,Reject
I2Hw58KHp8O,"The paper introduces the Conditional Masked Language Model with Correction (CMLMC), a novel approach to improve non-autoregressive (NAR) translation models without relying on distillation. The paper addresses two main issues in current NAR models: token indistinguishability and training-inference mismatch. The proposed model incorporates architectural modifications to improve token distinguishability and a correction loss to better align training and inference procedures. The authors provide extensive experimental results demonstrating that CMLMC achieves state-of-the-art performance on several benchmarks, both with and without distillation.","['Can the authors provide more clarity on the implementation of the correction loss?', 'How does the proposed model handle cases where the initial fully masked sentence leads to particularly poor translations?', 'Can the authors provide more qualitative examples to illustrate the impact of the proposed modifications?', 'Can the authors provide more details on the choice of hyperparameters and their impact on the performance of the correction mechanism?', 'How does the proposed method handle edge cases where token repetition is extremely frequent?', 'Can the authors elaborate on the computational overhead introduced by the additional masked attention layers?', 'Could you provide more detailed explanations of the architectural modifications, particularly the use of the FFN to combine token embeddings and positional encodings?', 'How does the increased model complexity and parameter count impact the scalability of CMLMC?', 'Have you considered isolating the impact of additional parameters from the architectural changes in your ablation study?', 'Can you provide more details on the autoencoder aggregator and its role in the model?', 'How does the proposed model compare to SMART in more detail, particularly in terms of the training process and architectural differences?', 'Have you tested the model on any additional datasets or more complex scenarios? If so, what were the results?', 'Can you provide a more thorough analysis of the impact of the additional parameters introduced by the modifications?']","['The paper should include a discussion on the potential limitations of the proposed approach, such as cases where it might not perform well or scenarios where the correction mechanism might fail.', 'The increased model complexity and parameter count may affect scalability. Additionally, the impact of the additional parameters on performance is not entirely isolated from the architectural changes.', 'The societal impact of deploying improved NAR translation models, particularly in sensitive contexts, is not addressed.']",False,3,3,3,7,4,"['Addresses a significant problem in NAR translation models by reducing reliance on distillation.', 'Proposes a novel correction loss and architectural modifications to improve translation quality.', 'Provides extensive experimental results on multiple benchmarks, showing significant improvements in BLEU scores.', 'Detailed ablation studies and analyses are provided to support the effectiveness of the proposed approach.', 'Achieves state-of-the-art performance on undistilled NAR models, approaching AR performance.']","['Some sections of the paper, particularly the explanation of the correction loss and the architectural modifications, could be clearer.', 'The novelty of the approach might be questioned as it builds on existing methods like CMLM and SMART. The paper should better differentiate its contributions from these prior works.', 'The paper could benefit from more qualitative analysis to provide deeper insights into how the proposed modifications impact translation quality.', 'The impact of the additional parameters on performance is not entirely isolated from the architectural changes.', 'The clarity of some sections, particularly the methodology, could be improved with more detailed explanations and visual aids.']",3,4,3,4,Accept
bilHNPhT6-,"The paper introduces the Distillation of a Mixture of Experts (DiME) algorithm for multi-objective reinforcement learning (MORL), applying it to offline RL and finetuning. The authors argue that many RL improvements can be viewed as multi-objective problems and propose replacing linear scalarization, commonly used for combining objectives, with DiME. They demonstrate that DiME outperforms state-of-the-art approaches in offline RL and finetuning.","['Can the authors provide more detailed guidance on how to select or learn the trade-off parameter α in practice?', 'Could the authors include additional ablation studies to analyze the impact of different components of DiME?', 'Can the authors provide more details on the complexities and practical challenges of implementing DiME?', 'What are the potential limitations and pitfalls of the proposed method, and how can they be mitigated?', 'How well does DiME generalize to other RL problems beyond offline RL and finetuning?', 'Can the authors include more comparisons with other advanced multi-objective RL methods?', 'Could the authors elaborate on potential limitations and negative societal impacts of their approach?', 'How does the computational complexity of DiME compare to traditional RL methods in terms of runtime and resource requirements?']","['The complexity of the proposed method and its practical applicability need more thorough evaluation.', 'Potential limitations and pitfalls should be more clearly addressed to provide a balanced perspective.', 'The paper lacks a detailed discussion on the potential negative societal impacts and ethical considerations of the proposed method.']",False,3,3,3,7,4,"['Addresses a pertinent and practical issue in RL by leveraging MORL.', 'Introduction of DiME, a novel MORL algorithm, which is shown to outperform existing methods.', 'Comprehensive experiments on multiple RL tasks, demonstrating the efficacy of the proposed method.', 'Clear theoretical foundation and derivation of the proposed method.']","['The complexity and practical applicability of DiME need more thorough evaluation.', 'The paper could benefit from more clarity in some sections, particularly in the derivations and the explanation of the experimental setup.', 'More detailed ablation studies and comparisons with other MORL algorithms would strengthen the claims.', 'Limited discussion on potential limitations and negative societal impacts.']",4,3,3,4,Accept
LQCUmLgFlR,"The paper investigates the optimal early stopping time in neural network training, contrasting overparametrized and underparametrized settings. The theoretical findings are supported by empirical experiments on standard datasets, demonstrating the practical relevance of early stopping in avoiding overfitting.","['Can you provide more details on how the semi-orthogonal matrix P is generated and its role in the theoretical analysis?', 'How sensitive are the results to the choice of noise variance and other parameters in the model?', 'Can you elaborate more on the applicability of your theoretical findings to non-linear settings and other types of regularization methods?', 'Why was 20% label noise chosen for the experiments? Can other levels of noise be tested?', 'How does the proposed method compare to other regularization techniques in practice?', 'Can the authors provide more detailed and comprehensive empirical results to support the theoretical claims?', 'How do the theoretical findings specifically advance the state of the art compared to existing literature on early stopping and parametrization?', 'Can the authors include more intuitive explanations and possibly visual aids to clarify the dense theoretical sections?', 'What are the practical implications of the theoretical findings for real-world applications, especially in terms of computational efficiency and resource usage?']","['The paper assumes specific data distributions and linear transformations that may not hold in all practical scenarios. Addressing these limitations and providing more general results would be beneficial.', 'Potential negative societal impacts are not discussed. For instance, reliance on large models can have significant energy and resource consumption implications.', 'The experiments need to be more comprehensive to establish a stronger connection between theory and practice. Additionally, the practical implications of the theoretical findings should be more thoroughly discussed.']",False,2,2,3,4,4,"['Addresses a significant and practical issue in machine learning regarding early stopping.', 'Provides theoretical insights and empirical evidence.', 'Connects theoretical findings to practical deep learning scenarios.', 'Well-organized and clearly written.']","['The model assumptions are somewhat idealized and may not fully capture real-world complexities.', 'Experiments focus on standard datasets and could benefit from additional experiments on larger and more diverse datasets.', 'The clarity of the theoretical derivations is lacking.', 'Experimental setups, like the use of 20% label noise, are not well-justified.', 'Missing comprehensive comparisons with other regularization techniques.', 'Some sections are difficult to follow due to dense mathematical notations.', 'The novelty of the contributions needs to be more clearly articulated, distinguishing it from prior work.']",3,2,3,3,Reject
rbFPSQHlllm,"The paper proposes AutoMO-Mixer, an automated multi-objective MLP-Mixer model for medical image-based diagnosis. The model aims to balance sensitivity and specificity using a Pareto-optimal model set and Bayesian optimization for hyperparameter tuning. The final output is obtained by fusing the output probabilities of the Pareto-optimal models using the evidence reasoning (ER) approach. Experiments on brain tumor MRI and COVID-19 CT datasets demonstrate improved performance over traditional CNN and MLP-Mixer models.","['Can the authors provide more details on the autoencoder aggregator used in the methodology?', 'How does the performance change if different types of aggregators or modulation functions are used?', 'Can additional ablation studies be provided to show the impact of each component in the proposed model?', 'How does the evidence reasoning approach work in detail?', 'What are the implications of using more diverse datasets and additional comparisons with state-of-the-art methods?']","['The paper does not sufficiently explain some components of the methodology, such as the autoencoder aggregator.', 'More ablation studies are needed to validate the effectiveness of each component.', 'The paper does not adequately discuss the limitations and potential negative societal impacts of the proposed model, particularly in a clinical setting.']",False,2,2,2,3,4,"['Addresses a critical issue in medical image diagnosis: balancing sensitivity and specificity.', 'The use of MLP-Mixer is novel in this context, potentially reducing the number of parameters compared to CNNs.', 'Multi-objective optimization and Bayesian optimization are well-motivated and could lead to more balanced and reliable models.', 'Experimental results show that AutoMO-Mixer outperforms CNN and MLP-Mixer on two medical imaging datasets.']","['The clarity of the methodology, specifically the autoencoder aggregator and the detailed optimization process, is lacking.', 'There are typographical and grammatical errors throughout the paper that affect readability.', 'The paper could benefit from more extensive ablation studies to thoroughly evaluate the impact of each component.', 'The presentation of results and figures could be improved for better understanding.', 'The novelty of the methodology is somewhat incremental, building on existing techniques without introducing a fundamentally new concept.', 'The number of experiments and datasets used for validation is limited.']",2,2,2,2,Reject
ms7xJWbf8Ku,"The paper proposes two packing algorithms, SPFHP and NNLSHP, to improve the efficiency of BERT pre-training by eliminating padding tokens. The authors claim a 2x speed-up without loss of accuracy. The paper includes detailed explanations of the algorithms and provides empirical results demonstrating the effectiveness of the approach.","['Can the authors provide a detailed comparative analysis with existing methods?', 'How does the proposed approach impact model performance across various tasks and datasets?', 'Can the authors provide more details or pseudocode to clarify the proposed algorithms?', 'How does the approach scale and generalize across different models and datasets?', 'Could you provide more details on the specific adjustments made to the BERT model for handling packed sequences?', 'Could you include a detailed ablation study on the impact of different hyperparameter adjustments?', 'What is the impact of the computational overhead introduced by the modifications?', 'How does the approach affect fine-tuning tasks in detail?', 'How do the proposed algorithms perform on datasets other than Wikipedia, such as domain-specific or low-resource datasets?', 'What are the potential limitations and negative societal impacts of the proposed methods?', 'How do the algorithms handle edge cases, such as very short sequences?']","['The paper does not sufficiently address the scalability and generalizability of the proposed approach.', 'A detailed comparative analysis with existing methods is missing.', 'The impact on model performance across various tasks and datasets is not thoroughly explored.', 'The paper should provide more implementation details and a comprehensive comparative analysis to strengthen its claims.', 'The computational overhead introduced by the proposed modifications is not deeply analyzed.', 'A thorough exploration of the impact on fine-tuning tasks is needed.', 'Scalability and robustness across different datasets should be demonstrated.', 'The clarity of some sections needs improvement, and additional ablation studies are recommended to understand the impact of different components.']",False,3,2,3,5,4,"['Addresses a significant issue in NLP model training by reducing computational overhead due to padding tokens.', 'Proposes two novel packing algorithms that are claimed to be efficient and easy to implement.', 'Provides empirical results demonstrating the effectiveness of the approach.', 'Includes code snippets and claims to share the full implementation, supporting reproducibility.']","['The idea of reducing padding to improve computational efficiency is not new; the novelty lies in the specific algorithms proposed.', 'Lacks a thorough comparative analysis with existing methods.', 'Insufficient details on the impact of the proposed changes on model performance across various tasks and datasets.', 'Presentation of the algorithms could be clearer; detailed pseudocode or a flowchart would enhance understanding.', 'Needs to address the scalability and generalizability of the approach across different models and datasets.', 'Lacks detailed ablation studies to understand the impact of different components of the proposed methods.', 'The clarity of the methodology section is lacking, making it difficult to fully understand the implementation and potential limitations.', 'Experimental results are not comprehensive enough to demonstrate robustness across different datasets and conditions.', 'Potential overfitting to specific datasets like Wikipedia, without sufficient exploration of other datasets.']",3,3,2,3,Reject
nwKXyFvaUm,"The paper proposes a novel approach to client selection in federated learning by focusing on diversity using submodular maximization. The approach, termed DivFL, aims to select a subset of clients that maximize a submodular facility location function defined over gradient space. This selection strategy is integrated into the federated averaging framework, showing improvements in convergence speed, fairness, and learning efficiency. The paper provides theoretical convergence analysis and extensive empirical results on both synthetic and real datasets.","['Can the authors discuss the practicality of Assumption 1 in real-world federated learning systems?', 'How does the performance of DivFL vary with different types of neural network architectures and federated learning tasks?', 'Can the authors provide more details on the implementation of the autoencoder aggregator and its impact on performance?', 'Could the authors provide more details on the synthetic data generation process and the model architectures used in the experiments?', 'Have the authors considered the impact of different submodular functions on the performance of DivFL? If so, could they provide more insights or results?', ""How does the 'no overhead' variant handle the potential staleness of the dissimilarity matrix? Are there any empirical results showing the impact of this staleness on the overall performance?"", 'Can the authors provide more details on the implementation of the submodular maximization algorithm used in DivFL?', 'How does the method handle stale gradients, and what impact does this have on performance?', 'Can you provide more ablation studies on the impact of different hyperparameters (e.g., number of clients selected, number of local epochs) on the performance of DivFL?']","['The paper should address the practical implications of the assumptions made in the theoretical analysis.', 'More empirical validation on diverse real-world datasets and tasks is needed to generalize the findings.', 'The paper does not adequately discuss the potential communication overhead associated with the proposed client selection method.', 'The practicality of implementing the proposed method in real-world federated learning systems is not thoroughly explored.', ""More details on the impact of different submodular functions and stale gradient updates in the 'no overhead' variant are needed."", 'The method relies on periodic gradient updates from all clients, which may not always be feasible in practical federated learning settings. The authors should discuss potential strategies to mitigate this requirement.', 'The scalability of the method to very large federated learning systems with thousands or millions of clients is not thoroughly evaluated.']",False,3,3,3,6,4,"['The proposed method addresses an important issue in federated learning: efficient and fair client selection.', 'The use of submodular maximization for client selection is novel and well-motivated.', 'Theoretical analysis of convergence is provided, which adds rigor to the proposed approach.', 'Extensive empirical validation on synthetic and real datasets demonstrates the effectiveness of the proposed method.']","['The theoretical analysis relies on several assumptions that might not hold in all practical scenarios. A discussion on the validity and practicality of these assumptions would be beneficial.', 'While the empirical results are extensive, additional experiments on a wider range of real-world datasets and federated learning tasks could strengthen the findings.', 'Some sections, especially the mathematical formulations and proofs, lack clarity and could benefit from more detailed explanations.', 'The description of the experimental setup, especially the synthetic data generation and the exact model architectures used, is somewhat lacking in detail. This makes it difficult to assess the reproducibility of the experiments.', ""The paper could benefit from more ablation studies to understand the impact of different components of the proposed method, such as the choice of submodular functions and the impact of stale gradient updates in the 'no overhead' variant."", 'The practicality of the approach in real-world federated learning systems is questionable, particularly regarding the communication overhead and the feasibility of computing and maintaining the dissimilarity matrix.']",4,3,3,3,Reject
anbBFlX1tJ1,"The paper introduces Boosted Curriculum Reinforcement Learning (BCRL), a novel method that leverages boosting techniques to improve curriculum reinforcement learning. BCRL approximates the action-value function as a sum of residuals learned from a sequence of tasks of increasing complexity. The method is theoretically analyzed and empirically validated in various environments using different RL algorithms.","['Can the authors provide more empirical evidence demonstrating the advantages of BCRL in more complex environments?', 'How does BCRL scale to larger and more complex tasks?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide more detailed explanations of the theoretical concepts, particularly the assumptions and conditions under which the results hold?', 'How does the proposed method perform in more diverse and complex environments beyond the ones tested?', ""What are the practical implications of the method's complexity, and how can it be mitigated?"", 'Can the authors provide more details on how the additional complexity of managing multiple function approximators is handled in practice?', 'How would the method perform if the assumption of Lipschitz continuity does not hold?', 'Are there any plans to compare BCRL with other baselines that also adapt the function approximator during learning?']","['The paper lacks discussion on the scalability of the proposed approach to more complex tasks and environments.', 'Potential negative societal impacts are not discussed.', 'The complexity of the theoretical analysis and the method itself might hinder its practical applicability.', 'More detailed ablation studies are needed to isolate the benefits of individual components.']",False,3,3,3,6,4,"['The introduction of boosting to curriculum reinforcement learning is a novel and original idea.', 'Theoretical analysis provides a solid foundation, including convergence guarantees and finite-sample approximation error analysis.', 'Comprehensive empirical validation demonstrates the advantages of BCRL over regular curriculum RL and other knowledge transfer baselines.']","['The paper is dense and could benefit from clearer explanations and better organization.', 'Empirical validation is limited and does not convincingly demonstrate significant improvements over baselines in more complex environments.', 'The method introduces additional complexity, particularly in managing multiple function approximators.', 'Potential limitations and negative societal impacts of the proposed method are not adequately addressed.']",4,3,2,3,Accept
JVWB8QRUOi-,"The paper proposes a novel framework to promote cooperation in multi-agent reinforcement learning (MARL) by leveraging homophilic incentives. The key idea is to encourage agents with similar environmental behaviors to exhibit similar incentivizing behaviors, thereby addressing the issue of second-order social dilemmas (2nd-SDs). The approach is validated through experiments on public goods and tragedy of the commons scenarios.","['Can the authors provide more detailed explanations and justifications for the chosen parameters and the design of the homophily loss?', 'What are the potential limitations or negative impacts of the proposed method in real-world applications?', 'Can the authors conduct additional ablation studies to isolate the effects of different components of their method?', 'Can the authors provide a more rigorous theoretical foundation for the proposed method?', 'How does the method perform in a broader range of SSDs? Can the authors include more varied environments in their experiments?', 'Can the authors improve the clarity of their presentation, particularly in the methodology and experiments sections?', 'Can the authors provide more formal theoretical analysis or proofs regarding the convergence and stability of the learning process with homophilic incentives?']","['The paper does not adequately discuss the potential limitations and negative societal impacts of the proposed method. It would be beneficial for the authors to address these aspects in more detail.', ""The method's reliance on observing other agents' actions for computing homophily loss may not be practical in all settings."", 'The delay in the effects of incentivizing actions could lead to slow learning, which is not fully addressed.']",False,2,2,2,4,4,"['Addresses a significant and challenging problem in MARL.', 'Introduces a novel concept of homophilic incentives inspired by human social behavior.', 'Provides comprehensive empirical evaluations on standard SSD environments.']","['Lacks rigorous theoretical analysis to support the proposed method.', 'The paper is complex and not well-organized, making it difficult to understand the methodology.', 'Empirical evaluation is limited in scope and lacks detailed ablation studies and sensitivity analyses.', ""The practicality of the method in real-world settings is questionable due to reliance on observing other agents' actions and delayed effects of incentivizing actions."", 'Presentation, including mathematical notations and explanations, needs improvement.']",3,2,2,3,Reject
dEelotBE6e2,The paper proposes a defense mechanism against backdoor attacks in deep learning models using an ensemble of weak learners. It introduces the concept of self-expanding sets and a boosting framework to identify and exclude poisoned data. The paper presents both theoretical analysis and experimental results demonstrating the effectiveness of the proposed method.,"['Can the authors provide more details on the experimental setup, particularly the parameters used?', 'What is the performance of the proposed method on other datasets, such as ImageNet or MNIST?', 'Can the authors conduct additional ablation studies to evaluate the impact of different hyperparameter settings and compare with more baselines?', 'How sensitive is the method to the choice of hyperparameters?', 'What is the computational overhead of the proposed method compared to baseline defenses?', 'How does the proposed method perform under different types of backdoor attacks or varying levels of poisoning?']","['The clarity of the paper could be improved, especially in the methodology and experimental setup sections.', 'The evaluation is limited to a single dataset (CIFAR-10), which raises concerns about the generalizability of the results.', 'The impact of hyperparameters on the performance of the proposed method is not well understood.', 'The bootstrapped measure of generalization needs further theoretical and empirical validation.', 'The robustness of the method under various conditions is not thoroughly explored, which is crucial for its practical deployment.']",False,3,3,3,6,4,"['Addresses a critical issue in machine learning security.', 'Introduces novel concepts like self-expanding sets and ISPL algorithm.', 'Strong theoretical foundation with proofs and properties that support the method.', 'Comprehensive experimental evaluation on CIFAR-10, showing significant improvement over existing defenses.']","['Lack of clarity in the description of the methodology and experimental setup.', 'Limited evaluation on datasets other than CIFAR-10, raising concerns about generalizability.', 'Insufficient exploration of hyperparameters and their impact on performance.', 'Theoretical assumptions and their practical implications need better justification.', 'Computational overhead and robustness under different attack scenarios are not thoroughly discussed.']",3,3,3,4,Reject
FndDxSz3LxQ,"The paper proposes Learn Locally, Correct Globally (LLCG), a distributed training algorithm for Graph Neural Networks (GNNs) that aims to reduce communication and memory overhead while maintaining high performance. The method involves local training with periodic model averaging and global server corrections to address the dependency between nodes in different subgraphs. The paper provides theoretical convergence analysis and extensive experimental validation.","['Can the authors provide more details on the experimental setup, including hardware specifications and any hyperparameters not mentioned in the paper?', 'Is the code for LLCG available to the public, and if so, can the authors provide a link to the repository?', 'Can the authors provide more detailed explanations and clarity in the theoretical analysis?', 'Can the authors discuss the potential negative societal impact and limitations of the proposed method?', 'How does the method perform in a real-world distributed setting compared to the simulated environment used in the experiments?', 'Could the authors include ablation studies to analyze the impact of different components of the proposed method?', 'How do different hyperparameters affect the performance of LLCG?', 'Can the authors elaborate on the practical implications of their theoretical findings?', 'How does LLCG address privacy concerns in practical settings?']","['The paper should include more details on the experimental setup to ensure reproducibility.', ""Additional experiments on more diverse datasets could provide further validation of the method's effectiveness."", 'The presentation of the paper could be clearer, especially in the technical details and theoretical analysis.', 'The paper lacks ablation studies to analyze the impact of different components of the proposed method.', 'The paper does not adequately discuss the limitations of the proposed method, such as potential scalability issues or assumptions in the theoretical analysis.', 'Privacy concerns are mentioned but not addressed in practical settings.']",False,3,2,3,5,4,"['Addresses a significant problem in distributed GNN training for large-scale graphs.', 'Introduces a novel approach combining local training with periodic model averaging and global server corrections.', 'Provides rigorous theoretical analysis of the convergence properties of the proposed method.', 'Includes extensive experiments demonstrating the effectiveness of the proposed method compared to existing approaches.']","['The paper could benefit from a more detailed description of the experimental setup and the hardware used for simulations.', 'Reproducibility of the results is crucial, but the paper does not provide detailed information on the implementation or access to the codebase.', 'The performance evaluation focuses on a limited set of datasets, and additional datasets or more diverse experiments could strengthen the claims.', 'The clarity of the theoretical analysis could be improved. Some parts are difficult to follow and require more detailed explanations.', 'The experimental results are conducted in a simulated environment rather than a real-world distributed setting, which may affect the generalizability of the results.', 'Potential ethical concerns and limitations are not adequately addressed. The paper should discuss the potential negative societal impact and limitations in more detail.', 'Lacks ablation studies to analyze the impact of different components of the proposed method.']",3,3,2,3,Reject
HRL6el2SBQ,"The paper introduces a method to enhance out-of-distribution (OoD) detection by utilizing intra-class mixup combined with angular margin. This approach is designed to reduce the angular spread in the latent space, improving the separability between in-distribution and OoD data. The authors claim that their method outperforms existing techniques such as empirical risk minimization (ERM) and inter-class mixup on multiple benchmarks.","['Can the authors provide more details on the experimental setup and parameter configurations?', 'How does the performance change when using intra-class mixup without angular margin and vice versa?', 'What are the potential limitations and negative societal impacts of this approach?', 'Can the authors provide more detailed ablation studies, particularly regarding the impact of different intra-class mixup parameters?', 'How does the proposed method compare to other mixup approaches in terms of OoD detection performance?', 'Can the authors clarify the intra-class mixup mechanism and its specific benefits over inter-class mixup?', 'Can you provide more details about the autoencoder aggregator and how it impacts the results?', 'Have you considered other types of mixup or aggregators? What were the results?', 'Can you provide more qualitative analyses, such as visualizations of the latent space, to support your quantitative results?']","['The paper should discuss the potential limitations of the proposed method, such as computational overhead, scalability, and any assumptions made.', 'A more thorough analysis of the negative societal impacts of the proposed method is needed.', 'The paper could benefit from more detailed explanations of the methodology and additional ablation studies to verify the robustness of the proposed method.']",False,3,2,3,5,4,"['The idea of using intra-class mixup to reduce angular spread and improve OoD detection is novel and well-motivated.', 'The paper addresses an important issue in machine learning: improving the reliability of OoD detection.', 'The proposed method shows promising results with significant improvements in AUROC and other metrics over baseline methods.', 'Comprehensive experiments are conducted to validate the proposed method, demonstrating significant improvements in OoD detection performance across various datasets and detection techniques.']","['The paper lacks clarity in explaining the experimental setup, particularly the parameters and configurations used.', 'The methodology section could benefit from more detailed explanations, especially regarding the implementation of intra-class mixup and angular margin.', 'There is a need for additional ablation studies to isolate the effects of intra-class mixup and angular margin individually.', 'Comparative analysis with other mixup methods is missing, which would strengthen the claims of superiority.', 'The qualitative analysis provided is limited. More visualizations and examples would help in understanding the effectiveness of the proposed method.', 'Potential limitations and negative societal impacts are not adequately discussed.']",3,3,2,3,Reject
t1QXzSGwr9,The paper proposes a novel method to use quantum neural networks (QNN) for image classification on larger and more realistic images than previously possible. This is achieved by a new encoding mechanism and the introduction of CRADL and CRAML network layers. The authors demonstrate the method with empirical results on the MNIST dataset.,"['Can you provide a more detailed theoretical analysis of the proposed methods?', 'Can you compare the proposed method with more state-of-the-art classical methods?', 'Can you provide more empirical results on larger datasets?', 'Can the authors provide more details on the encoding mechanism and how it reduces the number of qubits needed?', 'Have the authors considered applying their method to other datasets beyond MNIST to demonstrate generalizability?', 'Can the authors clarify how their proposed QNN layers (CRADL and CRAML) differ from existing quantum neural network architectures?', 'Can the authors provide more details on the specific quantum gates used in the encoding process?', 'What are the potential ways to mitigate the performance degradation observed when further compressing the images?', 'Are there any other datasets or image resolutions where the method has been tested?', 'Can the authors provide more rigorous theoretical foundations for their claims?', 'How does the proposed method compare with state-of-the-art classical and quantum methods on larger and more diverse datasets?', 'Could the authors provide more intuitive explanations and visual aids to improve the clarity of the methodology?', 'How scalable is the proposed approach to larger datasets and more complex images?', 'What are the practical implications and potential challenges of implementing the proposed methods on actual quantum hardware?']","['The paper does not adequately address the limitations and potential negative societal impacts of the work. The practical significance and theoretical soundness are questionable, and the necessity and advantage of using quantum methods are not convincingly argued or demonstrated.', 'The paper acknowledges the performance degradation with increased compression and the challenges in physical implementation. Future work could explore more efficient encoding strategies and better network architectures to improve scalability.', 'The paper does not sufficiently address the potential challenges in scaling the proposed methods to larger datasets and more complex images.', 'The practical implications of the work are not well-articulated, and the paper does not discuss the feasibility of implementing the proposed methods on actual quantum hardware.']",False,2,2,2,3,4,"['The paper addresses an important issue in quantum machine learning, namely the ability to handle larger and more realistic images.', 'The proposed encoding mechanism and the introduction of CRADL and CRAML network layers are novel.', 'The framework achieves comparable accuracy to classical neural networks with the same number of parameters for 8x8 images.', 'The authors provide supplementary code, which aids reproducibility.']","['The overall contribution and impact on the field seem limited. The quantum method achieves similar performance to classical methods on small datasets, and the necessity and advantage of using quantum methods are not convincingly argued or demonstrated.', 'The paper lacks thorough theoretical analysis and clarity in presentation, making it difficult to follow and reproduce the results.', 'The empirical results are limited, and the paper does not provide a comprehensive comparison with state-of-the-art classical methods.', 'The practical significance and theoretical soundness of the proposed method are questionable.', 'The performance degrades significantly when the images are further compressed to reduce qubit usage, limiting practical applicability.', 'The scalability of the method to even larger images remains unproven and is constrained by current hardware limitations.', 'The paper does not thoroughly address the limitations of the proposed methods, such as the scalability to larger datasets and more complex tasks. The potential negative societal impact is not discussed.']",3,2,2,2,Reject
e0uknAgETh,"The paper investigates the vulnerability of Spiking Neural Networks (SNNs) to adversarial attacks in the context of event-based vision systems. It adapts existing adversarial attack algorithms to the discrete and sparse nature of event-based data and validates the perturbations on neuromorphic hardware. The methods are tested on N-MNIST and IBM Gestures datasets, demonstrating the effectiveness of these perturbations.","['Can the authors provide more details on the autoencoder aggregator used in the experiments?', 'Could additional ablation studies be performed to evaluate the impact of different components and design choices in the methodology?', 'Can more qualitative analyses and visualizations of adversarial examples be included to enhance understanding?', 'Can the authors provide a more detailed comparison with existing defense strategies against adversarial attacks in SNNs?', 'How do the authors plan to address the limitations of their methods in future work?', 'Can the authors elaborate on the potential negative societal impacts of their findings?', 'Can you provide more details on the implementation of the Probabilistic PGD and SparseFool attacks?', 'How do your methods compare quantitatively against other state-of-the-art adversarial attack strategies in similar domains?', 'Can you expand on the defense strategies and their effectiveness against the proposed attacks?', 'How does the performance of the attacks change with different network architectures or training methods?', 'What are the practical implications for real-world deployment?']","['The paper could provide more clarity in certain experimental sections and include additional ablation studies to thoroughly evaluate the methodology.', 'The difficulty of applying these attacks in real-time scenarios and the need for offline computation is a significant limitation.', 'The potential negative societal impacts and ethical considerations of deploying vulnerable neuromorphic systems are briefly mentioned but not thoroughly explored.']",False,3,3,3,6,4,"['Addresses an important and relatively unexplored problem in the field of neuromorphic engineering and secure machine learning.', 'Adapts white-box adversarial attack algorithms to the unique characteristics of event-based data and SNNs.', 'Comprehensive experiments on well-known datasets, along with validation on neuromorphic hardware, demonstrate practical relevance.', 'Provides detailed results and analysis of the adversarial perturbations, including their effectiveness and properties.']","['Further details on some experimental sections could enhance clarity, particularly in describing the autoencoder aggregator.', 'More detailed ablation studies are needed to thoroughly evaluate the different components and choices made in the methodology.', 'The paper could benefit from additional qualitative analyses, including more visualizations of adversarial examples.', 'The presentation of the methods and results could be improved for better clarity. Some sections are dense and difficult to follow.', 'There is a lack of discussion on the limitations and potential negative societal impacts of the proposed methods.', 'The empirical analysis of the resulting perturbations is somewhat superficial and could be expanded.']",3,3,3,4,Reject
8XM-AXMnAk_,"The paper proposes a theory-driven deep active learning method, dynamicAL, which selects samples to maximize training dynamics. This approach is theoretically justified using the Neural Tangent Kernel (NTK) framework, linking faster convergence with better generalization performance. The method is evaluated on several datasets and neural network architectures, showing consistent performance improvements over existing methods.","['Can the authors provide more details about the pseudo-labeling strategy and its impact on the performance of dynamicAL?', 'What is the impact of different types of aggregators on the performance?', 'Can the authors provide more qualitative analysis and visualizations to illustrate the benefits of the proposed method?', 'How sensitive is the method to different initializations and network architectures?', 'Can the authors include more comprehensive ablation studies to better understand the contributions of each component of dynamicAL?', 'Can the authors provide a more detailed explanation of the theoretical assumptions and derivations, particularly in the context of active learning?', 'How robust are the empirical results across different initial labeled sets and pseudo-labeling qualities?', 'Can the authors clarify the experimental setup, including hyperparameter choices, to ensure reproducibility?', 'Can the authors provide more details on the impact of the ultra-wide condition on practical scenarios?', 'How does dynamicAL perform with highly imbalanced or noisy datasets?', 'Can the authors elaborate on the choice of pseudo-labeling and its impact on the results?', 'What are the computational costs associated with dynamicAL compared to other methods?', 'How does dynamicAL compare to semi-supervised learning methods in terms of empirical performance?']","['The paper should address the limitations related to the clarity of exposition and the need for more comprehensive ablation studies. Additionally, potential negative societal impacts of the proposed method should be discussed.', 'The approach relies on the quality of pseudo-labeling and the initial labeled set, which may affect its performance in practice. The scalability of the method to very large datasets and models is also a concern.', 'The theoretical analysis assumes certain conditions (e.g., ultra-wide neural networks) that may not always hold in practical settings.', 'The reliance on high-quality pseudo labels might limit the applicability of dynamicAL in scenarios with highly imbalanced or noisy datasets. More discussion on this limitation and potential solutions would enhance the paper.']",False,3,2,3,5,4,"['The paper addresses a significant problem in active learning, particularly for deep learning models.', 'The introduction of training dynamics as a metric for active learning is novel and theoretically justified using the NTK framework.', 'Extensive theoretical analysis is provided to support the main claims.', 'Empirical results show that dynamicAL outperforms several strong baselines across different datasets and model architectures.']","['The clarity of the paper can be improved, particularly in the explanation of the theoretical concepts and the method section.', 'More ablation studies are needed to understand the impact of different components of the method, such as the effect of different pseudo-labeling strategies and types of aggregators.', 'Some experimental details, such as the settings for the hyperparameters and the exact training protocol, need to be more thoroughly described.', 'The qualitative analysis and visualization provided are limited and could be expanded to better illustrate the benefits of the proposed method.', 'The empirical improvements, while consistent, are not dramatically better than existing methods, posing questions about the practical impact.', 'The assumptions and limitations of the NTK framework, such as the ultra-wide condition, need more discussion regarding their impact on practical scenarios.', ""The method's reliance on high-quality pseudo labels might limit its applicability in scenarios with highly imbalanced or noisy datasets.""]",4,3,2,3,Reject
qZNw8Ao_BIC,"This paper investigates the robustness of Vision Transformers (ViTs) by examining their sensitivity to patch-based transformations. The authors find that ViTs heavily rely on non-robust features that survive these transformations, which do not align with human perception. To mitigate this issue, they propose a novel training method using patch-based negative augmentation. They demonstrate through extensive experiments that this method improves robustness across several benchmarks.","['Can the authors provide more details about the autoencoder aggregator?', 'What is the performance of the proposed model by changing the type of aggregators?', 'Can the authors provide more qualitative analysis cases?', 'Can the authors provide more detailed ablation studies on the choice of patch-based transformation parameters?', 'Could you clarify the implementation details of the negative augmentation, particularly the choice of hyperparameters?']","['The paper lacks clarity in some sections and requires additional ablation studies to strengthen the claims.', 'The primary limitation is the need for more detailed ablation studies and clarity in the methodology.', 'The paper should explore potential negative societal impacts of the proposed method.']",False,3,2,3,5,4,"['Addresses an important issue in the robustness of Vision Transformers.', 'Novel approach using patch-based negative augmentation.', 'Comprehensive experiments demonstrating significant improvements in robustness.', 'Results show that the proposed method is complementary to traditional data augmentation techniques.']","['Lacks clarity in certain sections, particularly in explaining the methodological details.', 'Requires more detailed ablation studies, especially regarding the modulation function and different types of aggregators.', 'Qualitative analyses need more cases to be convincing.', 'Comparisons with existing methods could be more comprehensive.']",3,3,2,3,Reject
RLtqs6pzj1-,"The paper introduces FreeTickets, a novel ensemble learning framework that leverages dynamic sparse training (DST) to create efficient ensembles with reduced computational costs. The proposed methods, DST Ensemble and EDST Ensemble, aim to provide high accuracy, robustness, and efficiency by training sparse subnetworks and combining their predictions. The paper demonstrates improvements in predictive accuracy, uncertainty estimation, and out-of-distribution robustness while maintaining training/inference efficiency.","['Can you provide more detailed comparisons with additional state-of-the-art ensemble methods?', 'Could you include further ablation studies to explore the impact of different hyperparameters and methodological choices?', 'How do you ensure the reproducibility of your results beyond providing the source code?', 'What are the potential ethical considerations or societal impacts of your proposed methods?', 'Can the authors provide more details on the autoencoder aggregator and its role in the framework?', 'Have the authors considered the impact of different hardware supports for sparse computations on the practical applicability of the proposed methods?']","['The paper does not sufficiently address the potential limitations and societal impacts of the proposed methods.', 'The practical applicability of the proposed methods may be limited by the current hardware support for sparse computations.', 'The complexity of the methods could be a barrier to their adoption in real-world applications.']",False,3,3,3,5,4,"['The concept of using dynamic sparse training for ensemble creation is novel and potentially impactful.', 'The methods show significant improvements in computational efficiency while maintaining or improving predictive performance.', 'Comprehensive experiments and comparisons with existing methods like MIMO, BatchEnsemble, and others are provided.', 'Addresses high computational costs of traditional ensemble methods.', 'The paper is well-structured and provides detailed experimental results, including comparisons with state-of-the-art methods.']","['The paper lacks comparative analysis with a broader range of state-of-the-art methods.', 'More detailed ablation studies are required to fully understand the impact of various design choices.', 'Clarity of the explanations and pseudocode can be improved to make the paper more accessible.', 'The paper does not address potential ethical considerations or societal impacts of the proposed methods.', 'The complexity of the proposed methods may limit their practical applicability, especially in environments without hardware support for sparse computations.', 'Potential issues with reproducibility due to complex procedures.']",3,3,3,3,Reject
kHNKTO2sYH,"The paper introduces Clean Subspace Variational Autoencoder (CLSVAE), a novel semi-supervised method for detecting and repairing systematic errors in datasets. The method partitions the latent space into clean and dirty subspaces, enabling better reconstruction and repair. The paper presents comprehensive experiments on three image datasets with different levels of corruption and compares the results to several baselines.","['Can you provide more detailed explanations about the autoencoder aggregator?', 'Can you include more qualitative examples of repairs, especially for different levels of corruption?', 'Can you provide a more detailed explanation of the mutual information penalty and how it is implemented?', 'Have you considered evaluating the model on additional real-world datasets beyond image data?', 'How does the model handle cases where the type of systematic error is not known in advance?', 'Can the authors conduct additional ablation studies on the modulation function and the type of aggregators?', 'Can you provide more intuitive explanations and diagrams for the methodology?', 'Can you reorganize the experimental results to highlight the key findings more clearly?', 'How would CLSVAE perform on non-image data, such as tabular or time-series data? Have you considered any experiments in these domains?', 'Can you elaborate on the theoretical underpinnings of the compression hypothesis and the mutual information penalty? How critical are these components to the success of CLSVAE?', 'What are the potential negative societal impacts of your work, if any?']","['The main limitation is the clarity of some parts of the methodology. More detailed explanations and qualitative examples would enhance the understanding and impact of the paper.', 'The paper focuses on image datasets; evaluating on other types of data (e.g., tabular, sensor) would be valuable.', ""The mutual information penalty's impact on the model's performance and stability needs clearer justification and explanation."", 'The primary concern is the clarity of the paper and the need for additional ablation models to validate the proposed components.', 'The reliance on the compression hypothesis and the mutual information penalty, while novel, needs more rigorous theoretical and empirical validation.']",False,3,3,3,6,4,"['Novel idea of partitioning the latent space into clean and dirty subspaces.', 'Use of distance correlation to enforce low mutual information between subspaces.', 'Comprehensive experiments covering various corruption levels and trusted set sizes.', 'Significant improvements in detection and repair performance compared to baselines.', 'Addresses the significant problem of systematic errors in datasets.', 'Introduction of a new dataset (Art-Multi) for further evaluation.']","['Some parts of the methodology, like the autoencoder aggregator, need more detailed explanations.', 'The explanation of the mutual information penalty and its implementation could be clearer.', 'The empirical results section is dense and could benefit from more intuitive explanations.', 'Limited diversity in datasets; additional real-world datasets would strengthen the evaluation.', 'The paper could better differentiate its contributions from related work on handling random errors and semi-supervised outlier detection.', 'Additional ablation studies are needed to validate the proposed components, such as the modulation function and the type of aggregators.', 'Theoretical justification for the proposed approach could be stronger.', 'The practical implications and broader impact of the work are not sufficiently discussed.']",3,3,3,4,Reject
izj68lUcBpt,"The paper introduces Temporally-Adaptive Convolutions (TAdaConv) for video understanding. TAdaConv dynamically calibrates convolution weights based on temporal context, enhancing temporal modeling in video data. The method shows improvements on various video action recognition and localization benchmarks, demonstrating its effectiveness.","['Can the authors provide more ablation studies to further validate the effectiveness of TAdaConv?', 'Could additional explanations or visual aids be added to clarify some complex concepts?', 'Can the authors provide more detailed explanations and mathematical formulations for the calibration weight generation and initialization strategy?', 'Could the authors include additional ablation studies to investigate the impact of different components of TAdaConv, such as the effect of the global vs. local temporal context?', 'Can the authors share more details about the training protocols and hyperparameters used for each dataset?', 'Can the authors provide more intuitive explanations or diagrams for the calibration weight generation process?', 'What is the impact of different calibration dimensions in more detail? Can this be further explored?', 'Could the authors expand the qualitative analysis with more examples and insights?', 'Can the authors provide more details on the autoencoder aggregator used in the experiments?', 'Have the authors considered other types of modulation functions or aggregators, and how do they compare to the current choices?', 'Can the authors include more qualitative examples to illustrate the effectiveness of the proposed method?', ""Can the authors simplify or clarify some of the more complex technical details to improve the reader's understanding?"", 'Have the authors considered testing the method on a wider variety of datasets to demonstrate general applicability?']","['The paper could benefit from more ablation studies and additional explanations for complex concepts.', ""The paper's clarity and completeness could be improved, particularly in the explanation of the methodology and the provision of more comprehensive ablation studies."", 'The paper adequately addresses potential limitations, but further clarity and detailed exploration of the calibration weight generation process and its various dimensions are needed.', 'The main limitations are the complexity of the technical details and the need for more thorough ablation studies and generalization analysis.']",False,3,3,3,6,4,"['Novel approach to enhance temporal modeling in videos by dynamically calibrating convolution weights.', 'Thorough experiments and evaluations on multiple benchmarks.', 'Demonstrates significant improvements over state-of-the-art methods.', 'TAdaConv can be easily integrated into existing architectures and leverages pre-trained weights, making it practical for real-world applications.', 'The method introduces negligible additional computation overhead, making it efficient.']","['The explanation of the methodology, particularly the calibration weight generation and the initialization strategy, lacks clarity and could be more detailed.', 'The paper does not provide sufficient ablation studies to thoroughly investigate the effects of different components of the proposed method.', 'Some experimental details, such as the exact training protocols and hyperparameters for all datasets, are not sufficiently described.', 'The visualization and qualitative analysis, while helpful, could include more examples to better illustrate the effectiveness of TAdaConv.']",4,3,3,4,Accept
dzZQEvQ6dRK,"The paper investigates the use of contrastive methods, specifically BYOL, to learn disentangled representations. It introduces the concept of 'group disentanglement' and provides empirical evidence of competitive performance on synthetic and real-world datasets.","['Can the authors provide more theoretical insights into why BYOL achieves group disentanglement?', 'Can the authors include more baselines for comparison to strengthen the empirical results?', 'Can the authors clarify the methodology and experimental setup in more detail?', 'What is the rationale behind the choice of hyperparameters and normalization techniques?', ""How does 'group disentanglement' compare with traditional disentanglement in terms of practical utility and interpretability?"", 'What is the impact of different augmentation strategies on the disentanglement properties of the learned representations?']","['The paper focuses heavily on empirical results without providing deep theoretical insights. Additionally, some parts of the methodology and experimental setup lack clarity, which makes it difficult to fully understand and reproduce the experiments.', 'The paper does not adequately address the limitations and potential negative societal impacts of the work. More discussion on the scalability and generalizability of the proposed approach to other domains and tasks would be beneficial.']",False,2,2,3,5,4,"['Novel approach: Uses contrastive methods (BYOL) for disentanglement, which is different from traditional generative models.', 'Empirical evidence: Provides extensive experimental results on synthetic and real-world datasets.', 'Comprehensive analysis: Includes both qualitative and quantitative assessments.']","['Lack of deep theoretical insights: The paper is mostly empirical without strong theoretical backing.', 'Limited comparison with existing methods: While it compares with some baselines, the comparison could be broader.', 'Clarity issues: Some parts of the methodology and experimental setup are not clearly explained.', 'Experimental justification: The choice of hyperparameters and other experimental details are not well justified.', 'Significance and impact: The significance of the contributions is somewhat overstated without rigorous theoretical support.']",3,2,2,3,Reject
bgAS1ZvveZ,"The paper introduces value target lower bounding in reinforcement learning to improve the speed and efficacy of value learning. It demonstrates that an arbitrary lower bound on the value function converges to the same optimal value using the Bellman operator. The method is validated by experiments on Atari games, FetchEnv tasks, and a simulated car push and reach task, showing improvements over standard baselines such as TD3, SAC, and HER.","['Can the authors provide more detailed explanations or step-by-step proofs for the theoretical results?', 'What are the impacts of using different types of lower bound functions? Are there scenarios where one type significantly outperforms others?', 'How does the proposed method perform in highly stochastic environments? Are there any specific strategies to handle overestimation in such cases?', 'Can the authors provide more details on the implementation of lower bounding in complex environments like FetchEnv?', 'How does the method compare to other recent advances in reinforcement learning, such as distributional RL or model-based methods?', 'Can the authors clarify and elaborate on the experimental setup, including hyperparameter settings and implementation details, to ensure reproducibility?', 'What are the potential ethical implications and societal impacts of your reinforcement learning algorithms?']","['The paper does not extensively discuss the potential limitations of the proposed method in stochastic environments, where empirical returns might lead to overestimation of the value function.', 'The impact of different types of lower bounds and their computational trade-offs are not thoroughly analyzed.', 'The lack of comprehensive ablation studies and detailed explanations of the methodology and experimental setup are major concerns that need to be addressed.', 'The main limitation is that the theoretical guarantees are only for the tabular case. It is important to understand how the method performs with function approximation.']",False,3,2,3,5,4,"['The idea of using a lower bound on the value target is novel and theoretically sound, with proven convergence in the tabular case.', 'The method is simple to implement, requiring minimal computational overhead and no additional parameter tuning.', 'The experimental results are comprehensive, covering a wide range of tasks including Atari games and continuous control tasks, and show significant improvements in sample efficiency.']","['The clarity of the algorithm and some theoretical concepts could be improved. For example, the proof of the convergence theorem is somewhat dense and could benefit from additional explanatory steps.', 'The paper lacks detailed ablation studies to isolate the effects of different components of the proposed method.', 'The experimental setup lacks detailed descriptions, which are necessary for reproducibility and clarity.', 'The theoretical guarantees are limited to the tabular case, and the implications for function approximation in practice are not thoroughly discussed.', 'The paper does not sufficiently address the limitations and potential negative impacts of the proposed method, particularly when applied to stochastic environments.']",3,3,2,3,Reject
biyvmQe5jM,"The paper proposes ABEL, an automatic learning rate scheduler that uses weight norm dynamics to determine when to decay the learning rate. The authors argue that complex learning rate schedules are beneficial primarily in scenarios where the weight norm bounces, a phenomenon influenced by L2 regularization and high learning rates. Through extensive experiments in vision, NLP, and RL, ABEL is shown to perform as well as fine-tuned schedules and is more robust to hyperparameters.","['Can you provide more theoretical insights into why weight norm bouncing is necessary for the effectiveness of complex learning rate schedules?', 'How does ABEL perform with different initialization methods? Are there specific initializations that make weight norm bouncing less effective?', 'Have you tested ABEL on other architectures or tasks not covered in the paper? If so, how does it perform?', 'Can ABEL be extended to other hyperparameters beyond learning rate, such as momentum or weight decay?']","['The theoretical underpinnings of weight norm dynamics and their impact on learning rate schedules are not deeply explored.', 'The generalizability of the findings to other tasks and architectures is uncertain.', 'The dependence on specific initialization methods for the effectiveness of ABEL is not thoroughly explored.', 'The paper could benefit from a more detailed discussion on the limitations and potential failure cases of ABEL.']",False,3,3,3,5,4,"['The paper introduces a novel insight into the importance of weight norm dynamics in learning rate scheduling.', 'Extensive empirical evaluation across diverse domains validates the effectiveness and robustness of ABEL.', 'ABEL simplifies the learning rate scheduling process by reducing the need for manual tuning.', 'The paper addresses a practical problem in deep learning optimization.']","['The paper lacks a rigorous theoretical foundation explaining why weight norm bouncing is necessary for the effectiveness of complex schedules.', 'It is unclear how generalizable the findings are to other architectures and datasets not included in the study.', 'The dependence on initialization methods for the effectiveness of ABEL is not thoroughly investigated.', 'Certain sections, especially those detailing the algorithm, are dense and could benefit from further clarity.']",3,3,3,3,Reject
nkaba3ND7B5,"The paper introduces a framework for Autonomous Reinforcement Learning (ARL) and a benchmark suite, EARL, to evaluate algorithms designed for autonomous, non-episodic learning. It addresses the gap between traditional episodic RL and real-world autonomous learning by creating environments that require minimal human intervention.","['Can the authors provide more details on how they plan to ensure the reproducibility of their benchmarks and experimental results?', 'How do the authors envision integrating ARL with other emerging trends like meta-learning or transfer learning to further enhance the autonomy of RL agents?', 'What specific challenges do the authors foresee in extending their benchmarks to more complex and high-dimensional tasks?', 'Can you provide more detailed explanations of the formalism, especially regarding the two evaluation settings?', 'How do the proposed benchmarks compare to other existing benchmarks in terms of difficulty and relevance?', 'Can you include more diverse baseline algorithms in the experiments to validate the benchmark more thoroughly?', 'What are the potential future directions and impact of ARL algorithms based on your findings?', 'Can you provide more justification for the design choices in the benchmark and how they align with real-world scenarios?', 'How would the proposed benchmark handle more diverse tasks beyond manipulation and locomotion?', 'Can you clarify the definitions and distinctions between the different settings (deployment vs. continuing) in more detail?', 'What are the potential limitations and negative societal impacts of the proposed framework?', 'Can the authors provide more detailed explanations of the differences between the proposed ARL framework and existing reset-free RL approaches?', 'What are the main factors contributing to the poor performance of existing algorithms in the EARL benchmark?', 'Can the authors discuss any potential negative societal impacts of deploying autonomous RL systems in real-world scenarios?', 'Can the authors discuss potential directions for developing new ARL algorithms based on the insights gained from the benchmark?', 'Are there specific aspects of the framework that could be further expanded or refined to improve its applicability?']","[""The paper acknowledges the difficulty of sparse reward settings but doesn't offer new methodologies to address this issue."", ""The primary focus on benchmarking may limit the immediate impact on advancing RL algorithms' capabilities."", 'The formalism and explanations could be clearer to enhance understanding.', 'The analysis could include more depth and comparisons with a diverse set of baseline algorithms.', 'More discussion on future directions and the broader impact of ARL algorithms would be beneficial.', 'The paper does not adequately discuss the limitations of the proposed benchmark and the potential negative societal impacts of autonomous RL.', 'The potential negative societal impacts of autonomous RL, such as safety concerns, are not adequately addressed. The authors should discuss these aspects in more detail.']",False,3,3,3,6,4,"['Addresses a crucial gap in RL research by focusing on autonomous learning without episodic resets.', 'Introduces a well-defined benchmark suite (EARL) that includes a variety of tasks to evaluate ARL algorithms.', 'Provides comprehensive experimental evaluation demonstrating the limitations of current RL methods in autonomous settings.', 'Clear motivation and problem statement, emphasizing the practical relevance of ARL.']","['Limited novelty in proposing new RL techniques or algorithms.', 'Some parts of the formalism are not entirely clear and could benefit from more detailed explanations.', 'The analysis could be deeper in some sections, especially regarding the performance of different algorithms.', 'The set of baseline algorithms compared in the experiments could be more diverse to strengthen the validation of the proposed benchmark.', 'More detailed discussion on the potential impact and future directions for ARL algorithms would enhance the paper.', 'The paper lacks a detailed discussion on the potential negative societal impacts of autonomous RL, such as safety concerns in real-world deployments.']",3,3,3,4,Reject
OqlohL9sVO,"The paper proposes a novel image retrieval method, UGALR, that unifies global and local features using a single-stage, end-to-end pipeline. The method enhances retrieval efficiency and accuracy by fusing multi-attentive local features with global features and learning homography transformation through CNNs. Experimental results show state-of-the-art performance on benchmark datasets.","['Can the authors provide more details about the autoencoder aggregator and the implementation of the LALM block?', 'Could the authors conduct additional ablation studies to analyze the modulation function and the type of aggregators used?', 'Can more qualitative examples be provided to strengthen the claims?', 'Why did you choose the specific parameters and configurations used in your experiments? Can you provide justifications for these choices?', 'Can you compare your approach with a broader range of existing methods, particularly those using different types of attention mechanisms?', 'How does the proposed method compare with other recent approaches in terms of computational complexity and memory usage?']","['The paper could benefit from clearer descriptions of some components and additional ablation studies to provide deeper insights.', 'The clarity of the explanations for key components like the LALM block and intermediate supervision needs improvement. This is crucial for reproducibility and understanding the contributions.', 'The novelty of the approach could be better justified.', 'The experimental comparisons and ablation studies could be more comprehensive.']",False,3,2,3,5,4,"['The paper addresses efficiency and accuracy concerns in image retrieval with a novel approach.', 'Introduction of the Local Attention Learning Module (LALM) with spatial and channel attention is innovative.', 'Intermediate supervision enhances the learning process by differentiating the importance of attention and features.', 'Experimental results demonstrate significant improvements in accuracy and efficiency, achieving state-of-the-art performance.']","['The description of some components, such as the autoencoder aggregator and LALM, could be clearer.', ""Some crucial ablation studies are missing, which could provide a deeper understanding of the model's components."", 'The qualitative analysis could be more comprehensive with additional visualizations to strengthen the claims.', 'The novelty of the approach could be questioned since it builds heavily on existing methods, albeit in a more integrated manner.', 'The paper lacks a thorough comparison with a broader range of existing methods, particularly those using different types of attention mechanisms.']",3,3,2,3,Reject
cLcLdwOfhoe,"The paper presents FEDLITE, a novel framework for federated learning on resource-constrained clients. It introduces a product quantization method for compressing client activations and a gradient correction technique to address the communication overhead in split learning. The empirical results indicate significant communication cost reduction with minimal accuracy loss, demonstrating its potential for practical use in federated learning settings.","['Can the authors provide more detailed comparisons with other state-of-the-art quantization methods?', 'Could the authors elaborate on how the proposed method handles non-IID data distributions and varying client participation?', 'What are the practical deployment challenges of the proposed framework, and how can they be mitigated?', 'Can the authors provide more detailed ablation studies to explore the effects of different parameters and configurations?', 'Could the gradient correction mechanism be explained in more detail, particularly how it integrates into the overall training process?', 'Are there any other potential applications of the proposed method beyond federated learning with resource-constrained clients?']","['The paper should discuss potential limitations such as handling non-IID data distributions, varying client participation, and the impact of communication delays.', ""Practical deployment challenges and potential solutions should be addressed to provide a more comprehensive understanding of the framework's applicability."", 'The complexity of the proposed method might limit its practical applicability.', 'The paper could benefit from a more thorough discussion of ethical considerations and potential negative impacts.']",False,3,2,3,6,4,"['Addresses a critical issue in federated learning for resource-constrained clients: high communication costs due to model updates.', 'Introduction of product quantization and gradient correction techniques to effectively reduce communication overhead.', 'Comprehensive empirical evaluation on standard datasets showing significant communication reduction with minimal accuracy loss.', 'Theoretical analysis supporting the convergence of the proposed method.']","['The novelty and effectiveness of the proposed product quantization technique need further validation against more baseline methods.', 'The explanation of complex concepts and mathematical derivations lacks clarity, making it difficult for readers to fully understand the methodology.', 'Potential limitations and practical deployment challenges, such as the impact of non-IID data and varying client participation, are not adequately discussed.', 'The paper does not provide sufficient ablation studies to isolate the contributions of individual components of the proposed framework.']",3,3,2,4,Accept
FZoZ7a31GCW,"The paper introduces Draupnir, a deep generative model for ancestral protein sequence reconstruction that incorporates evolutionary information using a tree-structured Ornstein-Uhlenbeck process as a prior for a variational autoencoder. The method aims to improve the accuracy of ancestral sequence reconstruction by modeling the evolution of continuous latent traits of sequences. The model is benchmarked against state-of-the-art ASR methods on multiple datasets, showing competitive performance.","['Can the authors provide more detailed explanations of the neural network architectures and the training procedures used?', ""What is the impact of different hyperparameter choices on the model's performance?"", 'How does the model perform when varying the number of latent dimensions (nZ) or the length scale (λ) of the TOU process?', 'Can the authors provide more details on the autoencoder aggregator and its implementation?', 'How does the model perform if the given phylogenetic tree is inaccurate or unavailable?', 'Can additional cases be provided in the ablation studies to strengthen the evaluation?', 'Have you considered other types of modulation functions, and if so, how do their performances compare?', ""Can you include more examples in the qualitative analysis to better demonstrate the model's performance?""]","['The paper does not address the potential computational complexity and scalability issues of the proposed method when applied to larger datasets.', 'There is a need for more comprehensive ablation studies to understand the contribution of each component of the model.', 'The paper heavily relies on the availability and accuracy of the given phylogenetic tree, which may not always be feasible.', ""Additional ablation studies on different modulation functions and aggregator types would provide a more comprehensive understanding of the model's performance.""]",False,3,3,3,6,4,"['Innovative integration of evolutionary models with deep generative models.', 'Comprehensive benchmarking against state-of-the-art ASR methods on multiple datasets.', 'The use of a tree-structured Ornstein-Uhlenbeck process as a prior is novel and provides a strong theoretical foundation.', 'Potential for significant impact in biological and medical fields due to improved accuracy in ASR.']","['The clarity of the paper could be improved, especially in the methodology section where the model and its components are described.', 'The paper lacks detailed ablation studies on the impact of various components of the model, such as the choice of hyperparameters and the architecture of the neural networks.', 'Practical implementation details, such as the specific settings for the neural networks and training procedures, are not thoroughly described.', 'Limited discussion on the computational efficiency and scalability of the proposed method when extending to genomic-scale data.']",4,3,3,4,Reject
8rCMq0yJMG,"The paper proposes a novel source-target unified knowledge distillation (STU-KD) method to adapt compact machine learning models for local inference on edge devices. It addresses the challenge of adapting models to different data distributions in new environments while ensuring memory efficiency and privacy. The approach involves adapting a large source model to the target data using a memory-efficient UDA method (lite residual hypothesis transfer) and then transferring the knowledge to the compact model through collaborative knowledge distillation. The method is evaluated on several object recognition tasks, showing significant improvements in inference accuracy.","['Can the authors provide more details on the autoencoder aggregator?', 'Can additional ablation studies be conducted to better assess the impact of each component of the proposed method?', 'How does the proposed method specifically address the ethical concerns related to data privacy and security?', 'Can you provide more details on the LRHT method, particularly how the lite residual modules are designed and integrated?', 'How does the Co-KD method handle different types of loss functions on the server and edge devices?', 'Can you provide more experimental results with a variety of datasets and ablation studies to validate the effectiveness of each component of the proposed method?', 'How does the integration with secure aggregation impact the performance and privacy of the STU-KD method?']","['The clarity of the paper needs significant improvement.', ""Additional ablation studies are required to fully assess the method's effectiveness."", 'Ethical concerns about data privacy and security need to be more deeply explored.', ""The method's reliance on a large source model might limit its applicability in severely resource-constrained scenarios.""]",False,3,3,3,6,4,"['Addresses a well-motivated and practical problem of adapting compact models for edge devices under different data distributions while preserving privacy.', 'Proposes a novel combination of domain adaptation and knowledge distillation.', 'Comprehensive experiments demonstrating significant improvements in inference accuracy over state-of-the-art methods.', 'Integration of secure aggregation to ensure privacy.']","['Lacks clarity in explaining certain components, such as the autoencoder aggregator.', 'Needs additional ablation studies to validate the effectiveness of each component.', 'Complex methodology may hinder reproducibility without additional details.', 'Ethical concerns regarding privacy and data security are mentioned but not deeply explored.']",3,3,3,4,Reject
So6YAqnqgMj,"The paper introduces µ-EigenGame, an unbiased stochastic update method for eigendecomposition, which addresses the bias in the original EigenGame's updates. The proposed method is designed to perform better with smaller minibatches and allow for greater parallelism. The authors demonstrate the effectiveness of µ-EigenGame through applications in principal component analysis and spectral clustering, comparing it against the original EigenGame and other algorithms.","['Can the authors provide more details on the practical implementation of µ-EigenGame, particularly the handling of large datasets in a distributed environment?', 'How does µ-EigenGame perform in scenarios with extremely small minibatches, and what are the trade-offs in such cases?', 'Can the authors include additional ablation studies to better understand the contribution of each component of the proposed method?', 'Can the authors provide more practical examples and use cases where µ-EigenGame significantly outperforms traditional methods?', 'Is there a way to simplify the theoretical proofs or provide more intuitive explanations?', 'Can the authors discuss potential limitations and broader impacts of their work in more detail?']","['The paper should discuss potential limitations, such as the impact of extremely small minibatches on the performance and convergence of µ-EigenGame.', 'A discussion on the potential negative societal impacts of the proposed method should be included.', 'The primary limitation is the clarity of the theoretical sections, which may hinder understanding and reproducibility.', 'Additional ablation studies are needed to fully understand the contributions of different components of the proposed method.', 'The paper acknowledges that finite-sample convergence rates are not provided, which is a critical aspect for practical applications.', 'The complexity of implementing the proposed approach, especially in terms of parallelism and device coordination, is a potential limitation that could hinder its adoption.']",False,3,3,3,6,4,"['The paper addresses an important issue in the original EigenGame: the bias in updates when using minibatches.', 'The proposed µ-EigenGame enables more efficient parallel computation, making it suitable for large-scale data processing.', 'Theoretical analysis is provided to support the claims of asymptotic equivalence and unbiased updates.', 'Experimental results on large datasets, including MNIST and a conversational model dataset, demonstrate the practical improvements of µ-EigenGame.']","['The clarity of the paper could be improved. Some sections are dense and may be difficult for readers to follow, particularly the theoretical derivations.', 'The experimental results, while extensive, could benefit from additional ablation studies to isolate the impact of different components of the proposed method.', 'The paper lacks a detailed discussion on the potential limitations and negative societal impacts of the proposed method.', 'The reliance on game theory for eigenvector computation might not be immediately compelling without more practical examples and use cases.']",3,3,3,3,Reject
Zca3NK3X8G,"The paper introduces WaveCorr, a novel CNN architecture for deep reinforcement learning in portfolio management, focusing on permutation invariance to handle cross-asset dependencies effectively. The empirical results suggest significant performance improvements over state-of-the-art methods.","['Can you provide more details on the exact hyperparameters used in the experiments?', 'How robust are the results across different market conditions and time periods?', 'How does WaveCorr compare to existing methods in scenarios beyond just numerical performance?', 'What are the potential limitations of your approach?', 'Have you considered any ethical implications of applying this architecture in financial markets?', 'Could the authors provide more details on the implementation of the correlation layer and its computational complexity?', 'How does the performance of WaveCorr vary with different hyper-parameter settings?', 'Can additional benchmarks be included to further validate the proposed method?', 'Can the authors provide more details on the theoretical foundation and derivation of the Corr layer?', 'What specific hyperparameter tuning strategies were employed, and how sensitive is the model to these choices?', 'Can the authors elaborate on the computational complexity and training time of WaveCorr compared to other methods?', 'Can the authors provide more detailed explanations and diagrams for the Corr layer and the overall architecture?', 'How does the model perform on different types of financial instruments (e.g., bonds, commodities) or in different market conditions?', 'Can the authors provide more rigorous statistical analysis (e.g., significance testing) to support their performance claims?', 'Can the authors provide more details on the autoencoder aggregator?', 'What is the performance of the proposed model by changing the type of aggregators?', 'Can the authors provide additional ablation studies focusing on the modulation function?']","['The paper does not discuss the potential limitations of the proposed approach.', 'Ethical considerations around algorithmic trading and market manipulation are not addressed.', 'The paper could explore more diverse benchmarks and market conditions to validate the robustness of the proposed method.', 'Further clarity on technical details would enhance the comprehensibility of the proposed architecture.', 'Additional ablation studies could further strengthen the claims about the effectiveness of different components of the architecture.']",False,2,2,3,6,4,"['The concept of permutation invariance in policy networks is novel and well-motivated.', 'The architecture builds on the WaveNet structure, incorporating innovative correlation layers to capture cross-asset dependencies.', 'Empirical results show significant performance improvements in terms of annual return, Sharpe ratio, and other metrics.', 'Addresses a critical problem in portfolio management with a novel approach.', 'Extensive empirical validation using real-world data, showing substantial improvements in performance metrics.']","['The paper is densely packed with technical jargon, making it difficult to follow in some sections.', 'The exact hyperparameters and implementation details are not clearly specified.', 'The robustness and stability of the results need more thorough validation, especially given the volatile nature of financial markets.', 'Potential limitations and ethical considerations around algorithmic trading are not addressed.', 'The explanation of the Corr layer and its theoretical underpinnings could be clearer.']",4,2,2,4,Reject
YfFWrndRGQx,The paper proposes a framework for Multi-Objective Online Convex Optimization (MO-OCO) and introduces the Online Mirror Multiple Descent (OMMD) algorithm with two variants. It aims to address limitations in multi-objective bandits by providing a novel dynamic regret definition. Theoretical analyses and extensive experiments support the claims.,"['Can the authors provide a clearer distinction between the proposed framework and existing methods in the literature?', 'Could the authors simplify the presentation of the theoretical analysis to make it more accessible?', 'How does the proposed method compare with more recent baselines in multi-objective optimization and online learning?', 'What are the potential limitations and negative societal impacts of the proposed methods?', 'Can the authors provide more details on the choice of hyperparameters for the experiments?', 'How does the method scale when the number of objectives increases significantly?', 'Can the authors provide additional ablation studies to better understand the impact of the L1-regularizer and other components?', 'What are the potential real-world applications where this framework could be effectively deployed?']","['The paper lacks a thorough discussion of its limitations and potential negative societal impacts. Authors should provide a balanced view, addressing these aspects explicitly.', 'The clarity of the theoretical exposition needs improvement. Some sections are difficult to follow.', 'The empirical validation could be more comprehensive, especially regarding hyperparameter tuning and comparisons with more state-of-the-art methods.']",False,3,2,3,5,4,"['Addresses a relevant problem in multi-objective optimization and online learning.', 'Proposes a novel algorithm (OMMD) and provides two variants for handling different scenarios.', 'Includes theoretical analysis and bounds for the proposed algorithms.', 'Extensive experiments are conducted to validate the effectiveness of the proposed methods.']","['The originality of the proposed framework and algorithm is not entirely clear, as it builds heavily on existing methods without sufficiently distinguishing its contributions.', 'The paper is dense and complex, making it challenging to follow, especially in the theoretical sections.', 'The experiments lack critical comparison with more recent and relevant baselines in the field.', 'The practical implications and scalability of the proposed methods are not discussed in detail.', 'The paper does not adequately address the potential limitations and negative societal impacts of the proposed methods.']",3,3,2,3,Reject
Oh1r2wApbPv,"The paper presents an 'Imagine-and-Verbalize' (I&V) method for Generative Commonsense Reasoning (GCSR). The method involves a scene imagination module to construct a Scene Knowledge Graph (SKG) from input concepts and context, which is then used by a verbalization module to generate coherent and plausible scene descriptions. The approach is validated through extensive experiments and comparisons with state-of-the-art methods, demonstrating its effectiveness.","['Can the authors provide more detailed ablation studies to further validate the effectiveness of each component of the proposed method?', 'How can the complexity of the model be addressed to improve its practical applicability?', 'Can the authors clarify the implementation details, particularly regarding the training process and the integration of SKGs?', 'Can the authors provide more details on the process of constructing and linearizing the SKGs?', 'How does the imagination module handle cases where the input concepts are highly abstract or not directly related to each other?', 'What are the specific implementation details for training and fine-tuning the models (e.g., hyperparameters, training duration)?', 'How does the method perform in domains where external SKGs are sparse or unavailable?', 'Can additional ablation studies be conducted to further analyze the contributions of different components of the proposed method?']","['The complexity of the model may hinder its practical applicability. More detailed ablation studies are needed to further validate the effectiveness of each component.', 'The lack of detailed ablation studies on certain components and sparse implementation details are the major limitations of this paper.', 'The paper should elaborate more on the limitations of the proposed approach. For instance, how does the system handle highly abstract or loosely related input concepts?', 'The potential negative societal impacts of the work are not discussed in detail.', 'The reliance on external SKGs is a potential limitation, especially in domains where such resources are not comprehensive or available.', 'The clarity of certain explanations could be improved, particularly regarding the auto-regressive sequence generation for SKGs and the detailed functioning of the verbalization module.']",False,3,3,3,6,4,"['Addresses a significant challenge in GCSR with a novel method.', 'Introduces the use of SKGs to unify and leverage knowledge from different resources.', 'Experimental results show superior performance compared to existing methods.', 'Well-organized and clearly written paper.', 'The use of diverse SKGs from multiple modalities (text and vision) provides a rich set of commonsense knowledge for the imagination module.', 'The method shows robustness in low-resource settings, indicating its potential applicability in scenarios with limited training data.']","['The complexity of the model may affect its practical applicability.', 'More detailed ablation studies could further validate the effectiveness of each component.', 'Moderate agreement in human evaluation (κ = 0.21) raises some concerns about evaluation reliability.', 'The implementation details are somewhat sparse, making it difficult to fully understand the training process and reproduce the results.', 'Some sections of the paper are dense and could benefit from additional explanations and clarity.', 'The reliance on external SKGs could limit the generalizability of the method to domains where such resources are not available or are less comprehensive.', 'The human evaluation is limited to a small set of instances, which may not fully capture the general quality of the generated SKGs and sentences.']",4,3,3,4,Reject
youe3QQepVB,"The paper introduces a Multi-task Generative Modeling (MGM) framework that combines generative models with multi-task learning to improve visual perception tasks. The MGM framework uses synthesized images with weak annotations to facilitate multiple tasks, including semantic segmentation, depth estimation, and surface normal prediction. The approach is evaluated on NYUv2 and Taskonomy datasets, showing significant improvements over state-of-the-art multi-task methods.","['Can you provide more details on the self-supervision network and refinement network?', 'Can you conduct additional ablation studies to isolate the contributions of each component of the MGM framework?', 'Can you provide more visualizations and examples of the generated images and their impact on the tasks?', 'What is the impact of different choices for the self-supervision task on the overall performance?', 'How does the joint training mechanism work in practice, and what are its computational costs?', 'How do the authors address potential overfitting given the high complexity and number of parameters in the model?', 'Can the authors clarify the exact training procedure, especially how the generative model is jointly trained with the discriminative network?', 'Can you provide more details on the training process and computational overhead?', 'Could you include more qualitative examples of generated images and their impact?', 'How do you justify the selection of the refinement network and certain hyperparameters?']","['The paper does not fully explore the potential limitations of using synthesized images with weak annotations. It would be valuable to discuss possible negative impacts or failure cases.', 'The reliance on image-level scene labels may limit the applicability of the approach to other types of annotations.', 'Potential overfitting due to model complexity.', 'Lack of clarity in some sections, especially the training procedure and ablation studies.', 'The practical feasibility of the oracle annotator in the pilot study should be discussed.']",False,3,3,3,6,4,"['The paper addresses an important problem in multi-task learning by integrating generative models.', 'The proposed MGM framework is novel and provides a new perspective on using generative models for multi-task learning.', 'The experimental results are strong, showing significant improvements over state-of-the-art methods.', 'The framework is shown to be particularly effective in low-data regimes, which is a valuable contribution.']","['The paper could benefit from additional ablation studies to better understand the contributions of each component of the MGM framework.', 'The description of the self-supervision network and refinement network could be more detailed.', 'Some sections of the paper, particularly the training procedure and ablation studies, are not clearly explained and could benefit from additional detail.', 'Potential computational overhead introduced by the generative network is not analyzed.', 'The complexity of the model and the high number of parameters may lead to overfitting, especially in low-data regimes.']",4,3,3,4,Reject
8Py-W8lSUgy,"The paper proposes MetaLink, a novel framework for relational multi-task learning that constructs a knowledge graph connecting data points and tasks. This framework allows leveraging labels from auxiliary tasks to improve predictions on new tasks. The approach is evaluated on six benchmark datasets in biochemical and vision domains, showing significant improvements over state-of-the-art methods.","['Can you provide more details on how unseen tasks are initialized and how robust this process is?', 'What is the impact of using different GNN architectures in MetaLink?', 'How does MetaLink scale with more complex datasets and larger numbers of tasks?', 'Can the authors provide more detailed explanations and clear definitions of terms in the methodology section?', 'Can the authors conduct more ablation studies to isolate the contributions of different components of MetaLink?', 'What are the limitations and potential challenges of applying MetaLink in real-world scenarios?', 'Can the authors provide more examples and visualizations of the knowledge graph and its usage in different settings?']","['The paper acknowledges the issue of task correlation and dataset diversity. More discussion on practical limitations and ethical considerations would be beneficial.', 'The method may be less effective when tasks are not correlated.', 'The paper is limited to multi-label learning scenarios due to the availability of datasets.', 'The potential fairness issues related to task definitions should be considered during future deployment.', 'The clarity of the paper needs improvement, especially in the methodology section.', 'More ablation studies are needed to isolate the contributions of different components of MetaLink.', 'The paper does not discuss the limitations and potential challenges of applying MetaLink in real-world scenarios.']",False,3,2,3,5,4,"['The use of a knowledge graph to connect data points and tasks for multi-task learning is an innovative approach.', 'The empirical results show substantial improvements in both biochemical and vision domains.', 'The framework is flexible, handling various multi-task learning settings including relational meta-learning.', 'Addresses the practical problem of task heterogeneity in multi-task learning.', 'Comprehensive experiments demonstrating significant improvements over state-of-the-art methods.']","['The initialization process for unseen tasks is not clearly explained, raising concerns about its robustness.', 'The impact of different GNN architectures and specific implementation details are not thoroughly explored.', 'The scalability of the approach to more complex datasets and tasks is not well-validated.', 'The paper could benefit from more ablation studies to understand the contribution of different components in the proposed architecture.', 'The clarity of certain sections is lacking, especially regarding the initialization of task nodes in meta settings.', 'The methodology section lacks clarity in some parts, particularly in how the knowledge graph is constructed and how the GNN processes the graph for predictions.', 'More qualitative analysis and additional cases are required to support the claims.']",3,3,2,4,Reject
fVu3o-YUGQK,"The paper 'Efficient Self-Supervised Vision Transformers for Representation Learning' (EsViT) introduces a novel approach to self-supervised learning (SSL) using Vision Transformers (ViTs). The authors propose a multi-stage architecture and a region-matching pre-training task to improve efficiency and representation quality. They demonstrate significant performance improvements on ImageNet and various downstream tasks, showing EsViT outperforms existing methods in efficiency and accuracy.","['Can the authors provide more details on the implementation of the region matching task and how it integrates with the multi-stage architecture?', 'How does the computational overhead of EsViT compare with other state-of-the-art methods on a broader range of architectures?', 'Can the authors provide additional ablation studies to further validate the contributions of each component in EsViT?', 'How does the proposed method perform on tasks other than image classification? Can the authors provide results on other vision tasks such as object detection and segmentation?', 'Can the proposed method generalize to other Transformer architectures or convolutional networks? If so, please provide some preliminary results or insights.']","['The complexity of the proposed methods may limit their accessibility and reproducibility for the wider research community. Simplifying explanations and providing more implementation details could help address this issue.', 'The paper does not provide enough evidence outside the ImageNet benchmark to fully convince the impact of the proposed method.', 'The clarity of the explanations needs improvement, particularly in the description of the region-matching task.', ""The region-matching task's computational overhead and potential limitations are not fully explored."", 'Limited discussion on the negative societal impacts of the proposed method.']",False,3,3,3,7,4,"['The proposed multi-stage architecture and region-matching task are novel and well-motivated.', 'The paper tackles an important problem in self-supervised learning, aiming to improve the efficiency and performance of vision transformers.', 'Comprehensive experiments and comparisons with state-of-the-art methods are provided.', 'The introduction of a region matching pre-training task is innovative and effectively captures fine-grained region dependencies.', 'Extensive experimental results demonstrate the effectiveness of EsViT, achieving state-of-the-art performance on ImageNet and various downstream tasks.', 'The paper provides a thorough comparison with existing methods, showing clear improvements in both efficiency and accuracy.']","['The paper is dense and complex, making it challenging to follow the detailed methodology and experimental setup.', 'Some explanations, particularly around the region matching task and its implementation, lack clarity and could benefit from further elaboration.', 'The evaluation of computational overhead could be more detailed, including comparisons with a broader range of architectures.', 'The novelty of the contributions is limited as it mainly combines existing ideas rather than introducing fundamentally new concepts.', 'The clarity of the paper could be improved. The explanations are dense and hard to follow in some sections.', 'The experimental evaluation, while promising, is not exhaustive. More ablation studies and comparisons with recent works are needed to solidify the claims.']",4,3,3,4,Accept
N0uJGWDw21d,"The paper presents a novel self-supervised distillation method, BINGO, which uses bags of related instances to transfer knowledge from a large pretrained teacher model to a smaller student model. This approach aims to improve the performance of small-scale models in self-supervised settings by leveraging the relationships between similar samples. The method demonstrates significant improvements in performance for small-scale models, achieving state-of-the-art results on multiple benchmarks.","['Can the authors provide more details on the choice of hyperparameters and their impact on the results?', 'How does the performance of the method vary with different bagging strategies?', 'Could the authors elaborate on the computational overhead introduced by the bag-aggregation strategy compared to existing methods?', 'Can the authors provide more details on the autoencoder aggregator and its implementation?', 'What is the performance impact of using different modulation functions and types of aggregators?', 'How do the authors justify the increased computational complexity introduced by the method?']","['The paper does not discuss potential limitations of the proposed method, such as scalability or applicability to other domains.', 'There is no discussion on the potential negative societal impacts of the method.', 'The method introduces additional computational complexity which may not be justified for all use cases.', 'More discussion on potential negative societal impacts is needed.']",False,3,3,3,6,4,"['The method addresses an important issue in self-supervised learning for small-scale models.', 'The proposed bag-aggregation strategy is novel and shows significant performance improvements.', 'Comprehensive experimental results demonstrate the effectiveness of the method across various tasks and datasets.', 'The method has potential applications in resource-constrained environments, making it highly relevant for practical deployment.']","['The paper lacks detailed explanations for some of the algorithmic choices, such as the specific benefits of different bagging strategies.', 'The ablation studies are limited and do not fully explore the impact of various components of the method.', 'More clarity is needed in the methodology section, particularly regarding the implementation details and hyperparameter settings.', 'The computational complexity of the proposed method is higher than some existing methods, which might limit its practical applicability in some scenarios.', 'There is no discussion on the potential negative societal impacts of the method.']",3,3,3,4,Reject
q79uMSC6ZBT,"The paper presents GRAMMFORMER, a Transformer-based model guided by programming language grammar to generate code completions with placeholders for uncertain parts. This approach aims to improve code completion by explicitly marking uncertain areas, allowing for user intervention. The model is trained using reinforcement learning, with a reward function combining REGEXACC and ROUGE metrics. Experimental results on Python and C# datasets show that GRAMMFORMER outperforms traditional sequence models in generating longer and more accurate code sketches.","['Can the authors provide more details on the autoencoder aggregator used in the model?', ""What is the impact of different modulation functions and aggregators on the model's performance?"", 'Can the authors provide additional qualitative examples and visualizations of the generated sketches?', 'Can the authors provide more details on the pretraining strategy for GRAMMFORMER?']","['The clarity of the paper can be improved by providing more detailed explanations of certain components and additional ablation studies.', 'The high computational cost and the lack of a detailed ablation study are the main limitations of the paper.', ""The qualitative analysis mainly consists of cherry-picked examples, which may not provide a comprehensive evaluation of the model's performance."", 'The model requires substantial computational resources for training and inference.', 'Focus on Python and C# limits the generalizability of the work.']",False,3,3,3,4,4,"['The paper addresses the important issue of uncertainty in code completion, providing a practical solution for more accurate suggestions.', 'The use of grammar-based generation and reinforcement learning is novel and well-motivated.', 'Comprehensive experiments and comparisons with baseline models demonstrate the effectiveness of the proposed approach.', 'The introduction of the REGEXACC metric is a valuable contribution for evaluating the quality of code completions with holes.']","['The paper lacks detailed ablation studies on the impact of different components, such as the modulation function and the type of aggregators used.', 'Some parts of the methodology, like the autoencoder aggregator and the pretraining process, are not clearly explained.', 'The model and training process are quite complex, requiring significant computational resources.', 'Limited diversity in baseline models. Comparisons with more recent and sophisticated code completion models would be helpful.', 'Focuses on Python and C# only, making it unclear how well the model performs on other languages or domains.']",3,3,3,3,Reject
-9ffJ9NQmal,"The paper 'VICE: Variational Inference for Concept Embeddings' introduces a novel method for learning object concept embeddings using variational inference with a spike-and-slab prior. The method addresses limitations of the existing SPoSE model by providing a more appropriate model for sparsity and a principled approach for determining the number of dimensions in the embedding space. The paper demonstrates the effectiveness of VICE through comprehensive experiments, particularly on smaller datasets.","['Can the authors provide more details on the variational inference process and the spike-and-slab prior?', 'Can the authors include more detailed analyses of the specific cases where VICE outperforms SPoSE?', 'How can the interpretability of the dimensions be further validated through user studies or additional qualitative analyses?', 'What are the potential limitations and societal impacts of VICE?']","['The paper lacks a thorough discussion of potential limitations and societal impacts.', 'The interpretability claims are not fully substantiated with user studies or detailed qualitative analysis.', 'The paper could benefit from additional clarity in the description of the variational inference process and the spike-and-slab prior.', 'The experimental results, while thorough, could include more detailed analyses of the specific cases where VICE outperforms SPoSE.']",False,3,3,3,5,4,"['Addresses a significant problem in cognitive science and machine learning: learning interpretable object concept embeddings from human behavior.', 'The proposed method, VICE, introduces a novel use of variational inference with a spike-and-slab prior, which is a more appropriate model for sparsity compared to the Laplace prior used in SPoSE.', 'VICE provides a principled approach for determining the number of dimensions in the embedding space, reducing subjectivity and enhancing interpretability.', 'Extensive experiments demonstrate that VICE performs better than SPoSE on smaller datasets, which is crucial for practical applications in cognitive science.']","['The paper could benefit from additional clarity in explaining the variational inference process and the spike-and-slab prior.', 'The clarity of the paper, particularly in the methodological sections, needs improvement.', 'The paper lacks a thorough discussion of potential limitations and societal impacts.', 'The interpretability claims are not fully substantiated with user studies or detailed qualitative analysis.', 'The paper could include more ablation studies to understand the contribution of each component of VICE.']",3,3,3,4,Reject
UvNXZgJAOAP,"The paper proposes a 'sharp attention' mechanism for sequence-to-sequence learning tasks, aiming to enhance the alignment between input sequences and target outputs by using a sharpener module. The module consists of a localizer and an encoder to refine the representation of target-specific regions in the input image. The method is evaluated on synthetic handwritten digit recognition and real-world scene text recognition tasks.","['Can the authors provide a more detailed theoretical justification for the proposed sharp attention mechanism?', 'How does the proposed method compare against other advanced attention mechanisms in terms of computational complexity and real-world applicability?', 'Can the authors provide more visual examples and clearer explanations of how the sharpener module impacts the attention mechanism?', 'Can the authors provide more ablation studies for the different components of the sharpener module and context vector schemes?', 'How does the proposed method compare with other state-of-the-art attention mechanisms on more diverse and complex tasks?', 'Can the authors clarify the modeling and optimization sections for better understanding?', 'How does the proposed sharpener module differ from existing methods like spatial transformer networks (STNs)?', 'Would the proposed method generalize to other sequence-to-sequence tasks beyond scene text recognition?', 'Can you provide more details on the training and implementation to improve reproducibility?', 'Can you conduct more extensive ablation studies to validate the effectiveness of the sharpener module?', 'Can you provide more thorough comparisons with baseline models?', 'What are the potential limitations and negative societal impacts of your work?', 'What are the specific contributions of the localizer and encoder within the sharpener module?', 'How does the proposed sharp attention compare to recent advances in attention mechanisms, such as transformers and self-attention models?']","['The paper should address the potential computational overhead introduced by the sharpener module and how it impacts the scalability of the method.', 'The authors should provide more detailed implementation guidelines to improve the reproducibility of the results.', 'The paper does not discuss potential negative societal impacts and limitations of the proposed method. It would be beneficial to include a discussion on these aspects.', 'The paper should include more diverse datasets beyond scene text recognition to show the generalizability of the proposed approach.', 'Ablation studies are needed to demonstrate the effectiveness of each component of the sharpener module.']",False,3,3,3,4,4,"['Addresses an important issue in Seq2Seq learning, particularly the alignment challenge in visual tasks.', 'Introduces a novel sharpener module to refine attention focus.', 'Comprehensive experimental evaluation on both synthetic and real-world datasets.', 'Demonstrates improvements in performance and interpretability over baseline attention mechanisms.']","['Limited originality, as similar concepts have been explored in the context of attention mechanisms using STNs.', 'Lacks rigorous theoretical backing and comprehensive comparative analysis.', 'Some sections lack clarity, with critical details either insufficiently explained or hard to follow, affecting reproducibility.', 'Insufficient ablation studies and limited comparison with existing state-of-the-art methods.', 'Unexplored potential negative societal impacts and limitations of the proposed method.']",3,3,3,3,Reject
2yITmG7YIFT,"The paper presents HD-COS networks, which use cosine as the activation function and Hadamard-Diagonal transformations to improve computational efficiency in secure multi-party computation (MPC). The methods are theoretically motivated and aim to reduce communication and computational costs while maintaining performance. Experimental results on multiple datasets demonstrate the effectiveness of the proposed methods.","['Can the authors provide more details on the implementation of the cosine activation function in the MPC setup?', 'How does the performance of HD-COS networks compare with more recent state-of-the-art MPC methods?', 'Can the authors provide more detailed ablation studies to isolate the effects of the cosine activation and the Hadamard-Diagonal transformation separately?', 'What are the scalability limitations of HD-COS networks for larger datasets and deeper networks?', 'Can you provide more details on the autoencoder aggregator and its role in the overall architecture?']","['The authors have partially addressed the limitations related to scalability and applicability. More thorough discussion on potential negative societal impacts is needed.', 'The clarity of the autoencoder aggregator and some methodological details need improvement.', ""Further ablation studies on different components of the proposed architecture could strengthen the paper's contributions.""]",False,3,3,3,5,4,"['Addresses a relevant and practical problem in privacy-preserving machine learning.', 'The use of cosine as an activation function and Hadamard-Diagonal transformations is novel and theoretically motivated.', 'Empirical results on multiple datasets demonstrate the effectiveness of the proposed methods.']","['The paper lacks clarity in some sections, especially regarding implementation specifics and algorithmic steps.', 'Comparison with state-of-the-art MPC methods is limited.', 'More detailed ablation studies are needed to isolate the contributions of the cosine activation and Hadamard-Diagonal transformation.', 'Scalability limitations for larger datasets and deeper networks are not thoroughly discussed.', 'The reproducibility of the experiments is questionable due to limited details on hyperparameters and experimental setup.']",3,3,3,3,Reject
kUGYDTJUcuc,"The paper proposes a unified model that combines top-down and bottom-up attention mechanisms for visual recognition tasks using reinforcement learning. The model aims to address the limitations of traditional recurrent attention models (RAM) by providing a global view to guide the search for regions of interest. The model is evaluated on MNIST, CIFAR10, and SVHN datasets, showing some improvements over baseline methods.","['Can the authors provide more detailed descriptions of the model architecture and training process?', 'What are the specific hyperparameters and training settings used in the experiments?', 'Can the authors provide more ablation studies and comparisons with state-of-the-art methods?', 'How does the proposed method compare with more recent state-of-the-art methods in visual recognition tasks?', 'What are the potential limitations and negative societal impacts of your work?', 'Can the authors provide a more detailed explanation of how the combination of top-down and bottom-up attention mechanisms leads to improved performance?', 'Can the authors clarify the methodology, particularly the descriptions of the top-down and bottom-up models?', 'Can the authors provide more thorough comparisons and ablation studies to demonstrate the significance of their contributions?', 'Can the authors provide more justification for the added complexity in their model?', 'How does the model perform in terms of computational efficiency compared to baseline methods?', 'Can the authors provide more details about the entropy and context constraints and their specific contributions to the performance?', 'How does the model perform on more complex datasets beyond MNIST, CIFAR-10, and SVHN?', 'Can the authors provide a more detailed explanation of the Q-learning implementation in the top-down model?', 'How does the entropy constraint affect the performance, and what is the rationale behind its introduction?']","['The paper does not adequately address the limitations and potential negative impacts of the proposed model. More discussion on possible scenarios where the model might fail would be beneficial.', 'The paper does not discuss potential limitations such as computational overhead or the applicability of the model to different types of visual recognition tasks.', 'The potential societal impacts of the proposed method are not addressed.']",False,2,2,2,3,4,"['Addresses an important issue in visual attention models by integrating top-down and bottom-up mechanisms.', 'Utilizes reinforcement learning to guide the attention mechanism, which could potentially improve exploration and stability.', 'The idea of combining top-down and bottom-up attention mechanisms is interesting and has potential.']","['The originality is limited as similar concepts have been explored in previous works.', 'The technical soundness is questionable due to a lack of rigorous theoretical justification and detailed ablation studies.', 'Clarity is a major issue; the paper is hard to follow, and key components are not well-explained.', 'Experimental validation is incomplete. The paper lacks comprehensive comparisons with state-of-the-art methods and detailed hyperparameter settings.', 'The paper does not adequately address the limitations and potential negative impacts of the proposed model.']",2,2,2,2,Reject
F2r3wYar3Py,"The paper introduces a novel 'distortable canvas' model inspired by human cognitive processes for one-shot learning, aiming to achieve high classification accuracy with minimal data. The method uses a multiscale gradient descent technique to optimize transformations, and is evaluated on MNIST, EMNIST-letters, and Omniglot datasets, showing promising results in the tiny-data regime.","[""Can you provide more mathematical details and rigor in the explanation of the 'distortable canvas' model?"", 'How does the model perform on more complex, real-world datasets beyond the benchmarks tested?', 'Can you compare your approach with a broader range of state-of-the-art models, including various neural architectures?', 'Can the authors provide ablation studies to isolate the impact of different components such as the anchor grids and the blurring technique?', 'Were the same preprocessing and data augmentation techniques applied across all methods in the experimental comparison?']","[""The model's performance in larger datasets and its scalability are not thoroughly discussed."", ""The reliance on a nearest-neighbor classifier may limit the model's robustness to noisy or ambiguous data."", 'The potential limitations and negative societal impacts of the approach are not adequately addressed.']",False,2,2,3,4,4,"[""The concept of a 'distortable canvas' inspired by human cognitive abilities is novel and interesting."", 'The approach does not rely on pre-training, making it more applicable to scenarios with limited data.', 'The model shows promising results on standard benchmarks (MNIST, EMNIST-letters, Omniglot) in the tiny-data regime, outperforming several existing methods.']","[""The explanation of the 'distortable canvas' model lacks clarity and mathematical rigor, affecting reproducibility."", 'The empirical evaluation is limited, with insufficient comparisons to a diverse range of state-of-the-art models.', 'The scalability and generalizability of the method to more complex, real-world datasets are not addressed.', 'The paper lacks detailed ablation studies to isolate the contributions of different components of the model.', 'The clarity and organization of the paper need improvement, particularly in explaining the methodology and the multiscale optimization process.']",3,2,3,3,Reject
36SHWj0Gp1,"The paper proposes GenTAL, a generative denoising skip-gram Transformer model for unsupervised binary code similarity detection. The model aims to learn compact and robust representations of assembly code by leveraging a Transformer-based autoencoder architecture. The proposed method is evaluated on multiple datasets and compared against state-of-the-art methods, showing promising results.","['Can the authors provide more detailed ablation studies to isolate the impact of each component of the proposed model, such as the denoising autoencoder and the skip-gram inspired loss?', 'How does the model perform under different practical scenarios, such as varying levels of code obfuscation or optimization? Additional experimental results on these aspects would be helpful.', 'Can the authors clarify the model architecture and the loss functions with more detailed explanations and diagrams?']","['The paper does not adequately address the limitations of the proposed model, particularly in terms of its performance under different practical scenarios and the potential impact of the OOV problem on downstream similarity detection tasks.']",False,2,2,3,4,4,"['The paper addresses a critical problem in cybersecurity, focusing on binary code similarity detection, which has significant practical importance.', 'The proposed GenTAL model introduces a novel combination of Transformer-based architecture and skip-gram inspired loss design, which is innovative and has the potential to improve representation learning for assembly code.', 'Experimental results demonstrate that GenTAL outperforms several state-of-the-art methods across different evaluation scenarios, suggesting its robustness and effectiveness.']","['The paper lacks a comprehensive comparison with a broader range of existing methods, which limits the generalizability of the claimed improvements.', 'The experimental results focus on specific configurations, and it is unclear how the model performs under different practical scenarios, such as various levels of obfuscation or optimization.', 'The clarity of the paper could be improved, particularly in the explanation of the model architecture and the loss functions. Some sections are difficult to follow and may benefit from additional details and clearer diagrams.', 'The paper does not include detailed ablation studies to isolate the impact of each component of the proposed model, which would strengthen the validity of the results.']",3,2,2,3,Reject
n6Bc3YElODq,"The paper proposes a Model-Based Opponent Modeling (MBOM) approach that uses environment models to predict and adapt to various opponent types in multi-agent reinforcement learning tasks. The method involves recursive imagination to simulate opponent learning and Bayesian mixing to combine different imagined opponent policies. The approach is evaluated in competitive and cooperative environments, showing improved adaptation compared to existing methods.","[""Can the authors provide more detailed explanations and definitions of terms like 'recursive imagination' and 'Bayesian mixing'?"", 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide more diverse experiments across different environments and opponents?', 'Can the authors provide detailed hyperparameter settings and experimental configurations to ensure reproducibility?', 'What are the performance implications of different choices for the parameters in the Bayesian mixing process?', 'How does MBOM perform in scenarios with more complex or higher-dimensional state and action spaces?', 'Can the authors provide more details on the implementation of the environment model and the fine-tuning process for opponent models?', 'How does MBOM perform in environments with a larger number of opponents?', 'Can the authors include additional baselines and scenarios in the experiments to further validate the robustness of MBOM?', 'Could you provide more detailed explanations and visualizations of the recursive imagination and Bayesian mixing processes?', 'How does the method handle inaccuracies in the learned environment model?', 'What is the computational overhead of the proposed method?']","['The paper lacks discussion on the potential limitations and negative societal impacts of the proposed method.', 'The methodology section is not sufficiently clear, and the experiments are not diverse enough to fully support the claims.', 'The scalability of MBOM in environments with a large number of opponents is a potential limitation that needs further investigation.', 'The clarity of some methodological details could be improved to enhance reproducibility.', 'The potential negative societal impacts of deploying such adaptive multi-agent systems in real-world scenarios should be discussed.']",False,2,2,3,4,4,"['The paper addresses a significant challenge in multi-agent reinforcement learning: adapting to diverse and potentially learning opponents.', 'The proposed recursive imagination and Bayesian mixing methods are innovative and provide a new perspective on opponent modeling.', 'Empirical results show that MBOM outperforms several strong baselines, especially against learning and reasoning opponents.']","['The methodology section lacks clarity and detail, making it difficult to understand the exact workings of the proposed model.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed method.', 'Experiments are limited to two competitive tasks and one cooperative task, lacking diversity in environments and opponents.', 'Insufficient details on hyperparameters and experimental settings make it challenging to reproduce the results.', 'The paper would benefit from additional ablation studies to better understand the contributions of different components of MBOM.', 'The experimental results, while promising, lack sufficient qualitative analysis to explain the performance improvements.', 'The scalability of the approach is not thoroughly discussed, particularly in environments with a large number of opponents.', 'Potential computational overhead of the proposed method is not addressed.']",3,2,2,3,Reject
Ti2i204vZON,"The paper 'LEARNING REPRESENTATIONS FOR PIXEL-BASED CONTROL: WHAT MATTERS AND WHY?' explores the components crucial for learning representations in pixel-based reinforcement learning (RL) and introduces a simple baseline. It compares this baseline against more complex methods like contrastive learning, data augmentations, and pixel reconstruction, especially in environments with distractors. The paper provides comprehensive experiments across multiple benchmarks, including DMC Suite and Atari100K, and offers insights into the efficacy of different methods under various conditions.","['Can the authors provide more detailed architectural comparisons to highlight the differences between methods?', 'What are the specific reasons behind the failure of certain methods in environments with distractors?', 'Can you provide additional ablation studies to test the robustness of the baseline in more diverse environments?', 'How does the baseline perform in environments with different types of distractors or varying levels of complexity?', 'How exactly are the background distractors incorporated into the DMC tasks?', 'Can the authors provide more theoretical insights into why the proposed baseline outperforms more complex methods under certain conditions?', 'What specific steps can be taken to improve existing methods based on the findings of this paper?', 'What are the specific settings where the baseline significantly outperforms state-of-the-art methods?', 'Can the authors provide more quantitative metrics or visualizations to support the claims about the failure modes of other methods?', 'Can the authors provide more detailed ablation studies on the proposed baseline to understand the contribution of each component better?', 'What are the potential drawbacks or limitations of the proposed baseline?', 'Can the authors expand the discussion on the implications of the findings and provide more concrete recommendations for future research?']","['The paper does not sufficiently address the limitations of the proposed baseline and the environments in which it may not perform well.', 'Potential negative societal impacts are not discussed, particularly in real-world applications where robustness is critical.', 'The paper lacks theoretical analysis and focuses on specific benchmarks, limiting the generalizability of the findings.', 'The paper adequately discusses the limitations of existing methods but could explore more on the limitations of the proposed baseline.', 'Potential societal impacts are not thoroughly addressed, particularly around the deployment of RL systems in real-world scenarios.']",False,3,3,3,6,4,"['The paper tackles the important issue of learning robust representations in pixel-based RL settings with distractors.', 'The proposed simple baseline demonstrates competitive performance compared to complex methods, highlighting the potential over-engineering in existing methods.', 'Comprehensive experiments across multiple benchmarks, including DMC Suite and Atari100K, provide a broad evaluation of the proposed approach.', 'The analysis is thorough, with comparisons across various settings and benchmarks.', 'The paper emphasizes the importance of data-centric evaluation, which is a valuable insight.', 'The findings challenge the current state-of-the-art methods and propose a simpler approach that performs comparably or better in many scenarios.']","['The paper lacks detailed architectural comparisons, making it difficult to understand the exact differences in performance across methods.', 'Limited insights into why certain methods fail or succeed, particularly in environments with distractors.', 'The proposed baseline, while simple, may not be sufficiently novel to warrant significant contributions.', ""The baseline's performance in some cases seems only marginally better than existing methods, raising questions about its broader applicability."", ""The paper's novelty is somewhat limited as it primarily refines existing ideas rather than introducing a fundamentally new approach."", 'Some claims, particularly around the failure modes of other methods, could benefit from more rigorous theoretical backing.']",3,3,3,4,Reject
lvM693mon8q,"The paper proposes Compressed Vertical Federated Learning (C-VFL), a method to improve communication efficiency in vertically partitioned data settings by compressing intermediate embeddings shared between parties. The paper provides theoretical convergence analysis and demonstrates empirically that communication can be reduced by over 90% with minimal impact on accuracy.","['Can you provide more clarity on the mathematical derivations and assumptions?', 'Can you include more ablation studies to understand the impact of different components and hyperparameters?', 'Can you discuss potential negative societal impacts or privacy concerns in more detail?', 'Can you provide more intuitive explanations or diagrams to help clarify the theoretical proofs?', 'Have you considered testing the algorithm under different network conditions, such as varying latencies or packet loss?', 'Can the authors provide more details on handling scenarios where labels are not shared among all parties?', 'How does the method perform on additional datasets or with more complex models?', 'Can the authors improve the clarity of the theoretical analysis and the experimental setup descriptions?', 'How does C-VFL compare with other federated learning methods beyond the baselines provided?', 'Can you provide more insights on the scenarios where the assumption of bounded gradients may not hold and how this impacts the practical application of C-VFL?']","['The paper could benefit from more diverse datasets and tasks to demonstrate broader applicability.', 'The clarity of the presentation needs improvement, especially in mathematical derivations and assumptions.', 'The paper assumes all parties have access to the labels. In federated learning scenarios where labels are not shared, implementing the method might be challenging.', 'The authors mention the use of bounded gradient assumptions, which may not always hold in practice. It would be beneficial to discuss how this limitation might affect the applicability of C-VFL in real-world scenarios.', 'The empirical results are based on relatively small-scale experiments. It would be beneficial to see how the proposed method scales with larger datasets and a higher number of parties.']",False,3,3,3,6,4,"['Addresses a significant issue in VFL by reducing communication overhead.', 'Provides a solid theoretical analysis with convergence guarantees.', 'Empirical validation on real-world datasets shows practical benefits.', 'The proposed C-VFL framework is novel and employs embedding compression, which is a unique approach compared to traditional gradient compression.']","['The clarity of some mathematical derivations and assumptions could be improved.', 'Limited ablation studies to understand the impact of different components and hyperparameters.', 'The choice of datasets and tasks, while relevant, could be more diverse to demonstrate broader applicability.', 'The paper does not discuss potential negative societal impacts or privacy concerns in sufficient detail.', 'The presentation could be more concise and better organized.', 'Assumes all parties have access to the labels, which may not be practical.', 'Theoretical proofs are complex and require careful verification.', 'The experiments lack details about certain hyperparameters and experimental setup, which are crucial for reproducibility.']",3,3,2,4,Reject
f4c4JtbHJ7B,"The paper proposes Pixab-CAM, a novel class activation mapping (CAM) method that utilizes pixel-wise weights instead of channel-wise weights to generate explanation maps. The method aims to address the limitations of existing CAM-based methods, such as overestimated pixels and dependency on the activation tensor. The paper also introduces new evaluation metrics using adversarial attacks to assess the quality of explanation maps.","['Can the authors provide a more detailed explanation of the methodology, particularly the implementation of pixel-wise weights and the ablation boxes?', 'How do the new evaluation metrics using adversarial attacks compare to traditional metrics in terms of reliability and generalizability?', 'What are the potential limitations and negative societal impacts of the proposed method, and how do the authors plan to address them?', 'Can the authors provide more details and clarity on the autoencoder aggregator used in the methodology?', 'How does the use of pixel-wise weights and exclusion of the activation tensor compare with existing methods in terms of novelty and effectiveness?', 'Can the authors provide more validation and justification for the proposed evaluation metrics using adversarial attacks?', 'Can the authors include more extensive ablation studies and qualitative evaluations to strengthen their claims?', 'Have the authors explored different ablation box sizes and combinations in more detail? If so, can they provide the results of these experiments?', 'How does Pixab-CAM compare with non-CAM-based methods for generating explanation maps? Can the authors provide such comparisons?', 'Can the authors provide detailed comparisons with other advanced CAM techniques to establish the superiority of the proposed method?', 'Can the authors explain the design choices and the reasoning behind the selection of ablation boxes in more detail?', 'Can the authors provide clearer explanations for key concepts and reduce the use of dense technical jargon in the paper?', 'Can the authors demonstrate the impact of the proposed method on real-world applications more comprehensively?', 'Can you provide more details on the computational cost of the proposed method compared to existing CAM-based methods?', 'How well does the proposed method generalize to real-world scenarios beyond adversarial patches?']","['The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed method, such as its performance on more complex datasets or in real-world scenarios.', ""The paper's clarity and the explanation of some technical details are lacking, making it difficult to fully understand the methodology."", 'The novelty and effectiveness of the proposed approach need more rigorous justification and comparison with existing methods.', 'The proposed evaluation metrics are interesting but not thoroughly validated, raising questions about their effectiveness.', 'The paper does not fully explore the design choices for the ablation boxes, and the ablation studies are insufficient.', 'There is a lack of comparison with non-CAM-based methods for generating explanation maps.', 'The design choices and the reasoning behind specific decisions are not clearly explained.', 'The paper contains dense technical jargon and lacks clear explanations for key concepts.', 'The impact of the proposed method on real-world applications is not fully demonstrated.', 'The proposed method may be computationally expensive, which can limit its practical usability.']",False,2,2,2,3,4,"['The proposed method tackles significant limitations in existing CAM-based methods by using pixel-wise weights, which could lead to more accurate and faithful explanation maps.', 'The idea of not relying on the activation tensor to generate explanations is intriguing and could potentially solve the problem of overemphasis on irrelevant regions.', 'The introduction of new evaluation metrics using adversarial attacks is innovative and provides a fresh perspective on assessing explanation maps.', 'Comprehensive experimental evaluation demonstrates the effectiveness of the proposed method in generating high-quality explanation maps.']","['The paper lacks a clear and detailed explanation of the proposed methodology, especially the implementation of pixel-wise weights and the ablation boxes.', 'The evaluation metrics, while innovative, are not sufficiently validated. It is unclear whether the adversarial attack-based metrics are reliable and generalizable across different datasets and models.', 'The paper does not adequately address potential limitations and negative societal impacts of the proposed method. For example, it is unclear how the method performs on more complex datasets or in real-world scenarios.', 'The qualitative results, while visually compelling, need more rigorous quantitative validation to support the claims of superiority over existing methods.', 'The paper lacks detailed comparisons with other advanced CAM techniques, which is necessary to establish the superiority of the proposed method.', 'Some methodological details, such as the design choices and the reasoning behind the selection of ablation boxes, are not clearly explained.', 'The paper contains dense technical jargon and lacks clear explanations for key concepts, making it difficult to follow in some sections.', 'The proposed method may be computationally expensive, which can limit its practical usability.']",3,2,2,3,Reject
rGg-Qcyplgq,"The paper proposes a novel approach to distributional reinforcement learning (DRL) using Perturbed Quantile Regression (PQR) to randomize the risk criterion during exploration. This method aims to address the limitations of Optimism in the Face of Uncertainty (OFU) approaches, which can lead to biased action selection. The authors provide theoretical guarantees for convergence and demonstrate empirical effectiveness on several benchmark tasks, including N-Chain, LunarLander-v2, and Atari games.","['Can the authors provide more details on the autoencoder aggregator and its role in the proposed method?', 'How sensitive is the proposed method to the choice of hyperparameters, particularly the concentration parameter in the Dirichlet distribution?', 'Can the authors compare their method with a broader range of baseline methods, including more recent DRL approaches?', 'Can the authors provide more detailed ablation studies to isolate the contributions of different components of the proposed method?', 'Can the authors improve the clarity of the theoretical sections by providing better definitions and explanations of key terms and concepts?', 'How does the proposed method perform in environments with different levels of stochasticity?', 'What are the potential limitations and societal impacts of the proposed method? Addressing these aspects would provide a more comprehensive view of the method’s implications.']","['The primary concern is the clarity of the paper and the need for more comprehensive empirical validation. The authors should provide more details on the autoencoder aggregator and the construction of the ambiguity set.', 'The added complexity due to the perturbation mechanism and ambiguity set construction might limit the practical applicability of the method.', 'The clarity of the theoretical contributions could be improved, making the paper more accessible to a broader audience.', 'The potential limitations and societal impacts of the proposed method are not adequately discussed. Authors should address these aspects to provide a more comprehensive view of the method’s implications.']",False,3,3,4,6,4,"['The paper addresses a significant limitation of existing DRL methods by proposing a novel exploration strategy that perturbs the risk criterion.', 'Theoretical support is provided for the convergence and optimality of the proposed method under weaker contraction properties.', 'Empirical results show that PQR outperforms baseline methods on several benchmark tasks, demonstrating the practical effectiveness of the approach.']","['The empirical validation, while promising, needs to be more comprehensive. More experiments and comparisons with a broader range of baseline methods would strengthen the paper.', 'Certain parts of the paper, particularly the autoencoder aggregator and the construction of the ambiguity set, lack clarity and need more detailed explanations.', ""The method's sensitivity to different hyperparameters, such as the concentration parameter in the Dirichlet distribution, is not thoroughly explored."", 'The paper is dense and some sections, particularly the theoretical ones, could benefit from clearer explanations and better definitions of terms and concepts.', 'The comparison with existing exploration strategies is limited, and a broader range of comparisons would strengthen the empirical evaluation.', 'The introduction of the ambiguity set and the perturbation mechanism adds complexity to the method, which might make it less accessible for practitioners.', 'The discussion on potential limitations and societal impacts of the proposed method is insufficient. Addressing these aspects would provide a more comprehensive view of the method’s implications.']",4,3,3,3,Reject
bE239PSGIGZ,"The paper proposes a novel method, the Speech Synthesising based Attack (SSA), for generating audio adversarial examples from scratch using a conditional variational autoencoder (CVAE). This method addresses the limitations of existing audio-dependent attack methods by not relying on any existing benign audio. The paper includes comprehensive experiments across multiple datasets to demonstrate the efficacy of the proposed method.","['Can the authors provide more details about the autoencoder aggregator and its implementation?', 'What is the impact of using different types of aggregators or modulation functions on the performance of the proposed method?', 'How can the naturalness of the synthesized audios be improved while maintaining their adversarial properties?', 'What are the potential countermeasures to mitigate the proposed audio adversarial attack?', 'Can the authors include additional ablation studies to analyze the contribution of different components (e.g., CVAE, adaptive sign gradient descent)?']","['The naturalness of the synthesized adversarial audios is a significant concern, and further research is needed to address this limitation.', 'The transferability of the adversarial examples to other ASR models is limited, which could reduce the practical impact of the proposed method.', 'The paper lacks clarity in explaining certain technical details, which could hinder the reproducibility of the work.']",False,3,3,3,6,4,"['Introduces a novel threat model in ASR by generating audio adversarial examples from scratch.', 'Utilizes a conditional variational autoencoder (CVAE) for speech synthesis, which is a novel approach in this context.', 'Comprehensive experiments conducted across multiple datasets, including Audio Mnist, Common Voice, and Librispeech, showing the effectiveness of the proposed method.', ""Detailed analysis of the proposed method's performance, including word error rate (WER) and success rate (SR) metrics."", 'Incorporates an adaptive sign gradient descent algorithm with an annealing-based learning rate decay to optimize the adversarial audio synthesis.']","['The clarity of the paper needs improvement, particularly in explaining the autoencoder aggregator and the modulation function.', 'The MOS evaluation results indicate that the generated adversarial audios might not sound as natural as expected, which could be a significant limitation.', 'Additional ablation studies are needed to thoroughly investigate the impact of different model components and settings.', 'The transferability of the adversarial examples to other ASR models is limited, which could reduce the practical impact of the proposed method.']",4,3,3,4,Reject
SHbhHHfePhP,"The paper 'Equivariant Graph Mechanics Networks with Constraints' introduces a novel approach to modeling physical systems with geometric constraints using a graph neural network-based framework. The core idea is to use generalized coordinates to implicitly encode geometric constraints into the model, ensuring that the constraints are naturally maintained throughout the learning process. The paper also proposes a new form of orthogonality-equivariant functions to facilitate equivariant message passing, which is shown to be universally expressive under certain conditions.","['Could the authors provide more detailed explanations of the autoencoder aggregator and the generalized coordinates?', 'Have different types of aggregators or modulation functions been considered? How do they affect the performance?', 'Can the authors provide more comprehensive qualitative visualizations to strengthen their claims?', 'Can you provide more intuitive explanations and examples for the forward kinematics and equivariant message passing sections?', 'Could the authors include more ablation studies to validate the robustness and effectiveness of the proposed components?', 'What are the potential limitations and negative societal impacts of the proposed method?']","['The paper could benefit from additional clarity in some sections and further ablation studies to validate the proposed methods.', 'There is a need for more comprehensive qualitative visualizations to support the claims made in the paper.', 'The paper should include a detailed discussion on the limitations of the method, such as its applicability to different types of systems and the computational complexity associated with the forward kinematics.', 'Potential negative societal impacts, such as misuse in surveillance or military applications, should be addressed.', 'The paper should better discuss the potential limitations of the proposed approach, such as its scalability to very large systems or its sensitivity to inaccuracies in the physical constraints.']",False,3,3,3,6,4,"['The paper addresses an important and practical problem in modeling physical systems with geometric constraints.', 'The proposed method of using generalized coordinates to implicitly encode constraints is novel and effective.', 'The new form of orthogonality-equivariant functions is theoretically backed and shown to be universally expressive.', 'Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed approach.']","['The clarity of some sections could be improved, particularly the detailed explanations of the autoencoder aggregator and the generalized coordinates.', 'The paper could benefit from additional ablation studies to further validate the proposed methods, such as comparing different types of aggregators or modulation functions.', ""The qualitative visualizations provided could be more comprehensive to strengthen the paper's claims."", 'The theoretical justifications, particularly for the universal approximation properties of the proposed equivariant functions, could be more rigorously presented and better connected to the empirical results.', 'The paper lacks a detailed discussion on the limitations and potential negative societal impacts of the work.']",3,3,3,4,Reject
xaTensJtCP5,The paper proposes Ab Initio objective functions for optimizing MCMC proposal distributions using neural architectures. The approach combines existing metrics like GSM and MSJD with fitted coefficients to create objective functions that balance desirable MCMC properties. The authors validate their approach through theoretical analysis and extensive experimental comparisons with existing methods.,"['Can the authors provide more details on the practical implementation and computational costs?', 'Have the authors considered evaluating the proposed method on a broader set of MCMC problems?', 'Can the authors provide more practical examples to demonstrate the applicability of the proposed method in real-world scenarios?', 'How does the performance of the Ab Initio objective functions compare with other state-of-the-art methods in terms of computational efficiency?', 'Can the authors provide more details on the potential limitations of the proposed method?', 'Can the authors provide more intuitive explanations and clearer descriptions of the experimental setup and results?', 'Are there detailed guidelines or code repositories available to assist in the implementation of the proposed methodology?', 'What are the performance implications of using different types of aggregators?', 'Can the authors provide additional ablation studies to further validate the proposed method?']","[""The paper's complexity and focus on synthetic experiments limit its immediate applicability and reproducibility. Providing more real-world examples and detailed implementation guidelines could address these issues."", 'The clarity of the paper and the need for additional ablation studies are major concerns.']",False,3,3,3,6,4,"['The introduction of Ab Initio objective functions is a novel idea for optimizing neural MCMC proposals.', 'The paper provides comprehensive theoretical analysis and experimental results to validate the proposed method.', 'The experiments cover various scenarios, demonstrating the robustness of the proposed objective functions.']","['The paper is dense and may be difficult to follow for readers not deeply familiar with MCMC methods.', 'Experimental validation is primarily limited to synthetic tasks; broader evaluation across different types of MCMC problems and real-world applications would strengthen the claims.', 'The clarity and organization of the paper could be improved.', 'More practical examples and detailed implementation guidelines are needed to assist researchers in applying the proposed methodology.']",3,3,3,3,Reject
TXqemS7XEH,"The paper proposes a novel 'Pseudo-to-Real' training strategy to efficiently train extremely large models, up to 10 trillion parameters, using limited GPU resources. This involves initially sharing parameters across layers and then delinking them for final convergence. The approach is demonstrated on the M6 model and claims significant improvements in training efficiency.","['Can the authors provide more detailed explanations of the Granular CPU offloading mechanism?', ""How does the 'Pseudo-to-Real' strategy generalize to other architectures and tasks?"", 'Can the authors provide more clarity on the transition process from Pseudo to Real stage?', 'Have you conducted any ablation studies to understand the contribution of each component of the proposed methods?', 'Can you compare the performance of your methods with more existing methods in the literature?', 'Can you provide more details on the hyperparameters and implementation to improve reproducibility?', 'What are the potential limitations and negative societal impacts of this work?', 'How can the reproducibility of this work be ensured, given the lack of detailed implementation specifics?']","['The paper does not adequately address the potential negative societal impacts of training extremely large models.', 'There are several technical details that need further clarification.', 'The clarity of the paper needs improvement, especially in explaining the technical details of the proposed methods.', 'More comprehensive ablation studies and diverse experimental results are necessary to solidify the findings.']",True,2,2,3,4,4,"['Addresses a critical problem in training extremely large models with limited resources.', ""The 'Pseudo-to-Real' strategy is innovative and leverages parameter sharing in an interesting way."", 'Comprehensive experimental results showing significant improvements in training efficiency.', 'Potentially high impact, especially in the context of greener AI.']","['The originality is somewhat limited as similar ideas have been explored in different contexts.', 'Several technical details are either glossed over or not sufficiently explained, particularly the Granular CPU offloading mechanism.', 'The paper is dense and difficult to follow in several sections, especially the transition from Pseudo to Real stage.', 'Practical applicability on different architectures and tasks is not thoroughly demonstrated.', 'Ethical concerns are mentioned but not explored in enough detail.', 'Lack of detailed ablation studies to thoroughly evaluate the contributions of different components of the proposed method.', 'Insufficient empirical evidence to convincingly demonstrate the efficacy of the proposed method.', 'Limited discussion on the potential limitations and negative societal impacts.', ""The methodology for determining the switching point from 'Pseudo' to 'Real' stage lacks rigorous justification."", 'Potential reproducibility issues due to lack of detailed implementation specifics.']",3,2,2,3,Reject
iaxWbVx-CG_,"The paper introduces Hierarchical Cross Contrastive Learning (HCCL), a novel approach to self-supervised learning (SSL) that leverages hierarchical projection heads for contrastive learning. The method aims to distill information from hidden layers in the projection head, which is often overlooked in conventional contrastive loss frameworks. HCCL compares latent features across different levels and views, improving the generalization ability of learned visual representations. The method is validated through experiments on classification, detection, segmentation, and few-shot learning tasks, showing significant improvements over existing methods.","['Can the authors provide more details on the hierarchical projection head and its impact on the performance of HCCL?', 'Can the authors elaborate on the cross contrastive loss and its formulation?', 'Can the authors provide more detailed explanations and visualizations for the hierarchical projection head and the cross contrastive loss?', 'How does HCCL perform compared to more recent SSL methods not included in the current comparisons?', 'Can the authors provide additional ablation studies to further validate the components of HCCL, such as the choice of predictor and projection head architectures?', 'What are the potential failure cases and limitations of HCCL, and how might these be addressed in future work?', 'What are the impacts of different levels in the hierarchical projection head on performance?', 'Can the authors provide more details on the hyperparameters and training setups to ensure reproducibility?', 'Can the authors provide a more detailed theoretical justification for the hierarchical projection heads and cross-level contrastive losses?', 'Can the authors clarify the architecture of the hierarchical projection head and provide more intuition behind its design?', 'How does HCCL specifically differ from and improve upon existing contrastive learning methods?', 'What is the practical significance and broader impact of the improvements shown by HCCL?']","[""The paper could benefit from a more detailed analysis of the hierarchical projection head's impact on the performance of HCCL."", 'The complexity of the method may pose challenges for reproducibility and practical implementation without additional clarifications.', 'The paper lacks detailed ablation studies to isolate the contributions of each component.', 'The clarity and completeness of the methodology need improvement for better understanding and reproducibility.', 'The paper does not discuss potential limitations or edge cases where the proposed method might not perform well.', 'The computational overhead introduced by the hierarchical projection heads and multiple contrastive losses is not thoroughly analyzed.']",False,3,2,3,5,4,"['The paper addresses a significant limitation in existing SSL methods by leveraging hidden layers in the projection head.', 'The proposed Hierarchical Cross Contrastive Learning (HCCL) method is novel and well-motivated.', 'Comprehensive experiments are conducted, demonstrating the effectiveness of the method across various tasks and datasets.', 'Detailed ablation studies validate the contributions of different components of the proposed method.']","[""Some parts of the methodology, such as the hierarchical projection head's impact, could be clarified further."", 'The explanation of the cross contrastive loss could be more detailed to improve understanding.', 'The complexity of the method may make it difficult to reproduce and understand without additional clarifications.', 'Certain sections of the paper, particularly the implementation details and ablation studies, lack clarity and could benefit from more thorough explanations.', 'Although HCCL is compared to several baseline methods, additional comparisons with more recent methods would strengthen the paper.', 'The evaluation of the method on diverse datasets is thorough, but further analysis of failure cases and limitations would be beneficial.', 'The mathematical formulations and implementation details are somewhat opaque, which could hinder reproducibility.', 'There is no discussion of potential ethical concerns or biases in the data.', 'The paper lacks a detailed theoretical justification for the choice of hierarchical projection heads and cross-level contrastive losses.', 'The practical significance and broader impact of the improvements shown by HCCL are not thoroughly discussed.']",3,3,2,3,Reject
EMLJ_mTz_z,"The paper proposes a novel method to predict the performance of Convolutional Neural Networks (CNNs) by representing them as time-evolving graphs. It introduces a new, compact 'rolled' graph representation for convolutional layers and demonstrates that simple graph statistics can accurately predict the performance of various NN architectures after observing only a few epochs of training.","[""Can you provide more theoretical justification for why the 'rolled' graph representation retains sufficient information for performance prediction?"", 'Are there any specific scenarios or architectures where the proposed method does not perform well?', 'How do the results change if the number of epochs observed is varied?', ""Can the authors provide more details on the 'rolled' graph representation and how it differs from the 'unrolled' representation?"", 'What are the specific advantages of the proposed graph representation over existing methods?', 'Can the authors provide a more detailed explanation of the experimental setup and the selection of hyperparameters?', 'Are there any plans to make the code and datasets publicly available before acceptance to ensure reproducibility?', 'Can the authors provide more details on the graph representation, particularly how the edge weights in convolutional layers are computed and normalized?', 'How does the framework handle potential noise or anomalies in the early training epochs?', 'Could the authors discuss the potential limitations and scalability of the proposed framework in more detail?', 'What are the potential negative societal impacts of this work, if any, and how might they be mitigated?', 'Could you provide more details on the computational overhead introduced by the graph generation and feature extraction steps?', 'How sensitive is the proposed method to the choice of node features and the specific graph summary statistics used?', 'Can you provide more visualizations of the experimental results to illustrate the differences in performance between the rolled and unrolled graph representations?', 'Can you perform additional ablation studies to better understand the impact of different features and design choices?']","['The paper does not address potential limitations or failure cases of the proposed method. It would be beneficial to discuss scenarios where the method might not work as expected.', 'Potential negative societal impacts are not discussed. Using performance prediction to guide NN training could lead to biased models if not managed carefully.', 'The paper does not sufficiently address potential limitations in the proposed framework, such as handling noisy or incomplete training data and the scalability to very large networks.', 'There is no discussion on the broader ethical implications and potential misuse of this technology, which is important for responsible AI research.']",False,3,2,3,5,4,"['The idea of using a graph-based representation to predict NN performance is novel and impactful, potentially offering a way to reduce computational costs during training.', ""The proposed 'rolled' graph representation is more compact and computationally efficient compared to the existing 'unrolled' representation."", 'The paper provides extensive empirical analysis across multiple datasets (CIFAR-10, ImageNet) and architectures (LeNet, AlexNet, VGG, ResNet), showing consistent performance in predicting NN accuracy.']","[""The paper lacks a detailed explanation of how the 'rolled' representation retains all relevant information compared to the 'unrolled' one, which might raise concerns about whether significant details are lost."", 'The work focuses heavily on the empirical results but provides less theoretical grounding or discussion on why the proposed method works so effectively.', 'The experimental setup lacks details, and the selection of hyperparameters seems arbitrary without proper justification.', 'The results are not reproducible without access to the code and datasets used.', 'The paper lacks comprehensive experiments and comparisons with state-of-the-art methods.', 'Ethical considerations and potential negative societal impacts of the work are not discussed.']",3,3,2,3,Reject
kO-wQWwqnO,"The paper presents L2BGAN, an unpaired GAN-based framework for enhancing low-light images. The model employs cycle consistency, geometric and illumination consistency, and contextual loss to translate low-light images to bright images. The framework is tested on various benchmark datasets and demonstrates competitive results, particularly in improving image understanding tasks like face detection.","['Can the authors provide more details on the autoencoder aggregator used in the framework?', 'What is the performance of the proposed model with different types of aggregators?', 'Can the authors include more visual examples in the qualitative analysis?', 'What are the limitations and potential negative societal impacts of the proposed method?', 'Could the authors provide more detailed ablation studies on the choice of loss functions and the impact of individual discriminators?', 'Can the authors clarify the architectural details of the proposed model and the specific training procedures used?', 'How does your method compare with more recent state-of-the-art methods?', 'Can the authors provide more comprehensive evaluation metrics and a more detailed comparison with existing methods?']","['The paper lacks a thorough discussion on the limitations and potential negative societal impacts of the proposed method.', 'The clarity of certain sections is lacking, which affects the overall understanding of the methodology.']",False,2,2,2,3,4,"['Addresses the important problem of enhancing low-light images without requiring paired supervision.', 'Employs novel use of geometric and illumination consistency along with contextual loss.', 'Shows competitive results on multiple benchmark datasets.', 'Improves performance of image understanding tasks, such as face detection, on enhanced images.']","['Unclear description of the autoencoder aggregator, making it difficult to understand its implementation.', 'Lacks thorough ablation studies on the modulation function and different types of aggregators.', 'Limited qualitative analysis with only a few visual examples provided.', 'No discussion on the limitations and potential negative societal impacts of the proposed method.', 'Incomplete comparison with other state-of-the-art methods, especially in terms of raw performance metrics.', 'Lacks clarity in several methodological details.', 'Limited novelty as it primarily builds on existing GAN-based methods without substantial innovation.']",2,2,2,3,Reject
fJIrkNKGBNI,"The paper proposes a piece-wise polynomial filtering approach for Graph Neural Networks (GNNs) to improve node classification performance, especially on heterophilic graphs. The method involves learning multiple adaptive polynomial filters acting on different subsets of the graph's spectrum. The authors provide theoretical analysis and extensive experimental results to support the effectiveness of their approach.","['Can the authors provide more details on the computational complexity and practical implementation of the proposed method?', 'What are the limitations of the proposed method in terms of scalability and computational overhead?', 'Can the authors include additional ablation studies to clarify the contribution of each component of the proposed method?', 'Can the authors provide more intuitive explanations for spectrum partitioning and the choice of polynomial order?', 'How does the proposed method compare to the latest state-of-the-art methods not included in the paper?', 'Can the authors provide more detailed implementation and hyperparameter settings within the paper?', 'Can additional ablation studies and sensitivity analyses be conducted to further validate the empirical findings?']","['The main limitation of the proposed method is its computational complexity, particularly the cost of eigen decomposition for large graphs. The authors should discuss these limitations in more detail and provide potential solutions or workarounds.', 'The paper does not thoroughly address the potential computational overhead introduced by the eigenvalue decomposition and the scalability to very large graphs.', 'The paper could better address the potential negative societal impacts of improved graph filtering techniques, such as privacy concerns in social network analysis.']",False,3,3,3,5,4,"['Addresses a significant problem in GNNs, particularly their performance on heterophilic graphs.', 'The proposed piece-wise polynomial filtering method is novel and well-motivated.', ""Theoretical analysis provides a strong foundation for the proposed method's effectiveness."", 'Extensive empirical evaluation demonstrates significant performance improvements over state-of-the-art models on various datasets.']","['The description of the computational complexity and practical implementation details is somewhat lacking, making it difficult to assess the feasibility of the proposed method for very large graphs.', 'The paper could benefit from a deeper discussion on the limitations of the proposed method, particularly in the context of scalability and computational overhead.', 'While the experimental results are comprehensive, additional ablation studies could further clarify the contribution of each component of the proposed method.', 'Some sections of the paper, particularly the theoretical analysis, could benefit from clearer and more detailed explanations.', 'Comparative analysis is insufficient, lacking comparisons with some of the latest state-of-the-art methods.', 'Details for reproducibility are insufficient within the paper. Key implementation details and hyperparameter settings should be explicitly stated.']",3,3,3,4,Reject

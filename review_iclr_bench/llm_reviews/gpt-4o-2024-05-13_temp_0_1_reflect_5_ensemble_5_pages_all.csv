paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
tDirSp3pczB,The paper presents new theoretical bounds for contrastive unsupervised representation learning (CURL) and validates these bounds experimentally. The authors argue that larger negative samples improve downstream classification performance and provide tighter bounds compared to existing work.,"['Can the authors provide more diverse experimental validation across different tasks and datasets?', 'How do the proposed bounds perform in real-world scenarios beyond the datasets considered?', 'Can the authors provide more intuitive explanations or visualizations to help readers understand the theoretical results?', 'How do the assumptions made in the theoretical derivations affect the applicability of the results?', 'Can the authors clarify the practical implications of their findings?', 'What are the computational cost implications of using larger negative samples in practice?', 'How do the new bounds compare quantitatively with existing bounds in a broader range of scenarios?', 'Could the authors provide more details on how their theoretical bounds are novel compared to existing works?', 'Can the authors elaborate on the empirical setup to ensure reproducibility, especially for the synthetic datasets?', 'How do the authors address the potential variability in empirical results due to different random seeds?']","['Empirical validation may not fully support theoretical claims.', 'The paper is dense, making it hard to follow without a strong background.', 'Theoretical results are based on assumptions that may not hold in all scenarios.', 'Experiments on real-world datasets do not convincingly demonstrate improvements.', 'Theoretical analysis assumes normalized embeddings, which might not always be practical.', 'Empirical validations are limited to selected datasets and might not generalize across different domains.']",False,3,2,3,5,4,"['Provides new theoretical bounds for CURL.', 'Addresses an important empirical observation about the impact of negative sample size.', 'Includes detailed mathematical proofs and some experimental validation.']","['Experimental validation is limited and not comprehensive.', 'The paper is dense and complex, making it difficult to follow.', 'The novelty of the contribution is somewhat incremental, building on existing work.', 'Practical impact of the findings remains unclear.', 'Insufficient discussion of limitations and assumptions.']",3,3,2,3,Reject
YDud6vPh2V,"The paper introduces ξ-learning, a novel reinforcement learning algorithm that extends the Successor Feature (SF) framework to handle general reward functions. The authors provide theoretical convergence guarantees and demonstrate the algorithm's effectiveness through experiments in environments with linear and general reward functions. The key contributions include the definition of ξ-learning, theoretical proofs of its convergence, and experimental comparisons with standard Q-learning and classical SF framework.","['Can the authors provide more intuitive explanations or visualizations to help readers understand the complex notation and mathematical exposition?', 'Have the authors considered evaluating ξ-learning in a wider range of environments and tasks to better assess its generalizability?', 'Can the authors discuss potential limitations and negative societal impacts of ξ-learning in more detail?', 'Could the authors clarify how the computational complexity of ξ-learning could be mitigated in practical applications?', 'Are there specific types of environments where ξ-learning might not perform as well?']","['The paper does not adequately address potential limitations and negative societal impacts.', 'Limited diversity in experimental evaluation raises concerns about generalizability.', 'The increased computational complexity of the proposed method could limit its practicality.', 'The complexity of the paper might hinder understanding for some readers.', 'More diverse experimental environments could further validate the generality of the approach.', 'Potential high variance in model-free ξ-learning updates.', 'Practical challenges of implementing ξ-learning in real-world applications.']",False,3,2,3,6,4,"['Novel extension of the SF framework to handle general reward functions.', 'Theoretical proofs of convergence and performance guarantees.', 'Experimental results demonstrating improved performance over classical SF and Q-learning.']","['Complex notation and dense mathematical exposition hinder clarity.', 'Limited diversity in experimental environments raises concerns about generalizability.', 'Increased computational complexity could limit practical applications.', 'Insufficient discussion on potential limitations and negative societal impacts.']",3,3,2,3,Reject
xZ6H7wydGl,"The paper proposes an importance-sampling estimator for learning Stochastic Differential Equations (SDEs) that avoids the sequential dependence of traditional SDE integrators. This method results in lower-variance gradient estimates and is highly parallelizable, making it suitable for large-scale computations. The efficacy of the approach is demonstrated through experiments on benchmark tasks, showing significant performance improvements over existing methods.","['Can the authors provide additional details on the computational resources required for the experiments?', 'How sensitive is the method to the choice of importance distribution q?', 'Can the authors clarify the steps involved in handling state-dependent diffusion?', 'Can the authors provide more theoretical guarantees and discuss the limitations of their approach?', 'Can the authors analyze the impact of the choice of the importance distribution on the performance of the method?', 'Can the authors provide more evidence on the practical applicability of the method to real-world problems?', 'Can the authors provide more details on the initialization and hyperparameter tuning for the experiments?', 'How does the proposed method perform on other types of SDE models, particularly those with state-dependent diffusion?', 'Can the authors clarify the computational complexity of their algorithm compared to traditional SDE integrators in more detail?', 'What are the limitations of the proposed method in terms of model flexibility and potential overfitting?', 'Can the authors provide more details on the potential limitations and negative societal impacts of the proposed method?', 'How does the method perform on a wider range of SDE models and real-world datasets?', 'Can the authors elaborate more on the memory consumption and suggest possible optimizations?', 'Can you provide more detailed explanations or derivations for some of the theoretical results, particularly Theorem 1?', 'How well does the proposed method generalize to other types of SDEs or different application domains?', 'Have you considered the potential limitations and negative societal impacts of your work in more detail?']","['The method assumes that the diffusion matrix can be written as a Jacobian, which might not cover all real-world scenarios.', 'The approach still requires significant computational resources, which might limit its applicability in some settings.', 'The complexity of the method might make it difficult for practitioners to adopt.', ""The method's performance is highly dependent on the choice of the importance distribution."", 'Uncertainty quantification may be overconfident.', 'Theoretical guarantees and limitations are not thoroughly discussed.', 'Practical applicability to real-world problems is not fully demonstrated.', 'The method requires careful consideration of state-dependent diffusion processes and transformations to a space with constant diffusion. How do these transformations impact the overall model interpretability and potential biases?', 'The authors briefly mention increased memory consumption but do not provide a detailed analysis or possible optimizations.', 'Potential negative societal impacts are not addressed in the paper.']",False,3,3,3,5,4,"['The proposed method reduces gradient variance significantly.', 'Highly parallelizable, making it suitable for modern parallel hardware.', 'Can handle high-dimensional problems effectively.', ""Theoretical foundation based on importance sampling and Girsanov's theorem.""]","['The method is complex and may be difficult to implement correctly.', 'The paper could be clearer in its mathematical derivations and experimental setup.', 'Requires significant computational resources despite being parallelizable.', 'Handling state-dependent diffusion requires additional transformations, adding to the complexity.', 'Theoretical guarantees and limitations are not thoroughly discussed.', 'Overconfidence in uncertainty quantification is noted but not deeply analyzed.', ""Method's performance is highly dependent on the choice of the importance distribution."", 'Practical applicability to real-world problems is not fully demonstrated.', 'Reproducibility of the results is not entirely clear from the text.', 'The scope of experiments is limited and could benefit from more diverse datasets.', 'Comparison with state-of-the-art methods could be more comprehensive.', 'Memory consumption of the proposed method is significantly higher compared to some traditional methods.', 'The paper lacks a detailed discussion on potential negative societal impacts.']",4,3,3,3,Reject
CNY9h3uyfiO,"The paper explores the impact of linear reward shifting on value-based Deep Reinforcement Learning (DRL). It shows that reward shifting is equivalent to varying the initialization of the Q-function. Positive reward shifting leads to conservative exploitation, improving offline RL, while negative reward shifting promotes curiosity-driven exploration, enhancing online RL. The authors validate their insights through experiments in both continuous and discrete control tasks.","['How does the method perform in on-policy reinforcement learning settings?', 'Can you provide more detailed comparisons with current state-of-the-art methods, especially in offline RL scenarios?', 'How sensitive is the method to different hyperparameters?', 'Can the authors provide more detailed theoretical analysis to support their claims?', 'How do the proposed methods compare to state-of-the-art RL algorithms in more diverse and challenging environments?', 'Can the clarity of the mathematical derivations and experimental results be improved?', 'Can the authors provide more detailed explanations or visualizations to clarify the theoretical equivalence between reward shifting and Q-function initialization?', 'How sensitive is the method to different reward shifting constants? Could there be a guideline for selecting appropriate constants?', 'Are there any specific limitations or scenarios where reward shifting might not be effective?', 'How does the computational complexity of the proposed method compare to other state-of-the-art exploration methods?']","['Need for domain knowledge in setting appropriate reward shifts.', 'No explicit discussion on potential negative societal impacts.', 'The method relies heavily on reward shifting constants, which may not be straightforward to determine for different tasks.', 'The approach might not scale well to environments with highly complex and dynamic reward structures.']",False,3,2,3,5,4,"['Novel insight that reward shifting is equivalent to different Q-value initializations.', 'Comprehensive theoretical analysis and empirical validation.', 'Applicable to a wide range of RL tasks, both offline and online.', 'Clear writing and good organization.', 'Addresses critical issues in exploration-exploitation trade-offs and offline RL stability.']","['Limited evaluation scope; more baselines and state-of-the-art comparisons needed.', 'Focuses on off-policy methods; generalizability to on-policy methods is unclear.', 'The need for future work to explore automatic adjustment of reward shifts.', 'The paper is lengthy and dense, making it difficult to follow in some parts.', 'Insufficient discussion on the limitations and potential negative societal impacts.']",3,3,2,3,Reject
fXHl76nO2AZ,"The paper introduces Gradient Importance Learning (GIL), a novel method for handling incomplete data without imputation. GIL uses reinforcement learning to adjust gradients during back-propagation, leveraging missingness patterns to improve prediction accuracy. The method is tested on various datasets, showing improved performance over traditional imputation methods.","['Can you provide more detailed ablation studies to isolate the effect of each component?', 'How does the method scale with larger datasets and different domains?', 'What are the computational overheads introduced by the reinforcement learning component?', 'How does the method perform on datasets with different types and extents of missingness (MCAR, MAR, MNAR)?', 'Can the authors clarify how the proposed method compares in terms of interpretability and transparency to traditional imputation methods?', 'Can the authors provide more details on the implementation and the choice of hyperparameters used in the experiments?', 'What are the specific limitations of the proposed method compared to traditional imputation methods?', 'How does the method perform with different levels of missing data?', 'Can the authors provide more details on the implementation of the RL component in GIL?', 'How does the training time of GIL compare to traditional imputation methods?', 'Are there any specific scenarios where GIL might not perform well?', 'Can the authors provide more details on the specific RL algorithms used and their parameter settings?', 'How does GIL compare to other state-of-the-art methods not mentioned in the paper?', 'Can the authors provide more ablation studies to isolate the contributions of different components of GIL?']","['The complexity of the method may make it difficult to implement and understand for practitioners.', 'More detailed ablation studies are needed to fully understand the contribution of each component of the proposed method.', 'The paper does not thoroughly discuss potential negative societal impacts, particularly in sensitive domains like healthcare.']",False,3,3,3,6,4,"['Addresses a significant problem of missing data in machine learning.', 'Proposes a novel method combining reinforcement learning with gradient adjustment.', 'Experimental results show improvement over traditional imputation methods.', 'Detailed methodology and code repository provided for reproducibility.', 'Comprehensive evaluation on multiple datasets.']","['The complexity of the method might hinder its practical implementation and reproducibility.', 'The paper is densely written and could benefit from clearer explanations and structured presentation.', 'Need for more detailed ablation studies to isolate the contribution of each component.', 'Limited discussion on broader impact and potential negative societal implications.', 'Results on some datasets were not significantly better than state-of-the-art methods.']",3,3,3,3,Reject
bglU8l_Pq8Q,"The paper explores the performance gap between dual-encoder (DE) and cross-attention (CA) models in neural ranking tasks. It provides theoretical evidence that DE models can approximate a broad class of scoring functions, identifies overfitting as a key issue for DE models, and proposes a distillation strategy to mitigate this issue. Empirical results demonstrate the effectiveness of the proposed method on benchmark datasets.","['How do the assumptions in the theoretical results align with practical scenarios?', 'Can the authors provide more insights into the potential limitations and negative societal impacts of their work?', 'What are the computational overheads associated with the proposed distillation strategy?', 'Can the authors provide a comparison with more recent and advanced methods in neural ranking?', 'How does the proposed distillation strategy perform on other tasks beyond neural ranking?', 'Can the authors provide more detailed ablation studies to isolate the effects of different components in the proposed distillation strategy?', 'Are there any additional baselines or state-of-the-art methods that the authors can compare against to strengthen the empirical evaluation?', 'Can the authors provide more intuitive explanations or examples to make the theoretical contributions more accessible to a broader audience?', 'Can the authors provide more insights into the computational complexity of the proposed distillation strategy?']","['The theoretical results rely on assumptions that may not always hold in real-world applications.', 'The proposed distillation strategy, while effective, adds complexity and computational overhead to the training process.', 'Potential negative societal impacts, such as biases in retrieval, are not thoroughly explored.', 'The empirical evaluation is limited to a few datasets, which may not generalize to other tasks.']",False,3,3,3,6,4,"['Theoretical contributions establishing the capacity of DE models.', 'Empirical analysis identifying overfitting as a key issue for DE models.', 'A novel and effective distillation strategy to improve DE model performance.', 'Extensive experimental validation across multiple datasets.']","['Theoretical results are based on assumptions that may not hold in practical scenarios.', 'Empirical analysis may not account for all variables affecting performance.', 'The proposed distillation method adds complexity to the training process.', 'The paper could benefit from a deeper exploration of limitations and potential negative societal impacts.']",3,3,3,3,Reject
cU8rknuhxc,"The paper introduces DISDAIN, an intrinsic reward mechanism that leverages discriminator disagreement to improve unsupervised skill learning by addressing pessimistic exploration. The method is validated through experiments in both simple (Four Rooms) and complex (Atari) environments, showing promising results.","['Can the authors provide a more detailed theoretical analysis of the proposed DISDAIN method?', 'How does DISDAIN compare with more recent exploration methods not included in the experiments?', 'What are the computational costs in more detail, and how might these affect the broader applicability of the approach?', 'Can the authors discuss potential negative societal impacts or limitations of their work?', 'How does DISDAIN scale with extremely large and complex environments beyond Atari?', 'Can the authors provide more details on the computational overhead introduced by training an ensemble of discriminators?', 'How can the reproducibility of the experimental results be ensured? Are there any specific resources or scripts provided?', 'How do the results translate to practical applications and what are the potential use cases for learning a large number of skills?', 'Could the authors clarify the theoretical underpinnings of the DISDAIN reward, particularly for readers not deeply familiar with Bayesian approaches?', 'How robust are the results across different environments and hyperparameters?', 'How do the learned skills translate to practical performance improvements in downstream tasks?', 'Can the computational requirements be mitigated or optimized in some way?']","['The paper does not discuss potential negative societal impacts or limitations.', 'High computational cost is not adequately addressed.', 'The practical implications and potential applications of learning a large number of skills are not fully explored.', 'The robustness of the results across different environments and hyperparameters needs further validation.', 'The practical utility of the learned skills in real-world scenarios is not thoroughly analyzed.']",False,3,3,3,6,4,"['Novel approach to addressing pessimistic exploration in skill learning.', 'Empirical results demonstrate improvements in both simple and complex environments.', 'Clear and well-organized writing.', 'Comprehensive empirical validation on both simple and complex environments.', 'Clear distinction between epistemic and aleatoric uncertainty.', 'Thorough experimental design with comparisons to multiple baselines.', 'Incorporates modern techniques from Bayesian deep learning and reinforcement learning.']","['Lacks a robust theoretical foundation.', 'Experiments lack some critical baselines and ablations.', 'High computational cost limits applicability.', 'Does not adequately address potential negative societal impacts or limitations.', 'Scalability concerns with larger and more complex environments.', 'Potential computational overhead due to ensemble training.', 'Limited discussion on the reproducibility of results and experimental setup details.', 'The novelty is somewhat incremental, building on existing ensemble-based uncertainty estimation techniques.', 'Theoretical aspects could be clearer, particularly for readers not deeply versed in Bayesian methods.', 'Significance of results could be more compelling with practical applications and implications.', 'Additional baselines and more detailed ablation studies could strengthen the empirical findings.', 'The robustness of the results across different environments and hyperparameters needs further validation.', 'Empirical evaluation primarily focuses on the number of skills learned, with limited analysis of the practical utility of these skills.', 'Clarity issues in the description of some technical details, particularly the implementation of the ensemble method.']",3,3,3,4,Reject
HFPTzdwN39,The paper introduces 'reverse linear probing' to measure the interpretability of unsupervised and self-supervised visual representations by estimating mutual information between the representations and manually labeled concepts. The method is evaluated on various self-supervised learning models and provides insights into their interpretability.,"['Can the authors provide more details on how the mutual information is computed and normalized?', 'How does the choice of the number of clusters (K) affect the results? Is there an optimal value for K?', 'Are there any specific reasons for choosing the datasets and models used in the experiments?', 'Can the authors provide more details on the practical applicability of the proposed method in real-world scenarios?', 'How does the method perform with different types of datasets beyond ImageNet?', 'Can the authors discuss any potential negative societal impacts of their work?', 'How does the proposed method compare to other interpretability measures in terms of computational efficiency?', 'Can the method be applied to representations learned from non-visual data, such as text or audio?', 'How does the choice of clustering algorithm affect the interpretability measure?', 'Can the authors provide more detailed theoretical justification for using mutual information in this context?', 'How robust is the method to different choices of the number of clusters (K)?', 'Can the authors discuss potential limitations of their method in more detail?', 'How can the method be made more reproducible for other researchers?', 'How does the proposed method compare to other existing interpretability techniques in the literature?', 'Can the authors provide additional validation results on datasets other than ImageNet?', 'What are the potential limitations and negative societal impacts of the proposed method?']","['The method relies heavily on the manual labeling of concepts, which may not be scalable.', 'The choice of K-means for clustering might introduce biases in the evaluation.', 'Potential negative societal impacts include reliance on biased datasets and interpretability measures that may not generalize well.', ""The method's applicability to diverse datasets and real-world scenarios is not thoroughly explored."", 'Potential negative societal impacts, such as biased concept representations, are not discussed.', 'The method might be biased towards clustering-based models, which could affect the generalizability of the results.', 'The paper does not address the potential impact of noisy labels from the supervised classifiers used to enrich the concept space.', 'The societal impact is not addressed, even though interpretability has important ethical implications.', 'The method is primarily validated on ImageNet, and it is unclear how well it generalizes to other datasets.', 'The discussion on potential negative societal impacts of the method is lacking. For example, the method may inadvertently reinforce biases present in the data.']",False,3,3,3,5,4,"['Novel method for measuring interpretability of unsupervised representations.', 'Addresses an important problem in self-supervised learning.', 'Provides a quantifiable measure for interpretability.', 'Extensive experimental evaluation on multiple self-supervised learning models.', 'Clear and well-organized writing.']","['The methodology is not clearly explained in some parts, making it difficult to fully understand the approach.', 'The robustness of the experiments is questionable due to the lack of details on certain experimental settings.', 'The significance of the contributions is moderate and needs more justification in the context of practical applications.', 'Potential bias in evaluation due to the use of clustering-based methods for both training and evaluation.', 'Limited discussion on the practical applicability and generalizability of the method.', 'Insufficient exploration of potential negative societal impacts.', 'Some claims lack thorough justification and empirical validation.', 'Mathematical formulations could be more detailed and easier to follow.']",3,3,3,3,Reject
EJKLVMB_9T,"The paper presents SplitRegex, a framework for faster regex synthesis using a divide-and-conquer approach. The framework employs a neural network, NeuralSplitter, to split positive examples into substrings and then synthesizes subregexes for each substring before combining them into a final regex. The approach is evaluated on several benchmark datasets and shows improved synthesis speed and accuracy compared to existing methods.","['Can the authors provide more details on the training procedure for the NeuralSplitter?', 'How does the NeuralSplitter handle edge cases or noisy data?', 'Is there any theoretical analysis to support the divide-and-conquer approach in the context of regex synthesis?', 'Can the authors provide more detailed explanations of the experimental setup, including hyperparameters and dataset splits?', 'How does the performance of SplitRegex compare to other state-of-the-art regex synthesis methods not included in the baseline?', 'Can the proposed approach handle regex features such as backreferences and lookaheads/lookbehinds?', 'How does the NeuralSplitter model perform on regexes with significantly longer lengths or more complex structures?', 'What measures can be taken to mitigate potential negative societal impacts of this technology?', 'Why were only certain baselines chosen for comparison?', 'How does the framework handle negative examples in more complex scenarios?', 'Can the approach be scaled to handle extremely large datasets or very complex regex patterns?', 'What are the computational requirements for training and using the NeuralSplitter model?']","['The paper does not discuss potential limitations of the NeuralSplitter, such as handling noisy or ambiguous data.', 'The approach may not generalize well to more complex regex synthesis tasks.', 'There is no discussion on the potential negative societal impacts or ethical considerations of the proposed method.', 'The inability to generate the wildcard pattern as a subregex.', 'Exclusion of certain regex features such as backreferences and lookahead/lookbehind.', 'Potential negative societal impacts, such as misuse in malicious applications, are not discussed.', ""The dependency on the NeuralSplitter model's accuracy might limit the method's effectiveness."", 'The method may not scale well for very large datasets or highly complex regex patterns.']",False,3,3,3,5,4,"['The proposed divide-and-conquer approach for regex synthesis is innovative and shows potential.', 'The use of a neural network (NeuralSplitter) to split examples is a novel idea.', 'The experimental results demonstrate improvements in synthesis speed and accuracy on benchmark datasets.']","['The originality is somewhat limited as the divide-and-conquer paradigm is not new in the context of program synthesis.', 'The paper lacks rigorous theoretical analysis to support the claims made.', 'The clarity of the paper is compromised due to complex explanations and insufficient details in the methodology.', 'The experimental setup and results are not thoroughly explained, making it hard to reproduce the results.', 'The paper does not adequately address potential negative societal impacts or ethical considerations.', ""Dependency on NeuralSplitter model's accuracy."", 'Experiments focus on synthetic and benchmark datasets, potentially not representing real-world complexities.', 'Potential scalability issues for large datasets or complex regex patterns.']",3,3,3,3,Reject
MWQCPYSJRN,"The paper introduces Generative Negative Replay (GNR) for continual learning, using generated data as negative examples to mitigate catastrophic forgetting. The approach is validated on complex benchmarks like CORe50 and ImageNet-1000, showing improved performance over traditional generative replay methods.","['Could the authors provide more insights on the hyperparameter tuning process?', 'How does GNR compare with other advanced continual learning methods not mentioned?', 'Can the authors elaborate on the potential negative impacts of using GNR in real-world applications?', 'Can the authors provide more details on the implementation of the generative model?', 'How does GNR perform in scenarios where the learning-in-isolation problem is not significant?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide more details on the technical implementation of the selective gradient blocking?', 'What are the limitations of the proposed approach?', 'How does the performance of GNR scale with the complexity of the generative model?', 'Can the authors provide more details on how the stability of the generative models was ensured during training?', 'How does GNR perform compared to other state-of-the-art methods on additional benchmarks or datasets?', 'Could the authors elaborate on the potential limitations or edge cases where GNR might not perform as expected?', 'Is there any theoretical justification or analysis supporting the effectiveness of using generative negative replay over positive replay?', 'How sensitive is the performance of GNR to the quality of the generated data?']","['The paper does not adequately address potential negative societal impacts.', 'There is limited discussion on the scalability of GNR to other types of data beyond images.', 'The effectiveness of the approach in scenarios with a very high number of classes needs further exploration.', ""The impact of the quality of generated data on GNR's performance should be discussed in more detail."", 'The approach may still suffer from the data generation quality issues inherent to the generative models used.', 'The method might not generalize well to other types of continual learning tasks beyond the class-incremental and data-incremental scenarios tested.']",False,3,3,3,7,4,"['Novel approach of using generated data as negative examples.', 'Extensive experimental validation on complex benchmarks.', 'Addresses a significant problem in the field of continual learning.']","['Clarity issues in the explanation of the method and experiments.', 'Insufficient details on the hyperparameters tuning and selection process.', 'Limited comparisons with state-of-the-art methods beyond the chosen baselines.', 'Potential reproducibility issues due to incomplete code and data availability details.', 'Limited theoretical analysis to explain why GNR works better than traditional generative replay.']",3,3,3,4,Reject
8CEJlHbKoP4,"The paper proposes METAGEN, an unsupervised model that enhances object detection models with metacognition. METAGEN learns a meta-representation of the object detection system's performance and uses it to correct errors like hallucinations and misses. The model leverages Spelke principles to make inference tractable and is evaluated on synthetic data, showing improved accuracy over baseline models.","['How does METAGEN perform on real-world datasets compared to synthetic data?', 'What are the computational requirements and efficiency of the METAGEN model?', 'Have you considered the potential negative societal impacts of using METAGEN, especially in critical applications?', 'Can the authors provide more details on the specific hyperparameters used for METAGEN?', 'Can the authors clarify the process of joint inference over the world state and the metacognitive representation?', 'Can the authors provide more intuitive explanations or visual aids for the generative model and inference process?', 'What are the potential limitations of relying on Spelke principles, and how might these be mitigated?', 'Can the authors provide more detailed comparisons with state-of-the-art uncertainty-aware AI models?']","['The model has only been tested on synthetic data, which may not fully capture the complexities of real-world scenarios.', 'Potential overfitting to the synthetic dataset due to the lack of real-world validation.', 'The computational complexity and resource requirements are not discussed, which can be a significant limitation for practical applications.', ""The reliance on Spelke principles may limit the model's applicability in more complex or less structured environments."", 'Potential negative societal impacts such as bias in object detection need further exploration.']",False,3,3,3,6,4,"['Novel approach leveraging metacognition inspired by human cognitive processes.', 'Utilizes Spelke principles for tractable inference.', 'Demonstrates improved detection accuracy on synthetic data using state-of-the-art object detection models.', 'Unsupervised learning method does not require ground-truth labels.']","['The model is evaluated only on synthetic data, raising concerns about generalizability to real-world scenarios.', 'The complexity of the model and inference process may limit its practical applicability.', 'No discussion on computational efficiency or resource requirements.', 'Limited exploration of potential negative societal impacts or ethical considerations.', 'Clarity issues in the exposition of the model and inference procedure.', 'Reproducibility concerns due to sparse details about the implementation and hyperparameters.']",4,3,3,3,Reject
WVX0NNVBBkV,"This paper investigates the use of synthetic data generated by advanced generative models to improve the adversarial robustness of deep neural networks. It provides a theoretical framework using conditional Wasserstein distance to understand robustness transfer from proxy distributions to real data. The paper introduces a new metric, ARC, to evaluate the effectiveness of generative models for robustness transfer and demonstrates significant improvements in robust accuracy across multiple datasets.","['How does the proposed method perform on larger, more diverse datasets beyond those tested?', 'What is the computational cost of the approach in real-world scenarios, and how does it compare to traditional methods?', 'How does the approach handle class imbalances in the synthetic data?', 'Can you provide more intuition behind the ARC metric and its practical implications?', 'How sensitive is the performance to the choice of hyperparameters in the proposed method?', 'Can the authors provide more detailed guidelines or code snippets to enhance reproducibility?', 'Can you provide more details on the generalizability of your approach to other types of data (e.g., text or speech)?', 'How does the quality of synthetic data (e.g., presence of artifacts) impact the robustness transfer?']","['The authors could discuss more about the scalability and computational cost of the approach.', 'The societal impacts, both positive and negative, should be discussed in more detail.', 'The paper could better address the potential negative societal impacts of improving adversarial robustness, such as misuse in privacy-invasive applications.', 'The clarity of some sections, particularly the theoretical proofs and the experimental setup, needs improvement to ensure reproducibility.']",False,4,3,3,7,4,"['The idea of using proxy distributions for adversarial robustness is novel.', 'Theoretical framework to understand robustness transfer is valuable.', 'The paper is technically sound with rigorous theoretical analysis and extensive experimentation.', 'Significant improvements in robust accuracy across multiple datasets.', 'Introduction of a new metric (ARC) to evaluate the effectiveness of generative models for robustness transfer.']","['The clarity of some theoretical explanations could be improved.', 'The paper is lengthy and densely packed with information, affecting readability.', 'The computational cost of generating synthetic data and training robust discriminators is high.', 'Limited discussion on potential negative societal impacts.', 'Some methodological details, especially around experimental setup and parameter selection, are not clearly explained.']",4,4,3,4,Accept
74x5BXs4bWD,"The paper proposes EDO-CS, an Evolutionary Diversity Optimization algorithm with Clustering-based Selection for reinforcement learning tasks. The method aims to find a set of policies that balance high rewards and diverse behaviors. The authors validate their approach through experiments on various continuous control tasks, showing superior performance over existing methods.","['Can the authors provide a theoretical analysis of the convergence properties of EDO-CS?', 'Are there any specific scenarios where EDO-CS might fail to perform as expected?', 'Can the authors discuss potential negative societal impacts of their work in more detail?', 'Can the authors provide more details on the computational complexity of the proposed method?', 'How sensitive is the method to the choice of hyperparameters, and how were they selected?', 'Can the authors provide additional visual aids to explain key concepts, particularly in the dense sections?']","['The paper could benefit from a clearer discussion of potential negative societal impacts.', 'The theoretical properties of the proposed method, such as convergence guarantees, are not discussed.', 'The computational overhead of clustering in each iteration.', 'Scalability to larger policy spaces and more complex tasks needs further investigation.', 'Parameter sensitivity and the impact of different clustering algorithms require more detailed analysis.', 'The potential limitations of using K-means clustering in high-dimensional behavior spaces are not discussed.']",False,3,3,3,6,4,"['Addresses the well-motivated problem of balancing quality and diversity in RL.', 'Novel clustering-based selection mechanism.', 'Extensive experimental validation against multiple baseline methods.', 'Adaptive mechanism for balancing quality and diversity using multi-armed bandit.', 'Thorough literature review and context provided.']","['The paper is dense and may be difficult to follow for readers not familiar with QD algorithms and ES.', 'Lack of theoretical analysis of the proposed method’s convergence properties.', 'Limited exploration of potential negative societal impacts.', 'Some experimental results are only in the appendix, limiting readability.', 'Insufficient detail on computational complexity and scalability.', 'Limited discussion on the sensitivity to hyperparameters and their selection.']",3,3,3,3,Accept
4tOrvK-fFOR,The paper introduces a novel method for sound source detection using raw waveforms with multi-scale synperiodic filter banks that achieve multi-scale perception in both time and frequency domains. A Transformer-like backbone is used with two branches for learning semantic identity and spatial location representations. Experiments show that the proposed method outperforms existing methods on direction of arrival estimation and physical location estimation tasks.,"['Can the authors provide more details on the computational efficiency and scalability of the proposed method?', 'How does the method perform on real-world noisy datasets?', 'Can the authors clarify the initialization and training process of the synperiodic filter banks in more detail?', 'What are the computational requirements and potential limitations of the proposed method in practical applications?', 'How does the proposed synperiodic filter bank specifically differ from existing filter banks?', 'How do the authors plan to address potential ethical concerns related to sound source detection and privacy?', 'Can the authors provide more detailed implementation specifics, including hyperparameters and exact configurations used?']","['The computational cost of the proposed method is higher than some existing methods, which may limit its practical applicability.', 'The method has not been tested on a wide range of real-world noisy datasets, which raises concerns about its robustness.', 'The paper does not address potential negative societal impacts related to sound source detection and privacy.', 'The higher computational complexity might limit its applicability in real-time scenarios.']",False,3,3,3,5,4,"['The proposed synperiodic filter bank design is innovative and addresses the time-frequency resolution trade-off effectively.', 'The method achieves multi-scale perception in both time and frequency domains, which is a significant improvement over single-scale methods.', 'The experimental results indicate that the proposed method outperforms existing methods by a large margin.', 'The paper includes a comprehensive theoretical analysis of the filter bank design.', 'Thorough evaluation on multiple tasks and datasets, showing significant improvements.', 'Detailed ablation studies and qualitative comparisons.']","[""The paper's clarity is hampered by dense and complex explanations, making it difficult to follow in some sections."", 'The originality of the multi-scale perception approach can be questioned, as similar concepts have been explored in wavelet transforms.', 'The experimental evaluation lacks diversity in datasets and real-world scenarios to truly validate the robustness of the method.', 'The computational efficiency of the proposed method is a concern, as it requires significantly more time than some existing methods.', 'Limited discussion on the potential limitations and negative societal impacts.', 'Potential reproducibility issues due to lack of detailed implementation specifics.']",3,3,3,3,Reject
xFOyMwWPkz,"The paper introduces a novel method for assessing the status of individual units in CNNs using a topological-based entropy measure called feature entropy. The method aims to quantify the degree of chaos in the spatial pattern represented by a CNN unit and uses this metric to indicate the effectiveness of the unit. The authors validate their method through various experiments, showing that feature entropy correlates with network performance and can discriminate between networks with different generalization abilities.","['Can the authors provide more theoretical justification for why feature entropy is the best measure for unit performance?', 'Can the authors clarify the experimental setups, particularly how the training and evaluation data are split and used?', 'How does the proposed method compare to other state-of-the-art methods in terms of computational efficiency and ease of implementation?', 'How does the feature entropy method perform on other CNN architectures beyond VGG16 and ResNet34?', 'Can the authors provide more intuitive explanations or visualizations to help understand the mathematical formulations?', 'What measures can be taken to reduce the computational overhead associated with topological computations?', 'How does the method perform on other types of neural networks beyond CNNs?', 'Can the authors include more statistical analysis to support their experimental results?', 'How sensitive is the feature entropy to different network architectures and hyperparameters?', 'Can the authors provide more details on the potential real-world applications of feature entropy?', 'Are there any limitations or edge cases where feature entropy might not be a reliable indicator?', 'How does the method handle noisy or corrupted data?']","['The method may be computationally intensive due to the topological calculations involved.', 'The practical impact and broader applicability of the method are not convincingly demonstrated.', ""The method's complexity and dense mathematical formulations may make it difficult for others to reproduce the results."", 'Experiments are limited to specific CNN architectures, raising concerns about generalizability.', 'Computational overhead of topological computations in large-scale networks could be significant.', 'The method may not be directly applicable to non-CNN architectures.', 'Potential negative societal impacts are not addressed.']",False,2,2,2,4,4,"['Introduction of a novel metric (feature entropy) for assessing CNN units.', 'Comprehensive experimental validation on various datasets and network architectures.', 'The method shows potential for practical applications in network pruning and performance assessment.']","['Lacks a thorough theoretical justification for the proposed measure.', 'Some experimental setups and results lack clarity.', 'The paper is dense and difficult to follow, particularly for those not familiar with topological data analysis.', 'Practical impact and broader applicability are not convincingly demonstrated.', 'Limited generalizability due to experiments being primarily on VGG16 and ResNet34 architectures.', 'Potential computational overhead associated with topological computations in large-scale networks.']",3,2,2,3,Reject
gPvB4pdu_Z,"The paper proposes a novel compositional training framework for end-to-end deep AUC maximization, addressing the limitations of previous two-stage methods. The framework integrates cross-entropy (CE) loss and AUC loss in a compositional objective function, optimized using a stochastic algorithm with theoretical convergence guarantees. Extensive empirical evaluations demonstrate the effectiveness of the proposed method on various benchmark and medical datasets.","['Can the authors provide more detailed explanations or a supplementary tutorial on the theoretical aspects to enhance reproducibility?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the authors provide a more detailed and formal convergence proof with all necessary conditions?', 'How does the computational complexity of the proposed algorithm compare to existing methods, and what are the implications for practical applications?', 'Can the authors provide more intuitive explanations and clearer structuring of the mathematical formulations to improve the clarity of the paper?', 'Are there additional recent baselines in DAM or compositional training that could be included for more exhaustive comparisons?', 'Can the authors provide more details on the practical implementation challenges of the proposed method?', 'How does the proposed method compare with other recent advanced methods for DAM, not just the baselines used in this paper?', 'Can the authors discuss potential limitations and negative societal impacts of their method in more detail?']","['The paper does not adequately address potential negative societal impacts, such as biases in the training data that could be amplified by the model.', 'The complex theoretical parts might hinder reproducibility.', 'The convergence proof is informal and lacks detailed conditions, affecting the robustness of the theoretical guarantees.', 'The computational overhead and practical limitations of the proposed method are not fully explored.']",False,3,3,3,7,4,"['Novel compositional training framework for end-to-end AUC maximization.', 'Development of a stochastic optimization algorithm with theoretical guarantees.', 'Extensive empirical evaluations demonstrating significant improvements over existing methods.', 'Implementation and availability of the proposed method in an open-source library.']","['Theoretical parts are complex and might be difficult to reproduce.', 'The convergence proof is informal and lacks detailed conditions, affecting the robustness of the theoretical guarantees.', 'The proposed algorithm is computationally intensive due to multiple backpropagations, which might hinder its practical applicability.', 'The paper is dense with technical details, making it hard to follow, especially in the theoretical sections.', 'Comparisons with baselines could be more exhaustive, including more recent advancements in DAM and alternative compositional training techniques.', 'The potential negative societal impacts of the work are not thoroughly discussed.']",3,3,3,3,Accept
Eot1M5o2Zy,"The paper introduces AestheticNet, a model for facial beauty prediction aimed at reducing bias in training data. The authors present methods to generate synthetic images to balance datasets and propose adjusted training techniques to minimize bias. They claim significant improvements in prediction accuracy and fairness compared to existing models, achieving a high Pearson correlation coefficient of 0.9601.","['Can the authors provide more details on the synthetic data generation process?', 'How is the fairness of the synthetic data evaluated?', 'What are the specific steps taken to ensure the reproducibility of the results?', 'How does AestheticNet compare with more recent state-of-the-art methods not mentioned in the paper?', 'Can you clarify how the balancing of training data was achieved in practice?', 'How does AestheticNet perform on datasets beyond the SCUT-FBP5500?', 'Can the authors provide more details on the ethical considerations and long-term impacts of their approach?', 'How does the proposed method handle other forms of bias beyond ethnicity?']","['The paper does not adequately address the potential negative societal impacts of using synthetic data for facial beauty prediction.', 'The reproducibility of the results is questionable due to insufficient methodological details.', 'The reliance on synthetic data could lead to issues in real-world applicability.', 'Potential negative societal impacts are not fully addressed.', 'The approach may not generalize well to other datasets or tasks.', 'The robustness of the proposed method across different datasets and real-world scenarios is not demonstrated.', 'Ethical concerns related to the generation and use of synthetic images without addressing consent and privacy.']",True,2,2,2,3,4,"['Addresses the important issue of bias in facial beauty prediction.', 'Introduces a novel approach with synthetic data augmentation and weighted annotations.', 'Claims high prediction accuracy with state-of-the-art results.']","['The methodology is not clearly explained, making it difficult to reproduce results.', 'Limited comparative analysis with existing methods beyond basic metrics.', 'Potential ethical concerns regarding the generation and use of synthetic images.', 'The evaluation metrics and datasets used are not adequately described.', 'The paper is lengthy and sometimes difficult to follow due to excessive detail.', 'Insufficient discussion on the generalizability of the method beyond the dataset used.', 'Lack of thorough evaluation regarding the ethical implications and potential societal impact.']",3,2,2,3,Reject
rxF4IN3R2ml,"The paper 'MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention' presents a novel approach to improving time-series forecasting using attention mechanisms inspired by recent advances in Transformer architectures. The key contributions include a novel positional encoding mechanism, horizon-specific decoder-encoder attention, and decoder self-attention. Empirical results on both proprietary and public datasets demonstrate significant improvements in forecasting accuracy and reduction in forecast volatility.","['Can the authors provide more details on the computational complexity and scalability of the proposed methods?', 'How do the results compare on a wider range of public datasets?', 'Can the authors provide more detailed explanations for the proposed positional encoding and attention mechanisms?', 'How can the reproducibility of the results on proprietary datasets be improved or validated?', 'What specific steps were taken to ensure that the improvements are due to the proposed methods rather than other factors?', 'Can the authors provide more theoretical analysis to support the empirical findings?', 'How do the proposed attention mechanisms compare with other recent advances in Transformer architectures?', 'Can the authors elaborate on the potential negative societal impacts and ethical considerations of the proposed methods?', 'Can you provide more details on how to implement the proposed positional encoding?', 'Have you considered potential negative societal impacts of your work, and if so, could you elaborate on them?', 'Can you provide more details on how ethical concerns were considered in this work?', 'What potential negative societal impacts could arise from the application of your model, and how can they be mitigated?', 'Could you elaborate on how the model would perform in real-time forecasting scenarios?']","['Evaluation on proprietary datasets may not be reproducible.', 'Limited discussion on potential negative societal impacts.', 'The complexity of the proposed model may hinder its adoption and reproducibility without access to the source code.', 'The paper does not adequately address the limitations and potential negative societal impact of the proposed methods.', 'The theoretical foundations of the proposed methods are not thoroughly explored.']",False,4,3,4,7,4,"['Novel positional encoding and attention mechanisms.', 'Significant improvements in forecasting accuracy and volatility reduction.', 'Well-organized and clearly written paper.', 'Comprehensive empirical evaluation demonstrating significant performance improvements.', 'Reduction in excess volatility is well-motivated and empirically validated.']","['Evaluation on proprietary datasets limits reproducibility.', 'Some explanations of the proposed methods could be more detailed.', 'Limited discussion on computational complexity and scalability.', 'The clarity of some methodological descriptions could be improved.', 'Theoretical foundations of the proposed methods are not thoroughly explored.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",4,4,3,4,Accept
jJOjjiZHy3h,"The paper presents AdversarialAugment (AdA), a technique that optimizes image-to-image models to generate adversarially corrupted images, thereby improving robustness to image corruptions. The method is theoretically motivated and empirically validated, showing improvements over state-of-the-art techniques on CIFAR-10-C and IMAGENET-C datasets. It also improves worst-case performance against ℓp-norm bounded perturbations.","['How does AdA perform in domains other than images?', 'Can the computational cost be reduced without significantly impacting performance?', ""What are the implications of AdA's dependency on other augmentation methods for practical deployment?"", 'Can you provide a more detailed ablation study to isolate the contributions of different components of AdA?', 'How does AdA perform in real-world settings where the theoretical assumptions might not hold?']","[""The paper does not provide a detailed analysis of the method's applicability to non-image domains."", 'The computational complexity is higher compared to other methods, which could limit its practical deployment.', 'While the paper achieves state-of-the-art results, it relies heavily on combining multiple augmentation methods for optimal performance.', 'Potential societal impacts of adversarial training are not discussed in detail.']",False,3,3,3,6,4,"['Novel method combining adversarial techniques with data augmentation.', 'Theoretical motivation and conditions for consistency.', 'Extensive empirical validation showing state-of-the-art improvements on CIFAR-10-C and IMAGENET-C.', 'Improved robustness against common image corruptions and adversarial perturbations.']","['Higher computational complexity compared to other augmentation techniques.', 'Dependency on combining with other augmentation methods (AugMix & DeepAugment) for optimal performance.', 'Limited generalization beyond the image domain.', 'Potential overfitting to specific types of corruptions.', 'Clarity issues in the theoretical sections.', 'Incremental improvements rather than groundbreaking advances.']",3,3,3,3,Accept
Jjcv9MTqhcq,The paper presents a novel supervised pre-training method called Leave-One-Out K-Nearest-Neighbor (LOOK) aimed at improving the transferability of pre-trained models to downstream tasks. The method focuses on preserving intra-class semantic differences by using a kNN classifier instead of traditional linear classifiers during the pre-training stage. Extensive experiments across multiple downstream tasks demonstrate that LOOK outperforms existing state-of-the-art supervised and self-supervised pre-training methods.,"['Can you provide more detailed theoretical analysis to support the empirical findings?', 'Could you clarify some of the algorithmic steps and implementation details for better reproducibility?', 'What are the potential limitations and negative societal impacts of the proposed LOOK method?', 'Can the authors provide more details on the computational complexity and scalability of LOOK?', 'How does LOOK perform on larger datasets beyond those tested?', 'Can the authors discuss any potential negative societal impacts of their work?', 'What are the potential limitations and how do they impact the generalizability of the proposed method?', 'Are there any negative societal impacts or ethical concerns related to the use of LOOK?', 'Can the authors provide more details on the computational overhead introduced by LOOK compared to traditional supervised methods?', 'How does LOOK perform on other tasks like object detection and segmentation compared to state-of-the-art methods?', 'Can the authors provide more intuition behind the choice of specific hyper-parameters, such as the queue size and momentum?', 'Can you provide more detailed theoretical justification for using k-NN in the pre-training context?', 'How does the method scale with even larger datasets beyond ImageNet?', 'Are there any potential ways to reduce the computational complexity of the proposed method?']","['The paper does not fully discuss potential limitations such as computational overheads or specific scenarios where LOOK might perform poorly.', 'Potential negative societal impacts are not explored in depth. For instance, if the method is applied to sensitive data, how does it handle privacy concerns?', 'The method introduces additional complexity which may hinder its adoption.', 'The performance on tasks other than classification is not unequivocally superior.', 'The method may not scale well with significantly larger datasets due to computational demands.', 'The practical impact might be limited due to the complexity and resources required.', 'The theoretical justification for the method needs to be stronger.']",False,3,3,3,5,4,"['Addresses a crucial problem in the pretrain-finetune paradigm.', 'Novel approach with the Leave-One-Out K-Nearest-Neighbor (LOOK) method.', 'Extensive empirical evaluation showing superior performance on various downstream tasks.', 'Thorough discussion of related work.', 'Efficient implementation strategies for large datasets.']","['Lacks detailed theoretical analysis to support empirical findings.', 'Algorithmic description and implementation details could be clearer.', 'Does not fully explore potential limitations and societal impacts of the method.', 'Computational complexity and scalability are not thoroughly analyzed.', 'Dense mathematical formulation and experiment details may be challenging to follow.']",3,3,3,3,Reject
9jsZiUgkCZP,"The paper proposes UVC, a unified framework for compressing Vision Transformers (ViTs) by integrating pruning, layer skipping, and knowledge distillation. The problem is formulated as a constrained optimization framework and solved using the primal-dual algorithm. Experimental results show that UVC achieves significant reductions in computational overhead while maintaining competitive performance.","['Can the authors provide more detailed explanations or visualizations to better understand the pruning, layer skipping, and knowledge distillation processes?', 'How does the proposed framework handle potential biases introduced by compressing models?', 'Are there any specific limitations in terms of the types of ViTs or datasets where UVC might not perform as well?', 'How does UVC perform compared to other recent state-of-the-art methods not included in the current experiments?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the authors provide more details on the hyperparameters used in the primal-dual algorithm?', 'How sensitive is the performance of UVC to the choice of the resource budget?']","['The paper does not extensively discuss the potential negative societal impacts that might arise from deploying compressed ViTs, such as biases being amplified or performance degradation in critical applications.', 'The complexity of the unified framework may hinder reproducibility and understanding for researchers not familiar with constrained optimization and primal-dual methods.', 'The robustness of the method under different settings and hyperparameter choices is not fully explored.', 'The practical implications of deploying these compressed models in real-world scenarios are not deeply explored.']",False,3,3,3,6,4,"['Comprehensive approach combining pruning, layer skipping, and knowledge distillation.', 'Strong empirical results showing significant FLOPs reduction (up to 50%) with minimal accuracy loss.', 'Detailed experimental setup and analysis providing a clear understanding of the framework’s effectiveness.', 'Novel combination of multiple compression techniques for ViTs.', 'Theoretical formulation of the problem as a constrained optimization task.', 'Extensive experimental evaluation on popular ViT variants.', 'Code availability for reproducibility.']","['Complexity in understanding the unified framework and its mathematical formulation may hinder reproducibility.', 'Limited discussion on the potential negative societal impacts of deploying compressed ViTs.', 'High reliance on empirical results with less emphasis on theoretical foundations and formal proofs.', 'Clarity issues in the presentation of the methodology.', 'Insufficient analysis of the robustness of the method across different settings.', 'Lack of comparison with a broader range of state-of-the-art methods.', 'Some implementation details and hyperparameters for reproducing the results are not fully provided.', 'The visualizations, while helpful, could be clearer and more thoroughly explained.']",3,3,3,3,Accept
Ve0Wth3ptT_,"The paper presents DEGREE, a decomposition-based explanation method for Graph Neural Networks (GNNs). By decomposing the information flow in GNNs, DEGREE provides faithful explanations without relying on input perturbation or surrogate models. The method includes a subgraph-level explanation algorithm to reveal complex node interactions. The effectiveness of DEGREE is demonstrated through quantitative and qualitative experiments on synthetic and real-world datasets.","['Can the authors provide a detailed discussion on the limitations of DEGREE?', 'What are the potential negative societal impacts of using DEGREE?', 'Can the authors compare DEGREE with more recent and relevant methods in the explainability domain?', 'Can you provide a more detailed explanation of the decomposition process for different GNN layers?', 'How does DEGREE handle potential negative societal impacts or biases in the data or model?', 'Could you include more comprehensive experiments, including additional datasets and baselines, to strengthen your claims?', 'Can the authors provide more details on the implementation to ensure reproducibility?', 'How does the method perform on larger and more complex real-world datasets?', 'Can the authors elaborate on the potential limitations and negative societal impacts of DEGREE?', 'Can the authors provide more details on how the proposed method can be simplified for practical adoption?', 'How does DEGREE compare to other state-of-the-art explanation methods across different types of GNN architectures not covered in the paper?', 'Can the authors include additional evaluation metrics to cover different aspects of explainability?', 'Can the authors provide more details on the computational efficiency of DEGREE compared to other methods?', 'How does the performance of DEGREE vary with the complexity of the graph structures in the datasets?', 'Can the authors discuss the scalability of DEGREE for very large graphs and potential optimizations?']","['The paper does not adequately address the potential negative societal impacts of the proposed method. For example, how does DEGREE handle biases in the data or model?', 'The explanation of the decomposition process and aggregation algorithm could be clearer and more accessible to the readers.', ""The method's performance on larger and more complex datasets is not evaluated."", 'The complexity of the explanation method might reduce its practical applicability in real-world scenarios.', 'Potential negative societal impacts are not thoroughly discussed.', 'Limited diversity in evaluation metrics.', 'The potential computational intensity of the method, especially for larger graphs.', 'The clarity of the decomposition algorithm and its implementation could be improved.']",False,3,3,3,6,4,"['Introduction of a novel decomposition-based explanation method for GNNs.', 'Addresses major limitations of existing explanation methods (e.g., approximation and perturbation-based approaches).', 'Provides both node-level and subgraph-level explanations.', 'Comprehensive theoretical background.', 'Extensive experimental validation on both synthetic and real-world datasets.']","['The explanation of the decomposition process and aggregation algorithm is complex and may be difficult to follow.', 'Lacks a detailed discussion on limitations and potential negative societal impacts.', 'Comparison with baseline methods could be more exhaustive, including more recent and relevant methods.', 'Reproducibility of the results is not thoroughly ensured; more details on implementation would be beneficial.', 'Some results, especially qualitative ones, seem anecdotal and lack rigorous statistical analysis.']",4,3,3,3,Reject
aYSlxlHKEA,"The paper introduces Decentralized Model-based Policy Optimization (DMPO), a fully decentralized model-based reinforcement learning algorithm for networked multi-agent systems. It aims to improve sample efficiency while matching the asymptotic performance of model-free methods. Theoretical analysis is provided to support the performance claims, and empirical results are presented based on traffic control environments.","['Can the authors provide more details on how different the proposed approach is from existing work in terms of novelty?', 'How would the approach perform in different types of multi-agent environments beyond traffic control?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the proposed method be generalized to other types of multi-agent environments beyond traffic control?', 'How does the algorithm perform in terms of computational efficiency compared to existing methods?', 'Can the authors provide a more detailed discussion on the potential negative societal impacts and ethical considerations of their work?', 'Can you provide more details on the specific implementation of the graph convolutional networks used for the localized models?', 'How does the performance of DMPO scale with the increasing number of agents in more complex environments?', 'Can you include additional baselines in the empirical evaluation to provide a more comprehensive comparison?']","['The scalability of the algorithm to larger networks or more complex environments is not convincingly demonstrated.', 'The potential negative societal impact is not adequately addressed.', 'The empirical evaluation is limited to specific traffic control environments and does not cover a wide range of scenarios.', 'The robustness of DMPO to model inaccuracies and its impact on policy performance is not addressed in detail.', 'Potential negative societal impacts, such as biases introduced by localized models or unintended consequences in real-world applications, are not discussed.']",False,3,2,2,4,4,"['Addresses a relevant and challenging problem in multi-agent reinforcement learning.', 'Introduction of DMPO, which combines local models and communication to enhance efficiency.', 'Theoretical analysis providing performance bounds and sufficient conditions for policy improvement.', 'Empirical results demonstrating increased sample efficiency and competitive performance.']","['The novelty of the proposed approach may be overstated; similar concepts exist in the literature.', 'Limited diversity in experimental validation; only traffic control environments are used.', 'Potential negative societal impacts are inadequately addressed.', 'Some parts of the paper are unclear and could benefit from better organization and explanations.', 'The empirical validation lacks a thorough comparison with a wider range of state-of-the-art methods.']",2,3,2,3,Reject
buSCIu6izBY,"The paper introduces the Maximal Credit Assignment Occupancy (MaCAO) model for reinforcement learning, which aims to balance exploration and exploitation by maximizing state space exploration using a variational approach. The method is implemented in an actor-critic setup and tested on various benchmarks, showing improved performance.","['Can you provide the link to the code repository for reproducibility?', 'How does the method perform on tasks outside of the provided benchmarks, especially in real-world environments?', 'What are the computational requirements for training models using MaCAO compared to SAC and PPO?', 'Can the authors provide more details on the experimental setup, including hyperparameters and implementation details, to facilitate reproducibility?', 'How sensitive is the proposed method to the choice of hyperparameters, and did the authors conduct any hyperparameter tuning?', 'Can the authors provide ablation studies to isolate the contributions of different components of the proposed method?', 'Can the authors provide a more detailed explanation of the variational formulation and its advantages over existing methods?', 'How does the MaCAO model handle highly sparse reward settings?', 'Could the authors elaborate on the computational complexity and scalability of the proposed method?', 'Can the authors provide clearer explanations or visual aids for the mathematical derivations?', 'How does MaCAO perform in more diverse and complex environments beyond the provided benchmarks?', 'What are the limitations and potential negative societal impacts of the proposed approach?', 'Can the authors provide more detailed comparisons with baseline methods?', 'How does the proposed method perform in ablation studies to isolate its contributions?', 'Can the authors clarify the theoretical derivations and provide stronger evidence for their claims?']","['The complexity of the model may hinder its practical implementation.', 'The paper does not sufficiently address the potential negative societal impacts of the proposed method.', 'The computational cost associated with the non-parametric estimation of the occupancy distribution might be significant.', 'The method relies on a uniform prior, which may not always be suitable.', 'The theoretical formulation is dense and may be difficult for practitioners to implement.', 'The experimental results are limited to a few benchmarks and lack extensive comparison.']",False,3,2,3,4,4,"['The paper introduces a new perspective on reinforcement learning by combining reward maximization with state space exploration through a variational approach.', 'The paper provides a detailed theoretical formulation, including the introduction of new optimization objectives and variational evidence lower bound (ELBO).', 'The method is implemented in an actor-critic setup and tested on various benchmarks, showing improved performance.']","['The paper is dense and intricate, making it difficult to follow, especially for readers not already familiar with the subject matter.', 'While a repository link is promised, it is not currently provided, making it challenging to verify results.', 'Although the results show improvements on benchmarks, the experimental setup lacks diversity and could benefit from more comprehensive evaluations on a broader range of tasks.', 'The implications of the proposed method for real-world scenarios are not thoroughly discussed, primarily focusing on benchmark performance.', 'The paper does not sufficiently address the potential negative societal impacts of the proposed method.', 'The computational cost associated with the non-parametric estimation of the occupancy distribution might be significant.']",3,3,2,3,Reject
CC-BbehJKTe,"The paper introduces a novel concept called 'winning trees' to address program bloat in Genetic Programming (GP). It combines deterministic and random simplification methods to produce these winning trees, which are then used to initialize new GP runs, potentially leading to better convergence and fitness. The approach is validated through experiments on synthetic benchmarks and real-world symbolic regression problems.","['What is the rationale behind selecting a subtree depth of half the maximum tree depth? Have other depths been tested?', 'How do the results compare with other state-of-the-art methods for addressing program bloat in GP?', 'Can the authors provide clearer visualizations or summaries of the experimental results to improve readability?', 'Can the authors provide more details on the hyperparameter tuning process?', ""How do 'winning trees' differ from traditional building blocks in GP, and why were these particular constraints chosen?"", 'What are the limitations of the proposed approach, especially in terms of computational complexity and scalability?', ""Can the authors provide a more detailed theoretical analysis of why 'winning trees' should work better than other initialization methods?"", 'How were the parameters for the simplification and pruning methods chosen? Are there any guidelines or criteria?', 'Can the authors clarify the experimental setup, especially the choice of datasets and GP parameters?', 'Can the authors provide more details on the generalizability of the winning trees across different problem domains?']","['The paper does not provide a clear justification for certain design choices, such as the specific depth for selecting subtrees.', 'The generalizability of the findings is questionable due to inconsistent improvements across different settings.', 'The paper does not clearly discuss the potential computational overhead introduced by the simplification and pruning processes.', 'Scalability of the approach to larger and more complex problems is not addressed.', 'Potential negative societal impacts are not discussed.']",False,2,2,2,4,4,"[""Novel concept of 'winning trees' to address program bloat in GP."", 'Combination of deterministic and random simplification techniques.', 'Extensive experimental validation on synthetic and real-world datasets.']","['Lack of clarity in the presentation of some concepts and methods.', 'Insufficient theoretical foundation for the proposed methods.', 'Inconsistent improvements across different datasets and tree depths.', 'Limited discussion on the generalizability and limitations of the approach.', 'Mixed experimental results, with the approach not always outperforming baseline methods.']",3,2,2,3,Reject
AUszBTiYBB6,"The paper proposes a new aggregation method, Tmean(·), to mitigate Byzantine attacks in federated learning. This method involves trimming part of the data before averaging, which is shown to improve robustness against such attacks. The paper provides theoretical proofs for the robustness and convergence of the method and demonstrates its effectiveness through various experiments on MNIST and CIFAR-10 datasets.","['Can the authors provide more details on how Tmean(·) compares with other state-of-the-art methods in terms of computational efficiency and robustness?', 'Can the authors elaborate on the potential limitations of Tmean(·) in real-world scenarios?', 'Are there any specific societal impacts or ethical considerations that should be taken into account for the proposed method?', 'How does the proposed Tmean(·) compare with more recent Byzantine-resilient aggregation methods?', 'Can the authors provide more detailed explanations or visual aids to clarify the theoretical proofs?', 'What are the potential negative societal impacts of deploying the proposed method in real-world federated learning systems?', 'Can the authors provide more details on the experimental setup and justify the chosen hyperparameters?', 'How does Tmean(·) compare with other state-of-the-art aggregation rules in terms of both performance and robustness?', 'Can you provide more detailed explanations and validation of the theoretical proofs?', 'How does Tmean compare with other robust aggregation methods in more diverse and realistic attack scenarios?', 'Can you elaborate on the scalability and real-world applicability of Tmean in larger federated learning systems?', 'Can the authors include more diverse datasets and attack scenarios in their experiments?']","['The paper does not adequately discuss the limitations of the proposed method, such as its performance in non-convex settings or under different types of attacks.', 'The potential negative societal impacts of deploying Tmean(·) in federated learning applications are not addressed.', 'The broader societal impacts and potential misuse of the proposed method are not adequately addressed.', 'The paper does not sufficiently address the potential limitations of the Tmean(·) method, such as its computational complexity and scalability.', 'There is limited discussion on the potential negative societal impacts of the proposed method, such as privacy concerns in federated learning.', 'The experimental evaluation is not comprehensive enough to fully validate the effectiveness of Tmean(·).', 'The approach is incremental and may not significantly advance the state-of-the-art.']",False,2,2,2,3,4,"['Novel approach to mitigate Byzantine attacks using trimmed mean aggregation.', 'Theoretical analysis supporting the robustness and convergence of the proposed method.', 'Extensive empirical validation through experiments on MNIST and CIFAR-10 datasets.']","['The clarity and organization of the paper need improvement, making it difficult to follow.', 'Limited comparison with existing state-of-the-art methods, making it hard to assess the relative performance.', 'Inadequate discussion on the limitations of the approach and its potential negative societal impacts.', 'Theoretical proofs require more rigorous validation and might be challenging for readers to follow.', 'Experimental comparisons are limited and do not cover a wide range of baselines.', 'Real-world applicability and scalability discussions are insufficient.', 'Some typographical errors and unclear explanations reduce the clarity of the paper.']",3,2,2,3,Reject
7gWSJrP3opB,"The paper presents a theoretical analysis of example-selection methods for Stochastic Gradient Descent (SGD), introduces a new condition called 'average gradient error,' and proposes two new example-selection methods. Empirical validations are also provided to demonstrate the effectiveness of the proposed methods.","['Can the assumptions made in the theoretical analysis be relaxed?', 'How do the proposed methods perform in more diverse and realistic datasets?', 'Can the presentation be simplified to improve clarity and accessibility?', 'Can the authors provide more intuition behind the average gradient error condition?', 'How do the assumptions made in the theoretical analysis hold in practical scenarios?', 'Can the proposed methods be generalized to other optimization algorithms beyond SGD?', 'How does the proposed condition compare to existing conditions in terms of practical verifiability?', 'Can the authors provide more comprehensive comparisons with state-of-the-art methods in the empirical evaluation?', 'How sensitive are the proposed methods to the choice of hyperparameters?', 'What are the potential negative societal impacts of the proposed methods?', 'How scalable are the proposed algorithms to larger datasets and more complex models?', 'Can the empirical results be generalized to other types of datasets and tasks?', 'Are there any simpler ways to verify the complex inequalities and lemmas used in the proofs?']","['The reliance on assumptions that may not hold in practical scenarios.', ""Potential limitations in the empirical validation's comprehensiveness."", 'The complexity of the theoretical arguments may limit the accessibility of the paper.', 'The scalability of the proposed algorithms to larger datasets and more complex models is not thoroughly evaluated.', 'The potential negative societal impacts of the proposed methods are not addressed.']",False,3,3,3,6,4,"['Novel condition (average gradient error) for analyzing example-selection methods.', 'Extends analysis to both strongly convex and non-convex settings.', 'Proposes two new methods with promising empirical results.', 'Comprehensive theoretical analysis that unifies and extends previous results.', 'Thorough evaluation on standard benchmarks showing practical utility.']","['Theoretical results rely on assumptions that may not hold in practice.', 'Empirical validation may not be comprehensive.', 'Highly technical and dense, limiting accessibility.', 'The clarity of the assumptions and theoretical contributions could be improved.', 'Limited discussion on the potential negative societal impacts of the proposed methods.']",3,3,3,3,Reject
04pGUg0-pdZ,"The paper introduces a mini-batch Markovian sampled fully decentralized actor-critic algorithm for multi-agent reinforcement learning (MARL) in the average reward setting. It claims to be the first to establish finite-time convergence and sample complexity for this problem. The algorithm is designed to handle practical MARL settings where joint actions are unknown, and it aims to achieve efficient communication and sample efficiency.","['Can the authors provide more details on the practical applications and limitations of their approach?', 'How does the proposed algorithm perform in more diverse and complex environments?', 'Can the authors elaborate on any potential ethical concerns related to their method?', 'Some assumptions in the theoretical analysis (e.g., Assumption 5) seem quite strong. Can the authors discuss how these assumptions affect the applicability of their results in practical scenarios?', 'Can the authors provide more intuitive explanations or visualizations to improve the clarity of the theoretical results?', 'Why are the experimental results limited to only one baseline comparison?', 'Can you justify the assumptions made in the theoretical analysis more thoroughly?']","['The paper does not thoroughly address the limitations of the proposed algorithm in real-world scenarios.', 'Potential negative societal impacts, such as biases in decision-making, are not discussed.', 'The empirical evaluation is limited and does not cover a wide range of scenarios.', ""The paper's clarity could be improved, making it more accessible to a broader audience."", 'The practical implications and applications of the theoretical findings are not deeply explored.']",True,3,3,3,5,4,"['Novel approach for decentralized MARL in the average reward setting.', 'Establishes finite-time convergence and sample complexity.', 'Efficient communication strategy with batch sampling.', 'Addresses a significant and challenging problem in MARL.']","['The presentation is dense and challenging to follow, especially for non-experts.', 'Experimental validation is limited and lacks diversity in test scenarios.', 'Theoretical analysis relies on strong assumptions that may limit practical applicability.', 'Potential ethical concerns related to the application of the proposed method are not adequately addressed.']",3,3,3,3,Reject
B2pZkS2urk_,"The paper proposes Evolutionary Plastic Recurrent Neural Networks (EPRNN), integrating evolutionary strategies, plasticity rules, and recursion-based learning for task generalization. The method involves nested loops for meta-learning: an outer loop for evolving initial parameters and learning rules, and an inner loop for task-specific adaptation. The authors evaluate EPRNN on sequence prediction and wheeled robot navigation tasks, demonstrating its potential to generalize across tasks without gradient-based optimization.","['Can the authors provide more detailed explanations of the mechanisms and intuition behind EPRNN?', 'How does EPRNN compare with state-of-the-art methods in more detail?', 'Can the authors address the limitations and potential negative impacts of their work?', 'How does EPRNN perform on more diverse and complex tasks?', 'What are the specific advantages of EPRNN over other plasticity and evolution-based methods?', 'Can the authors provide more details on the algorithm and experimental setup to improve reproducibility?', 'Have other types of tasks been considered to demonstrate the generalizability of EPRNN?', 'Can the authors discuss the potential societal impacts of adaptive AI systems in more detail?', 'Can you provide more detailed comparisons with gradient-based methods, especially in terms of computational efficiency and performance?', 'How does the proposed EPRNN framework handle overfitting, given the evolutionary approach?', 'Can you elaborate on the potential negative societal impacts and ethical considerations of using EPRNN in real-world applications?', 'Can the authors provide more details on how hyperparameters were tuned?', 'How reproducible are the results? Are the codes and datasets available?', 'Can the authors elaborate on how their approach differs from and improves upon prior work?']","['The paper does not adequately address the limitations and potential negative societal impacts of the proposed framework.', 'The generalization claims are limited to a few specific tasks and may not hold for more complex scenarios.', 'Limited task variety in experiments may not sufficiently demonstrate generalizability.', 'Insufficient comparison with state-of-the-art methods.', 'Clarity issues in the presentation of the algorithm and experiments.', 'The comparison with gradient-based methods is limited, which could affect the perceived significance of the work.', 'Potential societal impacts are not addressed.']",False,2,2,2,4,4,"['Novel combination of plasticity and recursion in a meta-learning framework.', 'Extensive experiments on sequence prediction and wheeled robot navigation tasks.', 'Interesting and ambitious approach combining evolution strategies, plasticity, and recursion.']","['Lacks clarity in explaining the detailed mechanisms and the intuition behind EPRNN.', 'Experimental results are not convincingly better than existing methods.', 'Significant gaps in the related work section; some related works are not adequately cited.', 'Does not adequately address the limitations and potential negative societal impacts.', 'Presentation of results is somewhat confusing and lacks clear comparison with state-of-the-art methods.', 'Limited novelty as it builds on existing concepts of plasticity and recursion.', 'Claims of generalization are not fully substantiated with diverse and complex tasks.', 'Insufficient comparison with state-of-the-art differentiable plasticity methods.', 'Limited variety of tasks for demonstrating generalizability.', 'Under-explored potential negative societal impacts and ethical considerations.', 'Details on hyperparameter tuning and reproducibility are limited.', 'Dense writing and some figures/tables are hard to interpret.']",3,2,2,3,Reject
iMqTLyfwnOO,"The paper introduces the Augmented Sliced Wasserstein Distance (ASWD), a new distance metric designed to improve projection efficiency in high-dimensional spaces using neural networks to create nonlinear projections. The paper provides theoretical validation of ASWD and demonstrates its effectiveness through empirical experiments in generative modeling, color transferring, and Wasserstein barycenters.","['Can the authors provide a clearer and more concise description of the experimental setup to aid reproducibility?', 'How does the ASWD compare with recent advances in computational optimal transport that are not covered in the paper?', 'Are there specific types of neural network architectures that work better for the ASWD? If so, can the authors provide more insights?', 'Can the authors provide more intuitive explanations for the theoretical proofs?', 'How sensitive is ASWD to the choice of neural network architecture?', 'What are the practical limitations of ASWDs in terms of computational cost and scalability?', 'Can the authors provide more details on the computational resources required for training the neural networks used in ASWD?', 'Are there specific scenarios or datasets where ASWD performs worse than other methods? If so, what are the limitations of ASWD in these cases?', 'Can the authors provide more intuitive explanations or visualizations of the theoretical concepts to improve clarity?', 'How does the computational overhead of ASWDs compare to traditional SWDs in practice, given the reliance on neural networks?']","['The approach requires the use of neural networks, which may introduce additional computational overhead.', 'The reliance on a specific architecture for the neural networks may limit the generalizability of the approach.', 'Potential ethical considerations in applications involving generative modeling and data manipulation.', 'The paper does not fully address the computational cost and scalability issues of ASWDs.', 'There is limited discussion on the potential negative societal impact of ASWDs.', 'The interpretability of the neural networks used for mapping in ASWD could be further explored to understand the impact of different architectures on the performance.', 'The method’s performance is heavily reliant on the quality of neural network training.']",False,3,3,3,7,4,"['Novel approach to address the inefficiencies in Sliced Wasserstein Distances.', 'Comprehensive theoretical framework supporting the validity of ASWD.', 'Extensive empirical validation across various tasks.', 'Potential high impact in applications requiring efficient Wasserstein distance computation.', 'Provision of code via GitHub for reproducibility.']","['Theoretical contributions, while sound, are somewhat incremental.', 'The clarity and organization of the paper could be improved; it is dense and sometimes difficult to follow.', 'Experimental setup descriptions are convoluted, which may hinder reproducibility.', 'Certain sections, especially the Appendices, are overly detailed and detract from the main contributions.', 'The practical impact and generalizability of ASWDs are not fully explored.', 'The scalability of the ASWD in terms of computational resources is not thoroughly discussed, especially given the use of neural networks.', 'The experimental section could include more comparisons with recent baselines to better contextualize the improvements brought by ASWD.']",4,3,3,4,Accept
yx_uIzoHJv,"The paper proposes a method to induce compositionality in emergent languages by incorporating a topological similarity metric into the loss function of neural agents. The method aims to improve generalization, convergence speeds, and ease of language transmission without the need for generational transmission or additional learning phases.","['How does the proposed method compare against existing approaches in terms of computational complexity and performance?', 'Can the authors provide more detailed ablation studies to isolate the effects of the compositional pressure?', 'What are the limitations of the proposed method, and how can they be mitigated?', 'Can the authors provide more theoretical analysis to support the relationship between topological similarity and generalization?', 'Why do certain configurations fail to show improvement with the proposed method?', 'How does the proposed method compare with other regularization techniques in a more detailed manner?']","['The paper does not adequately discuss the limitations of the proposed approach, such as its applicability to different types of environments or the potential for overfitting with high compositional pressure.', 'Potential negative societal impacts, such as biases introduced in the emergent languages, are not addressed.']",False,2,2,2,4,4,"['Addresses an important aspect of language emergence: compositionality.', 'Proposes a straightforward method that can be integrated into existing environments.', 'Comprehensive experimental setup and evaluation.']","['Lacks comprehensive evaluation and comparison with existing methods.', 'Results section does not convincingly demonstrate the proposed benefits.', 'Issues with clarity and organization: hard to follow arguments and reproduce experiments.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'Lack of deep theoretical analysis to support the claims.']",3,2,2,2,Reject
4pijrj4H_B,"The paper presents fairness-aware data augmentation techniques for Graph Neural Networks (GNNs) to mitigate bias in node representations. The methods include feature masking, node sampling, and edge manipulation to balance the graph structure and reduce bias. Theoretical analyses and extensive experiments on real-world datasets demonstrate the efficacy of the proposed methods in improving fairness metrics while maintaining utility.","['How do the proposed methods scale with larger, real-world datasets?', 'What are the specific computational overheads introduced by the adaptive augmentation schemes?', 'How do the methods compare to simpler baseline approaches in terms of both fairness and utility?', 'Can the theoretical analysis be extended to cover more general cases or different types of graphs?', 'How do the proposed methods perform on other types of real-world datasets beyond those considered?', 'Can you provide more detailed explanations or visualizations of the augmentation procedures to improve clarity?']","['The discussion on the trade-offs between fairness and utility needs more depth.', 'The potential for misuse in biased datasets should be acknowledged more explicitly.', 'The scalability of the proposed methods for very large graphs needs further discussion.', 'While potential societal impacts are addressed, more detail on mitigating unintended consequences would be beneficial.']",False,3,3,3,6,4,"['Comprehensive theoretical analysis of bias sources in GNNs.', 'Introduction of adaptive data augmentation techniques for fairness.', 'Extensive experimental validation on multiple datasets.', 'Detailed appendices covering proofs and implementation details.', 'Addresses an important and underexplored topic of fairness in GNNs.', 'Methods can be integrated into various GNN-based frameworks.']","['The novelty of the approach is not convincingly established.', 'Dense and complex presentation, especially in theoretical sections.', 'Lack of clarity on some experimental choices and hyperparameters.', 'Moderate significance of results with limited practical impact.', 'Insufficient discussion on computational overheads and scalability.']",3,3,3,4,Accept
vh-0sUt8HlG,"The paper introduces MobileViT, a lightweight and general-purpose vision transformer designed for mobile devices. MobileViT aims to combine the spatial inductive biases of CNNs with the global representation capabilities of vision transformers. The authors present extensive experimental results showing that MobileViT outperforms existing CNN and ViT models on tasks like image classification, object detection, and semantic segmentation while maintaining low latency and a small parameter count.","['Can you provide more details on the implementation of the multi-scale sampler?', 'What are the specific limitations of MobileViT, and how do you plan to address them in future work?', 'How does MobileViT handle potential ethical concerns, especially those related to data privacy and deployment in sensitive applications?', 'How does MobileViT perform under different real-world usage scenarios beyond the datasets tested?', 'Can the authors provide more detail on the specific tools and environments used to measure mobile device performance?', 'Can the authors provide more details on the exact configurations and hyperparameters used in their experiments?', 'How does MobileViT perform on a broader range of datasets and scenarios beyond the ones presented?', 'Can the authors clarify the specific contributions of each component of the MobileViT architecture to the overall performance improvements?', 'How does MobileViT perform compared to the very latest state-of-the-art models in the field?', 'Can the authors provide more rigorous benchmarks for the claimed efficiency on mobile devices?', 'What are the potential limitations of MobileViT when scaled to larger models or different vision tasks?', 'How does MobileViT perform on other downstream tasks such as video classification?', 'Are there any plans to optimize MobileViT for specific hardware accelerators?']","['The paper does not discuss the limitations of MobileViT in detail, such as its performance on non-mobile devices or in real-world deployment scenarios.', 'Potential negative societal impacts, such as issues of data privacy and security, are not addressed.', 'Potential limitations in generalizability across different mobile devices and applications.', 'Possible challenges in optimizing the model for specific hardware without dedicated support.', 'The paper does not fully address the potential limitations of MobileViT in terms of scalability and generalization.', 'The efficiency benchmarks on mobile devices need more rigorous validation.', ""MobileViT's performance on mobile devices is limited by the lack of dedicated hardware optimizations.""]",False,3,3,3,6,4,"['Addresses an important problem of deploying efficient models on mobile devices.', 'MobileViT achieves impressive performance improvements over existing lightweight CNNs and ViT models.', 'The paper provides extensive experimental validation across multiple vision tasks and datasets.', 'The architecture is clearly laid out, and the authors provide open-source code for reproducibility.', 'Detailed ablations and comparisons bolster the robustness of their findings.']","['The novelty of the approach is somewhat limited as it primarily combines existing techniques from CNNs and transformers rather than introducing fundamentally new concepts.', 'The paper lacks a detailed discussion of the limitations and potential negative societal impacts of the proposed method.', 'The explanations of some technical details are not very clear, particularly the multi-scale sampler and its implementation.', 'Heavily relies on empirical results without sufficient theoretical backing to explain why the proposed method outperforms others.', 'Methods used to measure performance on mobile devices could be more transparent.', 'Technical soundness and clarity of certain claims need more rigorous validation.', 'Experimental methodology needs more comprehensive benchmarking and clear presentation of hyperparameters and configurations.', 'Dense and somewhat unclear presentation of results and comparisons.']",3,3,3,3,Reject
0rjx6jy25R4,"The paper introduces a novel framework, CNI-CGAN, which combines Positive-Unlabeled (PU) classification with Conditional Generative Adversarial Networks (CGAN) to leverage extra unlabeled data for both tasks in a mutually beneficial manner. The key contribution is the development of a Classifier-Noise-Invariant CGAN that can handle noisy labels from a PU classifier, theoretically proven to learn the clean data distribution. The paper provides theoretical guarantees and extensive experimental results to demonstrate the effectiveness of the proposed method.","['Can the authors provide more details on the computational cost and scalability of their method?', 'How does the method perform on more complex datasets or in real-world scenarios?', 'Can the authors provide more insights into the choice of hyperparameters and their impact on the results?', 'How do the theoretical assumptions hold in practical scenarios?', 'Why were certain state-of-the-art methods not included in the comparison?', 'Can the authors provide more details on the potential negative societal impacts?', 'How would the method perform on more complex datasets beyond MNIST, Fashion-MNIST, and CIFAR-10?', 'Can the authors provide more intuition behind the theoretical guarantees and how they were derived?', 'How does the proposed method compare with other robust GAN approaches in terms of computational efficiency?', 'What are the practical applications where this method would be most beneficial?', 'How sensitive is the method to the choice of hyperparameters, particularly λ, κ, and β?', 'Can the method be extended to handle other types of noise in the labels beyond those predicted by a PU classifier?', 'How does the method perform when the labeled data is extremely imbalanced?']","['The authors do not adequately discuss the limitations and potential negative societal impact of their work. A discussion on the scenarios where the method might fail or produce suboptimal results would be beneficial.', 'Theoretical assumptions might not hold in practical scenarios.', 'Limited comparisons with state-of-the-art methods.', 'Potential performance issues on more complex datasets.', 'The societal impact of using unlabeled data, especially in sensitive domains, is not discussed.', 'The impact of leveraging out-of-distribution data on model reliability and fairness should be considered.']",False,3,3,3,6,4,"['Addresses an important problem of label scarcity by utilizing abundant unlabeled data.', 'Novel combination of PU classification with conditional generation, leveraging the interdependence between the two tasks.', 'Robust theoretical analysis ensuring the validity of the proposed method.', 'Extensive experiments on multiple datasets demonstrating the effectiveness of the proposed method.']","['The paper is quite dense and may be difficult for readers to fully grasp without multiple readings.', 'Results could benefit from additional baselines and ablation studies to further validate the effectiveness of each component.', 'Robustness claims could be further strengthened with more varied and challenging settings.', 'Potential negative societal impacts and ethical considerations are not adequately addressed.', 'Theoretical assumptions may not hold in practical scenarios.', 'The impact and practical applicability of the method are not entirely clear.']",3,3,3,3,Reject
7B3IJMM1k_M,"The paper proposes a method for converting artificial neural networks (ANNs) to spiking neural networks (SNNs) with high accuracy and ultra-low latency. The key contribution is the introduction of a quantization clip-floor-shift (QCFS) activation function to replace the ReLU activation function in ANNs, which better approximates the activation function of SNNs. The authors provide theoretical analysis and proof of zero expected conversion error and demonstrate the effectiveness of their approach on CIFAR-10, CIFAR-100, and ImageNet datasets.","['Could the authors provide more details on the implementation and experimental setup?', 'What are the potential limitations and societal impacts of this work?', 'How does the proposed method compare with other state-of-the-art methods not covered in the paper?', 'How does the proposed method perform on tasks other than image classification?', 'Can the authors provide more details on the computational cost and energy efficiency of the proposed method compared to existing methods?', 'How sensitive is the performance to the hyperparameter L in different scenarios?', 'Can the authors provide more illustrative figures to explain the core concepts and theoretical derivations?', 'What is the impact of different components of the QCFS activation function? Ablation studies would be helpful.', 'How does the proposed method compare in terms of computational complexity and training time with existing methods?', 'Can the authors provide more practical guidelines for implementing the proposed method?']","['The paper does not discuss the potential limitations of the proposed method in detail.', 'The societal impacts of deploying SNNs using the proposed method are not addressed.', ""The method's performance is primarily evaluated on standard datasets. Its robustness in real-world applications is not demonstrated."", 'Potential negative societal impacts are not discussed in detail.', 'Theoretical justifications for the proposed method could be more rigorous.', 'Complexity of the proposed method might hinder its practical adoption without more streamlined guidelines.']",False,3,3,3,7,4,"['Theoretical foundation for the conversion error analysis.', 'Introduction of the quantization clip-floor-shift (QCFS) activation function.', 'Comprehensive experimental validation on large-scale datasets.', 'Outperforms state-of-the-art ANN-SNN conversion methods in accuracy and latency.', 'Code availability promoting transparency and reproducibility.']","['Some implementation and experimental details are missing.', 'Limited discussion on potential limitations and societal impacts.', 'Complexity in the explanations may hinder understanding and reproducibility.', 'Limited comparison with more diverse state-of-the-art methods.', 'Theoretical justifications for the proposed method could be more rigorous.']",4,3,3,4,Accept
k7efTb0un9z,"The paper proposes a novel Graph Network-based Scheduler (GNS) for learning rate scheduling, which represents the target network as a directed graph and leverages a graph message passing network to encode the state and train an agent via reinforcement learning. The method is evaluated on image classification (Fashion-MNIST, CIFAR10) and language understanding (GLUE) tasks, demonstrating improvements over traditional and contemporary scheduling methods.","['How does GNS perform on completely unseen tasks or datasets outside of image classification and language understanding?', 'What are the computational costs associated with GNS compared to simpler scheduling methods in practical scenarios?', 'Can the authors provide more detailed insights on the scalability of GNS to very large models or datasets?', 'Can the authors provide more detailed analysis of the computational overhead introduced by using GNNs for learning rate scheduling?', 'Can the authors provide more detailed experimental results, including additional baselines and ablation studies?', 'How does the proposed method perform in terms of convergence speed compared to the baselines?', 'How does the computational overhead of GNS compare with traditional learning rate schedulers in terms of training time and resources?', 'What are the specific hyperparameters used for tuning the GNN and reinforcement learning components?', 'How does the GNS perform compared to more recent adaptive learning rate methods?', 'What specific challenges might arise in reproducing the results, and how can these be mitigated?', 'Can you provide more details on the reward function design and how it influences the training dynamics?', 'Can you provide more examples or case studies where GNS might not perform well?']","['The paper primarily focuses on moderate time horizons and does not address very long training scenarios (e.g., BERT pre-training).', 'Potential overfitting to the tasks used for evaluation.', 'High computational cost and complexity may hinder practical adoption.', 'The paper does not address the computational overhead introduced by using graph neural networks for learning rate scheduling.', 'The experimental results show improvement, but the gains are not substantial enough to clearly demonstrate the superiority of the proposed method.', 'The paper does not discuss the potential environmental impact due to the computational resources required for training the reinforcement learning model.', 'Scalability to larger datasets and more complex models is not thoroughly evaluated.', 'The complexity of the method might make it difficult for practitioners to adopt.', 'Potential reproducibility issues due to the intricate design and training process.']",False,3,3,3,6,4,"['Novel approach of using Graph Neural Networks for learning rate scheduling.', 'Extensive experimental validation on diverse tasks including image classification and language understanding.', 'Detailed ablation studies and comparisons with various baselines.', 'Code availability for reproducibility.']","['Potential overfitting to specific tasks or datasets due to the complexity of the model.', 'High complexity and computational cost, which may limit practical applicability.', 'The clarity of the methodology and results presentation could be improved.', 'Limited discussion on the broader impact and potential negative societal implications.', 'The novelty of the method is somewhat incremental, building on existing reinforcement learning and graph neural network techniques.', 'The experimental results show improvement, but the gains are not substantial enough to clearly demonstrate the superiority of the proposed method.', 'The paper lacks a thorough analysis of the computational overhead introduced by using GNNs for learning rate scheduling.', 'Some sections, such as the experimental setup and results, could be more detailed.', 'Limited discussion on scalability to larger datasets and models.', 'Hyperparameter tuning details could be more elaborated.', 'Potential ethical concerns regarding the environmental impact of the computational resources required for training.']",4,3,3,3,Reject
hcoswsDHNAW,"The paper proposes Fast AdvProp, an accelerated version of Adversarial Propagation (AdvProp) for training deep neural networks. The method reduces training costs by simplifying expensive components of AdvProp, such as generating adversarial examples and pairing clean and adversarial samples. The paper presents empirical results showing that Fast AdvProp achieves similar or better performance compared to vanilla training and traditional AdvProp on various visual recognition benchmarks, without incurring additional training costs.","['Can the authors provide more details on how information leakage is mitigated using the shuffling BN technique?', 'How does Fast AdvProp perform on tasks other than image classification, such as natural language processing or speech recognition?', 'What are the potential limitations or failure cases of the proposed method?', 'Could you provide more detailed explanations of the gradient recycling technique and how it is implemented?', 'Can the authors provide more details on the decoupling process and its impact on training stability?', 'How does Fast AdvProp perform on models other than ResNet, such as transformers or other architectures?', 'Can the authors include more ablation studies to isolate the effects of each modification?', 'How does Fast AdvProp compare with other recent advancements in adversarial training?', 'Can the authors provide more intuition behind the choice of the specific ratio of clean to adversarial examples?', 'Can the authors provide more theoretical analysis or insights into why the proposed modifications are effective?']","['The paper focuses on image classification tasks, and its effectiveness in other domains is not explored.', 'Potential negative societal impacts of adversarial training techniques are not fully addressed.', 'The proposed methods may not generalize well to all types of neural network architectures or tasks.', 'The clarity of the presentation could be improved to make the paper more accessible to a broader audience.', 'The complexity of the proposed methods might hinder their adoption and reproducibility.']",False,3,3,3,6,4,"['Addresses a significant problem in adversarial training by reducing computational costs.', 'Demonstrates empirical performance improvements on multiple benchmarks.', 'Integrates well with existing data augmentation methods like Mixup and CutMix.', 'Provides open-source code to facilitate reproducibility.', 'Proposes novel techniques to reduce training costs, such as unpairing training samples and reusing gradients.']","['The explanation of some technical details, such as the handling of label leaking and parameter update synchronization, could be clearer.', 'Limited discussion on potential negative societal impacts, such as misuse of adversarial training techniques.', 'The evaluation primarily focuses on image classification tasks; broader applicability to other domains could strengthen the paper.', 'Theoretical analysis supporting the empirical results is limited.', 'Certain sections lack clarity, making it difficult to understand the exact modifications.', 'Potential issues with reproducibility due to the complexity of the proposed methods.']",3,3,3,3,Reject
QKEkEFpKBBv,"The paper presents Differentiable Nonparametric Belief Propagation (DNBP), a novel method that integrates neural networks with nonparametric belief propagation for end-to-end learning of probabilistic factors in graphical models. The method is validated on articulated pose tracking tasks, demonstrating competitive performance and the ability to handle uncertainty.","['Can the authors provide more details on the training stability and convergence of the DNBP method?', 'How does the performance of DNBP scale with larger and more complex graphical models?', 'What are the computational requirements for training and inference using DNBP?', 'How does DNBP compare with more recent state-of-the-art methods in similar tasks?', 'Can the authors provide more details on the implementation to improve reproducibility?', 'What are the potential limitations and negative societal impacts of DNBP, and how can they be mitigated?', 'How does the proposed method compare quantitatively and qualitatively to differentiable particle filters in similar tasks?', 'Can the authors provide more details on hyperparameter settings and training protocols to enhance reproducibility?', 'How robust is the method to variations in the graphical model structure and the number of particles used?', 'How does DNBP perform in comparison to other state-of-the-art methods for each of the evaluated tasks?', 'What are the potential limitations of the proposed method in terms of scalability and computational complexity?', 'How well does the method generalize to other types of tracking tasks or different domains?', 'What are the potential negative societal impacts of this technology?']","[""The method's scalability to larger and more complex tasks needs further exploration."", 'The computational complexity during training and inference may be high.', ""The dependence on high-quality training data can affect the method's robustness in real-world scenarios."", 'The paper does not sufficiently discuss the limitations of the method, such as the computational overhead of end-to-end training.', 'The potential negative societal impacts, especially in sensitive applications like robotics, are not addressed.', ""The method's reliance on a predefined graphical model structure may limit its applicability to more complex or dynamic environments."", 'The non-differentiable resampling step, although addressed in the paper, remains a potential bottleneck for fully end-to-end differentiable training.', 'Potential negative societal impacts are not explicitly discussed. For example, the use of such methods in surveillance or monitoring should consider ethical implications.']",False,3,3,3,5,4,"['Innovative integration of neural networks with nonparametric belief propagation.', 'Detailed experimental validation on multiple tracking tasks.', 'Clear and well-organized presentation.']","['Limited exploration of scalability and generalizability to diverse real-world applications.', 'Potential computational complexity not thoroughly addressed.', 'Dependence on the quality of training data and the effect on performance not fully discussed.', 'The novelty is somewhat incremental, building on existing methods like differentiable particle filters and nonparametric belief propagation.', 'Experimental evaluation could benefit from a broader range of tasks and comparisons with more state-of-the-art methods.', 'The clarity of the methodology and implementation details can be improved.', 'Potential limitations and societal impacts are not sufficiently addressed.']",3,3,3,3,Reject
AsyICRrQ7Lp,The paper proposes Bootstrapped Hindsight Experience Replay (BHER) with Counterintuitive Prioritization to address the challenge of sparse rewards in goal-conditioned environments in reinforcement learning. The method combines Bootstrapped DQN and HER with a novel prioritization mechanism that favors lower variance Q-values for exploitation. The approach is validated through comprehensive experiments in goal-reaching and robotics control tasks.,"['Can the authors provide a more detailed theoretical explanation for the counterintuitive prioritization mechanism?', 'How does the method perform in a wider range of environments, particularly those with different reward structures?', 'Can the authors clarify the process of tuning the temperature coefficient for different environments?', 'How sensitive is the performance to the number of Q-value heads?', 'Can the method be generalized to other types of RL tasks beyond goal-conditioned environments?', 'Can the authors provide a theoretical analysis or intuition behind the counterintuitive prioritization heuristic?', 'Can you provide more details on the hyperparameter tuning process?', 'How are the evaluation metrics defined and calculated?', 'Can you elaborate on the potential limitations and ethical concerns of your approach?']","['The paper primarily relies on empirical results without strong theoretical backing.', 'The environments tested are somewhat specific and may not generalize well to other tasks.', 'The impact of the proposed method on computational efficiency is not thoroughly discussed.', ""The method's complexity may limit its adoption in practical applications."", 'The empirical nature of the prioritization heuristic without theoretical backing could limit its generalizability.', 'Ethical concerns related to the deployment of reinforcement learning in real-world applications are not discussed.']",False,3,3,3,5,4,"['Combines Bootstrapped DQN and HER to enhance exploration and exploitation in sparse reward environments.', 'Introduces a novel counterintuitive prioritization mechanism.', 'Empirical results show improved performance over existing methods in several goal-conditioned tasks.', 'Clear problem definition and motivation.']","['Lacks a robust theoretical foundation for the counterintuitive prioritization mechanism.', 'Some sections are dense and could benefit from clearer explanations.', 'Limited novelty as it mainly combines established techniques.', 'Heavy reliance on empirical results without deep theoretical insights.', 'Complexity of the method may hinder easy adoption.', 'Insufficient details on hyperparameter tuning and evaluation metrics.', 'Potential limitations and ethical concerns are not adequately addressed.']",3,3,3,3,Reject
lQI_mZjvBxj,"The paper proposes a model-agnostic federated learning framework using knowledge distillation (KD). It introduces a theoretical framework for federated kernel ridge regression to analyze KD-based federated learning protocols, emphasizing model and data heterogeneity. The paper identifies significant performance degradation in alternating KD (AKD) and suggests averaged KD (AvgKD) and ensembling methods (EKD) to mitigate these issues. The empirical results on synthetic and real-world datasets validate the theoretical insights but do not achieve satisfactory performance.","['How can the proposed ensembling method (EKD) be made more practical for real-world applications?', 'Are there any alternative methods to address the performance degradation in KD under data heterogeneity?', 'Can the scalability and privacy concerns be further elaborated and addressed?', 'Can the authors provide more insights into the scalability of their proposed methods in large-scale federated learning scenarios?', 'How do the proposed methods compare with state-of-the-art federated learning techniques in terms of communication efficiency and computational overhead?', 'Can the authors discuss potential optimizations to improve the empirical performance of their methods?', 'How can the proposed methods be improved to achieve satisfactory performance in practical settings?', 'Can the theoretical analysis be simplified or better explained to enhance accessibility?', 'Are there alternative approaches to overcome the limitations of KD under data heterogeneity without requiring large ensembles?', 'Can the authors provide more insights into the practical applicability of the proposed methods?']","['The paper acknowledges the unsatisfactory performance of the proposed methods.', 'Potential scalability and privacy concerns due to the need for all-to-all communication and large ensembles.', 'Limited applicability to real-world complex datasets.', 'The proposed methods require high computational and communication costs, limiting their practicality.', 'The empirical performance does not show significant improvements over existing federated learning techniques.', 'The experiments are preliminary and not conducted on real-world complex datasets.', 'Potential negative societal impacts, such as increased energy consumption and privacy risks, are not explicitly discussed.']",False,2,3,2,4,4,"['Novel approach to model-agnostic federated learning using KD.', 'Comprehensive theoretical analysis using federated kernel ridge regression.', 'Identification of performance degradation issues in KD under data heterogeneity.', 'Clear and well-organized presentation.']","['Empirical results are unsatisfactory and do not achieve significant improvements.', 'The proposed ensembling method (EKD) requires large ensembles, which may not be practical.', 'Limited real-world applicability due to the need for large ensembles and unsatisfactory performance.', 'Potential scalability and privacy concerns not fully addressed.', 'High computational and communication costs, making the methods impractical for real-world applications.', 'Theoretical analysis is complex and may limit accessibility to a broader audience.']",3,2,3,2,Reject
OWZVD-l-ZrC,"The paper presents RUNE, an exploration method for preference-based reinforcement learning (RL) that uses uncertainty in learned reward functions as an intrinsic reward. The approach aims to improve feedback- and sample-efficiency in preference-based RL algorithms by encouraging exploration in regions with high uncertainty in human feedback. The method is tested on various tasks from the MetaWorld benchmarks, showing empirical improvements over existing methods.","['How does the method perform on a more diverse set of tasks beyond MetaWorld benchmarks?', 'Can the authors provide more details on the hyperparameter tuning process?', 'How sensitive is the method to the number of reward function ensembles?', 'Can the authors clarify the computational overhead introduced by maintaining and updating the ensemble of reward functions?', 'Can you provide more theoretical insights into why reward uncertainty should effectively guide exploration in preference-based RL?', 'How do you anticipate the method will perform in domains beyond robotic manipulation?', 'Can you clarify some technical details, such as the specific implementation of the intrinsic reward calculation?', 'How does RUNE perform compared to the latest state-of-the-art methods not included in the paper?', 'Can you provide more detailed explanations of the methodology, particularly the calculation of intrinsic rewards?', 'What are the potential downsides or limitations of using ensembles for reward uncertainty?', 'How robust is RUNE to noisy or inconsistent human feedback?']","['The method relies heavily on the quality of the human feedback, which can be noisy or inconsistent.', 'The computational cost of maintaining multiple reward models may be significant.', 'Potential negative societal impact includes the misuse of RL agents trained with biased or flawed human feedback.', 'The paper does not address potential limitations related to computational complexity or scalability to larger state-action spaces.', 'The societal impact of the work is not discussed, particularly in terms of how it might be applied in real-world human-guided RL systems.']",False,3,3,3,5,4,"['Addresses a practical issue in preference-based RL by focusing on feedback- and sample-efficiency.', 'Incorporates a novel exploration bonus based on reward uncertainty.', 'Shows improvement over existing methods in experimental results.', 'Comprehensive experiments on MetaWorld benchmarks.']","['The novelty is limited as it combines existing ideas of ensemble learning and intrinsic rewards.', 'The clarity of the methodology section is lacking, making it difficult to reproduce the results.', 'The experiments are limited to a narrow set of tasks from MetaWorld benchmarks and do not cover a diverse range of environments.', 'Theoretical justification for the effectiveness of reward uncertainty in guiding exploration is not deeply explored.', 'Insufficient discussion of the limitations and potential drawbacks of RUNE.', 'Lacks discussion on potential negative societal impacts.']",3,3,3,3,Reject
ghTlLwlBS-,"The paper introduces a Feudal Reinforcement Learning (FRL) model designed to bridge the gap between high-level language instructions and low-level actions in reinforcement learning tasks. The model employs a hierarchical structure with a manager agent generating sub-goals and a worker agent executing low-level actions to achieve these sub-goals. The approach is validated on two benchmarks, RTFM and Messenger, without the need for human-designed curriculum learning.","['Can the authors provide more detailed explanations and possibly visual aids to clarify the methodology?', 'What are the specific hyperparameters used during training for both the manager and the worker agents?', 'How do the authors address the potential scalability issues of their approach to more complex environments?', 'Can the authors provide more insights into the error propagation issue mentioned and how it might be mitigated in future work?', 'How does the approach generalize to more complex environments with noisier text and longer reasoning sequences?', 'What are the specific limitations of the approach in real-world applications?', 'How does the proposed approach compare with more recent baselines in the field?', 'What are the computational costs associated with training and deploying the proposed model?', 'What steps can be taken to ensure reproducibility of the results?', 'How does the model handle noisy or ambiguous texts in real-world scenarios?']","['The paper does not adequately address the limitations, particularly in terms of scalability to more complex environments.', 'Potential negative societal impacts are not discussed, such as the misuse of the technology in automated decision-making systems.', 'The method has not been tested in more complex real-world tasks where texts may be noisier and reasoning sequences longer.', 'Potential error propagation in sub-goal generation by the manager in noisy or complex environments.', 'The approach might not generalize well to real-world applications with noisy texts and long reasoning sequences.', 'The complexity of the model may hinder its applicability and reproducibility.']",False,2,2,3,5,4,"['Innovative hierarchical structure combining high-level planning and low-level execution.', 'Demonstrated competitive performance on challenging benchmarks (RTFM and Messenger).', 'Reduction in the need for human-designed curriculum learning.']","['The clarity of the methodology section is compromised by dense technical jargon and lack of clear explanations.', 'Experimental results, while promising, lack comprehensive statistical significance analysis.', 'Insufficient discussion on the limitations and potential negative societal impacts of the proposed approach.', 'Reproducibility is limited due to vague descriptions of training details and hyperparameters.', 'Lacks a significant novelty in methodology, mainly combining known techniques.']",3,2,2,3,Reject
aq6mqSkwApo,"The paper introduces Meta-OLE, a geometry-regularized method for few-shot image classification. It learns feature spaces with inter-class orthogonality and intra-class low-rankness, and adapts lightweight transformations for novel tasks. The approach also leverages query data for label propagation. The method achieves superior performance on few-shot image classification tasks compared to state-of-the-art methods.","['Can the authors provide more detailed implementation steps to enhance reproducibility?', 'How sensitive is the performance to different hyperparameter settings?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the authors provide more theoretical justification for the choice of orthogonal low-rank embedding?', 'Could the authors include additional ablation studies to evaluate the impact of different components of the method?', 'Can the authors provide more details on the hyperparameters and training protocols used in the experiments to improve reproducibility?', 'How does the method perform in few-shot learning tasks with different configurations (e.g., varying the number of classes and shots)?', 'Can the authors clarify the computational complexity of the proposed method compared to state-of-the-art methods?', 'How does the method perform with larger datasets and higher-dimensional feature spaces?', 'Can the authors clarify the process of adaptive subspace projections and its impact on classification performance?', 'How does the method perform with different network architectures beyond Conv-4 and ResNet?', 'How were the hyperparameters chosen, and what is their impact on the final performance?']","['The paper does not address the potential negative societal impacts of the proposed method.', 'Discussion on the limitations of the approach, such as scalability and computational cost, is minimal.', 'The method may not generalize well to tasks with significant domain shifts, as the evaluation is primarily on standard benchmarks.', 'The computational complexity of the method is not discussed, which could be a limitation for large-scale applications.', ""The method's performance in real-world applications beyond standard benchmarks is not evaluated."", 'The scalability of the method to larger datasets and more complex network architectures is not well-addressed.', 'The hyperparameter selection process is not clearly explained.']",False,3,2,3,6,4,"['Novel combination of orthogonal low-rank embedding with meta-learning.', 'Theoretical justification for the proposed geometry-regularized feature space.', 'Empirical results show superior performance on standard few-shot learning benchmarks.', 'Utilizes unlabeled data for transductive learning without auxiliary components.', 'Comprehensive experimental validation demonstrating superior performance.', 'Detailed ablation studies and discussions on hyperparameter selections.']","['Clarity of the paper is lacking in some sections, making it difficult to follow.', 'Reproducibility is hindered by insufficient implementation details.', 'Potential limitations and negative societal impacts are not adequately addressed.', 'The choice of certain hyperparameters and their impact on results need more justification.', 'Theoretical foundation for the proposed method is not thoroughly explored.', 'More comparisons with state-of-the-art methods in different settings could strengthen the claims.', 'The proposed method might be complex and not easily reproducible without significant effort.', 'Potential scalability issues with large datasets or higher dimensions.']",3,3,2,3,Reject
eMudnJsb1T5,"The paper introduces a new family of particle evolution samplers suitable for constrained domains and non-Euclidean geometries. The proposed methods, including Stein Variational Mirror Descent (SVMD), Mirrored Stein Variational Gradient Descent (MSVGD), and Stein Variational Natural Gradient (SVNG), aim to improve the approximation of target distributions by evolving particles in a dual space defined by a mirror map. The paper provides theoretical derivations, convergence proofs, and experimental results demonstrating the effectiveness of these new samplers.","['How do the proposed methods compare with the latest advancements in mirror descent and Stein operators?', 'Can the authors elaborate on the computational complexity and feasibility of the algorithms in large-scale applications?', 'What are the specific assumptions made in the theoretical proofs, and how do they impact the generalizability of the results?', 'Can the authors provide a more detailed discussion on the limitations and potential negative societal impacts of their work?', 'Can the authors provide more real-world application examples to demonstrate the practical impact of their methods?', 'What are the computational costs of the proposed methods compared to existing techniques in more detail?', 'How do the proposed methods perform in a wider range of benchmarks, particularly those with different types of constraints?', 'Can the experimental results be replicated, and are the implementations publicly available for verification?']","['The complexity of the algorithms may pose challenges for large-scale applications.', 'The theoretical proofs rely on specific assumptions that may limit the generalizability of the results.', 'The potential negative societal impacts of the proposed methods are not thoroughly discussed.', 'The convergence guarantees are provided under certain conditions which may not always hold in practical scenarios.', 'The application scope is somewhat limited to problems with specific geometric constraints.']",False,3,3,3,4,4,"['Introduces novel methods for particle evolution samplers in constrained and non-Euclidean spaces.', 'Provides theoretical derivations and convergence proofs.', 'Demonstrates the effectiveness of the proposed methods through extensive experiments.', 'Addresses limitations of standard SVGD in constrained domains and non-Euclidean geometries.']","['The novelty of the proposed methods needs careful assessment against existing literature.', 'Complexity and feasibility of the algorithms in large-scale applications are not thoroughly discussed.', 'Clarity of the theoretical proofs and assumptions made should be checked.', 'Dense technical content may be difficult for some readers to follow.', 'Limited discussion on the scalability of the proposed methods for large-scale problems.', 'Insufficient discussion on the limitations and potential negative societal impacts of the proposed methods.']",4,3,2,3,Reject
VNdFPD5wqjh,"The paper proposes Unit DRO, a novel approach for generalizable person re-identification (ReID) that does not rely on demographics such as domain labels or camera IDs. Instead, it employs a distributionally robust optimization (DRO) framework to handle distribution shifts. The method reweights important samples during training to improve generalization. The authors claim superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to existing methods.","['Can the authors provide more detailed explanations and intuitive insights into the mathematical formulations, especially the change-of-measure technique?', 'How do the authors ensure fair comparison with baselines that might use demographics data?', 'Can the authors provide more details on the hyperparameter tuning and its impact on the results?', 'What are the potential limitations of the proposed Unit DRO in practical scenarios?', 'How does Unit DRO perform on a wider range of datasets, particularly those with different characteristics from the ones used in the paper?', 'Can the authors provide additional experiments to evaluate the robustness of Unit DRO across various real-world scenarios?', 'How does the choice of datasets impact the generalizability of the proposed method?', 'Can the authors discuss potential limitations and negative societal impacts of their work in more detail?', 'Can the authors provide a detailed theoretical analysis and convergence guarantees for Unit DRO?', 'How are the hyperparameters for Unit DRO selected and justified?', 'Can the authors provide more details on the experimental setup, including the exact data splits and preprocessing steps?']","['The method may still require significant computational resources due to the reweighting mechanism.', 'The robustness of the approach across various real-world scenarios, where distribution shifts might be more complex, is not fully explored.', 'Potential ethical concerns related to the re-identification task itself are not discussed.', 'The paper does not fully explore the potential negative societal impacts of removing demographic considerations in sensitive applications like security.', 'Given the complexity of the proposed method, practical implementation details and computational costs are not discussed in depth.', ""The method's reliance on historical weights may introduce bias if the data distribution significantly changes over time."", 'The approach may not generalize well to other tasks beyond person ReID.', 'Potential negative societal impacts related to the use of person ReID technology are not addressed.']",False,3,2,3,5,4,"['Addresses a relevant problem of ReID without requiring demographics, which is important for privacy concerns.', 'Proposes a novel approach by reformulating DRO, which avoids complex bi-level optimization and scales well to over-parameterized regimes.', 'Empirical results indicate superior performance compared to several baseline methods.', 'Comprehensive ablation studies and visualizations support the effectiveness of the proposed methodology.']","['The mathematical formulations, especially around the reformulation of DRO, are complex and could benefit from clearer explanations and more intuitive insights.', 'The experimental comparisons might not be entirely fair, as the proposed method does not require demographics while baselines might.', 'The paper heavily relies on empirical results without a thorough theoretical grounding in some parts.', 'Some details about the implementation and hyperparameter tuning are missing, which could affect reproducibility.', 'The novelty of the approach seems incremental, heavily relying on existing DRO techniques.', 'Empirical evaluations lack thoroughness, especially in terms of hyperparameter sensitivity and comparison with more recent state-of-the-art methods.', 'The paper is dense with mathematical formulations, making it difficult to follow for readers unfamiliar with DRO.', 'Insufficient discussion on the ethical implications of using such models in sensitive applications.', 'Evaluation needs more diversity in datasets and settings to substantiate generalization claims.', 'Formatting issues make the paper less readable.', 'Theoretical justifications for some choices are not robustly argued.', 'Experimental setup could be more transparent.']",3,3,2,3,Reject
_j4hwbj6Opj,"The paper proposes a novel approach to 3D point cloud registration by formalizing it as a meta-learning problem. It introduces a 3D registration meta-learner to predict an optimal structure for the 3D registration learner, enabling it to quickly adapt to new point clouds with limited training data. The approach is tested on the ModelNet, FlyingThings3D, and KITTI datasets, demonstrating superior performance compared to existing methods.","['Can the authors provide more insights into the choice of hyperparameters, such as the region numbers in the dataset and the balance terms in the loss function?', 'How does the performance of the meta-learner change with varying amounts of training data?', 'Are there any specific failure cases or limitations of the proposed approach that the authors observed during their experiments?', 'What is the computational overhead introduced by the meta-learning framework compared to traditional methods?', 'Could the authors provide more insight into the scalability of the proposed method for larger datasets?', 'Can the authors clarify the notation used in the methodology section?', 'How does the proposed method handle extreme cases of noise or incomplete data in real-world scenarios?', 'What are the computational requirements and time complexity for training and inference using the proposed method?', 'Could you provide more detailed explanations for the loss function and the architecture of the meta-learner?', 'Why were certain baselines chosen for comparison, and how were the hyperparameters tuned for these baselines?', 'Could you justify the choice of datasets and the noise models used for the experiments?']","['The paper does not adequately address the potential limitations and negative societal impacts.', 'There should be a discussion on the possible biases introduced by the training datasets and the generalizability of the method across different types of 3D data.', 'The paper does not thoroughly discuss the potential computational overhead of the meta-learning framework.', 'There is a lack of clarity on how the proposed method scales with increasing data size and complexity.', 'The ethical considerations related to the misuse of 3D registration technology are not addressed.']",False,3,2,3,6,4,"['The paper introduces a novel meta-learning approach for 3D point cloud registration.', 'Experimental results show superior performance on ModelNet, FlyingThings3D, and KITTI datasets.', 'The methodology is detailed and technically sound.', 'Comprehensive evaluation on synthetic and real-world datasets.']","[""The paper's clarity and organization could be improved, making it easier to follow."", 'A more extensive discussion on the choice of evaluation metrics is needed.', 'The comparative analysis with state-of-the-art methods could be more in-depth.', 'Limited explanation of the hyperparameter choices and their impact on performance.', 'The complexity introduced by meta-learning might not be justified if simpler methods achieve comparable results.', 'Potential lack of discussion on computational overhead and scalability.']",3,3,2,3,Reject
iEvAf8i6JjO,The paper proposes Trust Region Gradient Projection (TRGP) for continual learning to address catastrophic forgetting and promote forward knowledge transfer. It introduces the notion of 'trust region' to select related old tasks and uses scaled weight projection to reuse frozen weights of selected old tasks. Extensive experiments show significant improvements over state-of-the-art methods.,"['Can you provide more theoretical backing or proofs for the effectiveness of the trust region and scaled weight projection?', 'How sensitive is TRGP to the choice of hyperparameters like the threshold ε?', 'Can you elaborate on the potential limitations of TRGP beyond the benchmarks tested?', ""Can the authors provide a more intuitive explanation of the 'trust region' concept?"", 'What are the potential limitations and negative societal impacts of the proposed method?', 'How does the scaling matrix initialization affect the performance of TRGP?', 'Can you provide more explicit comparisons and discussions on how TRGP differs from GPM?', 'How does the choice of hyperparameters (e.g., threshold ε) affect the performance?', 'Can you provide more details on the scalability of TRGP to larger datasets and more complex tasks?', 'What is the computational overhead of TRGP compared to other methods?', 'How does the method perform with a larger number of tasks (e.g., >20)?', 'Can the approach be generalized to other types of neural networks beyond those tested?', 'Can the authors provide more detailed explanations for the mathematical notations used in the trust region and scaled weight projection sections?', 'How does TRGP perform in real-world continual learning scenarios beyond standard benchmarks?', 'What are the computational overheads of TRGP compared to simpler methods?']","['The paper does not discuss the potential computational overhead introduced by the additional scaling matrices.', ""The method's applicability to real-world scenarios with non-synthetic data is not explored."", 'The scalability to a larger number of tasks is not discussed.', 'The impact of the chosen threshold and number of selected tasks on the overall performance could be further analyzed.', 'Potential negative societal impacts of the continual learning application are not considered.', 'Potential negative societal impacts are not discussed, such as biases in continual learning and their propagation.']",False,3,3,3,5,4,"['Novel concept of trust region based on gradient projection.', 'Extensive experimental validation with significant improvements over state-of-the-art methods.', 'Broad evaluation on multiple benchmarks.', 'Clear improvement metrics over existing methods.', 'Method does not require access to old task data, which is a practical advantage.']","['Lacks thorough theoretical analysis and rigorous proof of claims.', 'Complex and dense explanation of the methodology, hindering reproducibility.', 'Inadequate addressing of limitations and potential negative societal impacts.', 'Dense mathematical formulations that may be hard to follow for some readers.', 'The connection to existing methods like GPM needs to be more explicitly discussed.', 'Practical applicability and scalability to larger datasets and more complex tasks need further validation.']",3,3,3,3,Reject
ptZfV8tJbpe,The paper presents a novel approach for Multi-Label Text Classification (MLTC) using latent label encodings to model label correlations implicitly. The method involves concatenating a set of latent labels to text tokens and inputting them to BERT. The correlations between labels and between labels and text are modeled indirectly through these latent-label encodings. The approach aims to provide more flexibility and reduce inductive biases present in previous methods. The paper reports significant improvements over state-of-the-art results on two benchmark datasets: AAPD and RCV1-V2.,"['Can the authors provide more details on how the latent labels correlate with actual labels and the text context?', 'What are the potential negative societal impacts of this work?', 'Are there any specific scenarios where this method may not perform well compared to existing methods?', 'Can the authors provide a more detailed theoretical analysis to support the empirical findings?', 'Have the authors considered evaluating the approach on diverse datasets to validate its generalizability?', 'Can the authors provide a clearer explanation of the methodology, possibly with visual aids or diagrams?', 'How does the proposed method perform on datasets with a significantly different structure or context?', 'What are the potential limitations regarding the scalability of the method to very large label sets?', 'Can the authors provide more details on the hyperparameter selection process?', 'How does the method perform on other datasets or in different domains?', 'Can the authors clarify the computational overhead introduced by the latent label encodings?']","['The paper does not provide a detailed discussion on the potential negative societal impacts of the work.', 'There is a need for further clarity on the interpretation of latent labels.', 'The method might introduce additional complexity in understanding and debugging the model.', ""The method's performance on datasets with different characteristics (e.g., different domains, varying number of labels) is not evaluated."", 'Potential negative societal impacts are not discussed, such as biases that might be introduced by the model.', 'Limited insights into the interpretability of latent labels.', 'Potential scalability issues with very large label sets.', 'Sensitivity of latent label embeddings to pretraining.']",False,3,2,3,6,4,"['Novel approach using latent label encodings.', 'Significant improvement over state-of-the-art results on benchmark datasets.', 'Thorough experimentation and analysis, including feature studies and error analyses.']","['Complexity in understanding and interpreting latent labels.', 'Limited discussion on potential negative societal impacts.', 'Potential redundancy in explanations, making the paper lengthy and difficult to follow at times.', 'Lack of theoretical analysis to support the empirical findings.', 'Limited evaluation on diverse datasets to validate the generalizability of the approach.']",4,3,2,3,Reject
wQStfB93RZZ,"The paper introduces macro-action-based multi-agent actor-critic methods to address asynchronous decision-making in multi-agent systems. It proposes methods for decentralized learning, centralized learning, and centralized training for decentralized execution (CTDE). Empirical results show that these methods outperform primitive-action-based methods in various domains.","['Can the authors provide more detailed explanations or simplifications for the dense sections?', 'How were the hyperparameters chosen, and can the authors ensure there was no bias in the selection?', 'What are the potential societal impacts of these methods?', 'Can the authors test the methods in more diverse and complex environments?', 'Can the authors clarify the differences between their proposed methods and existing approaches?', 'How do the proposed methods scale with an increasing number of agents and macro-actions?', 'Can the authors discuss the computational cost associated with the proposed methods?', 'Can the authors provide a more detailed theoretical analysis of the proposed methods?', 'How do the methods perform in real-world scenarios beyond the simulated domains?', 'Can the authors discuss the statistical significance of their empirical results and potential overfitting issues?']","['The paper does not discuss potential societal impacts of the proposed methods.', 'The experimental domains are somewhat limited in diversity and complexity.', 'The scalability of the proposed methods with increasing agents and macro-actions is not discussed.', 'The impact of hyperparameter tuning on the results is not thoroughly discussed.', 'Potential negative societal impacts, such as the misuse of multi-agent systems in harmful applications, should be addressed.']",False,3,3,3,7,4,"['Addresses a significant and relevant problem in multi-agent reinforcement learning (MARL) with asynchronous decision-making.', 'Proposes novel methods (Mac-IAC, Mac-CAC, Naive Mac-IACC, and Mac-IAICC) for handling macro-actions.', 'Comprehensive theoretical formulation and empirical evaluation.', 'Promising results in various domains.', 'Clear presentation of methods and results.']","['The paper is dense and could benefit from better organization and clarity.', 'Some experimental details, such as hyperparameters, are buried in the appendix or missing, making it hard to assess reproducibility.', 'The novelty of the proposed methods compared to existing approaches is not sufficiently highlighted.', 'The theoretical framework could be more robust and detailed.', 'The paper does not adequately address potential limitations and societal impacts.']",3,3,3,4,Accept
W9G_ImpHlQd,"This paper presents a novel method to enhance the robustness of black-box machine learning models against adversarial attacks using zeroth-order optimization. The proposed method, ZO-AE-DS, integrates denoised smoothing with zeroth-order optimization and employs an autoencoder to reduce the dimensionality of the data, thereby addressing the high variance in gradient estimates. The paper demonstrates significant improvements in both certified accuracy and standard accuracy across various datasets for image classification and reconstruction tasks.","['Can the authors provide more detailed explanations or visualizations to help understand the mathematical formulations better?', 'How does the proposed method scale with larger datasets and more complex model architectures?', 'Are there any specific limitations or failure cases observed for the proposed method?', 'Can the authors provide more details on the computational overhead introduced by autoencoders?', 'How does the proposed method compare in terms of computational efficiency with other state-of-the-art defenses?', 'Can the authors clarify some of the technical derivations related to zeroth-order optimization?']","['The authors acknowledge the complexity and potential difficulty in reproducing the results.', ""Limited scope of experiments might not fully represent the method's performance in varied real-world scenarios."", 'Potential scalability issues with larger datasets and more complex models.', ""The method's reliance on autoencoders may introduce additional complexity and computational overhead.""]",False,3,3,4,5,4,"['Addresses a relevant and challenging problem of robustifying black-box ML models.', 'Innovative use of zeroth-order optimization combined with denoised smoothing.', 'Empirical results show significant improvements over existing methods.', 'Extensive experiments conducted on multiple datasets and model architectures.']","['The paper is technically dense and may be challenging for readers to reproduce.', 'Clarity of mathematical formulations and explanations can be improved.', 'Limited scope of experiments to specific datasets and architectures.', 'Potential scalability issues due to the complexity of the proposed method.', 'Lacks comprehensive comparison of computational efficiency with other state-of-the-art defenses.']",4,3,3,4,Reject
l431c_2eGO2,"The paper proposes Mix-MaxEnt, a method that adds an entropy maximization regularizer to a deterministic neural network to improve both accuracy and uncertainty estimates. The technique involves generating between-cluster samples through convex combinations of images from different classes and maximizing entropy on these synthetic samples. The method is evaluated on CIFAR-10 and CIFAR-100 datasets using ResNet and Wide-ResNet architectures, showing consistent improvements in accuracy and uncertainty estimation.","['Could the authors provide more rigorous theoretical analysis to support their claims?', 'How does the computational overhead of the proposed method compare to other uncertainty estimation techniques?', 'Could the authors include more recent baselines in their evaluation to provide a more comprehensive comparison?', 'Can the authors clarify the choice of specific uncertainty metrics and discuss their robustness?', 'Would the method generalize to other datasets and architectures beyond CIFAR and ResNet?', 'Can the authors provide statistical significance tests for their experimental results?', 'How does Mix-MaxEnt perform on other datasets beyond CIFAR-10 and CIFAR-100, particularly on larger and more complex datasets?', 'Can the authors discuss any potential negative societal impacts of their method?', 'Could the authors provide more details on the hyperparameter settings used during the experiments?', 'Were there any stability issues observed during the training with the Mix-MaxEnt approach?', 'Have you considered evaluating Mix-MaxEnt on additional datasets beyond CIFAR-10 and CIFAR-100?', 'Can you provide more details on how numerical stability issues with certain metrics were addressed?', 'Will you release the full code and detailed hyperparameters to facilitate reproducibility?', 'Can the authors provide more details on the stability of the feature space density estimation and how it affects the overall performance?', 'Can the authors provide more insights into the hyperparameter sensitivity and suggest ways to mitigate this issue?']","[""The method's effectiveness is demonstrated only on CIFAR-10 and CIFAR-100 datasets, which may not generalize to other datasets or tasks."", 'The paper does not provide a detailed analysis of the computational overhead introduced by the entropy maximization regularizer.', 'Potential issues with the robustness of the chosen uncertainty metrics are not addressed.', 'The paper does not adequately address potential limitations of the method, such as its dependency on the choice of interpolation factor and sensitivity to different datasets.', 'There is limited discussion on how the method scales with larger and more complex datasets.', 'The method relies on synthetic samples which might not always represent OOD data accurately.', 'Scalability to larger, more complex datasets remains unexplored.', 'Numerical stability issues were noted but not fully addressed.', 'The paper relies heavily on extensive hyperparameter tuning, which may limit its practical applicability.', 'The instability of certain metrics, such as feature space density estimation, raises concerns about the robustness of the method.']",False,3,3,3,5,4,"['The idea of using entropy maximization to improve uncertainty estimates is simple yet effective.', 'The method does not require architectural modifications or complex training procedures.', 'Extensive experiments on CIFAR-10 and CIFAR-100 with state-of-the-art architectures demonstrate the effectiveness of the proposed method.', 'Clear improvement in accuracy and uncertainty estimates compared to existing methods.', 'Thorough comparison with numerous baselines and detailed analysis of results.']","['Theoretical backing is insufficient; the paper lacks rigorous theoretical analysis to support the claims.', 'The clarity and organization of the paper could be improved; it is quite dense and hard to follow in parts.', 'The evaluation lacks comparisons with a broader range of baselines, especially recent advancements in uncertainty estimation.', 'The paper does not address potential computational overhead introduced by the additional regularization term.', 'Some of the results, especially in terms of uncertainty estimation, rely heavily on specific metrics which might not be the most robust.', 'Experimental results lack sufficient statistical tests to validate the improvements.', 'Stability and scalability to more complex datasets not thoroughly addressed.', 'Dependence on synthetic samples might limit applicability in certain scenarios.', 'High sensitivity to hyperparameter tuning, which may limit practical applicability.']",3,3,3,3,Reject
z3Tf4kdOE5D,"The paper proposes FEDDISCRETE, a federated learning framework that employs a probabilistic discretization mechanism to defend against weight poisoning attacks. The method transforms the client's model weights into a vector with two discrete values while ensuring unbiased estimation of the model weights at the server. Theoretical analysis and empirical evaluations demonstrate the utility, robustness, and convergence of FEDDISCRETE.","['Can the authors provide a clearer explanation of the discretization mechanism and its implementation?', 'How realistic are the assumptions made in the theoretical analysis?', 'Can the evaluation be extended to include more baselines and scenarios?', 'What impact does the discretization have on model performance in varied practical settings?', 'How practical and scalable is the proposed method in real-world heterogeneous environments?', 'Can the authors provide more intuitive explanations or summaries for the theoretical analyses?', 'Have the authors considered testing their approach on a wider variety of datasets and attack scenarios?', 'How does the communication overhead of FEDDISCRETE compare with existing methods, particularly in a real-world deployment scenario?', 'Can you provide more detailed comparisons with state-of-the-art methods in empirical evaluations?', 'How does the proposed method scale with a very large number of clients, such as in real-world FL scenarios?', 'Can you clarify the assumptions made in the theoretical analysis, particularly regarding the smoothness and bounded dissimilarity conditions?', 'Can the authors provide more details on the computational overhead introduced by the discretization mechanism?', 'How does the variance of the estimator impact the overall model performance in practice?', 'Can the method be adapted or extended to be more suitable for cross-silo federated learning?', 'Can the authors simplify the theoretical sections or provide more intuitive insights?', 'What are the potential limitations and negative societal impacts of the proposed method?']","['The method may not work well in cross-silo federated learning settings.', 'The empirical evaluation is limited to image classification datasets.', 'The variance of the estimator could be large, requiring further analysis or mitigation strategies.', 'The method could not defend against Byzantine attacks through the proposed discretization mechanism.']",False,3,3,3,5,4,"['Novel application of discretization to federated learning for defense against weight poisoning attacks.', 'Thorough theoretical analysis of utility, robustness, and convergence.', 'Empirical evaluation shows promising results on image classification datasets.']","['Theoretical sections are dense and difficult to follow.', 'Empirical evaluation is limited to image classification datasets and does not cover other types of data or tasks.', 'Comparison with more recent defense mechanisms is lacking.', 'Practicality and scalability in real-world scenarios with large numbers of clients are not fully addressed.', 'Restrictive assumptions in the theoretical analysis.']",3,3,3,3,Reject
a34GrNaYEcS,"The paper introduces RP-DRO, a novel approach to Distributionally Robust Optimization (DRO) using parametric likelihood ratios. The method aims to enhance robustness to distribution shifts without relying heavily on generative models. Key innovations include mini-batch normalization, KL penalty, and simultaneous gradient updates. The method is evaluated on image and text classification tasks, showing improvements in robust accuracy over existing DRO methods.","['Can the authors provide more details on how the parametric likelihood ratios are initialized and optimized?', 'How does the performance of RP-DRO compare to nonparametric methods in terms of computational efficiency?', 'Can the authors elaborate on the potential negative societal impacts of their method, particularly in terms of fairness and bias?', 'Can you provide more detailed theoretical analysis to support your empirical findings?', 'How do you justify the specific choices of datasets and hyper-parameter settings?', 'Can you provide a more comprehensive comparison to other state-of-the-art DRO methods?', 'How does the performance of RP-DRO vary with different batch sizes, specifically in real-world applications?', 'Can the authors clarify the implementation details for mini-batch normalization and simultaneous gradient updates?', 'How sensitive is the approach to the choice of hyper-parameters, and what strategies can be employed to mitigate this?', 'Are there theoretical guarantees for the stability and convergence of the proposed method?']","['The method introduces significant computational overhead due to the joint training of an adversary model.', 'Potential negative societal impacts, such as increased computational cost and environmental impact, are not thoroughly discussed.', 'The complexity of the approach may hinder its adoption in practical scenarios.', ""The method's reliance on mini-batch normalization may not scale well to very large datasets.""]",False,3,2,3,5,4,"['Novel approach to DRO using parametric likelihood ratios.', 'Thorough experimental evaluation on multiple datasets.', 'Demonstrated improvements in robust accuracy over existing methods.', 'Addresses a significant problem in machine learning.']","['Complexity of the proposed method may limit its practical applicability.', 'Significant computational overhead due to the joint training of an adversary model.', 'Insufficient clarity in some sections, particularly in the theoretical formulation and experimental setup.', 'Lack of detailed theoretical analysis.', 'Limited discussion on potential negative societal impacts.']",3,3,3,3,Reject
izvwgBic9q,"The paper investigates unsupervised learning of Full-Waveform Inversion (FWI) by integrating convolutional neural networks (CNN) and partial differential equations (PDE) in a loop. This novel approach transforms the supervised inversion task into an unsupervised seismic data reconstruction task, requiring only seismic data. The paper also introduces a new large-scale dataset, OpenFWI, to establish a benchmark for the FWI community. Experimental results demonstrate that the proposed model achieves comparable accuracy to supervised methods and even outperforms them when more seismic data is provided.","['Can the authors provide more details on the computational requirements and efficiency of their approach?', 'How does the method perform on real-world seismic data as opposed to synthetic data?', 'Can the authors elaborate on the specific challenges and limitations encountered when dealing with velocity maps where adjacent layers have very close velocity values?']","['The method requires significant computational resources for forward modeling due to the need to store gradients for backpropagation.', 'There is a lack of validation on real-world seismic data, which is critical for assessing practical applicability.', 'The approach may struggle with velocity maps where adjacent layers have very close velocity values.']",False,3,3,3,6,4,"['Novel integration of CNN and PDE for unsupervised FWI.', 'Introduces a new large-scale dataset, OpenFWI, for benchmarking.', 'Promising experimental results showing comparable or superior performance to supervised methods.', 'Addresses the practical challenge of acquiring velocity maps.']","['Lack of detailed explanation on some critical implementation aspects.', 'Potential limitations regarding computational resources (speed and memory).', 'Needs further validation on real-world data.', 'Some results, particularly on more challenging datasets, show significant errors.']",4,3,3,4,Accept
7pZiaojaVGU,The paper establishes an equivalence between data poisoning and Byzantine gradient attacks in personalized federated learning. It introduces a practical attack method called the counter-gradient attack (CGA) and demonstrates its effectiveness through theoretical analysis and empirical results.,"['Can the authors provide more detailed explanations of the experimental setup and results?', 'How do the proposed attacks compare to existing attacks in terms of effectiveness and difficulty of detection?', 'What are some potential mitigation strategies for the proposed attacks?', 'Can the authors discuss the practical implications of their findings in more detail?', 'Can the authors provide more insights into the potential gaps or assumptions in the theoretical proofs?', 'How do the practical experiments generalize across different federated learning scenarios?', 'Can the authors elaborate on the potential misuse of the proposed attacks and mitigation strategies?', 'What are the scalability concerns and real-world applicability of the proposed attacks?', 'Can the authors provide more extensive empirical validation of the counter-gradient attack in diverse federated learning scenarios?', 'How can the proposed methods be applied in real-world federated learning systems, and what are the practical challenges involved?', 'Can the authors improve the clarity of the proofs and theoretical sections to make them more accessible to a broader audience?', 'How robust is the proposed attack method to variations in the federated learning setup?', 'What are the potential real-world implications of this equivalence? Are there any mitigations possible?', 'Can the authors provide more detailed explanations or visual aids for the complex mathematical proofs?', 'Are there additional datasets or settings where the proposed attacks could be evaluated to demonstrate generalizability?', 'Can the authors provide a more detailed reproducibility checklist or guidelines to ensure other researchers can replicate the experiments?']","['The paper could explore practical implications and potential mitigation strategies in more detail.', 'The complex proofs and dense content may be difficult for readers to follow without additional context or simplification.', 'The scalability of the proposed attacks in real-world federated learning environments is not thoroughly discussed.', 'Potential negative societal impacts, such as misuse of the proposed attacks, need more attention.', 'The empirical evaluation is limited and does not comprehensively demonstrate the practical effectiveness of the proposed methods.', 'The clarity of the theoretical sections and proofs can be improved for better readability.', 'Practical utility and implications in real-world federated learning scenarios are not fully explored.', 'The empirical results are based on specific datasets and models, which might limit the generalizability of the findings.', 'The discussion on ethical concerns and potential negative societal impacts is minimal.', 'The equivalence might not hold in all settings or with different regularization terms.', 'The practical implementation of CGA might be challenging in real-world federated learning systems.']",False,3,3,3,6,4,"['Establishes a novel and impactful equivalence between data poisoning and Byzantine gradient attacks.', 'Provides rigorous theoretical proofs and thorough empirical evaluation.', 'Introduces a practical attack method (CGA) and demonstrates its effectiveness.', 'Discusses ethical considerations and the importance of algorithmic safety.']","['The paper is dense and complex, making it difficult for readers to follow without additional context or simplification.', 'The experimental setup and results could be explained more clearly.', 'Practical implications of the attacks and potential mitigation strategies are not fully explored.', 'The paper could benefit from more detailed discussions on related work and how this work advances the field.', 'Empirical validation is limited and not comprehensive enough to demonstrate practical effectiveness.', 'Some sections, particularly the proofs, are not as clearly written and may be difficult to follow for some readers.', 'Potential misuse of the proposed attacks is not thoroughly discussed.', 'More discussion on the scalability and real-world applicability of the attacks is needed.']",4,3,3,4,Accept
30SXt3-vvnM,"The paper introduces a kernelized classification layer for deep neural networks, which optimizes over all possible radial kernel functions to find an optimal nonlinear classifier. The proposed method aims to utilize embeddings from lightweight networks more effectively, thereby improving model efficiency without increasing the backbone complexity. Theoretical justifications and empirical evaluations are provided across various tasks, including image classification, natural language understanding, knowledge distillation, and active learning.","['Can the authors provide more comparisons with recent state-of-the-art methods?', 'How does the method scale with much larger datasets, both in terms of computational complexity and memory usage?', 'Can the authors provide more intuitive explanations or visual aids to help understand the theoretical concepts?', 'Can the authors provide more details on the computational overhead introduced by the kernelized classification layer in practical scenarios?', 'Could the proposed method be applied to other types of neural networks beyond those mentioned (e.g., RNNs for sequence data)?', 'How does the choice of M (the number of terms in the kernel approximation) affect performance in more complex tasks beyond CIFAR-10/100?']","['The paper does not address the potential negative societal impacts or ethical concerns related to the method.', 'Scalability and practical deployment issues need more discussion.', 'The method introduces additional parameters and computational complexity, which could be a concern for deployment in resource-constrained environments.', 'The paper does not extensively address potential biases introduced by the kernelized classifier or its impact on fairness in classification tasks.']",False,3,3,3,6,4,"['Provides a novel approach to leveraging kernel methods within deep learning frameworks.', 'Theoretical foundations are well-detailed and mathematically sound.', 'Experiments show consistent improvements over standard softmax classifiers in multiple tasks.', 'The method is complementary to existing model compression techniques, such as pruning and distillation.']","['The novelty of the approach is somewhat limited as kernel methods in deep learning are not entirely new.', 'Experiments are not sufficiently diverse; more datasets and comparisons with additional baselines are needed.', 'Practical implications and scalability of the method in real-world applications are not thoroughly discussed.', 'The paper is dense with theoretical details, which might impede comprehension for non-expert readers.', 'The impact of kernel choice might be overemphasized, and more ablation studies on different kernel functions could strengthen the claims.']",3,3,3,3,Reject
WxuE_JWxjkW,"The paper explores the expressivity of emergent languages in deep learning-based referential games, proposing that expressivity is a trade-off between contextual complexity and unpredictability. It introduces a novel measure of expressivity and addresses the issue of message type collapse using contrastive loss. The work is evaluated through a series of language transfer experiments.","['Can you provide more detailed explanations or examples to clarify the mathematical formulations used in the paper?', 'How do you envision the practical applications of this research in real-world AI systems?', 'Have you considered other types of games or tasks to further validate the findings?', 'Can the authors provide more details on how the contrastive loss was adapted specifically for their experiments?', 'How does the proposed measure of expressivity compare to other potential metrics?', 'Can the authors offer more insight into the unexpected finding of high redundancy in simple settings?', 'How does this work significantly differ from existing studies on emergent languages in referential games?', 'How were the hyperparameters chosen for the experiments, and how robust are the results to these choices?', 'Can the authors clarify the limitations of their approach and potential negative societal impacts?']","['The study is limited to referential games and may not generalize well to other types of language games or tasks.', 'The notion of message type collapse and its mitigation is specific to the experimental setup and may not be broadly applicable.', 'Potential negative societal impacts, such as misuse in adversarial settings, are not discussed.', 'Limited generalizability due to specific experimental setups.', 'Methodological complexity may hinder reproducibility.', ""Insufficient exploration of the implications of 'message type collapse'."", 'The societal impact of emergent languages and their applications should be addressed.']",False,2,2,3,4,4,"['Novel hypothesis on the trade-off between contextual complexity and unpredictability.', 'Introduction of a new measure for expressivity.', 'Thorough experimental validation.', ""Discovery and addressing of 'message type collapse'.""]","['Limited novelty in the hypothesis; the trade-off between complexity and unpredictability is somewhat intuitive and has been explored in other contexts.', 'Lacks clarity in several sections, making it difficult to follow.', 'Insufficient comparison with baseline methods.', 'Limited significance and impact on advancing the state of the art.', 'Some results and claims are not well-supported by the experiments.', 'The experimental results, while robust, may not fully capture the diversity of real-world scenarios.']",3,2,2,3,Reject
MvO2t0vbs4-,"The paper presents an extensive empirical analysis of the efficiency of committee-based models (ensembles and cascades) compared to single deep models. The authors demonstrate that even simple committee-based models can match or exceed the accuracy of state-of-the-art architectures while being more efficient. The findings are validated across multiple tasks and architecture families, including image classification, video classification, and semantic segmentation.","['How do the authors ensure that the empirical results are generalizable to other datasets and tasks not covered in the paper?', 'Can the authors provide more details on the computational resources required for the experiments?', 'Can the authors provide more theoretical insights into why committee-based models perform better in terms of efficiency and accuracy?', 'How do the specific design choices (e.g., thresholds for cascades) impact the results? Can these be generalized?', 'Can the authors clarify the methodology section to make the procedures more reproducible?', 'Can the authors clarify the specific scenarios where committee-based models are most beneficial compared to single models?', 'How do the proposed methods handle potential overfitting in the context of ensembles and cascades?', 'Can the authors provide more details on the computational complexity and practical implementation of the cascades?', 'How does the proposed approach compare to other state-of-the-art ensemble methods not mentioned in the paper?', 'Is there any specific reason why the authors did not include a comparison with more recent, sophisticated ensemble techniques?', 'Can the authors provide more details on the specific configurations and hyperparameters used for training the individual models in the ensembles and cascades?', 'How do the authors ensure that their results are not influenced by specific random initializations or other experimental artifacts?', 'Can the authors clarify the decision-making process for selecting the confidence thresholds in the cascades?']","['The paper does not address the potential limitations of using committee-based models, such as increased memory usage and complexity.', 'There is limited discussion on the potential negative societal impacts, such as increased energy consumption.', 'The work heavily relies on empirical results, potentially limiting generalizability.', 'The paper does not propose any novel methods, which may limit its impact in terms of advancing the field theoretically.', 'Potential negative societal impacts are not discussed, particularly regarding the computational cost of training multiple models.']",False,3,3,3,6,4,"['Comprehensive empirical analysis across multiple architectures and tasks.', 'Demonstrates significant improvements in computational efficiency and accuracy.', 'Provides practical insights into the use of committee-based models for real-world applications.']","['Lacks novelty as it primarily revisits known techniques rather than proposing new methods.', 'Heavy reliance on empirical results without deep theoretical insights.', 'Some sections are dense and could benefit from clearer exposition and organization.', 'The paper could include more discussion on potential limitations and negative societal impacts.']",3,3,3,3,Reject
IptBMO1AR5g,"The paper introduces a novel regularization method for deep neural networks by penalizing the trace of the Hessian matrix using stochastic estimators, named SEHT. The authors provide theoretical motivation based on generalization error bounds and stability analysis and support their claims with empirical results on image classification and language modeling tasks.","['Can the authors provide more detailed ablation studies to isolate the effects of different components of SEHT?', 'How does SEHT perform on larger datasets and more complex models?', 'Can the authors clarify the theoretical motivations, specifically the connection between Hessian trace regularization and stability analysis?', 'Can the authors provide more intuitive explanations for the key theoretical concepts introduced?', 'Are there specific failure cases or limitations where SEHT does not perform well?', 'Could the computational cost be elaborated with more comparisons to existing methods?', 'Can the authors provide a more detailed theoretical analysis to support the claim of improved generalization?', 'Could the authors provide more details on the experimental setup to ensure reproducibility?', 'What are the best practices for tuning the hyperparameters of the proposed method?']","['The paper does not thoroughly explore the limitations of the proposed method.', 'Potential negative societal impacts are not discussed.', 'Theoretical analysis of convergence properties is limited.', 'Potential computational overhead in large-scale settings is not thoroughly discussed.', 'Careful tuning of hyperparameters may be required, which is not addressed in detail.']",False,3,2,3,5,4,"['Novel idea of using Hessian trace for regularization.', 'Theoretical motivations provided.', 'Empirical results show improved performance over existing methods.', 'Comprehensive experiments on multiple datasets and neural network architectures.', 'Demonstrated compatibility with data augmentation techniques.']","['Theoretical justification is somewhat convoluted and not entirely convincing.', 'Empirical results lack thorough statistical analysis and ablation studies.', 'Clarity and organization of the paper need improvement.', 'Limited exploration of the limitations and potential negative societal impacts of the method.', 'Potential reproducibility issues due to insufficient details in the experimental setup.', 'Computational cost discussion could be more detailed and comparative.']",3,3,2,3,Reject
NuzF7PHTKRw,The paper proposes a method called Environment-Adversarial Sub-task Curriculum (EAT-C) to improve the efficiency and generalization of Reinforcement Learning (RL) on long-horizon tasks. The method introduces two curriculum policies: a cooperative planning policy that decomposes tasks into sub-tasks and an adversarial environment policy that modifies these sub-tasks' environments to make them challenging. The method aims to provide dense rewards and diverse training scenarios for the RL agent. Experimental results show significant improvements in efficiency and generalization over several benchmarks.,"['Could the authors provide more details on how the cooperative planning policy is initialized and trained?', 'How does the method handle cases where the adversarial environment makes the sub-tasks too difficult for the RL agent?', 'Can the authors clarify the computational complexity of training the three policies jointly?', 'Can the authors provide more detailed algorithmic steps to improve reproducibility?', 'How stable is the training process with three interacting policies?', 'Are there any failure cases or limitations that were not discussed?', 'How does the method compare to other state-of-the-art RL approaches in more detail?', 'Can you provide more detailed ablation studies to isolate the contributions of the cooperative planning policy and the adversarial environment policy?', 'How do you ensure that the tasks generated in the earlier stages are not overly difficult for the RL agent?', 'Can the method be simplified to enhance its practical applicability without losing much of its effectiveness?']","['The paper does not thoroughly address the potential negative societal impacts, such as the implications of adversarial environments in real-world applications.', 'The complexity and potential computational overhead of training three policies jointly are not fully discussed.', 'The stability and convergence of the mutual-boosting mechanism need further analysis.', 'Potential ethical concerns if the adversarial environment generation is misused.', 'The complexity of the method could limit its practical use.', 'Potential for generating overly difficult tasks, particularly in the early stages of training.', 'The paper does not address the potential scalability issues of EAT-C to more complex environments or real-world scenarios.', 'The impact of each component (planning policy and adversarial environment policy) is not thoroughly examined.', 'The computational complexity and resource requirements are not discussed.']",False,3,2,3,4,4,"['Novel combination of cooperative planning and adversarial environment generation.', 'Thorough experimental validation on diverse benchmarks.', 'Clear motivation addressing sparse rewards and generalization issues in RL.']","['Complexity of the proposed method may hinder reproducibility.', 'The clarity of the paper could be improved, especially in explaining the interaction between policies.', 'The paper lacks a detailed analysis of the limitations and potential negative societal impacts.', 'The method might be over-complicated without providing unique theoretical insights.', 'Stability of the mutual-boosting mechanism is not thoroughly analyzed.', ""Potential overstatement of the method's advantages without sufficient comparison to state-of-the-art methods."", 'Risk of generating overly difficult tasks in earlier stages of training.', 'Lack of detailed ablation studies to isolate contributions of individual components.', 'Scalability to more complex tasks or environments not demonstrated.']",3,3,2,3,Reject
zuDmDfeoB_1,"This paper investigates the conditions under which Model-Agnostic Meta-Learning (MAML) outperforms Non-Adaptive Learning (NAL) using theoretical and empirical analyses. The paper identifies task hardness and geographical distribution of task solutions as key factors influencing MAML's performance gains. It provides theoretical analysis in linear regression and two-layer neural networks, and supports its findings with experiments on Omniglot and FS-CIFAR100 datasets.","['Can the theoretical analysis be extended to more complex models and settings?', 'Are there additional datasets or tasks that could further validate the empirical findings?', 'Can the writing be clarified to make the paper more accessible to a broader audience?', 'How do the theoretical results extend to more complex neural network architectures beyond two-layer networks?', 'Can the authors provide more intuitive explanations or visualizations for the key mathematical derivations in the appendices?', 'What are the practical implications of the findings for practitioners using MAML in real-world applications?', 'How do the theoretical insights apply to other meta-learning algorithms beyond MAML?', 'Can the authors clarify the practical steps to implement the suggested training procedures for hard tasks in real-world applications?', 'Can the authors provide more insights into the practical applicability of their theoretical findings?', 'How do the assumptions made in the theoretical analysis hold in real-world scenarios?', 'Can the authors discuss the reproducibility and generalizability of their empirical results in more detail?', 'What are the potential limitations and negative societal impacts of this work?']","['The theoretical analysis is focused on relatively simple models, which may limit the generalization of the findings.', 'The empirical validation is limited to two datasets, which may not fully capture the diversity of tasks where MAML could be applied.', 'The analysis is primarily theoretical and may not fully capture practical challenges.', 'The empirical experiments are limited to specific datasets, and broader validation is needed.', 'The paper does not thoroughly explore the potential negative societal impacts of the proposed methods.', 'The theoretical analysis assumes idealized conditions that may not be present in real-world scenarios.', 'The empirical validation, while comprehensive, lacks a detailed discussion on reproducibility and generalizability.']",False,3,2,3,6,4,"[""Addresses a significant gap in understanding MAML's performance benefits."", 'Provides both theoretical and empirical evidence.', 'Experiments on image classification datasets support theoretical findings.', ""Clear identification of specific conditions (task hardness and geography) that influence MAML's performance.""]","['Theoretical analysis is limited to linear regression and two-layer neural networks, which may not generalize to more complex models.', 'Empirical validation could benefit from additional datasets and more diverse tasks.', 'Writing is dense and may be difficult to follow for readers unfamiliar with the technical details.', 'Limited discussion on reproducibility and generalizability of empirical results.', 'Lack of thorough discussion on limitations and potential negative societal impacts.']",3,3,2,3,Accept
4Muj-t_4o4,"The paper proposes a method for learning a subspace of policies in reinforcement learning to address the challenge of adapting to unknown test environments. The approach involves creating a convex subspace of policies, each with different parameter values, to enable better generalization and adaptation. The authors validate their method through extensive experiments in various environments and compare it with existing techniques, demonstrating competitive performance without the need for additional components or extensive hyper-parameter tuning.","['Can the authors provide more detailed explanations of the mathematical formulation for better clarity?', 'How does the approach handle environments with high-dimensional observation spaces?', 'Are there any specific limitations of the proposed method that were not discussed in the paper?', 'How does the method perform on more diverse and challenging environments?', 'Could the authors provide more insights into the choice of anchor policies and their impact on performance?', 'Can the authors provide more detailed explanations and justifications for their choice of hyperparameters in comparison to baselines?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their method?', 'How does the proposed method scale with the number of anchor policies (N > 2)?', 'Could the authors provide more insights into the failure cases?', 'How does the approach compare with state-of-the-art robust RL methods?', 'Can the authors provide more theoretical insights into why learning a subspace of policies leads to better generalization?', 'How does the performance of LoP compare to state-of-the-art methods in more complex environments?', 'Can the authors discuss potential limitations and societal impacts of their method in more detail?']","['The paper does not sufficiently address the potential limitations and negative societal impacts of the method. For instance, the computational resources required for training and evaluating multiple policies might be high.', 'It would be helpful to include a discussion on how the method scales with the complexity of the environment and the observation space.', 'The evaluation is limited to a set of standard RL benchmarks, which may not fully capture the complexity of real-world scenarios.', 'The method relies on the assumption that a subspace of policies can effectively capture the diversity needed for generalization.', 'Potential negative societal impacts, such as misuse in environments requiring ethical considerations, are not addressed.', 'The paper mentions the inability to use multiple training environments as a limitation but does not thoroughly explore potential societal impacts. Given the application in real-world systems, a more detailed analysis of ethical considerations and societal impacts would strengthen the paper.']",False,3,3,3,6,4,"['Novel approach of learning a subspace of policies in parameter space for better generalization.', 'Extensive experimental validation across multiple environments.', 'Competitive performance compared to existing methods.', 'Does not require additional components or complex hyper-parameter tuning.', 'Simpler to tune compared to other diversity-based methods.', 'Practical considerations and simplicity in tuning compared to existing methods.']","['The presentation of the method could be clearer, particularly the mathematical formulation and the algorithm details.', 'Limited discussion on potential limitations and negative societal impacts.', 'Some parts of the paper are dense and may be difficult for readers to follow.', 'Incremental novelty compared to existing methods.', 'Evaluation could benefit from more diverse and challenging environments.', 'Figures and tables could be more reader-friendly.', 'Baseline comparisons may be slightly biased, particularly in hyperparameter choices.', 'Inadequate discussion on limitations and potential negative societal impacts.', 'Lack of rigorous complexity analysis.', 'Insufficient theoretical analysis or proofs for some claims.']",3,3,3,4,Reject
m5EBN92vjN,"The paper proposes the Attention Aware Network (AASeg) for real-time semantic segmentation, integrating spatial attention (SA), channel attention (CA), and multi-scale context (MSC) modules to enhance feature extraction. The approach is validated on Cityscapes, ADE20K, and CamVid datasets, showing improved performance and speed compared to existing methods.","['Can the authors provide more details on the implementation specifics, especially the aggregation mechanism?', 'How does the proposed network handle edge cases or challenging scenarios in the datasets?', 'Can the authors discuss any potential limitations or negative societal impacts of deploying this network in real-world scenarios?', 'How does the proposed method compare against more recent state-of-the-art methods not included in the comparison?', 'What specific hardware and software configurations were used for the experiments?', 'Can the authors provide more detailed implementation steps to ensure reproducibility?', 'Can the authors provide more detailed explanations and diagrams for the spatial and channel attention modules?', 'Could you clarify the mathematical notations used in the spatial and channel attention modules for better understanding?']","['The paper does not adequately address the potential limitations of the proposed approach.', 'The societal impact of real-time semantic segmentation, especially in sensitive applications like autonomous driving, is not discussed.', 'The novelty is limited as the attention mechanisms and multi-scale context modules are well-known techniques.', 'The experimental setup and comparison with baselines need more transparency and detail.']",False,3,3,3,6,4,"['Novel combination of spatial and channel attention mechanisms with multi-scale context.', 'Comprehensive experimental evaluation on multiple datasets.', 'Promising results in terms of mean IoU and FPS.', 'Balanced trade-off between segmentation accuracy and inference speed.']","['The originality of the proposed modules (SA, CA, MSC) is limited as they are incremental improvements over existing techniques.', 'Lack of detailed explanation of the network architecture and implementation specifics.', 'Potential limitations and negative societal impacts are not adequately discussed.', 'Clarity issues in the presentation of the methodology and results.', 'Inconsistent experimental results and insufficient discussion.', 'Theoretical contributions are minimal, with much of the work focusing on empirical results.']",3,3,3,3,Reject
mqIeP6qPvta,"The paper proposes 'FoveaTer', a foveated transformer model for image classification, inspired by the human visual system's foveated vision. The model uses pooling regions and eye movements to perform object classification tasks, dynamically allocating computational resources based on image difficulty. The authors demonstrate that the FoveaTer model achieves comparable accuracy to full-resolution models while using significantly fewer computations and also show improved robustness against adversarial attacks.","['How does the performance of FoveaTer generalize to the full ImageNet dataset?', 'Can the authors provide more extensive validation of the adversarial robustness claims?', 'How does FoveaTer compare with other state-of-the-art models on different datasets?', ""Can the authors provide more details on the model's potential negative societal impacts and ethical considerations?"", 'How does the complexity of the proposed model affect its practical implementation and reproducibility?', 'Can the authors clarify the experimental setup and provide more details on the dataset used?', 'Can the authors provide a clearer differentiation of their work from existing foveated vision models?', 'Can the authors provide more details on the training time and computational resources required for the FoveaTer model compared to the full-resolution model?', 'Can the authors provide more clarity on the foveation module and its implementation?', 'What are the potential limitations of the proposed method, and how can they be addressed?', 'Can you elaborate on the computational cost comparison with more state-of-the-art models?', 'What are the limitations of the proposed approach in real-world applications?']","['The experimental evaluation is limited to ImageNet-100, which may not generalize to other datasets.', 'The robustness against adversarial attacks needs more extensive validation.', ""The model's complexity might hinder practical implementation and reproducibility."", 'Limited novelty in combining existing techniques reduces the overall impact.', 'The impact of the initial random fixation on the final classification accuracy is not thoroughly explored.', 'Potential negative societal impacts are not discussed in detail, such as biases in the dataset or misuse of the technology.', ""The model's performance is only evaluated on ImageNet, which may not represent its generalizability to other datasets."", 'The paper does not address the potential negative societal impacts of deploying such a model.', ""The model's performance on diverse datasets and real-world scenarios is not discussed.""]",False,3,2,3,5,4,"['Novel combination of foveated vision and transformer architecture.', 'Significant reduction in computational costs while maintaining accuracy.', 'Improved robustness against adversarial attacks.']","['Lack of strong differentiation from existing works on foveated vision.', 'Experimental validation is not comprehensive; focused on ImageNet-100.', 'Adversarial robustness claims need more extensive validation.', 'Some sections are dense and could be more concise.', 'Complexity of the model might hinder practical implementation and reproducibility.', 'Limited novelty in combining existing techniques, reducing the overall impact.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.']",3,3,2,3,Reject
JXSZuWSPH85,"The paper proposes a novel inverse reinforcement learning (IRL) method called SOLO-IRL, which leverages adversarial one-class classification to estimate rewards using only expert trajectories. This method aims to address the computational intensity of traditional IRL methods by eliminating the need for inner loops and baseline trajectories. The approach is validated through experiments on several OpenAI Gym environments, showing competitive performance. The key contributions include the introduction of adversarial one-class classification into IRL and the demonstration of its effectiveness in various tasks.","['Can the authors provide a more detailed theoretical explanation of why adversarial one-class classification is expected to work well in IRL settings?', 'How does SOLO-IRL perform in more complex, real-world tasks beyond the OpenAI Gym environments tested?', 'Are there specific scenarios where SOLO-IRL fails or does not perform well? If so, what are the reasons?', 'Can the authors provide a more detailed comparison with other state-of-the-art IRL methods?', 'How sensitive is the performance of SOLO-IRL to the choice of noise parameters in different tasks?', 'Can the authors clarify the role and necessity of the reconstruction objective in the learning process?', 'Can the authors provide more detailed descriptions of the hyperparameters and the experimental setup?', 'How does SOLO-IRL compare with other state-of-the-art IRL methods beyond LogReg-IRL and RED?', 'Can the authors include more theoretical analysis to support their claims?', 'Can the authors provide more justification for the choice of noise parameters?', 'How does the method perform in a wider variety of tasks and environments?', 'Can the authors clarify the derivation of key equations and provide more intuitive explanations?']","['The need for noise adjustment in the generator introduces another layer of complexity.', 'Potential negative societal impact is not explicitly discussed.', 'The method still requires tuning of noise parameters, which might be task-dependent.', 'The current experimental setup is limited to a few tasks, which might not fully demonstrate the generalizability of the proposed method.', ""The method's performance is highly dependent on the tuning of noise parameters."", ""Limited experimental validation may not fully capture the method's potential or limitations.""]",False,2,2,2,4,4,"['Eliminates the need for baseline trajectories, addressing a significant limitation in existing classification-based IRL methods.', 'Adversarial one-class classification helps refine the decision boundary around the expert, leading to more accurate reward estimation.', 'Validated through experiments on several OpenAI Gym environments, showing competitive performance.']","['Experimental results do not show a significant improvement over existing methods such as behavioral cloning and RED in most cases.', 'Lacks a detailed theoretical analysis of why adversarial one-class classification is effective for IRL.', 'Limited discussion on the limitations and potential failure cases of SOLO-IRL, especially in more complex environments.', 'The explanation of the method is dense and could benefit from clearer organization and more detailed descriptions of key components.', 'Reproducibility is questionable due to insufficient detail in the experimental setup.', 'Dependence on noise parameters is not well-justified.']",3,2,2,3,Reject
D78Go4hVcxO,"The paper investigates the properties and functionalities of Multi-Head Self-Attentions (MSAs) in Vision Transformers (ViTs). It provides insights into the behavior of MSAs in terms of generalization, loss landscape flattening, and their complementary nature to convolutional layers. The authors propose a new model, AlterNet, which integrates the strengths of both MSAs and convolutional layers, and demonstrate its superior performance through extensive experiments.","['Can the authors provide more details on the practical implications of their findings in real-world applications?', 'How does AlterNet perform in other vision tasks beyond image classification?', 'Are there any limitations or challenges in integrating MSAs with convolutional layers in other types of neural networks?', 'Can the authors provide a stronger theoretical foundation for their claims?', 'How does AlterNet compare to other state-of-the-art models in terms of performance?', 'Can the authors clarify the potential negative societal impacts and ethical concerns of their work?']","['The paper could benefit from a discussion on the practical implications of the findings in real-world scenarios.', 'The performance of AlterNet in other vision tasks beyond image classification is not explored.', 'The paper lacks a thorough theoretical foundation for the claims made.', 'The proposed model (AlterNet) may not be significantly more effective than existing models.', 'Clarity issues due to dense explanations and technical jargon.', 'Insufficient discussion on potential negative societal impacts and ethical concerns.']",False,2,3,3,5,4,"['Comprehensive analysis and detailed experiments that investigate the properties of MSAs.', 'Clear explanations and visualizations that help understand the behavior of MSAs and ViTs.', 'Proposal of a novel model (AlterNet) that demonstrates superior performance by combining MSAs and convolutional layers.', 'Open-source code and detailed experimental setups provided for reproducibility.']","['Some parts of the paper are dense and could be difficult for readers not familiar with the area.', 'The practical implications of the findings, especially in real-world scenarios, are not extensively discussed.', 'The proposed model, while innovative, might be seen as an incremental improvement rather than a groundbreaking one.', 'Lacks a strong theoretical foundation for the claims made.', 'Insufficient discussion on potential negative societal impacts and ethical concerns.', 'The paper lacks a thorough comparison with state-of-the-art models.']",3,3,3,3,Reject
8QE3pwEVc8P,"The paper introduces Zero-Cost-PT, a novel perturbation-based zero-cost operation scoring method for differentiable neural architecture search (NAS). The method aims to address robustness issues in existing NAS methods by using zero-cost proxies for operation scoring, significantly speeding up the search process while improving accuracy. The paper evaluates the proposed method on several benchmarks, including NAS-Bench-201 and DARTS search spaces, demonstrating its effectiveness compared to state-of-the-art methods.","['Can the authors provide more details on the theoretical basis for the superiority of perturbation over discretization?', 'How does the proposed method perform in terms of robustness against different types of search spaces?', 'Can the authors discuss any potential negative societal impacts of their method?', 'Can the authors provide more detailed explanations or visualizations of the proposed Zero-Cost-PT method to improve clarity?', 'What specific hyperparameters were used for each of the experiments, and how sensitive is the method to these hyperparameters?', 'How does the method perform on other tasks or datasets not included in the paper, to validate its generalizability?', 'Can the authors provide a deeper theoretical analysis of the proposed method?', 'How does Zero-Cost-PT compare to other recent zero-cost NAS methods in terms of theoretical underpinnings?', 'Can the authors provide more details on the experimental setup, including hardware and software configurations?', 'What are the potential limitations of the proposed method, especially in terms of transferability to other search spaces or tasks?']","['The paper does not thoroughly discuss the limitations of the proposed method. For example, how does the method perform under different hardware setups?', 'Potential negative societal impacts, such as the environmental cost of increased computational requirements, are not addressed.', 'The method may still rely on extensive hyperparameter tuning, which could limit its applicability.', 'The zero-cost proxies might not generalize well to all types of neural architectures or tasks.', 'Potential negative societal impact if the method is used to search for architectures that are then deployed without thorough validation.', 'The transferability of the method to other search spaces or tasks is not addressed.', 'The scalability of the method to very large search spaces is not thoroughly analyzed.']",False,3,3,3,5,4,"['Addresses a significant issue in differentiable NAS by introducing a novel zero-cost operation scoring method.', 'Thorough empirical evaluation on multiple benchmarks.', 'Demonstrates significant improvements in search speed and accuracy over state-of-the-art methods.', 'Well-structured and clearly written, with detailed methodology and results.']","['The novelty of the proposed method relative to existing zero-cost proxies is not entirely clear.', 'Potential limitations and negative societal impacts are not thoroughly discussed.', 'The complexity of the method might hinder reproducibility without the provided code.', 'Some claims, such as the superiority of perturbation over discretization, need more rigorous theoretical backing.', 'The clarity of the explanation of the method could be improved, especially for readers unfamiliar with the domain.', 'Limited information on the reproducibility of the experiments.']",3,3,3,3,Reject
reFFte7mA0F,The paper introduces Conditional Expectation based Value Decomposition (CEVD) for scalable on-demand ride pooling. CEVD improves upon the Neural Approximate Dynamic Programming (NeurADP) by considering the impact of other agents' actions on individual value functions using conditional probabilities. The paper reports up to a 9.76% improvement in overall requests served on a city-wide benchmark taxi dataset.,"['Can the authors provide more intuition or simplified explanations for the technical sections?', 'How robust is the approach to different city layouts or varying traffic conditions?', 'Are there any limitations to the scalability claims, especially in more complex urban environments?', 'Can you provide more details on the computational complexity of CEVD compared to NeurADP, especially in large-scale scenarios?', 'How does CEVD handle highly dynamic environments where agent dependencies change rapidly?', 'Are there any real-world deployment results or case studies to support the practical applicability of CEVD?', 'Can the approach be generalized to other types of on-demand services beyond ride pooling?', 'How does the performance of CEVD compare to other contemporary methods beyond NeurADP?', 'Can the authors provide more insights into the computational overhead introduced by the conditional probability calculations?', 'How sensitive is the CEVD to the choice of hyperparameters like λ and α?', 'Can you provide more detailed explanations of the theoretical foundations, especially the conditional probability calculations?', 'How does CEVD handle edge cases or scenarios with highly dynamic demand variations?', 'Can you discuss the potential limitations of CEVD in real-world deployments?', 'Can the authors provide more intuitive explanations or examples to clarify the key concepts, especially the conditional probabilities and their impact on agent interactions?', 'How sensitive is the performance of CEVD to the parameters λ and α? Is there a systematic way to tune these parameters?', 'Can the authors discuss potential limitations or challenges in deploying CEVD in real-world scenarios beyond the benchmark dataset used?']","['The paper does not discuss potential limitations in different city layouts or traffic conditions.', 'There is no mention of the computational overhead in real-time deployment scenarios.', 'The method assumes that agents/vehicles are homogeneous and does not account for heterogeneity.', 'The scalability of the clustering approach for very large datasets is not thoroughly discussed.', 'Potential negative societal impacts, such as increased traffic congestion due to more efficient ride pooling, are not addressed.', 'Scalability in real-world scenarios might face challenges not captured in the experimental setup.', 'Potential ethical concerns related to biases in request assignments and environmental impact are not addressed.', 'The paper does not fully address the potential over/underestimation issues in NeurADP.', 'The practical impact of the improvements might be limited in real-world settings.', 'There might be challenges in tuning the parameters λ and α, which could affect the performance of CEVD in different settings.']",False,3,3,3,6,4,"['Novel approach to consider inter-agent dependencies using conditional probabilities.', 'Significant performance improvement over the state-of-the-art method.', 'Comprehensive experimental evaluation on real-world data.']","['Some sections are overly dense and technical, making comprehension difficult.', 'Limited discussion on the robustness and generalization of the approach.', 'Lack of clarity in some methodological explanations.', 'The novelty might be considered incremental as it builds heavily on existing work.', 'The scalability and complexity of the proposed method need clearer justification.', 'The generalizability of the method beyond the tested dataset and scenarios is not thoroughly discussed.']",3,3,3,3,Reject
IsHQmuOqRAG,"The paper introduces OPPLE, a self-supervised framework for learning object-centric representations from single 2D images by predicting future scenes. It combines predictive learning with 3D motion prediction and introduces a new synthetic dataset with complex textures. The model aims to infer objects' 3D locations and segment objects without supervision.","['Can the authors provide more detailed and clear pseudocode or diagrams to better illustrate the proposed approach?', 'How does the model perform on more diverse and real-world datasets?', 'Can the authors elaborate on the computational complexity and runtime performance of the model?', 'Can the authors provide more details on the implementation of the object matching scores and the radial basis function used?', 'What are the potential limitations of the approach when applied to more complex and cluttered real-world scenes?', 'Can the authors provide more details on the training process and hyperparameters?', 'How does the model perform on real-world datasets with varying lighting conditions and non-rigid objects?', 'Can the model handle scenarios where self-motion information is noisy or unavailable?', 'What are the computational requirements for training and inference?', 'Can the authors provide more details on the implementation and evaluation of the imagination network?', 'How does the depth perception network contribute to the overall performance of the model?', 'Can the authors include more comparisons with other models on additional metrics?']","['The evaluation is limited to synthetic datasets, which may not fully represent real-world complexities.', 'The clarity in presenting the technical details needs improvement for better reproducibility.', 'The approach is mainly evaluated on synthetic data, and its performance on real-world datasets is not demonstrated.', ""The model's ability to handle more complex and cluttered environments with deformable objects is not explored."", 'The paper does not adequately address the potential negative societal impacts of the work.', 'The approach may have limitations in handling deformable objects or objects with complex lighting conditions.', ""The approach's applicability in scenarios with noisy or unavailable self-motion information is unclear."", 'Handling of non-rigid objects and varying lighting conditions is not fully explored.', 'Potential negative societal impacts, such as privacy concerns and misuse of technology, are not adequately addressed.']",False,3,2,3,5,4,"['Novel combination of predictive learning with 3D motion prediction.', 'Introduction of a new synthetic dataset with complex textures.', 'Superior performance in object segmentation compared to existing models.']","['Clarity of explanations is lacking, making it difficult to fully understand and reproduce the methodology.', 'Limited evaluation scope, primarily focusing on synthetic datasets.', 'Complex technical details are not well-supported with clear visual aids or diagrams.', 'Insufficient details on certain methodological aspects.', 'Potential over-reliance on synthetic benchmarks.', 'Practical implications and broader impact are not thoroughly discussed.', 'Ethical and societal impacts are not adequately discussed.']",3,3,2,3,Reject
fCSq8yrDkc,"The paper proposes a novel method for solving large-scale optimal transport (OT) problems using Douglas-Rachford splitting. The method avoids numerical issues associated with entropic regularization, provides sparse solutions, and has a lower iteration complexity compared to the Sinkhorn method. The authors detail an efficient GPU implementation and present substantial experimental results demonstrating the method's effectiveness.","['Can the authors clarify how the proposed method compares to other recent methods for OT, besides the Sinkhorn method?', 'Are there any specific application domains where the proposed method significantly outperforms existing methods?', 'Could the authors provide more insights into the practical implementation challenges of the GPU version?', 'How does the proposed method handle different types of cost matrices in practice?', 'What are the potential limitations of the proposed approach?', 'Can the authors provide more details on the potential limitations of their method?', 'How does the method perform on different types of OT problems beyond those tested in the experiments?', 'Can the authors clarify the specific improvements in iteration complexity and convergence rates in comparison to other recent methods?', 'How does the choice of the regularization parameter impact the performance of the proposed method?', 'Could the authors simplify or provide more intuitive explanations for the dense mathematical sections?', 'How does the method perform on real-world datasets beyond the synthetic benchmarks and MNIST?', 'Are there any specific types of OT problems where the method might not be as effective?']","['The paper does not fully address the broader applicability and robustness of the method beyond comparisons with the Sinkhorn method.', 'The complexity of implementation, particularly the GPU version, might limit practical adoption.', 'Potential negative societal impacts of the method are not discussed.', ""The method's performance on different types of cost matrices is not thoroughly discussed."", 'Clarity issues in some sections make it difficult to reproduce the results.', 'Reproducibility might be hindered due to complex implementation details, despite the open-source code.', 'The impact of the regularization parameter on performance needs further exploration.']",False,3,2,3,6,4,"['Novel application of Douglas-Rachford splitting to OT problems.', 'Avoids numerical issues of entropic regularization.', 'Provides sparse solutions.', 'Detailed GPU implementation.', 'Substantial experimental evaluation showing improved performance over Sinkhorn method.', 'Significant improvement in iteration complexity (O(1/ε)).', 'Comprehensive theoretical analysis with rigorous proofs for convergence rates and complexity.', 'Extensive experimental validation demonstrating effectiveness and efficiency.']","['Significant typographical errors and formatting issues throughout the paper.', ""Complexity of the algorithm's implementation might limit practical impact."", 'Evaluation focuses primarily on comparison with the Sinkhorn method, leaving broader applicability and robustness uncertain.', 'Theoretical analysis is dense and may not be easily understandable to a broader audience.', 'Limited comparison with other recent or advanced OT solvers.', 'The impact of the regularization parameter on performance needs further exploration.', 'Potential negative societal impacts and ethical considerations are not adequately addressed.']",4,3,2,4,Accept
vfsRB5MImo9,"The paper introduces Continual Knowledge Learning (CKL), a novel continual learning problem for Large Language Models (LLMs) aimed at maintaining up-to-date knowledge without forgetting previously learned information. It proposes new benchmarks and metrics (FUAR) to measure the retention, update, and acquisition of knowledge. The paper adapts existing continual learning methods to CKL and performs extensive experiments to evaluate their effectiveness.","['Can the authors simplify the presentation of their experimental setup and results?', 'How does the FUAR metric compare to existing metrics in terms of usefulness and interpretability?', 'Can the authors provide clearer justification for the introduction of FUAR?', 'Can the authors provide more discussion on the potential negative societal impacts of CKL?', 'Are there any plans to explore other LLM architectures beyond T5 and GPT-2?', 'Can the authors provide more details on the reproducibility of the experimental results?', 'Can the authors provide more details on the experimental setup, especially the selection of hyperparameters?', 'How does the proposed CKL method compare with traditional CL methods in terms of computational efficiency?', 'Can the authors discuss potential societal impacts and ethical considerations of CKL?', 'How do the proposed CKL methods compare to retrieval-augmented approaches in terms of maintaining and updating world knowledge?', 'Can the authors provide more details on how the FUAR metric was validated and its limitations?', 'What are the potential computational costs of applying the proposed CKL methods in practice?', 'Can the authors provide more details on how the baseline methods were specifically adapted for CKL?', 'What are the potential implications of CKL on the ethical use of LLMs in dynamic environments?', 'How do the authors plan to address the memory inefficiency of parameter-expansion methods in future work?']","['The complexity introduced by new metrics and extensive experiments might limit the accessibility and practical adoption of the proposed methods.', 'The potential negative societal impact of maintaining up-to-date knowledge in LMs, such as the risk of incorporating biased or incorrect information, needs to be addressed.', 'The paper does not adequately address the potential negative societal impacts of CKL.', 'The evaluation focuses primarily on T5 and GPT-2, limiting the generalizability of the findings to other LLM architectures.', 'The clarity of the experimental setup and results presentation needs improvement.', 'The paper does not address the computational costs and scalability of the proposed CKL methods.', 'The potential negative societal impacts of updating knowledge in LMs, such as the propagation of biases, are not discussed.', 'Memory inefficiency of parameter-expansion methods is highlighted but not thoroughly explored.']",False,3,3,3,6,4,"['Addresses an important problem in maintaining up-to-date knowledge in language models.', 'Introduces a novel benchmark and metric (FUAR) for evaluating continual learning in LMs.', 'Performs extensive experiments with various methods and provides a thorough analysis.', 'Provides insights into the unique challenges and performance of different CKL methods.']","['The paper is lengthy and dense, making it hard to follow.', 'The experimental setup is overly complicated.', 'The results do not provide a clear and convincing improvement over existing methods.', 'The introduction of new metrics like FUAR adds complexity without clear justification or comparison to existing metrics.', 'Limited novelty as it heavily builds on existing continual learning methods.', 'Societal impact and ethical considerations are not adequately addressed.', 'Limited discussion on the potential negative societal impacts of the work.', 'Somewhat narrow scope of the evaluation, primarily focusing on T5 and GPT-2.', 'Lack of exploration of other LLM architectures beyond T5 and GPT-2.', 'Limited information on the reproducibility of the results beyond the provided benchmark and code.']",3,3,3,3,Reject
kSwqMH0zn1F,"The paper introduces PipeGCN, a method to improve the efficiency of distributed GCN training by pipelining communication and computation. It provides a theoretical convergence analysis and demonstrates significant speedup in training throughput without compromising accuracy through extensive experiments.","['Can the authors provide more details or simplifications to make the theoretical convergence analysis more accessible?', 'Are there any plans to compare PipeGCN with other methods whose code is not currently available?', 'How does PipeGCN perform on non-GPU clusters or with different types of graphs?', 'Can the authors discuss potential limitations and scalability issues in more detail?', 'Can the authors provide more details about the hyperparameters used in the experiments?', 'How does the proposed method handle different types of GCN models beyond GraphSAGE?', 'Can the authors elaborate on the potential overhead introduced by the smoothing method in more detail?', ""Can you provide additional details on how the smoothing method's parameters were chosen?"", 'How does PipeGCN perform when integrated with other GCN variants, such as Graph Attention Networks (GATs)?']","['The paper does not address the scalability of the approach to different types of graphs.', 'Performance on non-GPU clusters is not discussed.', 'Dependency on specific hardware configurations could limit practical applicability.', 'The scalability of the method to extremely large graphs and multi-server setups is not fully explored.', 'The impact of the smoothing technique on various GCN architectures is not thoroughly investigated.']",False,3,3,3,7,4,"['Addresses a significant bottleneck in distributed GCN training.', 'Provides a theoretical convergence analysis for the proposed method.', 'Demonstrates significant improvement in training throughput through extensive experiments.', 'Proposes a smoothing method to mitigate staleness issues.', 'Code availability enhances reproducibility.']","['The theoretical convergence proof is complex and might not be easily accessible.', 'Comparison with other methods lacks some key baselines due to unavailability of code.', 'The paper does not adequately discuss potential limitations and scalability issues.', 'Dependency on specific hardware configurations could limit the practical applicability.', 'Some sections are dense and could benefit from clearer explanations or additional visual aids.']",4,4,3,4,Accept
gFDFKC4gHL4,"The paper introduces MASA, a framework for assessing ML API shifts by modeling them as differences in confusion matrices and using an adaptive sampling approach for efficient estimation. MASA is shown to significantly reduce the number of samples needed compared to standard methods, with comprehensive empirical support.","['Can the authors provide additional discussion on the potential negative societal impacts of MASA?', ""Are there practical examples where MASA's improved accuracy has led to significant real-world benefits?"", 'Can MASA be extended to non-classification tasks?', 'How does the method perform with datasets that have a significantly different distribution from those used in the paper?', 'Are there specific scenarios where MASA might fail or be less effective?', 'Can the authors provide more details on the choice of hyperparameters and their impact on the results?', 'How does MASA perform with different numbers of partitions (K)? An ablation study would be helpful.', 'What are the main limitations of MASA, and how can future work address them?', 'Can you provide more details on the computational complexity of MASA?', 'What are the specific assumptions behind the convergence rates presented in the theoretical analysis?', 'How does MASA handle cases where the number of classes is very large?', 'Can the approach be extended to non-classification tasks, and if so, how?']","['The paper briefly mentions the limitation of the method being more applicable to classification tasks with a moderate number of classes. Further discussion on other potential limitations and negative societal impacts would be beneficial.', 'For complex APIs (e.g., OCR, NLP), different measures might be needed, and this could be elaborated more in the paper.', 'The method is demonstrated mainly on classification tasks; its applicability to other types of tasks is not explored.', 'There is a potential for the method to be less effective on datasets with distributions very different from those used in the paper.', 'The paper does not extensively discuss the limitations of MASA or potential negative societal impacts. For example, how does MASA handle highly imbalanced datasets or noisy labels? Including such discussions would provide a more comprehensive view of the work.', 'Potential biases in the datasets used for evaluation are not discussed.', 'The impact of different parameter choices for MASA is not fully explored in the paper.']",False,3,3,3,7,4,"['Addresses a relevant and practical problem in the use of ML APIs.', 'Innovative method with solid theoretical basis.', 'Comprehensive empirical evaluation demonstrating effectiveness.', 'Theoretical guarantees for the proposed method.', 'Extensive empirical evaluations across various real-world datasets and APIs.']","['Highly dense with technical details, potentially hindering readability.', 'Brief discussion of limitations and potential negative societal impacts.', 'Lengthy and complex mathematical proofs.', 'Potential reliance on specific datasets and classification tasks, limiting generality.', 'Some parts of the methodology and results presentation lack clarity.', 'The description of the datasets and empirical setup could be more detailed to ensure reproducibility.']",4,4,3,4,Accept
d2TT6gK9qZn,"The paper introduces a Pade approximation-based exponential neural operator for solving initial value problems (IVPs) in partial differential equations (PDEs). The method uses multiwavelet bases for space discretization and embeds exponential operators in the neural model to reduce training parameters and improve data efficiency. The approach is validated on synthetic datasets (KdV and KS equations) and a real-world COVID-19 forecasting problem, showing improved performance and data efficiency over state-of-the-art methods.","['Can the authors provide more detailed explanations and justifications for the theoretical derivations?', 'How does the proposed method compare with additional baseline methods in more rigorous experiments?', 'Can the authors provide more insights into the practical implications and limitations of their approach?', 'How does the computational complexity of the proposed method compare with other state-of-the-art methods?', 'Can the authors provide more details on the scalability of the model with respect to input size?', 'How sensitive is the model to the choice of hyperparameters, particularly the degrees of Pade polynomials?']","['The paper does not adequately address the limitations of the proposed method. For instance, the scalability of the method to higher-dimensional PDEs or more complex initial conditions is not discussed.', 'Potential negative societal impacts are not considered.', 'The method may not scale well to very large datasets due to the complexity of Pade approximations.', 'The paper lacks extensive real-world validations beyond the COVID-19 dataset.']",False,3,2,3,6,4,"['Novel combination of Pade approximation and neural networks.', 'Theoretical analysis demonstrating bounded gradients.', 'Empirical validation on both synthetic and real-world data.', 'Potential improvements in data efficiency for scarce datasets.']","['Lack of clarity in the presentation of the methodology and theoretical derivations.', 'Limited discussion on computational overhead and scalability.', 'Insufficient comparison with more recent state-of-the-art techniques.', 'Dense and sometimes unclear presentation.']",3,3,2,4,Reject
_PHymLIxuI,"The paper proposes CrossFormer, a novel vision transformer architecture featuring Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA) designed to enable cross-scale feature interactions. Additionally, a Dynamic Position Bias (DPB) is proposed to handle variable-sized inputs efficiently. The model is evaluated on multiple vision tasks, showing improvements over existing methods.","['Can the authors provide more theoretical analysis to support the empirical results?', 'How does CrossFormer perform compared to the latest state-of-the-art models not mentioned in this paper?', 'Can the authors elaborate on the specific scenarios where their method significantly outperforms others?', 'Can you provide more details on the implementation of CEL and LSDA?', 'How does CrossFormer perform in scenarios where the input data distribution significantly differs from the training data?', 'Are there any specific failure cases or limitations observed during the experiments?', 'How does CrossFormer perform compared to other recent models in terms of computational efficiency?', 'Can the authors provide more detailed explanations or pseudocode for the key components, such as CEL and LSDA?', 'What are the specific challenges or limitations encountered in the implementation of CrossFormer?', 'Can you provide more detailed ablation studies to isolate the effects of CEL, LSDA, and DPB?', 'How does the LSDA mechanism compare with other sparse attention mechanisms in terms of computational efficiency and performance?', 'What are the potential limitations of CrossFormer, and how could they be addressed in future work?', 'How does the performance of CrossFormer compare with other vision transformers on a broader range of hyperparameters?', 'Can the authors clarify the computational costs and memory requirements in more detail?']","['The paper does not adequately address the theoretical underpinnings of the proposed methods.', 'Potential negative societal impacts are not discussed.', 'The scalability of the model to extremely large datasets or real-time applications is not addressed.']",False,3,3,3,6,4,"['Addresses a crucial problem of cross-scale feature interactions in vision transformers.', 'Proposes well-motivated methods (CEL and LSDA) with extensive experimental results.', 'Introduces a Dynamic Position Bias to handle variable-sized inputs.', 'Comprehensive experiments across multiple vision tasks.', 'Consistent performance improvements over strong baselines.']","['The novelty is somewhat incremental, building upon existing concepts.', 'Lacks thorough theoretical analysis to support empirical findings.', 'Missing comparisons with the latest state-of-the-art models.', 'Certain technical details and experimental setups could be explained more clearly to enhance reproducibility.', 'Some sections of the paper are not clearly written, making it hard to follow.', 'Potential societal impacts and limitations are not adequately discussed.']",3,3,3,3,Reject
Xg47v73CDaj,"The paper introduces ParNet, a neural network architecture that achieves high performance with significantly reduced depth by utilizing parallel subnetworks. The authors present empirical results showing that ParNet achieves state-of-the-art performance on ImageNet, CIFAR-10, CIFAR-100, and MS-COCO benchmarks while maintaining a depth of only 12 layers. The key innovation is the use of parallel substructures, which allows for effective parallelization and low-latency inference.","['Can you provide more theoretical analysis to support the empirical findings?', 'How do the architectural choices specifically impact the performance of ParNet?', 'Can you elaborate on the limitations and potential negative societal impacts of your work?', 'How does ParNet compare with other multi-stream architectures in terms of both accuracy and computational efficiency?', 'Can the authors clarify the architectural diagrams and provide more detailed explanations of the methodology?', 'Can the authors provide more details on how ParNet scales to other tasks beyond those evaluated?', 'What are the main limitations of ParNet, and how do the authors plan to address them?', 'Could the authors elaborate on the potential negative societal impacts of their work?', 'Can the authors provide more details on the potential overfitting due to increased parameter count?', 'How does the network perform on real-time applications, especially in terms of latency?', 'Could the authors elaborate on the specific hardware requirements for optimal performance?', 'How does ParNet compare to other parallel architectures in terms of scalability and practical deployment?', 'Can the authors clarify the specific differences between ParNet and similar approaches in the literature?', 'What are the limitations of ParNet in terms of network size, data complexity, and hardware requirements?']","['The paper does not provide a thorough analysis of the limitations of the proposed architecture.', 'Potential negative societal impacts are not discussed.', 'The scalability of ParNet beyond 3 streams is not tested due to computational constraints.', 'The reproducibility of the results is dependent on the release and quality of the open-sourced code.', 'The increased parameter count might lead to overfitting, which is not adequately addressed.', 'Scalability and performance under different hardware configurations are not thoroughly investigated.']",False,3,3,3,6,4,"['Challenges the conventional wisdom that high depth is necessary for high-performing neural networks.', 'Empirical results on multiple benchmarks demonstrate the efficacy of the proposed architecture.', 'Offers practical advantages in terms of parallelization and low-latency inference.', 'Provides a detailed scaling analysis and ablation studies.']","['The novelty of the approach seems incremental rather than groundbreaking.', 'Lacks rigorous theoretical analysis to support the empirical findings.', 'The paper is not very clear in explaining the architectural choices and their implications.', 'Does not adequately address potential limitations and negative societal impacts.', 'Scalability to other tasks and domains is not clearly established.', 'Certain sections, particularly the methodology, could be clearer.']",3,3,3,3,Reject
oxC2IBx8OuZ,"The paper presents Continual Federated Learning (CFL), a framework to address the challenges of time-varying heterogeneous data in Federated Learning (FL). CFL captures complex scenarios by approximating local objective functions and theoretically demonstrates faster convergence rates than FedAvg. The paper also provides extensive empirical evaluations showing CFL's effectiveness over state-of-the-art FL baselines.","['Can the authors provide more real-world datasets to validate the empirical results?', 'How does the CFL framework perform in large-scale, real-world FL scenarios?', 'Can the authors simplify the theoretical explanations to enhance clarity?', 'Can the authors provide more insights into the computational overhead and practical feasibility of the proposed methods, especially the generative methods?', 'What are the potential ethical implications of using generative methods in CFL, and how can these be mitigated?', 'Can the authors provide more details about the experimental setup to ensure reproducibility?', 'Can the authors compare CFL with more federated learning approaches beyond FedAvg and FedProx?', 'Can the authors provide more details on the assumptions made in the theoretical analysis?', 'Can the authors elaborate on the ethical and societal impacts of their work?', 'Can the authors provide more details on the specific hyperparameters used in the experiments?', 'What are the practical implications of the assumptions made in the theoretical analysis?', 'How does the computational overhead of the proposed methods compare to baseline methods?']","['The practical applicability of CFL in large-scale, real-world FL scenarios is unclear.', 'The complexity of theoretical contributions might hinder their verification and implementation.', 'The paper does not sufficiently discuss the computational overhead and practical feasibility of the proposed methods.', 'Ethical concerns related to generative methods are not addressed.', 'The complexity and density of the paper limit its accessibility.', 'The experimental evaluation is not comprehensive enough to demonstrate the generalizability of the proposed methods.', 'Theoretical assumptions may limit generalizability.', 'Need for more diverse and real-world datasets for validation.', 'The paper addresses limitations related to approximation quality but lacks a detailed discussion on potential negative societal impacts.']",True,3,3,3,6,4,"['Introduces a novel CFL framework for time-varying heterogeneous data in FL.', 'Provides rigorous theoretical analysis demonstrating faster convergence rates for CFL.', 'Extensive empirical results validating the effectiveness of CFL over SOTA FL baselines.', 'Addresses a significant gap in federated learning by considering time-varying heterogeneity.']","['Complex theoretical contributions might not be easily verifiable.', 'Empirical evaluations could benefit from more diverse datasets and real-world applications.', 'Practical applicability in large-scale, real-world scenarios remains unclear.', 'Some theoretical explanations are complex and could be simplified for better clarity.', 'Potential ethical concerns related to generative methods are not addressed.']",3,3,3,3,Accept
ULfq0qR25dY,"The paper introduces the maximum n-times coverage problem, a generalization of the multi-set multi-cover problem, and applies it to peptide vaccine design. It proposes two algorithms, NTIMES-ILP and MARGINALGREEDY, to solve this problem and demonstrates their effectiveness in designing COVID-19 vaccines that achieve higher population coverage compared to existing designs.","['Can you provide more details on the computational complexity of the proposed algorithms in practical scenarios?', 'Can you elaborate on any theoretical guarantees for the performance of the proposed algorithms?', 'How do you plan to address the potential societal impacts and ethical considerations of your work?', 'Can the authors provide more details on the datasets and metrics used for comparison with existing vaccine designs?', 'How do the proposed algorithms perform on other datasets or problems outside vaccine design?']","['The computational complexity of the proposed methods in large-scale practical scenarios.', 'Lack of a comprehensive theoretical analysis of the proposed algorithms.', 'Insufficient discussion on societal impacts and ethical considerations.', 'The complexity of the ILP formulation might pose challenges for reproducibility.', 'The paper could benefit from a broader comparative analysis with additional state-of-the-art methods.']",False,3,2,4,6,4,"['Novel problem definition with significant real-world application.', 'Proposes two practical algorithms for solving the problem.', 'Extensive experimental results demonstrating effectiveness.', 'Timely and significant application to COVID-19 vaccine design.']","['Clarity of the theoretical parts can be improved.', 'Computational complexity in practical scenarios is not thoroughly discussed.', 'Lacks a comprehensive theoretical analysis of the proposed algorithms.', 'Potential societal impacts and ethical considerations are not adequately addressed.', 'Limited comparative analysis with other combinatorial optimization methods.']",4,3,2,4,Accept
KTPuIsx4pmo,The paper proposes a novel approach to meta-imitation learning by observing human video demonstrations and translating them into robot demonstrations using a generative model called A-CycleGAN. The approach aims to reduce the data collection burden by only requiring human videos and not robot demonstrations during training.,"['How scalable is the approach with respect to the number of paired videos required for training?', 'Can the authors provide more rigorous validation of their evaluation metrics?', 'How does the approach perform on more diverse and complex tasks?', 'Can the authors provide more detailed explanations and visualizations of the A-CycleGAN architecture?', 'How does the adaptive loss mechanism quantitatively impact the training process?', 'Can the authors clarify the specific contributions of each module through ablation studies with more detailed statistical analyses?', 'How does the method perform on a wider range of tasks beyond shape-drawing and pushing?', 'What are the limitations in obtaining paired videos, and how can they be mitigated?', 'Can the method be extended to fully unsupervised learning without any paired data?', 'What are the potential societal impacts and ethical concerns of using this method in real-world applications?']","['The approach requires a certain amount of paired human-robot video data, which might still be challenging to collect.', 'The success rates, especially in simulated tasks, are not very high, indicating limited practical applicability.', 'Potential biases in the experimental tasks chosen may affect the generalizability of the results.', 'The paper does not thoroughly discuss potential negative societal impacts and ethical concerns.']",False,2,2,2,4,4,"['Novel application of generative models (A-CycleGAN) for translating human videos into robot demonstrations.', 'Addresses the significant challenge of data collection in robot learning.', 'Detailed experimental evaluation on both simulated and real-world tasks.']","['The reliance on paired video data might still pose practical challenges.', 'Evaluation metrics and experimental setup need more rigorous validation.', 'The performance improvements over existing methods are marginal.', 'Dense and sometimes difficult-to-follow methodology section.', 'Writing and organization need substantial improvement for better clarity.']",3,2,2,3,Reject
jJWK09skiNl,"The paper proposes a method for zero-shot detection of daily objects in the YCB Video Dataset using a modified YOLOv5 architecture. The method aims to enable robots to adapt to frequently changing objects in a smart manufacturing environment. Key contributions include a novel network structure for generalized zero-shot detection (gZSD), a new dataset splitting method, and an attribute labeling approach.","['Can the authors provide more detailed explanations of the loss functions and network architecture?', 'How does the proposed method compare to existing zero-shot detection methods in terms of performance?', 'Can the authors provide additional evaluation metrics beyond recall to better assess the effectiveness of the method?', 'What specific modifications were made to YOLOv5, and how do these modifications contribute to the performance improvements?', 'How does the attribute labeling method improve upon existing methods? Can you provide more details?', 'What steps were taken to ensure the robustness of the experimental results?', 'How does the proposed method handle different lighting conditions and occlusions in real-world scenarios?', 'What are the computational requirements and efficiency of the proposed method?']","['The paper does not address potential limitations in terms of generalization to other datasets.', 'There is no discussion on the computational efficiency or resource requirements of the proposed method.', 'The societal impacts of deploying such a system in manufacturing settings are not discussed.', 'The method may not perform well in varying lighting conditions and with occlusions, as suggested by the limited evaluation.']",False,2,2,2,3,4,"['Addresses a relevant problem in the context of smart manufacturing.', 'Uses the YCB Video Dataset, which is appropriate for the task.', 'Proposes a novel dataset splitting method and an attribute labeling method.']","['Limited novelty; primarily combines existing techniques rather than proposing new methodologies.', 'Technical explanations, particularly regarding loss functions and network architecture, lack depth and clarity.', 'Experimental evaluation is shallow, with only basic recall metrics reported.', 'Poorly organized and contains numerous grammatical errors, making it difficult to follow.', 'The paper does not adequately address the limitations and potential negative societal impacts of the work.']",2,2,2,2,Reject
bUAdXW8wN6,"The paper proposes Domain Invariant Adversarial Learning (DIAL), a novel adversarial training method that aims to improve both robustness and standard accuracy by enforcing a domain-invariant feature representation. The method uses Domain Adversarial Neural Networks (DANN) on natural and adversarial domains. Extensive experiments on MNIST, SVHN, CIFAR-10, and CIFAR-100 datasets demonstrate the effectiveness of DIAL compared to state-of-the-art adversarial training methods.","['Can the authors provide a more rigorous theoretical justification for why domain invariance should lead to better robustness?', 'What are the exact configurations and hyperparameters used in each experiment? Detailed steps would help in reproducibility.', 'How does the computational overhead of DIAL compare to other state-of-the-art adversarial training methods?', 'Can the authors discuss any potential limitations or negative societal impacts of their method more thoroughly?', 'How does DIAL perform on larger, more complex datasets beyond those tested?']","['The paper does not thoroughly discuss potential limitations such as the increased computational overhead due to the integration of DANN.', 'There is a lack of discussion on the potential negative societal impacts of the method.', 'The method may overfit the specific datasets and experimental setups used.', 'The scalability of the method to larger datasets and more complex models is not addressed.']",False,3,2,3,6,4,"['Novel combination of adversarial training and domain invariance.', 'Comprehensive experimental evaluation on multiple datasets.', 'Method shows significant improvements in robustness and standard accuracy.', 'Detailed ablation studies and visualizations to support the claims.']","['Lack of rigorous theoretical justification for why domain invariance improves robustness.', 'Presentation lacks clarity in some parts, particularly the detailed steps and configurations used in experiments.', 'Potential computational overhead introduced by integrating DANN into adversarial training is not adequately addressed.', 'Insufficient discussion of potential limitations and negative societal impacts.']",3,3,2,3,Reject
j-63FSNcO5a,"The paper proposes Disentanglement via Contrast (DisCo), a framework for learning disentangled representations by leveraging pretrained generative models using contrastive learning. The method involves fixing the pretrained generator and discovering traversal directions in the latent space as factors for disentangled representation learning. The paper introduces the Δ-Contrastor module, entropy-based domination loss, and hard negatives flipping strategy, achieving state-of-the-art performance on several generative models and datasets.","['Can the authors provide a more rigorous theoretical justification for why DisCo effectively discovers disentangled directions?', 'How does the choice of pretrained generative models impact the final performance of DisCo?', 'Can the authors provide more detailed analysis and experiments on the Flow model to understand its poorer performance?', 'Can the authors provide more detailed analysis on the impact of hyperparameters on the performance and robustness of DisCo?', 'Are there any theoretical insights or guarantees that can support the convergence of DisCo to disentangled solutions?', 'How does DisCo perform on more diverse and larger datasets beyond the benchmarks provided?', 'Can the authors clarify the specific architecture details of the encoder used in the Δ-Contrastor?', 'How sensitive is DisCo to the choice of hyperparameters like the number of directions (D) and the dimension of the representation (J)?', 'Can the authors provide more details on how their method handles potential negative societal impacts?', 'Is there any scenario where the current assumptions about linearity in the latent space might fail, and how could this be addressed?', 'How would the method perform with models that do not have pretrained versions available or with different types of generative models not covered in the experiments?', 'Can the authors provide a clearer explanation of the Δ-Contrastor?', ""How does the method's complexity affect its practical applicability?"", 'Can the authors expand on the limitations and potential societal impacts of their work?']","['The method may not work well if the pretrained generative models are not of high quality or are not well-aligned with the target dataset.', 'The theoretical justification for the method is intuitive and lacks rigorous proofs, which may limit its acceptance.', 'The method might be difficult to reproduce due to its complexity.', ""No strong theoretical guarantees for the method's convergence to disentangled solutions."", 'Limited analysis of hyperparameter impact and performance robustness.', 'The method assumes that pretrained generative models have some inherent disentanglement properties, which may not hold for all models.', 'The computational cost of training DisCo with large generative models like StyleGAN2 can be substantial.', 'Assumptions about the linearity of disentangled directions might not hold for more complex models like Flow.', ""Heavy reliance on pretrained models might limit the framework's applicability in scenarios where such models are not available."", 'Potential negative societal impacts are not thoroughly discussed.']",False,3,3,4,7,4,"['Novel approach leveraging pretrained generative models to mitigate the trade-off between disentanglement and generation quality.', 'Model-agnostic framework applicable to GAN, VAE, and Flow models.', 'Comprehensive experimental results demonstrating superior performance.', 'Well-motivated techniques like Δ-Contrastor, entropy-based domination loss, and hard negatives flipping.', 'Publicly available code which promotes reproducibility.']","['The paper is dense and could benefit from clearer explanations and better organization.', 'The theoretical justification for why DisCo works is somewhat intuitive and lacks rigorous proofs.', 'The impact of the choice of pretrained models on performance is not thoroughly analyzed.', 'Limited experiments on the Flow model and insufficient exploration of reasons for its poorer performance.', 'Complexity of the method might limit its practical applicability.', 'Limited discussion on potential negative societal impacts or ethical considerations.']",4,3,3,4,Accept
L1L2G43k14n,"The paper explores the correlation between flatness of the loss landscape and generalization in deep neural networks. It critiques existing flatness measures and proposes using the Bayesian prior, log P(f), as a more robust predictor of generalization. The paper presents both theoretical arguments and extensive empirical evidence to support this claim.","['Can the authors provide more detailed steps on how the GP approximations were used for the Bayesian prior calculations?', 'How does the proposed approach scale with larger and more complex datasets and architectures?', 'Could the authors discuss the limitations of using log P(f) in practical applications, especially in terms of computational cost?', 'Can the authors provide a stronger theoretical justification for using Bayesian priors as predictors of generalization?', 'Have the authors considered additional datasets and architectures to validate their findings?', 'How do the proposed Bayesian prior-based measures compare with other generalization predictors in the literature?', 'Can the authors clarify the novelty of their theoretical contributions?', 'Can the authors provide more structured explanations of their experiments and results?', 'What are the practical implications of using the Bayesian prior as a generalization measure?', 'Can the authors provide more practical guidance on calculating Bayesian prior in real-world applications?', 'How do the findings impact real-world deep learning applications, particularly those beyond image classification?', 'Could the authors elaborate on potential limitations of their approach in different DNN architectures or datasets?']","['The paper does not adequately address the computational cost of using GPs for prior estimation.', 'There is limited discussion on the applicability of the proposed method to more complex datasets and architectures.', 'The study is limited to image classification tasks and may not generalize to other domains.', 'The theoretical grounding for the Bayesian prior-based predictor is not fully developed.', 'The computational complexity in calculating Bayesian prior is a significant limitation.', 'The approach may not be easily applicable to all types of DNN architectures or datasets.', 'Further discussion is needed on the practical implications of the findings.']",False,3,3,3,5,4,"['Addresses a well-known and important problem in the field of deep learning.', 'Provides a comprehensive review of existing flatness measures and their limitations.', 'Proposes a novel approach using Bayesian prior to predict generalization.', 'Supports claims with extensive empirical evaluation.']","['Lacks significant theoretical novelty; the use of Bayesian priors is not new.', 'The empirical validation, while extensive, does not convincingly demonstrate the superiority of the proposed approach over existing methods.', 'The clarity of the paper suffers in some sections, making it difficult to follow and reproduce the experiments.', 'Computational complexity in calculating Bayesian prior limits practical applicability.', 'The impact on real-world applications is not extensively discussed.']",3,3,3,3,Reject
yV4_fWe4nM,"The paper proposes a novel deep fair clustering framework that integrates integer linear programming (ILP) with deep learning to ensure group-level fairness in clustering tasks. The method involves formulating the fairness objective as an ILP, which is then injected into a discriminative deep clustering model. The experimental results on real-world datasets show that the proposed approach outperforms existing methods in both clustering performance and fairness.","['Can the authors provide more detailed explanations of the complex mathematical formulations to improve accessibility?', 'Could the authors elaborate on the potential negative societal impacts of their proposed method?', 'How does the proposed method compare with other recent works in fair clustering and deep clustering in terms of novelty?', 'Can the authors provide more details on the scalability of the ILP approach and its computational complexity?', 'What are the practical limitations of the proposed method, especially in terms of applicability to large-scale datasets?', 'Can the authors provide more intuitive explanations or visualizations to improve the clarity of the theoretical and algorithmic sections?', 'Have the authors considered more diverse datasets, particularly those with real-world complexities, to validate the generalizability of their approach?']","['The scalability of the ILP formulation for very large datasets is a concern.', 'The clarity of the mathematical formulations needs improvement for better readability and understanding.', 'The experimental validation could be extended to more diverse and complex real-world datasets.', 'The flexible fairness constraints could be misused to create artificially unfair results, which is not thoroughly addressed.']",False,3,3,3,5,4,"['Novel integration of ILP with deep clustering for fairness.', 'Strong theoretical contributions with proofs of efficiency and optimality.', 'Comprehensive experimental validation demonstrating improved performance and fairness.']","['Limited discussion on scalability and computational complexity of the ILP approach.', 'Dense mathematical formulations that could benefit from additional explanations and clarifications.', 'Insufficient exploration of potential negative societal impacts and practical significance.', 'Limited diversity of datasets in the experimental evaluation, raising questions about generalizability.']",3,3,3,3,Reject
9rKTy4oZAQt,"The paper introduces a novel risk-sensitive policy gradient method for deep reinforcement learning (DRL), optimizing the distribution of full-episode outcomes using a cumulative distribution function (CDF). The method is evaluated in OpenAI Safety Gym environments, showing improved performance over standard Proximal Policy Optimization (PPO).","['Can the authors provide more intuitive explanations of their methodology?', 'How well does the proposed method generalize to other environments or tasks beyond the OpenAI Safety Gym?', 'Can additional baselines from recent state-of-the-art methods be included for comparison?', 'How does the proposed method compare to other state-of-the-art risk-sensitive RL methods?', 'Can the authors provide more details on the computational complexity of the proposed method?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide additional details on the experimental setup, including hyperparameters and training procedures?', 'Can the authors clarify the variance reduction techniques with more examples or illustrations?', 'Can the authors provide more details on the choice of environments and how representative they are of broader tasks?', 'How does the proposed method perform in more diverse and complex environments?', 'Can the authors provide insights into the reproducibility of their results?', 'Can you provide more detailed explanations or appendices for the mathematical derivations?', 'How were the hyperparameters chosen, and are they consistent across all experiments?', 'Can the method be evaluated on a more diverse set of environments beyond the Safety Gym?']","['Complexity and clarity of the proposed methodology.', 'Potential limitations in generalization to other types of environments.', 'Limited comparison with recent state-of-the-art methods.', 'The method is only tested on OpenAI Safety Gym environments, limiting generalizability.', 'The paper does not discuss potential negative societal impacts sufficiently.', 'The potential negative societal impact of applying the method in high-stakes real-world applications.', 'The method may require extensive tuning of the risk-sensitivity parameter η.', 'The complexity of the method might hinder its applicability in real-world scenarios.', 'The paper does not sufficiently address the limitations and potential negative societal impacts of its approach. For instance, the real-world applicability of the proposed method in safety-critical applications and its ethical implications are not discussed.']",False,3,3,3,5,4,"['Novel approach for incorporating risk-sensitivity into policy gradient methods.', 'Comprehensive experiments in various environments.', 'Effective use of variance reduction techniques.', 'Promising empirical results in OpenAI Safety Gym environments.']","['Complexity and clarity of the methodology.', 'Unclear generalization to other types of environments or tasks.', 'Limited comparison with broader set of recent state-of-the-art methods.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'Dense and complex mathematical derivations that may hinder clarity.', 'Reproducibility details are insufficient, particularly in terms of hyperparameters and code availability.']",3,3,3,3,Reject
lY0-7bj0Vfz,"The paper introduces Memory Concept Attention (MoCA), a module designed to enhance few-shot image generation in GANs by implementing a prototype-based memory attention mechanism inspired by 'grandmother neurons' in the visual cortex. Experiments demonstrate that MoCA improves image synthesis quality and robustness across multiple datasets and GAN architectures.","['Can the authors provide more intuitive explanations or simpler analogies for the momentum update mechanism and prototype memory learning?', 'Have the authors considered other GAN architectures or tasks beyond few-shot image generation?', 'Could the authors elaborate more on the potential societal impacts and ethical considerations of their work?', ""Can the authors provide a more rigorous theoretical justification for the connection between MoCA and 'grandmother cells' in the brain?"", 'Could the authors clarify the integration process of MoCA into the generator architecture with more detailed steps or diagrams?', 'What are the potential negative societal impacts of this work, especially concerning the creation of deepfakes, and how can they be mitigated?', 'Is there a plan to simplify the model implementation to enhance reproducibility?', 'Can you provide more detailed explanations and visualizations of the MoCA mechanism?', 'How does MoCA perform on tasks other than few-shot image generation?', 'What are the potential limitations and negative societal impacts of your approach?', 'Can the authors provide more detailed explanations on how the memory update mechanism works?', 'How does the computational overhead introduced by MoCA compare to existing methods?', 'Can the authors provide examples where MoCA fails or underperforms compared to the baseline?', 'How does MoCA generalize to other types of data or tasks beyond image synthesis?']","['The reliance on neuroscientific analogies may not translate perfectly to artificial networks.', 'Further exploration is needed regarding the broader applicability to different GAN architectures or tasks other than few-shot image generation.', 'The discussion on potential societal impacts and ethical considerations is somewhat superficial.', 'The connection to neuroscience is speculative and not rigorously justified.', 'Certain sections of the paper lack clarity, making it difficult to understand the MoCA mechanism fully.', 'The potential for misuse in generating deepfakes is acknowledged but not thoroughly discussed.', 'The complexity of the model might make it difficult for others to reproduce the results.', 'The method may not generalize well to tasks beyond few-shot image generation.', 'Potential negative societal impacts include misuse of image generation technology for creating deepfakes or misinformation.', 'The potential computational overhead and scalability issues are not addressed.', 'More discussion on how to mitigate the risks of misuse in creating deepfakes is needed.', ""The approach's applicability to other types of data or tasks is not explored.""]",False,3,2,3,6,4,"['Introduces a novel memory-based attention mechanism inspired by neuroscientific findings.', 'Comprehensive experiments across several datasets show consistent improvements.', 'Thorough ablation studies and visualizations provide strong support for the method.', 'Potential advancement in few-shot image generation, an important and challenging task.']","['Heavy reliance on neuroscientific analogies that may not perfectly translate to artificial networks.', 'Limited to a few types of GAN architectures and datasets, potentially lacking broader applicability.', 'Explanation of certain technical details might be complicated and less intuitive.', 'Potential societal impacts are mentioned but not deeply explored.', 'Theoretical justification and connection to neuroscience are somewhat speculative and not rigorously established.', 'Complexity in model implementation may hinder reproducibility.', 'Some sections of the paper are densely written, affecting clarity.']",3,3,2,3,Reject
R8sQPpGCv0,"The paper introduces Attention with Linear Biases (ALiBi), a novel positional encoding method for transformers that biases query-key attention scores with a penalty proportional to their distance. This enables the model to extrapolate to longer sequences than those seen during training. The authors demonstrate that ALiBi outperforms existing positional encoding methods, such as sinusoidal embeddings, rotary embeddings, and T5 bias, in various experimental settings. The method is shown to be efficient, requiring minimal changes to existing transformer architectures and incurring negligible computational overhead.","['Can the authors provide a deeper theoretical explanation for why ALiBi improves extrapolation capabilities?', 'Are there any potential limitations or negative societal impacts associated with the proposed method that the authors have not discussed?', 'How does ALiBi perform in comparison to other state-of-the-art methods in tasks other than language modeling, such as machine translation or text classification?', 'Can the authors provide more details on the choice of slopes for ALiBi and their generality across different datasets and tasks?', 'Have you considered the impact of different slope values for ALiBi, and how sensitive is the method to this hyperparameter?']","[""The paper does not provide a detailed theoretical explanation for why ALiBi improves extrapolation capabilities, which could help in understanding the method's strengths and limitations better."", 'Potential negative societal impacts of the proposed method are not discussed.', 'The primary source of performance improvement is the reduction of the early token curse, which might limit the generalizability of the approach.', 'The method may not generalize well to all types of NLP tasks beyond language modeling.', 'Further exploration of different slope values and their impact on performance is needed.']",False,3,3,3,7,4,"['The proposed method is simple and easy to implement, requiring minimal changes to existing transformer architectures.', 'Experimental results demonstrate significant improvements in extrapolation capabilities compared to existing positional encoding methods.', 'The method is efficient, with negligible computational overhead and memory increase.', 'The paper provides extensive empirical evidence, including experiments on multiple datasets and model sizes, to support the effectiveness of ALiBi.']","['The paper lacks a deep theoretical explanation for why ALiBi improves extrapolation capabilities.', 'The clarity of the presentation could be improved in some sections, particularly in the detailed explanation of the method.', 'Potential limitations and negative societal impacts of the proposed method are not adequately discussed.', 'The primary benefit of ALiBi might be due to the reduction of the early token curse rather than true extrapolation capability.', 'The generality of the method across different datasets and tasks is not entirely convincing.']",3,3,3,3,Accept
EHaUTlm2eHg,"The paper introduces Policy Gradients Incorporating the Future (PGIF), a method to enhance reinforcement learning (RL) by allowing agents to leverage future trajectory information without explicitly predicting the future. This is achieved using variational inference and latent-variable autoregressive models, coupled with an information bottleneck to avoid over-reliance on privileged information. The method is tested on various RL algorithms and domains, including online and offline RL, sparse rewards, and partially observable environments, demonstrating improved performance.","['How does the method perform when the future information is noisy or inaccurate?', 'Can the authors provide more details on the computational requirements and efficiency of training PGIF?', 'How does PGIF compare to other recent methods that use future information in RL, such as those leveraging hindsight experiences?', 'Could the authors provide more detailed explanations of the key technical concepts, such as the information bottleneck and Z-forcing?', 'Can the authors conduct more comprehensive ablation studies to isolate the impact of each component of the PGIF method?', 'What are the potential negative societal impacts of this work, and how do the authors plan to mitigate them?', 'How does the method perform with different values of the information bottleneck parameter (β)?', 'What are the computational overheads introduced by PGIF compared to baseline methods?', 'Can the authors provide a more detailed explanation of the auxiliary losses and their impact on the performance of PGIF?', 'Is there a theoretical analysis that can support the empirical findings presented in the paper?', 'How sensitive is the method to the choice of hyperparameters, especially the regularization terms?', 'How does the approach compare to existing methods like Hindsight Experience Replay in terms of computational efficiency and performance?', 'Can the authors provide more insights into the potential biases introduced by using future information, especially in offline settings?', 'How sensitive is the method to the choice of auxiliary losses and the complexity of the neural architectures used?']","['The potential biases introduced by future information are not fully addressed.', 'The computational cost of training with long trajectories and LSTMs could be a significant limitation.', ""The method's performance in highly noisy or uncertain environments needs further investigation."", 'The paper does not deeply explore the potential negative societal impacts and ethical considerations, which are increasingly important in AI research.', 'The method, while versatile, may have limitations in terms of computational efficiency and scalability, especially when applied to very large and complex environments.', 'The method relies on future trajectory information, which may introduce biases in learning.', 'Increased training time and computational costs due to the use of LSTMs and transformers.', 'The method relies on auxiliary losses and regularization, which might complicate implementation and tuning.', 'The paper lacks theoretical analysis, making it hard to generalize the empirical findings.', 'The use of future information may exacerbate biases present in the experience or offline dataset.']",False,3,2,3,5,4,"['Innovative approach to leveraging future trajectory information without explicit prediction.', 'Applicable to a wide range of RL algorithms and environments.', 'Demonstrates superior performance in several challenging RL tasks.', 'Comprehensive empirical evaluation across multiple domains.']","['Potential biases introduced by the use of future information are not fully explored.', 'The novelty of the method should be better contextualized within existing literature on incorporating future information.', 'The clarity of the explanation regarding the implementation details could be improved to facilitate reproducibility.', 'Training the model may be computationally intensive due to the use of LSTMs and long trajectories.', 'Dense and complex writing, which may hinder understanding.', 'Relies heavily on auxiliary losses and regularization, complicating implementation and tuning.', 'Lack of theoretical analysis to support empirical findings.']",3,3,2,3,Reject
Fj1Tpym9KxH,"The paper introduces Smooth Domain Adversarial Training (SDAT), which aims to improve the generalization of domain adversarial training (DAT) by focusing on the smoothness of the task loss. The authors provide both theoretical analysis and empirical evidence demonstrating that SDAT can enhance performance in unsupervised domain adaptation tasks. The method is evaluated on multiple datasets, including Office-Home, VisDA-2017, and DomainNet, and shows clear improvements over baseline methods.","['Can the authors provide more details on the selection criteria for the ρ value?', 'Have the authors considered evaluating their method on other types of domain adaptation tasks beyond image classification and object detection?', 'Can the authors clarify the potential limitations of their approach in terms of computational overhead?', 'What are the potential limitations and broader impacts of the proposed method?', 'How does SDAT perform in scenarios with extreme domain shifts or very small datasets?', 'Could the authors discuss potential limitations and negative societal impacts in more detail?']","['The paper does not address the potential limitations of the proposed method in terms of computational overhead.', 'The evaluation is limited to image classification and object detection tasks, which may limit the generalizability of the findings.', 'The selection criteria for the ρ value is not clearly explained, which may impact the reproducibility of the results.', 'Potential negative societal impacts of the method are not discussed.', 'The approach may not generalize well to scenarios with extreme domain shifts or very small datasets.']",False,3,3,3,6,4,"['Thorough theoretical analysis of the impact of smoothness on DAT.', 'Sound empirical evaluation with multiple datasets and methods.', 'Practical significance as the proposed method can be easily incorporated with existing DAT methods.', 'Novel perspective on smoothness in DAT.', 'Clear improvement over baseline methods.']","['Clarity of presentation could be improved, particularly in the theoretical sections.', 'The novelty of the contributions is somewhat limited as it focuses on the known concept of smoothness but applies it selectively.', 'The evaluation could be more comprehensive by including more diverse datasets and baselines.', 'Limited discussion on potential limitations and broader impacts.', 'Theoretical analysis could be more robust.']",3,3,3,3,Reject
k7-s5HSSPE5,"The paper proposes an unsupervised cross-lingual transfer method called Importance-Weighted Domain Alignment (IWDA). The method aims to improve cross-lingual learning by aligning feature representations and correcting class prior shifts. The approach is evaluated on multiple NLP tasks, demonstrating its effectiveness, especially under large prior shifts.","['Can the authors provide more details on how the baselines were chosen and whether other strong baselines were considered?', 'Could the authors elaborate on the potential negative societal impacts of their work?', 'What are the limitations of the proposed approach, especially in terms of scalability and computational cost?', 'Can the authors provide more detailed implementation steps to improve reproducibility?', 'How does IWDA perform on more diverse and low-resource languages?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can you provide more intuitive explanations for the empirical analysis and mathematical notations?', 'How generalizable are your results to other datasets and tasks?', 'Can you elaborate on the stability of IW estimates and how you plan to address it in future work?', 'How does the proposed method perform in ablation studies, particularly with different components of IWDA removed?']","['The paper does not adequately address the computational complexity of the proposed method.', 'The potential negative societal impacts of using such cross-lingual transfer systems are not discussed.', ""The method's reliance on accurate prior shift estimation could be a limitation."", 'Potential negative societal impacts include biases in cross-lingual transfer and misuse of the technology.']",False,3,3,3,6,4,"['Addresses an important problem in cross-lingual transfer learning.', 'Proposes a novel method (IWDA) that shows promising results compared to existing methods.', 'Extensive empirical analysis showing the correlation between feature alignment and transfer performance.', 'Demonstrated effectiveness across multiple NLP tasks.']","['Insufficient baselines in some evaluations.', 'Clarity of certain sections could be improved.', 'Potential limitations and negative societal impacts are not adequately discussed.', 'Limited novelty as the method builds on existing domain adaptation techniques.', 'Reproducibility is not fully ensured despite the provided code link; more implementation details are needed.', 'Evaluation on a broader range of datasets could strengthen the conclusions.']",3,3,3,3,Reject
SVwbKmEg7M,"This paper presents a novel method for unsupervised neural machine translation (NMT) using generatively pre-trained language models such as GPT-3. The approach involves few-shot amplification, distillation, and backtranslation to leverage the zero-shot translation capabilities of GPT-3. The proposed method achieves state-of-the-art results on the WMT14 English-French benchmark with a BLEU score of 42.1.","['Can the authors provide more details on the computational resources required for the experiments?', 'How does the method perform on language pairs with less training data and different linguistic characteristics?', 'Are there any plans to release the code and models to facilitate reproducibility?', 'How does the method handle biases inherent in pre-trained models like GPT-3?', 'What are the potential negative societal impacts of this approach, and how can they be mitigated?', 'Can the method be effectively applied using smaller, more accessible language models?', 'What are the computational requirements and costs associated with replicating the results?', 'How does the approach perform on other language pairs or benchmarks?', 'Can the authors provide a more detailed explanation of the few-shot amplification and distillation processes?']","[""The method's reliance on GPT-3 implies high computational cost and potential accessibility issues."", 'Potential ethical concerns related to the environmental impact of training large models and the biases present in the training data are not sufficiently addressed.', 'The generalizability of the method to other language pairs and tasks is not thoroughly evaluated.', 'The approach may not be feasible for researchers with limited access to large language models.', 'Potential biases inherent in the pre-trained models may affect the translation quality for certain languages.', ""The method's applicability to low-resource languages remains unclear.""]",True,3,3,3,5,4,"['The method achieves state-of-the-art results in unsupervised NMT.', 'The paper is well-organized and clearly written.', 'Extensive experimental validations are provided.', 'The approach simplifies the unsupervised NMT pipeline by using a single generative model.']","['The approach relies heavily on large-scale pre-trained models like GPT-3, which require substantial computational resources.', 'Reproducibility may be challenging due to the use of extremely large models.', 'The paper does not address the potential ethical concerns associated with the use of large-scale models adequately.', 'Limited discussion on the generalizability of the method to other language pairs and tasks.']",4,3,4,3,Reject
nK7eZEURiJ4,"The paper delves into the theoretical aspects and algorithmic advancements in distributional reinforcement learning (RL). It proposes a new perspective by interpreting distributional RL as entropy-regularized maximum likelihood estimation. Additionally, it introduces a novel Sinkhorn distributional RL algorithm and demonstrates its competitive performance on Atari games.","['Can the authors provide more intuitive explanations for some of the key theoretical insights?', 'How does the proposed Sinkhorn distributional RL algorithm perform in other types of environments beyond Atari games?', 'Can the authors discuss the potential limitations in computational complexity and scalability of the proposed algorithm?', 'Can you provide more baseline comparisons with other state-of-the-art RL algorithms?', 'Can you elaborate on the practical implications and potential applications of your theoretical findings?', 'How sensitive is the Sinkhorn algorithm to different hyperparameters?', 'Can the authors provide more detailed comparisons with existing methods to highlight the novelty and impact of the proposed Sinkhorn distributional RL?', 'How do the theoretical insights translate into practical advantages? Can these be demonstrated more clearly?', 'Can the authors provide more empirical results on diverse benchmarks to validate the broader applicability of the proposed method?', 'Can you provide more rigorous proofs for the theoretical claims?', 'How does the Sinkhorn-based algorithm compare to other state-of-the-art methods in a broader range of environments?', 'Can the clarity of the presentation be improved, especially in the theoretical sections?', 'What are the specific hyper-parameters used in the experiments, and how are they tuned?', 'How does the proposed SinkhornDRL algorithm compare with other recent DRL algorithms not mentioned in the paper?']","['The authors have addressed the limitations and potential negative societal impacts adequately. However, further discussion on the computational complexity and scalability of the proposed Sinkhorn distributional RL algorithm would be beneficial.', 'The paper could be clearer and more concise in presenting theoretical derivations.', 'More practical insights and guidance for practitioners would be beneficial.', 'The experiments could include more baseline comparisons to strengthen the empirical validation.', 'Theoretical proofs are not always rigorous.', 'The experimental validation is limited to Atari games.', 'The clarity of the presentation is lacking.']",False,3,2,3,5,4,"['Provides a thorough theoretical understanding of distributional RL.', 'Introduces a novel Sinkhorn distributional RL algorithm.', 'Demonstrates competitive performance on a suite of Atari games.', 'Addresses regularization, optimization, and acceleration in distributional RL comprehensively.']","['The paper is very dense and complex, making it difficult to follow.', 'Extensive reliance on appendices for proofs and explanations.', 'The novelty of some theoretical contributions appears incremental.', 'Practical impact and broader applicability require further validation.', 'Insufficient baseline comparisons with other state-of-the-art RL algorithms.', 'Limited empirical validation to a few Atari games.', 'Clarity of exposition is lacking, making it difficult to follow the arguments.']",3,3,2,3,Reject
SvFQBlffMB,"The paper introduces Pseudo-KD, an instance-specific label smoothing technique that aims to combine the benefits of label smoothing (LS) and knowledge distillation (KD) while maintaining efficiency. The method involves a two-stage optimization process and is evaluated on image classification and natural language understanding tasks, showing competitive performance.","['Can you provide more detailed proofs for the theoretical contributions, particularly for Theorem 1?', 'How does Pseudo-KD compare with the latest state-of-the-art methods not discussed in the paper?', 'Can you elaborate on the potential negative societal impacts of this work?', 'Can the authors provide more intuition and practical guidance on choosing the hyperparameters α and β?', 'How does the method perform on other tasks beyond image classification and natural language understanding?', 'Can the authors clarify the computational complexity and runtime comparison in more detail?']","['The potential negative societal impacts are not thoroughly discussed.', 'Theoretical contributions could be better substantiated with detailed proofs.', ""The method's performance in other domains is not explored."", 'Potential limitations and failure cases are not discussed in detail.', 'The complexity of the two-stage optimization problem may limit the scalability of the method.', ""The method's generalization to other tasks beyond classification is not thoroughly explored."", 'Limited theoretical analysis to support the empirical findings.']",False,3,3,3,5,4,"['Novel instance-specific label smoothing technique that generalizes LS and KD.', 'Deterministic and interpretable solution for optimal label smoothing.', 'Extensive experiments demonstrating effectiveness across multiple datasets and architectures.', 'Efficient training without the need for pre-trained teacher models.']","['Theoretical contributions could be better substantiated with detailed proofs and derivations.', 'Lacks thorough comparison with the latest state-of-the-art methods.', 'Some sections are dense and could benefit from clearer explanations and illustrations.', 'Potential negative societal impact is not discussed in depth.', 'Complexity of the two-stage optimization problem.', 'Potential scalability issues with larger datasets and models.']",3,3,3,3,Reject
uVXEKeqJbNa,"The paper proposes a Stiffness-Aware Neural Network (SANN) for learning Hamiltonian dynamical systems. It introduces a stiffness-aware index (SAI) to classify data into stiff and nonstiff portions, allowing for adaptive time integration strategies. The method is validated on the three-body problem and billiard model, showing significant improvements in stability and accuracy over existing methods.","['Can the authors provide more details on the computational overhead introduced by the adaptive step size and resampling techniques?', 'How would the method perform in real-world scenarios where data is often noisy?', 'Could the authors discuss any potential negative societal impacts of their method?', 'How does the method perform on other types of Hamiltonian systems beyond the three-body problem and billiard model?', 'What strategies can be employed to handle noisy training data more effectively?', 'How does the method generalize to non-Hamiltonian systems?', 'Can the authors provide examples of real-world applications where SANN could be beneficial?', 'Can the authors provide more theoretical justification for SAI as a proxy for SI?', 'What are the implications of the resampling technique on the generalization ability of the model?', 'Is there a theoretical justification for the choice of the Leapfrog integrator for both SRNN and SANN?', 'Can the authors discuss the scalability of SANN for larger datasets or more complex systems?', 'What are the potential trade-offs between accuracy and computational cost in SANN?']","['Sensitivity to coordinate transformations, although empirically addressed.', 'Struggles with noisy data, limiting real-world applicability.', 'The method shows instability under noisy data conditions.', 'The evaluation is limited to two types of Hamiltonian systems.', 'The resampling technique may increase computational cost.', 'Potential computational overhead due to resampling and adaptive time-stepping.', 'Limited validation on real-world datasets.', 'Possible sensitivity to hyperparameter choices such as stiff ratio and partition parameters.', 'The paper does not address the computational cost and scalability of SANN, especially for larger datasets or more complex systems.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,5,4,"['Introduction of a novel and effective stiffness-aware index (SAI) to classify time intervals.', 'Comprehensive evaluation on complex Hamiltonian systems, showing significant improvements over existing methods.', 'Detailed theoretical and empirical analysis of the proposed method.', 'Well-organized and clearly written paper.']","['Potential sensitivity to coordinate transformations, although addressed empirically.', 'Limited discussion on the computational overhead introduced by the adaptive step size and resampling techniques.', 'Lack of exploration of potential negative societal impacts, which is a crucial aspect for ethical considerations.', 'The experiments with noisy data show that the method struggles under significant noise, which limits its applicability in real-world scenarios where data is often noisy.', 'Evaluation limited to only two types of Hamiltonian systems, potentially limiting generalizability.', 'Unclear generalization to other types of dynamical systems.', 'Limited validation on real-world datasets.']",4,3,3,3,Reject
sTNHCrIKDQc,"The paper proposes graphon-based methods for clustering and testing network-valued data, introducing a novel graph distance based on graphon estimation. It presents two clustering algorithms and a two-sample test, providing theoretical guarantees and empirical validation.","['How do the methods perform on very large and sparse networks?', 'Can the assumptions be relaxed to make the methods more broadly applicable?', 'Are there any empirical results comparing the performance with more recent and advanced methods?', 'Can the authors provide more insights into how the smoothness assumptions affect the practical applicability of the proposed methods?', 'Are there any strategies to relax these assumptions in future work?', 'Could the methods be further optimized for computational efficiency, especially for very large networks?', 'How sensitive are the results to the choice of n0? Can the authors provide more empirical evidence or guidelines for choosing this parameter?', 'How do the proposed methods compare with state-of-the-art Graph Neural Networks in terms of computational efficiency and performance on large-scale networks?', 'Can the authors provide more insights into the scalability of their methods on large real-world networks?', 'Can you provide more practical guidelines for choosing the parameter n0?', 'How does the computational complexity of your methods compare with the existing ones?', 'Can you elaborate on the scalability of the proposed methods in practice, especially for very large networks?', 'Can the authors provide more details on the computational complexity of the proposed methods?', 'Are there any practical limitations when applying the proposed methods to very large graphs?', 'Can the authors provide additional insights into potential negative societal impacts of their work?']","['The assumptions might limit the applicability to certain graphs.', 'Scalability for very large and sparse networks is not fully addressed.', 'Parameter choices might require fine-tuning in practice.', 'The reliance on smoothness assumptions limits the practical applicability of the methods.', 'While the paper discusses potential negative societal impacts, it would benefit from a more detailed exploration of such impacts, particularly in sensitive applications like social network analysis.', 'The authors should discuss in more detail the limitations of their approach, particularly in terms of computational complexity and scalability.', 'Additionally, the potential negative societal impacts of applying these methods to sensitive data, such as social networks, should be addressed.', 'The paper does not thoroughly discuss the computational complexity of the proposed methods, especially for very large graphs.', 'Potential negative societal impacts of the work are not sufficiently addressed.', 'The clarity of mathematical notations and proofs could be improved to aid understanding and reproducibility.']",False,3,3,4,7,4,"['Addresses an important problem in network-valued data analysis.', 'Novel and theoretically grounded graph distance.', 'Provides rigorous theoretical analysis and proofs.', 'Empirical results are promising compared to existing methods.', 'Well-organized and clearly written.', 'Code and datasets are available for reproducibility.']","['Assumptions might limit applicability to certain types of graphs.', 'Methods rely on the graphon model, which may not be suitable for all network data.', 'Scalability for very large and sparse networks is not fully addressed.', 'Empirical comparisons with existing methods could be more thorough.', 'Parameter choices, although theoretically justified, might require fine-tuning in practice.', 'The clarity of the presentation can be improved, especially in the theoretical sections.', 'The novelty of some components, like the use of graphons, may not be very high since graphons are a well-known concept.', 'Reproducibility relies heavily on external code, which needs to be thoroughly verified.', 'Potential limitations and negative societal impacts are not sufficiently addressed.']",4,3,3,3,Accept
yztpblfGkZ-,"The paper introduces BankGCN, a novel graph convolutional network operator based on adaptive filter banks. BankGCN aims to address the limitations of existing message passing and spectral GCNs by decomposing multi-channel signals into subspaces and applying adaptive filters to capture diverse spectral characteristics. The proposed method combines elements of spectral and spatial approaches, leading to improved performance on several benchmark datasets for both node and graph classification tasks.","['Can the authors provide more details on the practical scalability of BankGCN for large-scale graphs?', 'How does the method perform in real-world applications beyond benchmark datasets?', 'What are the potential negative societal impacts of deploying BankGCN in sensitive applications?', 'Can the authors provide more detailed explanations and justifications for the claimed parameter reductions and improved spectral handling?', 'How does BankGCN perform on tasks beyond node and graph classification, such as link prediction or 3D point cloud classification?', 'Can the authors discuss the limitations of their approach and any potential negative societal impacts?', 'Can you provide more insights or examples of potential real-world applications where BankGCN would outperform existing methods?', 'What are the specific limitations of BankGCN, and how do they impact its applicability?', 'Can the authors discuss potential negative societal impacts of their work in more detail?', 'Can the authors provide more clarity on the computational complexity and scalability of BankGCN for large-scale graphs?', 'How does the model handle potential overfitting with numerous hyper-parameters?', 'Can the authors provide more details on how different projection functions impact the performance of BankGCN?', 'Could the authors include ablation studies on various hyperparameters such as the number of subspaces and the order of the polynomial filters?']","['The scalability of the method to large-scale graphs is not thoroughly validated.', 'Potential negative societal impacts are not adequately addressed.', 'Potential overfitting due to complex models and numerous hyper-parameters.', 'The impact of different projection functions on the performance of BankGCN is not explored.']",False,3,3,3,4,4,"['Novel approach combining spectral and spatial methods in GCNs.', 'Extensive theoretical justification and experimental validation.', 'Demonstrated improvement over several state-of-the-art methods.', 'Addresses a relevant and challenging problem in graph neural networks.']","['Dense and complex presentation, making it difficult to follow.', 'Limited discussion on the practical implications and scalability.', 'Potential negative societal impacts are not thoroughly discussed.', 'Potential for overfitting due to complex models and numerous hyper-parameters.']",4,3,3,3,Reject
FqKolXKrQGA,"The paper presents a transformer-like architecture, NuGgeT, to infer the network structure of network games using observed equilibrium actions without requiring explicit knowledge of the utility function. It benchmarks the proposed model against state-of-the-art methods on synthetic and real-world datasets, demonstrating superior performance.","['Can the authors provide more theoretical analysis on the generalization capabilities of NuGgeT?', 'How does the model scale with significantly larger networks beyond the sizes tested in the paper?', 'Can the authors explore more diverse real-world datasets to validate the general applicability of their method?', 'Can the authors provide more details on the hyperparameter tuning process for NuGgeT?', 'What is the computational complexity of the proposed method compared to the baselines?', 'Can the authors clarify how the model handles different sizes of graphs during training and inference?', 'Can the authors provide more detailed explanations or examples for the mathematical formulations?', 'What are the potential impacts of incorrect inferences made by the model in real-world applications?', 'Can the authors provide more details on why the proposed method performs better, especially in non-smooth settings?', 'How does the method handle cases where the utility function changes over time?', 'Can the authors elaborate on potential ethical concerns related to the application of inferred networks in real-world scenarios?']","['The current work is limited to static games and networks. Extending to dynamic settings and repeated games could be a valuable direction.', 'The method cannot guarantee the uniqueness of the inferred network structure.', 'The method may not generalize well to networks significantly different from those in the training set.', 'The paper does not thoroughly discuss the potential ethical implications and societal impacts of applying inferred networks in real-world scenarios.', ""The method's performance in dynamically changing networks and utility functions is not explored."", 'Potential negative societal impacts, such as misuse of inferred network structures, should be addressed.']",True,3,3,3,6,4,"['Addresses a significant practical limitation by not requiring explicit knowledge of the utility function.', 'Proposes a novel transformer-like architecture that accounts for symmetries in the problem.', 'Extensive evaluation on both synthetic and real-world datasets shows superior performance compared to existing methods.', 'Potentially broad applicability in various fields such as economics, social and biological networks.']","['The evaluation on real-world data could be more comprehensive, considering only two datasets.', ""Theoretical analysis of the model's generalization and robustness could be stronger."", 'Potential scalability issues with very large networks not addressed.', 'Some experimental details, such as hyperparameter tuning and computational complexity, are not thoroughly discussed.', 'Mathematical formulations are dense and could benefit from additional explanations.', 'Potential ethical concerns due to the application of inferred networks in real-world scenarios, which are not deeply discussed.']",3,3,3,3,Accept
34mWBCWMxh9,"The paper introduces spatial smoothing, a method that ensembles neighboring feature map points of Convolutional Neural Networks (CNNs) to improve the accuracy, uncertainty estimation, and robustness of Bayesian Neural Networks (BNNs) and deterministic neural networks. The method involves adding blur layers to models and provides both theoretical and empirical evidence to support its claims.","['Can you provide more rigorous theoretical proofs for the claims made in the paper?', 'How does spatial smoothing compare with other state-of-the-art methods in a more comprehensive set of benchmarks?', 'What are the potential limitations and negative societal impacts of using spatial smoothing?', 'Can the authors provide more details on the specific settings and hyperparameters used in the experiments?', 'How do the authors isolate the effects of spatial smoothing from other factors like hyperparameter tuning?', 'Can the authors provide more practical examples where the improvements in performance are significant and impactful?', 'Can the authors clarify the computational overhead introduced by spatial smoothing in more detail?', 'What are the limitations of spatial smoothing in terms of model architecture and dataset size?']","['The paper does not discuss the limitations of spatial smoothing in different types of neural network architectures or tasks.', 'The potential negative societal impacts, such as increased computational cost or biases introduced by the smoothing process, are not addressed.', 'The method may be limited to specific types of neural networks and datasets.', 'Potential loss of information due to blurring might affect performance on tasks requiring high spatial resolution.']",False,2,2,3,4,4,"['The idea of spatial smoothing is novel and potentially impactful for improving the efficiency of BNNs.', 'The paper provides both theoretical and empirical evidence to support the claims.', 'The method is shown to improve multiple aspects of model performance, including accuracy, uncertainty estimation, and robustness.', 'Comprehensive empirical evaluation across multiple models and datasets.']","['The paper lacks rigorous theoretical proofs and relies heavily on empirical results.', 'The clarity of the paper is compromised by the dense and sometimes unclear writing.', 'The experimental section could benefit from more comprehensive comparisons with state-of-the-art methods.', 'The limitations and potential negative societal impacts are not adequately discussed.', 'The reproducibility section needs more details on the experimental setup and hyperparameters.', 'Theoretical explanations lack depth and rigor.', 'Practical significance of the improvements is not clearly articulated.']",3,2,2,3,Reject
ZaVVVlcdaN,"The paper proposes FedChain, a novel framework for federated learning that combines the strengths of local and global update methods to achieve faster convergence and better communication efficiency. Theoretical contributions include new convergence rates and lower bounds. Empirical results support the theoretical claims with significant improvements over existing methods.","['Can you clarify the assumptions made regarding the bounds on variance and heterogeneity?', 'How does FedChain perform in highly heterogeneous and non-i.i.d. settings?', 'Are there practical considerations or limitations that should be addressed?', 'Can the authors provide more details on the experimental setup, including hyperparameter tuning and dataset partitioning?', 'How does the proposed method perform on other federated learning tasks and datasets?', 'Can the authors discuss the potential limitations and negative societal impacts of their work in more detail?', 'How does the proposed framework differ from existing methods that combine local and global update methods?', 'Can the authors provide more details on the theoretical analysis and include complete proofs?', 'Can the authors conduct more extensive experiments to evaluate the performance of the proposed framework on different datasets and scenarios?', 'Can the authors clarify how their approach significantly differs from similar ideas in the literature?', 'Could the authors provide more detailed experimental validation of the theoretical results?', 'How do the theoretical improvements translate to practical benefits in real-world federated learning applications?', 'Can the authors provide more detailed explanations and intuitions behind the theoretical analysis?', 'Can the authors expand the empirical evaluations to include more datasets and comparisons with other state-of-the-art methods?', 'What are the limitations and potential negative societal impacts of the proposed approach?']","['The assumptions on variance and heterogeneity may not hold in all practical scenarios.', ""The framework's generalizability to highly heterogeneous and non-i.i.d. settings is not thoroughly explored."", 'The paper does not adequately address the limitations of the proposed method, such as the complexity of implementation and potential scalability issues.', 'The authors should provide a more thorough analysis of the potential negative societal impacts of their work, such as privacy concerns and data bias.', 'The paper does not thoroughly investigate the potential negative societal impacts of its contributions.', 'The assumptions made in the theoretical analysis are quite strong and may not hold in practical scenarios.', 'The paper does not discuss the potential limitations of the FedChain framework, such as its scalability to a large number of clients or its performance in highly heterogeneous environments.', 'The paper does not address the potential negative societal impacts of federated learning, such as data privacy concerns and the potential for biased models.']",False,2,2,2,4,4,"['The combination of local and global update methods in federated learning is innovative and promising.', 'Strong theoretical foundations with new convergence rates and lower bounds.', 'Empirical results demonstrate significant improvements over existing methods.']","['The paper is dense and challenging to follow, especially for readers not intimately familiar with the theoretical aspects of federated learning.', 'Some assumptions (e.g., specific bounds on variance and heterogeneity) may not hold in all practical scenarios.', ""The framework's performance in highly heterogeneous and non-i.i.d. settings is not thoroughly explored."", 'Lack of clarity in experimental setup and hyperparameters.', 'Insufficient analysis of limitations and potential negative societal impacts.', 'Complexity of the proposed method may hinder practical implementation.', 'Empirical results are limited to specific datasets and may not generalize.', 'The originality of the contributions is questionable.', 'The theoretical analysis is incomplete and not entirely convincing.', 'The experiments are limited in scope and do not cover a wide range of datasets or scenarios.', 'The writing is somewhat unclear and disorganized.', 'The significance of the proposed framework is not well established.']",3,2,2,3,Reject
YJ1WzgMVsMt,"The paper presents a novel algorithm, Learning Online with Guidance Offline (LOGO), for reinforcement learning in sparse reward settings. It leverages offline demonstration data from sub-optimal policies to guide exploration and improve learning efficiency. The paper provides a theoretical performance guarantee and demonstrates the algorithm's effectiveness through simulations on the MuJoCo platform and real-world experiments with a TurtleBot.","['How does LOGO perform compared to other RL algorithms like PPO, DDPG, etc., outside of the TRPO framework?', 'Can the authors provide more insights into the limitations and potential drawbacks of LOGO?', 'How sensitive is the algorithm to the quality and quantity of the offline demonstration data?', 'Can the authors provide more detailed explanations of the mathematical notations and concepts used in the theoretical analysis?', 'What are the practical considerations and challenges in implementing the LOGO algorithm in different real-world scenarios?', 'Can the authors provide more details on how the discriminator is trained and validated?', 'How sensitive is the LOGO algorithm to the choice of hyperparameters?', 'Can the authors discuss any potential negative societal impacts of their approach?', 'Can the authors provide more details on the computational complexity of the LOGO algorithm?', 'How does LOGO perform on other benchmarks or real-world environments beyond the ones presented?', 'Can the authors clarify the adaptive rule for decaying δk in the algorithm?']","['The paper does not thoroughly address the limitations of LOGO, especially in terms of its dependency on TRPO and potential scalability issues.', 'The potential negative societal impacts of deploying RL algorithms in real-world settings are not discussed.', 'The algorithm may require fine-tuning of hyperparameters for different environments.', 'The reliance on sub-optimal behavior policies may limit performance improvement in some cases.', 'The approach assumes the availability of sub-optimal behavior policies, which might not always be feasible.', 'The reliance on TRPO may limit applicability to environments where TRPO is less effective.']",False,3,2,3,6,4,"['Innovative approach combining policy improvement and guidance using offline data.', 'Theoretical analysis and performance guarantees.', 'Extensive experiments on multiple benchmark environments and real-world validation.', 'Addresses a significant challenge in RL with sparse rewards.']","['Complexity in understanding the theoretical proofs and derivations.', ""Heavy reliance on TRPO, which might limit the algorithm's generalizability to other RL frameworks."", 'Insufficient discussion on limitations and potential negative societal impacts.', 'Some sections with dense mathematical notation may be challenging for readers less familiar with the topic.', 'The practical implementation details could be expanded for better reproducibility.']",3,3,2,3,Reject
kG0AtPi6JI1,"The paper introduces a novel method called sparse latent adaptation (SLA) to address the problem of learning over multiple visual domains without domain labels, termed latent domain learning. The method aims to dynamically adapt feature representations to instances from multiple domains using a learnable gating mechanism. The authors evaluate SLA on several benchmarks, including Office-Home, PACS, and DomainNet, and demonstrate its performance improvements over existing baselines.","['Can the authors provide more details on the implementation of the gating mechanism and how it was tuned during the experiments?', 'How does SLA compare to state-of-the-art methods in domain adaptation and domain generalization in terms of performance and computational efficiency?', 'Have the authors conducted any statistical significance tests to support their claims regarding the superiority of SLA?', 'Can the authors provide more details on how the choice of K affects the performance and complexity of the model?', 'What are the computational overheads associated with the proposed sparse adaptation strategy compared to standard methods?', 'Can the authors clarify the role of the gating mechanism in more detail, possibly with additional visualizations or examples?', 'Could the authors provide more details on how the selected benchmarks represent the generality of the proposed method?', 'Can the authors discuss the potential limitations and negative societal impacts of their method in more detail?']","['The paper does not discuss the potential computational overhead introduced by the gating mechanism in SLA.', 'The impact of SLA on the scalability of the model for large-scale datasets is not addressed.', 'There is a lack of discussion on the ethical considerations and potential societal impacts of the proposed method.', 'The method may suffer from overfitting with larger values of K, as indicated by the experimental results.', 'The choice of benchmarks might limit the generalizability of the results.', ""The method's reliance on a predefined number of latent domains (K) may limit its adaptability in different settings.""]",False,3,3,3,6,4,"['The paper addresses a relevant and challenging problem in the field of visual representation learning.', 'The proposed SLA method is novel and provides a flexible solution to the problem of latent domain learning.', 'The experimental evaluation is thorough, covering multiple benchmarks and comparing SLA to several baselines.', 'The paper is generally well-written and organized, making it easy to follow the main ideas and contributions.']","['The implementation details of SLA, particularly regarding the choice and tuning of the gating mechanism, are not thoroughly explained.', 'The results section could benefit from a more detailed comparison with state-of-the-art methods in related fields, such as domain adaptation and domain generalization.', 'The impact of the proposed method on computational efficiency and scalability is not discussed.', 'Some of the claims, such as the superiority of SLA over other latent domain methods, are not sufficiently supported by statistical significance tests.', 'The complexity of the method increases with the number of corrections (K), which may lead to overfitting issues.', 'The choice of benchmarks and datasets might be limited to specific domains, potentially limiting the generalizability of the results.', 'The paper lacks a thorough discussion on the potential limitations and negative societal impacts of the proposed method.']",4,3,3,3,Reject
o9DnX55PEAo,"The paper proposes a method for distilling large pretrained language models (PreLMs) into more efficient architectures using a bidirectional CMOW/CBOW-Hybrid model. The approach extends the CMOW/CBOW-Hybrid model with bidirectionality and introduces a two-sequence encoding scheme, achieving competitive performance on various NLP tasks with fewer parameters and faster inference speed.","[""Can the authors provide more details on the bidirectional component's implementation and its influence on the overall performance?"", 'How does the proposed method compare with other state-of-the-art distillation methods in terms of training time and resource efficiency?', 'What are the potential limitations of using CMOW/CBOW-Hybrid models in real-world applications?', 'Can the authors provide more details on the hyperparameter settings and training procedures to improve reproducibility?', 'How does the model perform on other challenging tasks beyond the GLUE benchmark?', 'Can the authors clarify the limitations and potential negative societal impacts of their approach in more detail?', 'Can the authors provide more detailed ablation studies to isolate the contributions of individual components?', 'How does the performance of the model vary with different embedding sizes?', 'What are the potential improvements for linguistic acceptability tasks?']","['The paper does not thoroughly discuss the limitations of the CMOW/CBOW-Hybrid model, such as its applicability to other types of tasks (e.g., question answering) or its scalability to larger datasets.', 'Potential negative societal impacts, such as biases in the distilled models, are not adequately addressed.', 'The trade-off between embedding size and downstream performance has not been thoroughly analyzed.']",False,3,2,3,5,4,"['Introduction of bidirectional components to CMOW/CBOW-Hybrid model.', 'Novel two-sequence encoding scheme for CMOW/CBOW-Hybrid.', 'Comprehensive experimental evaluation on the GLUE benchmark.', 'Efficient performance in terms of parameter count and inference speed.']","['The clarity of the paper can be improved; some sections are difficult to follow.', 'Limited novelty in some of the methods used (e.g., bidirectionality is well-explored in RNNs and LSTMs).', 'Insufficient discussion on the limitations and ethical concerns of the proposed approach.', 'While the results are promising, they do not significantly outperform existing models like MobileBERT in several key metrics.', 'Reproducibility of experiments is not well-addressed, with missing details on hyperparameter settings and training procedures.']",3,3,2,3,Reject
68n2s9ZJWF8,"The paper introduces Implicit Q-Learning (IQL), an offline reinforcement learning method that avoids querying out-of-sample actions during training. The method uses expectile regression to estimate state values and integrates these estimates into Q-function updates. This approach aims to mitigate distributional shift issues and demonstrates strong empirical performance on the D4RL benchmark.","['Can the authors provide more details on the implementation and tuning of expectile regression?', 'How does the performance of IQL compare to other recent offline RL methods not mentioned in the paper?', 'Could the authors expand on the theoretical analysis to better establish the generality of the method’s effectiveness?', 'Can the authors provide more insights on the choice of hyperparameter τ and its impact on the performance?', 'How does IQL perform in scenarios with highly sparse rewards?', 'Can the authors discuss potential limitations and societal impacts of their method in more detail?', 'Can the authors provide more justification for the choice of expectile regression over other techniques?', 'Is there publicly available code for reproducing the results presented in the paper?', 'How does the method perform on tasks outside of the D4RL benchmark?', 'Can the authors provide more detailed experimental results to ensure reproducibility?']","['The paper does not discuss the potential limitations of expectile regression and its tuning.', 'There is limited discussion on the generalizability of the method across different types of RL problems.', 'The impact of hyperparameter choices on the performance is not thoroughly analyzed.', 'Theoretical guarantees are not extensively discussed.', 'Potential overfitting to the D4RL benchmark without broader validation.', 'Limited information on the reproducibility of experiments.']",False,3,3,4,7,4,"['Proposes a novel approach to tackle the challenge of evaluating unseen actions in offline RL.', 'Achieves state-of-the-art performance on several D4RL benchmarks.', 'Computational efficiency and ease of implementation are highlighted.', ""Theoretical foundation supporting the method's effectiveness.""]","['The clarity of the explanation, particularly the theoretical aspects, could be improved.', 'The theoretical analysis could be more comprehensive.', 'Limited discussion on reproducibility and availability of code for replication.', 'The method might not be universally applicable to all offline RL problems.', 'Limited discussion on potential negative societal impacts or ethical concerns.']",4,3,3,4,Accept
z7DAilcTx7,"The paper introduces a novel approach to adversarial training by framing it within the distributional robustness optimization (DRO) framework and leveraging optimal transport theory. The authors propose the Adversarial Transport framework and an algorithm based on Langevin Monte Carlo to sample from the optimal adversarial distribution. The approach is validated on MNIST and CIFAR-10 datasets, demonstrating improvements over traditional PGD training in terms of robustness and training speed.","['Can the authors provide more extensive empirical validation on diverse datasets?', 'How does the approach compare with other state-of-the-art adversarial training methods beyond PGD?', 'Can the authors clarify the practical implementation details to enhance reproducibility?', 'How sensitive is the proposed method to the choice of hyperparameters, and how were these hyperparameters selected?', 'Can the authors clarify the specific advantages of using the ∞-Wasserstein distance over other distances in the context of adversarial training?', 'Is there a publicly available implementation or supplementary material to help reproduce the results?', 'Can the authors provide more justification for the chosen hyperparameters, especially λ?', 'How does the method perform on larger and more complex datasets beyond MNIST and CIFAR-10?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their approach?']","['The approach is primarily validated on MNIST and CIFAR-10, which are relatively simple datasets.', 'The dense technical presentation may limit the accessibility of the paper.', 'Potential scalability issues for larger and more complex datasets.', 'The method relies heavily on the correct tuning of hyperparameters, which might limit its applicability.', 'The assumption that ϵ < 1 might not hold in all practical scenarios, potentially limiting the generalizability of the results.', 'The paper does not address potential negative societal impacts of adversarial training techniques.']",False,3,2,3,5,4,"['Strong theoretical foundation connecting adversarial training with DRO and optimal transport.', 'Novel algorithm using Langevin Monte Carlo for sampling.', 'Improvements in robustness and training speed on MNIST and CIFAR-10 datasets.']","['Empirical validation is limited to MNIST and CIFAR-10, lacking broader applicability.', 'Complex and dense presentation, which may hinder understanding.', 'Insufficient comparison with a wider range of baselines.', 'Potential scalability issues for larger and more complex datasets.', 'The paper does not thoroughly address potential limitations and negative societal impacts.']",3,3,2,3,Reject
EcGGFkNTxdJ,"The paper presents HATRPO and HAPPO, novel extensions of TRPO and PPO for multi-agent reinforcement learning (MARL) with theoretical guarantees for monotonic improvement. The algorithms use a sequential policy update scheme and avoid parameter sharing. The paper includes theoretical analysis and empirical evaluation on Multi-Agent MuJoCo and StarCraftII benchmarks, showing that these methods outperform existing approaches.","['Can the sequential update scheme scale effectively to environments with a very large number of agents?', 'How sensitive are the proposed algorithms to the choice of hyperparameters?', 'Can the authors provide more intuitive explanations for the theoretical results?', 'Could the experimental results be supplemented with more rigorous statistical analysis?', 'What are the potential negative societal impacts of HATRPO and HAPPO?', 'Can the authors provide more intuitive explanations for some of the mathematical derivations?', 'How sensitive are HATRPO and HAPPO to hyperparameter choices, and how were the hyperparameters chosen for the experiments?', 'Can the authors elaborate on the computational complexity of HATRPO and HAPPO compared to traditional TRPO and PPO?', 'What are the practical limitations of assuming η-soft policies?']","['Theoretical complexity might limit accessibility to a broader audience.', 'Scalability of the sequential update scheme in environments with many agents.', 'The methods assume a fully-cooperative setting, which may not generalize to other types of multi-agent environments.', 'The computational cost of the proposed methods, especially HATRPO, might be high due to the need for sequential updates and KL-divergence calculations.', 'The paper does not fully address the practical limitations of the assumptions made (e.g., η-soft policies).', 'There is limited discussion on the broader societal impacts of the proposed methods.']",False,3,3,4,7,4,"['Novel theoretical contributions extending TRPO/PPO to MARL with guarantees of monotonic improvement.', 'Thorough empirical evaluation on benchmark tasks showing superior performance.', 'Clear explanation of methodologies and theoretical proofs.']","['Complexity of theoretical proofs might be difficult for practitioners to fully grasp.', 'Potential scalability issues with the sequential update schemes in large multi-agent systems.', 'Limited novelty in the practical implementation of HAPPO, which is a straightforward adaptation of PPO.', 'Dense and complex theoretical sections that could be better organized and explained.', 'Lack of rigorous statistical analysis in the experimental results.', 'Insufficient discussion on potential negative societal impacts.']",4,3,3,4,Accept
3pZTPQjeQDR,"The paper investigates how the size of the subword vocabulary learned by Byte-Pair Encoding (BPE) affects the memorization behavior of Transformer models. The authors demonstrate that larger BPE vocabularies lead to increased memorization capacity, as evidenced by improved performance in fitting random mappings, increased vulnerability to membership inference attacks, and higher accuracy in training data recovery tasks. The study spans multiple experimental setups and Transformer architectures.","['Can the authors provide more details on the practical implications of their findings? How can these insights be applied in real-world applications?', 'The explanation of why larger vocabularies lead to better memorization is somewhat vague. Could the authors provide a more detailed theoretical rationale?', 'How do these findings generalize to other subword tokenization methods beyond BPE?', 'Can the authors provide more examples or visualizations to help clarify the impact of BPE on memorization?', 'Could the authors provide more detailed explanations for the choice of hyperparameters and experimental settings?', 'How do the findings apply to real-world scenarios where memorization might be beneficial or harmful?', 'Could the authors discuss potential methods to mitigate the negative impacts of increased memorization, such as data leakage?']","['The study does not fully address the potential negative societal impact of enhanced memorization capabilities, such as data leakage.', 'The experiments are limited to specific datasets and Transformer architectures; the generality of the findings could be questioned.', 'The paper lacks a detailed discussion on how to balance memorization and generalization in practical applications.', 'Potential negative societal impacts, such as data leakage, are mentioned but not deeply explored.']",False,3,3,3,5,4,"['Comprehensive experimental design covering multiple tasks and model architectures.', 'Clear demonstration that larger BPE vocabularies enhance memorization even when controlling for the number of parameters.', 'Addresses an under-explored area in NLP regarding memorization in Transformer models.']","['Limited novelty as it builds on well-known techniques and existing knowledge.', 'Clarity issues, particularly in the explanation of certain experimental setups and the presentation of results.', 'The significance of the findings is somewhat incremental; the practical implications of the work are not fully explored or demonstrated.', 'Potential negative societal impacts, such as data leakage, are mentioned but not deeply explored.', 'The experiments are limited to specific datasets and Transformer architectures, which may affect the generalizability of the findings.']",3,3,3,3,Reject
AJO2mBSTOHl,"The paper proposes TAGI-DQN, a method that integrates Tractable Approximate Gaussian Inference (TAGI) into Deep Q-learning for Reinforcement Learning tasks. The method aims to match the performance of backpropagation-based DQNs while requiring fewer hyperparameters and avoiding gradient descent. Experimental results are provided for both on-policy and off-policy tasks, including Atari games.","['Can the authors provide more detailed comparisons with other state-of-the-art Bayesian RL methods?', 'How sensitive are the results to the choice of hyperparameters?', 'Can the authors clarify the mathematical derivations, particularly the assumptions and approximations used in TAGI?', 'How does the computational complexity of TAGI compare to traditional gradient-based methods in practice?', 'How does TAGI perform on a wider variety of RL benchmarks?', 'What specific measures can be taken to improve the computational efficiency of TAGI?', 'What are the potential limitations and failure cases of using TAGI for deep Q-learning?']","['Scalability needs further validation on more complex RL environments.', 'Potential computational inefficiency as noted in the slower training times compared to backpropagation.', 'Does not address the integration of TAGI into policy gradient methods or actor-critic frameworks.', 'Current implementation relies on MATLAB, limiting integration with other deep learning libraries like TensorFlow or PyTorch.', 'Potential negative societal impacts, such as unintended consequences of reinforcement learning models, are not discussed.']",False,2,2,2,4,4,"['Novel combination of Bayesian inference with Q-learning.', 'Promising empirical results on Atari games and simpler RL environments.', 'Reduction in the number of hyperparameters.']","['Dense and challenging to follow, particularly in the mathematical derivations and experimental setup.', 'Empirical validation needs more rigor, including hyperparameter sensitivity analysis and broader benchmarks.', 'Theoretical foundations of TAGI in the context of RL are not fully elaborated.', 'Limited empirical evaluation and lack of comprehensive performance comparison.', 'Computational efficiency is a concern with TAGI being slower than backpropagation.', 'No discussion on potential negative societal impacts or ethical considerations.']",3,2,2,3,Reject
YevsQ05DEN7,"The paper addresses the issue of dimensional collapse in contrastive self-supervised learning methods like SimCLR. It provides theoretical insights into the mechanisms causing collapse and introduces DirectCLR, a method that optimizes the representation space directly without a trainable projector. Empirical results on ImageNet demonstrate the effectiveness of DirectCLR.","['Can the authors provide empirical results on other datasets to validate the generalizability of DirectCLR?', 'How does DirectCLR compare with other recent non-contrastive methods in preventing dimensional collapse?', 'Can the authors clarify the practical implications of their theoretical findings in simpler terms?', 'Can the authors provide more comparisons with other state-of-the-art methods beyond SimCLR?', 'Can the theoretical analysis be made more accessible to a broader audience?', 'What are the potential negative societal impacts and limitations of DirectCLR?']","['The authors should discuss the potential impact of dimensional collapse in real-world applications.', 'Consideration of computational complexity and resources required for DirectCLR compared to existing methods.', 'Potential negative societal impacts are not discussed.', 'The empirical results are limited to a single dataset.', 'Theoretical analysis may be difficult to follow for a broader audience.']",False,3,3,3,7,4,"['Addresses a significant issue in self-supervised learning.', 'Provides solid theoretical foundations explaining dimensional collapse.', 'Proposes a novel method, DirectCLR, with empirical validation showing improved performance.', 'Includes empirical evidence showing the effectiveness of DirectCLR compared to SimCLR.', 'Well-written and well-organized.']","['The originality is somewhat limited as it builds on existing contrastive learning frameworks.', 'Empirical results are limited to ImageNet and lack broader validation across different datasets.', 'Clarity could be improved, especially in the dense mathematical sections.', 'The practical impact is limited without broader empirical validation.', 'Theoretical insights, while valuable, are complex and may be difficult for practitioners to fully grasp without substantial effort.', 'Potential negative societal impacts are not discussed.']",3,3,3,3,Reject
6Q52pZ-Th7N,"The paper proposes Pseudo-Labeled Auto-Curriculum Learning (PLACL) for semi-supervised keypoint localization. PLACL uses reinforcement learning to dynamically adjust pseudo-label thresholds and introduces a cross-training strategy to mitigate confirmation bias. The method is validated on multiple datasets, showing significant improvements over existing methods.","['Can the authors provide more details on the computational cost and efficiency of the proposed method?', 'How does the method perform compared to more recent baselines not included in the experiments?', 'Can the authors clarify the reinforcement learning framework and the cross-training strategy with more detailed explanations or diagrams?', 'How does PLACL perform on datasets not related to keypoint localization, such as object detection or semantic segmentation?', 'What are the specific computational requirements and potential optimizations for PLACL in a low-resource setting?', 'Can the authors provide more details on the hyperparameters used for the RL-based curriculum search?', 'How sensitive is the performance of PLACL to the choice of hyperparameters?', 'Can the authors elaborate on the potential negative societal impacts of this work?']","['The computational cost of the proposed method is relatively high, which may limit its applicability in resource-constrained environments.', ""The method's performance relies heavily on the quality of the reinforcement learning-generated curriculum, which might be sensitive to hyperparameter settings."", 'The paper does not thoroughly discuss potential limitations and the generalizability of the method to different domains or tasks.', ""The high computational complexity may limit the method's applicability in real-world scenarios with limited resources."", 'The paper does not fully address the potential negative societal impacts of using reinforcement learning for pseudo-label selection.']",False,3,3,3,7,4,"['Addresses a relevant and challenging problem in computer vision.', 'Innovative use of reinforcement learning for dynamic threshold adjustment.', 'Extensive experiments across multiple datasets with consistent improvements.', 'Cross-training strategy effectively addresses confirmation bias.']","['High computational complexity, which might limit applicability in resource-constrained settings.', 'Lack of clarity in the presentation of the reinforcement learning framework and its integration with pseudo-labeling.', 'Insufficient discussion of potential limitations and negative societal impacts.', 'Reproducibility of results may be challenging due to the complexity and computational requirements.']",4,3,3,4,Reject
XJFGyJEBLuz,"The paper introduces Born Again neural Rankers (BAR) for Learning to Rank (LTR) tasks, leveraging a novel listwise distillation framework and a teacher score transformation function. The authors demonstrate significant improvements over state-of-the-art models in empirical evaluations and provide theoretical insights into the effectiveness of their approach.","['Can the authors provide more details on the hyperparameters and tuning processes for reproducibility?', 'Why was the affine transformation chosen over Softmax for score normalization? Can further empirical evidence be provided for this choice?', 'How would the proposed methods perform on a broader range of datasets and real-world applications?', 'How do the results vary with different values of α in the proposed loss function?', 'Can the theoretical explanations be simplified for better understanding?', 'How does the proposed BAR framework handle potential overfitting issues?', 'What are the practical implications and scalability concerns of the proposed approach?', 'Can the authors elaborate on the robustness of the proposed method across different datasets and settings?', 'Can you provide more detailed theoretical justification for the necessity of your proposed listwise distillation framework?', 'How does BAR perform compared to other state-of-the-art models when considering computational efficiency and scalability?']","['The paper could benefit from more extensive experiments across diverse datasets to establish broader applicability.', 'Potential negative societal impacts are not discussed, which is crucial for responsible AI research.', 'The authors should discuss the potential negative societal impacts of improving ranking models, such as reinforcing biases in search engine results.', 'The paper lacks a thorough exploration of the limitations and practical challenges in implementing the proposed approach in real-world systems.']",False,3,3,3,4,4,"['Novel adaptation of Born Again Networks (BAN) to ranking problems.', 'Introduction of listwise distillation framework and appropriate teacher score transformation.', 'Strong empirical results outperforming state-of-the-art models.', 'Theoretical explanations on why listwise distillation is effective for neural rankers.']","['Complex and dense explanations that may be hard to follow.', 'Insufficient clarity on specific experimental settings and hyperparameters.', 'Limited evidence demonstrating broader applicability of the proposed methods beyond the datasets used.', 'Potential overfitting concerns due to the high performance improvements.', 'Theoretical contributions are not convincingly justified.', 'Potential negative societal impacts are not discussed, which is crucial for responsible AI research.']",3,3,3,3,Reject
u7UxOTefG2,"The paper investigates the effectiveness of Bayesian Neural Networks (BNNs) for out-of-distribution (OOD) detection, challenging the assumption that BNNs are inherently good at this task due to their epistemic uncertainty. The authors provide both theoretical analysis and empirical studies to show that common architectural choices do not necessarily lead to desirable OOD behavior. They highlight the importance of function space priors and discuss the trade-offs between generalization and OOD capabilities.","['How do the findings generalize to high-dimensional real-world data?', 'Can you provide more details on the experimental setup to enhance reproducibility?', 'What are potential solutions or future research directions based on your findings?', 'How would you recommend choosing function space priors for real-world applications?', 'Could you elaborate on the trade-off between generalization and OOD detection in more practical scenarios?']","['The study is based on low-dimensional problems, which may not generalize well to high-dimensional data.', 'The paper does not provide a clear path forward for improving OOD detection in BNNs.', 'Potential negative societal impacts include misapplication of BNNs in safety-critical systems based on misunderstood OOD detection capabilities.']",False,2,2,2,4,4,"['Addresses an important and timely topic.', 'Provides a thorough theoretical and empirical analysis.', 'Challenges a common assumption about BNNs and OOD detection, adding a critical perspective to the field.', 'Opens new avenues for research by questioning established beliefs.']","['Empirical studies are limited to low-dimensional settings, raising concerns about generalizability.', 'Some experimental results lack clarity and reproducibility details.', 'Does not provide a robust solution to the identified problem or actionable insights for improving OOD detection in BNNs.', 'Limited discussion on how findings can be generalized to high-dimensional real-world data.']",3,3,3,3,Reject
30nbp1eV0dJ,The paper presents tight lower bounds for differentially private empirical risk minimization (DP-ERM) for general convex functions. It introduces novel techniques such as the biased mean property for fingerprinting codes and achieves tight lower bounds for both approximate-DP and pure-DP settings.,"['Can the authors provide more context or practical applications where these theoretical improvements are critical?', 'Are there any empirical demonstrations or experimental validations that can support the theoretical claims?', 'Can the authors elaborate on potential limitations and negative societal impacts of their work?']","['The paper does not discuss potential negative societal impacts.', 'The practical applications and significance of the theoretical improvements are not clearly articulated.']",False,3,3,3,6,4,"['Addresses a significant gap in the literature by providing tight lower bounds for differentially private ERM.', 'Introduces novel techniques, such as the biased mean property for fingerprinting codes, which may be of independent interest.', 'Provides rigorous mathematical proofs to support the claims.']","['The paper is dense and difficult to follow due to heavy use of technical jargon and complex mathematical formulations.', 'The practical significance and impact of the theoretical improvements are not clearly articulated.', 'Lack of experimental validation or empirical demonstrations to support the theoretical claims.', 'The paper does not adequately address potential negative societal impacts or limitations.']",3,3,3,4,Reject
AJAR-JgNw__,"The paper presents DEPTS, a deep learning framework for periodic time series (PTS) forecasting. It addresses the challenges of complex dependencies on periodicity and various period compositions. DEPTS introduces an expansion module for layer-by-layer expansion of dependencies and a periodicity module to capture diversified periods. The framework also provides interpretability by distinguishing contributions from local momenta and global periodicity. Extensive experiments on synthetic and real-world data show that DEPTS outperforms state-of-the-art methods.","['Can the authors provide more details on the initialization strategy for periodic coefficients and its impact on the overall performance?', 'What is the computational complexity of DEPTS compared to other state-of-the-art methods? How does it scale with large datasets?', 'Can the authors provide more insights into the interpretability of the model? Are there examples where the interpretability provided actionable insights?', 'How does DEPTS perform compared to a broader set of baselines, including traditional statistical models and other deep learning approaches?', 'What measures have been taken to ensure that the model does not overfit to the training data, especially given the complexity of the periodicity module?', 'Can the authors provide more clarity on how the periodicity module parameters are initialized and optimized?', 'Are there any potential negative societal impacts of the proposed approach that need to be considered?', 'Can the authors provide more theoretical analysis to support their claims?', 'What are the specific hyperparameters used in the experiments?', 'Can the authors discuss any failure cases or limitations of their approach?', 'Can the authors elaborate on the practical implications and scalability of DEPTS in real-world scenarios?', 'How does the model perform with less hyperparameter tuning or in scenarios with limited computational resources?']","[""The initialization strategy for periodic coefficients is crucial for the model's performance but is not thoroughly evaluated."", 'The scalability and computational complexity of the model are not well discussed.', 'The interpretability analysis is limited and could be expanded to show more practical use cases.', 'The paper does not provide a detailed discussion on the potential negative societal impacts of DEPTS.', 'There is limited information on the generalization capabilities of the model and how overfitting is avoided.', 'Clarity in the explanation of the expansion and periodicity modules needs improvement.', ""The model's effectiveness might be limited to the datasets used in the experiments."", 'Potential overfitting due to the complexity of the model.', 'The complexity of the model might pose challenges for practical deployment.', 'Extensive hyperparameter tuning might lead to overfitting.', 'Scalability and robustness in diverse real-world scenarios need further exploration.']",False,3,3,3,6,4,"['Novel approach specifically designed for PTS forecasting.', 'Clear identification and addressing of key challenges in PTS forecasting.', 'Innovative use of expansion and periodicity modules.', 'Extensive experiments demonstrating significant improvements over baselines.', ""Provision of interpretability in the model's predictions."", 'Comprehensive theoretical exposition and detailed architecture design.', 'Publicly available code for reproducibility.']","['The initialization strategy for periodic coefficients could be more rigorously evaluated.', 'Limited discussion on the computational complexity and scalability of the proposed method.', 'The paper could benefit from a detailed comparison with more diverse state-of-the-art models.', 'The interpretability analysis is somewhat limited and could be expanded.', 'Evaluation is overly reliant on comparison with N-BEATS and lacks diversity in baselines.', 'Clarity issues in some sections, particularly in the explanation of the expansion and periodicity modules.', 'Potential overfitting and generalization issues not adequately addressed.', 'Insufficient details on hyperparameters and experimental settings for reproducibility.', 'Complexity of the model and reliance on hyperparameter tuning.', 'The robustness of the approach in diverse real-world scenarios needs further exploration.']",4,3,3,3,Accept
Uxppuphg5ZL,The paper proposes a novel framework for learned physical simulation using a constraint-based approach with a Graph Neural Network (GNN) as the constraint function and gradient descent as the solver. It tests the model on various physical domains and demonstrates better or comparable performance to state-of-the-art simulators. Key advantages include the ability to generalize to more solver iterations at test time and incorporating hand-designed constraints.,"['Can you provide a more detailed comparison with other baseline methods?', 'How does the model scale to larger, real-world problems?', 'Can you clarify the mathematical formulation and provide more intuitive explanations?', 'What are the computational overheads of the proposed method compared to traditional forward models?', 'How sensitive is the model to the choice of hyperparameters, especially the step size λ in the gradient descent solver?', 'Are there any specific limitations or scenarios where the proposed method might underperform compared to forward models?', 'Can the authors provide more details on the choice of hyperparameters and the specifics of the experimental setups?', 'How does the performance of the model scale with increasing complexity of the physical systems?', 'Can the authors discuss any potential negative societal impacts of their work?', 'Can the authors provide more details on the computational overhead associated with the iterative constraint-solving process?', 'Can the authors clarify the hyperparameters used in the experiments and provide more details on the training process?', 'How does the proposed method compare in terms of computational efficiency with other state-of-the-art simulators?', 'How does C-GNS compare with state-of-the-art methods on larger and more diverse datasets?', 'What measures are taken to ensure stability and convergence, particularly for the C-GNS-FP variant?']","['The scalability to real-world problems is not thoroughly addressed.', 'The computational complexity of the gradient descent solver might be high.', 'Potential issues with stability as indicated in the discussion on C-GNS-FP.', 'Potential negative societal impacts, such as the misuse of physical simulation in harmful applications, are not addressed.', 'Stability and convergence issues are noted, especially for the C-GNS-FP variant.', 'Limited evaluation on larger and more diverse datasets.']",False,3,3,3,6,4,"['Innovative use of GNN for constraint functions.', 'Thorough experimental evaluation on multiple physical domains.', 'Demonstrates ability to generalize to new constraints and solver iterations.', 'Potential to bridge traditional physics-based simulation methods with learned approaches.']","['Clarity issues in detailed mathematical formulation.', 'Insufficient comparison with a broader range of baseline models.', 'Limited discussion on practical applicability and scalability.', 'The novelty might be overstated without clearer differentiation from existing methods.', 'Dense and sometimes unclear presentation.', 'Limited discussion on hyperparameter choices and specific experimental setups.', 'Lack of discussion on potential negative societal impacts.', 'Potential reproducibility issues due to the technical complexity of the proposed method.']",4,3,3,3,Reject
3PN4iyXBeF,The paper proposes the Amortized Implicit Gradient Optimization (AmIGO) algorithm for bilevel optimization problems. It leverages warm-start strategies and presents a unified theoretical framework for analyzing its convergence in both stochastic and deterministic settings. The authors demonstrate that AmIGO matches the computational complexity of oracle methods and validate the algorithm through synthetic and practical experiments.,"['Can the authors provide more details on the potential limitations and negative societal impacts of their work?', 'How does AmIGO compare with other state-of-the-art bilevel optimization methods in terms of practical performance on large-scale datasets?', 'Can the authors elaborate on the choice of hyperparameters and their sensitivity analysis?', 'Can you provide more intuition behind the warm-start strategy and its impact on the convergence rates?', 'How does the performance of AmIGO vary with different choices of the hyperparameters, such as step-sizes and batch sizes?', 'Can you discuss the potential limitations or challenges of applying AmIGO to non-smooth or non-convex inner-level problems?', 'Can the authors provide more details on the experimental setup, including the choice of hyperparameters?', 'How does AmIGO perform when the inner-level problem is not strongly convex?', 'Can the authors elaborate on how the warm-start strategy affects the convergence rate in practical scenarios?', 'Can you provide more detailed implementation guidelines and hyper-parameter settings to facilitate reproducibility?', 'Could you expand on the limitations and potential negative societal impacts of your work?']","['The paper does not fully address the potential limitations and negative societal impacts of the proposed method.', 'The clarity of the presentation could be improved, particularly in explaining the theoretical framework and experimental setup.', 'The experiments focus on specific tasks and datasets. Additional experiments on a wider range of problems would strengthen the empirical analysis.', 'The analysis relies on certain assumptions about the smoothness and convexity of the functions involved. Discussing the impact of these assumptions on the applicability of the algorithm in more general settings would be beneficial.', 'The potential negative societal impacts of this work are not discussed in detail.']",False,3,3,3,7,4,"['Novel use of warm-start strategies in bilevel optimization.', 'Unified theoretical framework for convergence analysis.', 'Comprehensive experimental validation on synthetic and practical tasks.', 'Achieves computational complexity comparable to unbiased oracle methods.']","['Presentation could be clearer, especially in explaining complex theoretical concepts.', 'Potential limitations and negative societal impacts are not fully addressed.', 'Comparison with existing methods could be more thorough.', 'Some experimental details are not fully explained, making reproducibility challenging.']",4,3,3,4,Accept
Ih7LAeOYIb0,"The paper proposes the Iterative Memory Network (IMN), an end-to-end differentiable framework for long sequential user behavior modeling in recommender systems. IMN uses a target item as a memory trigger to elicit relevant information from long sequences through multiple iterations, updating a memory vector that encapsulates sequence information. The method aims to address the shortcomings of existing RNN and attention-based methods, demonstrating improvements in Click-Through Rate (CTR) on both public and industrial datasets. The paper also includes a comprehensive set of experiments, including ablation studies, to validate the proposed method.","['Can the authors provide a more detailed theoretical analysis to support their claims?', 'How does IMN compare to the latest advancements in efficient attention mechanisms (e.g., sparse or approximated attention)?', 'Can the authors clarify the specific implementation details needed to reproduce the results, particularly for the industrial dataset?', 'How does the IMN handle cases where the user behavior sequences are highly sparse or have missing data?', 'Can the authors provide more details on the hyperparameter settings and experimental configurations to enhance reproducibility?', 'What are the potential limitations or failure modes of IMN, particularly in diverse real-world scenarios?']","['The paper does not thoroughly address potential negative societal impacts of the proposed method.', ""The method's applicability to other domains beyond recommender systems is not discussed."", 'The potential impact of the method on user privacy is not discussed.', 'The scalability of the method to even longer sequences (e.g., beyond 1000) is not explored.']",False,3,3,3,7,4,"['The proposed IMN addresses the limitations of existing RNN and attention-based methods for long sequential data.', 'Empirical results show significant improvements over state-of-the-art methods on both public and industrial datasets.', 'The method is scalable, with only O(L) memory and time complexity, making it suitable for long sequences.', 'The paper includes a comprehensive set of experiments, including ablation studies, to validate the proposed method.', 'Significant real-world application impact with a 7.29% improvement in CTR.']","['The originality of the method is somewhat limited, as it primarily combines existing techniques in a novel way.', 'The paper lacks detailed theoretical analysis to support some of its claims.', 'Certain parts of the paper are not clearly written, making it difficult to follow the methodology and reproduce the results.', 'The impact of the proposed method on the broader field of machine learning and its practical implications are not fully explored.', 'Potential negative societal impacts of recommender systems, such as reinforcing filter bubbles, are not discussed.']",3,3,3,3,Reject
7Bc2U-dLJ6N,"The paper introduces SGEM, an optimization algorithm that integrates energy and momentum for non-convex stochastic optimization problems. The method builds on AEGD and aims to offer better convergence and generalization. Theoretical contributions include energy stability proofs, convergence rates, and regret bounds. Experiments show improved performance over AEGD and SGDM in some deep learning tasks.","['Can the authors provide more intuitive explanations for the theoretical results?', 'How does SGEM perform on a wider range of benchmarks and real-world tasks?', 'What are the potential limitations and negative societal impacts of SGEM?', 'Can the authors provide more details on the experimental setup, including the choice of hyperparameters?', 'How does SGEM compare with the latest optimization algorithms not discussed in the related work?', 'What are the limitations of SGEM in terms of scalability and practical deployment?']","['The paper does not discuss the potential limitations of SGEM in detail.', 'The impact of the proposed method on different types of optimization problems is not thoroughly explored.', 'The potential negative societal impacts of the method are not addressed.', 'The empirical evaluation is limited in scope and could benefit from additional benchmarks.', 'The practical applicability of the theoretical results is not thoroughly discussed.', 'The complexity of the algorithm might hinder its adoption in practice.']",False,3,3,3,5,4,"['Theoretical contributions: energy stability, convergence rates, and regret bounds.', 'Novel combination of energy-based gradient descent and momentum.', 'Empirical results demonstrating improved performance over AEGD and SGDM.']","['Limited novelty: primarily an extension of AEGD with momentum.', 'Dense and complex theoretical analysis with limited practical significance.', 'Insufficient empirical validation: experiments are not extensive enough.', 'Lack of detailed discussion on limitations and ethical considerations.', 'Writing can be improved for clarity, especially in explaining intuitive aspects.', 'The related work section is not comprehensive, missing recent advances and comparisons.', 'Experimental details are sparse, and it is unclear whether the experiments can be reproduced.', 'The practical impact and scalability of the method are not well discussed.']",3,3,3,3,Reject
rTAclwH46Tb,"The paper introduces Eigencurve, a learning rate scheduler designed to achieve minimax optimal convergence rates for SGD on quadratic objectives with skewed Hessian spectrums. Theoretical analysis and empirical results on CIFAR-10 and ImageNet demonstrate its effectiveness.","['Can the authors provide more insights into the practical scenarios where their assumptions (e.g., skewed Hessian spectrums) hold?', ""How computationally feasible is it to estimate the Hessian's eigenvalue distribution for large-scale models?"", 'Can the authors provide a more intuitive explanation of the theoretical results for a broader audience?', 'How sensitive is the performance of Eigencurve to errors in the estimation of the Hessian spectrum?', 'Can the authors provide more empirical results on diverse tasks and datasets?', 'What are the potential societal impacts of adopting Eigencurve in real-world applications?']","['The paper assumes skewed Hessian spectrums, which may not hold in all practical scenarios. Authors should discuss the implications of this assumption in more detail.', ""The computational cost of estimating the Hessian's eigenvalue distribution is high. The authors should explore ways to mitigate this issue."", ""The reliance on the Hessian spectrum's prior estimation is a significant limitation, as it can be impractical for large models."", 'The generalizability of the empirical results to other models and datasets is not well established.', ""Potential negative societal impact is minimal, but the method's scalability and feasibility in real-world applications remain a concern.""]",False,3,3,3,6,4,"['Novel approach that incorporates the eigenvalue distribution of the Hessian into learning rate scheduling.', 'Detailed theoretical analysis and proofs.', 'Promising empirical results on CIFAR-10 and ImageNet datasets.']","['Relies on specific assumptions (e.g., skewed Hessian spectrums) that may not hold universally.', ""Estimating the Hessian's eigenvalue distribution can be computationally expensive and impractical for large models."", 'Limited experimental validation across diverse tasks and datasets.', 'Clarity of the paper could be improved, particularly in explaining complex theoretical concepts to non-experts.', 'Potential societal impacts and limitations are not thoroughly discussed.']",4,4,3,4,Reject
ZumkmSpY9G4,"The paper proposes a generative framework to address the logits bias problem in online class-incremental learning (CIL). The method replaces the softmax classifier with a nearest-class-mean (NCM) classifier and introduces a pair-based metric learning loss (MS loss) for feature space optimization. Additionally, a hybrid loss is proposed to improve learning from new data. Extensive experiments on multiple datasets demonstrate the superiority of the proposed method over state-of-the-art replay-based methods.","['Can the authors provide more details on the theoretical proofs to improve clarity?', 'How does the method perform with different memory sizes in a more detailed manner?', 'Can the authors discuss the limitations of the proposed method in more detail?', 'Can the authors provide more details on the computational overhead introduced by the proposed method?', 'How sensitive is the performance to the choice of hyperparameters for the MS loss?', 'Are there any specific scenarios where the proposed method might perform poorly compared to traditional methods?', 'Can the theoretical analysis linking MS loss with generative classification be expanded?', 'How does the proposed method perform compared to advanced regularization techniques?', 'Can the experimental validation be extended to more diverse and real-world datasets?', 'Can the dense theoretical sections be supplemented with more intuitive explanations?', 'How does the proposed method perform in scenarios where the assumption of uniform class distribution does not hold?', 'Can the authors provide more intuitive explanations or visualizations for the theoretical derivations of the loss functions?', 'How sensitive is the method to the choice of hyperparameters, especially the weight of the Proxy-NCA loss?', 'Can the authors provide more details on the hyperparameter tuning process?', 'What are the potential limitations of the proposed method?', 'Can the method be applied to other types of continual learning tasks beyond class-incremental learning?']","['The method assumes the availability of a replay memory, which might not be practical in all scenarios.', 'The theoretical analysis might be difficult for some readers to follow, impacting reproducibility.', 'The reliance on the MS loss might complicate the tuning of hyperparameters.', 'The method might introduce additional computational overhead which needs to be discussed in more detail.', 'The theoretical analysis could be more comprehensive.', 'The experimental setup lacks diversity in datasets and real-world scenarios.', 'The paper could be clearer with more intuitive explanations of complex concepts.', 'Assumption of uniform class distribution might not be practical.', 'Reliance on a fixed replay memory size might limit scalability.', ""The method's performance might depend heavily on the choice of hyperparameters, which is not thoroughly discussed."", 'The generative approach, while theoretically sound, may have practical limitations not fully explored in the paper.']",False,3,3,3,6,4,"['Novel approach to bypass logits bias in online CIL.', 'Comprehensive theoretical foundation for the proposed method.', 'Extensive experimental evaluation on multiple datasets.', 'Significant improvements over state-of-the-art methods.']","['Theoretical proofs are complex and might be difficult for some readers to follow.', 'Insufficient discussion of ablation studies and comparisons with existing methods.', 'Clarity of the paper could be improved in some sections.', 'More discussion needed on the computational overhead of the proposed method.', 'Reliance on the MS loss and its hyperparameters might complicate adoption.', 'Theoretical analysis of the MS loss is not deeply explored.', 'Lacks comparison with advanced regularization techniques.', 'Experimental validation could benefit from more diverse datasets.', 'Assumptions (e.g., uniform class distribution) might not always hold.', 'Reproducibility details are sparse, particularly regarding hyperparameter tuning.', 'Potential limitations and societal impacts are not comprehensively addressed.']",4,3,3,4,Reject
MkTPtnjeYTV,"The paper investigates the memorization power of ReLU neural networks, showing that such networks can memorize any N points under a mild separability assumption using O(√N) parameters. This bound is argued to be optimal up to logarithmic factors. The authors also provide a generalized construction for networks with depth bounded by 1 ≤ L ≤ √N, and discuss the necessity and sufficiency of large bit complexity for memorization with a sub-linear number of parameters.","['Can you provide empirical validation of your theoretical results?', 'How do the theoretical assumptions hold in practical scenarios?', 'Could you clarify certain notations and technical details, particularly in Section 3?', 'Can the authors provide more intuitive explanations for the key steps in their proofs?', 'Are there any potential practical applications or experimental validations that could be derived from these theoretical results?', 'How does the required bit complexity in practice compare with the theoretical bounds presented?', 'What are the practical implications of the large bit complexity required for the proposed constructions?', 'How does the construction perform in practical scenarios where bit precision is limited?', 'How do the assumptions on data point separability affect the practical applicability of the results?', 'Can the presentation be improved to be more accessible to a wider audience?']","['The paper does not address the potential negative societal impacts of its findings, such as the misuse of neural networks for data memorization in sensitive applications.', 'The assumption that the input dimension d is at most O(√N) may not hold for all practical datasets.', 'The practical implications of the bit complexity and parameter bounds are not well explored.']",False,3,2,2,4,4,"['Thorough theoretical analysis.', 'Connection to existing work on VC-dimension and memorization bounds.', 'Novel contribution in demonstrating optimal memorization bounds up to logarithmic factors.', 'Extends results to networks with bounded depth and bit complexity.']","['Highly theoretical focus with limited practical applicability.', 'Lack of empirical validation.', 'Clarity issues in the explanation of technical details and notation.', 'Potential negative societal impacts not addressed.', 'Dense and difficult to follow, impacting clarity.', 'Assumptions on data separability may limit practical applicability.']",3,3,1,2,Reject
hOaYDFpQk3g,"The paper presents LightWaveS, a distributed framework for multivariate time series classification (MTSC) that integrates wavelet scattering and distributed feature selection to improve efficiency over the ROCKET model. The method achieves significant inference speedups while maintaining comparable accuracy.","['Could you provide more details on the specific wavelets used and how they were selected?', 'How does LightWaveS handle datasets with vastly different scales and noise levels?', 'What are the practical implications of the trade-offs between accuracy and inference speedup for different application scenarios?', 'Can the authors provide clearer explanations of the proposed method and its components?', 'How were the datasets chosen, and how do they represent typical MTSC problems?', 'Could the authors provide more detailed comparative analysis with deep learning models?', 'What steps can be taken to improve the reproducibility of the proposed method?', 'Can you provide more details on the potential negative societal impacts of your work?', 'How do you plan to address the moderate accuracy loss in certain datasets?', 'Could you elaborate on the choice of 500 features as the default number?', 'How does LightWaveS perform on a broader range of MTSC datasets not included in the UEA archive?', 'Can the authors provide more detailed theoretical justifications for the chosen wavelet scattering and feature selection methods?', 'What are the potential negative societal impacts of deploying LightWaveS, especially in critical applications like healthcare?']","['The limitations are adequately addressed in terms of the potential trade-offs between accuracy and inference speed, and the challenges of reproducibility due to the complexity of the method.', 'The paper does not address potential negative societal impacts of the work.', ""The emphasis on efficiency over accuracy may limit the method's applicability in scenarios where accuracy is paramount."", 'The trade-off between accuracy and speedup might not be acceptable for all applications.', 'Potential overfitting to the datasets used.']",False,3,2,3,5,4,"['Innovative approach using wavelet scattering and distributed feature selection.', 'Significant inference speedups (9x to 65x) compared to ROCKET.', 'Demonstrates linear scalability with the number of channels and effectiveness in a distributed environment.', 'Focuses on practicality and efficiency, important for real-world applications, especially in edge computing.', 'Comprehensive experimental evaluation.']","['Complexity in the description of the method might be difficult for readers unfamiliar with wavelet theory and ROCKET.', 'Limited evaluation with other state-of-the-art methods in MTSC.', 'Reproducibility might be challenging due to the complexity of the method.', 'Densely written and difficult to follow in some sections.', 'Does not consistently outperform state-of-the-art methods in terms of accuracy.', 'Comparative analysis with other methods could be more comprehensive.', 'Experimental settings and dataset choices are not sufficiently justified.', 'Potential overfitting to evaluated datasets.', 'Limited discussion on potential negative societal impacts.']",3,3,3,3,Reject
7MV6uLzOChW,"The paper presents a method for conditional image generation using pretrained VAE models, aiming to reduce training times and improve sample quality. The approach is evaluated on several tasks, including image inpainting, and demonstrates competitive results compared to GANs. Key contributions include faster training times due to leveraging pretrained models, empirical results indicating superior mode coverage, and a potential application in Bayesian experimental design.","['How sensitive is the method to the choice of the pretrained model?', 'Can the authors provide more details on how the pretrained models were selected and any specific criteria followed?', 'How does the performance vary when using pretrained models from datasets that are significantly different from the target dataset?', 'Can you clarify the theoretical justifications provided in Theorem 3.2?', 'Could you provide more details on the specific architectures used for the partial encoder and how they differ from the original encoder?', 'How does the method perform on tasks other than image completion and Bayesian optimal experimental design?', 'Can the authors provide more details on the scalability of their method for very high-dimensional data?', 'How does the method perform in scenarios where high-quality pre-trained models are not available?', ""Can the authors address potential failure cases and their impact on the method's performance?"", 'Can the method handle significant domain shifts between pretrained and target datasets?', 'Are there any additional steps required to mitigate biases in medical imaging applications?', 'Can the authors provide more details on the implementation and hyperparameters used in the experiments?', 'Can the authors discuss any potential negative societal impacts in more detail?']","['The reliance on pretrained models limits its applicability to scenarios where such models are not available or not suitable.', 'The current validation is limited to image inpainting and a few other tasks; broader validation would be beneficial.', 'Potential dataset mismatch issues when transferring pretrained models to new tasks or domains.', 'Ethical considerations related to biases in medical imaging need further exploration.']",False,3,3,3,6,4,"['Leveraging pretrained models to reduce training times is a significant practical contribution.', 'Empirical results indicate that the method outperforms state-of-the-art on certain metrics.', 'The potential application in Bayesian experimental design is well-motivated and interesting.', 'Comprehensive experimental evaluation across multiple datasets and tasks.', 'Solid theoretical underpinnings and empirical evidence.']","['The method depends on the availability of pretrained unconditional VAEs, which may not always be suitable for the target dataset.', 'Some explanations, particularly around theoretical contributions, could be clearer and more concise.', 'Validation on diverse datasets and additional tasks would strengthen the claim of generalizability.', ""The paper's clarity is hindered by dense text and could benefit from more visual aids to explain complex concepts."", 'Theoretical justifications lack clarity in certain parts.', 'Potential negative societal impacts, such as misuse in generating realistic deepfakes, are not thoroughly addressed.']",3,3,3,3,Reject
vcUmUvQCloe,"The paper introduces joint Shapley values, extending the Shapley value to measure the average marginal contribution of sets of features in a model's predictions. Theoretical foundations are provided, and the concept is illustrated through experiments on different datasets.","['Can the authors provide more extensive experimental validation on diverse real-world datasets?', 'How does the computational cost compare with existing methods like interaction indices and the Shapley-Taylor interaction index?', 'Can the presentation be simplified or key ideas highlighted to make the paper more accessible?', 'How does the proposed approach compare to other extensions of Shapley values in terms of computational complexity?', 'Can the authors provide more intuitive explanations or visualizations to help understand the key concepts?', 'What are the practical implications and usability of joint Shapley values in real-world scenarios?', 'Can you provide more detailed comparisons with existing interaction indices in the empirical section?', 'How does the computational complexity scale with larger datasets in practice?', 'Could you elaborate more on the ethical considerations and potential societal impacts of your work?', 'Can the authors provide a clearer explanation and organization of the key concepts and proofs?', 'How do joint Shapley values compare with existing methods in terms of computational efficiency and accuracy?', 'Can the authors discuss the potential limitations and societal impacts of their approach in more detail?', 'Can the authors provide more details on the implementation and experimental setup to address reproducibility concerns?']","['The computational cost may be prohibitive for large datasets or high values of k.', 'The evaluation is mostly theoretical with limited practical validation on real-world datasets.', 'The paper does not adequately address computational complexity and scalability issues.', 'Limited discussion on potential negative societal impacts.', 'More practical examples and clearer explanations of the experimental results are needed.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed approach. For example, how does the method handle high-dimensional data or correlated features? What are the computational constraints?', 'The authors mention the rapid increase in computational cost with higher-order explanations (k).', 'The paper does not address how the method scales with larger datasets beyond theoretical complexity.', 'Ethical considerations are mentioned only briefly without an in-depth discussion.', 'The societal impacts of the approach are not addressed.']",False,3,2,2,4,4,"['Novel extension of Shapley value to sets of features.', 'Comprehensive theoretical proofs and axiomatic foundations.', 'Illustrations on game theoretical models, simulated data, and real-world datasets.']","['Experimental validation may not fully demonstrate practical usefulness.', 'High computational cost could limit practical application.', 'Dense and difficult to follow for readers not familiar with the theoretical background.', 'Limited discussion on computational complexity and scalability.', 'Insufficient comparison with existing methods to clearly demonstrate the advantages of joint Shapley values.', 'Inadequate discussion of potential limitations and societal impacts.', 'Concerns about the reproducibility of the results due to the lack of detailed implementation and experimental setup.']",3,3,2,3,Reject
fHeK814NOMO,"The paper proposes an algorithm for automatically adjusting the learning rate during gradient descent by treating it as a trainable parameter. This approach leverages first and second-order gradients to optimize the learning rate alongside model weights. The method is evaluated through extensive experiments across various settings, demonstrating robustness to initial learning rates and batch sizes.","['Can the authors provide more clarity on the derivation of the second-order gradients?', 'How does the method scale with very large networks and datasets?', 'Are there any specific strategies to handle the additional complexity introduced by the meta-learning rate?', 'Can the authors provide more detailed theoretical guarantees for the convergence of the proposed methods?', 'How does the proposed method perform in scenarios with significantly different data distributions or non-standard architectures?', 'Can the authors elaborate on the potential negative societal impacts and ethical considerations of their work?', 'How does the proposed method perform on more diverse and challenging benchmarks beyond the datasets used?', 'Can the authors provide a more detailed analysis of the computational overhead in large-scale settings?', 'What are the potential limitations and ethical considerations of the proposed method?', 'Can the authors compare their approach to newer adaptive learning rate methods?']","['Potential scalability issues with large networks.', 'Additional hyperparameter tuning required for the meta-learning rate.', 'The robustness and sensitivity of the method to different hyperparameter settings need further exploration.', 'The theoretical analysis of convergence guarantees is insufficient.', 'The method may not generalize well to all types of non-convex loss functions.', 'The choice of the bound c in the second-order method can affect convergence.', 'Sensitivity to initial hyperparameters and update frequencies needs to be systematically studied.', 'There is no discussion of potential ethical considerations, such as the environmental impact of increased computational requirements.']",False,3,2,3,5,4,"['Addresses a significant problem in deep learning optimization.', 'Novel approach by treating the learning rate as a trainable parameter.', 'Extensive experimental evaluation across various datasets and architectures.', 'Computationally efficient with minimal overhead.']","['Dense and somewhat unclear explanations, particularly in the derivation and implementation sections.', 'Theoretical analysis lacks depth and rigor, particularly concerning convergence guarantees.', 'Potential scalability concerns for very large networks and datasets.', 'Additional complexity in terms of hyperparameter tuning for the meta-learning rate.', 'Limited exploration of the robustness and sensitivity of the method to different hyperparameters.', 'Insufficient discussion on the potential negative societal impacts and ethical considerations.']",3,3,2,3,Reject
rqolQhuq6Hs,The paper introduces a novel theoretical framework for understanding the escape dynamics of stochastic gradient descent (SGD) by transforming the loss landscape into a logarithmic scale. It derives a stochastic differential equation (SDE) with additive noise and proposes an escape rate formula dependent on the logarithmized loss barrier height. The work is validated through experiments on linear regression and neural networks.,"['How does this work fundamentally differ from existing theories on SGD dynamics?', 'Can the authors provide more rigorous justification for the decoupling approximation and other assumptions made in the derivation?', 'How robust are the experimental results? Can they be replicated in different settings and with different architectures?', 'Can the authors discuss potential limitations and ethical concerns of their work in more detail?', 'How does the proposed framework compare to existing methods in terms of computational efficiency?', 'What are the implications of the findings for practical applications of SGD?', 'Can the authors provide more intuitive explanations or diagrams to improve the clarity of the theoretical contributions?', 'How do the theoretical findings extend to more complex, real-world deep learning tasks?', 'Can additional experiments be conducted to validate the theoretical claims on more complex models and datasets?']","['The paper relies on several approximations and assumptions, which might limit the generalizability of the findings.', 'The experimental validation is limited in scope.', 'The potential negative societal impacts and ethical considerations are not adequately addressed.']",False,2,2,3,5,4,"['Provides a novel perspective on SGD dynamics using a logarithmic transformation.', 'Derives a new escape rate formula that explains the preference of SGD for flat minima with low effective dimensions.', 'Experimental validation supports the theoretical findings.']","['The originality of the work is questionable as it builds on existing theories without clearly differentiating itself.', 'The theoretical derivations are complex and hinge on several approximations that need more rigorous justification.', 'Experimental validation, while supportive, may not be robust or generalizable across different settings.', 'Potential limitations and ethical concerns are not adequately discussed.', 'The paper is dense and may be difficult for non-experts to follow.']",3,3,2,3,Reject
sBT5nxwt18Q,The paper proposes Critical Classification Regions (CCRs) to enhance explanation-by-example methods in eXplainable AI (XAI). CCRs aim to highlight important regions in test images and link them to regions in training images that influenced the model's decision. The paper includes computational experiments and a user study to validate the effectiveness of CCRs.,"['Can the authors provide more clarity on the computational methods used to derive CCRs, especially in the latent space?', 'How do the authors plan to generalize their method beyond the datasets used in this paper?', 'Can the authors discuss more on potential limitations and negative societal impacts of their method?', 'How does CCRs differ significantly from existing techniques like FAMs and CAMs?', 'Can the authors provide more theoretical analysis to justify the use of CCRs?', 'How do the authors address the computational cost and scalability of their methods?']","['The paper does not thoroughly address the limitations of the CCR method in terms of computational cost and applicability to other types of neural networks.', 'The potential negative societal impact of making incorrect predictions seem more correct to users should be discussed in more detail.', 'The user study is limited and does not provide conclusive evidence of the benefits of CCRs.']",False,2,2,2,4,4,"['Introduction of a novel method (CCRs) to enhance explanation-by-example techniques in XAI.', 'Comprehensive experimental evaluation, including both computational tests and a user study.', 'Potential practical applications in various domains, including medical diagnostics.']","['Potentially limited novelty as it builds upon existing methods like CAMs and FAMs.', 'The paper primarily focuses on specific datasets (CUB-200 and ImageNet), which may limit generalizability.', 'Some parts of the methodology, especially the computational experiments, lack clarity and detailed explanation.', 'The user study results show only a nuanced improvement in user perception, which might not be significant enough to justify the new method.', 'The paper is difficult to follow due to its convoluted structure and dense presentation.', 'Theoretical foundation for why CCRs improve interpretability is not well-established.', 'Limited discussion on the limitations and potential negative societal impacts of the proposed methods.']",3,2,2,3,Reject
49A1Y6tRhaq,"The paper proposes a novel method to bridge emergent languages from computational models with natural languages through corpus transfer. The authors demonstrate non-trivial transfer benefits for language modeling and image captioning tasks, particularly in low-resource settings. They also introduce a new metric to evaluate the transferability of emergent languages based on their translation to natural languages.","['Can the authors provide more details on how the new metric correlates with different downstream tasks?', 'How does the computational cost of the proposed method compare with existing methods?', 'Can the authors discuss potential negative societal impacts of their work in more detail?', 'How well does the proposed translation metric generalize to other languages and tasks not included in the experiments?', 'Can the authors provide more justification for the choice of metrics?', 'How robust are the findings across different hyperparameter settings?', 'Can the authors provide a more detailed theoretical analysis of why corpus transfer works better than direct model transfer?']","['The potential negative societal impacts of the work have not been thoroughly discussed.', 'Some claims regarding the benefits of the corpus transfer approach need stronger support through additional experiments or theoretical justifications.', 'The computational expense of the proposed methods may limit their practicality.', ""The translation metric's applicability to a broader range of languages and tasks needs further validation."", 'The approach may not scale well with larger datasets.', 'Potential issues with the robustness of the findings.']",False,3,3,3,5,4,"['Addresses an important gap in linking emergent and natural languages.', 'Introduces a novel corpus transfer method with promising results.', 'Proposes a new metric for evaluating emergent languages.', 'Robust experimental results demonstrating transfer benefits for language modeling and image captioning.']","['The clarity of the manuscript can be improved; some sections are difficult to follow.', 'Computationally expensive pre-training and fine-tuning processes.', 'Concerns about the scalability and generalizability of the approach.', 'Some claims lack strong experimental or theoretical support.', 'Potential negative societal impacts are not thoroughly discussed.']",3,3,3,3,Reject
9W2KnHqm_xN,"The paper introduces a SpatioTemporal aware Embedding framework (STEP) inspired by the entorhinal-hippocampal system. It applies this framework to the task of successive POI recommendation and traffic flow prediction, demonstrating state-of-the-art performance on benchmark datasets.","['Can the authors provide more details on the construction of the spatiotemporal context graph?', 'How does the proposed method handle edge cases or outliers in the data?', 'What are the specific limitations of the proposed method, and how can they be addressed in future work?', 'Can the authors provide more detailed explanations and justifications for the choice of hyperparameters?', 'How does the proposed method perform on other types of datasets beyond POI and traffic flow?', 'What are the limitations of the proposed method in terms of scalability and computational complexity?', 'How does the proposed method compare to state-of-the-art spatiotemporal embedding techniques beyond the provided baselines?', 'Can the authors provide more details on the scalability and computational overhead of the STE framework?', 'What are the potential limitations of the proposed method in real-world applications?', 'Can the authors provide more intuitive explanations or visualizations to clarify the complex concepts introduced?', 'How does the proposed method perform compared to the very latest state-of-the-art methods in spatiotemporal representation?', 'Can more detailed ablation studies be provided to isolate the impact of each component of the proposed model?', 'Can the authors provide more details on the reproducibility of the results?', 'How does the model handle missing or sparse data in real-world applications?', 'Can the authors elaborate on the potential ethical implications of their work?']","['The paper does not adequately address the limitations of the proposed method.', 'Potential negative societal impacts, such as privacy concerns, are mentioned but not discussed in detail.', 'The method might be computationally expensive due to the complex neural network architecture and graph-based representations.', 'Potential privacy concerns related to the use of spatiotemporal data are not thoroughly examined.', ""The method's dependency on specific parameter settings is not thoroughly explored."", 'The complexity of the model could limit its practical implementation.', 'There is a need for a more detailed discussion on the handling of missing or sparse data.']",False,3,3,3,6,4,"['Novel inspiration from the entorhinal-hippocampal system.', 'Thorough experimental validation on multiple datasets.', 'Clear improvement over state-of-the-art methods in successive POI recommendation.', 'Broad applicability in various spatiotemporal tasks.']","['Some sections lack clarity and detailed explanations, particularly in the methodology.', 'The combination of techniques is not entirely novel; it builds on existing graph-based and spatiotemporal modeling approaches.', 'Limited discussion on the limitations and potential negative societal impacts of the proposed method.', 'Potential overfitting to specific datasets; limited validation on diverse scenarios.', 'Complexity may hinder reproducibility.']",3,3,3,4,Reject
p98WJxUC3Ca,"The paper introduces a discrepancy-based active learning strategy for domain adaptation, focusing on Lipschitz functions. The authors adapt the concept of discrepancy distance to a localized class of functions performing accurate labeling on the source domain. They derive generalization error bounds and propose a practical K-medoids algorithm for large datasets, demonstrating its competitiveness against state-of-the-art methods.","['Can the authors provide more details or examples to clarify the dense theoretical sections?', 'Have the authors considered the impact of different types of domain shifts on their results?', 'How sensitive are the results to the choice of the parameter ε?', 'Can you provide more details on how the assumptions made for the theoretical derivations are justified in practical scenarios?', 'Could you clarify the steps of the accelerated K-medoids algorithm, especially in terms of computational complexity?', 'How can the proposed method be adapted to other types of loss functions not covered in the paper?', 'Can the authors provide more intuitive explanations and visual aids to help understand the theoretical derivations?', 'How does the proposed method perform on a wider range of datasets, particularly in comparison to more recent state-of-the-art techniques?', 'What are the practical implications of the assumptions made in the theoretical analysis?', 'Can the authors provide more intuition and simplified explanations for the theoretical results?', 'How do the assumptions on Lipschitz conditions affect practical applications?', 'Can the presentation of empirical results be made more user-friendly?', 'Can the authors provide more details on how the Lipschitz condition is ensured or approximated in practical applications?', 'How do the theoretical bounds translate into performance guarantees in real-world scenarios?', 'Can the authors discuss the scalability of the proposed method in even larger datasets or different data domains?']","['The practical implications of choosing the parameter ε need more discussion.', 'The assumptions regarding the Lipschitz nature of functions may not hold in all practical scenarios.', 'Potential negative societal impacts are not addressed.', 'The assumptions made for theoretical analysis might not hold in all practical scenarios.', 'The method assumes Lipschitz continuity of the functions, which may not hold in all practical scenarios.', 'The scalability of the method, while addressed, might still encounter limitations with extremely large datasets.', 'The complexity of theoretical proofs might hinder reproducibility.', ""The method's performance may vary significantly depending on the choice of initial labeled data."", 'There is a need for more comprehensive ethical considerations and potential societal impacts of the method.']",False,3,2,3,6,4,"['Addresses a significant problem in domain adaptation and active learning.', 'Theoretical contributions are well-founded and connected to empirical results.', 'Proposes a scalable and practical algorithm for large datasets.', 'Novel approach combining active learning and domain adaptation.', 'Comprehensive theoretical analysis with derived generalization bounds.', 'Empirical validation on multiple datasets showing competitive results.']","['Clarity of the paper can be improved, especially in the dense theoretical sections.', 'Empirical comparisons could benefit from more diverse datasets.', 'Assumptions and limitations are not thoroughly discussed, particularly the practical implications of parameter choices.', 'Assumptions for theoretical derivations might be restrictive.', 'Potential negative societal impacts are not thoroughly discussed.', 'Dense and challenging theoretical sections, lacking clarity.', 'Discussions on assumptions and limitations could be more comprehensive.', 'Theoretical assumptions, especially concerning Lipschitz conditions, may not hold in practice for many real-world datasets.', 'Limited discussion on the potential negative societal impacts and ethical considerations of the proposed method.', 'Experiments focus mainly on specific datasets, raising concerns about the generalizability of the results.']",3,3,2,3,Reject
Gx6Tvlm-hWW,"The paper proposes a novel conformal prediction method that trades off coverage for precision by limiting false positives. The approach is validated across tasks in NLP, computer vision, and computational chemistry.","['How does the proposed method scale with larger datasets and more complex models?', 'Can you provide more detailed guidance on selecting the parameter k in practical scenarios?', 'Can the authors provide more details on the choice of hyperparameters and their impact on the results?', 'How does the method perform with different sizes of the label space Y?', 'Can the authors discuss potential biases and societal impacts in more detail?', 'How generalizable is the proposed method to other set functions beyond DeepSets?', 'What are the computational requirements for the proposed calibration method in real-world settings?', 'Can the explanation of the mathematical formulations be simplified or clarified further?', 'Can the authors provide a more detailed comparison with state-of-the-art methods?', 'How does the proposed method perform in scenarios with varying levels of base model accuracy?', 'Can the authors clarify the potential limitations and societal impacts of this approach?']","['The method may propagate biases from underlying models, affecting fairness.', 'Scalability concerns in very large label spaces.', 'The complexity of the calibration method may restrict its practicality in scenarios with limited computational resources.', 'The method might not perform well with low base model accuracy.']",False,3,3,3,7,4,"['Addresses a significant limitation in existing conformal methods by focusing on false positive control.', 'Provides a new theoretical framework for conformal prediction with rigorous false positive control.', 'Empirically validated across multiple domains with promising results.']","['The paper is dense and complex, potentially hindering understanding and reproducibility.', 'Limited practical guidance on parameter selection.', 'Concerns about scalability to very large label spaces.', 'Limited discussion on potential societal impacts and biases.']",4,3,3,4,Accept
lu_DAxnWsh,"The paper presents an approach to improve the ability of neural networks, specifically Transformers, to handle tasks requiring multi-step reasoning (System 2 tasks). The authors propose training neural networks with intermediate steps, providing both theoretical proof and empirical validation through experiments on binary addition.","['How well does the proposed approach generalize to more complex tasks beyond binary addition?', ""Can the authors provide more intuitive explanations or visualizations to improve the paper's clarity?"", 'What are the potential societal impacts and limitations of this approach?', 'Have the authors considered alternative methods, such as modifying the architecture, to achieve similar results?', 'Have the authors considered the computational overhead introduced by requiring intermediate steps?', 'Can the authors provide more details on the potential real-world applications of this approach?', 'How does the proposed method compare with other state-of-the-art techniques for System 2 tasks?']","['The paper does not adequately address the limitations of the approach, particularly in terms of scalability and generalizability to more complex tasks.', 'Potential negative societal impacts, such as misuse in sensitive domains, are not discussed.', 'The practical utility of the approach in real-world scenarios is not well demonstrated.']",False,3,3,2,4,4,"['Addresses an important gap in current neural network capabilities, specifically in handling System 2 tasks.', 'The approach of using intermediate steps is well-motivated and supported by both theoretical and empirical evidence.', 'Theoretical proof provided for the expressiveness of a 1-layer 1-head Transformer in computing finite functions through intermediate steps.']","['The empirical evaluation is limited to binary addition, which may not generalize to more complex tasks.', 'The paper is highly technical and dense in sections, which detracts from its overall clarity.', 'Potential societal impacts and limitations are not adequately discussed.', 'The contribution is incremental and mainly relies on existing transformer architectures without significant architectural innovations.']",3,3,3,3,Reject
HfUyCRBeQc,The paper introduces selective ensembles to address inconsistencies in predictions and feature attributions in deep learning models. The method uses hypothesis testing to ensure consistency and abstains from making predictions when consistency cannot be guaranteed. Theoretical guarantees and empirical validations are provided.,"['Can the authors provide more insights into the practical applicability of selective ensembles in real-world scenarios?', 'How does the performance of selective ensembles compare to other state-of-the-art methods for ensuring prediction consistency?', 'What are the potential limitations and negative impacts of the proposed method?', 'Can the authors provide more details on the computational complexity of selective ensembles?', 'Have the authors considered any other state-of-the-art methods for comparison?', 'What are the potential negative societal impacts, especially in high-stakes applications?', 'Can the authors provide more details on the practical implications of high abstention rates in some datasets?', 'How do the authors address the potential negative societal impacts of abstaining in high-stakes decisions?', 'Can the proof of Theorem 3.1 be expanded or clarified for better understanding?', 'How does the method compare with other uncertainty estimation techniques?', 'Can the authors provide more details on the computational overhead of implementing selective ensembles?', 'What are the specific scenarios where abstention might be detrimental, and how can these be mitigated?', 'Can the authors discuss the potential limitations of the theoretical assumptions more thoroughly?']","['High abstention rates in some cases might limit practical applicability.', 'Theoretical assumptions may not hold in all real-world scenarios.', 'Potential negative societal impact of abstaining in critical decision-making scenarios is not fully addressed.', 'The computational cost of training multiple models is high.']",False,3,3,3,6,4,"['Addresses a significant issue in machine learning involving prediction and attribution inconsistency.', 'Proposes a novel and theoretically grounded method.', 'Provides theoretical guarantees for the performance of selective ensembles.', 'Demonstrates effectiveness empirically on multiple benchmark datasets.']","['Practical applicability of the method in real-world scenarios is not thoroughly discussed.', 'High abstention rates in some datasets raise concerns about practical applicability.', 'Theoretical assumptions may not hold in all practical scenarios.', 'Limited discussion on potential negative societal impacts and ethical considerations.', 'Computational complexity and deployment scenarios are not sufficiently discussed.']",3,3,3,3,Reject
8e2vrVvvaeQ,The paper investigates the principle behind indiscriminate data poisoning attacks and finds that the perturbations used in these attacks are almost linearly separable. It connects this property to the shortcut learning problem and proposes using pre-trained feature extractors as a defense mechanism. The paper includes extensive experiments to validate the findings and the effectiveness of the proposed defense. The authors claim that their findings reveal a fundamental vulnerability in deep learning models and suggest that pre-trained feature extractors can mitigate this issue.,"['How does the proposed defense mechanism perform in white-box settings where the attacker is aware of the defense strategy?', 'Can the findings be generalized to other types of attacks beyond the ones considered in the paper?', 'Is there any theoretical justification for the linear separability of the perturbations beyond the empirical observations?', 'Can the authors provide more theoretical evidence to support the connection between linear separability and shortcut learning?', 'Can the authors clarify the methodology for generating synthetic perturbations in more detail?', 'What are the potential negative societal impacts of the proposed defense mechanism?']","['The paper does not sufficiently address the performance of the proposed defense in white-box settings.', 'The scope of the experiments is limited to a few types of attacks and models.', 'The theoretical connection between linear separability and shortcut learning is not strongly established.', 'Potential negative societal impacts of the proposed defense mechanism are not discussed.']",False,3,3,3,5,4,"['The paper provides a novel perspective by connecting indiscriminate poisoning attacks to shortcut learning.', 'Extensive experiments are conducted to validate the hypotheses and findings.', 'The proposed defense mechanism using pre-trained feature extractors shows promising results.']","['The novelty of the findings may be overstated, as the concept of linear separability and its connection to adversarial attacks is not entirely new.', 'The experimental validation could be extended to a wider variety of attacks and models.', 'The effectiveness of the proposed defense in white-box settings is not sufficiently addressed.', 'The theoretical connection between linear separability and shortcut learning needs more rigorous backing.', ""The paper's presentation is sometimes unclear and could benefit from better organization and more precise explanations.""]",3,3,3,3,Reject
O476oWmiNNp,"The paper presents a theoretical framework for analyzing Vision Transformer (ViT) features in the Fourier spectrum domain and proposes two techniques, AttnScale and FeatScale, to mitigate the low-pass filtering effect in ViTs, thereby improving their performance when scaled to deeper architectures. The methods are tested across multiple ViT variants, showing consistent performance gains.","['Can the authors provide more detailed explanations or visualizations to help readers better understand the Fourier domain analysis?', 'Are there any specific limitations or assumptions in the theoretical proofs that need to be highlighted?', 'Can the authors provide more extensive evaluations of the proposed techniques across different ViT architectures to strengthen their claims?', 'How do the proposed techniques compare with other state-of-the-art methods in terms of computational efficiency and performance gains?', 'Can the authors discuss any potential limitations or failure cases of their proposed techniques?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?']","['The paper does not clearly articulate the assumptions in the theoretical proofs.', 'The applicability of the proposed techniques to various ViT architectures could benefit from more extensive evaluation.', 'The paper is dense and may be difficult to follow for readers without a strong background in Fourier analysis.', 'The negative societal impacts of making deeper and more powerful ViTs are not addressed.']",False,3,3,3,6,4,"['Provides a rigorous theoretical framework in the Fourier domain to analyze ViTs.', 'Proposes two novel techniques, AttnScale and FeatScale, that are efficient and hyperparameter-free.', 'Demonstrates consistent performance improvements across various ViT backbones.', 'The methods are computationally efficient and add minimal parameter overhead.']","['The theoretical sections are complex and may be difficult for a broader audience to understand.', 'The performance gains, while consistent, are relatively modest (up to 1.1%).', 'The originality of the methods may be questioned as they build on existing knowledge of filtering in signal processing.', 'The paper lacks a comprehensive discussion on the potential limitations and broader impacts of the proposed methods.']",4,3,3,3,Accept
JLbXkHkLCG6,"The paper introduces two methods, Pixel Sinkhorn Imitation Learning (P-SIL) and Pixel Discriminator Actor Critic (P-DAC), for imitation learning from visual observations without expert actions. These methods leverage adversarial learning and optimal transport to compute imitation rewards using representations from an RL encoder and demonstrate expert-level performance on DeepMind control suite tasks.","['How do the proposed methods compare with other recent visual imitation learning approaches not considered in the paper?', 'Can the authors provide more details on the computational cost and efficiency of their methods?', 'How well do the methods generalize to other domains beyond the DeepMind control suite tasks?', 'Can the authors provide more detailed explanations and justifications for the choice of baselines?', 'Can the authors provide more theoretical analysis to support the empirical results?', 'What are the potential negative societal impacts of this work?']","['The paper does not address the potential negative societal impacts of deploying AI systems that learn from visual observations, such as privacy concerns.', 'The methods may require significant computational resources, which could limit their accessibility and applicability in real-world scenarios.', 'The generalization of the methods to other tasks or environments is not thoroughly evaluated.', 'Potential ethical concerns related to imitation learning from visual data are not discussed.']",False,3,3,3,6,4,"['Addresses the challenging problem of imitation learning from pixel observations without expert actions.', 'Proposes novel extensions (P-SIL and P-DAC) of existing state-based approaches to the visual setting.', 'Provides comprehensive experimental evaluation with extensive ablation studies.', 'Demonstrates good performance on diverse tasks from the DeepMind control suite.', 'Makes the code available for reproducibility.']","['The methods are extensions of existing ideas rather than fundamentally new concepts.', 'Limited comparison with other recent visual imitation learning approaches.', 'Results may not generalize well to other domains beyond the DeepMind control suite.', 'Potentially high computational cost for training the models, especially P-DAC.', 'Lack of clarity in some methodological and technical details.', 'Insufficient discussion on societal impacts and ethical concerns.', 'Potential issues with the evaluation methodology, such as the choice of baselines.', 'Lacks theoretical analysis to support empirical results.', 'The paper is dense and complex, making it difficult to follow.']",3,3,3,3,Reject
UTTrevGchy,"The paper introduces the InfoMax Termination Critic (IMTC) algorithm, which aims to learn diverse and reusable temporally extended actions (options) in reinforcement learning by maximizing mutual information (MI) between options and state transitions. The authors validate the effectiveness of IMTC through various experiments, demonstrating its potential for quick adaptation to new tasks.","['Can the authors provide a clearer differentiation between IMTC and existing methods like VIC and TC?', 'How does the method scale with increasing state and action space sizes?', 'Are there any specific limitations or failure cases for IMTC that were observed during the experiments?', 'Can the authors elaborate on the computational complexity and feasibility of the proposed approach in real-world applications?', 'How does the performance of IMTC compare with other state-of-the-art methods not included in the paper?', 'Can the authors provide more justification for the assumption that the empirical distribution of options is independent of termination conditions?', 'Can the authors provide a more intuitive explanation of the mutual information-based objective?', 'What are the specific steps required to replicate the experiments using the provided code?']","['The paper does not adequately discuss the potential negative societal impacts of the proposed method.', 'The scalability of the method to large or continuous state spaces remains unclear.', 'The clarity of the paper is compromised by dense writing and complex mathematical notations, which could hinder reproducibility.', 'IMTC may not perform well in small environments where the number of possible trajectories is limited.', ""The method's complexity might hinder its practicality and broader adoption.""]",False,3,2,3,5,4,"['Addresses a significant problem in reinforcement learning: learning reusable and diverse options.', 'The proposed method, IMTC, is theoretically grounded in mutual information maximization.', 'Experiments show promising results in terms of the diversity and reusability of the learned options.', 'Thorough theoretical derivations and comprehensive experiments.']","['The paper is densely written and lacks clarity in several sections, making it difficult to follow.', 'The novelty of the approach is questionable as it heavily builds on existing methods like VIC and TC without substantial differentiation.', 'The experimental evaluation lacks rigorous comparisons with a broader set of baselines.', ""Potential issues with the method's scalability and applicability to environments with large or continuous state spaces."", 'Potential societal impacts and ethical considerations are not adequately addressed.', 'Reproducibility could be improved with more detailed experimental setup descriptions.']",3,3,2,3,Reject
CgV7NVOgDJZ,"The paper proposes Guided-TTS, a text-to-speech (TTS) model that generates high-quality speech using untranscribed speech data. It combines an unconditional diffusion probabilistic model with a phoneme classifier. The model is trained on untranscribed speech data to learn the unconditional distribution for speech, and during text-to-speech synthesis, it uses a phoneme classifier to guide the generative process. The method demonstrates comparable performance to existing TTS models on the LJSpeech dataset.","['Can the authors provide more detailed explanations of the methodology, specifically the training process of the phoneme classifier and the unconditional DDPM?', 'How does the performance of Guided-TTS compare to more baseline models beyond those mentioned?', 'Can the authors provide more detailed ablation studies to understand the contributions of different components of their model?', 'How does the model perform on other datasets besides LJSpeech?', 'What are the practical challenges in obtaining high-quality untranscribed data?', 'Can the authors provide more details on the computational resources required for training and inference?', 'Can the authors provide more details on the training and evaluation setup to ensure reproducibility?', 'How does Guided-TTS perform on other less controlled datasets or in real-world noisy conditions?', 'Could the authors clarify the specific advantages of their norm-based guidance method over previous guidance methods?', 'Can the authors discuss potential negative societal impacts of their method, such as misuse in generating fake audio?']","['The authors need to address the clarity and organization of the paper.', 'More rigorous evaluation and comparison with state-of-the-art methods are needed.', 'Potential negative societal impacts are not adequately discussed.', 'Complex architecture which may hinder reproducibility.', 'Evaluation is limited to a few datasets; further validation is needed across diverse conditions.']",True,2,2,3,4,4,"['Addresses the limitation of requiring transcribed data in TTS models.', 'Novel use of a diffusion probabilistic model for unconditional speech generation.', 'Experimental results show competitive performance with state-of-the-art models.', 'Potential to leverage large amounts of untranscribed speech data available online.']","['Technical soundness is questionable; the methodology lacks clarity and important details.', 'The paper is poorly organized and difficult to follow.', 'Evaluation lacks detailed analysis and comparison with more baseline models.', 'Complex architecture which may affect reproducibility and implementation for other researchers.', 'Insufficient discussion on potential negative societal impacts.']",3,2,2,3,Reject
o_HsiMPYh_x,"The paper proposes Average Thresholded Confidence (ATC), a method to estimate the performance of models on out-of-distribution (OOD) data using only labeled source data and unlabeled target data. ATC learns a threshold on the model's confidence scores from labeled source data and uses it to estimate the target domain accuracy based on the fraction of target examples exceeding the threshold. The paper provides theoretical foundations, empirical validation across several datasets, and shows ATC's superiority over existing methods.","['Can the authors provide more detailed explanations and justifications for the choice of datasets and experimental setups?', 'How does the performance of ATC compare with more recent methods not included in this study?', 'Can the theoretical results be extended to more complex models and datasets beyond the toy model?', 'Can the authors provide more detailed discussions on the potential limitations and failure cases of ATC?', 'How does ATC perform in scenarios with extreme distribution shifts or highly imbalanced datasets?', 'What are the computational overheads and scalability considerations of ATC in large-scale applications?', 'How does the method perform without temperature scaling?', 'Can the authors provide more detailed examples of when ATC fails?', 'What are the potential negative societal impacts of using ATC in real-world applications?', 'Can the authors provide more intuitive explanations or examples to clarify the theoretical analysis?', 'How sensitive is ATC to the choice of the threshold and the score function? Are there guidelines for selecting these parameters?', 'Can the authors provide more details on how ATC performs under extreme distribution shifts or in cases where the assumptions do not hold?', 'When will the code be released, and will there be detailed documentation to facilitate reproducibility?', 'Can the authors provide more details on how the threshold t is selected in practice?', 'Is there any intuition on why the method performs poorly on novel subpopulations in the BREEDS dataset?', 'Can the authors discuss potential extensions to improve performance on datasets with novel subpopulations?', 'How sensitive is the method to the choice of score function (e.g., maximum confidence vs. negative entropy)?']","['The paper acknowledges that ATC may fail on certain types of distribution shifts, particularly with novel subpopulations.', 'Potential negative societal impact is not discussed, although it may be minimal in this context.', 'The method might not perform well without temperature scaling, which can be a limitation in scenarios where temperature scaling is not feasible.', 'The paper does not thoroughly explore the potential failure modes of ATC, which could limit its applicability in certain settings.', 'The potential negative societal impacts of misestimating model performance in critical applications (e.g., healthcare, autonomous driving) are not sufficiently discussed.', 'Scenarios where ATC might fail due to violated assumptions and how to detect such cases.', 'Possible extensions or modifications to ATC that could make it more robust to various types of distribution shifts.', 'Ethical considerations related to the deployment of models in critical applications where performance estimation is crucial.']",False,3,2,3,6,4,"['The proposed method, ATC, is simple to implement and does not require labeled target data.', 'Theoretical analysis provides a foundation for understanding the limitations and applicability of the method.', 'Extensive empirical evaluation across multiple datasets and distribution shifts.', 'ATC outperforms several existing methods in predicting target accuracy.']","['The paper lacks clarity in some sections, making it difficult to follow the theoretical analysis and experimental setup.', ""The method's performance on novel subpopulations is significantly worse, indicating potential limitations in practical scenarios."", 'The explanation of the toy model and its relevance to real-world scenarios is not sufficiently detailed.', ""Some baseline methods' implementation details are not thoroughly discussed, which could affect the reproducibility of results."", 'Potential overclaims regarding the generalizability of the method.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'Possible clarity issues in mathematical formulations and experimental setup.', 'Limited exploration of scenarios where ATC may fail.']",3,3,3,3,Reject
LhObGCkxj4,"This paper presents a new theoretical framework for ensuring global convergence in finite-sum optimization problems, particularly focusing on deep neural networks. It introduces a composite formulation for machine learning minimization problems and proposes two algorithms based on this framework. The authors provide a thorough convergence analysis, demonstrating that the proposed methods can achieve an ε-global minimum under certain assumptions.","['Can the authors provide empirical results to validate the proposed theoretical findings?', 'How sensitive are the algorithms to the bounded style assumptions and over-parameterization? Can these assumptions be relaxed?', 'What are the potential limitations and negative societal impacts of this work?', 'How do the proposed methods compare with existing state-of-the-art algorithms in terms of performance and efficiency?', 'Are there specific applications or datasets where the proposed framework is particularly effective?']","['The paper assumes that the Hessian matrices are bounded, which may not always be the case in practice.', 'The over-parameterization assumption is quite strong and may not be applicable to all neural network architectures.', 'The paper lacks empirical validation, which is critical for assessing the practical utility of the proposed methods.', 'The non-standard assumptions may not always hold in practical settings, which could affect the generalizability of the results.']",False,3,3,3,4,4,"['Novel theoretical contributions to the field of optimization in machine learning.', 'Detailed and rigorous convergence analysis.', 'The proposed framework and algorithms are well-grounded in mathematical theory.']","['Lack of empirical validation to demonstrate practical applicability.', 'Restrictive assumptions (e.g., over-parameterization, bounded Hessian matrices) that may not hold in real-world scenarios.', 'Insufficient discussion on potential limitations and negative societal impacts.']",3,3,3,3,Reject
0SiVrAfIxOe,"The paper presents a novel closed-loop control policy for additive manufacturing using reinforcement learning. The authors propose a custom numerical model that approximates the deposition process qualitatively, leveraging limited hardware perception. The model integrates a data-driven noise distribution to minimize the sim-to-real gap. The reinforcement learning-based control policies are shown to outperform state-of-the-art controllers in both simulation and real hardware, demonstrating adaptability to various materials and dynamic environments.","['Can the authors provide more details on the potential limitations and negative societal impacts of their approach?', 'How does the proposed method compare with other state-of-the-art reinforcement learning approaches in similar domains?', 'Can the authors clarify the specifics of the experimental setup and provide additional visual aids to enhance understanding?', 'Can the authors provide more technical details on the custom numerical model and its validation?', 'How does the proposed method compare quantitatively with other state-of-the-art closed-loop controllers in additive manufacturing?', 'Can the authors provide more details on the training process, including hyperparameters and convergence criteria?', 'How does the proposed method compare to other advanced control methods not covered in the paper?', 'Can the authors clarify the interpretation of some of the figures, particularly Figures 2 and 3?', 'Could the authors provide more details on the limitations of their approach?', 'What are the potential ethical concerns associated with the proposed method?', 'How does the method handle significant variations in material properties not seen during training?', 'Can the approach be extended to other types of additive manufacturing techniques?', 'Can the authors provide more details on the assumptions and limitations of the custom numerical model?', 'How does the proposed method compare to other state-of-the-art methods in terms of computational efficiency?']","['The paper does not adequately address potential limitations and negative societal impacts of the proposed approach. For instance, the reliance on specific hardware setups and assumptions made in the numerical model could limit the generalizability of the method.', 'The scalability of the approach to more complex and larger-scale additive manufacturing tasks is not discussed.', 'The custom numerical model may have limitations that are not fully explored in the paper.', ""The clarity of the numerical model's explanation could be improved."", 'The paper lacks a thorough discussion on the potential ethical concerns and societal impacts of the proposed method.']",False,3,3,3,5,4,"['Addresses a significant problem in additive manufacturing with a novel RL-based approach.', 'The numerical model and reinforcement learning framework are well-designed and thoroughly explained.', 'The experimental results demonstrate substantial improvements over baseline methods in both simulation and real hardware.', 'The inclusion of several ablation studies strengthens the validity of the proposed approach.', 'Promising sim-to-real transfer, demonstrating practical applicability.']","['The novelty is moderate as RL has been applied to manufacturing control previously.', 'Technical depth and validation of the custom numerical model are insufficient.', 'Comparisons with existing state-of-the-art methods are lacking.', 'Lacks detailed explanation in some sections, particularly the training process and experimental setup.', 'Clarity of presentation could be improved, especially in structuring the results and discussion sections.', 'Potential negative societal impacts and ethical concerns are not adequately addressed.']",3,3,3,3,Reject
Fza94Y8VS4a,"The paper explores the evolution of uncertainty in learning-in-game systems using differential entropy. It demonstrates that differential entropy increases linearly with time for various learning algorithms, indicating increased unpredictability. The analysis is applied to multiple systems, including zero-sum games and one-population games, and extends to settings with perturbed payoffs.","['Can the authors provide more intuitive explanations for some of the dense mathematical formulations?', 'How do the findings translate to practical scenarios, and what are their implications for real-world applications?', 'Can the authors provide more experimental results to validate the theoretical findings?', 'How do the results generalize to more complex, real-world multi-agent systems beyond the specific game settings analyzed?', ""Could the authors explain 'the grand escape' phenomenon in simpler terms or provide a more intuitive example?""]","['The analysis is primarily theoretical, and practical implications are not thoroughly explored.', 'The paper does not address potential limitations of the differential entropy measure in this context.', 'The authors could further discuss the limitations in terms of real-world applicability and potential negative societal impacts, such as how increased unpredictability might affect stability in critical applications.']",False,3,3,3,6,4,"['Novel approach to analyzing uncertainty using differential entropy.', 'Detailed theoretical results with complete proofs.', 'Application to various learning algorithms and game settings.', 'Addresses a relevant and timely topic in machine learning and game theory.']","['Dense mathematical formulations make some sections difficult to follow.', 'Limited exploration of practical implications and significance of findings.', 'Lacks sufficient experimental validation to support the theoretical claims.', 'Real-world applicability and generalization to more complex systems are not thoroughly discussed.']",4,3,3,4,Reject
aYAA-XHKyk,The paper presents a novel method called Regrouping CPE (ReCPE) to improve class-prior estimation in Positive-Unlabeled (PU) learning. The method addresses the overestimation problem caused by the irreducibility assumption by creating an auxiliary distribution ensuring the assumption holds. This reduces bias in the estimation. The paper provides theoretical analysis and empirical evidence showing the effectiveness of ReCPE over existing methods.,"['Can you provide more justification for the selection of the hyper-parameter p?', 'How computationally expensive is the regrouping process in practice?', 'Are there any potential negative societal impacts or ethical concerns with the proposed method?', 'How sensitive is the method to the choice of hyper-parameter p?', 'Can the method be simplified without losing significant accuracy?', 'How does the method perform in real-world scenarios where the irreducibility assumption might partially hold?', 'Can the authors provide more detailed algorithmic steps for the implementation of ReCPE?', 'Can the authors clarify the computational complexity of the proposed method compared to existing methods?', 'Are there any specific scenarios or datasets where ReCPE performs significantly worse?', 'How would the proposed method scale with larger datasets?', 'Are there any specific applications where ReCPE would significantly outperform existing methods?']","['The selection of the hyper-parameter p seems somewhat arbitrary.', 'The computational cost of the auxiliary distribution is not discussed.', 'Limited discussion on potential negative societal impacts or ethical considerations.', 'High complexity and reliance on hyper-parameter tuning.', 'Practical implementation might be difficult for non-experts.', 'The method introduces additional complexity and hyper-parameters, which might make it less accessible to practitioners.', 'The paper does not fully explore the potential negative societal impacts of the proposed method.', 'Reproducibility might be an issue due to the complexity of the method and the need for precise hyper-parameter tuning.']",False,3,3,3,7,4,"['Addresses an essential problem in PU learning, focusing on class-prior estimation.', 'The proposed method is theoretically sound with detailed proofs.', 'Empirical results show clear improvements over existing methods across multiple datasets.', 'Novel approach to class-prior estimation without relying on irreducibility assumption.']","['Clarity could be improved, especially in the theoretical sections.', 'The selection of the hyper-parameter p seems somewhat arbitrary and could be better justified.', 'The introduction of an auxiliary distribution might be computationally expensive in practice.', 'Limited discussion on potential negative societal impacts or ethical considerations.', 'Complexity of the proposed method is high.', 'The practical implementation of ReCPE relies on hyper-parameter tuning, which might not be straightforward.', 'Potential issues with reproducibility given the complexity and the introduction of new hyper-parameters.']",3,3,3,3,Reject
2sDQwC_hmnM,"The paper introduces ZeroFL, a framework designed to accelerate on-device training for federated learning (FL) by leveraging sparsity. It proposes three local sparsification methods to improve performance while reducing communication costs. Experiments are conducted on CIFAR-10, FEMNIST, and SpeechCommands datasets to validate the approach.","['Can the authors provide more details on the specific hardware used for the experiments?', 'How does ZeroFL perform on other types of datasets (e.g., text, time-series)?', 'What are the potential negative societal impacts of deploying ZeroFL in real-world applications?', 'Can the authors clarify the differences between the three proposed local sparsification methods?', 'How does the proposed approach handle varying levels of device capabilities in a federated setting?', 'What are the potential limitations of the proposed approach in terms of scalability and generalizability?', 'Can the authors provide more details on the hyperparameters and their tuning process for the different datasets?', 'Can the authors provide a theoretical analysis to complement the empirical results?']","['The paper primarily focuses on image and audio datasets, which may limit the generalizability of the proposed methods.', 'The potential negative societal impacts of deploying ZeroFL are not adequately addressed.', 'The effectiveness of ZeroFL on very high sparsity levels (e.g., >95%) is not thoroughly evaluated.', ""The framework's performance on real-world federated learning systems with heterogeneous devices is not validated."", 'The impact of different hyperparameters on the performance of ZeroFL is not thoroughly explored.', 'The societal impact of the proposed method, particularly in terms of energy consumption and privacy, is not well-addressed.']",False,3,3,3,5,4,"['Novel approach to accelerating on-device training in FL by leveraging sparsity.', 'Comprehensive experimental validation across multiple datasets.', 'Significant improvements in communication efficiency and model accuracy.']","['Clarity issues in several sections, particularly in the explanation of the methods and experimental setup.', 'Limited evaluation scope, primarily focusing on specific datasets and sparsity levels.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'The paper does not adequately address the limitations of the proposed methods.', 'Lacks a thorough theoretical analysis to complement the empirical results.']",3,3,3,3,Reject
mF122BuAnnW,"The paper proposes a method called localized randomized smoothing to enhance the robustness of multi-output classifiers. This method applies varying levels of noise to different parts of the input based on their importance for the model's predictions. The authors derive a collective robustness certificate, which they demonstrate through experiments on image segmentation and node classification tasks.","['How sensitive is the proposed method to the choice of smoothing parameters (σmin and σmax)?', 'Can the authors provide more insights into the computational complexity of their method compared to the baselines?', 'Have the authors considered other types of noise distributions for localized smoothing?', 'Can the authors provide more diverse experimental results to validate the proposed method across different tasks and models?', 'Can the authors clarify the detailed mathematical derivations with additional explanations or visual aids?', 'How generalizable is the method to other types of tasks beyond those evaluated in the paper?', 'What are the potential limitations of the soft locality assumption, and how could these impact the applicability of the method?']","['The method assumes that the model is softly local, which may not always be the case in practice.', 'The choice of smoothing parameters requires a priori knowledge about the relevance of input regions, which may not always be available.', 'The use of Monte Carlo sampling for randomized smoothing can be computationally expensive, particularly for large datasets.', 'The approach might not scale well with very large datasets or highly complex models due to the computational overhead of solving the linear programs.']",False,3,3,3,5,4,"['Novel approach: The idea of localized randomized smoothing is innovative and could have significant implications for improving model robustness.', 'Theoretical contributions: The paper provides a solid theoretical foundation for the proposed method.', 'Comprehensive experiments: The authors conduct extensive experiments to demonstrate the effectiveness of the proposed method.', 'Addresses an important problem: The method is relevant for real-world applications involving multi-output classifiers.']","['Clarity: The paper is densely written and challenging to follow, especially in the theoretical sections. The clarity of the presentation needs improvement.', 'Evaluation methodology: The comparison with baselines is not entirely convincing. More diverse baselines and a detailed discussion on parameter choices are needed.', 'Reproducibility: The complexity of the method and the large number of hyperparameters make it difficult to reproduce the results.', 'Computational efficiency: The method relies on Monte Carlo sampling, which can be computationally expensive, particularly for large datasets.', 'Assumptions: The method assumes softly local models, which may limit its applicability.']",4,3,2,3,Reject
fRnRsdc_nR7,"The paper proposes Noise-FGSM (N-FGSM), a single-step adversarial training method that uses stronger noise and removes clipping to prevent catastrophic overfitting. The method is empirically validated on multiple datasets and architectures, showing improvements over existing methods while being computationally efficient.","['Can you provide a more in-depth theoretical analysis on why increasing noise magnitude prevents catastrophic overfitting?', 'What are the potential trade-offs between clean accuracy and adversarial robustness using N-FGSM?', 'How does N-FGSM perform in a real-world scenario with varying levels of adversarial attacks?', 'How do the authors justify the choice of noise distribution?', ""Are there theoretical guarantees for the proposed method's robustness?""]","['The approach relies heavily on empirical results without deep theoretical backing.', 'The effect of the method on clean accuracy is not extensively discussed.', 'The performance gap between single-step and multi-step methods remains, particularly for larger perturbations.', 'Potential overfitting to specific datasets and architectures is not thoroughly addressed.', 'The paper does not adequately discuss the limitations and potential negative societal impacts.']",False,3,3,3,5,4,"['Addresses a significant problem in adversarial training.', 'Demonstrates effectiveness through extensive empirical evaluation.', 'Clear and well-organized presentation.', 'Significant computational efficiency and speed improvements over existing methods like GradAlign.']","['Limited theoretical justification for the effectiveness of noise.', 'Potential trade-offs between clean accuracy and adversarial robustness are not deeply explored.', 'Relies heavily on empirical results without deeper theoretical insights.', 'Incomplete exploration of limitations and potential negative societal impacts.', 'Lacks detailed ablation studies to isolate the effects of each component of the method.']",3,3,3,3,Reject
mZsZy481_F,"The paper proposes a Few-shot ROBust (FROB) model for classification and out-of-distribution (OoD) detection in few-shot settings. It combines generative and discriminative models to create a confidence boundary and uses self-supervised learning for robustness. The methodology includes generating adversarial samples and performing outlier exposure (OE) even for zero-shots. The evaluation shows competitive performance on various datasets like CIFAR-10, SVHN, and CIFAR-100.","['Could the authors simplify the explanation of the proposed loss function and optimization steps?', 'How does the proposed tight boundary mechanism compare directly to a simpler, non-generative approach?', 'Can the authors provide more intuitive visualizations or examples of the generated adversarial samples and their impact on performance?', 'How does FROB compare to more recent state-of-the-art methods not included in the current benchmarks?', 'Can the robustness claims, particularly for zero-shot scenarios, be substantiated with additional experiments or ablation studies?', 'How does the choice of hyperparameters affect the performance of FROB?', 'How does FROB specifically differentiate from existing methods such as CCC and GOOD?', 'Can the authors provide more theoretical insights into the robustness guarantees of FROB?', 'What are the potential limitations of FROB, especially in real-world applications?', 'How does FROB handle ethical concerns, particularly in safety-critical applications?']","[""The paper's complexity might hinder reproducibility and practical implementation."", 'Potential over-reliance on specific datasets for evaluation, questioning generalizability.', 'Ethical implications of generating adversarial samples not thoroughly discussed.', 'The paper does not adequately address the potential negative societal impacts of deploying such models, especially in critical systems.', 'The complexity of the proposed method may limit its practical applicability without further simplification.']",False,3,2,3,5,4,"['Novel combination of generative and discriminative models for robustness.', 'Comprehensive evaluation across multiple datasets.', 'Addresses a significant problem in few-shot learning and OoD detection.']","['Dense and complex presentation, making it hard to follow.', 'Moderate originality with reliance on existing techniques.', 'Lack of clear narrative connecting methodology to improvements.', 'Insufficient clarity in the explanation of the proposed loss function and optimization.', 'Limited theoretical analysis and empirical backing for some claims.', 'Inadequate discussion of potential limitations and ethical concerns.']",3,3,2,3,Reject
K47zHehHcRc,"The paper introduces the concept of interventional consistency for autoencoders, aiming to improve the modularity and robustness of representations. It proposes a novel training scheme and an architectural modification called the explicit causal latent block (XBlock) to enhance autoencoders' interventional consistency. The paper includes experimental validations on different datasets and autoencoder variants.","['Can the authors provide a clearer and more intuitive explanation of the concept of interventional consistency?', 'What are the practical implications of the marginal improvements in the experimental results?', 'Could the authors include more details about the implementation of the regularization terms and hyperparameters in the main text?', 'How does the proposed XBlock affect the training time and computational resources compared to traditional autoencoders?', 'Can the authors discuss potential limitations or scenarios where interventional consistency might not be beneficial?', 'How does the proposed method perform on more diverse and complex datasets beyond MNIST and CelebA?', 'How does the proposed interventional consistency compare with other recent disentanglement metrics in terms of performance and computational complexity?']","['The paper does not adequately discuss the limitations and potential negative societal impacts of the proposed approach. It would be beneficial to include a discussion on the limitations of interventional consistency and its applicability in real-world scenarios.', 'The empirical evaluations are limited to only two datasets, which may not fully demonstrate the generalizability of the proposed methods.']",False,3,2,3,5,4,"['Novel Concept: The introduction of interventional consistency is a novel idea in the field of representation learning.', 'Comprehensive Experiments: The authors conducted detailed experiments on different datasets and autoencoder variants to validate their approach.', 'Architectural Innovation: The explicit causal latent block (XBlock) is an interesting architectural modification.', 'Theoretical Framework: The theoretical framework is well-developed and backed by causal inference principles.']","['Clarity Issues: The paper is densely written and difficult to follow, especially for readers who are not experts in the field. The mathematical formulations and explanations are not presented in a clear and intuitive manner.', 'Limited Novelty in Methods: While the concept of interventional consistency is novel, the methods used to achieve it (e.g., regularization terms) are standard and not particularly innovative.', 'Experimental Validity: The empirical results, while comprehensive, do not convincingly demonstrate the practical significance of the proposed approach. The improvements in scores are marginal, and the practical implications of these improvements are not well discussed.', 'Missing Details: Some key details, such as the exact implementation of regularization terms and hyperparameters, are relegated to the appendix, making it hard to evaluate the reproducibility of the results.', 'Limited Empirical Validation: The empirical evaluation is limited to only MNIST and CelebA datasets, which may not generalize to more complex datasets.', 'Insufficient Discussion of Limitations: The paper does not adequately discuss the limitations and potential negative societal impacts of the proposed approach.']",3,3,2,3,Reject
F0v5uBM-q5K,"The paper proposes Power-Aware Neural Networks (PANN), a method to reduce the power consumption of DNNs by switching to unsigned arithmetic and removing multipliers. The approach is supported by theoretical analysis and experimental results, demonstrating significant power savings with minimal accuracy loss.","['Can the authors provide more extensive evaluations on different architectures and datasets?', 'Can the authors discuss the trade-offs in terms of memory footprint and latency in more detail?', 'Can the authors provide insights into the practical implications of their approach on actual hardware?', 'Can the authors provide more details on how the proposed methods generalize to other types of neural networks and tasks beyond image classification?', 'Can the authors elaborate on any potential negative societal impacts of increased deployment of efficient models on end devices?', 'Can the authors provide more clarity on the implementation details of PANN, especially the process of switching to unsigned arithmetic?', 'How does PANN compare with other state-of-the-art power reduction techniques in real-world deployment scenarios?', 'Can the authors provide more details on the hardware implementation and evaluation, specifically regarding latency and memory overheads?', 'How does the proposed method handle different types of DNN architectures, such as recurrent neural networks or transformers?', 'Can the authors provide more details on the comparison with recent state-of-the-art methods?', 'How does the method perform on a wider range of tasks beyond image classification?']","['The experimental results are limited to specific architectures and datasets.', 'The trade-offs in terms of memory footprint and latency are not extensively discussed.', 'The practical implications on actual hardware are not thoroughly evaluated.', 'The paper does not discuss the potential negative societal impacts of increased deployment of efficient models on end devices, such as increased surveillance or environmental impacts.', 'The approach may be complex to implement and understand due to the extensive theoretical analysis, which could hinder its adoption.', 'The paper does not address potential limitations related to the increased memory footprint and latency due to additional additions.', 'The impact of the proposed method on training time and complexity is not discussed in detail.', 'Potential negative societal impacts, such as increased electronic waste due to more frequent hardware upgrades, are not considered.']",False,3,3,3,7,4,"['Addresses a critical issue in deploying DNNs on resource-limited devices.', 'Provides a detailed theoretical analysis of power consumption in DNNs.', 'Demonstrates significant power savings with minimal accuracy loss.', 'Can be applied both at post-training and during training.', 'Accurate power consumption models for DNN operations.', 'Practical methods for significant power reduction, such as switching to unsigned arithmetic and replacing multiplications with additions.', 'Extensive experimental validation demonstrating the effectiveness of the proposed methods.', 'Enables a seamless power-accuracy trade-off without changing the hardware.']","['Experimental results are limited to specific architectures and datasets.', 'Trade-offs in terms of memory footprint and latency are not extensively discussed.', 'Practical implications on actual hardware are not thoroughly evaluated.', 'The clarity of the technical sections could be improved; some parts are dense and difficult to follow.', 'Experiments are mostly limited to image classification tasks; the generalizability to other neural network types and tasks is not fully explored.', 'Potential negative societal impacts of increased deployment of efficient models on end devices are not discussed.', 'Complexity in understanding and replicating the approach due to extensive theoretical analysis.', 'Lack of detailed comparisons with state-of-the-art power reduction techniques beyond quantization, especially in terms of real-world deployment scenarios.', 'Theoretical analysis may not fully capture all practical aspects of hardware implementations, such as latency and memory overheads.']",3,3,3,4,Reject
ChKNCDB0oYj,"The paper proposes a mistake-driven image classification method that uses FastGAN-based data augmentation to address performance deficits in specific classes. By focusing on the worst-performing classes after initial training and augmenting them with FastGAN, the method aims to balance class-wise performance and improve overall accuracy. The approach is tested on five datasets with favorable results, often surpassing state-of-the-art methods.","['How does the mistake-driven approach compare to simpler data augmentation methods in terms of computational cost and performance?', 'What measures were taken to ensure that the generated images by FastGAN are of high quality and not introducing bias?', 'Can the approach be generalized to other tasks beyond image classification?', 'How does the proposed method compare with a broader range of state-of-the-art methods?', 'What are the potential overfitting issues with the mistake-driven approach, and how are they addressed?', 'Can the authors provide more details on the experimental setup, including hyperparameter settings and computational resources used?', 'Can the authors provide more details on how the worst-performing classes are selected and the impact of this selection on the final results?', 'What are the potential negative societal impacts of mistake-driven training, particularly in sensitive applications like medical imaging?', 'How does the method perform on datasets with higher resolution images compared to CIFAR-10?', 'Can the authors clarify how their method specifically differs from and improves upon existing GAN-based augmentation methods?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide more details on the hyperparameter choices and their impact on the results?', 'Can the authors provide more details on the implementation of the mistake-driven training workflow, specifically for reproducing the results?', 'How does the method perform on other types of datasets, such as those with different image modalities (e.g., medical imaging, satellite images)?', 'What are the computational costs associated with training the class-specific GANs in terms of time and hardware requirements?']","['The paper does not adequately address potential negative societal impacts of GAN-generated data, such as misuse in generating fake images.', 'The focus on GAN-based augmentation might not be suitable for all types of datasets, especially those with very high intra-class variability.', 'Potential overfitting issues with mistake-driven training.', 'Limited generalizability of the results to other datasets or tasks.', 'Reproducibility concerns due to insufficient details on the experimental setup.', ""The method's performance on low-resolution datasets like CIFAR-10 is limited."", 'The scalability and generalizability of the method to other domains and larger datasets are not discussed.', 'There is a lack of discussion on ethical considerations and potential negative impacts of using GAN-generated data.']",False,3,2,3,5,4,"['Novel approach to address performance imbalances in image classification.', 'Use of computationally efficient FastGAN for augmentation.', 'Combination of Progressive SpinalNet and SAM optimizer.', 'Thorough experimental evaluation including ablation studies.']","['Incremental improvement over existing methods without clear groundbreaking innovation.', 'Lack of detailed discussion on potential negative societal impacts.', 'Unclear novelty in using GANs for augmentation, as this has been explored in prior work.', 'Potential overfitting in experiments due to numerous hyperparameters and configurations.', 'Moderate originality, as it combines existing techniques without introducing fundamentally new concepts.', 'Quality concerns due to limited comparisons with a broad range of state-of-the-art methods and potential overfitting.', 'Clarity issues in the experimental setup and results sections.', 'The significance of results is not fully convincing, with limited improvement on some datasets.', 'Some experimental results, particularly on CIFAR-10, did not reach state-of-the-art levels.', 'The paper could benefit from more clarity in some sections, particularly the methodological details.', 'Reproducibility concerns due to insufficient details on the experimental setup.']",3,3,3,3,Reject
nhN-fqxmNGx,"The paper conducts a theoretical comparison of six variable selection methods in linear regression models, focusing on their Hamming errors. The methods compared are Lasso, Elastic Net, SCAD, Thresholded Lasso, Forward Selection, and Forward Backward Selection. The study derives convergence rates and phase diagrams for these methods under specific model assumptions.","['Can the authors provide more intuitive examples to explain the theoretical results?', 'How do the results translate to practical applications in real-world datasets?', 'Are there any empirical validations of the theoretical findings beyond the simulated experiments?', 'How sensitive are the results to deviations from the blockwise diagonal assumption and the rare and weak signal model?', 'Could the authors improve the clarity of the paper by providing more intuitive explanations and better-organized sections?']","['The study heavily relies on specific theoretical assumptions that may not hold in practical scenarios.', 'The assumption of a block-wise diagonal Gram matrix may not hold in many real-world applications.', 'The paper does not provide much practical guidance on how to choose between the methods based on the theoretical findings.', 'Potential negative societal impacts are not discussed.']",False,3,2,3,5,4,"['Novel focus on Hamming error as the primary metric for comparison.', 'Comprehensive theoretical analysis with detailed derivations.', 'Introduction of phase diagrams as a visual tool for comparison.']","['Heavy reliance on specific theoretical model assumptions, which may limit practical applicability.', 'Dense and technical writing, making it difficult for a broader audience to follow.', 'Limited discussion on the practical implications and how the results translate to real-world scenarios.', 'Poor formatting of tables and figures.', 'Insufficient empirical validation beyond synthetic experiments.']",3,3,3,4,Reject
mRc_t2b3l1-,"The paper explores the limiting dynamics of deep neural networks trained with stochastic gradient descent (SGD). It derives a continuous-time model for SGD, analyzes it using the Fokker-Planck equation, and validates the findings through empirical experiments on various architectures, including ResNet-18 trained on ImageNet.","['Can the authors provide more intuition behind the theoretical findings to make them more accessible?', 'How do the assumptions made (e.g., quadratic loss) hold in real-world scenarios?', 'Can the authors discuss potential practical implications and applications of their findings?', 'How robust are the results to deviations from the assumptions, especially the quadratic loss approximation and covariance structure?', 'Can the theoretical framework be simplified or made more accessible without losing key insights?', 'How do the findings generalize to other architectures and datasets beyond ResNet-18 and ImageNet?', 'Can the authors provide more intuitive explanations or visualizations for the complex mathematical constructs introduced?', 'Are there any practical implications or recommendations for training neural networks based on the findings?', 'How robust are the assumptions made in your theoretical model? Have you tested their validity in more practical settings?', 'How do the insights from this paper translate into practical improvements in training deep neural networks?', 'Can you clarify the novelty of your work in comparison to the existing literature?']","['The assumption of quadratic loss at the end of training may not hold in practice, limiting the applicability of the results.', 'The paper does not discuss potential negative societal impacts or ethical considerations.', 'Assumes a specific structure for the covariance of the gradient noise.', 'Complexity of the model may limit its practical applicability.', 'The practical applications of the theoretical findings are not clear.']",False,3,3,3,6,4,"['Comprehensive theoretical analysis of SGD dynamics.', 'Empirical validation across multiple neural network architectures.', 'Novel insights into the interaction between hyperparameters, gradient noise, and the Hessian matrix.', 'Combines both theoretical analysis and empirical validation.']","['Dense and complex theoretical analysis that may not be accessible to a broad audience.', 'Empirical validation may not convincingly demonstrate practical implications.', 'Assumptions such as quadratic loss at the end of training may not hold in real-world scenarios.', 'Strong assumptions regarding the quadratic approximation of the loss and the covariance structure.', 'Limited practical implications or improvements to current training practices.', 'Lacks clear evidence of significant originality or groundbreaking insights.']",3,3,3,4,Reject
-3Qj7Jl6UP5,"The paper introduces the concept of magnitude vectors for images, leveraging metric space properties for tasks such as edge detection and adversarial robustness. It provides a theoretical framework and a computationally efficient algorithm for calculating magnitude vectors.","['Can the authors provide more empirical results to validate the effectiveness of magnitude vectors in various datasets and tasks?', 'How does the performance of the proposed method compare with other state-of-the-art techniques in more detail?', 'Can the authors simplify the theoretical explanations or provide an intuitive understanding to improve clarity?', 'Can you provide more rigorous theoretical proofs for some of the analogies made?', 'How does the magnitude-based edge detection compare with other modern edge detection algorithms?', 'Can you include more comparisons with state-of-the-art methods in adversarial robustness?', 'Can the noise in edge detection using magnitude vectors be reduced?', 'Can the authors elaborate on the computational cost and runtime of the proposed algorithm compared to existing methods?', 'What are the potential limitations of using magnitude vectors for adversarial robustness?']","['The paper does not comprehensively address the potential limitations and negative societal impacts of the proposed method.', 'The computational efficiency of the proposed algorithm, though improved, might still be a limitation for very large images or datasets.', 'The noisiness in edge detection results needs addressing.', 'More rigorous theoretical proofs would strengthen the paper.', 'Comparisons with additional state-of-the-art methods in adversarial robustness are needed.', 'The paper does not address the potential limitations of the proposed method in high-dimensional datasets beyond images.', 'Potential negative societal impacts of using magnitude vectors in adversarial robustness are not discussed.']",False,3,2,3,5,4,"['Introduces a novel concept of magnitude vectors for images.', 'Provides a substantial theoretical framework.', 'Proposes a computationally efficient algorithm for calculating magnitude vectors.', 'Demonstrates potential applications in edge detection and adversarial robustness.']","['The clarity of the paper is hampered by dense mathematical notations and lengthy theoretical explanations.', 'Empirical results are limited in scope and the comparison with existing methods is superficial.', 'The practical utility of magnitude vectors in broader contexts remains uncertain.', 'Theoretical justifications are based on analogies rather than rigorous proofs.', 'Edge detection results are noisier compared to traditional methods.', 'Limited comparison with other state-of-the-art methods in adversarial robustness.']",3,3,3,3,Reject
alaQzRbCY9w,"The paper introduces the Stochastic Model Building (SMB) algorithm, which enhances Stochastic Gradient Descent (SGD) by using model building to adjust both the stepsize and search direction, incorporating second-order information. The method is shown to achieve faster convergence and better generalization in various machine learning problems.","['Why was the convergence analysis not provided for the original SMB method?', 'Could you provide more details on the computational overhead introduced by the model building step?', 'How does SMB perform on other types of neural network architectures beyond the ones tested?', 'Can the authors clarify the differences in convergence behavior between SMB and SMBi?', 'Why were some experiments run only once? Can the authors provide additional runs to ensure the robustness of the results?', 'How does the proposed method compare with other state-of-the-art algorithms like Adam in more diverse settings?', 'Can the authors provide more details on the implementation and hyperparameter tuning process for reproducibility?', 'What are the implications of the convergence analysis being based on SMBi rather than SMB?', 'Do you have plans to extend the experimental validation to more diverse datasets and models?', 'How does the computational overhead of SMB compare to traditional methods like SGD and Adam?', ""Can the authors provide more details on how the SMB algorithm's model building step affects the overall runtime?"", 'How does SMB handle very large datasets and models, given the additional computations required for model building?', 'What are the practical implications of not having stepsize auto-scheduling in the SMB algorithm?']","['Convergence analysis is only for SMBi, not the original SMB.', 'No discussion on potential negative societal impacts.', 'Limited experimental robustness due to single runs on some datasets.', 'Potential high computational cost due to the additional function and gradient evaluations required by the model-building steps.', 'The SMB algorithm lacks an internal learning rate adjusting mechanism, which is crucial for practical applications.', 'The dense mathematical sections could be made clearer for better understanding.']",False,3,3,3,5,4,"['Novel approach incorporating second-order information.', 'Experimental results show faster convergence and better generalization.', 'Robustness to a wide range of initial stepsizes.']","['Convergence analysis is provided for a modified version of the algorithm (SMBi), which underperforms compared to the original SMB.', 'Dense mathematical sections that could be clearer.', 'High computational cost due to extra mini-batch function and gradient evaluations.', 'Limited experimental validation across different datasets and models.', 'The paper does not address potential negative societal impacts or ethical considerations adequately.']",3,3,3,3,Reject
TKrlyiqKWB,"The paper proposes a new neural network architecture called Concept Subspace Network (CSN) which aims to generalize existing classifiers to handle multi-concept relationships, including fairness and hierarchy. The CSN uses prototype-based representations and can enforce concept independence or hierarchy through subspace alignment. The method is evaluated on several datasets, demonstrating comparable or superior performance to state-of-the-art methods in fair and hierarchical classification tasks.","['Can the authors provide more details on the scalability of CSNs for larger datasets?', 'How does the method perform compared to more recent baselines not included in the paper?', 'Can the authors clarify the training time and complexity of the CSN relative to other methods?', 'Can you provide more detailed explanations or visual aids to clarify the technical approach, especially the concept subspace alignment?', 'What are the potential limitations of CSNs in practical applications?', 'How do you address the potential negative societal impacts of CSNs, especially in terms of ethical considerations?', 'Can you provide more detailed explanations and justifications for the choice of alignment and KL loss terms?', 'How do you envision the practical deployment of CSNs in real-world scenarios?', 'Can you elaborate on potential negative societal impacts and how to mitigate them?', 'Can the authors provide a more detailed theoretical analysis to support the claims made in the paper?', 'How does the novelty of CSNs compare to existing methods like PCNs or HPNs?', 'Can the authors clarify the mathematical notations and provide more intuitive explanations for the methodology?', 'What is the practical significance of combining fair and hierarchical classification within a single model?']","['The paper does not address the scalability of CSNs for very large datasets.', 'Potential negative societal impacts are mentioned but not thoroughly explored.', 'The robustness of the method across different domains is not fully evaluated.', ""The model's complexity might limit its practical applicability.""]",False,3,2,3,5,4,"['Novel approach to unify different classification tasks (fairness, hierarchy) within a single model.', 'Prototype-based representations provide interpretability.', 'Demonstrates comparable or superior performance on standard benchmarks.', 'Extensive experimental validation across multiple datasets and tasks.']","['Evaluation lacks robustness and comprehensive comparison with more baselines.', 'Scalability and generalizability of the method are not convincingly demonstrated.', 'Clarity in the explanation of the method and results is lacking.', 'Ethical implications are mentioned but not deeply explored.', 'Complex methodology that might be difficult to implement and understand.']",3,3,2,3,Reject
w8HXzn2FyKm,"The paper presents a novel multi-agent linear stochastic approximation algorithm driven by Markovian noise and general consensus-type interaction, with time-varying directed graphs and stochastic matrices. It provides finite-time error bounds on the mean-square error for cases with both constant and time-varying step-sizes, relaxing the assumption of bi-directional communication.","['Can the authors provide more detailed examples or applications of the proposed algorithms in real-world scenarios?', 'How do the proposed finite-time bounds compare with those for algorithms using doubly stochastic matrices?', 'Are there any specific conditions or limitations under which the proposed algorithms may not perform well?', 'Can the authors provide more intuition behind the assumptions made, especially Assumption 6?', ""Is there any empirical validation or practical application that demonstrates the proposed algorithms' performance?"", 'How sensitive are the finite-time bounds to the choice of step-size and other parameters?', 'How does the proposed method perform in real-world scenarios with dynamic and potentially unreliable communication networks?', 'Can the authors provide more detailed explanations and examples to improve the clarity of the paper?', 'Can the authors provide more insights into the practical implications and computational feasibility of the proposed algorithms?', 'Are there any experimental results or case studies to demonstrate the effectiveness of the proposed methods in real-world scenarios?', 'Can the authors suggest ways to simplify or clarify the dense mathematical exposition for better readability?']","['The paper acknowledges the difficulty in computing some of the constants involved in the finite-time bounds.', 'Potential negative societal impacts are not explicitly discussed.', 'The computational feasibility of the proposed algorithms in large-scale settings is not discussed.', 'The restrictive nature of some assumptions, such as the existence of a limit for the absolute probability sequence, may limit the generalizability of the results.']",False,3,3,3,6,4,"['Addresses an under-explored area in distributed RL with stochastic matrices.', 'Provides rigorous theoretical analysis and finite-time error bounds.', 'Extends the applicability of existing algorithms to more realistic scenarios with uni-directional communication.']","['Complexity of proofs and dense presentation may hinder clarity.', 'Limited discussion on practical implications and applications.', 'Reproducibility might be challenging due to the intricate theoretical framework.', 'Assumptions such as uniform strong connectivity and existence of an absolute probability sequence may limit practical applicability.', ""No empirical validation or practical case studies are provided to demonstrate the algorithms' effectiveness in real-world scenarios.""]",4,3,3,4,Reject
e-JV6H8lwpl,"The paper proposes a novel nonlinear system identification method using a deep neural network with a bottleneck layer, aimed at providing a state estimator and predictor for model predictive control (MPC). The method extends traditional subspace methods to nonlinear systems and provides a theoretical basis for the approach. The paper includes illustrative examples to demonstrate the method's applicability.","['Can the authors provide more rigorous proofs for the theoretical claims?', 'Can the authors present more comprehensive experimental validation with diverse and complex examples?', 'How does the proposed method compare quantitatively with existing state-of-the-art methods?', 'Can the authors provide more details on handling noise and disturbances in the proposed method?', 'What are the specific hyperparameters used in the neural network, and how were they tuned?']","['The method has not been validated on high-dimensional or real-world systems.', 'The theoretical basis relies on strong assumptions which may not hold in practical scenarios.', 'Potential negative societal impacts are not discussed.', 'Overfitting risks are not adequately addressed, considering the high capacity of neural networks.', 'The notation and mathematical formulation are dense and could be simplified for better readability.']",False,3,2,3,5,4,"['Novel extension of subspace methods to nonlinear systems using neural networks.', 'Theoretical foundation based on the observability of the target system.', ""Illustrative examples demonstrate the method's application.""]","['Limited empirical validation with only a few illustrative examples.', 'Dense and complex notation, making the paper difficult to follow.', 'Insufficient discussion on practical applicability and overfitting risks.', 'Minimal discussion on potential negative societal impacts and limitations.']",3,3,2,3,Reject
ZWykq5n4zx,"The paper proposes a confidence-boosting framework to establish high-probability generalization bounds for randomized learning algorithms with on-average uniform stability, such as SGD with time-decaying learning rates. The authors provide theoretical results and demonstrate the application of their framework to both SGD and deterministic algorithms.","['Can the authors provide empirical results to validate the theoretical claims?', 'How does the proposed framework compare to existing methods in practical scenarios?', 'Can the authors discuss potential real-world applications and their impact?', 'Could the clarity of the mathematical notations and derivations be improved for better readability?', 'How does the proposed method compare to existing methods in terms of computational complexity?', 'Have you considered the potential negative societal impacts of your work?']","['The paper primarily focuses on theoretical analysis and lacks empirical validation.', 'Practical implications and potential real-world impact are not thoroughly explored.', 'The dense presentation may limit accessibility to a broader audience.', 'The paper does not thoroughly discuss the limitations and potential negative societal impacts of the proposed method.']",False,3,3,3,6,4,"['Addresses an important problem in understanding the generalization bounds for randomized learning algorithms.', 'Proposes a novel application of the confidence-boosting framework.', 'Provides thorough theoretical analysis and proofs.', 'Extends results to practical algorithms such as SGD with time-decaying learning rates.']","['The paper is densely written with heavy mathematical formalism, which can hinder clarity.', 'Empirical validation of the theoretical claims is lacking.', 'Practical implications and potential impact on real-world applications are not thoroughly discussed.', 'The organization of the paper could be improved to make the flow of ideas more coherent.']",3,3,3,4,Reject
3mgYqlH60Uj,"The paper presents a novel reinforcement learning model that incorporates biomechanical cumulative fatigue for generating full-body locomotion. The authors propose a Normalized Cumulative Fatigue (NCF) model derived from the Three Compartment Controller (3CC) model. The approach aims to produce more natural and symmetric locomotion without the need for motion capture data, finite state machines, or extensive hyper-parameter tuning.","['Can the authors provide more details on the assumptions made in the NCF model and how they affect the results?', 'Why did the authors choose a constant recovery coefficient (R=0.2) for all joints, and how does this choice impact the results?', 'Can the authors provide a comparison with more recent state-of-the-art techniques in the field?', 'How does the NCF model handle tasks and joints that are not isometric, given that the 3CC model was originally designed for isometric tasks?', 'Can the authors discuss more about the potential generalizability issues and how the NCF model can be adapted for different environments without hyper-parameter tuning?', 'Can the authors provide more detailed explanations and illustrations of the NCF model derivation?', 'How does the method perform in other types of locomotion tasks or with different character models?', 'Have the authors considered validating their model with real-world data or participants?', 'Can the authors provide more theoretical backing for the NCF model in dynamic and isokinetic tasks?', 'Can the authors clarify how the hyperparameters were tuned for the NCF model?']","['The model assumes a constant recovery coefficient for all joints, which may not be realistic.', 'The validity of the NCF model for locomotion from a biomechanical perspective is not well-established.', 'The paper primarily focuses on symmetry and does not explore other potential benefits of the proposed method.', 'The 3CC model is not task- and joint-agnostic, which could limit the applicability of the NCF model.', 'The 3CC model was designed for isometric tasks and may not be fully validated for isokinetic tasks like locomotion.', 'Future work should include studies with real participants to validate the NCF model from a biomechanical perspective.', ""The NCF model's dependence on specific hyper-parameters like recovery coefficient R for each joint."", 'Possible need for further tuning for different environments and tasks.', 'No discussion on the potential negative societal impact of the proposed method.']",False,2,2,3,5,4,"['Introduces a novel approach to integrating biomechanical fatigue into RL-based locomotion.', 'Shows promise in generating natural and symmetric movements.', 'Computationally efficient compared to traditional muscle-based models.', 'Eliminates the need for motion capture data, finite state machines, and morphological specifications.']","['Lacks thorough comparison with recent state-of-the-art techniques.', 'Assumptions made in the model may not hold in real-world scenarios.', 'Insufficient evidence that the NCF model is valid for locomotion from a biomechanical perspective.', 'Clarity of the paper could be improved, especially in the explanation of mathematical formulations and experimental setup.', 'Technical robustness of the NCF model is questionable in more challenging environments compared to the 3CC model.', 'Limited evaluation with only three specific simulated environments.', 'No experimental validation with real-world data or participants to confirm biomechanical accuracy.', 'Noticeable number of grammatical errors and typos, reducing clarity.']",3,2,2,3,Reject
z7p2V6KROOV,"The paper presents WILDS 2.0, an extension of the WILDS benchmark, which includes curated unlabeled data for unsupervised adaptation. It spans diverse modalities and tasks, providing a rich dataset for evaluating methods that use unlabeled data to mitigate distribution shifts. The paper systematically benchmarks state-of-the-art methods across these datasets and reports mixed results, suggesting avenues for future work.","['What are the specific limitations of the current methods that led to their mixed performance?', 'Are there any specific directions or hypotheses for future work to improve the robustness of unsupervised adaptation methods?', 'How do the authors plan to address the limited success of the evaluated methods in future iterations of the WILDS benchmark?', 'Can you provide more insights into why some methods did not show significant improvement over standard supervised training?', 'Are there any specific directions for future research that you believe could address the limitations observed in the current methods?', 'Can the authors provide more detailed insights into why some methods failed to outperform ERM?', 'What are the specific challenges faced during the evaluation of methods on non-image modalities?', 'Why were hyperparameters for pre-training algorithms not tuned, and could this have impacted the results?', 'Can the authors provide more details on the mixed results, and any hypotheses on why many methods did not outperform standard supervised training?', 'How do the authors plan to address the challenges in developing data augmentation techniques for non-image modalities?']","['The current methods evaluated show limited improvement over standard ERM.', 'The paper does not propose novel methods to address the issues identified.', 'Potential negative societal impacts include the possibility of biased models due to the distribution shifts and the nature of the datasets used.', 'The paper acknowledges that the current methods have limited success on the extended benchmark, suggesting room for improvement.', 'The potential negative societal impacts, such as biases in the datasets and ethical considerations in surveillance and privacy, are discussed.', 'The paper also notes the ethical implications and potential biases in the datasets, such as the bias in toxicity annotations in CIVILCOMMENTS-WILDS.']",False,3,3,3,6,4,"['Extends the WILDS benchmark to include curated unlabeled data.', 'Covers a diverse range of applications and tasks.', 'Provides a thorough evaluation of state-of-the-art methods.', 'Maintains consistency with the original benchmark, allowing for direct comparisons.', 'Provides a standardized protocol for evaluating methods that leverage unlabeled data.', 'Includes a wide range of applications, tasks, and modalities.', 'Open-source package and leaderboards facilitate reproducibility and further research.']","['Limited improvement of evaluated methods over standard ERM.', 'Mixed results suggest that current methods may not be robust enough.', 'Lack of novel methods proposed to address the issues identified.', 'The primary contribution is an extension of an existing benchmark, rather than introducing new methods or theoretical insights.', 'Some of the included methods did not show significant improvement over standard supervised training, raising questions about the efficacy of current approaches.', 'Reproducibility concerns due to the complexity and volume of the datasets and experiments.']",2,3,4,3,Reject
3Li0OPkhQU,The paper presents a semi-supervised algorithm for learning Convolutional Neural Networks (CNNs) under certain distributional assumptions. It shows that the algorithm can efficiently learn CNNs if the distribution of patches in the input images has low-dimensional structure. The paper provides theoretical guarantees and empirical results on datasets like MNIST and Fashion MNIST.,"['Can the authors provide more empirical results, especially on more challenging and varied datasets?', 'How do the assumptions on the low-dimensional structure of patches hold up in real-world datasets?', 'Can the authors elaborate on the practical implications and limitations of their theoretical results?', 'Can the authors provide more intuitive explanations for their theoretical results?', 'How do the proposed methods compare with the latest state-of-the-art methods in more complex settings?']","['The paper primarily focuses on theoretical guarantees, which might not fully translate to practical gains.', 'The assumptions on the data distribution could limit the applicability of the results.', 'The empirical validation is not comprehensive enough to support the broad claims.', 'The empirical evaluation is limited to relatively simple datasets, which may not demonstrate the full potential of the proposed algorithm.']",False,3,2,3,5,4,"['Provides a theoretical framework for learning CNNs under specific distributional assumptions.', 'The semi-supervised algorithm is novel and leverages data-dependent features.', 'Offers both theoretical analysis and empirical validation.']","['The empirical results are limited and do not compare well with state-of-the-art models.', 'The paper is complex and dense, making it hard to follow in places.', 'The distributional assumptions might be too stringent for practical applications.', 'Limited empirical evaluation on relatively simple datasets like MNIST and Fashion MNIST.', 'Lack of detailed discussion on the practical implications and limitations of the theoretical results.']",3,3,2,2,Reject
D1TYemnoRN,"The paper presents a framework that connects optimization and generalization by analyzing the length of optimization paths in gradient flow algorithms. It demonstrates that short optimization paths lead to good generalization through theoretical analysis. The framework is applied to three models: underdetermined ℓp linear regression, kernel regression, and overparameterized two-layer ReLU neural networks, providing explicit generalization bounds for each.","['Can the authors provide empirical results on large-scale real-world tasks to demonstrate the practical implications of their framework?', 'How robust is the proposed framework to different initialization methods and model architectures?', 'Can the authors simplify or elaborate some of the theoretical proofs for better readability?', 'How sensitive are the results to the assumptions made in the theorems?', 'Can the framework be extended to other machine learning models that do not satisfy the Uniform-LGI property?']","['The framework heavily relies on the Uniform-LGI property, which may not hold in all practical scenarios.', 'The assumptions regarding initialization methods may limit the applicability of the theoretical results.', 'Limited empirical validation on synthetic datasets.', 'Potential negative societal impacts are not discussed, though they seem minimal given the theoretical nature of the work.']",False,3,2,3,5,4,"['Addresses the important problem of connecting optimization with generalization.', 'Provides a novel framework with rigorous theoretical proofs.', 'Applies the framework to multiple models and shows detailed theoretical results.']","['Empirical validation is limited to small-scale synthetic problems.', 'Assumptions like specific initialization methods may limit the generality.', 'Theoretical reliance on Uniform-LGI property may not hold in practical scenarios.', 'Complex mathematical exposition that may hinder readability.', 'Insufficient discussion on potential negative societal impacts.']",3,3,3,3,Reject
CVfLvQq9gLo,"The paper introduces ARTEMIS, a method for image retrieval using free-form text modifiers. ARTEMIS combines Explicit Matching (EM) and Implicit Similarity (IS) modules, each utilizing lightweight attention mechanisms guided by text. The method is validated on multiple datasets, showing state-of-the-art performance.","['Can the authors provide more detailed discussion on the limitations and potential negative societal impacts of their work?', 'How does ARTEMIS handle cases with contradictory or negated text modifiers?', 'Could the authors provide more insights into the performance on datasets with more subjective annotations?', 'Can you provide more details on the computational complexity and efficiency compared to other state-of-the-art methods?', 'How does ARTEMIS perform on more diverse datasets beyond fashion and CIRR?', 'Can the authors provide more insights into how the method handles subjective judgments in text modifiers?', 'How does the method perform on datasets with less well-defined annotations?', 'Can the authors discuss potential negative societal impacts of their approach?', 'What measures have been taken to ensure that the method generalizes well beyond the specific datasets used?', 'Can the authors provide a more detailed analysis of potential biases in the datasets and their impact on the results?', 'How does ARTEMIS perform on other types of image retrieval tasks beyond fashion and open-domain?', 'Can the authors provide more details on the computational efficiency compared to simpler baselines?', 'How does the model handle queries with ambiguous or contradictory text modifiers?']","['The paper does not adequately discuss the limitations and potential negative societal impacts.', 'The method shows weaknesses in handling negation and subjective annotations.', 'The model struggles with negative formulations, which could be due to the limited presence of such examples in the training data.', 'The method relies heavily on the quality of textual modifiers, which may vary among annotators.', 'The method may struggle with negations and subjective judgments in text modifiers.', 'The approach relies on well-annotated datasets for training and evaluation.', ""The method's reliance on specific datasets may limit its generalizability to other domains."", 'Potential biases in datasets are not thoroughly analyzed.', 'Potential negative societal impact includes biases in retrieval based on training data.']",False,3,3,3,7,4,"['Novel combination of text-to-image and image-to-image retrieval.', 'Lightweight attention mechanisms.', 'Thorough experimental validation.', 'Code availability for reproducibility.', 'Clear and well-organized presentation.', 'Extensive experimental validation demonstrating state-of-the-art performance.']","['Limited discussion on limitations and societal impacts.', 'Qualitative examples show issues with negation and subjective annotations.', 'Performance improvements are consistent but not groundbreaking.', 'Some sections could be more concise.', 'Further details on the computational complexity and efficiency would be beneficial.', 'Dependency on well-annotated datasets for training and evaluation.', 'Incomplete analysis of potential biases and handling of negations in text.', 'Performance heavily tied to specific datasets, raising concerns about generalization.']",3,3,4,3,Accept
xRK8xgFuiu,"This paper introduces a new algorithm for causal discovery using Cholesky factorization, offering improved time and sample complexities compared to existing methods. The algorithm merges topology order learning and graph estimation into a single phase, leading to significant performance gains. Theoretical analysis and extensive experimental evaluations on synthetic and real-world datasets demonstrate the efficiency and effectiveness of the proposed method.","['Can the authors provide more detailed explanations for some of the theoretical proofs, particularly Lemma A.1 and Theorem A.2?', 'How does the performance of the algorithm vary with different types of noise in real-world data?', 'Could the authors elaborate on the choice of hyperparameters and their impact on the results?', 'How realistic are the assumptions required for the theoretical guarantees in practical datasets?', 'How does the proposed method compare to existing methods in more diverse real-world scenarios?', 'Can the authors make the code available during the review process to facilitate reproducibility checks?']","['The paper assumes linear SEM, which might limit its applicability to non-linear settings.', 'The impact of different noise distributions on performance is mentioned but not deeply explored.', 'Potential ethical considerations related to the misuse of causal discovery in sensitive domains are not discussed.', 'The complexity of the presented theoretical analysis could make the method less accessible to practitioners.']",False,3,3,3,7,4,"['Novel use of Cholesky factorization for DAG recovery.', 'Improved time and sample complexities compared to existing methods.', 'Comprehensive theoretical analysis with guarantees for exact DAG recovery.', 'Extensive experimental evaluations demonstrating state-of-the-art performance.']","['Theoretical proofs could be more clearly detailed and easier to follow.', 'Clarity of the presentation could be improved in some sections.', 'Some experimental results lack sufficient detail and context for interpretation.', ""The assumptions required for theoretical guarantees might be too strong and unrealistic in practical scenarios, potentially limiting the method's applicability."", 'Reproducibility of the experiments is not fully addressed; code is promised to be open-sourced upon acceptance, but it would be better if it were available during the review process.']",4,3,3,3,Accept
T_uSMSAlgoy,"The paper proposes a Tree-based Decoder-Centric (TDC) algorithm for identifying latent holes in the latent space of Variational Auto-Encoders (VAEs) for text generation. This approach shifts the focus from the encoder to the decoder, providing a novel perspective on latent hole identification. The paper includes extensive theoretical and empirical analyses to demonstrate the efficacy of the proposed method.","['Can you provide more details on the hyperparameter settings used in the experiments?', 'Could you elaborate on the theoretical justifications for choosing the ILIP indicator over others?', 'How does the performance of the proposed TDC algorithm compare to existing methods in terms of computational efficiency?', 'Can the theoretical proofs be simplified or clarified for better understanding?', 'What are the potential negative societal impacts of this work?', 'How does the use of PCA for dimensionality reduction affect the results? Are there potential artifacts introduced?', 'Can the proposed TDC algorithm be generalized to other types of VAEs or generative models beyond text generation?', 'What are the limitations of the TDC algorithm in terms of scalability and applicability to larger datasets?']","['The paper assumes that the principal components contain the most information, which may not always be the case.', 'The focus is solely on text generation; it would be interesting to see how the method performs on other types of data.', 'The reliance on PCA for dimensionality reduction might introduce artifacts.', 'The complexity and density of the theoretical justifications may limit accessibility.', 'The empirical validation could be strengthened with a more diverse set of metrics and comparative baselines.']",False,3,3,3,5,4,"['Novel focus on the decoder for latent hole identification.', 'Comprehensive empirical analysis including multiple datasets and VAE models.', 'Addresses a significant problem in text generation tasks.']","['Theoretical contributions could be more rigorously presented.', 'Methodology section is dense and somewhat difficult to follow.', 'Empirical validation could be more robust with a broader range of metrics and comparative baselines.', 'Limited novelty in the core algorithmic approach; heavily reliant on existing metrics.', 'The paper does not adequately address potential negative societal impacts.']",3,3,3,3,Reject
SN2bkl9f69,"The paper proposes MSMT-GAN, a novel architecture for text-to-image synthesis, introducing three new components: Multi-Tailed Word-level Initial Generation (MTWIG), Spatial Dynamic Memory (SDM), and Iterative Multi-Headed Mechanism (IMHM). The method aims to improve the quality and realism of generated images and is evaluated on the CUB and COCO datasets, showing significant improvements in some metrics over state-of-the-art methods.","['Can the authors provide more details on the specific implementations of the MTWIG and SDM modules?', 'How were the hyperparameters chosen for the experiments, and what impact do they have on the results?', 'What are the potential limitations of the proposed method, and how do they affect the generalizability of the results?', 'Can the authors discuss any potential ethical concerns or societal impacts associated with their work?', 'Can the authors provide more insights into why the improvements on the COCO dataset are not as significant as those on the CUB dataset?', 'How does the computational cost of the proposed method compare to other state-of-the-art methods?']","['The paper does not discuss the potential limitations of the proposed method, such as scalability to larger datasets or different types of text descriptions.', 'There is no mention of potential negative societal impacts or ethical concerns related to generating realistic synthetic images from text descriptions.', 'The method is computationally intensive, which may limit its practical applicability.', 'The improvements are dataset-dependent, suggesting potential overfitting or lack of generalizability.', 'The complexity of the proposed methodology may limit its adoption and reproducibility.']",True,3,2,3,5,4,"['Introduction of three novel components (MTWIG, SDM, IMHM) to address specific limitations in text-to-image synthesis.', 'Comprehensive evaluation on two datasets (CUB and COCO) showing improved performance over state-of-the-art methods.', 'Detailed ablation studies to demonstrate the effectiveness of each proposed component.']","['The clarity of the paper is lacking in several sections, making it difficult to understand the exact implementations and mechanisms.', 'The experimental setup and hyperparameters are not thoroughly explained, making it hard to reproduce the results.', 'Potential limitations and ethical considerations are not adequately addressed.', 'The improvements on the COCO dataset are marginal, raising concerns about the generalizability of the method.', 'The proposed method is computationally intensive, which may limit its applicability.']",3,3,2,3,Reject
6ya8C6sCiD,"The paper proposes a novel architecture called symbolic mapping to improve language learning in multi-agent systems. The authors hypothesize that language evolves from simple to complex tasks and validate this through various experiments, including task transfer and vocabulary expansion.","['Can the authors provide more details on the potential negative societal impacts of their work?', 'How does the proposed method compare to other state-of-the-art techniques in more complex environments?', 'Can the authors discuss the limitations of their evaluation metrics and how they might be improved?', 'Can the authors provide more details on the hyperparameter settings and training stability?', 'How would the approach perform on a wider range of tasks and datasets?', 'Can the authors provide more details on the theoretical foundation for symbolic mapping?', 'How does the proposed method compare to other state-of-the-art methods in terms of computational efficiency?', 'What are the potential limitations of symbolic mapping in real-world applications?', 'Can the authors provide more details on how symbolic mapping differs from existing symbolic representation techniques?']","['The paper does not address potential negative societal impacts or ethical concerns adequately.', 'The experimental setup may not capture the full complexity of real-world language learning scenarios.', 'The scalability of symbolic mapping to a larger number of agents and more complex tasks is not discussed.', 'Potential scalability issues when applying symbolic mapping to larger and more complex environments.', 'The paper does not sufficiently discuss the limitations of the proposed approach.']",False,3,2,2,4,4,"['Novel concept of symbolic mapping.', 'Comprehensive experimental validation.', 'Significant improvements in language compositionality and symmetry.']","['Limited generalizability of experimental results.', 'Lack of discussion on potential negative societal impacts and ethical concerns.', 'Limited comparison with other state-of-the-art methods.', 'Evaluation metrics may not fully capture the complexity of emergent language properties.', 'The clarity of the paper is lacking in several sections, making it difficult to follow.', 'Details on hyperparameter settings and training stability are missing.', 'Theoretical grounding is limited; the paper heavily relies on empirical results.', 'Potential over-complication of the proposed method.', 'Certain sections, particularly experimental setup and results, lack clarity.', 'The significance of the results is limited due to the specific nature of the experiments and potential issues with generalizability.']",3,3,2,3,Reject
1gEb_H1DEqZ,"The paper introduces PROPHET, a pre-trained language model designed to improve logical reasoning abilities by incorporating three novel pre-training tasks: logical connectives masking, logical structure completion, and logical path prediction. These tasks are based on a fact-based knowledge structure, consisting of predicate-argument triplets. The model is evaluated on various NLP tasks, including natural language inference, semantic similarity, machine reading comprehension, and document-level relation extraction.","['Can the authors provide more details on how the logical graph is constructed and its specific role in improving performance?', 'How does the performance of PROPHET compare to other models on a wider range of logical reasoning tasks?', 'Can the authors clarify the potential computational overhead introduced by the proposed pre-training tasks?', 'How does PROPHET compare to other recent state-of-the-art models in NLP tasks?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'Can the authors provide more details on the fact extraction process and how it differs from existing methods?', 'How do the introduced pre-training tasks compare to other recent approaches in terms of computational efficiency and scalability?', 'Can the authors discuss any potential ethical concerns or societal impacts associated with their model?', 'What specific factors contribute to the observed improvements in logical reasoning tasks?', 'How does the proposed method compare to other state-of-the-art methods on the same benchmarks?']","['The authors should address the potential computational overhead and resource requirements introduced by the new pre-training tasks.', 'The paper should discuss how the proposed approach generalizes to languages other than English.', 'The potential negative societal impacts of improved logical reasoning in language models should be considered.', 'The potential for biases in the logical reasoning tasks is not discussed.', 'The scalability of the approach to larger datasets and more complex tasks is not addressed.', 'The evaluation lacks a thorough analysis of why the proposed method outperforms baseline models.']",False,2,2,2,4,4,"['Proposes novel pre-training tasks aimed at enhancing logical reasoning in language models.', 'Demonstrates improvements over baseline models on several NLP tasks.', 'Focuses on reducing reliance on external knowledge sources by utilizing facts extracted from text.']","['Incremental improvements over existing models, which may not justify the complexity of the approach.', 'Limited novelty as it builds upon existing pre-training techniques like masked language modeling.', 'Methodology and broader implications are not clearly explained.', 'Evaluation may not comprehensively demonstrate the claimed advances in logical reasoning.', 'Dense and convoluted descriptions, particularly in the sections on pre-training tasks and logical graph construction.', 'Insufficient discussion on potential limitations and negative societal impacts.']",2,2,2,2,Reject
qyTBxTztIpQ,"The paper presents CrowdPlay, a comprehensive crowdsourcing pipeline for generating large-scale human demonstration data, specifically for offline learning and imitation learning in reinforcement learning environments. Contributions include a new dataset, benchmarks, and a detailed study on participant incentives to enhance data quality.","['Can the authors provide more details on the scalability and robustness of the system, especially under different incentive designs?', 'How do the authors plan to address the poor performance of current offline RL algorithms on the dataset? Are there specific algorithmic improvements they foresee?', 'Can the authors clarify how the dataset and framework can be immediately beneficial to researchers and practitioners in its current form?', 'Can the authors provide further validation of the incentive structures and their exact impact on data quality?', 'Could the presentation of t-SNE embeddings and other results be improved for better clarity?', 'What are the implications of the benchmarks showing that existing offline RL algorithms struggle with the dataset?', 'Can the authors provide more details on how they plan to address the imbalance in data collection?', 'What measures are in place to ensure scalability beyond the initial recruitment channels?', 'Can the authors expand on the ethical considerations regarding participant compensation?', 'How does the performance of CrowdPlay compare with other existing crowdsourcing platforms in terms of ease of use and scalability?', 'Can the authors elaborate on the ethical considerations taken for participant compensation, especially for unpaid participants from social media?', 'What specific improvements or advancements do the authors envision CrowdPlay can bring to offline learning that existing datasets and platforms cannot?']","['The dataset is primarily focused on Atari 2600 games, which may limit its applicability for other domains.', 'The performance of current offline RL algorithms on the dataset is suboptimal, indicating the need for more robust methods.', 'Potential ethical concerns related to fair compensation and participant motivation in crowdsourcing settings.', 'The dataset might be unbalanced, especially for different behavior types.', 'Collecting human-human multiagent data proved challenging.', 'The scalability of the approach to broader applications beyond Atari games is not fully demonstrated.', 'Ethical considerations, particularly around fair compensation, need more detailed discussion.', 'Potential biases in data collection due to different incentive structures.', 'Limited diversity in the types of games and tasks.', 'Technical challenges in scaling the system for a larger number of users.']",True,3,3,3,5,4,"['Introduces a novel framework for crowdsourcing human demonstrations in RL environments.', 'Provides a large-scale, diverse dataset of human gameplay in Atari 2600 games.', 'Thorough study on the effects of different incentive models on data quality.', 'Benchmark evaluations of several offline RL algorithms on the new dataset.', 'Open-source release of the code and dataset, promoting reproducibility and further research.']","['The clarity of the paper could be improved, especially in sections detailing technical implementations and experimental setups.', 'The evaluation shows that current offline RL algorithms perform poorly on the dataset, raising questions about the immediate utility.', 'Potential scalability concerns with the crowdsourcing pipeline, especially given the varied incentive designs and recruitment channels.', 'The paper could have provided more concrete examples or use-cases demonstrating the immediate benefit of the dataset and framework.', 'Limited novelty in methods; primarily leverages existing environments.', 'Potential ethical concerns related to fair compensation and participant motivation in crowdsourcing settings.', 'Technical complexity may hinder reproducibility and ease of use.']",3,3,3,3,Reject
hxitw01k_Ql,"The paper investigates the impact of different memory architectures on learning in partially observable Markov decision processes (POMDPs) through a two-hypothesis testing problem. It compares random access memory (RAM) and Memento memory, finding that constrained memory (Memento) can lead to better empirical results due to easier training. Theoretical findings are supported by empirical results.","['Can the authors provide more insight into how their findings generalize to more complex POMDP tasks?', 'How do the results compare with other recent approaches to memory architectures in reinforcement learning?', 'Can the authors provide additional empirical results to demonstrate the generalizability of their findings?', 'Can you provide more details on the empirical setup, including hyperparameter settings and computational resources used?', 'How sensitive are the results to the assumptions and conjectures made in the theoretical analysis?', 'Could you elaborate on the potential real-world applications and implications of your findings?']","['The study is limited to the two-hypothesis testing problem and may not directly apply to more complex POMDP tasks.', 'The practical implications of the findings are not thoroughly discussed.', 'The potential negative societal impacts are not addressed.', 'The theoretical analysis is heavily based on conjectures and specific assumptions, which may not hold in more complex or different POMDP scenarios.', 'The empirical evaluation is limited to a specific problem setup and may not generalize to other tasks.']",False,2,2,2,4,4,"['Addresses a significant problem in reinforcement learning related to POMDPs.', 'Provides a novel comparison between different memory architectures.', 'Theoretical findings are supported by empirical results.', 'Robust mathematical analysis and proofs.']","['Limited discussion on the practical implications and generalizability of the results.', 'Empirical results are specific to the two-hypothesis testing problem and may not generalize.', 'Needs a more thorough comparison with related work.', 'Dense mathematical sections which may limit accessibility.', 'The paper is somewhat poorly structured, making it difficult to follow the main contributions.', 'Insufficient details on the experimental setup and parameters.', 'Heavy reliance on conjectures and assumptions, limiting generalizability.', 'Potential negative societal impacts are not addressed.']",3,2,2,3,Reject
RftryyYyjiG,"The paper explores the use of tensor decomposition techniques for compressing pre-trained language models (PLMs) such as BERT. The authors propose a framework for matrix and tensor decomposition methods, present decomposition and reconstruction protocols to improve compression efficiency, and demonstrate the effectiveness of their methods on the GLUE benchmark.","['Can the authors provide more mathematical justification for the proposed tensor decomposition methods?', 'How does the proposed method compare with state-of-the-art compression techniques beyond those mentioned in the paper?', 'Have the authors considered the impact of their compression method on other NLP tasks besides those in the GLUE benchmark?', 'Can the authors provide more details on the practical challenges of implementing the proposed tensor decomposition methods?', 'What are the potential limitations and negative societal impacts of the proposed methods?', 'How do the authors ensure reproducibility of their results?', 'How generalizable are these methods to other PLMs beyond BERT?', 'Can the authors discuss in more detail the practical implications and potential real-world applications of their methods?']","['The paper does not address potential biases introduced during compression.', 'The environmental impact of retraining models for compression is not discussed.', 'The paper does not adequately address the potential negative societal impacts of model compression. The authors should discuss the implications of deploying highly compressed models in various applications.', 'Reproducibility of the results is not clearly addressed.', 'The ethical implications related to model compression, such as potential biases in compressed models, are not discussed.']",False,3,2,3,6,4,"['Novel application of tensor decomposition for PLM compression.', 'Thorough experiments showing significant parameter reduction.', 'Potential for practical applications in resource-constrained environments.', 'Comprehensive analysis and comparison of different decomposition methods.', 'Method is complementary to existing compression techniques like knowledge distillation.']","['Lacks detailed mathematical proofs and comprehensive comparisons with all relevant baselines.', 'Some sections, particularly those involving complex tensor operations, could benefit from more detailed explanations.', 'Impact on real-world tasks beyond the GLUE benchmark is not thoroughly explored.', 'The proposed methods are complex and may be challenging to reproduce.', 'Limited discussion on the potential negative societal impacts of model compression.', 'No clear comparison with other state-of-the-art compression techniques.', 'The originality of the approach is somewhat limited as tensor decompositions for neural network compression have been explored before.', 'The presentation is overly technical in some sections, making it less accessible to a broader audience.']",3,3,2,4,Accept
jNB6vfl_680,"The paper presents a pruning technique that combines Global Magnitude Pruning (GP) with a Minimum Threshold (MT) to achieve state-of-the-art (SOTA) performance on various neural network architectures and datasets. The authors demonstrate that GP alone is a strong pruning method and that adding MT can further enhance performance, particularly in high sparsity regimes. The method is evaluated on benchmarks like ResNet-50 and MobileNet-V1 on ImageNet, showing strong performance.","['Can you provide more details on how the Minimum Threshold (MT) values are chosen for different architectures?', 'How does the method perform on other types of neural networks, such as recurrent neural networks (RNNs) or transformer models?', 'Can you discuss the environmental impact of your method, especially considering the higher FLOPs in some scenarios?', 'Can you provide more theoretical insights into why GP with MT works better than other pruning methods?', 'Is there any scenario where GP with MT might perform worse than other pruning techniques?', 'How does the proposed method compare to other state-of-the-art pruning methods in terms of FLOPs?', 'Is the Minimum Threshold (MT) always necessary, or are there cases where it does not improve performance?', 'Can the authors provide more insights into the choice of MT values and their impact on different architectures?']","['Higher FLOPs in some scenarios.', 'Limited novelty as the core idea of magnitude pruning is well-known.', 'Potential environmental impact not discussed in detail.', 'The paper does not adequately address the scalability and applicability of the method to a broader range of neural network architectures and datasets.', 'The simplicity of the MT approach raises concerns about its effectiveness in different scenarios.', ""The method's reliance on empirical results without deep theoretical backing."", 'Potential performance issues on architectures not tested in this paper.']",False,3,3,3,5,4,"['Simple and effective pruning method.', 'Comprehensive experimental validation on multiple architectures and datasets.', 'Achieves SOTA performance on several benchmarks.', 'Reproducibility is well addressed with code availability and detailed experimental setup.', 'Well-written and organized paper.']","['Incremental novelty; the core idea of magnitude pruning is well-established.', 'Higher FLOPs in certain scenarios.', 'Lack of theoretical analysis and deep insights into why the method works.', 'Limited discussion on the scalability and applicability to a broader range of architectures and datasets.', 'Potential concerns about the generalizability and robustness of the method.', 'Over-reliance on empirical results without sufficient comparative analysis with other pruning techniques.', 'Potential negative societal impacts and ethical considerations are not thoroughly addressed.']",2,3,4,3,Reject
Ih0iJBSy4eq,"The paper proposes reinforcement learning algorithms for finding Stackelberg-Nash Equilibria (SNE) in leader-controlled general-sum Markov games. It introduces both online and offline RL methods, provides theoretical guarantees on sublinear regret and suboptimality, and claims to be the first work to do so. The algorithms are designed to be sample efficient and incorporate function approximation for handling large state spaces.","['Can the authors provide more details on the empirical validation of the proposed algorithms?', 'How sensitive are the results to the assumptions made, particularly the access to a computational oracle?', 'Can the methods be extended to settings where the leader-controller assumption does not hold strictly?', 'How do the proposed algorithms perform compared to existing methods in practice?', 'Can the authors provide more intuitive explanations and clearer organization for the theoretical results?', 'Have you considered any potential negative societal impacts of your work?']","['The reliance on computational oracles and leader-controller transitions may limit practical applicability.', 'The paper does not discuss the potential negative societal impacts of the proposed methods.', 'The theoretical results are promising, but the lack of empirical validation limits the practical significance of the work.']",True,3,2,3,4,4,"['Addresses a novel problem in multi-agent reinforcement learning.', 'Provides rigorous theoretical guarantees for the proposed algorithms.', 'Incorporates function approximation to handle large state spaces.']","['The paper is dense and may be difficult to follow for readers not familiar with the domain.', 'Lack of empirical validation to demonstrate the practical applicability of the proposed algorithms.', 'Relies on strong assumptions such as access to a computational oracle and leader-controlled transitions.', 'Ethical considerations and potential societal impacts are not sufficiently addressed.']",3,3,2,3,Reject
N0n_QyQ5lBF,The paper introduces a new task called unsupervised vision-language (VL) grammar induction and proposes a method named CLIORA to extract a shared hierarchical structure for both images and language captions simultaneously. The method uses a new evaluation metric called Critical Concept Recall Rate (CCRR) and improves state-of-the-art performance on MSCOCO and Flickr30k Entities benchmarks.,"['Can the authors provide more details on the potential negative societal impacts of their work?', 'Can the methodology be presented more clearly, possibly with more diagrams or step-by-step explanations?', 'How does the proposed method perform on other datasets or tasks outside of MSCOCO and Flickr30k?', 'Can the authors justify the significance of the new evaluation metric, CCRR, in more detail?', 'Can the authors provide more details on how CLIORA differs significantly from existing methods in visually-grounded grammar induction and weakly-supervised visual grounding?', 'Can the authors elaborate on the specific contributions of the new evaluation metric, CCRR, and how it better assesses VL grammar induction compared to existing metrics?', 'Can the authors provide more insights into the limitations of CLIORA and potential directions for future work?', 'How does CLIORA perform on datasets with more complex scenes and descriptions?', 'Can the authors provide additional ablation studies to better understand the contributions of different components of the model?', 'How does CLIORA perform when using different pre-trained object detectors or embeddings?', 'How does the method handle cases where there is no clear visual correspondence for certain language constituents?', 'Can the authors provide a clearer explanation of the model architecture and training process?', 'How do the introduced evaluation metrics correlate with established metrics in the field?', 'Can the authors provide a more thorough comparison with existing methods in both the vision and language domains?', 'What are the systematic conditions under which CLIORA fails or underperforms?']","['The paper does not adequately address the limitations and potential negative societal impacts of their work.', 'The methodology is complex and not clearly presented, which may hinder reproducibility.', 'The paper does not thoroughly discuss the potential negative societal impacts of the work.', 'The limitations of the proposed method, such as its scalability to larger datasets and more complex scenes, are not addressed in detail.', 'The paper mentions the challenge of modeling contextual semantics but does not provide a thorough discussion on the limitations of the proposed method in this regard.', 'The paper does not provide a comprehensive analysis of the limitations of the proposed method.', 'There is no systematic study of the conditions under which CLIORA fails or underperforms.']",False,2,2,2,4,4,"['Introduction of a novel task in the vision-language domain.', 'Proposes a new method, CLIORA, with a multi-level fusion strategy.', 'Introduces a new evaluation metric, CCRR, for VL grammar induction.', 'Shows state-of-the-art performance on MSCOCO and Flickr30k Entities benchmarks.']","['The paper is not clearly written and organized, making the methodology hard to follow.', 'Experimental results, while promising, are not convincingly demonstrated across a variety of tasks or datasets.', 'Limited discussion on the potential negative societal impacts of the proposed method.', 'The significance of the proposed evaluation metric, CCRR, is not well justified.', 'The novelty of the task and method is not entirely clear due to overlap with existing works.', 'The clarity of the paper could be improved, particularly in the technical sections.', 'The significance of the results is modest, with only slight improvements over baselines.', 'The paper could benefit from more thorough empirical validation and stronger presentation.', 'The reproducibility section could be more detailed; for example, providing more specific instructions or scripts for reproducing results.', 'The limitations section lacks depth; it should explicitly discuss potential negative societal impacts and other limitations of the proposed approach.', 'The method relies heavily on pre-trained object detectors and embeddings, which may limit its generalizability.', 'The practical applications and broader impact of the proposed task and method are not well articulated.']",3,2,2,3,Reject
HiHWMiLP035,"The paper proposes E[2]CM, an early exit mechanism based on class means, aimed at reducing computational costs without requiring gradient-based training. The method is particularly useful for low-power devices and extends to unsupervised learning tasks. The effectiveness of E[2]CM is demonstrated on CIFAR-10, CIFAR-100, KMNIST, and MNIST datasets using various ResNet architectures.","['Can the authors provide more details on the hyperparameters and training conditions used in the experiments?', 'How does the performance vary across multiple runs? Can the authors provide statistical validation or variance analysis?', 'Can the authors elaborate on the potential limitations and practical implications of deploying E[2]CM in real-world scenarios?', 'Can the authors provide a more rigorous theoretical justification for the use of class means?', 'How does the performance of E[2]CM vary with different types of neural network architectures other than ResNets?', 'What are the implications of the memory overhead caused by storing class means at each layer, especially for large-scale networks?', 'Can the authors clarify the mathematical notations used in Section 3.1?', 'Have the authors evaluated the statistical significance of the improvements reported?', 'How does the proposed method generalize to other datasets and network architectures?', 'What are the potential negative societal impacts of using E[2]CM in critical applications? How can these be mitigated?']","['The paper does not fully address the limitations of using class means for early exit, such as potential issues with class overlap or ambiguous samples.', 'The practical implications of deploying E[2]CM in low-power devices are not fully explored.', 'The memory overhead and computational cost of storing and using class means need to be evaluated more thoroughly.', 'The generalizability of the approach to other datasets and network architectures should be explored.', 'Potential negative societal impacts of using E[2]CM in critical applications are not discussed.']",False,2,2,3,4,4,"['Novel use of class means for early exit, reducing the need for gradient-based training.', 'Potential for application in low-power devices, improving computational efficiency.', 'Promising experimental results showing improvements in accuracy and computational cost.', 'Applicable to both supervised and unsupervised learning tasks.']","['Limited originality as it builds upon established concepts of early exits and class means.', 'Lacks rigorous statistical validation and detailed experimental setup.', 'Clarity of the paper can be improved; explanations are somewhat scattered.', 'Significance is moderate; practical implications and limitations are not fully explored.', 'Potential memory overhead due to storing class means at each layer.']",3,2,2,3,Reject
GQd7mXSPua,The paper proposes a meta-learning framework for predicting task-specific covariance matrices using diagonal or low-rank factors to improve uncertainty quantification and out-of-distribution (OOD) detection. The method leverages an attentive set encoder and introduces an energy-based inference procedure for better calibration. The effectiveness of the approach is demonstrated through experiments on synthetic data and benchmark few-shot learning datasets.,"['Can the authors provide more detailed explanations of the inference procedure, particularly the energy-based approach?', 'How would the proposed method compare to additional baselines not included in the experiments?', 'Can the authors provide more details on the implementation of the attentive set encoder and its hyperparameters?', 'How does the proposed method compare with the latest state-of-the-art techniques in terms of both accuracy and computational efficiency?', 'Are there specific tasks or domains where this method significantly outperforms existing methods?', 'Can the authors provide more details on how to reproduce the results? For example, sharing the code or detailed implementation steps.', 'How does the method perform under different meta-learning scenarios or with different types of covariance structures?', 'Can the authors elaborate on the potential negative societal impacts and limitations of their approach?']","['The paper acknowledges the limitations in terms of the complexity of the proposed method and the need for further evaluation on more diverse datasets.', 'The complexity of the method could limit its practical applicability.', 'The paper does not address potential negative societal impacts, such as biases in the datasets used for training and evaluation.', 'The authors should discuss the potential limitations of their approach more thoroughly.', 'There is a lack of discussion on the computational complexity of the proposed methods.']",False,3,2,3,5,4,"['Addresses a significant problem in meta-learning and uncertainty quantification.', 'Proposes a novel framework combining meta-learning with covariance matrix prediction.', 'Shows improvements in experimental results over existing methods.', 'Employs advanced techniques like set transformers and matrix determinant lemmas.', 'Comprehensive related work section.']","['The paper is dense and may be challenging to follow for non-experts.', 'Some parts of the methodology, particularly the inference procedure, could be better explained.', 'The experimental setup could benefit from additional baselines for a more thorough comparison.', 'The novelty of the method is somewhat incremental, combining existing techniques.', 'Reproducibility might be an issue due to limited details on implementation specifics.', 'The practical significance of the results is not clearly demonstrated.', 'Potential negative societal impacts and limitations are not adequately discussed.']",3,3,2,3,Reject
vr39r4Rjt3z,"The paper proposes two architectural modifications, Masked Highway Connection (MHC) and Layer-Wise Normalisation (LWN), to mitigate catastrophic forgetting in neural networks during continual learning. The experiments demonstrate that these modifications improve performance compared to baseline methods and are compatible with existing continual learning techniques.","['Can the authors provide more details on the theoretical analysis supporting the effectiveness of MHC and LWN?', 'Can the authors clarify the experimental setup, especially the choice of hyperparameters and datasets?', 'How do the proposed methods compare to other state-of-the-art techniques not mentioned in the paper?', 'How do MHC and LWN perform in more varied and complex continual learning tasks?', 'Can the authors provide a more detailed analysis of the limitations of MHC and LWN?', 'How do these methods compare with other state-of-the-art continual learning techniques in terms of computational efficiency?', 'How do the modifications affect the computational complexity and training time?', 'Can more intuitive explanations or diagrams be provided to improve clarity?']","['The paper does not thoroughly explore the limitations of the proposed methods, such as potential increases in computational cost.', 'Potential negative societal impacts are not discussed.', 'The methods might increase the computational cost, which is not discussed.']",False,2,2,2,4,4,"['The proposed methods, MHC and LWN, show empirical improvements in continual learning tasks.', 'The methods are compatible with existing continual learning techniques, enhancing their applicability.', 'The paper addresses the significant issue of catastrophic forgetting in neural networks.']","['The novelty of the proposed methods is incremental, building on existing architectures like highway connections and normalization techniques.', 'The theoretical analysis is not thorough enough to fully support the claims made.', 'The presentation of the experimental setups and results lacks clarity and detail.', 'Concerns about reproducibility due to insufficient details on hyperparameters and experimental settings.', 'The paper does not adequately address the limitations and potential negative societal impacts of the work.']",3,2,2,3,Reject
EhYjZy6e1gJ,"The paper presents PiCO, a novel framework for Partial Label Learning (PLL) that integrates contrastive learning with a prototype-based label disambiguation strategy. The method aims to improve the quality of representations and effectively disambiguate candidate labels. Theoretical justifications are provided from an Expectation-Maximization perspective, and extensive experiments demonstrate state-of-the-art performance on benchmark datasets.","['How does the method perform under different data generation processes?', 'What is the impact of the moving-average factor and other hyperparameters on the performance?', 'Can the authors provide more insights into the computational efficiency and feasibility of the method in large-scale applications?', 'Can the authors provide more details on the computational complexity of PiCO compared to other PLL methods?', 'How does PiCO perform in real-world applications with different types of data and label ambiguity?', 'What are the potential negative societal impacts of PiCO, and how can they be mitigated?', 'Can the authors provide more discussion on the practical scalability of PiCO, especially on larger datasets?', 'Are there any potential limitations or negative societal impacts of the proposed method that have not been addressed in the paper?', 'How would PiCO perform on other types of datasets beyond image classification?', 'Can the authors provide additional empirical validation for some of the theoretical claims made in the paper?', 'How does the proposed method perform on a wider range of datasets and tasks beyond image classification?', 'Can the authors provide more concrete examples or applications where PiCO would be particularly beneficial?', 'How does the method handle cases with extreme label ambiguity or noise?', 'Can the authors clarify the potential negative societal impacts of their work and how they plan to mitigate them?']","['The method might be computationally intensive due to the use of contrastive learning and prototype updates.', 'The moving-average factor and other hyperparameters need careful tuning, which might limit the practical applicability.', 'The paper does not provide a detailed discussion on the limitations of the proposed method.', 'Potential negative societal impacts are not adequately addressed.', 'Experiments are limited to a few datasets, which may not fully demonstrate the scalability of the approach.', 'The evaluation is primarily on image classification datasets, which may limit the generalizability of the results.', 'Potential negative societal impacts, such as misuse or bias in the disambiguation process, are not discussed.']",False,3,4,3,7,4,"['Novel integration of contrastive learning with prototype-based label disambiguation.', 'Theoretical justifications from an Expectation-Maximization perspective.', 'Extensive empirical validation showing state-of-the-art performance.', 'Well-written and organized, providing sufficient details for reproducibility.']","['The theoretical justifications could be clearer and more accessible.', 'Limited ablation studies on the impact of different components and hyperparameters.', 'No significant discussion on the computational efficiency and scalability of the method.', 'Limited evaluation on a few datasets; broader generalization is not demonstrated.', 'Potential negative societal impacts are not thoroughly discussed.']",3,3,4,3,Accept
OCgCYv7KGZe,"The paper proposes Auto-Encoding Inverse Reinforcement Learning (AEIRL), an IRL framework that leverages auto-encoders to generate more robust reward signals. The method is evaluated on various MuJoCo tasks and shows improved performance in both clean and noisy settings.","['Can the authors provide more detailed descriptions of the experimental setup?', 'How do the authors justify the use of auto-encoders theoretically?', 'Can the authors include comparisons with more recent state-of-the-art methods?', 'How does AEIRL perform on a more diverse set of tasks beyond MuJoCo environments?', 'What are the limitations of AEIRL in terms of computational complexity and scalability?', 'Could the authors elaborate on the hyperparameters used in the experiments and their selection process?', 'How does AEIRL handle varying levels of noise in expert demonstrations?', 'Are there any real-world applications where AEIRL has been tested?', 'What are the potential negative societal impacts of AEIRL?', 'How does the computational efficiency of AEIRL compare to other methods?']","['The paper should address the limitations in clarity and experimental detail to improve reproducibility.', 'Potential negative societal impacts are not discussed in detail.', 'The current evaluation is limited to MuJoCo tasks, which may not fully represent the diversity and complexity of real-world environments.', ""The method's reliance on the quality of the auto-encoder could be a potential limitation."", 'The computational efficiency of the method compared to baselines is not extensively discussed.']",False,2,2,3,5,4,"['Novelty: The use of auto-encoders in IRL is a novel idea.', 'Robustness: The method demonstrates improved robustness in noisy settings.', 'Comprehensive Evaluation: The paper includes extensive experiments and ablation studies.']","['Clarity: The paper is not well-organized and is difficult to follow. The descriptions are often convoluted.', 'Theoretical Justification: The paper lacks a deep theoretical analysis or justification for the proposed method.', 'Experimental Details: Some experimental setups and results lack clarity, impacting reproducibility.', 'Baseline Comparisons: The comparisons with baselines could be more rigorous and include newer methods.', 'Limited Scope: The evaluation is limited to MuJoCo tasks, which may not fully represent the diversity and complexity of real-world environments.']",3,2,2,3,Reject
LtKcMgGOeLt,The paper investigates the application of the Sharpness-Aware Minimizer (SAM) to Vision Transformers (ViTs) and MLP-Mixers to improve their performance and robustness without large-scale pre-training or strong data augmentations. The authors show that SAM helps these models achieve better accuracy and robustness compared to ResNets of similar sizes when trained from scratch on ImageNet.,"['Can the authors provide more theoretical insights into why SAM improves the performance of ViTs and MLP-Mixers?', 'How does the increased computational cost of SAM impact its practical applicability in real-world scenarios?', 'Can the authors discuss the potential limitations of their approach on other datasets or tasks beyond ImageNet?', 'Can the authors provide more comparisons with other state-of-the-art methods?', 'Could the authors clarify the potential negative impacts and limitations of SAM, particularly in larger datasets?', 'What are the broader ethical implications of deploying these models in real-world applications?', 'Can the authors provide more details on the theoretical aspects of SAM and its connection to higher-order optimization?', 'How does SAM perform on datasets other than ImageNet? Can the authors provide results on more varied datasets?', 'Can the authors explore the diminishing impact of SAM with larger datasets in more detail?', 'What are the computational trade-offs when using SAM, and are there ways to mitigate the increased training cost?', 'Can the benefits of SAM be extended to other model architectures, such as convolutional neural networks (CNNs)?']","['The increased computational cost due to SAM (approximately 2x) might limit its practical applicability.', 'The effect of SAM diminishes as the training dataset becomes larger.', 'Potential broader implications of deploying these models in real-world applications are not discussed.', 'Limited exploration of varied datasets beyond ImageNet.', 'Potential over-reliance on specific dataset structures and preprocessing techniques.', 'The results might be highly dependent on the specific dataset and tasks used for evaluation.', 'Potential ethical concerns regarding increased computational cost and environmental impact.']",False,3,3,3,6,4,"['Addresses a significant problem in training ViTs and MLP-Mixers.', 'Proposes a well-motivated solution (SAM) with both theoretical and empirical support.', 'Conducts extensive experiments across various tasks showing considerable improvements.', ""Provides detailed analyses of the models' intrinsic properties."", 'Offers comprehensive experimental details for reproducibility.', 'Supports reproducibility by providing code and model checkpoints.', 'Well-written and clearly organized.']","['The computational overhead of SAM is significant, which may limit its practical applicability.', 'The paper is very dense, which may make it challenging for readers to follow.', 'Limited exploration of limitations and potential negative impacts.', 'Comparisons with other state-of-the-art methods are somewhat limited.', 'Ethical considerations are not adequately discussed.', 'Theoretical insights into why SAM improves ViTs and MLP-Mixers are not sufficiently explored.', 'Results might be highly context-dependent and not generalize well to other datasets or tasks.']",3,3,3,3,Accept
zz9hXVhf40,"The paper revisits design choices in offline model-based reinforcement learning (MBRL), proposing a thorough comparison of various uncertainty heuristics and introducing novel evaluation protocols. It demonstrates that optimized hyperparameter selection using Bayesian Optimization can lead to substantial performance improvements over existing state-of-the-art methods.","['Can the authors provide more theoretical justification for the choice of certain hyperparameters?', 'How do the proposed methodologies generalize to other reinforcement learning tasks beyond the benchmarks used?', 'Can the authors provide more details on the computational resources required for their experiments?', 'How do the authors ensure the reproducibility of their results given the large number of hyperparameters?', 'Can the authors simplify some of the statistical metrics and figures for better understanding?', 'Can the authors provide more details on the fairness of the experimental baselines compared to the state-of-the-art methods?', 'How do the authors address potential reproducibility issues given the complexity of the experiments?', 'Can the authors provide more details on the ethical considerations and potential real-world impacts of their methods?', 'Are there specific reasons for the choice of certain hyperparameters that were not fully explained in the paper?', 'How does the proposed Bayesian Optimization approach compare to other hyperparameter optimization methods in terms of computational efficiency?', 'Could the authors provide more details on the computational cost and feasibility of using Bayesian Optimization in real-world applications?', 'What are the potential limitations and negative societal impacts of the proposed methods?', 'Can the authors discuss how they controlled for implementation details in their comparative results?']","['The paper primarily focuses on continuous control tasks. The applicability of the findings to other RL tasks or domains is not thoroughly explored.', 'Potential negative societal impacts are not discussed in detail, especially regarding the deployment of RL policies trained offline.', 'Scalability of the approach could be an issue.', 'Potential mismatch between theoretical guarantees and practical performance.', 'Need for better understanding of the implications on dynamics generalization.', 'Reproducibility might be an issue due to the lack of detailed implementation and hyperparameter settings.', 'The paper does not adequately discuss the computational cost and feasibility of Bayesian Optimization.']",False,3,3,3,7,4,"['Comprehensive comparison of existing uncertainty heuristics.', 'Novel evaluation protocols for assessing uncertainty penalties.', 'Detailed experiments demonstrating significant performance improvements.', 'Clear insights into the interaction between different design choices in MBRL.', 'Well-written and organized paper with clear presentation of results.', 'Rigorous experimental comparison using Bayesian Optimization.', 'Addresses practical issues in offline RL with solutions beneficial to researchers and practitioners.']","[""The paper's complexity may overwhelm readers new to the field."", 'The robustness and reproducibility of the results need further verification.', 'Potential overemphasis on empirical results without sufficient theoretical backing in some areas.', 'Insufficient details on computational resources required.', 'Dense and difficult to follow for readers not familiar with offline MBRL.', 'Limited discussion on the generalizability of the findings.', 'Potential concerns about the fairness and comprehensiveness of the experimental baselines.', 'Some key implementation details and hyperparameter settings are not fully transparent, which might affect reproducibility.', 'Potential ethical concerns regarding the applicability of the methods in real-world settings are not deeply discussed.']",3,3,3,4,Accept
bsycpMi00R1,"The paper introduces Natural Hidden Gradient (NHG) dynamics for non-convex non-concave zero-sum games, including GANs. It provides theoretical guarantees for global convergence under specific conditions and explores different geometries (hidden mapping and Fisher information). Empirical results are provided as proof-of-concept.","['Can the authors provide more extensive empirical validation of NHG dynamics on larger datasets and more complex models?', 'Are there any practical guidelines or heuristics for choosing the appropriate geometry (hidden mapping or Fisher information) for different types of games?', 'How sensitive are the proposed methods to the assumptions made, particularly overparametrization? Are there any strategies to mitigate issues when these assumptions do not hold?']","['Limited empirical validation.', 'Scalability issues due to tensor pseudo-inversion step.', 'Assumptions like overparametrization may not always hold.']",False,3,3,3,7,4,"['Innovative approach with NHG dynamics.', 'Theoretical contributions with proofs for global convergence.', 'Well-organized and clearly written.', 'Significant results for understanding dynamics in non-convex non-concave games.']","['Limited empirical validation.', 'Several assumptions that may not hold in practice.', 'Potential scalability issues with NHG dynamics.']",4,3,4,3,Accept
WN2Sup7qLdw,"The paper presents Multi-Resolution Continuous Normalizing Flows (MRCNF), a novel approach to generative modeling using neural ODEs. The proposed method leverages a multi-resolution strategy to improve computational efficiency and reduce the number of parameters required for training. The authors demonstrate that MRCNF achieves competitive bits-per-dimension (BPD) scores on various image datasets while using fewer parameters and less training time compared to prior methods.","['Can the authors provide more detailed explanations or visualizations to improve the clarity of the multi-resolution transformation?', 'How does the proposed method compare with more recent state-of-the-art models not mentioned in the paper?', 'Can the authors provide more insights into the potential limitations and failure cases of MRCNF?', 'Can you provide more details on the specific parameter settings used in the experiments?', 'How does the proposed MRCNF compare to CNFs in terms of generated image quality?', 'What are the potential limitations of MRCNF in practical applications?', 'Can the authors provide more detailed experimental comparisons with state-of-the-art methods on multiple datasets?', 'How does the proposed unimodular transformation compare empirically with other transformations?', 'Can the authors clarify the computational complexity of the proposed method in comparison to existing approaches?', 'Can the authors provide more detailed comparisons with state-of-the-art methods, particularly in terms of image quality metrics such as FID?', 'Could the authors clarify and improve the notation and mathematical formulation used in the paper?', 'What are the specific limitations of the proposed method in terms of generalization to other datasets or higher resolutions?', 'How does the performance of MRCNF scale with higher resolution datasets beyond ImageNet128?', 'Can the authors elaborate on the practical implications and potential applications of MRCNF in real-world scenarios?']","['The paper does not discuss potential negative societal impacts in detail.', ""The method's performance on more diverse and larger datasets is not explored."", 'The approach may still be limited by the inherent challenges of normalizing flows, such as handling high-dimensional data effectively.', 'The paper does not thoroughly address the issue of out-of-distribution detection, which is a significant limitation for practical applications.', 'There is a lack of clarity in some of the mathematical formulations, which could hinder reproducibility.', 'The limitations of the proposed method, such as its applicability to different types of data, are not adequately discussed.', 'The potential negative societal impacts of the work, such as the generation of fake images, are acknowledged but not deeply discussed.', 'The evaluation is primarily focused on likelihood metrics, with less emphasis on qualitative assessments such as sample quality.', 'The impact of the proposed unimodular transformation on training stability and convergence needs further exploration.']",False,3,2,3,4,4,"['Introduction of a multi-resolution approach to Continuous Normalizing Flows.', 'Significant reduction in computational cost and number of parameters.', 'Competitive performance in terms of bits-per-dimension on standard datasets.', 'Allows for parallel training and demonstrates super-resolution capabilities.', 'Provides thorough mathematical formulation and theoretical justification.']","['The clarity of the presentation is lacking, making it difficult to follow the proposed method and its implementation details.', 'Novelty compared to existing methods like WaveletFlow is not strongly established.', 'Limited experimental comparisons with a broader range of baseline models.', 'Ablation studies are present but could be more comprehensive.', 'Out-of-distribution detection performance is weak, which is a significant limitation.', 'The impact and significance are moderate but not groundbreaking.', 'Some claims lack robust empirical support.', 'The notation used is sometimes inconsistent, leading to confusion.', 'The paper does not provide sufficient evidence to support the claims of improved efficiency and performance.']",3,3,2,3,Reject
ExJ4lMbZcqa,"The paper presents Visually-Informed Dereverberation of Audio (VIDA), a novel method for audio dereverberation leveraging both audio and visual inputs. The approach uses an end-to-end model that includes a Visual Acoustics Network (VAN) and a UNet-based dereverberation module. The authors create a new large-scale dataset using SoundSpaces for realistic acoustic renderings of speech in various 3D environments. Evaluation results demonstrate state-of-the-art performance in speech enhancement, speech recognition, and speaker verification tasks.","['How well does the method generalize to real-world environments not covered by the training data?', 'What are the specific computational resources required for training and inference with the VIDA model?', 'Can the authors provide more details on the computational efficiency and real-time applicability of VIDA?', 'How does the model perform on other datasets or in different environmental conditions?', 'Can the authors clarify the potential impact of overfitting to the specific dataset used for training?', 'Can you provide more details on the robustness of VIDA in diverse real-world scenarios?', 'How does VIDA compare with other state-of-the-art methods in more detail?', 'Can you elaborate on the technical aspects related to the Visual Acoustics Network?', 'How does the model handle environments with dynamic changes (e.g., moving objects or people)?', 'Can the authors elaborate on the potential limitations of the dataset and how they might affect the results?', 'Can the authors provide more details on the potential negative societal impacts of their work?', 'How does the model perform in real-time scenarios given its complexity?', 'Can the authors expand on the robustness of their model in noisy environments?']","['The method may have limited applicability in environments where visual data is not available or is of poor quality.', 'Increased computational complexity due to the integration of visual and audio data, which may not be suitable for all practical applications.', ""The model's performance in very noisy environments needs to be further explored."", 'The potential negative societal impact of relying on visual data for audio processing should be discussed.', 'The paper does not fully address the computational complexity and potential latency issues of the proposed model.', 'There is a risk of overfitting to the specific dataset, which might limit the generalizability of the results.', ""The model's performance in highly dynamic environments or with moving speakers is not evaluated.""]",False,3,3,4,7,4,"['Novel approach integrating visual and audio modalities for dereverberation.', 'Comprehensive dataset with realistic acoustics for training and evaluation.', 'Impressive performance improvements over traditional audio-only methods.', 'Detailed experiments and ablation studies showcasing the effectiveness of the proposed method.']","['Potential concerns regarding the generalization to real-world scenarios despite promising results in simulated environments.', 'The increased complexity and computational requirements due to the integration of visual data.', 'Some parts of the paper are overly detailed, which might hinder readability and understanding.', 'Limited discussion on the computational efficiency and real-time applicability.', 'Potential overfitting to the specific dataset used for training.']",4,3,3,4,Accept
xtZXWpXVbiK,"The paper proposes FORBES, a flow-based recurrent belief state model for POMDPs, incorporating normalizing flows into variational inference to learn complex belief states and integrating these into downstream RL algorithms. The method is evaluated on digit writing tasks and visual-motor control tasks, showing some improvements over existing methods.","['Can the authors provide more comprehensive statistical analyses to substantiate their claims of superiority over existing methods?', 'How does the performance of FORBES compare to other baselines not covered in this paper?', 'Can the authors clarify the theoretical claims about the universal distributional approximator with more empirical evidence?', 'Can the authors provide more intuitive explanations for the theoretical concepts introduced?', 'How sensitive is FORBES to the choice of normalizing flows and hyperparameters?', 'Can the authors elaborate on the computational complexity and efficiency of FORBES compared to traditional methods?', 'How does FORBES perform in environments with significantly larger state and action spaces?', 'Are there any potential negative societal impacts or ethical concerns associated with the use of FORBES in real-world applications?']","['The paper does not thoroughly discuss the potential negative societal impacts or ethical considerations.', 'The experiments are limited to specific tasks; broader validation is necessary.', 'The clarity of the paper could be improved for better understanding.', 'Potential computational overhead due to the use of normalizing flows.', 'Scalability to even larger and more complex tasks remains to be seen.', 'The need for detailed hyperparameter tuning might limit practical applicability.']",False,3,2,3,5,4,"['Novel integration of normalizing flows into belief state learning for POMDPs.', 'Strong theoretical foundation with detailed mathematical formulations and proofs.', 'Empirical validation on digit writing and visual-motor control tasks showing superior performance.']","['The paper is densely written and difficult to follow, with complex mathematical notations and explanations.', 'Experimental validation is not comprehensive enough, with limited statistical analyses and comparisons with a broader range of baselines.', 'Theoretical advantages of using normalizing flows are not sufficiently justified.', 'Concerns about the scalability and computational overhead of the proposed method.', 'Lack of thorough discussion on potential limitations and negative societal impacts.']",4,3,2,4,Reject
-29uFS4FiDZ,"The paper proposes a two-stage method to distill multiple word senses from a pre-trained language model (BERT) to create multi-sense embeddings. The approach aims to overcome polysemy issues in non-contextual embeddings by using attention mechanisms and knowledge distillation. The authors demonstrate the effectiveness of their method through experiments on contextual word similarity and sense induction tasks, showing competitive or superior performance compared to state-of-the-art models. Additionally, the method's benefits are highlighted in a downstream application involving topic modeling.","['Can the authors provide more detailed explanations and diagrams to clarify the two-stage method?', 'How robust are the experimental results? Can the authors provide more details on the variability and reproducibility of their experiments?', 'What are the potential limitations and ethical concerns of the proposed method, particularly in the context of resource-constrained systems?', 'Can the authors provide a more detailed comparison with the latest state-of-the-art models?', 'Can the authors clarify the two-stage distillation process with more specific details and perhaps a flow diagram?', 'Can the authors discuss any error cases or limitations observed during the experiments?', 'Could the authors provide more details on the training process and hyperparameter selection?', 'How do the authors ensure that the baselines used for comparison are fairly evaluated?', 'Can the authors elaborate on the computational efficiency of their method compared to other distillation approaches?', 'How does the proposed method compare with other state-of-the-art models in terms of computational efficiency and scalability?', 'Can you provide more details on the hyperparameter tuning process and its impact on the results?', 'How would the model perform on other downstream tasks beyond topic modeling?']","['The paper does not adequately address the computational overhead introduced by the two-stage method.', 'There is a lack of discussion on the potential negative societal impact of the proposed method, such as biases in the distilled embeddings.', 'The paper does not discuss the potential limitations of using pre-trained models like BERT in low-resource languages or domains.', 'The societal impacts of misinterpretation of word senses in critical applications (e.g., legal, medical) are not addressed.', 'The method may not scale well for real-time applications due to the additional computational overhead.', 'The paper lacks a detailed discussion on the limitations of the proposed approach, particularly in terms of scalability and generalization to other languages or domains.', 'The potential negative societal impacts of the work are not addressed.']",False,3,2,3,4,4,"['Novel approach to distill knowledge from BERT for multi-sense embeddings.', 'Comprehensive experiments on multiple benchmark datasets.', 'Performance improvement in both word sense induction and contextual word similarity tasks.', 'Application in an embedding-based topic model demonstrates practical benefits.']","['The methodology section is complex and could benefit from clearer explanations and diagrams.', 'The experimental results need further verification to ensure robustness and reproducibility.', 'The paper lacks a thorough discussion on the limitations and potential ethical concerns associated with the proposed method.', 'The impact of the proposed method on resource-constrained systems remains unclear.', 'Insufficient differentiation from prior work on multi-sense embeddings and knowledge distillation.', 'Evaluation lacks thoroughness, particularly in terms of reproducibility and scalability.']",3,3,2,3,Reject
TNxKD3z_tPZ,"The paper proposes using Persistent Homology (PH) to estimate the generalization error of neural networks without a validation set. By computing PH diagram distances between consecutive neural network states, the authors show that these distances correlate with validation accuracy. This is demonstrated empirically on various benchmarks and models.","['How do you plan to address the computational scalability issues for larger models and datasets?', 'Can you provide more details on how this method could be extended to support convolutional layers directly?', 'What are the potential negative societal impacts of the proposed method, if any?', 'Can you provide more theoretical justification for why PH distances correlate with generalization properties?', 'How does the method handle different types of neural network architectures beyond MLPs and CNNs?', 'Can the authors elaborate on the potential impact of spurious homological features on the results?']","[""The method's computational scalability is a major limitation."", 'Currently limited to MLP architectures and does not support convolutional layers directly.', 'No predictive model for validation accuracy provided.', 'The representation of neural networks using directed flag complexes may overlook critical dynamics.', 'The empirical results, while showing strong correlations, do not necessarily imply causation or robustness across varied architectures and datasets.']",False,3,3,3,5,4,"['Novel approach using PH to estimate generalization error without a validation set.', 'Provides empirical evidence of the correlation between PH distances and validation accuracy.', 'Tested on diverse benchmarks and models.', 'Innovative use of algebraic topology in neural network training.']","['Major computational scalability issues.', 'Method limited to MLP architectures, not supporting convolutional layers directly.', 'Empirical validation lacks robustness due to limited range of datasets and models.', 'No predictive model for validation accuracy provided, limiting practical applicability.', 'Lack of theoretical justification for the correlation between PH distances and generalization.', 'Dense and technical writing style, making it hard to follow for non-experts.']",3,3,3,3,Reject
AS0dhAKIYA0,"The paper proposes a novel approach to enhance the interpretability of Machine Reading Comprehension (MRC) models using Semantic Role Labeling (SRL) and semantic role relation tables. The authors introduce nine semantic relation tables to represent the semantic relations within sentences and among sentences, and they integrate entity names to establish semantic relations among questions, articles, and target sentences. The proposed method is evaluated on the HotpotQA dataset, showing some performance improvements.","['Could you provide more details on the convolution operations and how they integrate local and global features?', 'How does the performance of the proposed model compare to other interpretability-focused models?', 'Can you provide more insights into the choice of hyperparameters and their impact on the results?', 'What specific measures were taken to ensure the reproducibility of the experiments?', 'Can you provide a clearer explanation and illustration of the semantic role relation table?', 'How does the proposed model compare with more recent state-of-the-art models beyond the baselines listed?', 'How can the clarity and organization of the paper be improved for better understanding?', 'What are the specific hyperparameters used in the experiments?', 'How does the proposed method handle more complex sentences with multiple predicates and arguments?', 'What are the potential limitations of using semantic role relation tables in real-world applications?']","[""The model's performance does not significantly outperform existing state-of-the-art models."", 'The method relies on SRL tools, which may have their own limitations and inaccuracies.', 'The paper does not address the potential computational overhead introduced by the additional semantic relation tables.', 'Potential scalability issues with increasing sentence and verb counts are not addressed.', 'Reproducibility is a concern due to the vague methodology description.', 'Potential negative societal impacts are not discussed.', 'The interpretability claims need more detailed validation and comparison with other methods.']",False,2,2,2,3,4,"['Novel approach to enhance interpretability using SRL and semantic role relation tables.', 'Introduction of nine semantic relation tables to capture various semantic relations.', 'The method shows some stability in performance with a smaller training dataset.']","['Experimental results are not significantly better than state-of-the-art models like BERT.', 'The clarity of the writing and organization of the paper could be improved.', 'Evaluation and comparison with baselines could be more thorough.', 'The explanation of the model architecture and the convolution operations is not detailed enough.', 'Potential reproducibility issues due to lack of detailed methodology.', 'Potential scalability issues with increasing sentence and verb counts are not addressed.', 'Limited discussion on potential negative societal impacts or ethical considerations.']",3,2,2,2,Reject
qTHBE7E9iej,"The paper proposes a novel hierarchical approach to learning transferable motor skills using a three-level hierarchy of both discrete and continuous latent variables. The method, termed Hierarchical Latent Mixtures of Skills (HeLMS), is evaluated on manipulation tasks and demonstrates improved performance and sample efficiency in transfer scenarios compared to existing methods.","['Can the authors provide a more detailed theoretical analysis to support the empirical results?', 'How does the performance vary with different numbers of latent components in the hierarchical model?', 'Can the authors clarify the notations used in the equations to improve readability?', 'Can the authors provide more details on the hyperparameter selection process and the sensitivity of the method to these parameters?', 'How does the method perform in more complex and diverse real-world environments not covered by the current experiments?', 'Can the authors elaborate on the potential limitations of the proposed method, especially in terms of computational complexity and scalability?', 'Can the authors provide more clarity on the methodological details, particularly the training procedure and network architectures?', 'How do the results compare with more recent baselines not considered in the paper?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their approach?', 'Can the authors provide more details on the computational requirements for training HeLMS?', 'How does the method scale with the number of skills and the complexity of tasks?', 'Can the authors elaborate on the potential limitations and failure modes of the proposed approach?', 'What are the ethical considerations and potential societal impacts of this work?', 'Can the authors clarify why the performance on object set 2 is significantly worse and how this impacts the overall effectiveness of HeLMS?', 'How does the complexity of HeLMS compare to simpler baselines in terms of computational cost?']","['The paper does not discuss potential negative societal impacts of the work, which is crucial in the current research climate.', 'The method section is dense and could benefit from more concise and clear explanations.', 'The method may be overly complex and difficult to implement in practice.', 'Potential overfitting to specific manipulation tasks.', 'Limited discussion on scalability and generalizability to other domains.', 'No discussion on ethical considerations or potential negative societal impacts.', 'The computational complexity and resource requirements are not discussed.', 'The potential limitations in terms of scalability and generalization to more complex tasks are not addressed.', 'The ethical implications of advanced robotic capabilities need to be considered.']",False,3,3,3,5,4,"['Novel combination of discrete and continuous latent variables in a three-level hierarchy.', 'Extensive experimental evaluation demonstrating improved performance and sample efficiency.', 'Detailed analysis of when and how the learned skills are beneficial.']","['Lack of rigorous theoretical analysis to support the empirical findings.', 'Dense and somewhat unclear method section, with complex notation.', 'Incremental novelty compared to closely related work such as NPMP.', 'No discussion on potential negative societal impacts or ethical considerations.', 'The complexity of the tasks and the environments used in the experiments might not fully represent real-world challenges.', 'Reproducibility of experimental results is not fully addressed.']",3,3,3,3,Reject
vEIVxSN8Xhx,"The paper introduces a novel log-polar space convolution (LPSC) method aimed at increasing the local receptive field (LRF) of convolutional neural networks (CNNs) without increasing the number of parameters. The LPSC uses elliptical convolution kernels in log-polar space to encode spatial structures more effectively. The method is tested across multiple datasets and network architectures, showing improvements over conventional and dilated convolutions.","['How does the method perform in terms of memory usage and computational efficiency compared to other advanced convolution methods?', 'Can the authors provide more details on the practical implications of the increased memory overhead and longer training times?', 'Are there any potential strategies to mitigate the memory and computational drawbacks of the proposed method?', 'Can the authors provide a more detailed theoretical analysis to support the claims of increased receptive field and parameter efficiency?', 'How does the proposed method compare to other advanced convolution methods in terms of computational complexity and performance?', 'Can the authors clarify the implementation details to ensure reproducibility?', 'Can the authors provide more details on the implementation of the LPSC layer, particularly the log-polar space pooling?', 'How does the computational complexity of LPSC compare to other advanced convolution methods in terms of training and inference times?', 'Can the authors provide additional experiments to demonstrate the generalizability of LPSC across different types of datasets?', 'Can the authors clarify the computational overhead introduced by the log-polar space pooling?', 'How sensitive are the results to the choice of hyperparameters Lr, Lθ, and g?', 'Can the authors provide more details on the ablation study to isolate the contributions of different components of LPSC?', 'Can the authors provide more detailed explanations or code snippets for the log-polar pooling implementation?', 'How sensitive are the model performances to the hyperparameters Lr, Lθ, and g? Can you provide guidelines for selecting these in practical scenarios?', 'Are there any optimizations or approximations that could reduce the computational and memory overheads introduced by LPSC?']","['The authors mention the significant memory overhead and the increased training time as critical drawbacks. They provide some potential hyperparameters but do not offer strategies to mitigate these issues.', 'The paper does not address the potential challenges in tuning the hyperparameters for different tasks and datasets.', 'The high computational complexity and memory overhead of the proposed method may limit its practicality in real-world applications.', 'The potential for overfitting on specific datasets is not adequately addressed.', 'The introduction of additional hyperparameters (Lr, Lθ, g) may complicate the tuning process and affect the overall performance.', 'Potential negative societal impacts are not explicitly discussed, although none are immediately apparent given the context of the work.']",False,2,2,3,4,4,"['The LPSC concept is novel and addresses the issue of limited LRF in lower layers of CNNs.', 'The method demonstrates improvements in various tasks compared to conventional and dilated convolutions.', 'Comprehensive experiments and ablation studies validate the effectiveness of the proposed method.']","['The implementation via log-polar space pooling incurs significant memory overhead, limiting practical applications.', ""The introduction of additional hyperparameters may require careful tuning, complicating the method's use."", 'The substantial impact on training and inference time is a critical drawback for real-world applications.', 'The writing is somewhat unclear and disorganized, making it difficult to follow the methodology.', 'Lacks thorough theoretical analysis to support the claims.', 'Certain technical explanations, such as the implementation details of the LPSC layer, are not clearly presented, making it difficult to fully understand the method.', 'The potential for overfitting on specific datasets is not adequately addressed.']",3,2,2,3,Reject
BduNVoPyXBK,"The paper introduces Feature Attending Recurrent Modules (FARM), a novel state representation learning architecture for deep reinforcement learning (RL) aimed at enabling generalization across diverse task environments. FARM learns perceptual schemas that capture recurring task-oriented perceptions and behaviors, distributing them across multiple recurrent modules with a dynamic feature attention mechanism. The paper claims that FARM outperforms existing methods like LSTM, AAA, and RIMs in various generalization tasks, including object-motion recall, sequential active perception of 3D objects, and memory retention in longer tasks with distractors.","['Can the authors provide more details on the justification for the chosen hyperparameters?', 'How would FARM perform in tasks outside the tested environments?', 'Can the authors elaborate on how feature attention provides an advantage over spatial attention specifically in the context of RL?', 'Can the authors provide more theoretical insights into why FARM performs better in certain scenarios?', 'How were the hyperparameters tuned, and is there a possibility of bias towards the proposed method?', 'Can the authors provide more intuitive explanations and visual aids for the FARM architecture?', 'What are the potential limitations and broader implications of the proposed method?', 'Can the authors provide more detailed ablations to isolate the contributions of each component of the FARM architecture?', 'How does the performance of FARM compare with other recent transformer-based architectures?', 'Can the authors clarify how the dynamic feature attention mechanism specifically contributes to the observed generalization improvements?']","['The paper does not extensively discuss the potential societal impacts of the proposed method.', 'The generalization claims are supported by specific tasks; it remains unclear how well FARM would perform in entirely different RL environments.', 'The paper does not address the scalability of FARM to real-world, large-scale environments.', 'There is a lack of discussion on the computational overhead introduced by FARM compared to simpler models.', 'Potential ethical concerns related to the misuse of RL systems in sensitive applications are not discussed.']",False,2,2,2,4,4,"['The problem of generalization in RL is significant and under-explored.', 'The proposed FARM architecture is novel and well-motivated.', 'Empirical evaluations across multiple tasks show promising improvements over baselines.', 'The paper is thorough in its analysis and comparisons with existing methods.']","['The paper is dense and can be difficult to follow, especially the technical details of the FARM architecture.', 'Some of the experimental setups and hyperparameter choices are not fully justified.', 'The impact of feature attention versus spatial attention needs more thorough exploration.', 'Potential societal impacts are not discussed extensively.']",3,2,2,3,Reject
AypVMhFfuc5,"The paper proposes FrugalMCT, a framework designed to efficiently select and combine multiple ML APIs for multi-label classification tasks. FrugalMCT aims to optimize for both accuracy and cost by employing an online algorithm that adapts to different data inputs and budget constraints. The framework includes an accuracy predictor, a service selector, and a label combiner, and is evaluated on various tasks using ML APIs from major providers like Google, Microsoft, and IBM. The results indicate significant cost savings and accuracy improvements over individual APIs and existing methods like FrugalML.","['How does FrugalMCT perform on significantly larger datasets or in real-time applications?', 'Can the authors provide more detailed comparisons with other ensemble methods for multi-label classification?', 'What are the potential ethical implications of using commercial APIs, particularly regarding fairness, bias, and privacy?', 'Can the authors provide more details on the deployment and practical use cases of FrugalMCT?', 'How does the choice of the accuracy predictor (e.g., random forest) impact the overall performance and are there alternative predictors that could be considered?']","['The paper primarily focuses on empirical results without extensive theoretical validation, which could limit the generalizability of the findings.', 'Scalability to very large datasets or real-time applications is not thoroughly discussed.', 'Potential negative societal impacts related to the use of commercial APIs, such as fairness, bias, and privacy, are not adequately addressed.', 'The reliance on random forest regressors for the accuracy predictor may limit the generalizability of the approach.']",True,3,3,3,5,4,"['Addresses an important problem in the MLaaS industry: optimizing cost and accuracy for multi-label classification tasks.', 'Proposes a novel framework that combines multiple APIs, which has not been widely explored in existing literature.', 'Includes extensive empirical evaluations using real-world APIs and datasets, demonstrating significant improvements in cost and accuracy.', 'Offers theoretical guarantees on the near-optimal performance of the online algorithm.', 'Release of a large annotated dataset for multi-label ML prediction APIs.']","['Over-reliance on empirical evaluations without sufficient theoretical analysis on the generalizability of the results.', 'Limited discussion on the scalability of the proposed method for very large datasets or real-time applications.', 'Lack of detailed comparison with other ensemble methods for multi-label classification beyond FrugalML.', 'Potential ethical concerns related to the use of commercial APIs, including issues of fairness, bias, and privacy.', 'Dense and sometimes difficult to follow, especially the notation-heavy sections.']",3,3,3,3,Reject
XWODe7ZLn8f,"The paper proposes C3-GAN, a method for unsupervised fine-grained class clustering using InfoGAN extended with contrastive learning. The method aims to learn feature representations that form distinct cluster boundaries in the embedding space and maximizes mutual information between latent codes and image observations. The approach is validated on four fine-grained image datasets, showing state-of-the-art clustering performance.","['Can the authors provide more intuitive explanations for the scene decomposition method?', 'How does the method perform on datasets outside of the four fine-grained ones used?', 'What are the specific limitations of C3-GAN in terms of computational resources and scalability?', 'Can you provide more details on how the contrastive loss is specifically implemented in conjunction with the GAN framework?', 'How sensitive is the method to the choice of hyperparameters?', 'Can you elaborate on the limitations of your approach in more detail?', 'How does your method handle datasets with a very large number of fine-grained classes?', 'What are the computational requirements for training C3-GAN compared to baseline methods?', 'Can the authors provide more insights into the choice and tuning of hyperparameters?', 'How does the method perform on datasets with different characteristics or in different domains?', 'Can the authors elaborate on the potential broader impact and applicability beyond fine-grained image clustering?', 'Can the authors provide more details on the setup and hyperparameters used for the experiments?', 'How does the method perform on datasets with a different number of classes or more complex datasets?', 'Can the authors discuss the potential negative societal impacts of the method in more depth?', 'Can the authors provide more insights on the reproducibility of their results?', 'How does the method perform on datasets with more complex scenes?', 'Can the authors elaborate on the potential societal impacts of their work, both positive and negative?']","['The reliance on the specific formulation of contrastive loss might limit adaptability.', 'Potential negative societal impacts related to the misuse of generative models.', 'The method might not scale well to very large datasets without human annotations.', 'The method may be sensitive to hyperparameter settings, which can affect reproducibility.', 'Potential scalability issues with datasets having a very large number of classes.', 'The performance gains over baseline methods need more rigorous validation.', 'The reliance on specific hyperparameters (e.g., number of clusters) which might limit the generalizability.', ""The method's applicability to domains beyond fine-grained image clustering is not demonstrated."", 'Potential negative societal impacts are not deeply discussed, especially related to the misuse of GANs.', 'The paper does not discuss the limitations of the method in detail.', 'Potential negative societal impacts are briefly mentioned but not thoroughly analyzed.', 'The method relies heavily on the effectiveness of GANs, which are known to have reproducibility issues.', 'The approach might not generalize well to datasets with more complex scenes or multiple objects.']",False,3,3,3,6,4,"['Combines InfoGAN with contrastive learning for improved clustering.', 'Demonstrates state-of-the-art performance on four fine-grained datasets.', 'Addresses the mode collapse issue in GANs.', 'Removes reliance on human-annotated labels.', 'Provides extensive experimental results across multiple datasets.', 'Code availability supports reproducibility.']","['Limited originality, heavily builds on existing methods.', 'Dense and sometimes unclear presentation.', 'Potential reproducibility issues due to under-explained methodologies.', 'Incremental contributions rather than fundamentally new ideas.', 'Mathematical formulations and hyperparameters need more detailed explanations.', 'Some claims about state-of-the-art performance need further validation.', 'The discussion on limitations is insufficient.', 'Potential ethical concerns are acknowledged but not deeply explored.']",3,3,3,4,Reject
Yr_1QZaRqmv,The paper proposes a decision tree algorithm for solving Markov Decision Processes (MDPs) with large state spaces. The algorithm incrementally disaggregates the state space using a tree-growing strategy and solves smaller MDP instances with Linear Programming. The approach aims to offer a computationally tractable and interpretable solution policy.,"['Can you provide more intuitive explanations or visualizations to make the methodology clearer?', 'How does the proposed method compare to state-of-the-art deep learning methods in terms of computational efficiency and performance?', 'Can you apply the method to more complex, real-world problems to better demonstrate its scalability and robustness?', 'Can the authors provide more empirical comparisons with state-of-the-art methods?', 'How does the method perform on a wider range of MDP problems beyond the provided examples?', 'Can the complexity analysis be simplified for broader accessibility?']","['The method may not scale well to very large state-action spaces.', 'The success of the method depends on the structure of the MDP, which may limit its applicability.', ""The method's performance is not well-established for a broader range of MDP problems."", 'The computational savings are theoretically claimed but not empirically validated.', 'The impact of the choice of hyperparameters, such as the number of partitions, is not discussed.', 'Potential negative societal impacts are not considered.', 'The method relies heavily on the assumption that the optimal policy can be represented as a decision tree, which may not hold for all MDPs.', 'The computational complexity, while potentially reduced, is still dependent on several factors that may not be controllable.', ""Lack of discussion on the method's performance in stochastic environments or with incomplete data.""]",False,2,2,2,3,4,"['Addresses the problem of interpretability in MDP solutions.', 'Proposes a method that could be computationally efficient for certain types of MDPs.', 'Includes theoretical analysis and numerical examples.']","['Limited originality; builds on existing concepts without introducing fundamentally novel methods.', 'Dense and difficult-to-follow presentation with a lack of intuitive explanations.', 'Weak experimental validation with simplistic examples.', 'Lack of comparison with state-of-the-art methods.', 'Insufficient discussion of limitations and potential negative societal impacts.', 'Theoretical claims on computational savings lack sufficient empirical backing.', 'Complexity analysis and optimality discussion are convoluted.', ""Limited evidence on the method's applicability to a broader range of problems.""]",2,2,2,3,Reject
XVPqLyNxSyh,"The paper introduces a general methodology for discovering spurious features in deep neural networks with minimal human supervision. The authors leverage the neurons of robust models as interpretable visual feature detectors to annotate neural features as core or spurious. The methodology is applied to the ImageNet dataset, resulting in the creation of the Salient Imagenet dataset, which includes annotations of core and spurious visual attributes.","['Can the authors provide more details on the scalability of the methodology to other datasets beyond ImageNet?', 'How would the framework handle non-spatial spurious signals which cannot be easily visualized with heatmaps?', 'What potential improvements and future directions do the authors envision for this line of research?', 'How does the methodology generalize to other datasets and models?', 'What measures were taken to ensure the reliability and consistency of Mechanical Turk annotations?', 'Can the authors provide more details on the potential biases introduced by the use of human annotations?', 'Have you considered evaluating the framework on additional models or datasets?', 'Can you expand on the potential negative impacts and ethical considerations of your work?', 'Have you explored the applicability of your methodology to other datasets or tasks beyond image classification?', 'How do you mitigate potential biases introduced by the Mechanical Turk workers in annotating core and spurious features?', 'Can the authors provide more details on how the robust model was trained?', 'How do the results compare with other methods for identifying spurious features?', 'What are the limitations of using Gaussian noise for corruption? Are there alternative methods?']","['Potential ineffectiveness for discovering non-spatial spurious signals', 'Limited discussion on scalability and generalizability', 'The reliance on Mechanical Turk annotations introduces potential biases and variability', ""The methodology's applicability to other datasets and models is not thoroughly validated"", 'The evaluation is limited to a few models, which may not generalize well to other architectures', 'The paper does not discuss potential negative societal impacts in sufficient detail', 'The reliance on existing techniques limits the originality of the methodology', 'Potential negative societal impacts, such as biases in the dataset annotations, are not thoroughly discussed']",False,2,2,2,5,4,"['Innovative approach to identifying spurious features with minimal human input', 'Extensive experimental validation and dataset creation', 'Clear and well-organized presentation', 'Significant contribution to the field with the creation of the Salient Imagenet dataset', 'Addresses a critical issue in deep learning regarding spurious features']","['Limited discussion on the scalability and generalizability of the approach', 'Potential ineffectiveness for non-spatial spurious signals', 'Relies heavily on Mechanical Turk annotations with insufficient quality control', 'Evaluation is limited to a few models; broader testing is needed', 'Minimal discussion on potential negative impacts and ethical considerations', 'Some sections lack clarity, especially the technical details', 'Methodology relies heavily on existing techniques and does not present significant novelty']",2,2,2,2,Reject
8la28hZOwug,"The paper proposes Prototypical Contrastive Predictive Coding (ProtoCPC), which integrates knowledge distillation and contrastive learning. The method is tested on tasks such as supervised model compression, self-supervised model compression, and self-supervised learning via self-distillation, and claims to outperform existing methods.","['Can the authors provide more details on the initialization and training process for the prototypes?', 'How does the method perform on tasks involving different domains or types of data?', 'Can the authors elaborate on the potential biases that might be introduced or exacerbated by the ProtoCPC method?', 'Can the authors provide a clearer, more concise explanation of the mathematical formulations?', 'How does ProtoCPC perform in tasks beyond the three distillation tasks mentioned?', 'What are the limitations of ProtoCPC, and how do they impact its applicability?', 'Can you provide more detailed hyperparameter settings for the experiments, especially for the ImageNet results?', 'How does the ProtoCPC method perform with different types of prototypes or different numbers of prototypes?', 'Can you clarify the implementation details of the Sinkhorn-Knopp operator used in the experiments?', 'What are the potential limitations of the ProtoCPC method in various real-world applications?', 'Can the authors provide more intuition behind the choice of the ProtoCPC objective?', 'How does the method perform on other datasets beyond CIFAR-100 and ImageNet?', 'What are the potential societal impacts of this work?', 'Can you provide more detailed mathematical proofs and explanations for the ProtoCPC objective?', 'How do you ensure the reproducibility of your results? Can you provide more details on the experimental setup and hyperparameters?', 'Have you considered additional baselines for comparison? How does your method perform compared to other recent state-of-the-art methods not included in your experiments?']","['The paper does not address the potential biases that might be perpetuated by the distilled models, which could have negative societal impacts.', 'The complexity of the approach may limit its practical applicability and reproducibility.', 'The paper does not discuss the computational complexity and scalability of the ProtoCPC method.', 'Potential negative societal impacts of using ProtoCPC in sensitive applications are not addressed.', 'The method relies on a substantial amount of labeled data for supervised tasks, which may not always be available.', 'The scalability of the method to larger datasets and models is not discussed.', 'The dependency on prototypical methods and contrastive learning might limit the applicability of the method to certain types of tasks and models.']",False,3,2,3,4,4,"['Novel combination of knowledge distillation and contrastive learning.', 'Extensive experimental validation on multiple benchmarks.', 'Claims of state-of-the-art performance in several distillation tasks.']","['Clarity issues in the presentation of the methodology.', 'Missing methodological details that could affect reproducibility.', 'Insufficient discussion on potential negative societal impacts and biases.', 'Complexity of the approach may pose challenges for practical implementation.', 'Incremental improvements over existing methods rather than groundbreaking advancements.']",3,3,2,3,Reject
okmZ6-zU6Lz,"The paper studies the controllability of large-scale networked dynamical systems with limited knowledge of the network structure. It proposes a learning-based framework to infer the controllability of fine networks from coarse measurements, introducing two approaches: a Model Order Reduction (MOR) approach and a learning-based approach using the stochastic block model (SBM). The paper derives theoretical bounds on the approximation error and provides experimental validation.","['Can the authors provide more details on the computational complexity of the proposed methods in large-scale networks?', 'How do the assumptions about the stochastic block model and synchronization affect the generalizability of the results?', 'Can the authors provide more practical applications or case studies to illustrate the real-world impact of their methods?', 'Can the authors provide more intuitive explanations for the key mathematical concepts?', 'How sensitive are the results to the assumptions, particularly the synchronization of coarse nodes with community structure?', 'Are there practical examples where the proposed framework has been or could be applied?', 'Could you provide more details on the practical implementation of your methods, especially in real-world scenarios like brain networks?', 'How do the assumptions made in your theoretical analysis affect the generalizability of your results to different types of networks?', 'Can the authors provide more detailed comparisons between the proposed methods and existing approaches in terms of practical applications?', 'How do the proposed methods perform on real-world networks, and what are the potential challenges in applying these methods in practice?', 'Can the authors elaborate on the ethical concerns mentioned in the paper and suggest potential mitigations?']","['The assumptions about the SBM and synchronization may limit the applicability of the results to other types of networks.', 'The paper does not discuss the computational complexity of the proposed methods, which is important for large-scale applications.', 'The complexity of the methods may limit practical applicability.', 'The assumptions required for the theoretical results are quite strong.', 'Potential negative societal impacts are mentioned but could be more detailed.', 'The paper acknowledges the assumption that the fine-scale network is generated by a stochastic block model, which may not always hold in real-world scenarios.', 'The paper mentions potential negative societal impacts if the methods are misapplied, such as manipulating influential groups in social networks.']",True,3,2,3,4,4,"['Addresses a relevant and challenging problem in network controllability with practical implications.', 'Presents a novel framework and derives theoretical bounds on the approximation error.', 'Proposes a learning-based approach that shows potential advantages over traditional MOR methods.', 'Includes comprehensive related work and thorough experimental validation.']","[""The paper's clarity could be improved, especially in the mathematical derivations and explanations."", 'The assumptions made (e.g., SBM, synchronization) may limit the generalizability of the results.', 'Could provide more practical applications or case studies to illustrate the real-world impact.', 'The computational complexity of the proposed methods in large-scale networks is not discussed in detail.', 'Potential societal impacts are mentioned but not deeply explored.']",3,3,3,3,Reject
DrZXuTGg2A-,"The paper introduces interactive shuffle protocols for stochastic convex optimization (SCO) under shuffle privacy. It proposes a new noninteractive protocol for summing vectors with bounded L2 norm and combines it with methods like mini-batch stochastic gradient descent, accelerated gradient descent, and Nesterov’s smoothing method to achieve improved loss guarantees for various convex loss functions. The contributions include theoretical improvements over local and central models of differential privacy.","['Can the authors provide more extensive empirical validation and comparisons with state-of-the-art methods?', 'Can the clarity of the mathematical derivations and algorithm descriptions be improved?', 'What are the practical implications and feasibility of the proposed methods in real-world settings?', 'How scalable are the proposed protocols in real-world scenarios with large datasets?', 'Can the authors improve the clarity of the presentation, especially in structuring the results and proofs?', 'How feasible is the assumption of a trusted shuffler in real-world scenarios? Are there alternative approaches that relax this assumption?', 'Can you provide examples of real-world applications where these protocols could be beneficial?', 'Do you have any experimental results to validate the theoretical guarantees presented?', 'Could the authors provide empirical validation or experiments to demonstrate the practical efficacy of the proposed methods?', 'Can the complexity of the protocols be reduced or explained in a more accessible manner?']","['The empirical validation is limited, and more extensive experiments are needed to substantiate the claims.', 'The practical feasibility of the proposed methods, especially in real-world settings, is not thoroughly discussed.', 'The clarity of the exposition, particularly in the mathematical derivations and algorithm descriptions, could be improved.', 'The paper assumes a trusted shuffler, which may not always be practical.', 'Theoretical results are strong, but practical applicability is limited.', 'The paper does not discuss the computational overhead in real-world settings.']",False,3,3,3,5,4,"['Novel approach to handling SCO under shuffle privacy.', 'Combination of multiple established techniques to achieve improved loss guarantees.', 'Theoretical contributions that advance the understanding of differential privacy in the shuffle model.', 'Robust theoretical guarantees for privacy and utility.', 'Detailed analysis and proofs.']","['Limited empirical validation and comparison with state-of-the-art methods.', 'Clarity of exposition could be improved, especially in mathematical derivations and algorithm descriptions.', 'Practical feasibility and real-world implications of the proposed methods are not thoroughly discussed.', 'The protocols are complex and might be difficult for readers to follow.', 'Dense theoretical sections that could benefit from additional explanations or simplifications.']",4,3,3,4,Reject
EMxu-dzvJk,"The paper proposes GRAND++, a graph neural network model that introduces a source term into the diffusion process to mitigate over-smoothing and improve performance with limited labeled data. The model is theoretically grounded and shows significant performance improvements over existing GNN architectures in various benchmark datasets.","['Can the authors provide more intuitive explanations or visualizations for the mathematical derivations, especially for readers who may not be experts in graph theory?', 'Have the authors considered potential applications or domains where GRAND++ might be particularly beneficial?', 'What are the computational costs associated with GRAND++ compared to other GNN models, especially in terms of training time and memory usage?', 'Can you provide more details on the choice of datasets and hyperparameters used in the experiments?', 'How does GRAND++ compare with other recent state-of-the-art models that address over-smoothing and low-labeling rates?', 'Can you clarify the theoretical analysis further, particularly the random walk interpretation?', 'Can the authors provide more intuitive explanations for some of the more dense theoretical sections?', 'How does GRAND++ compare with other recent methods not mentioned in the paper?', 'Can additional details be provided about the experimental setup, specifically hyperparameters and training conditions?', 'Can the authors provide ablation studies to isolate the impact of the source term?']","['The paper does not address potential negative societal impacts of the proposed method.', 'The computational complexity and resource requirements of the model could be discussed in more detail.', 'Potential limitations in scalability for very large graphs should be addressed.', 'The impact of the source term on different types of graphs and tasks could be further explored.']",False,3,3,4,6,4,"['Novel approach to address over-smoothing in GNNs by introducing a source term.', 'Strong theoretical foundation and connection to random walk interpretations.', 'Comprehensive experimental validation across multiple datasets and baselines.', 'Significant improvements in performance for deep architectures and low-labeling rate scenarios.']","['The mathematical derivations are complex and could benefit from clearer explanations and more intuitive descriptions.', 'The novelty is incremental, building on existing work on graph diffusion processes.', 'Limited discussion on potential negative societal impacts and ethical considerations.', 'Empirical evaluation lacks detail in terms of datasets and hyperparameters.', 'Insufficient comparison with other recent state-of-the-art models tackling similar issues.', 'Some sections are dense and could benefit from clearer explanations.', 'The notation is complex and may be difficult for some readers to follow.', 'Additional comparisons with more recent work could strengthen the paper.', 'Experimental results could benefit from additional context and clarity.', 'Reproducibility of the results could be enhanced with more details on hyperparameters and experimental settings.']",3,3,3,4,Accept
DIjCrlsu6Z,"The paper proposes a method to identify and control directions orthogonal to a classifier, aiming to use these directions in tasks such as style transfer, domain adaptation, and fairness. The authors define orthogonality in the nonlinear case and introduce a method to construct orthogonal classifiers. They demonstrate the utility of their method through empirical evaluations.","['Can the authors provide more insights into the practical scenarios where the assumption of orthogonal random variables might fail?', 'How sensitive are the empirical results to the choice of datasets and settings? Could the authors provide broader validation?', 'Can the authors clarify the potential limitations and negative societal impacts of their proposed method?', 'Can the authors provide more detailed comparisons with state-of-the-art methods in the empirical evaluations?', 'How do the proposed metrics comprehensively capture the improvements claimed in the paper?', 'Can the authors clarify the construction and training of the orthogonal classifier in the non-linear case?', 'Can the theoretical formulation be simplified for better understanding?', 'How does the method perform across a broader range of datasets and configurations?', 'Can more baselines be included for a comprehensive empirical comparison?']","['The assumption of orthogonal random variables may not hold in all practical scenarios.', 'The empirical validation is limited to specific datasets and settings.', 'The potential negative societal impacts are not thoroughly discussed.', 'The method presumes the availability of a well-performing full classifier, which might not always be feasible.', ""Potential simplicity bias in learning the full classifier, which could affect the orthogonal classifier's performance."", 'The reliance on diffeomorphisms may limit practical applicability.', ""The method's effectiveness heavily depends on the robustness of the full classifier."", 'Empirical results show variance which needs deeper analysis.']",False,3,2,3,5,4,"['The paper tackles a novel and relevant problem of controlling orthogonal directions to a classifier.', 'The proposed method is simple and elegant, leveraging existing classifiers to construct orthogonal ones.', ""Empirical evaluations demonstrate the method's applicability in diverse tasks like style transfer, domain adaptation, and fairness."", 'Theoretical foundations are provided, including proofs and generalization bounds.']","[""The assumption that orthogonal random variables exist may not hold in all practical scenarios, which could limit the method's applicability."", 'The empirical results, while promising, are limited to specific datasets and settings. Broader validation is necessary.', 'Some sections, particularly on the theoretical aspects, are dense and may lack clarity for a broader audience.', 'The paper does not thoroughly discuss the potential limitations and negative societal impacts of the proposed method.', 'Theoretical contributions are somewhat incremental.', 'Evaluation metrics used are not comprehensive enough.']",3,3,2,3,Reject
89W18gW0-6o,"The paper proposes FOCAL++, an improvement over FOCAL for context-based offline meta-reinforcement learning (COMRL). It incorporates intra-task attention mechanisms and inter-task contrastive learning to enhance task representation learning. Theoretical analysis and empirical evaluations demonstrate the superior performance and robustness of FOCAL++ across multiple benchmarks.","['How sensitive is the performance of FOCAL++ to the choice of hyperparameters, especially the temperature (τ) and momentum (m) in the contrastive learning framework?', 'Can the authors provide more insights into the computational overhead introduced by the attention mechanisms and contrastive learning compared to FOCAL?', 'Can the authors provide more intuitive explanations for some of the theoretical results?', 'How do the proposed methods perform in real-world scenarios beyond the provided benchmarks?', 'Are there any specific limitations or failure cases observed during the experiments?', 'Can the authors provide more intuitive examples or illustrations to explain the intra-task attention and inter-task contrastive learning mechanisms?', 'How would the proposed method perform on a wider variety of benchmarks beyond the ones tested?', 'Are there any limitations or potential drawbacks of FOCAL++ that were not addressed in the paper?', 'How sensitive is the model to the choice of hyperparameters?', 'Can the authors provide a more detailed discussion on the scalability of FOCAL++?', 'How does FOCAL++ perform in other types of RL environments beyond the ones tested?', 'Can the authors provide more detailed hyperparameter settings to improve reproducibility?', 'Could the theoretical analysis be simplified or clarified further to aid understanding?', 'What are the primary differences and improvements of FOCAL++ over FOCAL in terms of implementation and performance?']","['The paper primarily focuses on synthetic benchmarks, and it is unclear how well the proposed methods would generalize to real-world applications.', 'The approach requires tuning several hyperparameters, which might be challenging in practice.', 'Potential challenges in scaling the proposed methods to larger and more diverse task distributions.', 'The paper could better address the potential negative societal impacts of the proposed method, particularly in high-stakes applications like healthcare and autonomous driving.', 'The complexity of the experimental setup might limit reproducibility.', 'Potentially high computational resources required for training and evaluation.']",False,3,3,3,8,4,"['Addresses a significant problem in COMRL with practical implications.', 'Proposes well-motivated and theoretically grounded methods.', 'Demonstrates clear improvements in performance and robustness.', 'Includes thorough analyses and ablation studies to justify the design choices.', 'Novel combination of attention mechanisms and contrastive learning in the COMRL context.', 'Comprehensive theoretical analyses supporting the proposed improvements.', 'Empirical evaluations demonstrate significant performance gains across multiple benchmarks.']","['Theoretical contributions might be dense for readers not well-versed in the field.', 'Some parts could benefit from clearer explanations and more intuitive descriptions.', 'Empirical evaluation relies heavily on synthetic benchmarks, which might not fully capture real-world challenges.', 'Adds significant complexity to the architecture, which might hinder reproducibility and scalability.', 'Highly specialized and may not be easily generalizable to other RL settings.', 'Dense and complex writing, making it difficult to fully grasp the methods and implications.']",4,4,3,3,Accept
Z0XiFAb_WDr,"The paper introduces the Language-complete Abstraction and Reasoning Corpus (LARC), a dataset of natural language instructions for solving ARC tasks. It aims to study human cognitive processes and improve AI's ability to generalize to novel situations by leveraging natural language. The paper provides a detailed linguistic analysis, compares natural programs to computer programs, and evaluates current program synthesis techniques on LARC.","['Can the authors provide more details on the implementation of the bandit algorithm and its specific role in data collection?', 'How do the authors plan to address the scalability issue of human-generated data in future work?', 'Are there any plans to incorporate more advanced models, such as transformers, to improve the performance on LARC tasks?', 'How do the authors plan to address the low success rates of the program synthesis models?', 'What measures are in place to ensure the ethical use of the LARC dataset and the cognitive processes it aims to model?', 'Can the authors provide more details on how they ensured the quality and consistency of the natural language instructions in LARC?', 'What steps can be taken to improve the reproducibility of the results, given the complexity of the models and dataset?', 'How do the authors plan to address the ethical concerns related to the use of natural language in critical applications?']","['The paper does not fully address the scalability of using human-generated data for training models.', 'The performance of current models on LARC tasks is still significantly lower than desired, indicating that more robust solutions are needed.', 'Potential negative societal impacts, such as the ethical implications of reverse-engineering human cognitive processes, are not fully discussed.', 'Potential negative societal impact includes misuse of natural language instructions in critical applications. Authors should provide guidelines or frameworks to mitigate such risks.']",True,2,2,3,4,4,"['Introduction of LARC, a novel dataset that augments ARC with natural language instructions.', 'Detailed linguistic analysis of natural programs and comparison with computer programs.', 'Identification of key challenges in using program synthesis techniques for natural language instructions.', 'Concrete suggestions for improving program synthesis techniques.']","['Limited success of the proposed models in solving LARC tasks.', 'Lack of clarity in some methodological details, especially regarding the bandit algorithm and its application.', 'Potential over-reliance on human-generated data, which may not scale well.', 'The complexity of the proposed methods and the dense presentation make it difficult to follow.', 'Potential ethical concerns about the use of human cognitive processes for AI development are not fully addressed.']",3,3,2,3,Reject
PilZY3omXV2,"The paper introduces CoST, a contrastive learning framework for disentangling seasonal and trend representations in time series forecasting. The approach leverages both time-domain and frequency-domain contrastive losses to learn these representations. The authors provide a causal perspective to justify their approach and perform extensive experiments demonstrating significant improvements over state-of-the-art methods. The framework is shown to be robust across various backbone encoders and downstream regressors.","['Can the authors provide more theoretical justification for the disentanglement approach?', 'How does the performance vary with different hyperparameters for the contrastive loss functions?', 'Can the authors elaborate on potential limitations and negative societal impacts of their approach?', 'How does the computational complexity of CoST compare with other state-of-the-art methods, especially for very large datasets?', 'Can the methodology description be expanded, particularly around the construction and application of the contrastive loss functions?', 'Can the authors provide more detailed explanations on the computational overhead introduced by the contrastive losses?', 'How does the choice of different data augmentations affect the performance of CoST?', 'Could the authors discuss potential limitations and future work in more detail?']","['The approach may not generalize well to all types of time series data.', 'The complexity of the method could hinder practical adoption without significant computational resources.', 'Potential biases in the training data could affect the learned representations.', 'The paper does not fully address the computational overhead introduced by the additional components.', 'More diverse datasets could be included to further validate the robustness of the approach.']",False,3,3,3,7,4,"['Novel combination of disentanglement and contrastive learning for time series forecasting.', 'Extensive experimental validation showing significant improvements over state-of-the-art methods.', 'Robustness across various backbone encoders and downstream regressors.', 'Thorough ablation studies and sensitivity analyses.', 'Open-sourced code to facilitate reproducibility.']","['Theoretical justification for the proposed approach could be stronger.', 'Some technical details are complex and could benefit from clearer explanations.', 'Computational complexity and scalability are not thoroughly discussed.', 'Potential limitations and negative societal impacts are not adequately addressed.', 'Figures and tables are densely packed, affecting readability.']",4,3,3,4,Accept
lkQ7meEa-qv,"The paper introduces Neural Acoustic Fields (NAFs), a neural implicit representation designed to model the acoustic properties of a scene. By capturing the impulse response function between emitter and listener locations, NAFs aim to predict sound propagation in novel locations. The paper demonstrates applications in cross-modal generation and sound source localization using this framework.","['Can the authors provide more details on why NAFs outperform the baselines theoretically?', 'Have the authors tested the model on more diverse and larger datasets to ensure generalization?', 'Can the authors elaborate on the potential ethical and societal impacts of their work?', 'Can the authors provide more clarity on the methodology, particularly the use of Fourier transform and local geometric features?', 'How does the proposed NAF method compare quantitatively with other state-of-the-art methods in terms of accuracy and computational efficiency?', 'Can the authors provide more details on the training and validation process, especially regarding hyperparameter selection and dataset splits?', 'What are the potential limitations of NAFs in terms of scalability to larger and more complex scenes?', 'Can you provide more justification for the choice of Fourier domain representation and handling phase information?', 'Have you considered comparing NAFs with more diverse baselines from existing audio modeling techniques?', 'How well do NAFs generalize to other datasets and scenarios not covered in this paper?', 'Can the authors elaborate on the computational requirements and scalability of the proposed method?', 'How does the method perform in real-world scenarios compared to synthetic setups?', 'Are there any human-centric evaluation metrics considered?']","['Potential overfitting to specific scenes used in training.', 'Lack of detailed theoretical grounding for the performance.', 'Insufficient discussion on the broader impacts and ethical considerations.', 'The paper does not adequately address potential negative societal impacts.', 'The clarity of the methodology section needs improvement for better reproducibility.', 'The paper does not discuss the computational complexity and scalability of the proposed model in detail.', 'The potential societal impacts of this technology, such as privacy concerns related to audio data, are not addressed.']",False,3,3,3,6,4,"['Novel approach in modeling acoustics using neural implicit representations.', 'Comprehensive experiments and comparisons with baselines.', 'Potential significant impact on AR/VR, gaming, and audio-visual learning.', 'Detailed methodology for capturing and using local geometric features to improve generalization.']","['Lack of detailed theoretical explanation for the performance.', 'Potential overfitting and generalization issues due to limited training scenes.', 'Insufficient discussion on ethical and societal impacts.', 'Clarity issues in some sections, making it difficult to follow.']",3,3,3,3,Reject
kj0_45Y4r9i,"The paper presents Clustering by Discriminative Similarity (CDS), a novel method for data clustering that learns an unsupervised similarity-based classifier by minimizing the generalization error bound of classifiers associated with data partitions. The theoretical foundation is built on Rademacher complexity, and the method is empirically validated on multiple datasets.","['Can the authors provide more details on the scalability of the proposed method for very large datasets?', 'How does the proposed method compare with more recent state-of-the-art clustering methods?', 'Can the authors clarify the assumptions made in the theoretical analysis?', 'Can the authors provide more intuitive explanations or visual aids to help understand the theoretical derivations?', 'Are there any specific scenarios or types of data where CDSK might not perform well?', 'How sensitive is the CDSK algorithm to the choice of kernel and hyperparameters?', 'Can the authors provide more details on the hyperparameter tuning process?', 'How does the method perform in terms of computational efficiency compared to the baselines?', 'What are the practical implications and limitations of the proposed method in real-world scenarios?', 'Can the authors provide more details on the practical implementation of Algorithm 1?', 'How does the proposed method compare to state-of-the-art techniques in terms of computational efficiency?', 'Can the authors clarify the parameter tuning process, particularly for the regularization parameter λ?', 'Can the authors clarify some of the more technical aspects, particularly the derivation of the generalization error bound?']","['The method may have scalability issues due to its complexity.', 'The paper does not provide a detailed comparison with more recent state-of-the-art clustering methods.', 'The explanation of theoretical concepts and experimental results could be clearer.', 'The paper does not sufficiently address the complexity of the proposed method and its implications for practical applications.', 'Potential negative societal impacts are not discussed.', 'The method’s computational efficiency is not thoroughly evaluated.', ""The paper's technical density may limit its accessibility to a broader audience.""]",False,3,2,3,6,4,"['Novel approach to clustering using discriminative similarity.', 'Thorough theoretical analysis using Rademacher complexity.', 'Promising experimental results demonstrating the effectiveness of the proposed method.']","['Complexity of the method and potential scalability issues.', 'Lack of detailed comparison with more recent state-of-the-art methods.', 'Clarity of the paper could be improved, especially in the explanation of theoretical concepts and experimental results.', 'Limited discussion on the computational complexity and scalability of the proposed method.', 'Insufficient discussion of potential limitations and negative societal impacts.']",3,3,2,3,Reject
-3yxxvDis3L,The paper addresses improving the sample complexity of Stochastic Gradient Descent (SGD) over highly dependent data using periodic data subsampling and mini-batch SGD. It provides theoretical analysis and some numerical experiments to validate the proposed methods.,"['Can you provide more comprehensive experiments on real-world datasets to validate the theoretical findings?', 'Could you clarify the notation in Section 3.2, specifically the transition from equation (4) to the subsequent theoretical results?', 'How do the proposed methods compare to other existing methods for handling dependent data in terms of computational efficiency?', 'How sensitive are the results to deviations from the φ-mixing assumption?', 'Can the proposed methods be generalized to other types of data dependencies?', 'What are the practical challenges in implementing the proposed methods in real-world applications?']","['Theoretical results depend heavily on the assumptions made about data dependence, which may not hold in all practical scenarios.', 'The empirical validation is limited to synthetic data; real-world applicability is uncertain.', 'Scalability to large datasets or more complex models is not addressed.', 'Potential negative societal impact is not discussed.']",False,3,2,2,4,4,"['Addresses a significant problem in practical machine learning applications where data independence is not guaranteed.', 'Provides a thorough theoretical analysis of the proposed methods.', 'Validates the theoretical findings with numerical experiments.']","['The originality is moderate as the methods are extensions of existing techniques.', 'The clarity of the paper needs improvement; the dense notations and explanations could hinder understanding.', 'The experimental validation is limited to synthetic data, lacking real-world scenarios.', 'Ethical considerations and limitations are not adequately discussed.', 'The practicality of the proposed methods in real-world scenarios is not sufficiently discussed.']",2,3,2,3,Reject
BkIV7EOXkSs,The paper investigates the implicit regularization properties of the Bregman Proximal Point Algorithm (BPPA) and Mirror Descent (MD) for classification tasks with linearly separable data. It provides theoretical results showing non-trivial margin bounds that depend on the condition number of the distance-generating function and demonstrates convergence to the maximal margin solution in Mahalanobis distance. The paper also includes some experimental results on synthetic data and practical neural network training tasks.,"['Can the authors provide more intuitive explanations or visualizations to help understand the theoretical results?', 'Are there plans to extend the theoretical analysis and experimental validation to nonlinear models and more complex datasets?', 'How do the authors address the potential societal impacts of their work?']","['The paper primarily focuses on linear models and synthetic data, limiting the generalizability of the results.', 'The clarity of the writing could be improved to make the paper more accessible to a broader audience.', 'The potential negative societal impacts of the work are not discussed.', 'The experimental section could be expanded to include more diverse datasets and models to validate the theoretical findings.']",False,3,2,3,5,4,"['Novel theoretical contributions and rigorous analysis of BPPA and MD.', 'Extension of findings to practical applications and neural networks.', 'Establishing connections between margin properties and the condition number of the distance-generating function.']","['Dense and complex notations that make the paper difficult to follow.', 'Limited empirical validation and scope of experiments.', 'Insufficient discussion on limitations and potential societal impacts.']",3,3,2,3,Reject
yhCp5RcZD7,"The paper presents a novel method for 3D geometry representation using implicit displacement fields. The method extends traditional displacement mapping to a continuous implicit setting, enabling a frequency-based decomposition of the shape. The approach shows promising results in terms of detail representation and stability, and it is demonstrated for applications in surface reconstruction and detail transfer.","['Can you provide more details on the network architecture and the training process?', 'How does your method perform on more diverse datasets, especially those with different types and levels of detail?', 'What are the potential failure cases of your method, and how do you plan to address them in future work?', 'Can you discuss the computational cost of your method in comparison to state-of-the-art approaches?', 'Can you provide more empirical validations for the theoretical claims, particularly in diverse and challenging scenarios?', 'How does the method perform on real-world 3D scans compared to synthetic datasets?', 'Can the approach be extended to handle unaligned shapes for detail transfer?', 'What are the computational requirements for training and inference in practical scenarios?']","['The paper does not sufficiently address the potential negative societal impact of its use in generating detailed 3D models, which could be used inappropriately.', 'The scalability of the method to very large datasets and its computational efficiency are not thoroughly explored.', ""Possible failure cases, such as the method's performance on highly complex or noisy data, are not discussed."", 'The necessity of pre-alignment in detail transfer tasks.', 'Potential overfitting in sparse and noisy data scenarios.']",False,3,3,3,4,4,"['Novel and theoretically grounded extension of displacement mapping to implicit functions.', 'Demonstrates significant improvements in representing geometric details compared to state-of-the-art methods.', 'Proposes a new neural architecture with a frequency hierarchy that improves training stability and representational power.', 'The method shows potential for detail transfer applications.']","['The methodology and network architecture are not always clearly explained, which may hinder reproducibility.', 'The experimental evaluation, while extensive, could benefit from more diverse benchmarks and a deeper exploration of potential failure cases.', 'The paper does not sufficiently discuss the limitations and potential negative societal impacts of the proposed method.', 'The scalability and computational cost of the method, particularly in comparison to competing approaches, are not thoroughly addressed.']",4,3,3,3,Reject
AkJyAE46GA,"The paper investigates whether pretrained models enhance active learning by selecting more informative examples that resolve task ambiguity. It demonstrates that finetuning pretrained models with data acquired through uncertainty sampling achieves higher accuracy with fewer labels across various datasets compared to random sampling. The study spans multiple datasets, including those with spurious correlations, latent minority groups, and domain shifts, showing significant performance improvements.","['Can the authors provide more insights into the computational costs associated with using pretrained models for active learning?', 'How do the results generalize to domains significantly different from the pretraining dataset?', 'Can the authors discuss the potential societal impacts of their approach, particularly concerning underrepresented groups?', 'Can the authors provide more details on the choice of baselines and why certain methods were not included?', 'What are the limitations of the proposed early stopping criterion without a validation set?', 'Can the authors provide more details on the experimental setup and the specific metrics used for evaluation?', 'How do the authors address the potential limitations and negative societal impacts of their work?', 'Can the authors discuss the generalizability of their findings to other types of models and datasets?', 'What are the computational costs and practical feasibility of implementing the proposed approach in real-world settings?', 'Can the authors provide more theoretical justification for why pretrained models exhibit better active learning capabilities?', 'How generalizable is the proposed early stopping heuristic across different types of tasks and models?', 'Could the authors clarify the specific configurations and hyperparameters used in the experiments to ensure reproducibility?', 'How does the performance vary with different levels of label noise in the training data?', 'What are the specific challenges when applying this approach to datasets far from the pretraining distribution, and how might these be addressed?']","['The paper does not sufficiently explore the computational costs and domain generalization limitations.', 'A more thorough discussion on the societal impacts of using pretrained models for active learning is needed.', 'The need for a human in the loop for data acquisition, which increases training time.', 'The method requires relatively noise-free labeling, which might not be feasible in all scenarios.', 'The reliance on pretrained models assumes access to large-scale pretraining data, which may not be feasible for all applications.']",False,3,3,3,6,4,"['Addresses a relevant and practical problem in ML, task ambiguity.', 'Presents a novel perspective on how pretraining impacts active learning.', 'Comprehensive experimental results showing significant performance improvements.', 'Clear and reproducible methodology.', 'Proposes a practical heuristic for early stopping in the absence of a validation set.']","['Insufficient exploration of limitations, particularly computational costs and domain generalization.', 'Lacks discussion on societal impacts, particularly underrepresented groups.', 'Assumes high familiarity with datasets and methods, limiting accessibility.', 'The novelty is somewhat incremental as the use of pretrained models in active learning is known.', 'Some methodological details are unclear, particularly around the baselines used.', 'Dense presentation that may be hard to follow for readers without prior knowledge.', 'Limited discussion on the generalizability of the findings to other types of models and datasets.', 'The paper does not provide a detailed analysis of the computational cost and practical feasibility of the proposed approach in real-world settings.']",3,3,3,3,Reject
mfwdY3U_9ea,"The paper introduces IGEOOD, an OOD detection method based on information geometry, specifically using the Fisher-Rao distance. The method is designed to work with any pre-trained neural network and can adapt to different levels of access to the ML model. Empirical results show that IGEOOD outperforms or is competitive with state-of-the-art methods across various datasets and network architectures.","['Can the authors provide more details on the hyperparameter settings for the experiments?', 'How does IGEOOD perform on other types of data, such as textual data, given that the experiments are focused on image data?', 'Is there any ablation study to show the contribution of each component of IGEOOD?', 'Can the authors provide more theoretical insights or proofs to support the empirical results?', 'How does IGEOOD perform under different hyperparameter settings, and is there a risk of overfitting?', 'Can the authors simplify the presentation and organization of the paper to improve readability?', 'Can the authors discuss the potential negative societal impacts of their work?', 'How does IGEOOD scale with very large models or datasets?', 'Can the authors provide more diverse datasets or additional baselines to further substantiate their claims?']","['The method assumes a Gaussian distribution for the latent features, which might not hold for all types of data.', 'The approach may be computationally intensive due to the calculation of Fisher-Rao distances, especially for large datasets.', ""The method's complexity might make it less accessible and harder to reproduce."", 'Potential overfitting due to multiple hyperparameters and validation datasets.', 'The complexity of the method may hinder its adoption.', 'Marginal improvements in some scenarios suggest the need for further validation or optimization.', 'The impact of hyperparameter sensitivity on performance is not fully explored.']",False,3,2,3,6,4,"['Innovative use of Fisher-Rao distance for OOD detection.', 'Versatility in different experimental setups: BLACK-BOX, GREY-BOX, and WHITE-BOX.', 'Empirical results show competitive performance with state-of-the-art methods.', 'Comprehensive theoretical foundation and empirical evaluation.']","['The clarity of the paper can be improved; some sections are difficult to follow.', 'Limited comparisons with more recent state-of-the-art methods.', 'Reproducibility could be an issue due to the complexity of the method and the lack of detailed hyperparameter settings.', 'Dense presentation and heavy use of mathematical notation.', 'Potential negative societal impacts are not deeply addressed.']",4,3,2,3,Reject
6hTObFz_nB,"The paper proposes a novel approach to safety-aware reinforcement learning called latent shielding. This method uses learned internal representations to predict and avoid unsafe trajectories, eliminating the need for handcrafted models of environmental dynamics. The paper introduces a Safety Recurrent State-Space Model (SRSSM) and a training regime for integrating latent shielding with reinforcement learning agents. The approach is demonstrated through experiments showing improved adherence to safety specifications and comparable performance to previous approaches.","['Can the authors provide more detailed explanations of the experimental setup and parameters?', 'How does the approach generalize to more complex and diverse environments?', 'What are the computational costs associated with the latent shielding method?', 'Can the authors provide more theoretical analysis to support the claims?', 'Have the authors considered testing the approach in more diverse or real-world environments?', 'Can the authors provide clearer explanations or additional diagrams for the technical sections?', 'How robust is the proposed method when applied to more complex real-world environments?', 'Can the authors elaborate on potential limitations and failure cases of the latent shielding approach?', 'Can the authors provide more details on how the shield introduction schedule was empirically chosen?', 'What steps can be taken to regain some formal safety guarantees?', 'How does the method perform in more diverse and complex environments?', 'Can the authors provide more details on mitigating the lack of formal safety guarantees?', 'What are the computational overheads introduced by latent shielding compared to traditional methods?']","['The paper does not adequately address the limitations of the latent shielding method in highly complex or non-stationary environments.', 'Potential negative societal impacts are not discussed in detail.', 'The loss of formal safety guarantees is a significant limitation.', 'The evaluation is limited to two environments, which may not be sufficient to generalize the findings.', 'The shield introduction schedule lacks rigorous theoretical support.', 'Potential negative societal impacts include the incorrect application of the method in critical real-world scenarios without formal guarantees.']",False,3,2,3,5,4,"['Novel approach to safety in reinforcement learning using latent dynamics.', 'Addresses the challenge of environments without pre-defined dynamics models.', 'Empirical results show some improvement in safety and performance.', 'Integration with existing model-based RL frameworks like Dreamer.']","['Clarity issues: The paper is dense and difficult to follow in places.', 'Limited scope of experiments: More diverse and complex environments are needed to validate the approach.', 'Incremental improvements: The method shows only modest improvements over existing techniques.', 'Reproducibility concerns: Key details and parameters are not always clearly explained.', 'Lacks thorough theoretical analysis.', 'Loss of formal safety guarantees compared to traditional methods.', 'Potential overfitting to the selected benchmark environments.']",3,3,2,3,Reject
0d1mLPC2q2,"The paper investigates the interplay between Knowledge Distillation (KD) and Data Augmentation (DA) and introduces new methods (TLmixup, TLCutMix, and TLCutMix+pick) to enhance KD performance. The authors present a framework to explain this interplay and validate their findings through extensive experiments on CIFAR-100, Tiny ImageNet, and ImageNet datasets. The proposed methods achieve state-of-the-art accuracy by using stronger augmentation schemes.","['Can the authors provide more details on the computational cost and feasibility of the proposed methods for large-scale applications?', 'How do the proposed methods generalize to other neural network architectures not tested in the paper?', 'Can the authors clarify the rationale behind the specific choices of DA techniques and their parameters?', 'How does the method perform on other large-scale datasets beyond ImageNet?', 'Are there any specific scenarios or types of data where the proposed methods might not be effective?', 'Could the authors elaborate on the potential societal impacts of their work?', 'How do the authors plan to address the limitations of their proposed methods in future work?', 'The paper mentions that TLCutMix+pick does not perform as well on ImageNet. Can the authors provide more insights into why this might be the case?', 'Can the authors provide more detailed explanations on the choice of hyperparameters for the proposed DA methods?', 'How do the results vary with different teacher-student architectures beyond those tested?', 'Can the authors elaborate on the potential limitations of their proposed methods?', 'Can the authors provide a more concise summary of their experimental results?', 'How does the performance of the proposed methods vary with different hyperparameter settings?']","['The potential for overfitting due to extensive training iterations needs to be addressed.', 'The paper should discuss the broader applicability of the proposed methods to other neural network architectures and tasks.', 'Consideration of the computational cost for the proposed methods in practical applications.', 'The paper does not thoroughly discuss the computational overhead introduced by the proposed DA schemes, which could be significant.', 'The effectiveness of the proposed methods on larger datasets and in real-world applications remains to be fully validated.', 'Potential negative societal impacts of the proposed methods are not discussed.', 'The proposed methods are incremental improvements over existing techniques.', 'The paper does not address potential negative societal impacts or ethical considerations.', 'TLCutMix+pick does not perform as well on larger datasets such as ImageNet.', 'The paper does not fully explore the impact of hyperparameter choices on the performance of the proposed DA methods.', 'The experiments are primarily focused on specific teacher-student pairs, and additional experiments could be conducted to validate the findings across a wider range of architectures.', 'The potential limitations and negative societal impacts of using stronger DA methods in KD are not discussed in depth.', 'The clarity of the presentation is lacking, which might hinder reproducibility.']",False,3,3,3,6,4,"['Novel insights into the interplay between KD and DA.', 'Introduction of new DA techniques tailored for KD (TLmixup and TLCutMix).', 'Extensive experiments on multiple datasets demonstrating the effectiveness of the proposed methods.', 'Achieves state-of-the-art performance using the original KD loss with the proposed DA techniques.', 'Potential to inspire more powerful KD algorithms.']","['Some sections, particularly the mathematical formulations, could be clearer.', 'Potential over-reliance on extensive training iterations, which might not be practical for all applications.', 'Limited discussion on the generalizability of the proposed methods to other types of neural network architectures beyond those tested.', 'The presentation of the paper is somewhat cluttered and can be made more concise.', 'Some tables and figures are not well formatted and can be confusing to the reader.', 'The paper could benefit from a more thorough discussion of potential limitations and negative societal impacts.', 'The results on ImageNet are less convincing compared to CIFAR-100 and Tiny ImageNet, indicating potential limitations on larger datasets.']",4,3,3,4,Accept
e-IkMkna5uJ,"The paper explores the concept of spectral bias in neural networks, particularly focusing on image classification tasks. It introduces two methodologies for measuring spectral bias: label smoothing extended to multi-class classification and a linear interpolation method between test examples. The paper investigates how different factors such as model size, regularization, and data augmentation affect the frequency characteristics of the learned functions, providing extensive experimental evidence from CIFAR-10.","['Can the authors provide more details on the computational cost of their proposed methodologies?', 'How sensitive are the results to the choice of hyperparameters in the experiments?', 'Can the authors elaborate on the theoretical implications of their findings?', 'How generalizable are the findings to other datasets beyond CIFAR-10?']","['The computational cost of the proposed methodologies is not thoroughly discussed.', 'The theoretical analysis could be more rigorous.', 'Potential negative societal impacts are not deeply explored, particularly in applications of improved model generalization.', 'Experiments limited to CIFAR-10 dataset.', 'Lack of theoretical foundation for the observed phenomena.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",False,3,2,3,5,4,"['Addresses a relevant and timely topic in machine learning.', 'Proposes novel methodologies for measuring spectral bias.', 'Provides extensive experimental validation on a variety of models and settings.', 'Insightful findings on how different factors influence the frequency characteristics of learned functions.']","['The paper could be better organized; some sections are dense and hard to follow.', 'The theoretical underpinnings are not explored in depth; more rigorous analysis could strengthen the claims.', 'Some experimental details are missing, which could affect reproducibility.', 'Experiments are conducted only on CIFAR-10, which may limit generalizability.', 'The connection between spectral bias and real-world applications remains somewhat abstract.']",3,3,3,3,Reject
Zk3TwMJNj7,"The paper investigates the directional bias in Stochastic Gradient Descent (SGD) for nonparametric regression models, specifically kernel regression. It claims that SGD converges in the direction of the largest eigenvalue of the Gram matrix, which helps it generalize better than Gradient Descent (GD). Theoretical results are provided along with limited experimental validation.","['Can the authors provide more extensive experimental validation to demonstrate the practical utility of their theoretical findings?', 'How robust are the theoretical results to variations in the conditions, such as the diagonal dominance of the Gram matrix?', 'Can the authors improve the clarity of the presentation, especially in the theoretical sections?', 'Can the authors provide more empirical evidence for the diagonal dominance assumption in practical datasets?', 'How does the proposed directional bias theory apply to other types of machine learning models beyond kernel regression?', 'Can the authors elaborate on the potential implications for deep learning models with more empirical support?', 'How robust are the results to variations in the kernel function and step size?', 'Can the directional bias phenomenon be observed in more complex, real-world datasets?', 'How does the choice of kernel function affect the generalization performance of SGD?', 'How robust are the theoretical results to variations in the assumptions?', 'Can the authors provide more extensive experimental validation on different datasets and more complex models?', 'How do the findings translate to practical applications in deep learning?', 'Can the authors provide more justification for the assumptions about diagonal dominance?', 'How sensitive are the results to variations in the step sizes used in the experiments?', 'Can the authors provide more concrete examples of how their results might apply to deep learning?']","['The paper relies heavily on the assumption of diagonal dominance in the Gram matrix, which may limit its applicability.', 'The experimental validation is limited to small-scale simulations and a modest neural network experiment on FashionMNIST.', 'The assumptions on diagonal dominance and specific kernel functions may not hold in practical scenarios.', 'Limited discussion on practical implications and negative societal impacts.']",False,3,2,3,5,4,"['Provides a rigorous theoretical analysis of directional bias in SGD.', 'Extends the concept of directional bias from parametric to nonparametric models.', 'Detailed proofs are provided in the appendices.']","['Relies on very specific conditions (e.g., diagonal dominance of the Gram matrix).', 'Experimental validation is limited and not convincingly demonstrating practical utility.', 'The paper is densely written and may be difficult to follow.', 'The practical implications for real-world deep learning tasks are speculative.']",2,3,2,3,Reject
rrWeE9ZDw_,"The paper presents a method for autonomously learning object-centric representations for high-level planning in reinforcement learning. The proposed framework aims to create portable abstractions that can be transferred between tasks with similar objects, thereby reducing the sample complexity for learning new tasks. The authors validate their approach through experiments in various domains, including a 2D crafting domain, Blocks World, and Minecraft, demonstrating efficient high-level planning and transferability. The method involves partitioning options into subgoal options, learning preconditions and effects, and generating PDDL representations that can be used by off-the-shelf planners.","['Can the authors provide more quantitative comparisons with closely related work?', 'What are the potential limitations of the proposed approach?', 'Can the authors discuss any potential negative societal impacts of their work?', 'How does the proposed method compare quantitatively with existing state-of-the-art methods in terms of sample efficiency and planning efficiency?', 'Can the authors provide a clearer, step-by-step explanation of the methodology, ideally with visual aids?', 'What are the computational costs associated with the proposed approach, especially in the context of high-dimensional environments like Minecraft?']","['The approach might be limited by the assumption that the agent can individuate objects in its environment.', 'The framework may not handle tasks with highly dynamic and unpredictable object behaviors well.', 'Scalability to very high-dimensional tasks is not thoroughly explored.', 'Potential overfitting during the feature selection phase is not addressed.', 'The reliance on pre-specified high-level skills may limit the generalizability of the approach.']",False,3,2,3,5,4,"['Addresses the significant challenge of efficient transfer of learned representations in RL.', 'Provides a comprehensive framework including partitioning options, learning preconditions and effects, and generating PDDL representations.', 'Extensive experimental validation across different domains.', 'Potential to significantly improve sample efficiency in reinforcement learning.', 'Demonstrates applicability to both low-dimensional and high-dimensional tasks.']","['Lacks detailed comparison with closely related work in terms of quantitative metrics.', 'Technical details are relegated to the appendix rather than included in the main text, making it difficult to follow.', 'The paper is densely written and lacks clarity, making it difficult to follow.', 'Scalability to very high-dimensional tasks beyond Minecraft is not thoroughly explored.', 'Potential limitations and ethical considerations are not thoroughly discussed.']",3,3,2,3,Reject
DIsWHvtU7lF,"The paper introduces FINN, a compositional physics-aware neural network designed to learn spatiotemporal advection-diffusion processes. FINN combines neural networks with numerical simulation techniques, achieving superior modeling accuracy and generalization capabilities. The authors evaluate FINN on several PDEs and real-world problems, demonstrating its effectiveness compared to existing methods.","['Can the authors provide a clearer, more concise explanation of the methodology?', 'How does FINN perform on a wider range of PDEs not covered in the paper?', 'Can the authors discuss the potential limitations and negative societal impacts of their work in more detail?', 'How does FINN handle noisier, less structured real-world data compared to synthetic data?', 'What are the specific challenges in extending FINN to higher-order PDEs?', 'Can the authors provide more details on the technical implementation of the flux and state kernels?', 'How does FINN handle different types of boundary conditions in practical applications?', 'Can the authors clarify the specific contributions of each module (ϕ, ϕ, and Φψ) in the overall performance improvement?', 'Is there any additional analysis or visualization comparing the learned functions with the true physical properties?', 'Can the authors provide more details on the computational complexity of FINN compared to other models?', 'How does the model handle cases where the underlying physical equations are not well understood or are partially known?', 'Can the authors elaborate on the potential applications of FINN beyond the examples provided?', 'How does FINN fundamentally differ from existing methods like PINN?', 'Can the authors provide more rigorous theoretical analysis to support their claims?', 'How does FINN handle varying boundary conditions in practice, and how robust is it to different types of noise in the data?']","['The paper does not adequately address the limitations and potential negative societal impact of their work. For instance, the potential overfitting to specific tasks and the implications of applying FINN to noisier real-world data are not sufficiently discussed.', 'The current implementation of FINN is limited to first and second order spatial derivatives.', 'The method is currently applicable only to homogeneously distributed data, with plans to extend to heterogeneous data (graphs).', 'The training time is considerable for 2D data, and runtime efficiency on GPU needs improvement.', 'Potential negative societal impacts are not discussed in detail.']",False,3,3,3,4,4,"['Introduction of a novel compositional physics-aware neural network.', 'Comprehensive evaluation on multiple PDEs and real-world scenarios.', 'Claims of superior modeling accuracy and generalization.', 'Application to real-world data shows practical utility and potential for broader adoption.']","['The paper is lengthy and dense, which might hinder reproducibility and understanding.', 'Clarity of the methodology could be improved for better comprehension.', 'Experimental comparisons, though extensive, might not be sufficiently comprehensive to establish the superiority of FINN conclusively.', 'Potential overfitting to the specific tasks demonstrated.', 'Limited discussion on the limitations and potential negative societal impact.', 'The current implementation may not be optimized for GPU, affecting runtime performance.']",4,3,3,3,Reject
Ivku4TZgEly,"The paper critiques the Integrated Gradients (IG) method for attribution in machine learning, highlighting issues of fairness and attribution transfer. It introduces a new method, Integrated Certainty Gradients (ICG), which aims to address these issues by augmenting the input space with certainty information and training the model to handle incomplete information. The paper provides both theoretical analysis and empirical results to support the proposed method.","['Can the authors provide more clarity on the practical applicability of ICG in real-world scenarios?', 'How does the performance of ICG compare to IG in terms of computational complexity?', 'Can the theoretical sections be simplified for better readability?', 'Can the authors provide a more rigorous theoretical justification for the new method, Integrated Certainty Gradients?', 'How does ICG compare to other state-of-the-art attribution methods in a broader range of scenarios?', 'Can the authors clarify the training process for ICG and provide more detailed hyperparameter settings?', 'What are the broader applicability and generalizability of ICG beyond the specific scenarios tested?', 'Can the authors provide more comprehensive experimental validation on more realistic datasets and tasks?', 'How does the proposed method scale with larger and more complex models?', 'Can the authors elaborate on the ethical considerations and societal impacts of their work?', 'Can the authors provide more detailed explanations or visual aids to clarify the theoretical foundations of ICG?', 'How does the novelty of ICG compare to existing methods like Expected Gradients in more detail?', 'Could the authors provide more detailed instructions or code snippets to ensure the reproducibility of their results?']","['The method requires a special training process which may not be feasible for all types of models or datasets.', 'The paper does not fully explore the potential negative societal impacts of misattribution in critical applications like medical imaging or loan applications.', 'Theoretical validation of the new method is not thorough.', 'Potential for overfitting to specific scenarios.', 'Broader applicability and generalizability are not well-discussed.', 'The paper does not sufficiently address the broader applicability and scalability of the proposed method.', 'Potential limitations of the method are not deeply explored.', 'Ethical considerations and societal impacts are not thoroughly discussed.']",False,3,3,3,6,4,"['Addresses a relevant and important problem in the field of model interpretability and fairness.', 'Proposes a novel method (ICG) with a detailed experimental evaluation.', 'Identifies specific failure modes in existing methods and provides a clear motivation for the new method.', 'Comprehensive experimental evaluation across multiple scenarios.', 'Clear organization and logical flow of sections.']","['Theoretical foundations and explanations are not rigorously presented and can be convoluted.', 'Clarity in some sections, especially theoretical aspects and training methods, could be improved.', 'The practical applicability of ICG in real-world scenarios is not thoroughly discussed.', 'Experimental validation is limited and somewhat artificial.', 'Reproducibility is a concern as the details provided may not be sufficient for independent verification of the results.', 'Ethical considerations and societal impact are not deeply explored.']",3,3,3,4,Reject
rdBuE6EigGl,"The paper proposes adding a direct connection between the input and the output in recurrent neural networks (RNNs) to improve performance on language modeling tasks. The proposed method is evaluated on the Penn Treebank and WikiText-2 datasets, showing consistent performance improvements across different RNN architectures.","['How does the performance of the proposed dual architecture compare to other advanced models beyond the ones mentioned in the paper?', 'Could the authors provide more details on the hyperparameter tuning process for the dual architectures?', 'What are the computational costs associated with the dual architecture compared to the standard models?', 'Can the authors provide more context on how their approach differs from other methods that introduce direct connections or residual connections in neural networks?', 'Have the authors tested the dual architecture on other types of sequence modeling tasks beyond language modeling? If so, what were the results?', 'Can the authors provide more detailed explanations or hypotheses for why the dual connection improves performance?', 'Can the authors discuss the potential limitations and broader applications of the dual architecture beyond language modeling?', 'Have the authors considered the computational overhead introduced by the dual connection?', 'What are the potential ethical concerns and societal impacts of the proposed approach?', 'Can the authors provide a stronger theoretical justification for the proposed modification?', 'How does the proposed modification perform on larger datasets and other tasks beyond language modeling?', 'Can the authors implement more state-of-the-art techniques to provide a fairer comparison?', 'What are the specific hyperparameters used in the experiments?', 'Can the authors provide more details on the experimental setup to ensure reproducibility?']","['The paper does not explore the potential broader applicability of the dual architecture beyond the tested language modeling tasks.', 'There is limited discussion on the potential negative societal impact of the proposed method.', 'The theoretical foundation for the proposed modification is not strong.', 'The impact on larger datasets and other tasks is not explored.', 'Several state-of-the-art techniques were not implemented in the comparison.', 'The lack of theoretical analysis limits the understanding of the proposed method.']",False,3,2,3,4,4,"['The proposed modification is simple and easy to implement.', 'The experimental results demonstrate consistent improvements across different architectures and datasets.', 'The dual architecture achieves state-of-the-art results in some cases.']","['The novelty of the method is somewhat limited, as it essentially adds a straightforward bypass layer.', 'The theoretical justification for the modification is weak.', 'The experimental setup could be more comprehensive, with more detailed comparisons to existing advanced architectures and training techniques.', 'The clarity and organization of the paper are not optimal, making it somewhat challenging to follow the methodology and results.', 'The impact of the modification on other tasks and larger datasets is not explored.', 'The paper does not address the potential negative societal impact of the proposed method.', 'The potential computational overhead introduced by the dual connection is not discussed.']",2,3,3,3,Reject
q2ZaVU6bEsT,"The paper proposes a new feature pyramid network (FPN) for tiny object detection that incorporates context augmentation and feature refinement. Additionally, it introduces a data augmentation method called copy-reduce-paste. The proposed methods are evaluated on the PASCAL VOC dataset, showing improvements in mean average precision (mAP) compared to other state-of-the-art methods.","['Can the authors provide more theoretical insights into the context augmentation and feature refinement mechanisms?', 'How does the proposed method perform on other datasets besides VOC?', 'Can the authors clarify the architecture details and provide a clearer diagram of the proposed network?', 'Can the authors provide more detailed ablation studies comparing CAM and FRM with recent state-of-the-art methods?', 'Can the authors clarify the specific implementation details and hyperparameters used in the proposed modules?', 'Have the authors considered evaluating the method on additional datasets to validate its generalizability?', 'Can you elaborate on the potential limitations and negative societal impacts of your work?']","['The paper should provide more theoretical analysis to support the proposed mechanisms.', 'The novelty of the data augmentation method is limited.', 'The generalizability of the results is limited as the evaluation is performed on a single dataset.', 'Potential negative societal impacts, such as misuse in surveillance or privacy breaches, are not discussed.']",False,2,2,3,4,4,"['Addresses the important problem of tiny object detection.', 'Introduces novel components such as the context augmentation module (CAM) and the feature refinement module (FRM).', 'Proposes an innovative data enhancement technique, copy-reduce-paste.', 'Experimental results demonstrate improvements over existing methods.']","['The paper is difficult to follow due to unclear writing and organization.', 'Limited evaluation to a single dataset raises concerns about generalizability.', 'Theoretical justification for some methods is lacking.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'Lacks detailed ablation studies and comparisons with more advanced recent methods.']",3,2,2,3,Reject
V7eSbSAz-O8,The paper proposes a framework for benchmarking the robustness of machine learning (ML) and deep learning (DL) methods in classifying SARS-CoV-2 spike protein sequences. It introduces error profiles similar to those produced by modern sequencing technologies and evaluates the performance of ML and DL models using k-mer based feature representations and one-hot encoding.,"['How does the proposed framework compare with other state-of-the-art models beyond Keras?', 'Can the authors provide more detailed explanations for some of the experimental results, especially in the robustness section?', 'Is there a reason why only Keras was used for DL models and not other architectures like CNNs or LSTMs?', 'Why was only 1% of the data used for training? Would larger training sets yield different results?', 'How were the hyperparameters for the ML and DL models selected?', 'Why were only certain types of errors (random and consecutive) considered? Are there other error types that could be relevant?', 'Could the authors clarify how the robustness metrics were computed?', 'How do the introduced error simulation methods compare to real-world sequencing errors?', 'What are the limitations of the proposed framework, and how can they be addressed?']","['The paper does not sufficiently address the potential negative societal impacts of misclassifications in the context of public health.', 'The robustness evaluation could be more comprehensive by including a wider range of adversarial attack types.', 'The framework is only evaluated on SARS-CoV-2 spike sequences, limiting its perceived generalizability.']",False,2,2,2,4,4,"['Timely and relevant topic given the ongoing COVID-19 pandemic.', 'Introduction of a novel benchmarking framework for testing model robustness.', 'Comprehensive experiments covering various ML and DL methods and error generation strategies.']","['Limited novelty in methods and approaches.', 'Lack of theoretical depth and analysis.', 'Experimental setup raises questions about generalizability, such as the use of a small training set.', 'The paper is lengthy and somewhat disorganized, reducing clarity.', 'Insufficient discussion on the limitations and potential negative societal impacts.', 'Comparative analysis with other state-of-the-art models beyond Keras is missing.']",3,2,2,3,Reject
GlN8MUkciwi,The paper proposes a method for video-text retrieval that incorporates user comments using a Context Adapter Module (CAM) with hierarchical attention mechanisms to filter irrelevant information. The approach aims to improve retrieval performance by leveraging user comments and is validated on standard benchmarks.,"['How does the model perform on more diverse datasets beyond RedditVC and KineticsComments?', 'Can the authors provide more detailed explanations of the hierarchical attention mechanism and the Context Adapter Module?', 'Are there any plans to address the ethical concerns related to using user-generated content without explicit consent?', 'How does the model handle comments in languages other than English?', 'Can you provide more details on the computational complexity of the proposed method compared to the baselines?', 'How does the method perform on datasets with highly irrelevant or noisy comments?', 'What specific steps were taken to ensure the ethical use of user-generated content?', 'Can the authors provide more theoretical justification for the CAM and its components?', 'How does the proposed method compare with other state-of-the-art video-text retrieval methods?', 'What measures have been taken to address potential biases in the user-generated content used for training?', 'How generalizable is the proposed method to other datasets and tasks beyond video-text retrieval?']","['The model may overfit to specific datasets, limiting generalizability.', 'Potential ethical concerns regarding the use of user-generated content without explicit consent.', 'The paper does not thoroughly discuss the potential biases in the RedditVC dataset and how they might affect the results.', 'The societal impact and ethical considerations are not adequately addressed, especially the implications of using user-generated content.']",True,2,2,2,4,4,"['Novel approach to incorporating user comments in video-text retrieval.', 'Hierarchical attention mechanism to filter irrelevant information.', 'Competitive performance on standard benchmarks.']","['Limited novelty in the approach; hierarchical attention mechanisms are already well-studied.', 'Potential overfitting to specific datasets, as demonstrated by varying performance across different benchmarks.', 'Lack of thorough evaluation on diverse datasets beyond RedditVC and KineticsComments.', 'Clarity of presentation is hindered by complex language and insufficient explanation of key concepts.', 'Ethical concerns related to using user-generated content without explicit consent from the authors.']",3,2,2,2,Reject
1-YP2squpa7,"The paper introduces BP-based message-passing algorithms with a reinforcement term for training deep neural networks. These algorithms are adapted for mini-batch training on GPUs and claim to offer competitive performance with SGD on tasks like image classification and continual learning, especially on sparse networks.","['Can the authors provide more detailed comparisons with SGD, including different hyperparameter settings?', 'How robust are the BP-based algorithms to different network architectures and datasets?', 'Can the authors elaborate on the computational complexity and runtime comparisons?', 'How does the proposed method handle overfitting compared to SGD?', 'Can the authors provide a clearer explanation of the BP-based message-passing algorithms and their implementation?', 'How does the proposed method scale to more complex architectures, such as convolutional networks?', 'Can the authors provide more significant improvements over existing methods like BinaryNet?', 'What are the computational complexity and practical implementation details, especially regarding GPU optimizations?', 'Can the authors provide more comprehensive comparisons with state-of-the-art methods across a broader set of benchmarks?', 'How do the proposed algorithms perform in terms of computational efficiency compared to SGD on larger datasets and more complex architectures?', 'Can the authors provide more theoretical analysis to support their claims, particularly regarding the convergence properties of the proposed algorithms?']","['The potential negative societal impacts of the work are not discussed.', 'The limitations regarding the scalability to very large datasets and models are not addressed.', 'The scalability and applicability to more complex architectures need further exploration.', 'The practical implementation details, especially regarding GPU optimizations, are not adequately discussed.', 'The clarity of the paper needs improvement to make it accessible to a broader audience.']",False,2,2,2,4,4,"['Proposes a novel application of BP-based algorithms to deep learning.', 'Claims to offer a viable alternative to SGD with comparable performance.', 'Includes detailed theoretical underpinnings and extensive related work.', 'Adaptation of the method for GPU computation.']","['The paper is dense and complex, making it hard to follow.', 'Experimental results, while promising, need more extensive validation.', 'Comparison with existing methods like SGD could be more thorough.', 'The implementation details and reproducibility aspects are not fully addressed.', 'Limited theoretical support and analysis of convergence properties.', 'Inadequate comparison with state-of-the-art methods beyond SGD.', 'Lack of discussion on the scalability and practical implementation details on larger datasets and architectures.']",3,2,2,3,Reject
hfU7Ka5cfrC,"The paper proposes an approximate hypergradient-based hyperparameter optimization method applicable to continuous hyperparameters in differentiable model weight updates, requiring only one training episode without restarts. It extends existing methods to include arbitrary optimizer hyperparameters like learning rates and momenta, and provides a convergence argument to the true hypergradient. The method is evaluated on several datasets, showing competitive performance with less computational overhead compared to existing methods.","['Can the authors provide more details on the computational complexity of their method compared to state-of-the-art methods?', 'How robust are the approximations and assumptions made in the derivations? Can the authors provide more empirical evidence or theoretical analysis?', 'Can the authors include more direct comparisons to other state-of-the-art hyperparameter optimization methods in their evaluation?', 'Can the authors provide more statistical analysis of their empirical results?', 'How does the method perform on additional, more varied datasets?', 'Can the authors clarify the practical usability of their method in real-world applications?', 'What are the potential drawbacks or limitations of this method in different settings?', 'Can the authors provide more details on how the method handles potential overfitting in high-dimensional hyperparameter settings?', 'How does the method compare to more sophisticated baseline methods beyond simple random search or gradient descent?', 'Can the authors provide a more intuitive and simplified explanation of the derivation for better accessibility?', 'Can the authors provide more clarity on the derivation steps, particularly around Equation (6) and its approximations?', 'How does the proposed method compare against other state-of-the-art hyperparameter optimization methods in terms of both performance and computational efficiency?', 'Can the authors elaborate on the impact of short-horizon bias in their method and how it might be mitigated?']","['The method relies on approximations that may not hold in all practical scenarios.', 'Potential overfitting to the validation set is not adequately addressed.', 'Scalability claims are based on empirical results without thorough theoretical analysis.', 'Ethical considerations and societal impact are acknowledged but not deeply explored.']",False,2,2,2,4,4,"['Addresses a significant problem in hyperparameter optimization by including optimizer-specific hyperparameters.', 'Reduces computational overhead by avoiding multiple training restarts.', 'Provides theoretical convergence argument to the true hypergradient.', 'Empirical evaluation on a variety of datasets and architectures.']","['Clarity issues in the mathematical derivations and algorithmic descriptions.', 'Theoretical foundation lacks rigorous proofs and relies heavily on approximations.', 'Empirical results, while extensive, do not show a significant improvement over existing methods.', 'Discussion on the limitations and potential negative impacts is superficial.', 'The clarity of the paper is hampered by dense mathematical notations and insufficient explanations of key steps.']",3,2,2,3,Reject
dLTXoSIcrik,"The paper proposes the POELA algorithm to address an overfitting problem in offline policy optimization using importance sampling. The method constrains the policy to select actions that ensure a lower bound on importance weights, thus avoiding unrealistic avoidance of low-reward initial states. Theoretical justifications and empirical evaluations in both synthetic and real-world healthcare datasets are provided.","['How sensitive is the method to the choice of the δ parameter? Have the authors explored the robustness of the method to different values of δ?', 'Can the authors provide more empirical comparisons to other recent methods in the domain?', 'What are the computational requirements of the proposed method compared to the baselines?', 'Can the authors provide more rigorous theoretical proofs for the proposed algorithm?', 'How does the eligible actions constraint compare to other regularization methods in terms of theoretical foundations?', 'Can the authors provide comparisons with a broader range of state-of-the-art methods in different domains?', 'Can the authors provide more details on the implementation of the POELA algorithm, particularly the choice of distance metric?', 'How does the proposed method compare with other recent advances in offline RL, such as model-based approaches?', 'Can the authors clarify the assumptions made in the theoretical analysis and their practical implications?', 'Can you provide more details on the choice of hyperparameters and their impact on the results?', 'How robust are the results to different dataset sizes and configurations?', 'Could you provide additional intuition or examples to explain the theoretical analysis?']","[""The method's performance depends on the choice of the δ parameter, which may require careful tuning."", 'The empirical evaluations are limited to specific domains (healthcare), and it would be beneficial to see results in other application areas.', 'The eligible actions constraint might limit the expressivity of the policy class.', 'The method may not generalize well to non-healthcare domains due to the specific nature of the datasets used.', 'Potential negative societal impacts are not thoroughly discussed.', 'The variability in empirical results raises concerns about the robustness of the proposed method.']",False,3,3,3,4,4,"['Addresses a critical overfitting problem in offline policy optimization.', 'Theoretical justifications are provided and proven.', 'Empirical results on synthetic and real-world datasets show the effectiveness of the proposed method.', 'The paper is clearly written and well-organized.']","['Limited novelty as it builds on existing concepts of importance sampling and pessimism under uncertainty.', 'Empirical results could benefit from additional baselines and more diverse datasets.', 'The sensitivity and optimal selection of the δ parameter need more exploration.', 'Theoretical justifications are not entirely clear and could be more rigorously presented.', 'The empirical evaluation lacks diversity, focusing mainly on healthcare-related datasets.']",3,3,3,3,Reject
-dzXGe2FyW6,"The paper introduces a new fairness metric called Equalized Robustness (ER) and a novel algorithm, Curvature Matching (CUMA), to achieve fair model robustness against distributional shifts. The approach is validated through experiments on multiple datasets, showing superior performance in maintaining fairness under distributional shifts.","['Can the authors provide more detailed explanations of the methodology and experimental setup?', 'How does the proposed method generalize to other datasets and real-world applications?', 'What are the potential negative societal impacts of the proposed method?', 'Can the authors provide more theoretical justification for the ER metric?', 'How sensitive is the CUMA algorithm to different choices of hyperparameters?', 'Can the authors include more scenarios of distributional shifts in their evaluation to further validate the robustness of their approach?', 'How does the proposed ER metric compare to other existing robustness metrics in terms of both theoretical and empirical performance?', 'Can the authors provide a more detailed explanation of the Curvature Matching algorithm, particularly the one-shot power iteration method?', 'What are the potential limitations and negative societal impacts of the proposed methods, and how can they be mitigated?', 'Can the authors provide more theoretical insights into why ER is a robust measure for fairness under distributional shifts?', 'How does CUMA perform on datasets with different types of distributional shifts not covered in the paper?', 'Can the authors elaborate on the computational complexity of the curvature matching process?', 'Have the authors considered the computational cost and scalability of the proposed method, especially for large datasets?', 'Can the authors provide more robust empirical validations, such as cross-validation, on different datasets or settings?']","['The complexity of the method may limit its practical applicability.', 'Limited generalizability due to the specific datasets used in the experiments.', 'Potential negative societal impacts are not adequately discussed.', 'The paper should discuss the potential computational overhead introduced by the CUMA algorithm.', 'The authors should address the limitations regarding the specific types of distributional shifts considered in their experiments.', 'Potential negative societal impacts, such as the risk of overfitting to specific types of fairness constraints, should be discussed.', 'The paper does not thoroughly discuss potential negative societal impacts and ethical considerations of the proposed methods.', 'The clarity and explanation of the technical details, especially the Curvature Matching algorithm, need improvement.', 'The paper does not fully explore the limitations of the proposed method, such as its scalability to larger datasets or more complex models.', 'Potential negative societal impacts of ensuring fairness under distributional shifts, such as overfitting to rare scenarios, are not discussed.', 'The proposed method may have high computational costs, which are not discussed in the paper.', 'The sensitivity to hyperparameters is not thoroughly investigated.', 'The generality of the proposed method across various types of distribution shifts is not fully validated.']",False,3,2,3,5,4,"['Novelty in introducing ER as a fairness metric that considers distributional shifts.', 'Well-designed CUMA algorithm aimed at achieving both in-distribution and out-of-distribution fairness.', 'Comprehensive experimental validation on multiple datasets.']","['The complexity of the proposed method may limit its practical applicability.', 'Lacks clarity in several sections, making the methodology and experimental setup difficult to follow.', 'Limited generalizability due to experiments being conducted on specific datasets.', 'Inadequate discussion on the potential negative societal impacts of the proposed method.', 'Theoretical analysis on the robustness of ER could be more thorough.', 'The selection of hyperparameters for the CUMA algorithm seems somewhat arbitrary and might need more justification.', 'The experimental results, while promising, are not exhaustive enough to cover a wide range of potential distributional shifts.', 'The clarity of some methodological details, like the one-shot power iteration method, could be improved.', 'The concept of using MMD for fairness is not entirely novel and has been explored in earlier works.', 'The experimental results lack thorough statistical validation and significance testing.']",3,3,2,3,Reject
m8uJvVgwRci,"The paper introduces Weak Indirect Supervision (WIS), a new paradigm for synthesizing training labels from indirect supervision sources with mismatched output spaces. The Probabilistic Label Relation Model (PLRM) is developed to address this challenge by leveraging user-provided label relations. The paper also introduces a notion of distinguishability for unseen labels and provides a generalization bound for PLRM. Experiments on image and text classification tasks, as well as a real-world advertising application, demonstrate the effectiveness of the proposed method.","['Can the authors provide more details on the process of fitting the PLRM?', 'How does the method perform with varying degrees of noise in the label relations? Could this be a limitation?', 'Can the authors clarify the high variance observed in the experimental results? What factors contribute to this variance?', 'Can the authors provide more details on how the ILFs were constructed and their specific characteristics?', 'How was the high variance in experimental results addressed, and what steps were taken to ensure robustness?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their approach?', 'How does the proposed method compare to other state-of-the-art methods in zero-shot learning and transfer learning?', 'Can the authors provide more intuitive explanations and visualizations to enhance the clarity of the theoretical contributions?', 'Are there additional real-world applications where PLRM can be validated?', 'Can the authors provide more details on the scalability of PLRM in large-scale real-world applications?', 'How does the performance of PLRM compare to other state-of-the-art weak supervision methods across different datasets and domains?', 'Can the authors elaborate on the practical implications of the distinguishability condition in real-world scenarios?', 'Can the authors provide additional details or visual aids to clarify the theoretical proofs and derivations?', 'Could the authors include ablation studies to show the contribution of each component of the PLRM model?', 'What are the practical challenges and limitations encountered during the deployment of the proposed WIS framework in real-world applications?']","[""The method's reliance on user-provided label relations could be a limitation if the relations are noisy or inaccurate."", 'High variance in experimental results might indicate sensitivity to certain parameters or dataset characteristics.', 'The paper does not sufficiently discuss the limitations of the proposed approach.', 'Potential negative societal impacts, such as biases in the synthesized training data, are not addressed.', ""The high variance in experimental results suggests the method's performance may not be consistent across different datasets."", 'The complexity of the theoretical contributions may limit the accessibility and reproducibility of the work.', 'The paper acknowledges potential limitations in scalability and practical deployment, which should be further addressed in future work.', 'The potential negative societal impacts, such as biases in the synthesized training data, should be discussed in more detail.']",False,3,2,3,6,4,"['Novel problem formulation with WIS to utilize indirect supervision sources.', 'Introduction of PLRM to model and leverage label relations effectively.', 'Theoretical contributions including the concept of distinguishability and a generalization bound.', 'Empirical validation on both academic datasets and a real-world application.']","['Certain methodological details, such as the exact process for fitting the PLRM, are not fully clear.', 'The impact of potential noisy label relations on the performance of PLRM is not extensively discussed.', 'The experimental results show high variance, indicating potential instability or sensitivity in the method.', 'The clarity of the exposition is lacking, particularly in the explanation of the PLRM and the experimental setup.', 'Insufficient details on how the ILFs were created and their specific characteristics.', 'The paper does not thoroughly discuss potential limitations and negative societal impacts.', 'Theoretical contributions are complex and may not be easily accessible.', 'Requires further validation in real-world scenarios.']",3,3,2,3,Reject
ckZY7DGa7FQ,"The paper introduces Belief Fine-Tuning (BFT), a framework for improving belief state models in partially observable Markov systems by leveraging approximate dynamic programming during inference. The approach is validated through experiments on the game Hanabi, demonstrating improved belief state accuracy and downstream search performance.","['Can the authors provide more details on the baseline models used for comparison?', 'How were the hyperparameters chosen, and how sensitive are the results to these choices?', 'What are the potential limitations of the BFT approach, particularly in different domains or with different types of models?', 'Can the authors discuss any potential negative societal impacts of their work?', 'Can you provide more details on how BFT can be applied to other games or domains beyond Hanabi?']","['The paper does not adequately discuss the limitations of the BFT approach or its potential negative societal impacts.', 'Further clarification is needed on the scalability and generalizability of the approach to other domains beyond Hanabi.', 'The authors mention the need for sampling access to the dynamics model. This requirement could limit the applicability of BFT in some real-world scenarios where such access is not feasible.', ""The method's reliance on fine-tuning might introduce substantial computational overhead, which could be a limitation for time-sensitive applications."", 'The societal impacts of the method are not discussed, especially in the context of multi-agent systems where decision-making can have significant consequences.']",False,3,3,3,5,4,"['Novel application of inference-time fine-tuning for belief state modeling in partially observable Markov systems.', 'Comprehensive experimental setup, demonstrating improvement on a complex benchmark game (Hanabi).', 'Potential for significant practical impact in multi-agent systems and other complex partially observable domains.']","['The originality of the core idea is somewhat limited as inference-time fine-tuning has been explored in other contexts.', 'The clarity of the methodology and results presentation needs improvement for better readability and understanding.', 'The paper lacks a detailed discussion of limitations and potential negative societal impacts.', 'Experimental results are not thoroughly explained, and the adequacy of baseline models and hyperparameter choices need clarification.', 'The experimental validation is limited to a single game (Hanabi), raising concerns about generalizability.']",3,3,3,4,Reject
e6MWIbNeW1,"The paper proposes an Inductive Graph Partitioning (IGP) framework that leverages historical graph snapshots to train a dual graph neural network (GNN). The trained model is then used for fast and high-quality graph partitioning of new graphs. The approach aims to balance quality and efficiency and can handle graphs with non-fixed numbers of nodes and clusters. The method is validated on various synthetic and real datasets, demonstrating competitive results.","['Can the authors provide more theoretical analysis to support the empirical findings, particularly regarding the expressive power of the inductive GNN and the similarity between training and test graphs?', 'How does the method perform on graphs with significantly different structures from the training graphs? Can the authors provide more robustness analysis?', 'What are the potential ethical considerations and societal impacts of the proposed method?', 'How well does the method scale with very large graphs (e.g., millions of nodes)?', 'Can the authors provide more details on the computational requirements for training the dual GNN?', 'How does the method perform on real-world datasets not included in the evaluation?', 'Can the authors provide more practical insights into the complexity analysis?', 'What are the specific applications where this method would be most beneficial?', 'How does the performance of IGP vary with changes in the hyperparameters, and what guidelines can be provided for their selection?', 'Can the authors clarify the trade-off between quality and efficiency with more concrete examples?', 'What are the theoretical guarantees or performance bounds of the proposed method?']","[""The method's complexity and dependency on hyperparameter tuning could limit its practical applicability."", 'The paper lacks theoretical analysis to support its empirical findings.', 'The robustness and generalizability of the method across different types of graphs need further validation.', 'Theoretical analysis of performance bounds is missing.', 'Reproducibility may be challenging due to insufficient details on experimental setups.']",False,3,2,3,5,4,"['The IGP framework introduces a novel inductive approach to graph partitioning, leveraging historical graph data for better generalization.', ""Comprehensive experimental evaluations on both synthetic and real-world datasets, showcasing the method's potential."", 'The paper provides a detailed description of the methodology, including the dual graph neural network architecture and the feature extraction module.', 'The proposed method achieves competitive results in terms of partitioning quality and efficiency compared to state-of-the-art baselines.']","['The method is complex and involves multiple components that require careful hyperparameter tuning, which might be challenging for practitioners.', 'The clarity of the paper could be improved; certain sections are dense and difficult to follow.', 'There is a lack of theoretical analysis to support the empirical findings, particularly regarding the expressive power of the inductive GNN and the similarity between training and test graphs.', 'The robustness and generalizability of the method across different types of graphs need further validation.', 'Ethical considerations and potential societal impact are not adequately addressed.']",3,3,2,3,Reject
QNW1OrjynpT,"The paper investigates the short-term memory capabilities of neural language models, focusing on Transformers and LSTMs. Using a novel paradigm, the authors evaluate how well these models can retrieve previously seen words and their order. The experiments reveal that Transformers significantly outperform LSTMs in memory retrieval tasks across various conditions.","['Can you explore more LSTM variants, such as those with attention mechanisms or copy mechanisms?', 'How do you think the superior memory retrieval capabilities of Transformers will impact practical applications?', 'Can you discuss potential negative societal impacts of improved memory retrieval in language models?', 'Can the authors provide more details on the experimental setup, particularly the choice of noun lists and intervening texts?', 'How do the findings apply to other architectures beyond transformers and LSTMs?', 'Can the authors clarify how their findings might impact practical applications in NLP?', 'Can the authors elaborate on any potential biases introduced by the choice of word lists and intervening texts?', 'How do the findings translate to real-world applications of these language models?', 'Are there any plans to explore variations within LSTM models or other architectures for a more comprehensive comparison?', 'Have you considered exploring hybrid models or variations of the Transformer and LSTM architectures?']","['Limited exploration of LSTM variants.', 'Need for broader discussion on practical implications.', 'Potential negative societal impacts are not thoroughly discussed.', 'The study is limited to transformers and LSTMs; other architectures might show different memory capabilities.', 'Potential biases in the experimental setup.', 'The study primarily focuses on English text; how would the results generalize to other languages?', 'The experiments are well-constructed but might not fully capture the complexities of real-world language processing tasks.', 'The study primarily focuses on two specific architectures and may not generalize to all types of neural language models.']",False,3,3,3,6,4,"['Novel task and methodology for evaluating memory in language models.', 'Comprehensive experimental setup and analysis.', ""Clear demonstration of Transformer's superior memory retrieval capabilities."", 'Well-organized and clearly written.']","['Limited exploration of LSTM variants (e.g., LSTMs with attention mechanisms).', 'Dense sections that may be challenging for a broader audience.', 'Insufficient discussion on practical implications and potential negative societal impacts.', 'Some experimental setups and results are not clearly explained.', 'The reproducibility section could be more detailed.']",3,3,3,3,Reject
R332S76RjxS,"The paper presents a global convergence theory for deep ReLU implicit networks using over-parameterization. It demonstrates that a randomly initialized gradient descent converges to a global minimum at a linear rate for an m-width implicit neural network with n training samples, given the network is over-parameterized. The authors provide rigorous theoretical proofs and validate their findings with experiments on real-world datasets.","['Can the authors provide more intuitive explanations or visual aids to help understand the theoretical results?', 'How does the proposed theory apply to practical scenarios in implicit neural networks?', 'What are the limitations and potential negative societal impacts of this work?', 'How sensitive are the convergence results to the choice of initialization and hyperparameters?', 'Are there any extensions or modifications to the proposed theory that could address the limitations related to over-parameterization?', 'Can the authors provide additional experiments on more diverse datasets to further validate the empirical findings?', 'Could the authors simplify some of the complex mathematical notations to make the paper more accessible?']","['The paper does not adequately discuss the practical implications and applications of the proposed theory.', 'Potential negative societal impacts, such as the use of over-parameterized models in sensitive domains, are not addressed.', 'The theory relies heavily on over-parameterization, which may not be feasible in all practical scenarios.', 'The assumption that no two data points are parallel is strong and may not always hold in practice.', 'The paper does not address how the results would change with different initialization schemes or activation functions other than ReLU.']",False,3,2,3,5,4,"['Novel theoretical contributions to understanding the global convergence of implicit neural networks.', 'Rigorous and detailed mathematical analysis supporting the claims.', 'Addresses a significant gap in the theoretical understanding of implicit deep learning.']","['The paper is highly technical and may not be easily accessible to a broad audience.', 'Clarity issues in several sections, making it difficult to follow the logical flow of arguments.', 'Practical implications and potential applications of the theory are not well discussed.', 'Dependence on over-parameterization might limit practical applicability.', 'Experiments are limited to binary classification tasks; broader evaluation would strengthen the results.', 'The impact of initialization and specific choices of hyperparameters on convergence are not thoroughly explored.']",3,3,3,3,Reject
V3C8p78sDa,"The paper explores the saturation phenomena in downstream (DS) task performance as upstream (US) accuracy improves through large-scale pre-training of Vision Transformers, MLP-Mixers, and ResNets. The authors conduct over 4800 experiments and propose a model to predict DS performance based on US accuracy. They analyze the impact of scaling model size, data, and compute, and investigate the role of hyper-parameters in DS performance.","['Can the authors provide more theoretical grounding for the non-linear relationship between US and DS performance?', 'How do the authors address the potential biases introduced by hyper-parameter tuning in their extensive study?', 'What measures can be taken to improve the reproducibility of the experiments given the scale of the study?', 'Can the authors provide a clearer distinction between their contributions and prior work?', 'Could the authors improve the organization and clarity of the paper to make it more accessible?', 'How do the authors address potential ethical concerns related to the environmental and monetary costs of scaling up models?', 'Can the authors provide more insights into the practical implications of the saturation phenomenon in real-world applications?', 'How do the findings generalize to other modalities beyond image recognition?', 'Are there any specific recommendations for practitioners based on the observed saturation behavior?', 'How do the authors plan to mitigate the potential biases introduced by using models not specifically trained for this study?', 'Can the authors provide more details on the steps taken to ensure the clarity and reproducibility of their experiments?', 'Are there any specific strategies to improve the clarity of presentation in the main body of the paper?']","['The paper does not sufficiently discuss potential negative societal impacts and ethical considerations, particularly regarding the environmental cost of large-scale pre-training.', ""The study's reliance on extensive computational resources may hinder reproducibility."", 'The study focuses primarily on supervised image recognition, not addressing unsupervised pre-training or other modalities.', 'The environmental and monetary costs of scaling up models are significant and should be discussed in more depth.', 'Potential biases in the meta-study due to the aggregation of experiments conducted for different purposes.', 'The practical implications and real-world impact of the findings are not thoroughly discussed.']",False,3,2,3,6,4,"['Extensive empirical study with over 4800 experiments.', 'Investigation of multiple architectures: Vision Transformers, MLP-Mixers, and ResNets.', 'Proposes a model to predict DS performance based on US accuracy.', 'Addresses the impact of scaling model size, data, and compute.', 'Challenges existing assumptions about the linear transferability of improvements.']","['Clarity and organization of the paper could be improved.', 'Some claims, particularly regarding non-linear relationships and hyper-parameters, lack sufficient theoretical grounding.', 'Potential societal impacts and ethical considerations are not adequately discussed.', 'Reproducibility of some experiments might be challenging due to the scale of the study.', 'The reliance on aggregated models from different sources might introduce biases.', 'Practical implications of the findings are not thoroughly discussed.']",3,3,2,3,Reject
EVqFdCB5PfV,"The paper introduces DOCHOPPER, a model that uses iterative hierarchical attention to answer complex questions over long documents. The model achieves state-of-the-art results on multiple QA tasks and is highly efficient at inference time.","['Can you provide more detailed explanations of the iterative attention and query updating mechanisms?', 'How do the modifications to datasets like ShARC and HotpotQA impact the reproducibility of your results?', 'What are the potential societal impacts and limitations of DOCHOPPER that were not addressed in the paper?', 'Can the authors provide more theoretical justification for the design choices made in DOCHOPPER?', 'How does DOCHOPPER compare with other state-of-the-art models for similar tasks, beyond those mentioned?', 'Can the authors clarify the iterative attention mechanism and its specific advantages over existing methods?', 'How were the dataset modifications validated to ensure they do not introduce biases?', 'Can you provide more theoretical insights into the convergence and robustness of the iterative attention mechanism?', 'Could you conduct additional ablation studies to isolate the impact of each component of DOCHOPPER?', 'Can you elaborate on the potential negative societal impacts and ethical considerations of deploying DOCHOPPER in real-world settings?', 'Can the authors clarify the mathematical formulations used in the query update mechanism?', 'How do the baselines handle the same tasks and how are they specifically implemented in the experiments?', 'Why does the model underperform in certain scenarios like HybridQA?', 'Can the authors provide more detailed pseudocode or algorithm descriptions to aid reproducibility?', ""Can the authors discuss potential ways to improve DOCHOPPER's performance on tabular data?"", 'How does DOCHOPPER handle biases in the QA models, and what measures are taken to mitigate potential negative societal impacts?']","['The paper does not thoroughly discuss the potential biases and limitations of the model.', 'Modifications to datasets might impact the generalizability and reproducibility of the results.', 'The model may not generalize well to other types of documents or question types not covered by the datasets used.', 'The efficiency claims are based on specific hardware and may not hold in different environments.', ""The model's performance on tabular data (HybridQA) is significantly lower compared to other datasets.""]",False,3,3,3,6,4,"['Achieves state-of-the-art results on multiple datasets.', 'Efficient at inference time with significant speed improvements.', 'Novel use of hierarchical attention and iterative query updating.']","['Clarity issues in explaining core mechanisms of the model.', 'Lacks detailed theoretical justification for some design choices.', 'Experiments are partially based on modified datasets, potentially affecting reproducibility.', 'Limited discussion on potential societal impacts and limitations.', 'Insufficient comparison with other state-of-the-art models designed for similar tasks.', 'Heavy reliance on empirical results with insufficient ablation studies.']",3,3,3,4,Reject
3ILxkQ7yElm,"The paper introduces a method to learn continuous environment fields via implicit functions, which encode the reaching distance between any two points in a 2D or 3D space. The proposed method aims to guide dynamic agent behaviors in 2D mazes and predict human trajectories in 3D indoor environments. The main contributions include the introduction of a novel scene representation (environment field), learning dense fields with neural implicit functions, and applying these fields to agent navigation and human trajectory prediction.","['Can the authors provide more details on the training setup and hyperparameters used for the experiments?', 'How does the proposed method compare with other state-of-the-art methods in terms of computational efficiency and scalability?', 'Have the authors considered any potential negative societal impacts of their work, such as privacy concerns or misuse of trajectory prediction?', 'Can the authors provide more detailed experimental results comparing their method to additional baseline methods?', 'Can the authors elaborate on the limitations of their approach in different types of environments?', 'Is it possible to provide more detailed reproducibility information to ensure that the experiments can be replicated by other researchers?', 'How does the method handle dynamic changes in the environment during inference?']","['The paper does not discuss potential limitations in terms of scalability to very large or complex environments.', 'The societal impacts of deploying such trajectory prediction systems in real-world applications are not addressed.', ""The method's performance in extremely complex or dynamic environments is not evaluated."", 'The ethical implications of using human trajectory data and potential biases in the model are not discussed in detail.']",False,3,2,3,6,4,"['The proposed method introduces a novel scene representation that encodes reaching distance, which can guide dynamic agent behaviors.', 'The use of implicit functions to learn continuous environment fields from discretely sampled data is innovative and shows potential for efficient generalization.', 'The method demonstrates promising results in both 2D maze navigation and 3D human trajectory prediction, with extensive experiments validating its effectiveness.']","['The paper lacks detailed ablation studies to thoroughly validate each component of the proposed method.', 'Some of the experimental setups and comparisons are not fully described, which may hinder reproducibility.', 'The potential negative societal impacts of the work are not adequately discussed.', 'The clarity of the presentation could be improved, particularly in the explanation of the methodology.', 'Limited discussion on the generalizability to more complex environments.']",4,3,2,4,Reject
ccWaPGl9Hq,"The paper proposes a theoretical framework for deployment-efficient reinforcement learning (DE-RL), establishing information-theoretic lower bounds and presenting algorithms to achieve optimal deployment efficiency. The framework is extended to 'Safe DE-RL' and 'Sample-Efficient DE-RL'.","['Can the authors provide experimental validation of the proposed algorithms?', 'How do the proposed algorithms perform in practical scenarios compared to existing methods?', 'What is the computational complexity of the proposed algorithms?', 'Can the authors provide more intuitive explanations for some of the complex mathematical formulations?', 'How do the theoretical findings translate to practical applications? Are there any case studies or real-world examples?', 'What are the potential negative societal impacts of deployment-efficient RL, and how can they be mitigated?', 'How do the assumptions regarding the reachability coefficient impact the real-world applicability of the algorithms?', 'Can the authors discuss the feasibility of applying the proposed algorithms in large-scale settings?']","['The paper lacks experimental validation, which is crucial to demonstrate the practical effectiveness of the proposed methods.', 'The computational complexity of the proposed algorithms is not discussed, which is important for understanding their feasibility in real-world applications.', 'The assumptions regarding the reachability coefficient and its practical implications are not thoroughly discussed.', 'The complexity of the proofs may limit the accessibility of the results to a broader audience.', 'Potential negative societal impacts of deployment-efficient RL are not fully addressed. For example, frequent deployment of sub-optimal policies in sensitive applications (e.g., healthcare) could have adverse effects.']",False,3,3,3,6,4,"['Addresses a relatively unexplored yet important problem in RL.', 'Provides a novel formalization of DE-RL.', 'Derives new theoretical results and lower bounds.', 'Proposes algorithms with provable guarantees.', 'Well-organized and clearly structured.']","['Lacks experimental validation and practical applicability.', 'Some sections are mathematically dense and could benefit from more intuitive explanations.', 'The paper does not provide a discussion on the computational complexity of the proposed algorithms.', 'Potential negative societal impacts are not fully addressed.']",4,3,3,3,Reject
BlyXYc4wF2-,"The paper introduces two novel algorithms, Multi-Agent Constrained Policy Optimization (MACPO) and MAPPO-Lagrangian, designed to address safety constraints in multi-agent reinforcement learning (MARL). The authors also propose the Safe Multi-Agent MuJoCo benchmark suite for testing these safety-aware MARL methods. Theoretical guarantees for both safety and performance improvement are claimed, and empirical results are provided to validate these claims.","['Can the authors provide more details on the scalability of the proposed algorithms in real-world applications?', 'How do the proposed methods perform in more diverse and complex environments beyond the provided benchmark suite?', 'What are the potential negative societal impacts of deploying these algorithms in safety-critical applications?']","['The scalability of the proposed algorithms is not thoroughly discussed, which is crucial for real-world applications.', 'The potential negative societal impacts of using these algorithms in safety-critical applications are not adequately addressed.']",False,3,2,3,6,4,"['Introduces two novel algorithms for safe MARL, addressing a crucial aspect of real-world applications.', 'Proposes a new benchmark suite, Safe Multi-Agent MuJoCo, which fills a gap in existing resources for evaluating safety-aware MARL methods.', 'Claims theoretical guarantees for both safety and performance improvement, supported by detailed mathematical formulations.']","['The clarity and organization of the paper are suboptimal, making it difficult to follow the methodology and results. For instance, the mathematical formulations are dense and not well-explained, which could hinder understanding.', 'The empirical evaluation is limited, with comparisons made only against a few baselines. More diverse and complex environments could provide a better assessment of the proposed methods.', 'Potential limitations and negative societal impacts are not adequately addressed, particularly concerning the scalability and real-world applicability of the proposed methods.']",3,3,2,3,Reject
Dup_dDqkZC5,"The paper proposes Latent Variable Sequential Set Transformers (AutoBots) for joint multi-agent motion prediction. The model uses temporal and social multi-head self-attention mechanisms to generate scene-consistent trajectories. Extensive theoretical analysis and empirical validation are provided, showing strong performance on multiple benchmarks, including nuScenes, Argoverse, TrajNet++, and Omniglot.","['Could the authors provide more details or visualizations to clarify the model architecture and the flow of data?', 'What are the potential limitations or failure cases when generalizing this approach to more complex environments or other domains?', 'How does the choice of context encoding (like using CNNs for map information) impact the overall performance? Are there other encoding strategies that were considered?', 'Can the authors provide more details on the training stability and convergence of the model?', 'How does the model handle edge cases where agent trajectories are highly unpredictable?', 'Can the authors elaborate on the potential societal impacts and ethical considerations of deploying such models in real-world scenarios?', 'Can the authors provide more detailed comparisons to state-of-the-art methods, highlighting the advantages of AutoBots?', 'How does the model perform in real-world applications, particularly in safety-critical scenarios?', 'Can the theoretical analysis, particularly the permutation equivariance proof, be better integrated into the main text for improved clarity?', 'Can you provide more clarity on how your approach differs from existing transformer-based methods?', 'How does your method handle scenarios with a large number of agents?', 'Can you elaborate on any limitations or potential negative societal impacts not discussed in the paper?', 'Can the authors provide more details on the training objective and how the latent variables are integrated into the model?']","['The approach is limited to settings where a perceptual pipeline provides structured sets representing entities.', 'Memory limitations may restrict the number of sets processed simultaneously.', 'Errors or unknown entities not captured by the input sets would not be modeled.', ""The model's performance might degrade with a significant increase in the number of agents or the input sequence length."", 'Handling real-world sensor noise and occlusions is not discussed.', ""The reliance on structured sets might limit the model's applicability in unstructured environments."", 'The impact of errors or unknown entities in the perceptual pipeline is not addressed.', 'Potential negative societal impacts include the misuse of trajectory prediction in surveillance or autonomous weapon systems.']",False,3,2,3,5,4,"['Novel introduction of Latent Variable Sequential Set Transformers (AutoBots) for multi-agent motion prediction.', 'Thorough theoretical analysis including proofs of permutation equivariance.', 'Strong empirical results across multiple datasets (nuScenes, Argoverse, TrajNet++, Omniglot).', 'Computationally efficient, trainable on a single desktop GPU.']","['Paper is dense with technical details, which might be challenging for some readers.', 'Limited ablations on different context encoding strategies.', 'Discussion on generalization to other domains or complex environments could be expanded.', 'The clarity of some sections, particularly the mathematical notations and proofs, could be improved.', 'Potential limitations in scalability and handling real-world complexities.', 'Comparative significance with state-of-the-art methods needs more emphasis.', 'Complexity of the model might pose reproducibility issues.', 'Theoretical analysis and proofs are not well-integrated into the main paper.', 'Comparisons to state-of-the-art methods could be more comprehensive.', 'The impact on real-world applications and advantages over existing methods are not entirely clear.']",3,3,2,3,Reject
x4tkHYGpTdq,"The paper introduces the Dually Sparsity-Embedded Efficient Tuning (DSEE) framework to fine-tune large pre-trained language models efficiently by leveraging sparsity in both weight updates and final model weights. The method combines low-rank decomposition and magnitude-based pruning to achieve parameter and resource efficiency. Extensive experiments demonstrate the effectiveness of DSEE across various models (BERT, GPT-2, DeBERTa) and datasets, showing significant savings in computation and memory with competitive performance.","['Can the authors provide more details on the hyperparameter choices, such as the values for r and N?', 'How does the proposed method perform on tasks beyond NLP, such as computer vision or multi-modal tasks?', 'What are the potential limitations of the proposed method in practical deployment scenarios?', 'Can the authors provide additional baselines for comparison to further validate the effectiveness of DSEE?', 'How does the choice of hyperparameters affect the performance of DSEE?', 'Can the authors clarify the ethical considerations and limitations of their work in a more detailed manner?', 'Can the authors provide a more detailed ablation study to isolate the contributions of different components of the proposed method?', 'How does the proposed method perform in real-world deployment scenarios?', 'Can the authors provide more intuitive explanations or visual aids to help understand the complex methodology?', 'Can the authors provide more details on the statistical significance of their results?', 'What are the potential negative societal impacts of this work?', 'How reproducible are the sparse matrix generation methods?', 'Can the authors elaborate on the potential negative societal impacts of their method?', 'How does the method perform on other types of models beyond language models?', 'Can the authors provide more details on the computational overhead introduced by the proposed method?']","['The paper does not discuss the potential negative societal impacts of deploying sparse models in resource-constrained environments.', ""The method's performance on tasks beyond NLP is not evaluated, which limits the generalizability of the results."", ""The method's complexity may hinder reproducibility and practical implementation."", 'The impact of hyperparameter choices on performance is not thoroughly explored.', 'The potential negative societal impacts of making large models more accessible are not discussed.', 'The paper does not adequately address potential limitations in the scalability of the proposed method to even larger models.', 'The impact on real-world applications is not thoroughly discussed.', 'Sparse matrix generation methods may impact reproducibility.']",False,3,3,3,6,4,"['Addresses a significant problem in fine-tuning large pre-trained language models.', 'Combines low-rank decomposition and magnitude-based pruning innovatively.', 'Demonstrates significant parameter and resource efficiency gains.', 'Extensive experimental validation across multiple models and datasets.']","['Lacks detailed explanations and justifications for some choices, such as the specific values for hyperparameters.', 'Some claims are not fully supported by theoretical or empirical evidence.', 'Insufficient discussion on potential limitations and societal impacts.', 'Presentation could be improved for better clarity and organization.', 'Methodology involves multiple complex components which could be simplified.', 'Experimental comparisons could include more baselines for robustness.', 'Reproducibility is limited by the complexity of the method and lack of detailed hyperparameter settings.', 'Lacks thorough ablation studies to isolate contributions of different components.', 'Mathematical formulations and algorithms need more rigorous justification.', 'Impact on real-world applications and deployment scenarios is not clearly demonstrated.', 'Some experimental results are not statistically significant.', 'Sparse matrix generation methods may impact reproducibility.']",3,3,3,3,Reject
Rupm2vTg1pe,"The paper introduces the Infinite Contextual Graph Markov Model (ICGMM), an extension of the Contextual Graph Markov Model (CGMM) that uses Hierarchical Dirichlet Processes (HDPs) to automatically determine the latent state size of each layer. The model is evaluated on eight graph classification tasks, showing competitive performance against supervised methods.","['Can the authors provide more details on how the approximate inference procedure trades off between accuracy and speed?', 'How does the model perform when edge features are included, and are there plans to incorporate edge features in future work?', 'Can the authors clarify the main differences between ICGMM and other Bayesian nonparametric models for graph processing?', 'Can the authors provide more details on how the Gibbs sampling complexity can be managed for very large datasets?', 'How does the model handle varying sizes and complexities of graphs in practice?', 'What are the potential ethical impacts of this work, if any?', 'Can the authors provide more details on the reproducibility of the results given the computational complexity of the model?']","['The naive Gibbs sampling approach does not scale well to very large datasets.', 'The model currently does not account for edge features, which could limit its applicability in certain tasks.', ""Reproducibility might be challenging due to the model's computational complexity."", 'The ethical considerations and potential negative societal impacts are not discussed in sufficient detail. Potential negative societal impacts could include misuse of the model for malicious purposes or biases in the data leading to unfair outcomes.']",True,3,3,3,5,4,"['Novel extension of CGMM using HDPs.', 'Automatic adjustment of model complexity without extensive hyper-parameter tuning.', 'Competitive performance on graph classification tasks compared to supervised methods.', 'Introduction of a faster approximate inference procedure.']","['Scalability issues with the naive Gibbs sampling approach.', 'Exclusion of edge features in the model.', 'Some sections, especially the technical details, lack clarity and could be better explained.', 'Potential ethical impacts and limitations are not thoroughly discussed.']",3,3,3,3,Reject
RB_2cor6d-w,"The paper proposes APSyn, a method for generating imperceptible adversarial attacks using multi-patch perturbations. APSyn leverages program synthesis and numerical optimization to create targeted attacks with fewer perturbed pixels compared to the C&W attack. The method is evaluated on MNIST, Fashion-MNIST, CIFAR-10, and ImageNet, showing high success rates and lower L0 distortion.","['Can the authors provide more details on the gradient estimation process for discrete variables?', 'How does the proposed method perform in a real-world physical setting, beyond the datasets evaluated?', 'What specific measures can be taken to mitigate the potential negative societal impacts of the proposed method?', 'What are the reasons behind the choice of certain hyperparameters? Can the authors provide more justification?', 'Have the authors considered validating their approach through real-world physical experiments?', 'Can the authors provide more details on the hyperparameter settings and how they were chosen?', 'Could the authors clarify the initialization process for patches in more detail?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the authors provide more clarity on how the gradient estimation for discrete variables is implemented?', 'How does APSyn compare to other state-of-the-art physical adversarial attacks beyond C&W?', 'What specific steps can be taken to mitigate the potential negative societal impacts of this work?', 'Can the authors provide more insights into the potential real-world applicability and robustness of APSyn-generated attacks?']","['The method has not been evaluated in real-world physical settings, which limits its practical applicability.', 'The paper does not sufficiently address the potential negative societal impacts of adversarial attacks.', 'Some sections of the paper lack clarity and could benefit from more detailed explanations.', ""The method's applicability to real-world scenarios is not thoroughly explored.""]",True,3,2,3,5,4,"['Introduces a novel combination of program synthesis and numerical optimization for adversarial attacks.', 'Demonstrates high success rates and competitive performance on multiple datasets.', 'Achieves significantly lower L0 distortion, making the attacks more practical for physical execution.']","['The novelty of the approach may be overstated as it builds on existing methods.', 'Clarity and organization of the paper could be improved, especially in explaining the technical details.', 'Potential negative societal impacts and ethical considerations are not sufficiently addressed.', 'Dense technical details and mathematical notation hinder readability.', 'Assumed success in physical implementations without real-world validation.', 'Some hyperparameters and choices lack sufficient justification.', 'The evaluation methodology could benefit from additional baselines for comparison.', 'The potential for real-world application and the significance of the results are not convincingly demonstrated.']",3,3,2,3,Reject
0uZu36la_y4,"The paper introduces Class Focused Online Learning (CFOL) to address the issue of uneven class performance in adversarial training. By leveraging the Exponential-weight algorithm for Exploration and Exploitation (Exp3), CFOL adaptively focuses on the weakest classes, improving their performance without significant computational overhead. The method provides high probability convergence guarantees and demonstrates significant improvements in the performance of the weakest classes across multiple datasets.","['Could the authors provide more details on the hyperparameter tuning process for CFOL and the baselines?', 'How sensitive is CFOL to the choice of the step-size η and the uniform mixing parameter γ?', 'Have the authors considered applying CFOL in non-adversarial settings, and if so, what are the preliminary results?', 'Can the authors elaborate on the computational complexity of CFOL compared to traditional adversarial training methods?', 'Are there any specific scenarios where CFOL might not perform well or might introduce new vulnerabilities?', 'Can the authors provide more empirical results on other datasets and attack scenarios?', 'How does the method perform under different adversarial attack strengths?', 'Can the authors discuss the potential negative societal impacts of their method?']","['The paper acknowledges the limitation of potential reduction in clean accuracy due to temporal ensembling.', 'The implementation complexity due to batch normalization in deep learning models is noted but could be further elaborated.', ""The method's novelty is somewhat limited as it combines existing algorithms."", 'Empirical evaluation lacks depth in terms of a broader range of datasets and attack scenarios.', 'The paper does not sufficiently address potential negative societal impacts.']",False,3,3,3,7,4,"['The problem of uneven class performance in adversarial training is well-motivated and novel.', 'The use of Exp3 provides high-probability convergence guarantees for the worst class loss.', 'The empirical results show significant improvements in the performance of the weakest classes across multiple datasets.', 'The method is compatible with existing adversarial training setups.']","['The paper is dense and some sections could benefit from additional explanations and better structuring.', 'More details on hyperparameter tuning and specific experimental setups could improve reproducibility.', 'Additional comparison with more recent state-of-the-art methods in adversarial training would strengthen the case for CFOL.', 'Insufficient discussion on potential trade-offs in average performance and computational complexity.', 'Limited novelty as it combines existing algorithms.', 'Empirical evaluation lacks depth and variety.', 'Insufficient discussion on potential negative societal impacts.']",3,3,3,3,Accept
AAeMQz0x4nA,"The paper proposes a novel method called Explicit Credit Assignment joint Q-learning (ECAQ) for multi-agent systems. Unlike existing methods that implicitly learn credit assignment, ECAQ explicitly optimizes an assignment function to distribute rewards among agents based on their contributions. Theoretical foundations are provided, and the method is empirically evaluated on StarCraft II maps and a cooperative navigation task.","['How does ECAQ perform in more diverse environments beyond StarCraft II and cooperative navigation?', 'Can the method be scaled to handle larger multi-agent systems effectively?', 'How do the authors plan to address the ethical considerations related to sacrificing certain agents for optimal joint actions?', 'Can the authors provide more details on the hyperparameter tuning process for ECAQ?', 'How does ECAQ perform when integrated with more advanced architectures like Qatten or QPLEX?']","['Scalability issues for large-scale agents due to computational complexity.', 'Limited applicability to non-monotonic payoffs.', 'Potential ethical concerns related to agent sacrifice in cooperative settings.', 'The method is limited to fully cooperative settings and may raise ethical issues when optimal joint actions require sacrificing certain agents.', 'The method struggles with non-monotonic payoffs due to non-negative constraints on the transformation network and weighting vectors.']",True,4,3,4,7,4,"['Novel approach to explicit credit assignment in multi-agent systems.', 'Strong theoretical grounding and detailed methodology.', 'Comprehensive experimental validation on challenging benchmarks.', 'Good performance compared to advanced baselines.', 'Interpretability of credit assignments.']","['Scalability issues for large-scale agents due to computational complexity.', 'Limited applicability to non-monotonic payoffs.', 'Potential ethical concerns related to agent sacrifice in cooperative settings.', 'Empirical validation is limited to a few specific environments.', 'The paper is dense with complex mathematical formulations, making it less accessible.']",4,4,3,4,Reject
PGGjnBiQ84G,"The paper proposes a novel approach to learn texture mapping for 3D surfaces and applies it to document image unwarping. The method uses a continuous bijective mapping between 3D surface positions and 2D texture-space coordinates, implemented through a differentiable rendering pipeline. The approach shows promising results in document unwarping and texture editing.","['Can the authors provide more experimental results on diverse document shapes and textures?', 'What are the potential negative societal impacts and ethical considerations of the proposed texture editing application?', 'Can the authors suggest ways to reduce the training time to make the method more practical?', 'Can you provide more details on the computational resources required for training?', 'How does the method generalize to other types of documents or textures?', 'What measures can be taken to mitigate the potential ethical misuse of the document editing capabilities?', 'Can the authors provide more details on how the forward-backward MLPs are initialized and trained?', 'What are the specific limitations of the proposed method in terms of scalability and generalizability?', 'How does the method compare to other state-of-the-art techniques in terms of computational efficiency?']","['The high training time makes it unsuitable for real-time applications.', 'Potential negative societal impacts of texture editing are not well addressed.', 'Method may not generalize well to other domains such as garments or faces without significant modifications.', 'Potential negative societal impact due to the ability to edit real documents and possibly alter their content maliciously.', 'Relatively fewer views available for real-world scenarios, leading to worse performance.']",True,3,2,3,5,4,"['Novel approach to learn surface parameterization for implicit neural representations.', 'Achieves state-of-the-art results in document unwarping.', 'Allows for texture editing applications.', 'Significant improvement in OCR performance.', 'Effective use of multi-view images for training.']","['Insufficient experimental validation across diverse scenarios.', 'High training time, making it impractical for real-time applications.', 'Lack of discussion on potential negative societal impacts and ethical considerations.', 'Clarity and organization of the methodology section can be improved.', 'Limited generalizability to other domains without significant modifications.']",4,3,2,3,Reject
xDIvIqQ3DXD,"The paper presents a theoretical analysis of the approximation properties of recurrent encoder-decoder architectures, focusing on their universal approximation capabilities in linear settings. It introduces the concept of a temporal product structure and provides detailed mathematical proofs and some numerical experiments to illustrate the theoretical claims.","['Can the authors provide more extensive empirical validation to support their theoretical claims?', 'How can the results be extended to non-linear settings?', 'Can the authors provide more intuitive explanations or visualizations to help understand the concept of temporal product structure?', 'How would the theoretical insights guide practical applications in real-world scenarios?']","['The results are primarily limited to linear settings.', 'The paper is very dense and may not be accessible to a broad audience.', 'Limited discussion on practical implications and how the theoretical results can be applied in real-world scenarios.']",False,3,3,3,5,4,"['Addresses a significant theoretical gap.', 'Introduces the novel concept of a temporal product structure.', 'Provides detailed mathematical proofs and thorough theoretical analysis.']","['The paper is dense and difficult to follow, limiting accessibility.', 'Scope is restricted to linear settings, which may limit practical applicability.', 'Limited empirical validation and practical implications discussed.']",3,3,3,3,Reject
NrB52z3eOTY,"The paper presents a method for effective uncertainty estimation in classifiers using evidential models. The authors introduce KLoS, a Kullback-Leibler divergence criterion, and KLoSNet, an auxiliary neural network to refine this criterion. The methods are evaluated on various datasets and compared against existing uncertainty measures, demonstrating superior performance.","['How sensitive are the methods to the choice of hyperparameters?', 'Can the authors provide more details on the computational complexity of KLoSNet?', 'Are there any plans to release the code and datasets to improve reproducibility?', 'Can the authors provide more practical real-world scenarios where KLoSNet can be applied?', 'How does the method perform in non-visual recognition tasks?', 'Can the authors clarify the computational overhead of integrating KLoSNet compared to existing methods?', 'Can you provide more details on the training procedure for KLoSNet, especially regarding the choice of hyperparameters?', 'How does the performance of KLoSNet compare to simpler uncertainty estimation methods in terms of computational efficiency?', 'Can you elaborate on the theoretical derivation of KLoS and how it aligns with the training objective?', 'Can you provide more theoretical backing for the properties of KLoS?', 'How does KLoSNet perform compared to other state-of-the-art methods on different datasets?', 'What are the potential negative societal impacts of your method?', 'Can the authors provide more detailed comparisons with a wider range of existing uncertainty estimation methods?', 'How do the authors address the potential overlap of their contributions with existing methods?', 'Can the authors clarify the derivation and explanation of KLoS and KLoSNet?', 'How robust is the proposed method under different data distributions and real-world conditions?', 'Can the authors discuss the ethical and societal impacts of their method in more detail?']","['The methods introduce additional complexity and computational overhead, which may not be suitable for all applications.', 'The reliance on multiple hyperparameters requires careful tuning, which may not be straightforward.', 'The paper does not thoroughly address the potential negative societal impacts of deploying these methods in real-world applications.', 'The complexity of the method may hinder its practical adoption.', 'Potential limitations in generalizing the results beyond the datasets used in the experiments.', 'The need for further validation on robustness under different conditions and datasets.', 'The paper does not address the potential computational overhead introduced by KLoSNet.', 'The method is primarily evaluated on image datasets; it would be beneficial to see results from other domains.', 'There is a lack of discussion on the potential negative societal impacts of the proposed method.', 'Theoretical properties of KLoS need more exploration.', 'Potential negative societal impacts not discussed.', 'The paper does not provide a thorough comparison with a broad range of existing techniques.', 'The novelty and significance of the contributions need clearer justification.', ""The method's robustness under various conditions requires further validation."", 'Ethical and societal impacts are not adequately addressed.']",False,3,3,3,6,4,"['Introduces a novel measure (KLoS) for capturing uncertainties without requiring OOD training data.', 'Proposes an auxiliary neural network (KLoSNet) to refine the uncertainty estimation.', 'Thorough evaluation on multiple datasets and architectures.', 'Clear and well-organized presentation with detailed explanations.']","['Complexity of the proposed methods may hinder practical implementation.', 'The paper relies on multiple hyperparameters, and the sensitivity to these parameters is not thoroughly analyzed.', 'Reproducibility is limited since the code and datasets are not provided.', 'The paper is dense and complex, potentially hindering reproducibility and understanding.', 'The significance of the contribution may be seen as incremental given existing literature.', 'Lack of practical real-world scenarios in evaluation, which could limit the generalizability of the results.', 'The robustness of the proposed method under different conditions and datasets needs further validation.', 'Some methodological details are not clearly explained, making it hard to reproduce the results.', 'The evaluation could benefit from more diverse datasets and more detailed ablation studies.', 'The impact of KLoSNet compared to simpler baselines is not always clear.', 'Theoretical properties of KLoS not fully explored.', 'Limited discussion on potential negative societal impacts.']",3,3,3,3,Reject
rMbLORc8oS,"The paper proposes SemiRetro, a hybrid framework combining template-based and template-free methods for retrosynthesis prediction. It introduces semi-templates and a Directed Relational Graph Attention (DRGAT) layer, which reportedly improve scalability, accuracy, and interpretability. Experimental results on the USPTO-50k dataset demonstrate that SemiRetro outperforms state-of-the-art methods in both top-1 and top-k accuracy for center identification and synthon completion. The method aims to reduce template redundancy while preserving essential chemical knowledge, and it integrates these semi-templates into a two-step template-free framework.","['Can the authors provide more insights into the novelty of the DRGAT layer compared to other GNN architectures?', 'How does SemiRetro perform on larger datasets beyond USPTO-50k?', 'Are there any specific limitations or negative societal impacts that should be considered?', 'Can the authors provide empirical evidence to support the claim of better interpretability, such as case studies or visualizations?', 'What evidence supports the practical utility of semi-templates in real-world retrosynthesis applications?']","['The paper does not address the potential limitations and negative societal impacts of using SemiRetro in detail.', 'Scalability claims are based on a single dataset; further validation on larger datasets is needed.', 'The practical utility of semi-templates in real-world scenarios is not well-supported by evidence.']",False,3,3,3,6,4,"['Combines the strengths of template-based and template-free methods.', 'Introduces semi-templates to reduce redundancy and improve interpretability.', 'Uses a novel DRGAT layer to enhance feature extraction.', 'Demonstrates significant improvement in accuracy and scalability over state-of-the-art methods.', 'Comprehensive experiments with detailed results and comparisons.']","['The novelty of the DRGAT layer is not thoroughly justified compared to existing GNN variants.', 'Limited discussion on the potential limitations and negative societal impacts of the proposed method.', 'The scalability claims, while supported by data, might need further validation on larger datasets.', 'The paper could benefit from more detailed ablation studies to isolate the contributions of different components.', 'The claim of better interpretability lacks empirical evidence, such as case studies or visualizations.']",3,3,3,3,Reject
U-_89RnR8F,"The paper introduces Conceptual Counterfactual Explanations (CCE), a method that combines counterfactual explanations with Concept Activation Vectors (CAVs) to explain model mistakes using human-understandable concepts. The method is validated on standard datasets and medical imaging applications, showing its ability to identify spurious correlations and biases without needing access to training data.","['How does the performance of CCE vary with the richness of the concept bank?', 'Can the authors provide more details on the optimization procedure, especially the handling of validity constraints?', 'What are the potential negative societal impacts of deploying CCE in real-world applications?', 'Could the authors provide a more detailed comparison with existing methods?', 'How does the quality of the concept bank affect the performance of CCE?', 'Can the authors discuss potential limitations and negative societal impacts of their method in more detail?', 'Can the authors simplify or provide more clarity on the optimization process for generating counterfactual explanations?', 'How does CCE compare quantitatively with other existing explanation methods?', 'Can the authors provide more detailed examples of how CCE explanations are used in practice?', 'What are the main limitations of CCE in terms of scalability and applicability to different data modalities?', 'Can the authors provide more details on the parameter choices and their justifications?', 'How does the method scale with larger, more complex datasets?', 'Can the authors clarify the explanation generation process with additional examples or visualizations?', 'How does CCE perform compared to other state-of-the-art explanation methods?', 'Can the authors provide more details on how the concept library is constructed and how its quality impacts the results?', 'What measures can be taken to ensure the validity and meaningfulness of the explanations provided by CCE?']","['The method relies heavily on the quality and comprehensiveness of the concept bank.', 'Possible misinterpretations of the concepts suggested by CCE.', 'Potential biases introduced by manually defined or automatically discovered concepts need to be addressed.', 'Ensuring the validity and meaningfulness of the explanations is a challenge that requires further exploration.', 'The scalability of the method for large-scale datasets is not thoroughly discussed.', 'Potential negative societal impacts, such as misinterpretation of explanations by non-experts, should be considered.']",False,3,3,3,6,4,"['Innovative combination of counterfactual explanations and Concept Activation Vectors (CAVs).', 'Does not require access to training data, making it applicable in various scenarios.', 'Validated on diverse datasets, including real-world medical applications.', 'Publicly available code, promoting reproducibility.']","['Dependence on the quality and comprehensiveness of the concept bank.', 'Some mathematical formulations and optimization details are not fully clear.', 'Lack of detailed comparison with existing methods.', 'Insufficient discussion on limitations and potential negative societal impacts.', 'Complexity in understanding the optimization process for generating counterfactual explanations.']",3,3,3,4,Reject
Qu_XudmGajz,"The paper proposes an enhancement to the observational distribution in Variational Autoencoders (VAEs) by using a low-rank parameterization that captures spatial dependencies between pixels. This approach aims to produce more realistic and spatially coherent samples compared to the conventional pixel-wise independent distributions. The authors provide both qualitative and quantitative evaluations, demonstrating the effectiveness of their method. Furthermore, they illustrate interactive editing capabilities and interpolation in the observation space.","['Can the authors provide more details on the stability issues encountered during training and how they were mitigated?', 'How does the proposed method compare to other state-of-the-art VAE variants in terms of image quality?', 'Can the authors clarify the computational cost of their method compared to standard VAEs?', 'How does the proposed method scale with larger datasets and higher resolution images?', 'Can the authors discuss the potential impact of their method on downstream tasks beyond image synthesis?']","['The method introduces stability issues that require additional constraints to resolve.', 'The evaluation metrics used have known limitations and may not fully capture the improvements in sample quality.', 'Potential biases inherited from the datasets used (e.g., CELEBA) which may affect the generalizability of the results.', 'The scalability of the proposed method to larger datasets and higher resolution images is not thoroughly evaluated.']",False,3,3,3,5,4,"['Addresses an overlooked aspect of VAE architectures by focusing on the observational distribution.', 'Introduces a low-rank parameterization to model spatial dependencies, resulting in more realistic and spatially coherent samples.', 'Provides both qualitative and quantitative evaluations.', 'Demonstrates interactive editing capabilities and interpolation in the observation space.', 'Comprehensive theoretical background and justifications.']","['Technical soundness is questionable due to the instability issues encountered and the reliance on additional constraints.', 'The clarity of the paper could be improved, particularly in the explanation of the methods and the experimental setup.', 'The evaluation metrics used (FID) are known to have limitations, and the results are not entirely convincing.', 'Potential scalability issues with larger datasets and higher resolution images.', 'Limited discussion on computational overhead.']",3,3,3,3,Reject
GrFix2vWsh4,"The paper provides a theoretical analysis linking Cross-Entropy (CE) and Dice losses for segmentation tasks, revealing hidden label-marginal biases in each. It proposes a new combined loss function integrating CE with explicit L1 regularization to control label-marginal bias. Extensive experiments on medical and natural image datasets validate the proposed method.","['Can the authors provide a more intuitive explanation of the theoretical analysis?', 'How does the proposed method perform on datasets other than medical imaging and Cityscapes?', 'Are there any scenarios where the proposed combined loss might not perform well?', 'Could the authors provide more clarity on the proof techniques used in the theoretical analysis?', 'Have the authors considered additional benchmarks to further validate their approach?', 'Are there potential applications beyond segmentation where the proposed loss could be beneficial?', 'How does the proposed method compare to other state-of-the-art methods not included in the current experiments?', 'Can the authors provide more details on the computational overhead introduced by the L1 regularization?']","['The proposed method might be computationally more expensive due to the need for additional regularization terms.', 'Potential lack of generalization across different types of segmentation tasks not covered in the experiments.', 'The paper does not deeply discuss potential limitations and negative societal impacts of the proposed method. For example, how does the method handle different types of class imbalances in real-world scenarios? Are there any potential biases introduced by the regularization terms?']",False,3,3,3,6,4,"['Novel theoretical insights linking CE and Dice losses.', 'Comprehensive experimental validation on multiple datasets.', 'Practical solution to address class imbalance in segmentation tasks.']","['Theoretical analysis is dense and may be hard to follow.', 'Limited explanation on how intuitive the proposed method is for practitioners.', 'Experiments could be extended to more diverse datasets to ensure generalizability.', 'The connection between CE and Dice is insightful but not entirely novel.', 'Potential limitations and societal impacts are not deeply discussed.']",4,3,3,3,Reject
pzgENfIRBil,"The paper proposes a novel method, Self-consistent Gradient-like Eigen Decomposition (SCGLED), to solve approximated Schrödinger equations without relying on domain-specific heuristics for initial guesses. It adapts techniques from stochastic k-PCA for iterative eigen decomposition. The method aims to treat the eigenvalue problem as an online learning task and demonstrates its efficacy through empirical results.","['Can the authors provide more theoretical analysis or guarantees for the proposed method?', 'Have the authors considered evaluating the method on a wider range of datasets or quantum systems?', 'Can the paper be restructured for better clarity and readability, especially in the mathematical sections?', 'How does SCGLED perform on real-world datasets beyond the W4-17 dataset?', 'What are the potential limitations and ethical concerns associated with SCGLED?', 'How sensitive is the method to the choice of hyperparameters such as the learning rate and damping factor?', 'Could the authors provide more details on the algorithm and experimental setup to improve reproducibility?']","['Theoretical assumptions may not hold in practice.', 'Limited scope of empirical evaluation.', 'Potential negative societal impacts are not addressed.', 'The convergence analysis is not rigorous, relying on heuristics.', 'The empirical evaluation, while promising, needs more extensive comparison with recent methods.']",False,2,2,3,4,4,"['Novel approach to solving self-consistent eigenvalue problems.', 'Eliminates the need for domain-specific heuristics.', 'Promising empirical results showing performance improvements over traditional methods.', 'Potential to generalize to other scientific computing problems.']","['Lack of strong theoretical guarantees and convergence proofs.', 'Limited evaluation on a specific dataset without broader comparisons.', 'Clarity and structure of the paper need improvement.', 'Insufficient discussion on potential negative societal impacts.', 'Complex notation and presentation could be clearer.', 'Overstated claims without addressing limitations.']",4,2,2,3,Reject
Mlwe37htstv,"The paper introduces Wasserstein Policy Optimization (WPO) and Sinkhorn Policy Optimization (SPO), two novel extensions of policy optimization in reinforcement learning that use Wasserstein and Sinkhorn trust regions respectively. The contributions include theoretical guarantees of monotonic performance improvement and convergence properties, the derivation of closed-form policy updates, and empirical evaluations in tabular domains and robotic locomotion tasks.","['Can you provide more details on the computational complexity of WPO and SPO compared to TRPO and PPO?', 'How sensitive are the results to the choice of hyperparameters, especially for the entropic regularizer in SPO?', 'Could you include additional baselines in the empirical evaluation to strengthen the comparative analysis?', 'Can the authors clarify the main differences and novelties of their approach compared to existing works on Wasserstein metrics in RL?', 'Can the authors provide more intuitive explanations for their theoretical results?', 'How do the proposed methods perform in more complex and high-dimensional tasks compared to the benchmarks?', 'Can the authors clarify the hyperparameters, network architectures, and other implementation specifics to improve reproducibility?', 'How do the methods perform under different settings of the entropic regularizer for SPO?', 'Can the authors provide more details on how the proposed methods scale with larger state and action spaces?', 'Are there any practical considerations or limitations when implementing WPO and SPO in real-world applications?']","['The paper does not sufficiently address the computational costs associated with the proposed methods.', 'There is limited discussion on the scalability of the methods to larger state and action spaces.', 'Potential negative societal impacts are not discussed.', 'Reproducibility is hampered by the lack of detailed implementation specifics.']",False,3,3,3,6,4,"['Novel use of Wasserstein and Sinkhorn metrics for policy optimization.', 'Theoretical guarantees of performance improvement and convergence.', 'Derivation of closed-form policy updates.', 'Empirical results showing improved performance over TRPO and PPO.']","['Incremental novelty given existing work on Wasserstein metrics in RL.', 'Empirical evaluations lack comparisons with a broader range of baseline methods.', 'The paper is dense and difficult to follow in parts, especially in the theoretical sections.', 'Limited discussion on the practical implications and computational costs.', 'Insufficient details on hyperparameters, network architectures, and implementation specifics for reproducibility.', 'Potential negative societal impacts are not discussed.']",3,3,3,4,Reject
nKWjE4QF1hB,The paper introduces a Proof Cost Network (PCN) to modify the AlphaZero algorithm's objective from winning to solving games quickly. The authors propose two training targets aimed at finding the shortest path to a solution and estimating the proof cost. Experiments on 15x15 Gomoku and 9x9 Killall-Go problems show that PCN outperforms standard AlphaZero networks in game-solving tasks.,"['Can the authors provide more detailed descriptions of the hyperparameters used in the experiments?', 'How do the authors ensure that the generated problem sets are unbiased and represent a fair comparison between PCN and AlphaZero?', 'What are the potential negative societal impacts of this research, and how can they be mitigated?', 'Can the authors provide more theoretical justification for the modifications made to the AlphaZero algorithm?', 'How sensitive are the results to the choice of parameters for PCN, and were any hyperparameter tuning techniques used?', 'Can the authors provide more details on the experimental setup, specifically how the problems were generated and the criteria for success?', 'What are the potential applications of this approach beyond the two specific games tested?', 'Can the authors provide more detailed explanations of the mathematical formulations and algorithm descriptions?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'Can the authors provide more clarity on how the Proof Cost Network differs fundamentally from existing heuristics?', 'How does the approach generalize to other games or domains beyond the ones tested?', 'Can you provide more details on how the training targets for the PCN were derived?', 'How does the choice of heuristics impact the performance of the PCN?', 'What are the potential limitations of using PCN in other games or applications?']","['The paper does not address potential negative societal impacts.', 'Limited discussion on the scalability of the proposed approach to other games or larger game boards.', 'Reproducibility concerns due to insufficient details on hyperparameters and training protocols.', 'Scalability to more complex games or real-world applications is not addressed.', 'Potential negative societal impacts of using game-solving techniques in other domains are not discussed.', 'The computational resources required for training the PCN are significant, which could limit the accessibility of the approach.', 'The approach may not generalize well to other types of games or problem domains without significant modifications.']",False,2,2,3,5,4,"['Novel approach to modifying AlphaZero for game-solving tasks.', 'Comprehensive experiments on 15x15 Gomoku and 9x9 Killall-Go.', 'Clear explanation of the proposed PCN and its integration with existing algorithms.', 'Addresses an important problem of game solving, distinct from game playing.']","['The experimental setup lacks clarity and detailed descriptions are deferred to appendices.', 'Limited discussion on potential negative societal impacts.', 'Reproducibility concerns due to lack of detailed hyperparameter settings and training protocols.', 'The comparison between PCN and standard AlphaZero is not entirely fair, as the problems generated might be biased.', 'Lacks thorough theoretical foundation for the proposed modifications.', 'Presentation is cluttered and lacks clarity.', 'Impact and generality of results are not well demonstrated.', 'Incremental novelty, building on existing techniques like AlphaZero and proof number search.', 'Dense sections that could benefit from clearer explanations.']",3,2,2,3,Reject
H4EXaI6HR2,The paper proposes a novel architecture for modeling the cost-to-go function in electrical power systems using a series of neural networks with time-dependent parameters. The method aims to handle the complexity of country-scale power grids that include renewable and traditional energy sources. The proposed model is evaluated on the Uruguayan power grid and is shown to outperform the currently used backward dynamic programming method both in terms of cost and computational efficiency.,"['Can the authors provide a clearer explanation of the parametric network series and how the parameters are learned?', 'How does the proposed method generalize to other power systems with different characteristics?', 'Can the authors provide additional results to demonstrate the robustness of their method?', 'What specific measures were taken to ensure the interpretability of the model?', 'Can the authors provide more detailed comparisons with other state-of-the-art methods?', 'What are the specific challenges faced in extending the method to medium and long-term scenarios?', 'How sensitive is the proposed method to different hyperparameters and initialization choices?', 'Can you provide more rigorous theoretical analysis or proofs to support your claims?', 'Have you tested the proposed method on other datasets or scenarios to demonstrate its generalizability?', 'Can you provide more details on the training process and hyperparameter selection?', 'What specific measures have you taken to ensure the reproducibility of your results?', 'Can you discuss in more detail the potential negative societal impacts of your work?', 'How does the proposed model handle different scales of seasonal patterns (e.g., daily vs. yearly)?', 'What are the limitations of the proposed method in terms of scalability and generalizability to other power grids?', 'Can the authors elaborate on the theoretical guarantees of the proposed method?']","['The evaluation is limited to the Uruguayan power grid, which may not be representative of other power systems.', 'The paper does not discuss potential negative societal impacts of the proposed method.', ""The method's reliance on time-dependent parameters may limit its applicability to scenarios with less predictable patterns."", 'The approach may require frequent retraining, which could offset some computational advantages.', 'Potential negative societal impacts of energy dispatch decisions are not discussed.', 'The generalizability of the method to other datasets or scenarios is not demonstrated.', 'Potential computational overhead due to the complex architecture.']",False,2,2,2,3,4,"['Addresses a complex and relevant problem in electrical power systems.', 'Proposes an innovative combination of neural networks and time-dependent parameters.', 'Demonstrates significant computational efficiency gains over traditional methods.', 'Claims to provide interpretable models which capture general trends in the problem domain.']","['The paper lacks clarity in several sections, particularly in the explanation of the proposed method and its evaluation.', 'The novelty of the contributions is somewhat questionable as similar ideas have been explored in related works.', 'The evaluation is limited to a specific scenario, which raises questions about the generalizability of the results.', 'There are inconsistencies in the presentation, such as unclear diagrams and poorly formatted tables.', 'Lacks rigorous theoretical analysis and proofs.', 'Insufficient comparison with existing methods, especially in terms of performance and applicability.', 'Limited discussion on reproducibility and availability of code or datasets.', 'Potential negative societal impacts are not addressed.']",3,2,2,3,Reject
WQVouCWioh,"The paper introduces DARK, a novel framework for de novo protein design using deep generative models trained on synthetic sequences. The authors claim that DARK can generate protein sequences with diverse and ordered structures, improving on the efficiency of comparable sampling-based approaches. The framework is evaluated using AlphaFold for structural prediction, showing significant improvements over existing methods.","['Can the authors provide more details on the reproducibility of their results?', 'How does DARK compare with other state-of-the-art models not included in the comparison?', 'What are the potential ethical implications of this work, and how can they be mitigated?', 'Can you provide more details on the computational resources required for training DARK models? How feasible is it for other researchers to reproduce your results?', 'Have you considered any experimental validation of the generated sequences? If so, what were the results?', 'Can you discuss in more detail the potential societal and ethical impacts of your work? How do you propose to mitigate any negative consequences?', 'How were the hyperparameters for the iterative training process selected?', 'Can the authors elaborate on the potential biological relevance of the generated protein structures beyond the used evaluation metrics?', 'How does DARK generalize to natural sequences, and what are the performance metrics in such cases?', 'What specific steps were taken to ensure the diversity of the generated sequences? How was this diversity measured and validated?', 'Can the authors provide more insights into the iterative training process and its impact on the final model performance?', 'How does the performance of DARK models vary with different types of synthetic sequences?', 'What are the potential limitations of using AlphaFold as the primary evaluation tool?', 'How does the proposed framework handle potential biases in the synthetic sequence data?', 'Can the authors discuss the potential long-term impacts of their work on the field of protein design?']","['Reproducibility of the results is not guaranteed.', 'Practical applicability and scalability of the approach need further validation.', 'Ethical considerations related to the use of synthetic sequences and potential misuse need to be addressed.', 'The paper relies heavily on computational predictions (e.g., AlphaFold) without extensive experimental validation, which might limit the practical impact of the work.', 'The computational resources required for training DARK models are substantial, potentially limiting accessibility and reproducibility.', 'The discussion on potential societal and ethical impacts is limited. Given the potential for misuse or unintended consequences of designing novel proteins, a thorough examination of these impacts is necessary.']",True,3,3,3,6,4,"['Proposes a novel framework (DARK) for de novo protein design.', 'Uses synthetic sequences to address limitations of natural sequence-based models.', 'Detailed methodology and experimental evaluation.', 'Extensive evaluation using state-of-the-art structure prediction (AlphaFold).', 'Demonstrates practical applicability by designing sequences for specific protein folds.']","['Concerns about reproducibility of results.', 'Evaluation lacks comparison with more diverse baselines.', 'Practical applicability and scalability need further validation.', 'Potential ethical considerations not fully addressed.', 'Heavy reliance on computational predictions without extensive experimental validation.', 'High computational resource requirements may limit accessibility and reproducibility.', 'Some methodological details are unclear, particularly regarding hyperparameters and iterative training setup.']",3,3,3,3,Reject
SgEhFeRyzEZ,"The paper provides a theoretical analysis of the Feedback Alignment (FA) algorithm for deep linear networks, offering convergence guarantees, exploring implicit regularization phenomena, and proposing initialization schemes to mitigate anti-regularization effects. The analysis includes both continuous and discrete-time dynamics.","['Can the authors provide more detailed explanations or examples for some of the key mathematical derivations?', 'How do the assumptions made in the theoretical analysis affect the practical applicability of the results?', 'Can the authors conduct experiments on real-world datasets to demonstrate the practical utility of the theoretical findings?', 'How do your results compare to existing work on implicit regularization?', 'Are there ways to relax some of the assumptions on initialization?', 'Could the authors elaborate more on the potential negative societal impacts and ethical considerations of their work?', 'Can you clarify the notation used in Section 3 to improve readability?']","['The assumptions made in the analysis might limit the applicability of the results to practical scenarios.', 'The experimental validation is limited and does not cover real-world datasets.', 'The paper does not address the scalability of FA to non-linear networks, which is crucial for real-world applications.', 'Limited discussion on the societal impacts of the work. The authors should address the broader implications of using FA in various applications.', 'The technical nature of the paper might make it difficult for practitioners to implement the proposed methods without additional guidance.']",False,3,3,3,6,4,"['Provides rigorous theoretical analysis of FA, including convergence rates.', 'Explores the impact of initialization schemes on learning dynamics.', 'Bridges a gap in literature by offering convergence proofs for deep networks under FA.', 'Addresses both continuous and discrete dynamics, providing a comprehensive view.']","['Assumptions made for simplification might limit practical applicability.', 'Experimental validation is limited and focused on synthetic data.', 'Clarity issues in some mathematical derivations and proofs.', 'Real-world applicability and scalability to non-linear networks are not demonstrated.', 'Dense mathematical exposition may limit accessibility to a broader ML audience.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",3,3,3,4,Reject
WcZUevpX3H3,"The paper proposes FEDPNAS, a personalized Neural Architecture Search (NAS) algorithm for Federated Learning (FL). The algorithm learns a base architecture that can be structurally personalized for quick adaptation to each local task. The contributions include a novel architecture that separates a base and personalizable component, a context-aware sampling distribution, and an FL algorithm that optimizes a common architecture followed by personalization at each client. The empirical results on CIFAR-10 and MNIST datasets show improved performance over existing NAS and FL methods.","['How well would the proposed method generalize to other types of data (e.g., text, time-series)?', 'What are the computational requirements and how does the algorithm scale with the number of clients and tasks?', 'How sensitive is the performance to the choice of hyperparameters?', 'Can you provide more detailed motivation for the need for a personalized NAS in FL, especially compared to existing methods?', 'How does the computational complexity of FEDPNAS compare to standard FL and NAS methods?', 'Can you provide more insights into the theoretical foundations of the proposed method, especially the use of the first-order Taylor approximation?', 'How does the computational overhead of FEDPNAS compare to existing FL methods in real-world applications?', 'Can the authors provide more details on the scalability of FEDPNAS in terms of the number of clients and the size of the datasets?', 'Could the authors elaborate on the potential negative societal impacts and ethical considerations of deploying FEDPNAS in real-world applications?', 'Can the authors provide more empirical results on diverse datasets to validate the generality of their approach?', 'How does the personalized FL objective perform on tasks with varying levels of heterogeneity?', 'Can the theoretical analysis be simplified or made more accessible?']","['The paper does not discuss the potential negative societal impacts of the personalized NAS approach in detail.', 'Scalability issues might arise given the computational complexity of the proposed method.', 'The empirical validation is limited to image datasets, which may limit the generalizability of the findings.', 'The computational overhead and scalability of the proposed method in real-world, resource-constrained FL scenarios need to be addressed.']",False,3,3,3,5,4,"['Addresses an important problem in Federated Learning by allowing for model personalization at both task and context levels.', 'Introduces a novel architecture that factorizes into a base and a personalizable component.', 'Provides empirical evidence showing significant improvements over state-of-the-art FL and NAS methods.', 'Includes theoretical analysis to support the proposed methods.']","['The complexity of the proposed method may make it challenging to implement and scale.', 'The clarity of the paper could be improved, particularly in the explanation of the technical details.', 'The potential limitations and broader impacts of the approach are not deeply explored.', 'The empirical analysis is limited to image datasets, raising questions about generalizability to other types of data.', 'Theoretical sections are dense and might not be easily accessible to all readers.']",3,3,3,3,Reject
eSHBmLnD1s8,"The paper proposes a two-stage stochastic subsampling model aimed at reducing the computational burden of processing high-dimensional data in deep learning algorithms. It introduces a candidate selection stage using conditionally independent Bernoulli random variables, followed by an autoregressive subsampling stage using conditionally dependent Categorical random variables. The method is shown to outperform existing approaches in several tasks, such as image classification and reconstruction, and enhances the scalability of nonparametric models.","['Can the authors provide more details on how the candidate selection and autoregressive subsampling stages interact and influence each other?', 'How does the performance of the proposed method compare to other advanced subsampling techniques not mentioned in the paper?', 'Have the authors conducted any analysis on the potential biases introduced by the subsampling method?', 'Can the authors provide more theoretical insights into why the two-stage approach works better than a single-stage approach?', 'Are there any limitations in terms of the types of datasets or tasks where this method might not perform as well?', 'How does the performance of this method scale with increasing dataset sizes?', 'Can the authors provide more details on the computational complexity and requirements of the proposed method in large-scale applications?', 'Can the authors provide more intuitive explanations or visual aids to help understand the mathematical formulation?', 'How does the proposed method handle biases in the data, especially in terms of gender or race, when selecting the most informative subsets?', 'Can the authors provide more detailed ablation studies to isolate the contributions of each component of their method?']","['The paper does not thoroughly discuss the potential biases introduced by the subsampling method, which could impact the fairness of downstream tasks.', 'The scalability of the method for extremely large datasets is not fully explored.', 'Ethical considerations related to the selection of data points and their impact on model predictions are not adequately addressed.', 'The computational cost of the autoregressive subset selection stage is high, which may limit its practical applicability.', 'Theoretical analysis supporting empirical results is lacking.']",False,3,3,3,6,4,"['Innovative two-stage subsampling approach.', 'Broad applicability to feature and instance selection tasks.', 'Experimental results showing significant performance improvements.', 'Provision of source code for reproducibility.']","['The clarity of the methodology could be improved, especially in the mathematical formulation.', 'Limited comparison to other advanced subsampling methods beyond DPS and INVASE.', 'Potential unaddressed limitations and ethical considerations, especially regarding biases in subsampled data.', 'The complexity and computational requirements are not thoroughly discussed, especially for large-scale applications.', 'Dense mathematical notation and complex descriptions that can hinder reproducibility.']",3,3,3,4,Reject
1JN7MepVDFv,"The paper explores the relationship between disentanglement and multi-task learning using synthetic datasets. It aims to determine if multi-task learning encourages disentanglement and if disentangled representations benefit multi-task learning. The authors conduct empirical studies using various models and multiple disentanglement metrics. Key contributions include the construction of synthetic datasets, analysis of multi-task learning's effect on disentanglement, and evaluation of disentangled representations in multi-task settings.","['Can the authors provide a clearer explanation of the experimental setup and metrics used?', 'How do the authors address the inconclusiveness and variabilities in the results?', 'Can more theoretical insights be provided to support the empirical findings?', 'Can the authors provide more details on the synthetic datasets used, including their validation?', 'Why do the results vary significantly across different datasets?', 'How do the authors plan to address the inconclusive nature of their findings?', 'Can the authors provide more detailed explanations or visual aids to improve the clarity of the dense methodology section?', 'Can the authors elaborate on the potential negative societal impacts and limitations of their work?']","['The reliance on synthetic datasets may limit the applicability of the findings to real-world scenarios.', 'The results are inconclusive, making it difficult to draw definitive conclusions about the practical benefits of disentangled representations in multi-task learning.', 'Potential negative societal impacts are not thoroughly discussed.']",False,2,2,2,4,4,"['Addresses an important and timely topic in machine learning.', 'Provides a thorough empirical analysis using synthetic datasets.', 'Uses multiple disentanglement metrics to validate results.']","['Results are inconclusive and vary across datasets.', 'Lacks a strong theoretical framework to support empirical findings.', 'Clarity could be improved, particularly in the results and discussion sections.', 'Heavy reliance on synthetic datasets, limiting generalizability to real-world scenarios.', 'Potential negative societal impacts and limitations are not adequately addressed.']",3,2,2,2,Reject
8rR8bIZnzMA,"The paper presents Dynamic Graph Transformer (DGT), a Transformer-based model for dynamic graph representation learning. It introduces spatial-temporal encoding and a temporal-union graph structure to capture graph topology and temporal information. The model is pre-trained using two complementary self-supervised tasks and evaluated on multiple real-world datasets.","['Can the authors provide additional empirical validation for the scalability of DGT on larger datasets?', 'Could the authors clarify the methodology sections, especially the spatial-temporal encoding and the training strategies?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'How does the approach compare to continuous time-step algorithms in terms of scalability and performance?', 'Can the authors provide more clarity on the theoretical analysis related to the Bayesian error rate?', 'How does the model handle extremely large graphs beyond the datasets used in the experiments?', 'Can the authors provide more theoretical justification for the effectiveness of the proposed spatial-temporal encoding?', 'How does DGT perform on extremely large graphs or in real-time applications?', 'Can the authors provide more details on the computational complexity of DGT compared to other methods?', 'How does the model perform with extremely noisy data, and are there any specific techniques to mitigate noise effects?', 'Could the authors provide more insights into the limitations and potential negative societal impacts of their work?', 'Can the authors provide more details on the temporal-union graph and how it is constructed?']","['Potential computational overhead for very large graphs.', 'Sensitivity to hyper-parameter settings.', 'Possible biases in real-world datasets used for evaluation.', 'The paper does not adequately address the scalability of DGT for extremely large graphs or real-time applications.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,6,4,"['Novel Transformer-based architecture for dynamic graphs.', 'Innovative spatial-temporal encoding and temporal-union graph structure.', 'Theoretical backing using information-theoretic analysis.', 'Extensive experimental validation on real-world datasets.']","['Scalability claims need further empirical validation.', 'Dense and complex methodology sections, need clearer explanations.', 'Lack of discussion on potential negative societal impacts and limitations.', 'Concerns about the comparability of baselines and scalability.', 'Presentation could be improved, especially in terms of clarity and organization of different sections.']",3,3,3,3,Reject
sOK-zS6WHB,"The paper introduces a scalable fingerprinting mechanism for generative models aimed at responsible disclosure to prevent misuse such as deep fakes. The method embeds unique fingerprints into generative models, allowing for accurate detection and attribution of generated samples to their source models. The approach is demonstrated to be efficient, scalable, and robust through comprehensive experimental results.","['Can more details be provided on real-world deployment scenarios and practical implications?', 'How does the approach compare in detail to other state-of-the-art methods in terms of limitations?', 'Can the authors provide more details on the robustness testing, especially against more sophisticated adversarial attacks?', 'How does the proposed method compare to other state-of-the-art deep fake detection methods in terms of computational efficiency?', 'What are the ethical considerations and potential misuses of the fingerprinting technique itself?', 'Can the authors provide more detailed explanations and clarifications on the mathematical formulations presented in Section 3.1?', 'How does the method perform in real-world scenarios where the generated images undergo significant post-processing before being analyzed?', 'What are the potential limitations of the method in extremely adversarial settings?', 'How does the method handle cases where the generated content is highly diverse and complex?']","['The discussion on limitations is somewhat limited, especially regarding practical deployment in diverse environments.', 'Potential negative societal impacts could be discussed more thoroughly.', 'The robustness of the fingerprinting technique against sophisticated adversarial attacks needs more exploration.', 'The scalability claims should be backed by more extensive experiments.', 'The authors should discuss potential ethical concerns related to the misuse of fingerprinting technology itself.', 'More discussion on practical deployment scenarios and limitations regarding scalability would be beneficial.']",False,4,4,4,8,4,"['Addresses a highly relevant and timely issue of responsible disclosure of generative models.', 'Novel approach combining concepts from image watermarking and network watermarking.', 'Scalable and efficient solution enabling many unique fingerprints without extensive retraining.', 'Comprehensive experimental results demonstrating effectiveness, fidelity, capacity, scalability, secrecy, and robustness.', 'Good reproducibility with code and models available on GitHub.']","['Needs more detailed comparison with related work, especially on the limitations of existing methods.', 'Lacks explanation on the practical implications and real-world deployment scenarios.', 'Some sections are overly technical, which might hinder understanding for a broader audience.', 'Technical details on robustness and scalability need further validation.', 'Potential ethical concerns and limitations are not explicitly discussed in detail.']",4,4,4,4,Accept
7YDLgf9_zgm,"The paper introduces Recursive Gradient Optimization (RGO) for continual learning, aiming to minimize forgetting without data replay or expanding network capacity. The method involves an iteratively updated optimizer and a virtual Feature Encoding Layer (FEL). Experimental results demonstrate significant improvements on several benchmarks, achieving state-of-the-art performance.","['Can the authors provide more intuitive explanations or examples to clarify the dense theoretical parts?', 'How does the method perform when the assumptions of over-parameterization and close vicinity are not met?', 'Can the authors comment on the scalability of the approach for larger and more complex datasets?', 'Can the authors provide more details on how the isotropic distribution assumption affects the theoretical results?', 'How does the approach perform in real-world scenarios with more complex and varied tasks?', 'Can the authors elaborate on the practical implementation challenges of the recursive optimization process?', 'Can the authors provide more details on the computational overhead introduced by the projection matrix?', 'How does the method perform on narrower network architectures?', 'Can the theoretical sections be simplified or summarized for better readability?', 'Can the authors provide more details on how the feature encoding layer (FEL) impacts the overall model performance?', 'What measures have been taken to ensure the reproducibility of the results given the complexity of the theoretical derivations?', 'Can the authors elaborate on the potential negative societal impacts or ethical concerns of the proposed method?', 'Can the authors provide more intuitive explanations or visualizations for the theoretical derivations, particularly the matrix manipulations?', 'How does RGO perform compared to other state-of-the-art methods not included in the current baselines?', 'Can the authors elaborate on the computational overhead introduced by RGO, especially in terms of training time and memory usage?']","['The method assumes over-parameterization and close vicinity, which may not hold for narrower networks.', 'The complexity of the method may limit its practical applicability.', 'Potential negative societal impacts are not explicitly discussed.', 'The paper needs to discuss more on the assumptions made for the theoretical results and how they hold in real-world scenarios.', 'More attention should be given to the potential negative societal impacts of this work.', 'The high complexity of the theoretical components might make the method difficult to reproduce.', 'Limited discussion on the societal impacts or ethical considerations of the proposed method.', 'The computational overhead introduced by the iterative updates and matrix manipulations is not thoroughly discussed.', 'Potential negative societal impacts, such as the environmental cost of increased computational resources, are not addressed.']",False,3,3,3,6,4,"['Novel approach combining gradient optimization and feature encoding.', 'Thorough theoretical analysis and proofs.', 'State-of-the-art performance on multiple benchmarks.', 'Does not rely on data replay or expanding network capacity.']","['Complexity of the method and assumptions like over-parameterization and close vicinity.', 'Some parts of the paper, especially mathematical derivations, are dense and hard to follow.', 'Practical impact may be limited due to the complexity of implementation.', 'Insufficient clarity in sections explaining the recursive optimization process and the feature encoding layer.', 'Limited discussion on potential negative societal impacts.', 'Computational costs and overhead are not clearly addressed.']",3,3,3,3,Reject
WqoBaaPHS-,The paper introduces a new notion of top-label calibration for multiclass classification and a multiclass-to-binary reduction framework (M2B) to unify different calibration types. The authors demonstrate the effectiveness of these concepts using histogram binning and provide theoretical guarantees and empirical results on CIFAR-10 and CIFAR-100 datasets.,"['How does the proposed top-label calibration perform on datasets with significant class imbalance or other real-world challenges?', 'Can the authors provide more intuitive explanations or visualizations of the theoretical guarantees provided?', 'How does the performance of the proposed methods scale with larger datasets and more complex models?', 'Could the authors provide more details on the limitations and potential negative societal impact of their work?', 'Can the authors elaborate on why TL-HB performs worse on CIFAR-100 compared to CIFAR-10 and suggest potential solutions?', 'How do the methods perform on non-image datasets or datasets from other domains?', 'Are there any practical guidelines or heuristics for choosing the number of bins in histogram binning for different datasets?']","['The paper should include more discussion on the potential negative societal impacts of miscalibration, especially in high-stakes applications such as healthcare or criminal justice.', 'The methods rely on having a sufficiently large calibration dataset, which may not always be feasible in practice.', 'The performance of the methods in the presence of dataset shift or non-iid data is not addressed.', 'The complexity of the theoretical guarantees might be challenging for practitioners to understand and apply.', 'The experiments are limited to image classification tasks, which may limit the perceived generalizability of the methods.']",False,3,3,4,7,4,"['Introduction of a novel and practically meaningful concept of top-label calibration.', 'Development of a unified M2B framework that leverages well-established binary calibration methods.', 'Empirical results demonstrating improved calibration performance across multiple datasets and architectures.', 'Provision of theoretical guarantees for the proposed methods.']","['The paper does not sufficiently explore the limitations of the proposed methods in real-world scenarios, particularly in the presence of class imbalance.', 'The empirical evaluation is limited to CIFAR-10 and CIFAR-100; it would be beneficial to see results on a wider range of datasets.', 'The theoretical guarantees are provided in the appendices, making them less accessible to readers.', 'Some parts of the paper, especially the detailed algorithms and theoretical proofs, are quite dense and might be challenging for some readers to follow.', 'Limited discussion on the potential limitations and negative societal impact.']",4,3,3,4,Reject
v-v1cpNNK_v,"The paper presents NASI, a novel Neural Architecture Search (NAS) algorithm that leverages the Neural Tangent Kernel (NTK) to estimate the performance of neural networks at initialization, thereby avoiding the need for model training during the search process. The method claims to be label- and data-agnostic, ensuring the transferability of selected architectures across different datasets. The approach is evaluated on various datasets, demonstrating competitive performance and transferability across tasks.","['Can the authors provide more rigorous theoretical support for the label- and data-agnostic claims?', 'How does the NTK approximation scale with larger and more complex architectures?', 'Are there any specific scenarios where the proposed method might fail or be less effective?', 'How robust are the NTK approximations in practice, especially for architectures not extensively studied in the paper?', 'Can the authors provide more empirical evidence or ablation studies to support the effectiveness of the NTK-based approach?', 'How does NASI compare with other state-of-the-art training-free NAS methods in terms of computational cost and accuracy?', 'Can the authors provide more details on the practical implications of avoiding model training entirely?', 'How does NASI perform compared to state-of-the-art NAS methods on more diverse and larger-scale datasets?', 'Can the authors clarify the conditions under which the label- and data-agnosticism holds?', 'Can the authors provide more intuitive explanations for the theoretical concepts?', 'How does the method perform in real-world scenarios beyond the benchmark datasets?', 'What are the limitations of the proposed method in terms of scalability and generalization?', 'How does the NTK approximation affect the performance of NASI in significantly different search spaces or architectures?', 'Can the method be extended to other types of neural networks beyond the ones tested (e.g., RNNs, GANs)?', 'What are the computational overheads associated with computing the NTK approximation?']","['The approximation of NTK is computationally costly and might not scale well with larger architectures.', 'Potential bias and fairness issues due to automated architecture search are not discussed.', 'The empirical support for label- and data-agnosticism, while promising, needs further theoretical backing.', 'The paper lacks a detailed discussion on the limitations of the NTK-based approach, particularly in terms of scalability and generalizability to diverse neural architectures.', 'Potential negative societal impacts, such as computational cost and energy consumption, are not addressed.', 'The assumption of infinite width in NTK may not hold in practical settings.', ""The method's performance on extremely large datasets and more complex tasks remains to be validated."", 'Potential computational overhead of NTK evaluations is not thoroughly discussed.', 'The complexity of the theoretical framework may limit its accessibility and reproducibility.']",False,3,3,3,6,4,"['Novel use of NTK to avoid model training during NAS.', 'Claims of label- and data-agnosticism are supported by empirical results.', 'Improved search efficiency with competitive effectiveness across datasets.', 'Well-structured and comprehensive experimental evaluation.', 'Theoretical grounding and comprehensive analysis.']","['Dense mathematical formulations that may hinder readability.', 'Some theoretical claims, particularly regarding label- and data-agnosticism, could be more rigorously supported.', 'Limited discussion on the practical limitations and scalability of the approach.', 'The accuracy of NTK approximations is crucial but not thoroughly validated.', 'Heavy reliance on mathematical descriptions may hinder clarity for a broader audience.', 'The potential limitations and negative societal impacts are not adequately addressed.', 'Results, although promising, need more robust validation and reproducibility assurances.']",3,3,3,3,Reject
rq1-7_lwisw,"The paper introduces a novel task called Object Concept Learning (OCL) aimed at enhancing object understanding by reasoning about object affordances and their attributing properties. The authors provide a densely annotated dataset and propose a baseline model, Object Concept Reasoning Network (OCRN), which uses causal reasoning to improve object concept learning.","['Can you provide more detailed comparisons with existing methods in terms of both performance and computational efficiency?', 'How does your dataset handle variations in object states, and how does the model generalize to unseen states?', 'What are the specific limitations of your method, and how could future work address these?', 'How does the proposed task of OCL differ from existing tasks in object recognition and affordance learning?', 'Can the authors provide a clearer explanation and justification for the causal inference methodology used in OCRN?', 'What are the practical applications of the proposed task and dataset, and how do they advance the state of the art?']","['The paper does not adequately address the limitations related to the complexity of the dataset and model, as well as potential biases in the data.', 'More discussion on potential ethical implications and data privacy is needed.', 'The annotation process for causal relationships may introduce biases, which could affect the validity of the results.', 'The potential negative societal impact of biased object understanding models is not discussed.', 'The computational cost of the proposed model is high, which might limit its applicability.']",False,2,2,2,4,4,"['Proposes a novel and important task in object understanding.', 'Introduces a comprehensive and densely annotated dataset.', 'Presents a baseline model (OCRN) that integrates causal reasoning with object concept learning.']","['The paper is dense and difficult to follow.', 'Experimental results lack robustness and detailed comparisons with state-of-the-art methods.', 'Technical soundness, particularly in causal inference, is not convincingly demonstrated.', 'Practical applicability and performance of the proposed OCRN need further validation.', 'Potential biases in the dataset and methods are not adequately addressed.']",3,2,2,3,Reject
HMJdXzbWKH,"The paper introduces Q-Rex and Q-RexDaRe, novel Q-learning algorithms that combine Online Target Learning (OTL) and Reverse Experience Replay (RER). These methods aim to improve the convergence and sample efficiency of Q-learning, providing the first non-asymptotic sample complexity bounds for Q-learning in ZIBEL MDPs.","['Can the authors provide more intuitive explanations of the proposed algorithms?', 'How do the methods perform compared to a wider range of baselines?', 'What are the potential real-world applications and limitations of these methods?', 'Can the authors provide more empirical results in diverse environments to demonstrate the generality of their methods?', 'How does the performance of Q-Rex and Q-RexDaRe compare with state-of-the-art methods in more challenging tasks?', 'Can the authors provide additional clarifications on the mathematical derivations?', 'Would it be possible to include more diverse experimental setups to further validate the methods?']","['The practical impact and applicability are not thoroughly discussed.', 'The clarity of the explanations and notation needs improvement.', 'The empirical validation is limited to a few specific settings, which may not generalize well.', 'The potential negative societal impacts are not adequately addressed.', 'The methods rely on specific assumptions (e.g., linear MDPs, ZIBEL), which may limit their applicability to more general settings.', 'Potential computational overhead due to the use of OTL and RER.']",False,3,2,3,5,4,"['The combination of OTL and RER is novel and innovative.', 'Theoretical results provide new non-asymptotic sample complexity bounds.', 'Addresses a gap between theoretical and practical performance of Q-learning.', 'Extensive empirical evaluation showing superior performance over baseline methods.']","['The paper is dense and difficult to follow with complex notation.', 'Comparative analysis with a wider range of baselines is lacking.', 'The practical impact and applicability in real-world scenarios are not thoroughly discussed.', 'Incremental innovation rather than groundbreaking.', 'Limited empirical validation across diverse environments.', 'Some proofs and theoretical claims are highly intricate and potentially difficult to verify.']",4,3,2,3,Reject
aPOpXlnV1T,"The paper identifies pitfalls in the standard approach of using negative log-likelihood (NLL) loss for training probabilistic neural networks, particularly in estimating heteroscedastic Gaussian distributions. The authors propose a modification called β-NLL, which introduces an exponentiated variance term to mitigate these issues. Extensive experiments on synthetic and real-world datasets show that β-NLL performs better in terms of robustness and predictive performance.","['How does the performance of β-NLL compare with other state-of-the-art uncertainty estimation methods not discussed in the paper?', 'Can the authors provide more insights into the computational overhead introduced by the β-NLL loss?', 'How does the selection of β affect the performance across different tasks and datasets?', 'Could the authors provide more guidance on selecting the β parameter for different datasets?', 'Are there any specific scenarios where β-NLL might not perform well compared to traditional NLL or other methods?', 'Can the authors provide more guidance on selecting the β hyperparameter? Are there any heuristic methods or rules of thumb?', 'How does the computational complexity of β-NLL compare to traditional NLL in practice?', 'Are there any specific types of problems or datasets where β-NLL might not be effective?', 'Could you provide more detailed comparisons with other state-of-the-art uncertainty estimation methods, particularly focusing on their limitations and how β-NLL overcomes them?', 'How sensitive is the β-NLL loss to the choice of the β parameter in real-world applications? Can you provide guidelines for selecting an appropriate β value?', 'Could you elaborate on the computational overhead introduced by the β-NLL loss compared to traditional NLL loss?']","['The paper does not discuss the potential increase in computational complexity due to the introduction of the β term.', 'The generalizability of the results to other types of data distributions or neural network architectures is not thoroughly validated.', 'There is a lack of discussion on the potential negative societal impacts of the proposed method.', 'The need for careful tuning of the β parameter.', 'Potential complexity in implementing and integrating the proposed method into existing systems.', 'Potential limitations in generalizing the approach across various problem domains and types of data.', 'The proposed method might not perform well in scenarios where the variance is not a good indicator of data point importance.', 'Limited sensitivity analysis of the β parameter makes it challenging for practitioners to adopt this method without further empirical guidance.', 'The proposed solution may not be universally superior, as shown in some comparisons with other methods.', 'Potential barriers to adoption due to computational cost and effort required for tuning β.']",False,3,3,3,4,4,"['Comprehensive theoretical analysis identifying the pitfalls of the NLL loss.', 'Introduction of a novel loss function, β-NLL, which is shown to mitigate identified issues.', 'Extensive empirical validation across a variety of datasets and tasks.', 'Clear explanations and well-organized structure.']","['The complexity of the proposed modification may limit its practical applicability.', 'The novelty of the approach is limited as it builds upon existing known issues and solutions.', 'Potential overclaims about the generalizability of the proposed approach without thorough validation on more diverse datasets.', 'The paper could benefit from more detailed ablation studies to isolate the effects of different components of the β-NLL.', 'Implementation complexity and the necessity of careful tuning for the β parameter.', 'Potential challenges in practical applications due to the added complexity.', 'Limited discussion on the computational overhead and sensitivity analysis of the β parameter.', 'Lacks a detailed comparison with state-of-the-art methods, focusing on their limitations and improvements.']",3,3,4,3,Reject
9Hrka5PA7LW,"The paper investigates unsupervised continual learning (UCL) and proposes Lifelong Unsupervised Mixup (LUMP) to address catastrophic forgetting. It demonstrates through extensive experiments that UCL is more robust compared to supervised continual learning (SCL). The authors provide quantitative and qualitative analyses to support their claims. The paper systematically analyzes the learned feature representations and loss landscapes, showing that UCL achieves smoother loss landscapes and learns meaningful feature representations.","['Can the authors provide more details on the implementation of LUMP and its computational complexity?', 'How does LUMP perform on high-resolution datasets like ImageNet?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their work?', 'Can the authors provide more detailed analysis on why LUMP is effective in mitigating catastrophic forgetting?', 'Are there plans to evaluate the proposed method on high-resolution or more diverse datasets?', 'Could the authors discuss how their work compares with the latest advancements in unsupervised continual learning?', 'Can the authors provide more theoretical justification for the claim that UCL is more robust to catastrophic forgetting?', 'Can the authors provide more details on the sensitivity of the method to hyperparameters?', 'Have you considered testing your methods on high-resolution datasets to demonstrate scalability?', 'Can you provide additional baselines or datasets to strengthen your empirical evaluations?', 'How do you plan to address the limitations mentioned in the paper in future work?']","['The paper does not address the performance of LUMP on high-resolution datasets.', 'Limited discussion on the potential negative societal impacts of UCL methods.', 'The impact of hyperparameter tuning on the performance of UCL and LUMP is not explored in depth.', 'Potential negative societal impacts include the misuse of unsupervised learning techniques in sensitive applications without proper oversight.']",False,3,3,3,7,4,"['Introduction of a novel method (LUMP) for UCL.', 'Comprehensive experimental evaluation on multiple datasets.', 'Quantitative and qualitative analyses supporting the claims.', 'Good comparison with existing SCL and UCL methods.', 'Systematic analysis of learned representations and loss landscapes.']","['Some sections lack clarity and detailed explanations, particularly on the implementation of LUMP.', 'Limited discussion on potential limitations and ethical concerns.', 'The paper could benefit from a more thorough theoretical analysis of why UCL is more robust.', 'Limited dataset diversity; no high-resolution tasks evaluated.', 'Sparse discussion on related work, especially recent advancements.', 'Lack of ablation studies for deeper insight into LUMP.']",3,3,3,3,Accept
b30Yre8MzuN,The paper 'NEUROSED: Learning Subgraph Similarity via Graph Neural Networks' introduces a novel Siamese Graph Neural Network architecture designed to learn subgraph edit distance (SED) and graph edit distance (GED). The model incorporates inductive biases to ensure properties like the triangle inequality and performs efficiently on large datasets. The approach demonstrates significant improvements over existing methods in terms of accuracy and speed.,"['How does the model perform on different types of graphs (e.g., directed, weighted)?', 'Can the approach be generalized to other graph similarity measures beyond SED and GED?', 'What are the limitations in terms of scalability with respect to the size of the query graphs?', 'Can the authors provide more intuitive explanations or visualizations for the theoretical properties, especially the preservation of the triangle inequality?', 'Could the authors expand the ablation studies to include more variations and provide deeper insights into the contributions of different components?', 'What are the potential directions for addressing the limitations related to the performance on larger query sizes?']","[""The model's performance on larger query sizes and unseen larger queries needs improvement."", 'Scalability concerns with respect to computational complexity in real-world deployment.', 'The complexity of the theoretical framework requires careful implementation to ensure reproducibility.', 'Potential societal impact and ethical considerations are not thoroughly addressed.']",False,3,3,3,6,4,"['Novel approach to learning SED using a siamese GNN architecture.', 'Strong theoretical foundation with proofs for key properties.', 'Extensive experimental evaluation demonstrating significant improvements.', 'Well-organized and clearly written paper with comprehensive supplementary materials.']","['Limited exploration of practical implications and real-world deployment scenarios.', 'Validation is limited to specific datasets.', 'Scalability concerns with larger query graphs.', 'Need for further generalization to different types of graphs and similarity measures.']",4,3,3,3,Accept
NH29920YEmj,This paper introduces a new method for Positive and Unlabeled (PU) learning called Positive and Unlabeled learning with Partially Positive Mixup (P[3]Mix). The method leverages a heuristic mixup technique to improve data augmentation and correct supervision. The authors demonstrate that P[3]Mix consistently outperforms state-of-the-art PU learning methods on multiple benchmark datasets.,"['Can the authors provide more detailed explanations or visualizations of the heuristic mixup technique?', 'How does the performance of P[3]Mix vary with different values of the mixup hyperparameter (alpha)?', 'Can the authors provide additional ablation studies to understand the contribution of each component of the proposed method?', 'Can the authors provide more theoretical analysis or justification for the proposed heuristic mixup technique?', 'How does the performance of P[3]Mix generalize to other types of datasets not included in the experiments?', 'Can the authors provide more details on the hyperparameter settings and their impact on performance?', 'How does the proposed method compare with other recent PU learning methods that also use data augmentation?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?', 'Can the authors provide more detailed pseudocode for the heuristic mixup process?', 'How does the method perform on other real-world datasets outside of the benchmark ones used?', 'Can the authors elaborate on the computational complexity of the proposed method compared to existing techniques?', 'Can the authors provide more details on the implementation of the heuristic mixup technique, specifically the candidate mixup pool and the selection process?', 'How does P[3]Mix perform on other real-world datasets not included in the paper, such as those from different domains?', 'Can the authors clarify the exact hyperparameter settings used in the experiments for reproducibility purposes?']","['The reliance on the heuristic mixup technique may limit the generalizability of the method to other types of weak supervision problems.', 'Potential negative societal impact is not thoroughly discussed, which is important given the sensitivity of applications like medical diagnosis.', 'The method relies heavily on the selection of the mixup partners, which may be dataset-specific.', 'Potential negative societal impacts include misuse in sensitive applications like medical diagnosis without thorough validation.', 'The paper should address the scalability of the method to larger datasets.', ""The method's performance on highly imbalanced datasets is not thoroughly discussed."", 'The paper briefly mentions robustness improvements but lacks a detailed discussion on the limitations of the proposed method.', 'Potential negative societal impacts of misclassifying positive instances in critical applications (e.g., medical diagnosis) are not adequately discussed.']",False,3,2,3,6,4,"['The method introduces a novel adaptation of the mixup technique specifically for PU learning.', 'Comprehensive experimental results that demonstrate the effectiveness of the proposed method.', 'The paper addresses a significant problem in PU learning with a potentially impactful solution.']","['Certain methodological details, particularly regarding the heuristic mixup technique, could be explained more clearly.', 'The paper could benefit from additional ablation studies to further isolate the impact of different components of the proposed method.', 'Lacks detailed theoretical analysis to support the claims.', 'The clarity and organization of the paper could be improved.', 'Limited impact beyond the specific datasets and problem settings studied.', 'Potential issues with reproducibility due to insufficient detail in the methodology.', 'Potential limitations and negative societal impacts are not adequately addressed.', 'Limited comparison with more recent related works in PU learning and data augmentation.']",3,3,2,3,Accept
MqEcDNQwOSA,"The paper proposes a novel embedding structure called k-sub-embedding to compress word embeddings in neural language models. It aims to reduce the number of embedding parameters significantly without much performance degradation. The method is evaluated on GLUE and XNLI benchmarks, showing promising results.","['Can you provide more theoretical insights into why the k-sub-embedding method works?', 'How do you choose the hyperparameters for the k-sub-embedding method?', 'Can you explain how this method generalizes to other tasks beyond those evaluated?', 'What are the potential pitfalls or failure modes of this method?', 'How do you ensure reproducibility of your experiments?', 'Can the authors provide more details on the clustering algorithm and its computational complexity?', 'How does the proposed method compare to other state-of-the-art embedding compression techniques?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide clearer pseudocode or step-by-step illustrations of the algorithms?', 'How does the proposed method handle out-of-vocabulary (OOV) words during inference?', 'Can the authors clarify the impact of different hyperparameter settings on the performance of sub-embeddings?']","['The paper does not discuss potential negative societal impacts or limitations adequately. It would be helpful to see a discussion on these aspects, especially given the importance of ethical considerations in NLP.', 'The complexity of managing sub-embeddings may offset the benefits of parameter reduction.', 'The paper does not sufficiently address the potential negative societal impacts of embedding compression, such as biases in smaller models.', 'The paper does not clearly discuss the potential limitations and negative societal impacts of the proposed method. This should be addressed in a dedicated section.', 'The paper does not adequately discuss the limitations of the proposed method, such as the potential decrease in interpretability of the embeddings.']",False,3,2,3,4,4,"['Significant reduction in embedding parameters.', 'Promising empirical results on standard benchmarks.', 'Innovative approach to reducing embedding size.', 'Potentially wide applicability to various language models.']","['Lack of theoretical analysis and insufficient differentiation from existing work.', 'Unclear explanations and poor organization make the paper difficult to follow.', 'Insufficient detail in the experimental setup to ensure reproducibility.', 'No discussion on potential negative societal impacts or limitations.', 'Slight performance degradation in some tasks raises concerns about practical applicability.', 'Complexity of the proposed methods might hinder reproducibility.', 'The novelty may not be sufficiently distinct from prior work.', 'Marginal performance improvement may not justify the additional complexity introduced.']",3,3,2,3,Reject
A05I5IvrdL-,"The paper addresses the problem of optimizing memoryless stochastic policies in infinite-horizon POMDPs using a novel geometric and algebraic framework. It characterizes the optimization problem as a linear optimization problem with polynomial constraints, provides estimates for the number of critical points, and demonstrates the approach on a navigation problem in a grid world.","['Can the authors provide more details on the computational complexity of their method?', 'How does the proposed method scale with the size of the state, observation, and action spaces?', 'Are there any practical applications where this method has been successfully applied beyond the grid world example?', 'Can the authors provide more intuitive explanations or visual aids to help understand the complex mathematical derivations?', 'How does the proposed polynomial optimization framework compare with existing methods in terms of computational complexity and performance?', 'Can the authors provide additional experiments on more complex POMDPs to demonstrate the practical applicability of their approach?']","['The authors have addressed some limitations, but they should discuss the scalability and practical applicability of their method in more detail.', 'The methods assume the observation matrix β to be invertible, which might not always be the case in practical applications.', 'The computational complexity of solving the polynomial optimization problems in large-scale POMDPs is not fully addressed.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,7,4,"['Novel geometric and algebraic characterization of the optimization problem in POMDPs.', 'Detailed description of the feasible state-action frequencies using polynomial constraints.', 'Theoretical estimates for the number of critical points.', 'Rigorous mathematical analysis and proofs.', 'Potentially significant impact on both theoretical research and practical applications.']","['Highly theoretical and may lack immediate practical applicability.', 'Complexity of the proposed method may limit its use in large-scale POMDPs.', 'Limited empirical validation beyond the grid world example.', 'Clarity issues, especially in the mathematical derivations and proofs.', 'Assumes observation mechanism β has linearly independent columns.']",4,3,3,3,Accept
h-z_zqT2yJU,"The paper introduces Adaptive Temperature Knowledge Distillation (ATKD), which adjusts the temperature of the teacher and student models during knowledge distillation to address performance degradation issues caused by sharpness gaps. The method's effectiveness is demonstrated through experiments on CIFAR-100 and ImageNet datasets.","['Can you provide more detailed explanations or simplifications for the theoretical derivations?', 'Have you considered evaluating the ATKD method on more diverse datasets beyond CIFAR-100 and ImageNet?', 'Can you elaborate on any potential negative societal impacts or ethical concerns associated with your work?', 'Can the authors provide a deeper theoretical justification for the chosen form of adaptive temperature adjustment?', 'Have the authors considered the computational overhead introduced by adaptive temperature adjustments?', 'Can the authors provide more experimental results on varied datasets to validate the generalizability of ATKD?', 'How does ATKD perform in domains outside of computer vision, such as NLP or reinforcement learning?', 'Can the authors provide more detailed comparisons with additional baseline methods?', 'Are there any ablation studies to isolate the contributions of different components of ATKD?', 'Can the authors clarify the theoretical justification for the sharpness metric and adaptive temperatures?', 'Can the authors provide more rigorous justification for the use of Taylor expansions in the derivation of the sharpness metric?', 'How does the proposed method scale with larger datasets and models not covered in the experiments?', 'Can the authors clarify the practical implications of using adaptive temperatures in real-world scenarios?', 'Can the authors justify the assumption that the sum of logits is zero during training?', 'Can the authors provide more detailed comparisons with existing methods beyond just accuracy metrics?']","['The theoretical derivations might be complex for readers to follow.', 'The proposed method has been tested on CIFAR-100 and ImageNet, but further validation on more diverse datasets could strengthen the findings.', 'The paper does not address potential negative societal impacts or ethical concerns related to the proposed method.', 'The approach may not generalize well to other types of models or tasks beyond image classification.', 'Potential computational overhead due to the adaptive temperature mechanism.', 'Possible ethical concerns related to the deployment of models trained with ATKD if not properly validated.', 'Theoretical justification for the sharpness metric and its derivation could be stronger.', 'Practical scalability and implications are not fully explored.', 'The method relies on the assumption that the sum of logits is zero, which needs more justification.', 'The broader impact and applicability of the method are not discussed in detail.']",False,3,2,3,5,4,"['Identifies and addresses a known performance degradation problem in knowledge distillation.', 'Proposes a novel metric to quantify the sharpness of model outputs.', 'Extensive experimental results showing improvements over state-of-the-art methods on CIFAR-100 and ImageNet.']","['Theoretical derivations are complex and could benefit from more detailed explanations or simplifications.', 'The novelty of the sharpness metric and ATKD approach might need further validation across more diverse benchmarks.', 'Potential negative societal impacts or ethical concerns are not adequately addressed.', 'Clarity issues in the presentation, particularly in mathematical sections.', 'Lacks deep theoretical justification for the specific form of adaptive temperature adjustment.', 'Insufficient discussion on limitations and potential negative societal impacts.']",3,3,2,3,Reject
Ctjb37IOldV,"The paper proposes a Variance Principle to explain why dropout helps in finding flatter minima in neural network training, leading to better generalization. The principle is empirically validated through experiments on various datasets (MNIST, CIFAR-10, CIFAR-100) and network structures (fully-connected networks, ResNet-20).","['Can the authors provide more detailed explanations of the experimental setup and how the results were obtained?', ""How does the proposed Variance Principle compare to other explanations for dropout's effectiveness?"", 'Are there any specific limitations or potential negative societal impacts of this work that the authors have not discussed?', 'Can you provide more rigorous theoretical validation of the Variance Principle?', 'How can the results be reproduced by other researchers? Are there any publicly available code or datasets?']","['The paper does not discuss the limitations of the proposed Variance Principle in detail.', 'Potential negative societal impacts of dropout and its widespread use are not considered.', 'The experiments are limited to relatively small datasets and may not generalize to larger, more complex datasets.', 'The paper lacks a thorough discussion on the scalability of the proposed principle to larger models and datasets.']",False,3,2,3,5,4,"['Addresses an important question in deep learning.', ""Proposes a novel Variance Principle to explain dropout's effectiveness."", 'Provides extensive empirical evidence using different datasets and network structures.', 'Well-situated within existing literature, making clear connections to prior work.']","['Theoretical foundation of the Variance Principle is not well-developed.', 'Lack of clarity in explaining the experimental setup and results.', 'Incremental contribution, building heavily on existing work on dropout and SGD.', 'Densely written and difficult to follow in parts.', 'Potential limitations and negative societal impacts are not adequately addressed.']",3,3,2,3,Reject
dEwfxt14bca,"The paper investigates mode-switching, non-monolithic exploration for reinforcement learning agents. It explores different modes, timescales, and signals for switching between exploration and exploitation. The authors propose adaptive and robust algorithmic components and test their methods on Atari games using the R2D2 architecture.","['Can the authors provide more detailed explanations for the chosen methods in simpler terms?', 'How do the proposed methods perform in environments other than Atari games?', 'Can the authors provide more conclusive evidence to support the claims regarding the benefits of specific triggers and modes?', 'How does the proposed approach scale to more complex environments beyond Atari?', 'Are there any benchmarks or comparisons with non-Atari environments to ensure generalizability?', 'What are the computational costs associated with the mode-switching mechanisms compared to traditional methods?', 'How does the performance of the proposed method compare with state-of-the-art exploration methods?', 'What are the practical implications of the proposed methods for real-world applications?']","['The paper does not address potential negative societal impacts of the proposed methods.', 'The generalizability of the findings beyond Atari games is not discussed.', 'The complexity of the proposed methods may hinder their adoption.', 'Limited empirical evaluation on a small subset of Atari games.', 'Lack of theoretical analysis to support the empirical findings.']",False,3,2,3,4,4,"['Addresses an underexplored area in RL: the timing of exploration.', 'Proposes practical algorithms for adaptive and robust mode-switching.', 'Empirical results show the effectiveness of intra-episodic exploration.', 'Thorough experimental setup with detailed comparative results.']","['The paper is complex and dense, making it difficult to follow.', 'Some claims regarding the benefits of specific triggers and modes are not conclusively supported by the results.', 'The study is limited to a subset of Atari games, restricting the generalizability of the findings.', 'Lacks sufficient comparison with state-of-the-art methods.']",3,3,2,3,Reject
XHUxf5aRB3s,"The paper presents a novel approach to addressing non-stationarity in cooperative multi-agent reinforcement learning (MARL) using a trust-region decomposition network (TRD-Net) and a new notion, δ-stationarity. The method aims to control policy divergence through adaptive trust-region constraints, leading to stable performance improvements in various cooperative tasks.","['Can you provide more intuitive explanations for the key concepts such as δ-stationarity and trust-region decomposition?', 'How does the proposed method perform in real-world scenarios beyond the simulated environments?', 'What are the computational overheads associated with the TRD-Net and how do they compare to baseline methods?', 'Can you elaborate on the practical implications of your findings and how they can be applied in real-world MARL applications?', 'Can the authors provide more empirical results in diverse and complex environments?', 'How does the approach compare to other state-of-the-art methods in terms of scalability?', 'Can the authors clarify the mathematical formulations and provide more intuitive explanations?', 'Why were certain hyperparameters chosen, and how sensitive is the algorithm to these choices?', 'Can the authors provide more detailed ablation studies to isolate the impact of each component of the TRD-Net?', 'How does the performance of MAMT compare to other recent state-of-the-art methods not included in the baseline comparisons?', 'What is the computational complexity and scalability of the proposed method?', 'Can the authors provide more details on the generalizability of their approach to other MARL tasks?', 'Are there any simplifications or approximations that could make the method more accessible to practitioners?', 'How does the method perform in highly dynamic and unpredictable environments compared to the ones tested?', 'How stable is the proposed method across different random seeds and hyperparameters?']","['The complexity of the theoretical framework and its practical implementation.', 'Potential computational overheads introduced by the TRD-Net.', 'The clarity of explanations and presentation of novel concepts.', 'The paper does not address potential limitations such as computational complexity and scalability in large-scale environments.', 'The societal impact of the work is not discussed.', 'Lacks detailed ablation studies.', 'Limited comparison to recent state-of-the-art methods.', 'Unclear computational complexity and scalability.', 'Potential ethical implications are not thoroughly addressed.']",False,3,2,3,4,4,"['Introduces δ-stationarity as a new measure of non-stationarity in MARL.', 'Uses trust-region decomposition to manage policy divergence effectively.', 'Extensive experimental validation showing performance improvements.', 'Combines theoretical analysis with practical implementations.', 'Robust theoretical foundations, with detailed proofs and lemmas.']","['The paper is dense and complex, making it difficult to follow.', 'Theoretical justifications are heavily notation-based and complex.', 'Practical implications and usability in real-world applications are not well highlighted.', 'Clarity in presenting the novel concepts and their significance could be improved.', 'Limited empirical evaluation across diverse environments.', 'Combination of existing techniques rather than fundamentally new concepts.', 'Lacks clear explanation and justification for hyperparameter choices.', 'Experiments do not convincingly demonstrate claimed performance improvements.', 'Ablation studies suggest benefits of TRD-Net may not be substantial.', 'Figures and tables are not well-integrated into the text.', ""Reproducibility might be challenging despite the provided code due to the method's complexity."", 'Lack of in-depth discussion on potential ethical concerns.']",3,3,2,3,Reject
pgkwZxLW8b,"The paper proposes Federated Sampled Softmax (FedSS), a method designed to reduce computational and communication costs in federated learning settings by sampling a subset of classes and optimizing only the corresponding model parameters. The empirical results show that FedSS performs comparably to the full softmax method while being more resource-efficient.","['Can you provide more details on the scalability of FedSS in terms of the number of clients and classes?', 'How does FedSS compare with more recent federated learning methods?', 'Can you elaborate on the potential negative societal impacts or ethical considerations of FedSS?', 'Can you provide more detailed theoretical analysis or proofs to support the convergence of the proposed method?', 'Are there any specific scenarios where FedSS might not perform well compared to the full softmax method?']","['The paper does not discuss the potential negative societal impacts of deploying FedSS.', 'Scalability analysis in terms of the number of clients and classes is not detailed.', 'Assumes label space is known and uniformly sampled, which may not always hold true.', 'Potential biases introduced by the sampling method could affect fairness and robustness.', 'May not be effective for tasks with highly imbalanced class distributions.', 'There is no discussion on how the method handles heterogeneous data distributions across clients.']",False,3,3,3,6,4,"['Introduction of a novel method (FedSS) for federated learning.', 'Addresses a significant problem in federated learning with a focus on resource efficiency.', 'Empirical results demonstrate the effectiveness of the proposed approach.', 'Comprehensive experiments conducted on multiple datasets.']","['Lacks detailed theoretical analysis or proofs of convergence.', 'Some sections are dense and could benefit from additional explanations.', 'Limited novelty, as the method is an extension of existing sampled softmax techniques.', 'Minimal discussion on potential limitations and negative societal impacts.']",4,3,3,3,Reject
s51gCxF70pq,"The paper presents k-Step Latent (KSL), a novel representation learning method for reinforcement learning (RL) that enforces temporal consistency via a self-supervised auxiliary task. The method aims to improve sample efficiency and performance in high-dimensional state spaces by predicting action-conditioned representations of the state space multiple steps into the future. KSL is integrated with the Soft Actor-Critic (SAC) algorithm and evaluated on the PlaNet benchmark suite, showing significant improvements over state-of-the-art methods.","['How would KSL perform in environments with higher-dimensional action spaces or more complex dynamics than those in the PlaNet benchmark suite?', 'Are there specific scenarios or types of tasks where KSL fails to provide significant improvements over baseline methods? If so, what are they?', 'Can the increased wall clock time be mitigated through architectural modifications or more efficient training strategies?', 'Can the authors provide more details on how KSL scales to more complex environments with higher-dimensional state spaces?', 'What are the potential negative societal impacts of this work, and how do the authors plan to mitigate them?', 'Can the authors clarify the computational overhead introduced by KSL and its impact on training time?', 'Can the authors provide a clearer explanation of how KSL differs from existing methods like BYOL and SPR?', ""Are there any specific real-world applications where KSL's improvements in sample efficiency would be particularly beneficial?"", 'Can the authors provide more detailed pseudocode or implementation details to improve reproducibility?', 'How sensitive is the performance of KSL to the choice of hyperparameters, particularly the value of k?']","['The increased wall clock time for training is a significant limitation, which might affect the scalability of the method.', 'Potential scalability issues in environments with more complex dynamics or higher-dimensional action spaces are not discussed.', 'While the paper shows improved generalization, detailed failure cases and robustness across a broader range of tasks are not extensively covered.', 'Potential negative societal impacts are not adequately addressed.']",False,3,3,4,7,4,"['The method is novel and innovative, introducing k-step predictions to enforce temporal consistency in latent representations.', 'The paper is technically sound, with detailed theoretical justifications and extensive experimental evaluations.', 'The writing is clear and well-organized, making it easy to understand the proposed method and its results.', 'The results show significant improvements in sample efficiency and performance over existing methods, highlighting the potential impact of KSL in the field of RL.']","['The method is complex and might be difficult for practitioners to implement without substantial effort, especially due to the reliance on multiple optimizers and detailed architectural choices.', 'KSL requires increased wall clock time compared to other methods, which could be a limiting factor for real-world applications.', 'The paper does not extensively discuss potential limitations or failure cases of KSL in different environments or tasks not included in the benchmarks.', 'Some key details are buried in the appendices, which might hinder clarity.', 'The implementation details, while provided, are complex and might be hard to reproduce.', 'Limited discussion on potential negative societal impacts.']",3,3,3,4,Accept
Rx9luEzcSoy,"The paper introduces the concept of Lottery Image Prior (LIP), applying the Lottery Ticket Hypothesis (LTH) to DNN-based image priors. It empirically investigates whether sparse subnetworks can match the performance of dense networks in image inverse problems. The paper presents extensive experiments in image restoration and compressive sensing using both untrained and pre-trained models, validating the existence and transferability of LIP.","['Can the authors provide more theoretical insights or analysis to support the empirical findings?', 'How do the practical efficiency gains of using LIP compare to the dense models in real-world applications?', 'Can the methodology for finding and evaluating LIP be explained more clearly, possibly with pseudocode or additional diagrams?', 'How do the LIP subnetworks compare to other state-of-the-art methods for image restoration tasks?', 'Have the authors considered other types of neural network architectures or tasks beyond image restoration?', 'What are the potential negative societal impacts of this research, if any?']","['The paper primarily relies on empirical validation, which may not be sufficient for establishing the theoretical foundations of LIP.', 'The efficiency gains and practical implications of using LIP are mentioned but not thoroughly analyzed or quantified.', 'The methodology is complex and might be difficult for practitioners to implement without detailed guidance.', 'The experiments are primarily conducted on specific datasets, which may limit the generalizability of the results.', 'The paper lacks a thorough discussion of the potential negative societal impacts or ethical considerations of the proposed approach.']",False,3,3,3,6,4,"['Novel idea of applying LTH to image priors.', 'Extensive empirical validation in different settings.', 'Detailed experimental results and clear organization.', 'High transferability of LIP subnetworks across tasks and datasets.', 'Potential practical implications for improving computational efficiency in image restoration tasks.']","['Lacks strong theoretical analysis for LIP.', 'Methodology could be explained more clearly in some sections.', 'Practical implications and efficiency gains are not thoroughly discussed.', 'Dense and sometimes difficult to follow.', 'Potential limitations and negative societal impacts are not fully addressed.']",3,3,3,4,Reject
ab7lBP7Fb60,"The paper introduces an algorithm to enforce group fairness in private federated learning (PFL) by extending the modified method of differential multipliers (MMDM). The proposed algorithm, FPFL, is demonstrated on the Adult and FEMNIST datasets, showing its ability to mitigate unfairness exacerbated by differential privacy in federated learning.","['Can the authors provide more insights into the performance of FPFL on a broader range of datasets?', 'How can the sensitivity to differential privacy noise be mitigated in practical deployments?', 'Could the authors provide more intuitive explanations for the complex mathematical formulations?', 'Can you provide more detailed insights into the scalability of FPFL for larger models and datasets?', 'Have you considered alternative methods to reduce the sensitivity of FPFL to DP noise?', 'Can you elaborate on the computational complexity of FPFL compared to other federated learning algorithms?', 'Can the authors provide more detailed implementation details or release the code to ensure reproducibility?', 'How does the proposed method generalize to other tasks and datasets beyond the Adult and modified FEMNIST datasets?', 'Can the authors discuss the potential societal impact of deploying such algorithms in real-world scenarios?', 'How does FPFL perform under different privacy budgets (e.g., varying ε and δ values)?', 'Can the authors clarify the practical implications of the increased sensitivity to DP noise and how this can be mitigated in real-world applications?', 'How does the performance of FPFL compare with other state-of-the-art fairness algorithms in federated learning?', 'Can the authors elaborate on potential negative societal impacts and how they plan to mitigate them?']","['The FPFL algorithm is sensitive to differential privacy noise, requiring large cohort sizes for effective training.', ""The method's complexity may hinder its practical implementation and scalability."", 'The scalability of the algorithm to larger models and real-world datasets is not demonstrated.', 'The paper lacks a detailed discussion on potential negative societal impacts.']",False,3,3,3,5,4,"['Addresses a relevant and timely problem in machine learning fairness within federated learning settings.', 'Novel combination of MMDM with PFL to address fairness.', 'Comprehensive experimental evaluation on two datasets.', 'Clear articulation of the problem and related work.', 'Theoretical underpinning of the proposed FPFL algorithm is well-defined.']","['Limited to two datasets, which may affect generalizability.', 'High sensitivity to differential privacy noise, limiting practical applicability.', 'Complex mathematical formulations that could benefit from further simplification or explanation.', 'Scalability to larger models and datasets is not thoroughly explored.', 'Lacks detailed implementation details and code, which could hinder reproducibility.', 'The paper lacks clarity, making it difficult to reproduce the results.']",3,3,3,3,Reject
KeBPcg5E3X,"The paper proposes ContraLORD, a method that integrates contrastive learning into latent optimization for representation disentanglement in generative models. The authors evaluate their approach on ten benchmarks and demonstrate its effectiveness in learning both discriminative and generative representations.","['Can the authors provide a more thorough theoretical analysis to support their claims?', 'Can the authors include more comparative studies with the latest state-of-the-art methods?', 'What are the potential negative societal impacts and ethical considerations of this work?', 'Can the authors provide more details on the theoretical foundations behind the contrastive learning mechanisms used?', 'Could the authors elaborate on the hyperparameters used in the experiments and their selection process?', 'Is there a specific reason for choosing ResNet-50 as the encoder architecture, and how does it impact the results?', 'Can the authors provide more details on the implementation of the content-level and residual-level contrastive losses?', 'How does the proposed method compare with other recent state-of-the-art methods not included in the comparison tables?', 'What are the specific limitations of the proposed method, and how might they impact its applicability in real-world scenarios?', 'Can the authors provide theoretical justification for the chosen content-level and residual-level contrastive losses?', 'What are the computational requirements and scalability considerations for the proposed method?', 'Can the authors provide more details on the ethical considerations, particularly regarding the use of large datasets?', 'How does ContraLORD perform on tasks other than linear classification and disentanglement?', 'Can the authors clarify some of the dense mathematical notations and provide more intuitive explanations?']","['Theoretical analysis is lacking.', 'More comparative studies with state-of-the-art methods are needed.', 'Ethical considerations and potential negative societal impacts are not adequately discussed.', 'The method may require significant computational resources for training due to the use of multiple encoders and contrastive learning.', 'Potential negative societal impact could arise from misuse of generative models that produce highly realistic and potentially deceptive images.', 'The paper does not adequately address its limitations. It would be beneficial to discuss potential scalability issues, the computational cost of the proposed method, and any assumptions made that might limit its generalizability.']",True,3,2,3,5,4,"['Novel integration of contrastive learning and latent optimization.', 'Extensive experiments on multiple benchmarks.', 'Comprehensive ablation studies to validate the effectiveness of the proposed losses.']","['Lacks thorough theoretical analysis and mathematical explanations.', 'Insufficient detail in the experimental setup for reproducibility.', 'Limited comparison with recent state-of-the-art methods.', 'Potential scalability issues due to computational complexity.']",3,3,2,3,Reject
neqU3HWDgE,"The paper proposes a novel approach for unsupervised disentanglement in generative models using a tensor product structure on the torus. The method claims to naturally lead to disentangled representations and supports this claim with theoretical and experimental results. The authors introduce a new metric, the DC-score, to assess the combined disentanglement and completeness performance of their method.","['How does the proposed method compare to other state-of-the-art techniques beyond the datasets and metrics used in the paper?', 'Can the authors provide more intuitive explanations or visualizations to make the concepts more accessible?', 'What steps are being taken to address the limitation of scaling to datasets with a large number of generative factors?', 'Can the authors provide more details on the hyperparameters used in the experiments and their impact on the results?', 'Could the authors clarify the computational complexity of the proposed method compared to the baselines?', 'What are the potential negative societal impacts of this work?', 'What are the practical implications of the proposed method in real-world applications?']","['The method may not scale well to datasets with a large number of generative factors.', 'The explanation and theoretical foundation may be dense and challenging for some readers.', 'Potential ethical concerns with the application of disentangled representations are not discussed.']",False,3,3,3,7,4,"['Introduction of a novel and original method using the torus for latent space representation.', 'Comprehensive theoretical foundation based on entropy considerations.', 'Extensive experimental evaluation on multiple datasets.', 'Introduction of the DC-score as a new metric for assessing disentanglement and completeness.', 'Code availability for reproducibility.']","['Complex and dense explanation that may be hard to follow for readers not familiar with the underlying concepts.', 'Potential issues with scaling to datasets with a large number of generative factors.', 'Need for further validation and reproducibility of results.', 'Limited discussion on the potential negative societal impacts of the work.']",4,2,3,4,Accept
DYaFB19z1ig,"The paper proposes self-distribution distillation (S2D) and hierarchical distribution distillation (H2D) to improve uncertainty estimation in neural networks. S2D integrates a teacher-student training approach within the same model, aiming to bypass the need for separate ensemble training. H2D extends this by distilling the knowledge of S2D-style ensembles into a single robust model. The methods are evaluated on CIFAR-100 and several out-of-distribution detection tasks, showing improvements over standard models and some ensemble methods.","['Can the authors provide more detailed pseudocode or algorithmic steps for S2D and H2D to improve clarity and reproducibility?', 'How sensitive are the proposed methods to hyperparameter choices, particularly the temperature scaling and the number of forward passes in S2D?', 'Can the authors clarify the computational costs and time efficiency for training H2D models compared to standard ensembles?', 'Can the authors provide a clearer explanation of how their method differs from existing ensemble distillation techniques?', 'How robust are the proposed methods across different types of neural network architectures and datasets?', 'Can the authors provide more detailed comparisons with state-of-the-art methods in uncertainty estimation?', 'Can the authors discuss potential limitations and ethical considerations of deploying these methods in real-world applications?']","['The paper acknowledges the potential instability in training S2D models, but more discussion and empirical analysis on this aspect would be beneficial.', 'The methods are primarily evaluated on image classification tasks. It would be interesting to see results in other domains like NLP or speech recognition.', 'The performance of the proposed methods is demonstrated primarily on image classification tasks. It would be important to evaluate their performance in other domains such as NLP or speech recognition.', 'The methods might be complex to implement and require significant computational resources during training.', 'Potential overfitting on the CIFAR-100 dataset due to the intricate setup.', 'Limited evaluation on diverse datasets and tasks raises questions about generalizability.', 'The paper does not adequately discuss the limitations of the proposed methods, such as potential overfitting and sensitivity to hyperparameters.', 'The potential negative societal impacts, such as misuse of uncertainty estimates in safety-critical applications, are not addressed.']",False,3,2,3,5,4,"['The proposed methods (S2D and H2D) are novel and address an important issue in uncertainty estimation for neural networks.', 'Comprehensive experimental evaluation on CIFAR-100 and out-of-distribution datasets.', 'The approach shows improvements over standard models and some ensemble methods in uncertainty estimation.']","['The paper is dense and difficult to follow in parts, which may hinder reproducibility.', 'Some experimental results are marginal, and the improvements are not consistently significant across all metrics.', 'The practical implementation details and computational costs, particularly for H2D, are not fully clear.', 'Limited discussion on the generalizability of the results to other datasets and tasks.', 'Insufficient comparison with state-of-the-art methods.']",3,3,2,3,Reject
8in_5gN9I0,"The paper proposes data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles in graph streams using machine learning-based heavy edge oracles. Theoretical results include improved space complexity bounds and optimality under certain conditions, while empirical results demonstrate the effectiveness of the proposed methods compared to state-of-the-art baselines.","['How practical is the assumption of having an accurate oracle in real-world scenarios?', 'Can the proposed methods be extended to other types of subgraph counting problems?', 'What are the limitations of the empirical evaluation, and how might they affect the generalizability of the results?', 'Can the authors provide more practical details on implementing the heavy edge oracle in noisy settings?', 'How does the proposed method compare to a broader range of strong baseline algorithms in empirical evaluations?', 'Can the explanations, especially in the supplementary material, be made more concise?', 'How feasible is it to train a perfect oracle in practice? Can the authors provide more details on the training process and the associated costs?', 'Can the authors provide more information about the datasets used in the experiments, including their source and characteristics?', 'How would the proposed algorithms perform under different noise models in the oracle predictions?', 'What are the potential limitations of the proposed methods, especially in terms of scalability to larger datasets?', 'Can you provide more detailed proofs for the theoretical claims?', 'How do you address the potential limitations and ethical concerns of using machine learning in this context?', 'Can you clarify the experimental setup and the metrics used to evaluate the improvements?', 'Can the authors provide more details on the practical implementation of the oracle, especially in noisy real-world scenarios?', ""How exactly are the oracle's predictions integrated into the algorithms, and what are the potential pitfalls in real-world applications?"", 'Could the authors provide additional experiments or analyses on the robustness of the oracle in highly noisy environments?']","['The paper assumes the availability of accurate oracles. In practice, obtaining such oracles may be challenging.', 'The empirical evaluation focuses on specific datasets, which may not represent all types of real-world graph streams.', 'The paper acknowledges potential issues with noisy oracles and the assumption of knowing certain parameters a priori. It would benefit from discussing adaptive methods that do not require such assumptions.', 'The societal impact is not deeply discussed, though it is probably minimal due to the nature of the research.', 'The assumption of a perfect oracle is a significant limitation. Real-world datasets often contain noise and inaccuracies that can impact the performance of the proposed algorithms.', 'The paper does not discuss the potential negative societal impacts of the work, such as privacy concerns in sensitive data streams.', 'The reliance on the accuracy of the oracle might limit practical applicability. It would be beneficial to discuss potential strategies to mitigate errors in oracle predictions.', 'There is limited discussion on the computational overhead introduced by the oracle, especially in larger and noisier datasets. More analysis on this aspect would be valuable.']",False,3,3,3,6,4,"['Integration of machine learning-based oracles in graph stream algorithms is novel.', 'Comprehensive theoretical analysis including space complexity bounds and optimality proofs.', 'Extensive empirical evaluation on real-world datasets showing improvements over existing methods.', 'Innovative use of machine learning techniques to improve classical streaming algorithms.']","['Assumes availability of accurate oracles, which may not always be practical.', 'Empirical evaluation might not cover all possible real-world scenarios.', 'Some proofs and theoretical justifications are dense and may be difficult for readers to follow.', 'Complexity of implementing the heavy edge oracle, particularly in noisy settings, requires more practical insights.', 'Empirical comparisons could include a broader range of strong baselines for more exhaustive benchmarking.']",4,3,3,4,Accept
u6sUACr7feW,"The paper proposes DPP-TTS, a text-to-speech model that leverages Determinantal Point Processes (DPPs) to diversify prosodic features in speech synthesis. The method aims to generate more expressive speech without compromising naturalness. The paper includes detailed methodology, experiments, and comparisons with state-of-the-art models.","['How well does the proposed method generalize to other datasets and languages?', 'Can the authors provide more details on the reproducibility of the method?', 'Are there any plans to improve the inference speed of the model?', 'Can the authors provide more detailed pseudocode or flow diagrams to clarify the implementation of the prosody diversifying module?', 'What are the potential limitations of using DPPs for prosody diversification in text-to-speech models?', 'How does the model perform in real-world applications beyond the experimental setup?', 'Can the authors provide more details on the computational complexity and real-time applicability of the PDM?', 'How sensitive is the model to the tuning of the introduced hyperparameters (e.g., quality weight, number of candidates)?', 'Can the authors provide more details on the computational complexity and training time of DPP-TTS compared to the baselines?', 'How does the model perform on other datasets besides LJSpeech? Is the approach generalizable?', 'Can the authors elaborate on the choice of hyperparameters, especially the quality weight w and the number of candidates nc?', 'Could the authors provide more details on the training stability and any measures taken to ensure it?', 'How does the choice of quality weight value w affect the naturalness and diversity trade-off?', 'Can the method be generalized to other languages with different prosodic characteristics?']","['The paper does not address the generalizability of the method to other datasets and languages.', 'The technical complexity of the method might hinder reproducibility.', 'The slower inference speed of the model could limit its practical applicability.', 'The paper does not sufficiently address the potential negative societal impacts of the proposed method.', 'The complexity of the method may limit its practical applicability and reproducibility.', 'The paper does not discuss potential limitations like the increased complexity of the model and its impact on training and inference times.', 'There is limited consideration of the potential negative societal impacts, such as misuse in generating misleading audio content.']",False,3,3,3,6,4,"['The paper introduces a novel application of DPPs in speech synthesis.', 'Comprehensive experiments and evaluations demonstrate the effectiveness of the proposed method.', 'The paper is well-structured and clearly written.', 'The proposed method addresses a significant problem in TTS systems.', 'Detailed methodology explanations for reproducibility.', 'Promising results showing improved prosody diversity without sacrificing naturalness.']","['The method involves multiple complex components, which might make it difficult to reproduce.', 'Experiments are conducted on a single dataset, raising questions about generalizability.', 'Inference speed is slower compared to the baseline, which might limit practical applicability.', 'More diverse and extensive evaluations could strengthen the validation of the proposed method.', 'Insufficient discussion on the potential negative societal impacts and ethical concerns.', 'Some experimental details and hyperparameter choices are not fully justified.']",4,3,3,3,Reject
e8JI3SBZKa4,The paper proposes a method for kernel similarity matching using Hebbian learning rules. The authors derive an upper bound for the sum of squared errors between output and input kernel similarities and implement this in a one-layer recurrent neural network. The method aims to generate high-dimensional linearly separable representations that are sparse and selective for specific input patterns. The algorithm is compared to neural random Fourier methods and Nyström methods for approximating the kernel matrix.,"['Can the authors provide more theoretical analysis or guarantees for the convergence of the proposed algorithm?', 'Why does the performance degrade with increasing output dimensionality? Can this issue be addressed or mitigated?', 'Can the authors discuss the sensitivity of the algorithm to learning rates in more detail?', 'Are there any ethical considerations related to this work that need to be addressed?', 'How does the performance vary with different types of kernels beyond those tested?', 'Can the authors provide more insights or guidelines on selecting optimal learning rates for their method?', 'Are there any strategies to improve the convergence stability of the proposed method?', 'Can the authors provide more detailed explanations and justifications for the performance degradation in higher-dimensional settings?', 'How does the proposed method compare to random Fourier features in terms of computational complexity and scalability?', 'Can the authors provide more experimental results to demonstrate the effectiveness of their method?', 'How does the proposed method perform on larger and more complex datasets?', 'Can the authors clarify the theoretical guarantees of convergence for their gradient descent ascent algorithm?']","['The paper does not provide rigorous theoretical guarantees for the convergence of the algorithm.', 'The performance degrades with increasing output dimensionality, suggesting potential limitations in scalability.', ""The algorithm's sensitivity to learning rates is mentioned but not thoroughly discussed."", 'The method does not perform well in high-dimensional settings.', 'Empirical convergence issues need to be addressed.', 'Potential negative societal impacts are not discussed.', 'The convergence of the algorithm is highly sensitive to learning rate choices, which can be a barrier for practical applications.', 'The method does not consistently outperform existing methods, particularly for high-dimensional outputs.', 'The paper does not provide theoretical guarantees for the convergence of the gradient descent ascent procedure.', 'The paper does not adequately discuss the limitations of the proposed method, such as its scalability to larger datasets and its sensitivity to hyperparameters.']",False,2,2,2,4,4,"['Integrates biologically plausible learning rules with kernel-based machine learning.', 'Derives and implements an online learning rule for recurrent neural networks.', 'Provides empirical results on both synthetic and real-world datasets.', 'Strong biological motivation aligning with Hebbian learning principles.']","[""Lacks rigorous theoretical guarantees for algorithm's convergence."", 'Performance degrades with increasing output dimensionality without thorough analysis.', 'Insufficient discussion on limitations, especially sensitivity to learning rates.', 'Presentation needs improvement to clearly distinguish novel contributions from existing works.', 'No discussion on ethical considerations.', 'Empirical results are inconsistent, particularly in high-dimensional settings.', 'Limited practical significance due to poor performance in higher dimensions.', 'Theoretical justifications are somewhat unclear and complex.']",3,2,2,2,Reject
inSTvgLk2YP,"The paper proposes MeshInversion, a novel method for single-view 3D mesh reconstruction using a pre-trained 3D GAN. The method employs GAN inversion to reconstruct textured meshes by searching for a latent code that best fits the input image. The paper introduces Chamfer Texture Loss and Chamfer Mask Loss to address misalignment and discretization-induced information loss. The method demonstrates state-of-the-art performance on the CUB-200-2011 and PASCAL3D+ datasets, showing robustness to occlusions and less common shapes.","['Can the authors provide more theoretical justification for the proposed losses?', 'How does the method perform on other datasets beyond CUB-200-2011 and PASCAL3D+?', 'Can the authors discuss potential negative societal impacts of their work?', 'What are the hyperparameters used for training the GAN and during the inversion process?', 'Can the method be adapted for real-time applications, or is it inherently resource-intensive?', 'How sensitive is the method to inaccuracies in the initial camera pose and mask predictions?']","['The method is evaluated primarily on CUB-200-2011 and PASCAL3D+ datasets, which may limit generalizability.', 'Potential negative societal impacts and limitations are not adequately discussed.', 'The complexity of the losses might make the approach less accessible for practical applications.', 'Not entirely robust to variations in camera pose and mask predictions.']",False,3,3,3,6,4,"['Novel use of GAN inversion for 3D mesh reconstruction.', 'Introduction of Chamfer Texture Loss and Chamfer Mask Loss.', 'Promising experimental results showing state-of-the-art performance.', 'Robustness to occlusions and less common shapes.']","['Lack of detailed theoretical analysis.', 'Evaluation limited to specific datasets.', 'Insufficient discussion on potential negative societal impacts and limitations.', 'Certain sections lack clarity, making it difficult to follow the methodology.', 'Over-reliance on pre-trained GANs, which may limit the applicability to other domains or object categories.', 'Complexity of the proposed losses may hinder reproducibility.', 'Heavy reliance on qualitative comparisons for evaluation.']",4,3,3,4,Reject
0lSoIruExF,"The paper proposes methods to integrate user-item similarity into hybrid neighborhood-based recommendation systems. It aims to improve recommendation accuracy while addressing privacy concerns by minimizing the need for extensive user data collection. The proposed methods are evaluated using the MovieLens 20M dataset, showing improvements in RMSE and MAE over existing models.","['Can the authors provide more details on the computational complexity and scalability of the proposed methods?', 'How do the proposed methods perform in real-world recommendation scenarios beyond the MovieLens dataset?', 'What measures have been taken to address potential negative societal impacts and ethical concerns related to user privacy?', 'Can the authors provide more theoretical analysis to support the empirical results?', 'How were the hyperparameters and optimization techniques chosen, and can this process be better justified?', ""Can the authors provide clearer explanations of their methodology to improve the paper's clarity?"", 'How do the proposed methods compare to recent state-of-the-art techniques?', 'What are the specific computational costs associated with the proposed methods in real-world applications?']","['The paper does not sufficiently address the potential negative societal impacts and ethical concerns related to user privacy.', 'The practical impact and scalability of the proposed methods are not thoroughly discussed.', 'The additional computational complexity introduced by the new methods is not sufficiently justified.', 'The limited evaluation on a single dataset raises questions about the robustness of the proposed methods in different contexts.']",False,2,2,2,3,4,"['Addresses a relevant problem in recommendation systems by focusing on privacy.', 'Comprehensive experimental validation using a well-known dataset.', 'Proposes novel methods for representing user preferences.']","['Incremental improvement rather than a novel contribution.', 'Limited discussion on the practical impact and scalability of the proposed methods.', 'Insufficient attention to potential negative societal impacts and ethical concerns.', 'Lack of detailed theoretical analysis to support the empirical results.', 'Dense and unclear writing, making it difficult to follow the methodologies and reproduce results.', 'The improvements in accuracy, while statistically significant, may not be practically meaningful.']",2,2,2,2,Reject
4lLyoISm9M,"The paper introduces Range-Net, a novel deterministic two-stage neural optimization approach for low-memory Singular Value Decomposition (SVD). It aims to provide high accuracy while adhering to the Eckart-Young-Mirsky theorem and offers significant improvements over existing randomized SVD methods. The authors provide theoretical guarantees and empirical validations against state-of-the-art methods.","['Can the authors provide more details on the computational complexity of Range-Net, especially for very large datasets?', 'How does Range-Net perform in a distributed computing environment?', 'Are there any specific types of data or applications where Range-Net might not be suitable?', 'Can further clarifications be provided on the initialization process and the convergence criteria?', 'Can the authors provide more specific implementation details and parameter settings used during the experiments to facilitate reproducibility?', 'How does Range-Net perform compared to other non-randomized SVD methods beyond SketchySVD?', 'Can the authors elaborate on any limitations or failure modes observed during the experiments?', 'Can the authors provide more details on the computational time comparison with existing methods?', 'Are there any specific real-world datasets where Range-Net has been applied successfully?', 'What are the potential limitations when scaling Range-Net to even larger datasets?']","['The potential negative societal impacts of the work are not adequately addressed.', 'Further exploration is needed to ensure the practical applicability and scalability of Range-Net in diverse real-world settings.', 'The paper does not clearly address the computational time aspect, which is crucial for practical applications.', 'Reproducibility might be an issue due to the lack of detailed implementation specifics.', 'The impact of the method on computational resources and runtime for extremely large datasets is not clear.']",False,3,2,3,6,4,"['Novel solution for low-memory SVD.', 'Strong theoretical guarantees.', 'Comprehensive experimental validation.', 'Fully interpretable network design.', 'Addresses a significant issue of memory requirements in Big Data applications.']","['Dense and challenging to follow.', 'Lack of clarity on practical scalability and reproducibility.', 'Limited comparison with other state-of-the-art methods.', 'Insufficient discussion on potential societal impacts and limitations.', 'Details regarding implementation and experimental setup are insufficient for reproducibility.']",4,3,2,3,Accept
g4nVdxU9RK,"The paper proposes Rewardless Open-Ended Learning (ROEL), a method that combines unsupervised reinforcement learning with the POET framework to train agents in evolving environments without predefined reward functions. The aim is to generate a diverse set of increasingly complex skills through mutual information-based exploration. The authors demonstrate the approach on the bipedal walker environment, showing qualitative and quantitative results.","['How does ROEL compare to other state-of-the-art methods in unsupervised reinforcement learning?', 'Can the authors provide more detailed theoretical analysis to support their empirical findings?', 'How do the authors plan to address the reproducibility concerns?', 'Are there plans to test ROEL on a wider variety of environments?', 'Can the authors provide a more detailed comparison with a broader range of baselines?', 'How does ROEL handle potential pitfalls such as overfitting to certain types of environments?', 'Can the authors clarify the steps involved in the mutation and transfer phases within the POET framework in more detail?', 'Can you elaborate on the computational resources required for training ROEL compared to baseline methods?']","['The paper does not provide a thorough discussion on the limitations of the proposed method, such as scalability and computational requirements.', 'Potential negative societal impacts are not addressed.']",False,2,2,2,4,4,"['The combination of unsupervised reinforcement learning and the POET framework is innovative.', 'Addresses a relevant problem in reinforcement learning where reward functions are hard to define.', 'Empirical results show potential for improved generalization and diversity of skills.']","['Lacks rigorous theoretical analysis to support its claims.', 'Experimental validation is limited to a single environment type.', 'Dense and complex language makes the paper difficult to follow.', 'Insufficient comparison with a broader range of baselines.', 'Reproducibility concerns due to ambiguous implementation details.', 'Minimal discussion on limitations and potential negative societal impacts.']",3,2,2,3,Reject
6PlIkYUK9As,"The paper proposes a method for selecting informative and diverse subsets of data for training deep learning models, incorporating balancing constraints on predicted class labels and decision boundaries using matroids. The method is evaluated on standard and long-tailed classification datasets, showing marginal improvements over existing methods.","['Can the authors provide more insights into the impact of different hyperparameters on the performance?', 'How does the method perform on other types of datasets beyond image classification?', 'Can the authors elaborate on the computational overhead introduced by the triple-clique constraint?', 'Can the authors provide a more detailed breakdown of the computational complexity and practical applicability of their method?', 'Can the authors provide more insights into the choice of hyperparameters and their impact on the results?', 'Can the authors elaborate on the potential limitations and negative societal impacts of their work?', 'Can the authors provide more details on the implementation of the matroid constraints?', 'How does the proposed method compare to other state-of-the-art subset selection methods?', 'Can the authors include more ablation studies to isolate the contributions of each component of their method?', 'How sensitive is the method to the choice of hyperparameters (λ1, λ2, λ3)?', 'Can the proposed method be extended to other types of data (e.g., text, audio)?', 'How does the performance of the method change with different initial seed sizes?']","['The method shows limited improvement on standard datasets.', 'The applicability of the method to other types of datasets is not explored.', 'The method might be computationally intensive, limiting its scalability.', 'The explanation of the method is complex and may require simplification for better understanding.', 'More discussion on the potential ethical implications and limitations is needed.', ""The method's performance is only marginally better than existing approaches on standard datasets."", 'The paper does not discuss the scalability of the method to extremely large datasets or other domains beyond image classification.', 'Potential negative societal impacts, such as algorithmic bias introduced by subset selection, are not addressed.', 'The method relies on the accuracy of the initial model trained on the seed dataset.', 'The computational complexity of the algorithm, while improved, is still significant for very large datasets.', 'The approach may not generalize well to other types of data or tasks beyond classification.', 'The societal impact of reducing training costs is positive, but the authors should also consider potential negative impacts, such as the reduced need for human annotators.']",False,3,3,3,5,4,"['Addresses significant problem of computational and labeling cost in deep learning.', 'Combines different selection objectives and incorporates balancing constraints innovatively.', 'Well-organized paper with theoretical guarantees and efficient algorithm.', 'Novel use of matroids for balancing constraints.', 'Promising results on long-tailed datasets.']","['Empirical results show only marginal improvements over existing methods on standard datasets.', 'The complexity of the proposed method might limit its practical applicability.', 'Dense mathematical notation and definitions might be challenging for non-experts.', 'Theoretical contributions are somewhat incremental.', 'Experimental evaluation could benefit from additional baselines and ablation studies.', 'Clarity can be improved, particularly in the explanation of matroid constraints and the greedy algorithm.', 'Lacks detailed analysis and discussion on the trade-offs and limitations of the proposed method.', 'Potential ethical considerations and limitations are not extensively discussed.']",3,3,3,3,Reject
EFSctTwY4xn,"The paper introduces an Adaptive Federated Meta-Learning (AFML) framework to achieve generalizable personalized federated learning (PFL) under non-IID data scenarios. The core contribution is the adaptive trade-off theorem, which balances information flow from the initial model and the local dataset during local adaptation. This approach is evaluated on CIFAR-100 and Shakespeare datasets, showing improved personalized accuracy and reduced communication costs compared to existing PFL methods.","['Can the authors provide more detailed derivations and proofs for the adaptive trade-off theorem?', 'How does AFML perform under different types and levels of non-IID distributions beyond what is presented?', 'Can the authors include more ablation studies to isolate the effects of different components of AFML?', 'What are the ethical considerations and potential negative societal impacts of this approach?']","['The paper does not discuss the potential limitations and negative societal impacts of the proposed AFML framework.', 'The robustness of AFML under various real-world non-IID scenarios needs further validation.']",False,3,2,3,5,4,"['Novel adaptive trade-off theorem based on information theory.', 'Demonstrated improvements in personalized accuracy and communication efficiency.', 'Addresses the challenge of non-IID data in federated learning.']","['Theoretical derivation and empirical validation require more detail and rigor.', 'Writing and organization need significant improvement for clarity.', 'Experimental evaluation lacks comprehensive comparison metrics and ablation studies.', 'Ethical considerations and societal impacts are not adequately discussed.']",3,3,2,3,Reject
5o7lEUYRvM,"The paper presents a novel approach to Bayesian deep learning by leveraging function-space variational inference (fVI) with Dirichlet predictive priors. This method aims to enhance uncertainty quantification and adversarial robustness. The authors extend variational implicit processes to the classification setting, propose a novel Dirichlet KL estimator, and demonstrate the method's effectiveness on various image classification tasks.","['How does the proposed method scale with increasing dataset size and model complexity?', 'Can the authors provide more detailed comparisons with state-of-the-art methods beyond ensembles and MC dropout?', 'How sensitive is the method to the choice of the Dirichlet prior parameters?', 'Can the authors provide more mathematical rigor to support their claims, particularly regarding the Dirichlet KL divergence estimation?', 'How does the method perform on higher-dimensional classification tasks beyond CIFAR100?', 'Can the approach be extended to other types of neural network architectures beyond those tested?', 'How does the computational complexity of the proposed method compare to traditional weight-space BNNs in practice?']","[""The method's complexity and the need for iterative optimization might limit its applicability in real-time systems."", 'Scalability to very large models and datasets remains uncertain.', 'Potential computational overhead due to Dirichlet MLE estimation.', 'The choice of the index set in the function-space KL divergence term is critical, but effective strategies for constructing these sets are left as future work.', 'The approach requires careful tuning of the prior regularization, especially for high-dimensional classification tasks, which might limit its applicability.']",False,3,3,3,6,4,"['The paper presents a novel method by shifting the perspective from weight-space to function-space variational inference.', 'Innovative application of Dirichlet predictive priors in function-space variational inference.', 'Solid theoretical foundation and detailed derivations.', 'Extensive experimental validation across different datasets and models.', 'Provision of code for reproducibility.']","['The experimental results do not conclusively demonstrate substantial improvements over existing methods.', 'Complex mathematical formulations and dense technical jargon can hinder understanding.', 'Scalability concerns for high-dimensional classification tasks and very large datasets.', 'Overlap with existing techniques like Prior Networks and Belief Matching, with insufficient comparative analysis.', 'Dense presentation may be challenging for readers not familiar with Bayesian methods.']",4,3,3,4,Reject
i2baoZMYZ3,"The paper introduces Action Quantization from Demonstrations (AQuaDem), a method to discretize continuous action spaces in reinforcement learning by leveraging human demonstrations. This approach aims to improve exploration efficiency and performance by converting continuous actions into a finite, meaningful set derived from demonstrations, enabling the application of discrete-action RL algorithms. The method is evaluated across three setups: RL with demonstrations, RL with play data, and imitation learning, showing promising results.","['How does the performance of AQuaDem change with varying quality and quantity of demonstration data?', 'Can the method handle suboptimal or noisy demonstrations effectively?', 'How does the choice of temperature (T) in the loss function affect the discretization quality and overall performance?', 'Can the authors provide more details on the hyperparameter tuning process?', 'What is the computational overhead of the AQuaDem method compared to state-of-the-art continuous control methods?', 'Can the authors provide more detailed illustrations or examples to clarify the AQuaDem framework?', 'How does AQuaDem specifically address the limitations of previous discretization methods?', 'Can the authors include more ablation studies to better understand the contribution of each component of AQuaDem?', 'How does AQuaDem perform compared to more recent continuous control methods that were not included in the current set of baselines?', 'Can the authors provide a more detailed theoretical analysis of the proposed method?']","['Assumes high-quality demonstrations, which may not always be available.', 'Scalability to very high-dimensional action spaces remains unaddressed.', 'Potential negative societal impact is not discussed; ethical implications of using human demonstration data should be considered.', ""The method's applicability to more diverse and realistic setups is unclear.""]",False,3,3,3,6,4,"['Novel approach for action discretization leveraging human demonstrations.', 'Detailed empirical evaluation showing consistent improvements over state-of-the-art methods.', 'Potential for significant impact on continuous control RL.']","['Relying on the quality and representativeness of demonstrations may limit applicability.', 'Scalability to environments with very high-dimensional action spaces is not thoroughly addressed.', 'Limited theoretical analysis of the impact of hyperparameters, particularly the temperature.', 'Insufficient ablation studies to understand the influence of different components of the method.', 'Some sections of the paper are difficult to follow due to dense technical language and lack of clear illustrations.', 'Lack of discussion on potential limitations and negative societal impacts.']",3,3,3,3,Reject
hjlXybdILM3,"The paper presents SimpleBits, a method to simplify neural network inputs by minimizing their encoding bit size using a pre-trained generative model. The method is evaluated in three scenarios: per-instance simplification during training, dataset condensation, and post-training simplification. The results indicate that SimpleBits can effectively remove superfluous information, maintain task performance, and provide insights into model behavior.","['How does SimpleBits compare with other state-of-the-art simplification or interpretability methods?', 'Can the authors provide more details on the baselines used for evaluation, and why certain baselines were chosen over others?', 'What are the computational costs associated with SimpleBits, especially in large-scale datasets?', 'Can the authors provide more empirical validation for the correlation between simplicity and encoding bit size?', 'What are the potential negative societal impacts of applying SimpleBits in real-world scenarios?', 'How does SimpleBits perform on a wider variety of datasets beyond the ones evaluated?', 'Can the authors provide more details on the optimization process for the simplifier network?', 'How does SimpleBits compare to other input simplification methods not mentioned in the paper?', 'What is the impact of different hyperparameter settings on the performance of SimpleBits?', 'Is the method scalable to larger datasets, and if so, what are the computational requirements?', 'How does SimpleBits perform with other generative models besides Glow? Are the findings consistent?', 'Can the authors provide a more detailed comparison with simpler baselines, particularly in terms of computational efficiency and interpretability?', 'How does SimpleBits handle noise or adversarial examples in real-world datasets?', 'How were the hyperparameters for the generative model and simplifier network chosen?', 'Why were certain datasets chosen for evaluation, and are there plans to test on more complex datasets?', 'How does SimpleBits compare with other state-of-the-art methods in terms of performance and interpretability?']","['The paper does not extensively discuss the potential negative societal impacts of simplifying inputs, such as biases introduced or amplified by the simplification process.', 'The method relies heavily on the pre-trained generative model, which may not be available or feasible for all datasets and applications.', 'The method may oversimplify inputs, potentially losing critical information in complex datasets.', 'The potential negative societal impacts, particularly in medical applications, need to be thoroughly addressed.', 'Reproducibility concerns due to the lack of detailed implementation steps.', 'The paper does not address the computational cost and efficiency of training with SimpleBits, which could be a significant limitation.', 'The reliance on a single generative model (Glow) may limit the generality of the findings.', 'The practical applicability and integration of SimpleBits into existing ML workflows are not sufficiently explored.']",True,3,3,3,4,4,"['Novel approach leveraging encoding bit size for simplification.', 'Comprehensive evaluation across different settings.', 'Provides insights into the trade-offs between input simplicity and task performance.', 'Potential applications in improving interpretability and reducing dataset sizes.']","['Limited novelty in methodologies; heavily relies on existing generative models and optimization techniques.', 'Some evaluation metrics and baselines are not thoroughly discussed or compared.', 'The paper is dense and may be challenging for readers to follow.', 'Theoretical foundation on the correlation between simplicity and encoding bit size needs stronger empirical validation.', 'Limited evaluation on a narrow set of datasets; broader validation needed.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'Reproducibility concerns due to the complexity of the method and potential lack of details in supplementary materials.', 'Potentially insufficient comparison with other simplification methods.', 'Limited discussion on the impact of hyperparameter choices.', ""The method's scalability to larger datasets is not thoroughly explored."", 'Relies heavily on a single generative model (Glow), raising questions about generality.', 'The practical impact and broader applicability of the method are not convincingly demonstrated.', 'Comparisons with simpler baselines (e.g., Gaussian blurring, JPEG compression) are not comprehensive.', 'Potential to overlook important nuances in complex datasets, leading to oversimplification.', 'Reproducibility of results is questionable due to the lack of detailed implementation steps.']",3,3,3,3,Reject
pWBNOgdeURp,"The paper introduces a new class of pruning algorithms for deep neural networks based on Koopman operator theory. It aims to provide a theoretical foundation for magnitude and gradient-based pruning methods, showing their equivalence under certain conditions and offering insights into their performance pre-convergence. The paper conducts experiments to validate the proposed methods on standard datasets and architectures.","['Have you considered the scalability of your approach for larger neural networks beyond the ones tested?', 'Could you provide more details on how your methods compare with other state-of-the-art pruning techniques?', 'What are the potential negative societal impacts of your proposed methods?', 'Can the authors provide more theoretical justifications for the application of Koopman operator theory to neural network pruning?', 'Have the authors tested their methods on other models and datasets beyond MnistNet and ResNet-20?', 'Can the authors provide more details on the experimental setup and hyperparameters used in their experiments?', 'Can the authors provide more intuitive explanations or visualizations to make the complex mathematical concepts more accessible?', 'How do the computational requirements of Koopman-based pruning compare to traditional methods, especially for very large networks?', 'Can the authors clarify how their methods can be integrated into standard deep learning frameworks?']","['Scalability to larger neural networks is not thoroughly addressed.', 'Limited evaluation on different datasets and architectures may limit the generalizability of the results.', 'Potential ethical and societal impacts are not discussed.', 'Theoretical justifications for the proposed methods are not strong enough.', 'The paper does not discuss potential negative societal impacts or ethical considerations.']",False,2,2,2,4,4,"['Introduction of a theoretically motivated pruning method based on Koopman operator theory.', 'Unification of magnitude and gradient-based pruning methods.', 'Potential to provide new insights into the dynamics of neural network training.']","['Limited experimental validation with a narrow range of benchmarks.', 'Lack of comprehensive comparison with state-of-the-art pruning methods.', 'Complex mathematical concepts that may not be easily accessible to a broader audience.', 'Preliminary results that do not convincingly demonstrate practical superiority.', 'Insufficient discussion on the limitations and societal impacts of the proposed methods.']",3,2,2,2,Reject
iLHOIDsPv1P,The paper introduces the PAC-Bayes Information Bottleneck (PIB) framework to understand and improve the generalization capability of neural networks by focusing on the information stored in weights (IIW). It proposes an efficient algorithm to approximate IIW and validates the approach through various experiments.,"['Can the authors provide more empirical results on diverse datasets to validate the robustness of their approach?', 'Could the authors simplify or provide additional explanations for the more complex mathematical derivations?', 'How does the proposed PIB perform in comparison to other state-of-the-art methods in a wider range of tasks?', 'Can the authors provide more rigorous proofs for Lemma 2 and Lemma 3?', 'How sensitive is the proposed method to the choice of hyperparameters in practical applications?', 'Can the authors elaborate on the potential limitations and challenges of the proposed PIB approach in real-world scenarios?', 'What are the potential negative societal impacts or ethical concerns related to the proposed methods?']","['The paper does not discuss potential limitations in the scalability of the proposed method.', 'The societal impact is not addressed. The use of information-theoretic measures in practical applications could raise concerns regarding privacy and interpretability.', 'The theoretical justification for the connection between IIW and generalization is not fully established.', 'Potential computational overhead of the proposed Bayesian inference algorithm using SGLD.']",False,3,3,3,5,4,"['The paper tackles a fundamental problem in machine learning: understanding neural network generalization.', 'Introduces a novel concept (PIB) with theoretical backing.', ""Empirical results show promise and demonstrate the approach's potential."", 'Combines PAC-Bayes theory with information bottleneck methods.', 'Opens new avenues for research in understanding neural network generalization.']","['The paper is dense and complex, requiring additional explanations in some sections.', 'Empirical validation is limited to a few datasets; broader validation is needed.', 'Some theoretical claims, while backed by proofs, could be further elaborated for clarity.', 'Limited comparison with existing methods, which makes it difficult to evaluate the true impact and significance of PIB.', 'The paper does not adequately address potential negative societal impacts or ethical concerns related to the proposed methods.']",3,3,3,3,Reject
0q0REJNgtg,"The paper introduces a retrieval-augmented reinforcement learning (R2A) paradigm, where a retrieval process is trained to map past experiences to optimal behavior for RL agents. This retrieval mechanism aims to address disadvantages of traditional RL methods, such as computational expense and model capacity limitations. The approach is integrated into offline DQN and online R2D2 agents and evaluated on Atari, a multi-task offline RL environment, and the BabyAI environment. The experiments show that R2A improves learning speed and performance compared to baseline methods.","['Can you provide more details on the training process of the retrieval mechanism?', 'How does the computational overhead of R2A compare to the baseline methods in terms of runtime and resource usage?', 'How does the proposed method compare to other non-parametric memory-based RL methods in terms of performance and efficiency?', 'How does the method scale with larger and more complex environments?', 'Can the authors discuss potential negative societal impacts and ethical considerations in more detail?', 'How does the retrieval process handle noisy or irrelevant data in the retrieval dataset?']","['The paper should include a more comprehensive discussion of the computational overhead of the proposed method compared to baseline methods.', 'The potential negative societal impacts of the proposed method should be more thoroughly examined.', 'The method introduces significant complexity, which may limit its practicality for large-scale problems.', 'There is a potential risk that the retrieval process could retrieve misleading or irrelevant information.']",False,3,2,3,5,4,"['Novel approach of integrating a retrieval process with RL agents.', 'Demonstrates significant improvements in learning speed and performance across different environments.', 'Extensive experimentation, including ablations to understand the contributions of various components.', 'Addresses limitations of traditional RL methods, such as computational expense and slow integration of experiences.']","['Some methodological details are unclear, particularly about the retrieval process and its training.', 'The computational overhead of the proposed method compared to baseline methods is not thoroughly analyzed.', 'Limited comparison with related work, especially episodic control methods.', 'The potential negative societal impacts of the proposed method are not adequately discussed.']",3,3,2,3,Reject
kQ2SOflIOVC,The paper introduces a method for few-shot classification of histology images by integrating contrastive learning (CL) and latent augmentation (LA). It proposes three cross-domain tasks to simulate real clinical problems and demonstrates that models trained with CL generalize better than those trained with supervised learning. The proposed method leverages both unsupervised pre-training and latent feature augmentation to improve the generalizability and efficiency of few-shot learning systems.,"['Can the authors provide more detailed theoretical analysis to support the observed empirical results?', 'How does the proposed method perform compared to other few-shot learning techniques beyond those mentioned?', 'Can the authors elaborate on the computational complexity and scalability of their approach?', 'Can the authors provide more robust justification for the claim that latent augmentation significantly outperforms traditional data augmentation?', 'How does the proposed method perform on other types of medical images or non-medical datasets?', 'Can the authors provide more detailed ablation studies on the impact of different hyperparameters in the latent augmentation process?']","['The paper does not address potential failure cases and limitations of the proposed method in detail.', 'Limited discussion on the impact of domain shifts and how robust the method is to varying types of histology images.', 'Potential negative societal impacts such as bias in medical image analysis are not thoroughly examined.', 'The method relies heavily on the quality of the pre-trained encoder, which may limit its applicability to scenarios with less powerful pre-training capabilities.', 'The approach is tailored to histology images, and its generalizability to other types of images or domains is not thoroughly explored.']",False,3,3,3,6,4,"['Addresses a clinically significant problem of few-shot learning in histology images.', 'Combines contrastive learning and latent augmentation which are relevant and promising techniques.', 'Provides extensive experimental validation across various cross-domain tasks.', 'Shares code, enhancing reproducibility and transparency.']","[""The paper's clarity is compromised by dense and complex explanations, making it difficult for readers to follow."", 'Limited theoretical analysis to support the empirical findings.', 'The proposed method relies heavily on empirical results without sufficient discussion on potential limitations and failure cases.', 'Lacks a detailed comparison with more diverse state-of-the-art techniques in few-shot learning.']",3,3,3,3,Reject
gCmCiclZV6Q,"The paper proposes using CLIP, a pre-trained vision-language model, to automate the identification of offensive content in large image datasets. The authors argue that this approach can aid in the curation and documentation of datasets, which is typically a labor-intensive and error-prone process. The method leverages the implicit knowledge encoded in CLIP to identify offensive images based on several categories such as objects, symbols, and actions.","['How does the proposed method compare with other existing methods for identifying offensive content in terms of accuracy and efficiency?', 'Can the authors provide more details on the optimization process for prompt tuning?', 'What measures can be taken to mitigate the biases inherited from the pre-trained models?', 'How does the approach perform on other large-scale datasets beyond ImageNet?', 'What are the specific limitations of the proposed method in terms of false positives and negatives?']","['The paper does not address how the approach would handle the evolving nature of what is considered offensive.', 'The reliance on pre-trained models may propagate existing biases and ethical concerns.', 'There is a potential for misuse if the method is not applied in a human-in-the-loop setting as recommended.', ""The definition of 'offensive' content is subjective and may not be universally applicable.""]",True,3,3,3,5,4,"['Addresses a significant and relevant problem in dataset curation and ethical AI.', 'Proposes a novel use of pre-trained vision-language models for identifying offensive content.', 'Provides empirical results demonstrating the effectiveness of the approach on the ImageNet-ILSVRC-2012 dataset.']","['The paper lacks a detailed comparison with other existing methods for identifying offensive content.', 'The methodology section is somewhat unclear and could benefit from a more comprehensive explanation.', 'The ethical considerations section acknowledges potential biases but does not propose concrete solutions or guidelines for mitigating them.', 'Limited discussion on the limitations and potential negative societal impacts of the proposed approach.', ""The evaluation is limited and does not explore the approach's limitations in diverse contexts.""]",3,3,3,3,Reject
xS8AMYiEav3,"The paper presents REASSURE, a novel methodology for repairing ReLU neural networks by constructing a patch network tailored to the linear region containing the buggy input. The method guarantees the removal of the buggy behavior while minimizing changes in the function space and preserving the continuous piecewise linear nature of the network. Theoretical guarantees for soundness, completeness, minimality, and locality are provided. Experimental results demonstrate that REASSURE outperforms existing methods in terms of repair efficacy, locality, and limiting negative side effects.","['Can you provide more details on how REASSURE can be scaled to very large networks?', 'Is there any discussion on potential negative societal impacts of this work?', 'How does the method perform on networks with non-ReLU activation functions or non-CPWL architectures?', 'Can the approach be extended to other types of neural networks, such as convolutional or recurrent networks?', 'What are the computational limitations of the proposed method when applied to large-scale neural networks?', 'How does REASSURE scale with very high-dimensional input spaces, such as those found in image recognition tasks?', 'What are the computational overheads associated with constructing support networks and patch functions?', 'Can the authors provide more extensive experimental evaluations on diverse datasets and network architectures?', 'How does REASSURE perform in comparison to more recent neural network repair techniques not mentioned in the paper?', 'Can the authors clarify the computational complexity and scalability of the approach for very large networks?']","['The paper lacks a detailed discussion on the potential negative societal impacts of the proposed methodology.', 'The approach may face scalability challenges with high-dimensional inputs.', 'Potential computational overhead due to the construction of support networks and patch functions.', 'The effectiveness of the approach in non-ReLU networks is not explored.', 'The evaluation is limited to specific benchmarks; broader validation is necessary.', 'The practicality of applying REASSURE in real-world scenarios with very large and complex neural networks is unclear.']",False,4,3,3,7,4,"['Novel approach to neural network repair with strong theoretical guarantees.', 'Comprehensive theoretical analysis and proofs.', 'Experimental results showing significant improvement over existing methods.', 'Clear and well-organized presentation of the methodology and results.']","['Potential scalability concerns with high-dimensional input spaces.', 'Limited applicability to non-ReLU networks.', 'The need for further experiments on more diverse and complex datasets to validate the effectiveness and scalability of the approach.', 'Limited discussion on potential negative societal impacts.']",4,4,3,4,Accept
OqHtVOo-zy,"The paper proposes a novel approach for handling instance-dependent label noise by using a Bayes label transition matrix estimated via deep neural networks. The authors argue that transitioning from Bayes optimal labels to noisy labels reduces uncertainty and enables better generalization. The method is applied to multiple datasets with various levels of noise, showing superior performance over state-of-the-art methods.","['Can the authors provide more insight into how the assumption that patterns causing label noise are commonly shared holds in various real-world scenarios?', 'How significant is the distribution bias in the distilled examples, and what approaches could mitigate this issue?', 'Can the authors provide more details on the theoretical guarantees for the distilled examples?', 'How does the proposed method handle cases where the noise rate is extremely high?', 'What are the potential biases introduced by using distilled examples, and how can they be mitigated?', 'Can you provide more details on the mathematical formulation and theoretical guarantees?', 'How does the model generalize to real-world datasets with different noise characteristics?', 'Can you elaborate on the potential societal impacts and limitations of your work?']","['The assumption that patterns causing label noise are commonly shared might not always be valid.', 'Potential distribution bias in distilled examples could affect the transition matrix estimation.', ""The method's performance in scenarios with extremely high noise rates needs to be evaluated further."", 'The paper lacks a thorough discussion on the limitations of the proposed method.', 'Potential biases in the distilled dataset are not deeply analyzed.', 'Societal impacts are mentioned briefly but not discussed in detail.']",False,4,3,4,7,4,"['Addresses a significant problem in weakly supervised learning.', 'Introduces a novel and theoretically sound approach: the Bayes label transition matrix.', 'Well-described methodology with thorough experiments demonstrating superior performance.', 'Utilizes deep neural networks for scalable and efficient estimation of transition matrices.']","['The paper is dense and complex, potentially difficult for readers to fully understand without multiple readings.', 'Assumption that patterns causing label noise are commonly shared may not always hold in practice.', 'Potential distribution bias in distilled examples is mentioned but not thoroughly investigated.', 'Theoretical concepts are not explained clearly, making it difficult for readers to fully grasp the methodology.', 'Limited discussion on potential societal impacts and limitations.', 'Some sections of the paper lack clarity and are difficult to follow.']",4,4,3,4,Accept
oTQNAU_g_AZ,"The paper presents DAIR (Disentangled Attention Intrinsic Regularization), a novel method to address the domination and conflict issues in bimanual robot manipulation tasks. The method uses an intrinsic regularization term to encourage robots to focus on different subtasks using disentangled attention, leading to safer and more efficient cooperation. The approach is evaluated on five diverse tasks, showing significant improvements over baselines in terms of efficiency, safety, and generalization.","['Can the authors provide more details on the theoretical foundations of DAIR? How does the disentangled attention mechanism theoretically lead to reduced conflicts and domination?', 'The paper mentions that the code will be released upon publication. Can the authors provide a timeline or ensure the code is available for reviewers?', 'Can the authors provide more details on the implementation of the disentangled attention mechanism?', 'How does the method generalize to different robot types or task configurations?', 'What are the potential limitations of the proposed approach?', 'Can the authors provide more details on the selection and tuning of hyperparameters, particularly λ?', 'How does the performance of DAIR compare to other state-of-the-art methods not included in the current set of baselines?', 'Can the authors elaborate on the potential negative societal impacts of their work, especially in the context of real-world applications?']","['The paper does not currently provide the code, which impacts reproducibility.', 'Theoretical analysis is limited; more insights into why the method works would be beneficial.', 'The paper does not sufficiently address the potential limitations of the proposed method, particularly in real-world scenarios.', 'There is no discussion on the potential negative societal impacts of deploying such robotic systems in various environments.', 'The scalability of the method to more complex and higher-dimensional tasks is not explored.']",False,3,3,3,7,4,"['Addresses a critical problem in multi-agent reinforcement learning: domination and conflict in bimanual manipulation.', 'Proposes a novel intrinsic regularization technique using disentangled attention.', 'Comprehensive experimental evaluation on five diverse tasks, showing significant improvements over baselines.', 'Demonstrates improved sample efficiency, reduced conflicts, and better generalization to more complex tasks.']","['The clarity of the paper can be improved; some sections are dense and difficult to follow.', 'Theoretical analysis of the proposed method is limited; a deeper exploration could strengthen the paper.', 'Reproducibility is promised but not currently available, which is crucial for validating the results.', 'Limited discussion on the limitations and broader impacts of the work.', 'Potential overfitting to specific tasks due to the chosen regularization technique.']",3,3,3,4,Accept
KSSfF5lMIAg,"The paper proposes novel model-agnostic interpretability methods for Multiple Instance Learning (MIL) models. The authors critique existing methods, which are often model-specific and limited by certain assumptions, and introduce new methods that can be applied across various MIL models. They evaluate these methods on several datasets, demonstrating up to a 30% increase in interpretability accuracy.","['Can the authors provide more theoretical analysis to support the claims made in the paper?', 'How do the proposed methods impact the overall performance of the MIL models?', 'What is the computational complexity of each proposed method, and how does it compare to existing methods?', 'Can the authors provide more clarity on the choice of hyperparameters for the MILLI method?', 'How do the proposed methods perform on more complex and varied MIL datasets beyond those tested?', 'Can the authors discuss the potential negative societal impacts and ethical considerations in more detail?', 'Can the authors provide more details on the hyperparameter tuning process for MILLI and other methods?', 'How do the proposed methods perform on datasets with different characteristics, such as varying bag sizes or instance distributions?', 'Are there any limitations in terms of computational complexity or scalability for the proposed methods?', 'Can you provide more detailed explanations of the methodological steps, particularly in Sections 3.2 and 3.3?', 'Have you considered evaluating the methods on more real-world datasets to better understand their practical applicability?', 'Could you elaborate on the potential ethical and societal impacts, especially for sensitive applications like healthcare?', 'Can the authors provide more details on how hyperparameters were tuned for each dataset?', 'How do the proposed methods compare in computational complexity to existing methods?', 'Can the authors clarify the novelty of their methods compared to existing techniques like LIME and SHAP?']","['The paper should address the potential computational overhead of the proposed methods.', 'The authors should discuss the applicability of their methods in real-time or large-scale scenarios.', 'The paper does not thoroughly address the potential negative societal impacts and ethical considerations.', 'Some explanations, particularly in the methodology section, are unclear and could benefit from further elaboration.', 'The methods are evaluated on a limited set of datasets, raising concerns about their generalizability to other types of data.', 'The computational complexity of the proposed methods, especially MILLI, could be a limiting factor for large-scale applications.', 'The evaluation focuses mainly on synthetic and benchmark datasets, which may not fully represent real-world scenarios.', 'Possible over-reliance on certain features (e.g., color) for interpretability, which may not generalize well to other datasets.']",False,3,3,3,6,4,"['Comprehensive critique of existing MIL interpretability methods.', 'Introduction of novel, model-agnostic methods.', 'Thorough empirical evaluation on multiple datasets.', 'Addresses a relevant problem in MIL interpretability.', 'Clear improvement in interpretability accuracy over existing methods.']","['Lacks sufficient theoretical analysis to fully support the claims.', 'Complexity of new methods, particularly MILLI, might limit practical applicability.', 'Evaluation focuses heavily on interpretability metrics without balancing model performance.', 'Potential reproducibility concerns despite the provided code and detailed appendices.', 'Limited discussion on ethical implications and potential negative societal impact.', 'Some unclear explanations in the methodology section, particularly regarding the MILLI hyperparameters and sampling strategies.', 'The reliance on specific datasets may limit the generalizability of the findings.', 'The evaluation metrics could be more diverse to cover different aspects of interpretability.']",3,3,3,3,Reject
on54StZqGQ_,"The paper introduces degradation attacks on certifiably robust neural networks, showing that these models can erroneously reject non-adversarial inputs, thereby reducing utility. It proposes attack algorithms and evaluates their effectiveness against state-of-the-art certifiable defenses like GloRo Nets and Randomized Smoothing. The study also suggests potential defenses against such attacks.","['Can the authors provide more detailed explanations and examples to improve the readability of the mathematical notations?', 'How do degradation attacks compare to other types of adversarial attacks in terms of practical impact on deployed models?', 'Can the authors evaluate the proposed defense strategies more rigorously?', 'How do the proposed defenses compare to other potential defenses in terms of computational cost and practical feasibility?', 'Could the authors clarify the impact of their findings on real-world applications beyond image classification, such as autonomous driving systems?']","['The paper acknowledges that the proposed defenses are not fully evaluated and leaves significant future work in this area.', 'Potential negative societal impacts include the possibility of malicious actors using degradation attacks to compromise the utility of deployed models.', 'The empirical evaluations are limited to a few datasets and model architectures, which may not generalize to other settings.']",False,3,3,3,5,4,"['Identifies a novel vulnerability in certifiably robust neural networks.', 'Provides empirical evidence demonstrating the efficacy of degradation attacks.', 'Addresses a significant issue in the field of adversarial robustness.']","['The novelty of the attack methods is limited; they primarily repurpose existing adversarial attack algorithms.', 'The theoretical foundations for the success of these attacks are not deeply explored.', 'The proposed defenses are speculative and not thoroughly evaluated.', 'The paper is dense and challenging to follow, particularly in the methodological sections.', 'The practical applicability and societal impacts of the proposed solutions need more discussion.']",3,3,3,3,Reject
R3zqNwzAVsC,"The paper introduces the Ethical Module, a post-processing method to mitigate gender bias in pre-trained face recognition models. It involves training a shallow neural network using the von Mises-Fisher loss to adjust the deep embeddings from the pre-trained model, thereby improving representation for discriminated subgroups.","['How does the proposed method compare with other state-of-the-art bias mitigation techniques?', 'Can the authors provide more detailed explanations and intuitive interpretations of the von Mises-Fisher loss?', 'What are the potential ethical implications of deploying the Ethical Module in real-world applications?', 'How does the reliance on private gender classifiers affect the generalizability of the results?', 'Can the method be extended to address other types of bias, such as racial or age bias?']","['The method focuses only on gender bias, limiting its applicability to other types of bias.', 'Reliance on private gender classifiers may introduce additional biases and affect generalizability.', 'Insufficient discussion on the potential negative societal impacts of the proposed method.', 'Potential over-reliance on the von Mises-Fisher loss hyperparameters, which might limit the generalizability.']",True,2,2,2,3,4,"['Addresses the critical issue of bias in face recognition.', 'Proposes a computationally efficient post-processing method.', 'Includes extensive experimental validation on multiple datasets.']","['Limited originality; similar post-processing methods have been proposed before.', 'Clarity is compromised by dense mathematical notations and insufficient explanations.', 'Lacks comprehensive comparisons with other state-of-the-art bias mitigation techniques.', 'Potential ethical implications are not thoroughly addressed.', 'Relies on pre-trained gender classifiers, which may introduce additional biases.', 'Limited exploration of intersectional biases and other types of biases beyond gender.']",2,2,2,2,Reject
BGvt0ghNgA,"The paper introduces Lipschitz-constrained Skill Discovery (LSD), a novel method for unsupervised skill discovery in reinforcement learning that overcomes the limitations of mutual information-based approaches. LSD encourages the discovery of dynamic and diverse skills by incorporating a Lipschitz continuity constraint. The authors demonstrate the effectiveness of LSD through extensive experiments in MuJoCo environments, showing significant improvements over existing methods.","['Can the authors provide more details on the applicability of LSD to environments beyond MuJoCo?', 'How does the performance of LSD compare in real-world robotics tasks?', 'Are there any specific ethical considerations or potential negative impacts associated with this work?', 'Can the authors provide more theoretical insights into why the Lipschitz constraint specifically leads to more dynamic skills?', 'How does LSD perform in environments with high-dimensional observations, such as pixel-based inputs?', 'Can the authors compare LSD with a broader range of baseline methods to further validate its effectiveness?']","['The effectiveness of LSD in environments where Lipschitz constraints are not meaningful is not fully addressed.', 'The paper is primarily focused on MuJoCo environments, which may limit the perceived applicability of the method.', 'LSD may not encourage dynamic behaviors in environments where Lipschitz constraints are not semantically meaningful, such as pixel-based control.', 'Continuous LSD mainly discovers locomotion skills, which might limit its applicability in diverse environments without modifications.', 'The skills learned are influenced by the state space normalization, which could affect generalizability.']",False,3,3,3,7,4,"['Novel approach that addresses limitations of MI-based skill discovery methods.', 'Comprehensive experimental evaluation and comparisons.', 'Theoretical justification and empirical validation of the proposed method.', 'Potential for zero-shot goal-following without further training.', 'Clear demonstration of the limitations of MI-based methods.']","['Limited to MuJoCo environments; applicability to more diverse or real-world environments is not explored.', 'Potential limitations in environments where Lipschitz constraints are not meaningful.', 'Dense technical content may be difficult for some readers to follow.', 'Ethical considerations and broader impacts are not thoroughly discussed.', 'The novelty of using Lipschitz constraints in skill discovery might not be sufficiently groundbreaking as it builds on existing techniques like spectral normalization.']",4,3,3,3,Accept
1XdUvpaTNlM,"The paper introduces a probabilistic channel pruning method called Batch Whitening Channel Pruning (BWCP) for CNNs. The method uses batch whitening to enhance the activation probability of important channels while stochastically pruning unimportant ones. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet datasets demonstrate the effectiveness of BWCP in reducing computational cost while maintaining accuracy.","['Can the authors provide the source code and a detailed list of hyperparameters for reproducibility?', 'How does the method perform on other tasks beyond image classification, such as object detection or segmentation?', 'Can the authors provide a more detailed analysis of the limitations and potential negative societal impacts of BWCP?', 'Can the authors provide more intuitive explanations for the mathematical derivations?', 'How sensitive is the method to the choice of regularization parameters?', 'Can the authors provide more details on the computational overhead introduced by the whitening technique?', 'How does BWCP perform on other types of neural networks, such as RNNs or transformers?', 'Can the authors discuss potential limitations or scenarios where BWCP may not perform well?', 'What are the potential ethical considerations and societal impacts of deploying BWCP in real-world applications?']","['The paper lacks discussion on the potential limitations of the method, such as its applicability to other types of neural networks or tasks beyond image classification.', 'There is no detailed analysis of the potential negative societal impacts, such as fairness and bias in the pruned models.', 'The method requires careful tuning of regularization parameters.', 'The computational overhead during training is increased due to the whitening technique.', 'The complexity of the BWCP method may limit its practical applicability, especially in resource-constrained environments.']",False,3,2,3,4,4,"['Novel probabilistic approach to channel pruning.', 'Extensive experimental validation on multiple datasets.', 'Theoretical analysis supporting the method.', 'Significant improvement in accuracy and computational efficiency.']","['Complexity of the proposed method may hinder its practical applicability.', 'Presentation and clarity need significant improvement.', 'Reproducibility is not fully addressed; code and hyperparameters should be provided.', 'Lack of detailed analysis on limitations and potential negative societal impacts.', 'Mathematical derivations are dense and hard to follow.']",3,3,2,3,Reject
cpstx0xuvRY,"The paper presents a theoretical analysis of the generalization error of iterative semi-supervised learning (SSL) algorithms using information-theoretic principles, focusing on a binary Gaussian mixture model (bGMM). The authors provide theoretical bounds on the generalization error and validate these bounds with experiments on benchmark datasets such as MNIST and CIFAR.","['Can the theoretical results be extended to more complex data distributions beyond the binary Gaussian mixture model?', 'How sensitive are the results to the choice of hyperparameters in the experiments?', 'Can you provide more comprehensive empirical results to validate the theoretical claims?', 'How do the derived bounds compare with existing bounds in the literature for similar setups?', 'What are the potential limitations of your theoretical framework in practical applications?', 'Can you provide more details on how the theoretical bounds were derived? Some steps in the derivation are not very clear.', 'How does your work compare to other methods that also use information-theoretic bounds for generalization error in SSL?', 'Can you elaborate on the choice of the binary Gaussian mixture model? How well does it generalize to more complex data distributions?', 'Can the authors provide additional experiments on more diverse datasets?', 'How would the proposed bounds apply to more complex models beyond bGMM?', 'Could the authors improve the clarity of some of the more complex mathematical formulations?', 'Can the authors provide more intuitive explanations or visual aids to enhance the understanding of their theoretical results?', 'How does the proposed method compare with other state-of-the-art SSL methods not mentioned in the paper?']","['The reliance on bGMM limits the generalization of theoretical results to more complex real-world data distributions.', 'The complexity of mathematical derivations may limit the accessibility of the paper to a broader audience.', 'The empirical validation is limited and may not comprehensively support the theoretical claims.', 'The potential societal impacts of improved SSL algorithms are not discussed.', 'The paper does not sufficiently address the scalability of the proposed method to very large datasets.', 'Potential societal impacts of using pseudo-labels, which might reinforce biases in the data, are not discussed.']",False,3,3,3,6,4,"['Addresses an important problem in semi-supervised learning.', 'Provides a novel theoretical framework using information-theoretic principles.', 'Theoretical results are validated through experiments on benchmark datasets.']","['Complex mathematical derivations and notations make the paper difficult to follow.', 'Theoretical results are based on bGMM, which may limit generalization to more complex real-world data distributions.', 'Experimental section could benefit from more extensive evaluation on diverse datasets and models.', 'Potential limitations and societal impacts of the work are not adequately discussed.']",3,3,3,4,Reject
Wm3EA5OlHsG,"The paper introduces the Scene Transformer, a novel model for joint motion prediction in autonomous driving. The model uses a scene-centric, agent permutation equivariant architecture inspired by Transformers and achieves state-of-the-art performance on the Argoverse and Waymo Open Motion Dataset (WOMD). The model is flexible and can perform multiple prediction tasks using a masking strategy.","['How does the model perform in completely unseen driving scenarios?', 'Can the authors provide more details on the computational resources required?', 'What steps have been taken to address potential biases in the datasets?', 'Can the authors provide more detailed explanations of the factorized self-attention mechanism?', 'How does the model handle edge cases where agent interactions are highly non-linear and unpredictable?', 'Can the authors discuss the computational efficiency of the model in more detail?', 'Are there any ablation studies to isolate the contribution of different components of the architecture?', 'How do the authors plan to address potential ethical concerns related to the deployment of the model in real-world scenarios?', 'Can the authors provide more insights into the potential limitations and failure cases of the proposed model?', 'What are the ethical considerations and potential societal impacts of deploying this model in real-world autonomous driving scenarios?', 'How does the proposed model handle edge cases or rare events in the dataset?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?']","['The paper does not fully address the potential biases in the data and the societal impact of deploying the model.', 'The complexity of the architecture may limit reproducibility.', 'The complexity of the model may make it difficult to deploy in real-time applications.', 'Limited exploration of the trade-offs between model performance and computational cost.', 'Potential failure cases and limitations are not discussed in detail.', 'The lack of detailed ablation studies makes it difficult to attribute improvements to specific components.', 'The potential negative societal impacts of the work are not thoroughly discussed. For example, how might this model be used in ways that could harm public safety?']",True,3,3,4,7,4,"['Innovative unified architecture for multiple motion prediction tasks.', 'State-of-the-art performance on Argoverse and WOMD datasets.', 'Flexible masking strategy for different prediction tasks.', 'Efficient factorized self-attention mechanism.']","['Complex architecture and training process.', 'Evaluation metrics may not fully capture the quality of multi-agent interactions.', 'Potential generalizability issues to unseen driving scenarios.', 'Inadequate discussion of potential negative societal impacts.', 'Limited discussion on computational efficiency and scalability.', 'Lack of detailed ablation studies.']",4,3,3,4,Accept
-uZp67PZ7p,"The paper presents a novel approach for solving inventory management (IM) problems using Multi-Agent Reinforcement Learning (MARL). It introduces the concept of shared-resource stochastic games and proposes the Context-aware Decentralized Proximal Policy Optimization (CD-PPO) algorithm. The contributions include modeling agents' interactions through shared resources, proposing an efficient learning algorithm, and demonstrating superior performance through extensive experiments.","['How does the proposed method perform on different datasets and in different scenarios, such as varying levels of demand volatility?', 'Can the theoretical convergence properties of the surrogate objective function be further elaborated?', 'How does the method scale with an even larger number of SKUs or more complex multi-echelon supply chains?', 'Can the authors provide more details on the context augmentation methods and their impact on the performance of the algorithm?', 'How does the proposed method handle scenarios with more complex interactions among agents beyond shared resources?', 'Can the authors provide a more detailed comparison with existing baselines, particularly in terms of the computational complexity and scalability of the methods?']","['The method is not tested on distributed environments, which is a significant area for future work.', 'Potential negative societal impacts, such as job displacement due to automation, are not discussed.', 'The paper does not adequately discuss the limitations of the proposed method, particularly in scenarios with highly dynamic and unpredictable environments.', 'Scalability to a very large number of agents and real-time applications may be challenging.']",False,3,3,3,6,4,"['The concept of shared-resource stochastic games is novel in the context of inventory management problems.', 'The proposed CD-PPO algorithm effectively leverages the shared-resource structure to improve learning efficiency.', 'The methodology is well-explained, and the experimental results support the claims of improved performance.', 'The paper is clearly written and well-organized, allowing for reproducibility.', 'The approach addresses a significant problem in supply chain management and has potential applications in other domains.']","['The experimental scope is limited to a specific dataset (Walmart sales data). Additional datasets could further validate the approach.', 'Comparisons with other state-of-the-art methods could include more diverse MARL algorithms.', 'The paper lacks a thorough theoretical analysis of the surrogate objective function and its convergence properties.', 'The clarity of the presentation could be improved, particularly in the methodology section.', 'The potential negative societal impacts, such as job displacement due to automation, are not discussed.']",3,3,3,3,Accept
vgqS1vkkCbE,"The paper introduces Value Function Spaces (VFS), a novel approach for state abstractions in hierarchical reinforcement learning (HRL). By using value functions of low-level skills, VFS creates a skill-centric representation that aids in long-horizon reasoning. The authors demonstrate the effectiveness of VFS through empirical evaluations in maze-solving and robotic manipulation tasks, showing that it outperforms several competitive baselines. The primary contribution is the introduction of VFS, which leverages the properties of value functions to form an effective representation for high-level planning.","['How can the proposed method be extended to include the learning of low-level skills?', 'Can the authors provide more details on the potential ethical concerns associated with their approach?', 'How does the method perform in other domains beyond maze-solving and robotic manipulation?', 'Can the authors provide more details on the hyperparameters used in the experiments?', 'How does VFS perform in combination with other representation learning methods?', 'What are the main failure cases for VFS, and how can they be addressed?', 'Can the authors provide more diverse experimental tasks to validate the broader applicability of VFS?', 'Can the authors provide more details on the implementation of the VFS representation?', 'How does VFS perform in more diverse and complex environments beyond maze-solving and robotic manipulation?', 'Could the authors clarify the process of constructing the value function space and its computational complexity?', 'How does the performance of VFS change with different sets of low-level skills? Are there any limitations in terms of skill diversity?', 'Can the authors provide more insights into the computational complexity and scalability of VFS?', 'How does the proposed VFS method compare with more recent HRL techniques not covered in the paper?', 'Can the authors provide more details on the hyperparameters and training protocols used in the experiments?', 'What are the specific limitations of VFS in its current form, and how can they be addressed in future work?']","['The paper does not address the learning of low-level skills, which is crucial for HRL.', 'The generalizability of the approach to other domains is not well-explored.', 'Potential ethical concerns and limitations are not discussed in detail.', 'The method might not generalize well to tasks that require different sets of skills or have different dynamics.', 'The scalability of the approach to more complex tasks with a higher number of low-level skills is not thoroughly evaluated.', 'There is limited discussion on how VFS behaves in partially observable settings, which are common in real-world applications.', 'Potential negative societal impacts, such as the misuse of robotic systems trained using VFS, are not discussed.']",False,3,3,3,6,4,"['Novel concept of using value functions for state abstractions.', 'Thorough empirical evaluations demonstrating significant improvements.', 'Clear and well-organized presentation.', 'Demonstrates improved performance in long-horizon tasks and zero-shot generalization.']","['Does not address how low-level skills are learned.', 'Experimental results are limited to specific tasks, raising questions about generalizability.', 'Lacks detailed discussion on potential ethical concerns and limitations.', 'Insufficient details on experimental setups and hyperparameters.', 'The combination with other representation learning methods is not fully explored.', 'The methodology lacks clarity in some sections, making it difficult to reproduce results.']",3,3,3,3,Reject
2DJn3E7lXu,The paper evaluates 18 different hardware metric predictors in the context of Neural Architecture Search (NAS) across multiple datasets and metrics. It identifies Multi-Layer Perceptron (MLP) models as the most promising predictors and quantifies the impact of predictor inaccuracies on architecture selection. The study also suggests that verifying predictions of selected architectures can lead to improved results and that fast but inaccurate prediction models can be preferable under a time budget. The authors provide their code and results to facilitate reproducibility.,"['Can the authors provide more clarity on the choice of datasets and their relevance?', 'How do the results generalize to other types of NAS tasks beyond the ones studied?', 'Can the authors elaborate more on the limitations and potential drawbacks of using MLPs as the best predictors?', 'How do the results compare to other recent studies in the same domain?', 'What are the limitations of the simulation approach, and how might they affect the conclusions?', 'Have you considered including meta-learning predictors in your evaluation?', 'Can you provide more details on how the simulation results compare to real-world scenarios?', 'What are the specific limitations of the top-performing predictors such as MLPs?', 'How do the authors address the potential overfitting of the predictors to specific datasets?', 'Can the authors provide more details on the hyperparameter tuning process for each predictor?']","['The authors should discuss more potential drawbacks and limitations of using MLPs as the best predictors.', 'The societal impact of hardware-aware NAS should be addressed more comprehensively.', 'The simulation approach may not fully capture the complexities of real-world NAS, and this should be addressed.', 'The study acknowledges the absence of meta-learning predictors and the limitations of simulations in capturing real-world scenarios. It also notes the need for more detailed analysis of predictor limitations.', 'The paper could further explore the potential overfitting of predictors to specific datasets and provide more details on the generalizability of the results.']",False,3,2,3,5,4,"['Comprehensive evaluation of a wide range of predictors.', 'Detailed analysis and comparison using multiple datasets.', 'Simulation to quantify the impact of predictor accuracy on architecture selection.', 'Provision of code and data for reproducibility.']","['The clarity of the presentation is sometimes lacking, with dense text and complex figures.', 'Limited novelty; many concepts are incremental improvements rather than groundbreaking.', 'Potential weaknesses in experimental design, such as the choice of predictors and datasets.', 'The simulation approach has limitations and may not fully capture real-world scenarios.', 'The practical significance of the findings may be limited to a specific aspect of NAS, reducing its broad interest to the community.']",3,3,2,3,Reject
aBAgwom5pTn,"The paper presents DYHPO, a novel dynamic and efficient gray-box hyperparameter optimization method utilizing Bayesian optimization with a deep kernel Gaussian Process surrogate. DYHPO addresses the poor correlation of hyperparameter performance at different budgets by dynamically deciding which configurations to continue and how much budget to allocate. The method is evaluated on 50 datasets across various modalities (tabular, image, NLP) and shows significant improvements over state-of-the-art baselines.","['Can the authors provide more detailed steps for reproducing the experiments, particularly the implementation specifics of the surrogate model and acquisition function?', 'How were the computational resources managed to ensure fair comparison across different methods?', 'What are the theoretical justifications for the chosen deep kernel and its specific architecture?', 'Can the authors discuss potential limitations and negative societal impacts in more depth?', 'How does DYHPO perform on very large deep learning models such as Transformers?', 'Can the authors provide more mathematical details on the deep kernel GP and the multi-fidelity expected improvement acquisition function?', 'How does DYHPO handle the computational overhead of fitting the Gaussian Process model, especially with large datasets?', 'Is there a plan to release the code to ensure reproducibility of results?']","['The paper does not adequately discuss potential limitations, such as the scalability to very large models or the impact of different types of hyperparameter configurations.', 'There is a lack of discussion on the negative societal impacts, like the environmental cost of extensive computational experiments.', ""The method's applicability to very large deep learning models is not evaluated."", 'Reproducibility is affected by the lack of detailed experimental setup information.']",False,3,2,3,6,4,"['Introduces a novel approach combining gray-box HPO with Bayesian optimization and deep kernels.', 'Demonstrates significant empirical improvements over state-of-the-art methods across diverse datasets and models.', 'Thorough experimental evaluation with detailed analysis and comparisons.', 'Addresses an important problem in the optimization of deep learning hyperparameters.']","['Method description lacks clarity in some parts, making it difficult to reproduce the results.', 'Fairness of some comparisons can be questioned, particularly in terms of computational resources and hyperparameter settings for baselines.', 'The paper doesn’t adequately discuss potential limitations and negative societal impacts.', ""Some theoretical justifications for the method's effectiveness are lacking or not well-explained."", 'Limited evaluation on very large deep learning models, such as transformers, which are crucial for practical applications.']",3,3,2,3,Reject
SsPCtEY6yCl,"The paper investigates the uncomputability and inapproximability of partition functions in energy-based sequence models (EBMs), presenting rigorous theoretical proofs and discussing the implications for model selection and parameter estimation. The authors suggest less expressive model families as alternatives to mitigate these issues.","['Can the authors provide more intuitive explanations or practical examples to make the content more accessible?', 'Are there any potential practical applications or experiments that could illustrate the impact of the theoretical findings?', 'Can the authors provide more concrete examples or case studies where these theoretical findings impact practical applications?', 'Are there any proposed methods or guidelines for practitioners to navigate the computability issues highlighted in this paper?', 'How do these theoretical limitations affect existing energy-based models used in NLP or bioinformatics?']","['The paper is highly theoretical and may not provide immediate practical applications.', 'The dense mathematical content may limit accessibility to a broader audience.', 'The practical impact of the theoretical results is not well-explored.', 'The proposed alternatives may not address all practical concerns without empirical validation.']",False,4,4,4,8,4,"['Novel exploration of uncomputability issues in energy-based sequence models.', 'Technically sound with thorough proofs and logical consistency.', 'Addresses a fundamental issue in theoretical machine learning.', 'Well-structured and comprehensive coverage of related topics.']","['Highly theoretical with limited immediate practical applicability.', 'Dense content that may be challenging for a broad audience.', 'Lack of concrete solutions or alternatives that can be directly applied by practitioners.', 'Proposed alternatives are not extensively validated through empirical studies.']",4,4,4,4,Accept
RxplU3vmBx,"The paper introduces a Cost-Free Incremental Learning (CF-IL) method that mitigates catastrophic forgetting in deep neural networks by synthesizing past exemplars through a memory recovery paradigm. This method does not require additional memory buffers or parallel networks, relying solely on the learner network to recall previous knowledge. The approach is evaluated on CIFAR-10 and Tiny-ImageNet datasets, showing competitive performance compared to state-of-the-art methods.","['Can the authors provide more details on the initialization and optimization process for generating synthesized samples?', 'How does the computational complexity of the proposed method compare to other state-of-the-art methods?', 'Can the authors discuss the limitations of the proposed method in more detail, particularly in terms of scalability to larger datasets?', 'Could the authors provide a more thorough theoretical analysis of why the proposed method works?', 'How were the hyperparameters chosen, and could there be a more systematic approach to their selection?', 'What are the potential negative societal impacts of the proposed method?', 'How does the performance of CF-IL compare to other state-of-the-art methods in a more comprehensive set of benchmarks?', 'Can the authors provide more detailed explanations and diagrams for the memory recovery paradigm?', 'What are the potential limitations and failure scenarios for CF-IL?', 'How does the method handle classes with highly imbalanced data?', 'What are the specific hyperparameters used in the experiments, and how were they selected?', 'Can the authors elaborate on the ablation studies and the impact of different hyperparameters on the performance?', 'Are there any potential limitations or negative societal impacts of the proposed method?', 'Can the authors provide more details on the memory recovery paradigm, specifically the constraint application step?', 'How does the method perform in scenarios with a significantly higher number of classes or more complex datasets?']","['The paper does not adequately address the computational complexity and scalability of the proposed method.', 'There is a need for clearer explanations of certain methodological aspects, such as the memory recovery paradigm.', 'The method relies on empirical selection of hyperparameters.', 'Theoretical analysis of the method is lacking.', 'Potential negative societal impacts are not discussed.', ""The method's effectiveness may vary with the complexity of the dataset."", 'Scalability to very large datasets is not thoroughly evaluated.', 'The potential for generating misleading or incorrect pseudo-examples needs consideration.', 'The paper does not discuss the limitations related to the scalability and potential biases of the memory recovery paradigm.', 'No discussion on the potential negative societal impacts of the proposed method.', 'The paper could benefit from a more detailed discussion on the limitations of relying solely on the learner network for memory recovery.', ""Further exploration of the method's scalability and performance on more complex datasets would be valuable.""]",False,3,2,3,6,4,"['Innovative approach to synthesizing past experiences without additional memory requirements.', 'Extensive experimental validation on well-known datasets.', 'Clear motivation and problem statement addressing a significant issue in incremental learning.', 'Potential to significantly reduce memory overhead in incremental learning.']","['The clarity of the methodology, particularly the memory recovery paradigm, could be improved.', 'Potential overclaims about the superiority of the method without sufficient justification.', 'Limited discussion on the computational complexity and efficiency of the proposed method.', 'Lacks thorough theoretical analysis.', 'Hyperparameters are empirically chosen without clear justification.', 'Potential negative societal impacts are not discussed.', 'Experimental setup details are insufficient for reproducibility.', 'Ablation studies and comparisons with other methods are not well-explained.']",3,3,2,3,Reject
PgNEYaIc81Q,"The paper introduces the ComPhy dataset for compositional physical reasoning, focusing on hidden physical properties like mass and charge. It also proposes a neural-symbolic framework, Compositional Physics Learner (CPL), to tackle the tasks posed by the dataset. The dataset and model are evaluated against various baselines, showing the challenges in physical reasoning tasks.","['How was the dataset balanced to ensure fair evaluation?', 'Can you provide more details on how the baselines were implemented and trained?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide more insights into simplifying the CPL model for broader research use?', 'What are potential approaches to improve the generalizability of the model on more complex scenes?', 'Can the authors provide more details on the limitations of their proposed model?', 'How does the model perform on more complex scenes, and what are the challenges?', 'What are the potential societal impacts and ethical considerations of this work?', 'Can you provide more details on how the CPL model ensures the accuracy of inferred physical properties?', ""How does CPL handle cases where the initial perception of objects' properties is incorrect?""]","['The generalization of the proposed model to real-world scenarios is not thoroughly discussed.', 'More details on potential limitations and negative societal impacts would be helpful.', 'The complexity of the CPL model may hinder its accessibility and use in broader research.', ""The model's performance drops on more complex scenes, indicating potential issues with generalizability."", 'Scalability and generalization to more complex scenes are not deeply analyzed.', ""Potential limitations in the model's ability to predict long-term dynamics."", 'The paper does not discuss potential biases in the dataset, such as object appearance correlations.', ""The proposed model's complexity might hinder its practical applicability and reproducibility.""]",False,3,3,3,6,4,"['Introduction of a novel dataset, ComPhy, which focuses on hidden physical properties.', 'Proposal of a new neural-symbolic framework, CPL, for compositional physical reasoning.', 'Thorough experimental evaluation showing the challenges of the proposed dataset.', 'Comprehensive evaluation of a wide range of baseline models.', 'Innovative model combining multiple components.']","['The paper is dense and could be made more concise.', 'Some technical details, especially in the methodology, are hard to follow.', 'Limited discussion on the generalization of the proposed model to real-world scenarios.', 'The proposed CPL model is complex and may not be easily accessible for broader research use.', ""Significant performance drops on more complex scenes, questioning the model's robustness and generalizability."", 'Lacks thorough analysis on limitations.', 'No discussion on ethical considerations and societal impacts.']",4,3,3,3,Reject
qI4542Y2s1D,"The paper 'FILM: FOLLOWING INSTRUCTIONS IN LANGUAGE WITH MODULAR METHODS' introduces a modular approach for embodied instruction following, achieving state-of-the-art performance on the ALFRED benchmark without requiring expert trajectories or low-level language instructions. The method comprises language processing, semantic mapping, semantic search policy, and a deterministic policy for navigation and interaction.","['Can the authors provide more details on how the deterministic policy compares to learned policies in more complex scenarios?', 'What are the specific limitations and potential negative societal impacts of the proposed method?', 'How does the choice of grid size for the semantic search policy affect the performance, and why was adaptive grid sizing not considered?', 'How feasible is the template assumption for different types of instructions and environments, and what alternatives can be explored?', 'Can the authors provide more details on how the templates for language processing were created and how they affect the generalizability of the method?', 'What are the potential negative societal impacts of deploying such embodied agents in real-world environments?', 'How does the performance of FILM compare on other benchmarks or in more diverse real-world scenarios?', 'What are the computational requirements for training and deploying FILM?', 'Can the method be extended to handle more complex tasks involving multiple rooms or outdoor environments?', 'How does the performance of FILM change when applied to environments significantly different from those in ALFRED?', 'Can the semantic search policy be adapted to new tasks or environments without extensive retraining?', 'What are the implications of the potential biases in the trained models for real-world applications?', 'Can the proposed method generalize to other tasks and environments beyond the ALFRED benchmark?', 'What are the potential biases in the training data, and how do they impact the results?', 'Can you provide more insights into the failure modes and limitations of the proposed method?']","[""The reliance on pre-trained models and fine-tuning might limit the demonstration of the modular approach's full capabilities."", 'The deterministic policy may not be robust enough for more complex scenarios.', 'Potential negative societal impacts and ethical concerns are not thoroughly discussed.', 'The effectiveness of the semantic search policy is dependent on the grid size, and adaptive grid sizing was not explored.', 'The template assumption for subtasks may not be practical for all types of instructions and environments.', 'The reliance on specific benchmarks like ALFRED may limit generalizability.', 'Potential biases in the trained models.', 'Limited discussion on scalability and computational requirements.', 'Lack of detailed error analysis and failure mode explanations.']",False,4,3,4,7,4,"['Novel modular approach that eschews the need for expert trajectories and low-level instructions.', 'Significant performance improvements over existing methods on the ALFRED benchmark.', 'Detailed evaluation and ablation studies that demonstrate the effectiveness of individual components.', 'The approach shows strong generalizability to unseen environments.', 'Thorough explanation of methods and reproducibility protocols.']","['Reliance on specific templates for language processing, which may limit generalizability.', 'Potential biases in the trained models due to the use of Ai2Thor, which is biased towards North American homes.', 'Limited discussion on potential negative societal impacts or ethical concerns.', 'Evaluation is primarily focused on the ALFRED benchmark; broader evaluation on more diverse or real-world scenarios is needed.', ""The semantic search policy's effectiveness heavily relies on the choice of grid size, and adaptive grid sizing was not explored.""]",4,4,3,4,Reject
uy602F8cTrh,"The paper introduces CausalDyna, a novel Dyna-style model-based reinforcement learning algorithm that leverages structural causal models (SCMs) to perform counterfactual reasoning. The approach generates counterfactual episodes by modifying object properties, thus improving the agent's ability to generalize to unseen or rare object properties. The method is evaluated in the CausalWorld robotic manipulation environment, showing superior performance in terms of sample efficiency and generalization compared to MBPO and SAC.","['Can you provide more details on the implementation of the SCMs and how they are integrated into the RL framework?', 'What are the main limitations of your approach, and how do they impact the generalizability of your results?', 'Could you discuss the potential negative societal impacts of your method, particularly in real-world robotic applications?', 'How does the method perform in environments with more complex causal relationships?', 'What is the impact of inaccuracies in the SCM on the overall performance of CausalDyna?', 'Can the approach be adapted to handle partially observable environments?', 'How were the hyperparameters for CausalDyna chosen? Were they the same as those used for MBPO and SAC?', 'Can the authors provide more details on the specific architecture of the world model and policy networks?', 'How does CausalDyna perform on other benchmarks or real-world robotic tasks?', 'Can the authors provide additional baselines and ablation studies to better understand the contribution of each component in CausalDyna?']","['The dependency on the accuracy of the SCMs for reliable counterfactual data generation.', 'Potential difficulties in scaling the approach to more complex environments or tasks.', 'Limited discussion on the potential ethical implications of deploying such methods in real-world scenarios.', 'The approach assumes fully observable environment properties, which may not hold in real-world scenarios.', 'Potential negative societal impacts, such as misuse in sensitive applications or unintended consequences in real-world deployments.']",False,3,3,3,6,4,"['Innovative use of SCMs for counterfactual reasoning in reinforcement learning.', 'Significant improvements in sample efficiency and generalization over state-of-the-art methods.', 'Thorough experimental evaluation in a realistic robotic manipulation environment.', 'Clear motivation and well-defined methodology.']","['Heavy reliance on the accuracy of the world model for generating meaningful counterfactuals.', 'Limited discussion on the limitations of the proposed method and its potential negative societal impact.', 'Reproducibility of the results may be challenging due to the complexity of the experimental setup.', 'Some parts of the paper could be better organized and clearer, particularly the presentation of results.']",4,3,3,3,Reject
iaqgio-pOv,"The paper proposes model-agnostic local explanations for similarity learners using feature attributions and analogies. It focuses on explaining the similarity between pairs of inputs as determined by a black-box similarity learner. The methods are applied to text and tabular data, and their efficacy is demonstrated through quantitative evaluations and user studies.","['Can the authors provide additional validation or experiments to strengthen the robustness of the results?', 'How do the authors address potential biases in the user study?', 'Can the authors elaborate on the ethical considerations and potential negative societal impacts of their work?', 'Could the authors provide more details on the implementation of the proposed methods, especially the analogy-based explanation?', 'How sensitive are the proposed methods to the choice of hyperparameters?', 'Could the authors elaborate on the potential limitations and scalability of their methods in practical applications?', 'Can the authors provide more details on the hyperparameters used in the experiments?', 'How does the analogy-based method perform in other domains beyond text and tabular data?', 'Can the authors clarify the choice of participants for the user study and how it impacts the results?', 'How were the hyperparameters for the analogy-based methods selected? Was there any tuning involved?', 'Can the authors provide more rigorous and detailed explanations of the mathematical formulations and proofs?']","['The paper does not sufficiently address potential negative societal impacts and ethical considerations.', 'Experimental results are not robust enough to convincingly demonstrate the efficacy of the methods.', 'The methods may not scale well to very large datasets due to their complexity.', 'The explanation methods might not be entirely faithful to the black-box models, leading to potential misinterpretations.', 'There could be challenges in applying these methods to other types of data beyond text and tabular.', 'The user study is limited to participants with backgrounds in data science, engineering, and business analytics, which may not generalize to other user groups.']",False,2,2,2,4,4,"['Addresses an underexplored area of providing explanations for similarity models.', 'Proposes a novel analogy-based explanation method.', 'Includes theoretical analysis and proof of submodularity for the analogy objective function.', 'Extensive experimental setup including quantitative evaluations and a user study.']","['Limited novelty in the proposed methods as they build on existing concepts.', 'Experimental results lack robustness and sufficient validation.', 'Clarity of presentation could be improved, especially in dense mathematical sections.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'Complexity of the proposed methods may limit their practical applicability.', 'Reproducibility concerns due to insufficient details on implementation and hyperparameter selection.']",3,2,2,3,Reject
JmU7lyDxTpc,The paper investigates the phenomenon of epoch-wise double descent in neural networks using a linear teacher-student model and tools from statistical physics. It derives closed-form analytical expressions for generalization error dynamics and validates these findings through numerical experiments.,"['Can the authors provide more intuitive explanations for some of the complex mathematical derivations?', 'How well do the findings generalize to more complex neural network architectures beyond the linear model used?', 'Can the authors provide additional experimental validation on a wider range of real-world datasets?', 'What are the practical implications of these findings for training large-scale neural networks in practice?', 'Can the assumptions and simplifications in your model be relaxed without losing the analytical tractability?', 'Are there any practical guidelines you can provide for practitioners based on your findings?']","['The simplified linear model may not fully capture the complexities of real-world neural networks.', 'Limited scope of experimental validation.', 'Potential negative societal impacts are not thoroughly discussed, though the authors believe their work is theoretical and lacks direct societal impact.']",False,3,2,3,5,4,"['Addresses an underexplored aspect of double descent in neural networks.', 'Uses a mathematical framework to provide theoretical insights.', 'Derives closed-form analytical expressions for generalization error dynamics.', 'Validates findings with numerical experiments.', 'Well-cited and contextualizes within existing literature.']","['Incremental novelty; double descent has been extensively studied.', 'Simplified model limits applicability to real-world neural networks.', 'Dense and mathematically intensive writing may hinder understanding.', 'Limited experimental validation on synthetic data and a single real-world dataset.', 'Practical implications and broader impact of the findings are not clearly articulated.']",3,3,2,3,Reject
ZC1s7bdR9bD,"The paper introduces a novel method for uncertainty attribution in Bayesian models using path integrals and in-distribution curves. It aims to provide more interpretable, sparse, and relevant attributions compared to existing methods. The authors validate their approach on benchmark image datasets and compare it against popular attribution methods like integrated gradients, LIME, and kernelSHAP.","['Can the authors provide more details on the statistical significance of their experimental results?', 'How does the method perform on non-image datasets or other types of models?', 'Can the authors discuss any potential ethical concerns or limitations in more detail?', 'Can the authors provide more details on the optimization process for finding fiducial points? How sensitive is the method to the choice of fiducial points?', 'What are the computational costs associated with the proposed method compared to existing methods?', 'How does the proposed method significantly differ from existing counterfactual and integrated gradient-based methods?', 'Can the authors provide more practical applications or scenarios where this method outperforms existing techniques?', 'Can the authors clarify the methodology section to make it more accessible to readers not deeply familiar with path integrals and integrated gradients?', 'What are the limitations of the proposed method and how do they impact its applicability?', 'How does the choice of fiducial and out-of-distribution path impact the results?', 'What are the specific limitations of your method, and how do you plan to address them?', 'Can the authors provide more details on the computational complexity and runtime performance of the proposed method?', 'Can the authors clarify the choice of certain hyperparameters, such as the penalty term in the optimization process?']","['The paper does not discuss the limitations of the proposed method in detail.', 'Potential ethical concerns are not adequately addressed.', 'The choice of fiducial and out-of-distribution path remains controversial.', 'The method may not generalize well to non-image data.', 'Potential computational overhead due to the use of path integrals.', 'The method’s applicability to non-image data is not demonstrated, which limits its generalizability.', 'The computational complexity and runtime performance are not discussed.', 'The choice of hyperparameters in the optimization process is not clearly justified.']",False,2,2,2,4,4,"['Proposes a novel approach for uncertainty attribution in Bayesian models.', 'Addresses an important problem in Bayesian machine learning.', 'Comprehensive validation on multiple benchmark datasets.', 'Detailed comparison with existing popular methods.']","['The paper is dense and difficult to follow in some sections.', 'Validation experiments lack rigorous statistical analysis.', 'Comparisons with existing methods sometimes appear anecdotal.', 'Does not adequately address potential limitations and ethical considerations.', 'The novelty of the method is questionable as it mainly builds on existing techniques like integrated gradients and counterfactual explanations.', 'The technical soundness needs further validation, especially in terms of the optimization process for finding fiducial points and the stability of the method.', 'The clarity of the methodology section is lacking; mathematical notations and explanations can be confusing.', 'Experiments are performed on standard datasets, which do not fully justify the practical application or scalability of the method.', 'The paper does not sufficiently address limitations and potential negative societal impacts.']",2,2,2,2,Reject
qnQN4yr6FJz,The paper proposes a hybrid method combining generative and discriminative approaches using variational inference for handling incomplete features. The method introduces a new variational approximation and variance reduction technique within the black-box variational inference framework. Empirical results demonstrate the effectiveness of the proposed method.,"['Can the authors provide a clearer and more detailed explanation of the variational approximation and variance reduction technique?', 'What are the potential limitations of the proposed method in practical applications?', 'How does the proposed method compare to other state-of-the-art methods for handling incomplete features across a wider range of datasets and scenarios?', 'Can the authors discuss the potential societal impacts and ethical considerations of their method?', 'What are the computational costs associated with the proposed method compared to others?', 'How does the proposed method perform with larger datasets or in real-time applications?', 'Are there any specific scenarios where the method might fail or perform suboptimally?']","['The proposed method may not generalize well to all types of incomplete data scenarios.', 'The empirical validation is limited and does not cover a wide range of datasets and scenarios.', 'The explanation of the methodology is not sufficiently clear, which may hinder reproducibility.', 'The scalability of the method is not thoroughly evaluated.', 'The potential negative societal impacts of the method, especially in sensitive applications like healthcare, are not discussed.', 'Potential difficulty in understanding due to dense mathematical notation.', 'The method might be less practical for real-time applications or very large datasets without significant computational resources.']",False,2,2,3,4,4,"['Addresses an important problem of prediction with incomplete features.', 'Novel combination of generative and discriminative approaches.', 'Utilizes variational inference, making it widely applicable.', 'Empirical results show some effectiveness of the proposed method.']","['The explanation of the proposed method is convoluted and lacks clarity, particularly in the sections detailing the variational approximation and variance reduction technique.', 'Certain steps in the methodology are not adequately justified or explained, such as the choice of specific parameters and the rationale behind the surrogate transform.', 'Experimental validation is limited in scope and does not convincingly demonstrate the superiority of the proposed method across a diverse set of datasets and scenarios.', 'Potential societal impacts and ethical considerations are not discussed, which is crucial for methods applied to sensitive data like healthcare records.', 'High computational demands due to the complexity of the proposed method, which may limit its practicality for large-scale or real-time applications.']",3,2,2,3,Reject
HuaYQfggn5u,"The paper introduces FedBABU, a federated learning algorithm that only updates the body of the model during federated training. The head remains fixed and is fine-tuned during evaluation for personalization. Extensive experiments show that FedBABU outperforms existing methods, including FedAvg, in both global model performance and personalized settings.","['Can the authors provide more details on the experimental setup, particularly the datasets and model architectures used?', 'How does the fixed head initialization impact the overall training stability and convergence?', 'Can the authors discuss any potential limitations or scenarios where FedBABU might not perform as well?', 'Can the authors provide more detailed comparisons with existing methods to better substantiate their claims?', 'How does FedBABU perform in different federated learning scenarios beyond CIFAR datasets?', 'Can the authors elaborate on potential applications and broader significance of FedBABU?', 'Can the authors provide more theoretical justification for updating only the body?', 'How does the algorithm scale with larger datasets and more diverse clients?', 'What are the potential ethical implications of this work?', 'Have you considered testing the proposed method on other types of datasets beyond CIFAR100 and EMNIST?', 'How does the performance of FedBABU change with different model architectures?']","['The paper does not thoroughly discuss the potential negative societal impact.', 'Limited exploration of scenarios where FedBABU might not perform optimally.', 'Lack of theoretical justification for the proposed method.', 'Limited exploration of scalability and real-world applicability.', 'Insufficient discussion of ethical implications.']",False,3,3,3,7,4,"['Novel approach of decoupling the body and head for federated learning.', 'Extensive experimental validation showing consistent improvements.', 'Addresses both global model performance and personalization.', 'Potential for significant impact on federated learning, especially in high heterogeneity scenarios.']","['The approach might be considered incremental as it builds directly on FedAvg with a simple modification.', 'Clarity of the paper could be improved, particularly in the experimental setup and results sections.', 'Limited discussion on the societal impact and broader implications.', 'Weak theoretical justification for the chosen approach.', 'Limited exploration of real-world applicability and scalability.']",3,3,3,4,Accept
YmONQIWli--,"The paper introduces an efficient SDE solver for score-based generative models, which significantly accelerates the generation process while maintaining or improving sample quality. The solver uses adaptive step sizes tailored to score-based generative models and requires minimal tuning. Extensive experiments demonstrate the solver's effectiveness across various datasets and model configurations.","['Can the authors provide more detailed explanations and potentially pseudocode for the key algorithmic steps?', 'How does the proposed method generalize to non-image data or other modalities?', 'What are the potential negative societal impacts of this work, especially considering its application in generating synthetic data?', 'Can the authors provide more details on the choice of hyperparameters and how sensitive the results are to these choices?', 'Have the authors considered the potential negative societal impacts of faster data generation in generative models?', 'Can the authors provide more insights into why the proposed method works better than other higher-order SDE solvers?', 'Can the authors elaborate on the specific challenges faced when applying off-the-shelf SDE solvers to score-based generative models?']","['The method was primarily tested on image data, which may limit its applicability to other data types.', 'There is a risk that the improvements seen in the experiments may not fully generalize to all score-based generative models.', 'The focus on continuous-time models limits generalizability.', 'The necessity of selecting a relative tolerance parameter partially offsets the advantage.', 'The robustness of the method is a concern due to non-convergence in some preliminary experiments.', 'Potential negative societal impacts are not discussed.', 'The complexity of the algorithm might hinder reproducibility without detailed implementation guidance.']",False,3,3,3,7,4,"['Significant speedup in data generation compared to Euler-Maruyama.', 'Maintains or improves sample quality.', 'Minimal tuning required for step sizes.', 'Generalizable to various types of diffusion processes (e.g., VE, VP).', 'Theoretical underpinnings are well-explained.', 'Extensive experimental validation on both low and high-resolution images.']","['Clarity issues in the presentation of the algorithm and experimental setup.', 'Focuses primarily on image data, which may limit generalizability.', 'Insufficient discussion on potential limitations and negative societal impacts.', 'Complexity of the algorithm might hinder reproducibility without detailed implementation guidance.', 'The novelty of combining existing techniques could be questioned.', 'Marginal improvements in quality in some results.']",3,3,3,4,Accept
4jUmjIoTz2,"The paper proposes a collaboration framework, CDA[2], to enhance adversarial robustness by enabling multiple sub-models to collaborate rather than merely ensemble. The framework aims to minimize vulnerability overlap among sub-models and select the best-performing sub-model for prediction. Theoretical analysis and empirical experiments on CIFAR-10 demonstrate that CDA[2] outperforms existing ensemble methods in terms of adversarial robustness against both white-box and black-box attacks.","['Can the authors provide more intuitive explanations for Algorithms 1 and 2?', 'How does the computational cost of CDA[2] compare to traditional ensemble methods in practical scenarios?', 'What are the potential limitations or failure cases of CDA[2] in adversarial settings?', 'Can the authors provide a more detailed discussion on the potential negative societal impacts and ethical considerations of deploying such robust models in real-world applications?', 'How does the proposed method compare to other state-of-the-art adversarial defenses beyond ensemble methods?', 'Is the code for reproducing the experiments publicly available, and are there detailed instructions for replicating the results?']","['The potential computational overhead of training and inference with multiple sub-models and PPD heads.', 'The paper does not thoroughly discuss the limitations or potential failure cases of the proposed method.', 'Potential negative societal impacts are not addressed, such as the misuse of adversarial defenses in malicious applications.']",False,3,3,3,6,4,"['Novel approach to adversarial robustness through collaboration among sub-models.', 'Theoretical analysis supporting the advantages of collaboration over traditional ensembles.', 'Comprehensive empirical evaluation demonstrating improved robustness on CIFAR-10.']","['The clarity of the algorithms and theoretical proofs could be improved.', 'The approach might be computationally expensive due to the need for multiple sub-models and additional PPD head training.', 'The paper could benefit from more discussion on the limitations and potential negative societal impacts.', 'Reproducibility of the results is not thoroughly addressed, with partial details on the experimental setup and code availability.']",3,3,3,3,Reject
q9zIvzRaU94,"The paper proposes a method called State-Dependent Causal Inference (SDCI) for causal discovery from conditionally stationary time-series data. The method integrates state variables to account for changes in the dynamics of the observed system. The authors evaluate the method on synthetic data, showing that it can recover causal dependencies with high accuracy.","['Can the authors provide more details on how the method would perform on real-world data?', 'Are there any plans to extend the evaluation to more diverse and real-world datasets?', 'Can the authors elaborate on the potential limitations or failure cases of the method?', 'How does the proposed method handle missing data or noisy observations in real-world scenarios?', 'Can the authors provide a theoretical justification for the assumptions made in the SDCI method?', 'What are the computational requirements and scalability of the proposed method for larger datasets?']","['The method has been evaluated only on synthetic data, which may not fully capture the complexities of real-world scenarios.', 'The paper does not discuss potential negative societal impacts or limitations in detail.', 'The approach may struggle with real-world data complexities, such as missing data or selection bias, which are not addressed in the current work.']",False,3,2,3,4,4,"['Addresses a novel problem of causal discovery in non-stationary time-series data.', 'Proposes a probabilistic deep learning approach that integrates state variables.', 'Shows promising results in synthetic experiments.']","['Evaluation is limited to synthetic data and does not include real-world scenarios.', 'The paper is dense and difficult to follow, particularly in the mathematical sections.', 'Limited discussion on limitations and potential negative societal impacts.']",3,3,2,3,Reject
JV4tkMi4xg,"The paper introduces NN+MILP, a novel discrete model-based optimization (MBO) framework using piecewise-linear neural networks as surrogate models and MILP for optimizing the acquisition function. The method aims to address the challenges of optimizing acquisition functions in high-dimensional discrete spaces with combinatorial constraints. The paper provides experimental results on several benchmarks, including DNA binding, NAS-Bench-101, and synthetic problems.","['Can the authors provide more detailed explanations and equations for the MILP formulation?', 'How does the performance of NN+MILP scale with increasing problem size and complexity?', ""Are there any specific hyperparameters or settings that are crucial for the method's success?"", 'How does NN+MILP compare with other state-of-the-art methods in terms of computational efficiency?', 'Can the authors provide more details on the computational overhead and scalability of the MILP solver?', 'How does the performance of NN+MILP vary with different surrogate network architectures?', 'Can the authors elaborate on the potential ethical considerations and societal impacts of their work?']","['The scalability of MILP is a significant concern, as highlighted by the longer solve times for larger problems.', 'The paper does not explore the impact of different neural network architectures on the performance of NN+MILP.', 'There is limited discussion on the generalizability of the approach to other types of optimization problems (e.g., continuous or mixed-integer domains).', 'The potential negative societal impacts of applying the method in different domains are not thoroughly discussed. Ethical considerations, especially in sensitive application areas, should be more explicitly addressed.']",False,3,3,3,5,4,"['Introduction of a novel MBO framework combining neural networks and MILP.', 'Potential for broad applicability in various discrete optimization problems.', 'MILP provides theoretical optimality guarantees for the acquisition function.', 'Extensive experimentation on multiple benchmarks.']","['Clarity of the MILP formulation and its integration with neural networks is lacking.', 'Limited discussion on the scalability of the method for larger problem instances.', 'Reproducibility of results is not fully addressed; additional implementation details are needed.', 'Comparison with state-of-the-art methods is not exhaustive.', 'Potential over-reliance on synthetic benchmarks; more real-world applications would strengthen the validity of the approach.']",3,3,3,3,Reject
pC00NfsvnSK,"The paper introduces Generalized Similarity Functions (GSF), a novel framework aimed at improving zero-shot generalization in offline reinforcement learning (RL) through the use of contrastive learning. The authors also introduce a new benchmark, offline Procgen, to evaluate their method. The empirical results demonstrate that GSF outperforms state-of-the-art methods on this benchmark.","['Can the authors provide more details on the implementation of the GSF framework?', 'How sensitive is the GSF method to the choice of hyperparameters?', 'Can the authors provide more intuition behind the choice of the cumulant function?', 'Can the authors provide additional benchmarks to demonstrate the broader applicability of GSF?', 'Can the theoretical analysis be simplified and more clearly connected to practical implementations?', 'How does the proposed method perform on other benchmarks or real-world datasets?', 'What are the computational requirements and scalability of the proposed approach?', 'Can the theoretical analysis be simplified or clarified further?', 'Could you provide more detailed ablation studies to understand the contribution of each component?', 'How does the performance of GSF vary with different hyperparameter settings?', 'How does GSF perform compared to other state-of-the-art methods on different types of POMDPs?', 'Can the authors provide more insights into the training stability and computational requirements of GSF?']","['The paper does not thoroughly discuss the limitations of the proposed method.', 'Potential negative societal impacts are not addressed.', 'The method relies heavily on the quality and quantity of offline data, which may not always be available in real-world scenarios.', 'Potential challenges in scaling the approach to larger or more complex environments.', 'The complexity of the proposed method might limit its accessibility and adoption.', 'The paper lacks a thorough discussion on the potential negative societal impacts of this work.', 'The choice of hyperparameters, particularly the number of quantiles (K), is not thoroughly justified.']",False,3,2,3,6,4,"['Novel theoretical framework for improving zero-shot generalization in offline RL.', 'Extensive experimental evaluation on a newly introduced benchmark.', 'Demonstrated improvement over state-of-the-art baselines.', 'Comprehensive theoretical analysis of the proposed method.']","[""The paper's clarity could be improved, especially in the theoretical sections."", 'Some theoretical claims are not rigorously proven.', 'Reproducibility of the results may be challenging due to lack of detailed implementation details.', 'The empirical validation is restricted to a single benchmark, raising concerns about generalizability.', 'Limited discussion on the choice of hyperparameters and their impact on performance.', 'Potential negative societal impacts are not adequately addressed.']",3,3,2,3,Reject
LOz0xDpw4Y,"The paper introduces an innovative dynamic programming approach to optimize the inference time schedules of pre-trained Denoising Diffusion Probabilistic Models (DDPMs). This method aims to find log-likelihood-optimal discrete time schedules that significantly reduce the number of refinement steps required during inference, making DDPMs more computationally feasible for high-dimensional data. The proposed method is efficient, has no hyper-parameters of its own, and can be applied to any pre-trained DDPM without retraining. The authors demonstrate the efficiency and effectiveness of their approach through experiments on CIFAR10 and ImageNet 64x64 datasets.","['Can you provide more details on how the dynamic programming approach scales with larger datasets or higher dimensional data?', 'What are the implications of the trade-off between log-likelihood optimization and FID scores for practical applications?', 'Have you considered applying this method to other types of generative models beyond DDPMs?', 'Can the authors provide a detailed comparison of the computational overhead of their method compared to other fast-sampling techniques?', 'How does the method perform on larger and more complex datasets beyond CIFAR10 and ImageNet 64x64?', 'Can the authors elaborate on the potential impacts of the observed discrepancy between log-likelihood and FID scores on the practical applicability of their method?', 'Can the authors elaborate on the practical implications of their method for real-world applications?', 'How does the proposed method compare to other state-of-the-art techniques in terms of computational cost and sample quality trade-offs?', 'Could the authors provide more details on the potential limitations and negative societal impacts of their work?', 'Can the authors provide more detailed pseudocode or a clearer explanation of the dynamic programming algorithm?', 'How does the method perform on other datasets or in other domains beyond image generation?', 'Can the authors discuss potential limitations or negative impacts of their method in more detail?', 'Can you provide more details on the potential limitations and failure cases of your method?', 'How does the method perform on other types of generative models beyond DDPMs?', 'Can you elaborate on the relationship between optimizing ELBO and FID scores?']","['The trade-off between log-likelihood optimization and FID scores is a potential limitation, especially for applications prioritizing sample quality.', ""The method's performance on datasets with higher diversity could be further explored."", ""The method's reliance on log-likelihood may not always align with sample quality as perceived by human evaluators or other metrics like FID."", 'The evaluation is limited to specific datasets and models, which may not generalize to all scenarios.', 'The authors mention that optimizing for the unweighted ELBO can lead to higher FID scores, indicating a need for further research into finding the best variational lower bounds.', 'The potential negative societal impacts of more efficient generative models, such as misuse or bias, are not discussed in detail.', 'The paper does not discuss the potential negative impacts of faster sampling in generative models, such as misuse in generating deepfakes or other harmful content.']",False,3,3,3,6,4,"['Addresses a significant computational challenge in DDPMs.', 'Innovative use of dynamic programming to optimize inference schedules.', 'Substantial improvements in sampling speed with minimal loss in sample quality.', 'Method is applicable to any pre-trained DDPM without requiring retraining.', ""Comprehensive experimentation on different datasets and models demonstrates the method's effectiveness.""]","['Trade-off between log-likelihood optimization and FID scores.', 'Limited comparisons with state-of-the-art methods beyond the datasets and models used.', 'Clarity of some technical sections could be improved.', 'Potential biases in the datasets and models used for evaluation are not addressed.', 'Insufficient discussion of limitations and societal impacts of the proposed approach.']",3,3,3,3,Accept
DBOibe1ISzB,"The paper proposes a novel Transformer-based framework, Simulation Transformer (SiT), for particle-based physics simulation. SiT introduces interaction tokens to capture the rich semantics of particle interactions and abstract tokens to disentangle material-specific characteristics from domain-specific semantics. The authors evaluate SiT across various complex environments, demonstrating superior performance and generalization compared to existing methods.","['Can the authors provide more theoretical analysis to support the proposed method?', 'What are the potential negative societal impacts of this work?', 'Can the authors elaborate on the limitations of SiT in more detail?', 'Can the authors provide more details on the training process and the choice of hyperparameters?', 'How does SiT perform under different initializations and with different random seeds?', 'Can the authors provide more insights into the potential overfitting observed in some experiments?', 'How does the model perform in real-world scenarios outside of the controlled environments?', 'What are the computational overheads introduced by the interaction and abstract tokens?', 'How does SiT perform in terms of computational efficiency compared to existing methods?', 'Can the authors provide more details on the scalability of SiT for larger and more complex simulations?', ""Are there specific real-world applications where SiT's improvements would be particularly impactful?"", 'How does SiT perform in real-world environments, beyond synthetic datasets?', 'Could the authors elaborate on the choice of hyperparameters and their sensitivity to different settings?']","['The paper lacks a detailed discussion on the potential negative societal impacts of the proposed method.', 'There is a need for a more detailed theoretical analysis to support the empirical findings.', 'The scalability of SiT to even larger and more complex environments is not thoroughly tested.', 'The potential societal impacts of the proposed method are not discussed.', 'The paper does not adequately address the computational overhead introduced by the interaction and abstract tokens.', 'The practical significance of the improvements might be marginal.', 'The robustness of SiT to different simulation settings is not thoroughly addressed.', 'The evaluation is limited to synthetic environments, which may not fully capture real-world complexities.']",False,3,2,3,6,4,"['Introduction of interaction tokens to capture rich semantics of particle interactions.', 'Implementation of abstract tokens to disentangle material-specific characteristics from domain-specific semantics.', 'Extensive experimental evaluation across multiple complex environments.', 'Demonstrated superiority in performance and generalization over existing methods.']","['Lack of in-depth theoretical analysis supporting the proposed method.', 'Insufficient details on the potential negative societal impacts and limitations.', 'The novelty claim is somewhat diluted due to the similarities with existing Transformer and particle-based simulation frameworks.', 'Over-reliance on experimental results without a strong theoretical underpinning.', 'Some sections lack clarity, particularly in the explanation of the methodology and the training process.', 'The robustness of the proposed method under different conditions and settings needs further validation.', 'Potential overfitting in more complex environments, as indicated by some experimental results.', 'Dense and complex writing that could benefit from clearer explanations and better structuring.', 'Marginal practical significance of the improvements over existing methods.', 'The robustness and scalability of the proposed method are not thoroughly addressed.', 'The potential impact on broader research and real-world applications is not well articulated.', 'The evaluation primarily focuses on synthetic environments, which may not fully capture real-world complexities.']",3,3,2,3,Reject
Tubzedlc4P,The paper proposes a Riemannian geometric structure for point cloud data by interpreting point clouds as samples from an underlying probability distribution and using the Fisher information metric as the Riemannian metric. Two autoencoder case studies demonstrate the advantages of this framework in interpolation and learning optimal latent space coordinates.,"['Can the authors provide more details on how the fixed number of points assumption can be mitigated in real-world scenarios?', 'How does the choice of kernel function impact the performance of the proposed method?', 'Can the authors compare their method with more recent state-of-the-art techniques in point cloud analysis?', 'Can the authors provide more detailed and intuitive explanations of the key concepts and methodologies?', 'How do the proposed metrics compare with existing metrics in terms of computational efficiency and practical applicability?', 'Can the authors provide more empirical validation on a broader set of benchmarks?', 'Can you provide more detailed comparisons with state-of-the-art methods on additional datasets?', ""How does the proposed method perform in real-world scenarios where point clouds may not meet the 'fixed number of points' assumption?"", 'Can the authors provide a more structured and detailed description of the experimental setup to ensure reproducibility?', 'Can the authors provide more clarity on the practical implications and applications of the proposed framework beyond the two case studies?', 'How sensitive is the proposed method to the choice of kernel functions in defining the statistical manifold?', 'What modifications are needed if the assumption of fixed number of points in point clouds is violated?']","['The assumption of a fixed number of points in each point cloud may not hold in practical applications. The authors suggest upsampling/downsampling as a solution, but this needs further elaboration.', 'The choice of kernel function is critical, yet the authors primarily use the Gaussian kernel without exploring other options extensively.', 'Potential negative societal impacts are not addressed.']",False,3,2,2,4,4,"['Novel application of Riemannian geometry to point cloud data.', 'Theoretical foundation is well-developed and rigorous.', 'Potential for more comprehensive and robust analysis of point cloud data.']","['The clarity of the presentation could be significantly improved; some sections are difficult to follow.', 'The evaluation could be more comprehensive, particularly in comparing with state-of-the-art methods.', 'Potential limitations regarding the fixed number of points assumption and kernel choice are not thoroughly addressed.', 'Lack of thorough theoretical analysis and empirical validation.', 'Complex proofs that may not be easily verifiable.', 'Incremental improvements that may not justify the added complexity.', 'Reproducibility concerns due to the complex experimental setup.']",3,3,2,2,Reject
bTteFbU99ye,"The paper proposes a methodology to evaluate neural language models' ability to estimate probabilities of sequences, particularly focusing on rare events in the heavy-tail of natural language distributions. The authors use generative models trained on natural data to create artificial languages with known probabilities, allowing precise evaluation. They find that LSTM and Transformer models systematically underestimate the probabilities of rare sequences, overestimate ill-formed sequences, and that this underestimation persists even with increased training data.","['How well do the findings generalize to real-world language modeling tasks beyond the synthetic setup?', 'Can the authors provide more detail on how the insights from this study can be applied to improve real-world language models?', 'What are the potential limitations of using artificial languages for evaluation?']","['The study relies heavily on artificially generated data, which might not fully represent the complexities of natural language.', 'There is limited discussion on the potential negative societal impacts of the work.', 'The practical implications of the findings for real-world applications are not thoroughly explored.']",False,3,3,3,5,4,"['Novel evaluation methodology using artificial languages.', 'Thorough experimental setup and clear results.', 'Detailed analysis of how model performance varies with training data and distributional properties.']","['Artificial nature of the evaluation setup may limit real-world applicability.', 'Overreliance on synthetic data generated by models might not fully capture the complexity of natural language.', 'Limited discussion on the practical implications of findings for real-world language modeling tasks.']",3,3,3,3,Reject
dIVrWHP9_1i,"The paper introduces G-Mixup, a novel graph data augmentation method that interpolates graphons to generate synthetic graphs for graph classification. The method aims to improve the generalization and robustness of graph neural networks (GNNs). Extensive experiments show that G-Mixup significantly improves the performance of GNNs across multiple datasets and backbones.","['Can the authors provide more detailed guidance on choosing hyperparameters for G-Mixup?', 'How does G-Mixup perform on extremely large-scale graph datasets?', 'Can the authors elaborate on the potential negative societal impacts and ethical considerations of their approach?', 'Can the authors provide more details on the computational complexity and scalability of G-Mixup?', 'Can the authors discuss potential limitations or failure cases of the method in more detail?', 'Can the authors provide more details on the experimental setup, particularly the hyperparameters used for G-Mixup?', 'How does G-Mixup compare with other state-of-the-art graph data augmentation methods in terms of performance and scalability?', 'Are there any specific applications or domains where G-Mixup would be particularly beneficial or limited?']","['The paper does not sufficiently address the potential negative societal impacts of generating synthetic graph data.', 'The complexity of the method might limit its applicability to real-world problems.', 'More practical guidance on hyperparameter selection is needed.', 'The method is computationally intensive due to graphon estimation and graph generation, which may limit its applicability to very large-scale datasets.', 'The generalizability of the method to other types of graph data or tasks is not well-discussed.']",False,3,3,3,7,4,"['Novel adaptation of Mixup for graph data.', 'Extensive theoretical analysis and guarantees.', 'Comprehensive experimental evaluation demonstrating performance improvements.', 'Demonstrates robustness to label and topology corruption.', 'Thorough comparison with existing methods, demonstrating clear advantages.']","['The explanation of some concepts, such as graphon estimation, could be clearer.', 'The complexity of the implementation may limit practical adoption.', 'Limited discussion on potential negative societal impacts and ethical considerations.', 'The choice of hyperparameters, such as the number of nodes in generated graphs, needs more practical guidance.', 'Certain sections, especially the theoretical parts, could be clearer and more accessible.', 'Some experimental details are relegated to the appendix, making it harder to follow the main text.', 'The empirical evaluation, while extensive, could benefit from more diverse datasets and additional baselines.']",4,4,3,4,Accept
FFGDKzLasUa,"The paper introduces a novel approach to model-agnostic meta-learning (ML) by incorporating stochastic local winner-takes-all (LWTA) activations in deep networks. The proposed method, termed StochLWTA-ML, aims to learn sparse and stochastic representations, potentially enhancing generalization capabilities. The method is evaluated on standard few-shot image classification benchmarks, showing improved performance with fewer parameters compared to existing state-of-the-art methods.","['Could the authors provide more details on the initialization schemes and hyperparameters used?', 'How sensitive is the method to the choice of the number of competing units per block?', 'Can the authors elaborate on the computational overhead during prediction, especially for larger sample sizes (B)?', 'How does the method perform on tasks outside of few-shot image classification?', 'Can the authors provide more detailed mathematical derivations of the proposed approach?', 'How does the proposed approach compare with traditional non-stochastic LWTA in terms of performance?', 'What are the potential limitations and negative societal impacts of this work?', 'How was hyperparameter tuning performed across different datasets?', 'Can the authors clarify the specific initialization schemes and hyperparameter settings used in the experiments?', 'How does the proposed method perform in comparison to other recent meta-learning approaches not cited in the paper?', 'Can the authors provide more theoretical justification for the claimed benefits of stochastic LWTA in meta-learning?', 'How does the increased computational complexity during prediction affect the practical applicability of the proposed method?', 'Can the authors provide more theoretical analysis on why stochastic LWTA activations improve generalization?', 'How does the proposed method perform on other types of meta-learning tasks beyond few-shot classification?', 'Can the authors clarify the implementation details to enhance reproducibility?']","['The paper does not adequately address potential negative societal impacts.', 'The robustness of the method to different datasets and tasks needs further investigation.', 'The scalability of the approach for larger datasets and more complex models is not discussed.', 'The increased computational complexity during prediction may limit practical applicability.', 'The complexity of the method and the detailed hyperparameter settings may affect the reproducibility of the results.']",False,3,2,3,4,4,"['Novel combination of stochastic LWTA activations and Bayesian principles.', 'Achieves state-of-the-art performance on several benchmarks.', 'Reduction in the number of parameters, which could lead to computational efficiency.']","['The clarity of the paper is suboptimal; many sections are dense and difficult to follow.', 'Experimental setup and comparisons lack transparency, making reproducibility challenging.', 'Insufficient discussion on the limitations and potential negative societal impacts.', 'Some claims, especially regarding the theoretical contributions, need more rigorous validation.']",3,3,2,3,Reject
ahi2XSHpAUZ,"The paper proposes a method called WeakM3D for weakly supervised monocular 3D object detection using 2D boxes and LiDAR point clouds as supervision. The method introduces several strategies including geometric alignment loss, ray tracing loss, loss balancing, and learning disentanglement to improve 3D box predictions. The paper reports that WeakM3D outperforms some fully supervised methods on the KITTI benchmark.","['Can the authors provide more details on the computational complexity and runtime of the proposed method?', 'How does the performance of WeakM3D compare to simpler baseline methods?', 'Can the authors discuss any potential limitations or failure cases of the proposed method?', 'What are the ethical considerations and potential negative societal impacts of the proposed method?', 'Can the method be adapted to work without LiDAR data, perhaps using another form of weak supervision?', 'Could the clarity of the loss calculations and the handling of various challenges be improved with additional visual aids or simplified explanations?', 'Are there plans to validate the method on more diverse datasets beyond KITTI, Waymo, and NuScenes?']","['The authors should discuss potential limitations including the complexity of the proposed method, performance on different datasets, and any failure cases.', 'The potential negative societal impacts and ethical considerations should also be addressed.', 'The reliance on LiDAR data limits the applicability of the method in scenarios without such data.', 'The complexity of explanations may hinder understanding and reproducibility.', 'Evaluation is limited in diversity, which affects the generalizability claims.']",False,3,3,3,7,4,"['Addresses an important problem in 3D scene understanding.', 'Proposes a novel method to reduce reliance on costly 3D box annotations.', 'Comprehensive experimental validation on the KITTI benchmark.', 'Provides a detailed description of the method and its components.', 'Demonstrates competitive performance compared to some fully supervised methods.']","['The proposed method is highly complex with multiple loss terms and strategies.', 'The clarity of the paper could be improved, especially in the descriptions of the loss functions and training process.', 'The originality is somewhat limited as the method heavily builds upon existing work.', 'The paper lacks a thorough discussion on potential limitations and ethical concerns.', 'Method relies on LiDAR data, limiting applicability in scenarios without such data.', 'Evaluation is mostly limited to the KITTI dataset, with limited generalization to other datasets.']",3,3,3,4,Reject
EZNOb_uNpJk,"The paper presents ClimateGAN, a novel GAN-based architecture for generating photo-realistic images of floods to raise awareness about climate change. The model consists of a Masker for predicting flood masks and a Painter for creating the water textures. The paper details the architecture, training methodology using both simulated and real data, and evaluation through ablation studies and human evaluations.","['How do the authors plan to mitigate potential misuse of the generated images?', 'Can the authors provide more details on how the human evaluation was conducted and how biases were minimized?', 'Are there any plans to extend the evaluation to more diverse datasets or real-world scenarios?', 'Can the authors provide more details on the selection criteria for real-world images?', 'How does ClimateGAN perform on images with complex geometries, such as slopes or dense vegetation?', 'What are the specific challenges in extending the model to different water levels, and how might these be addressed in future work?', 'How do the authors plan to address the lack of ground-truth data for evaluation?', 'Can the authors provide more concrete evidence of the impact of generated images on climate change awareness and behavior change?', 'Are there plans to improve the clarity and accessibility of the paper for a broader audience?', 'How well does the model generalize to real-world images beyond the virtual world used for training?', 'What are the specific failure cases of the Masker, and how can they be addressed in future work?', 'Can the computational cost and environmental impact be reduced without compromising model performance?', 'What are the potential negative societal impacts of generating synthetic images of floods, and how can they be mitigated?', 'Can the authors provide more details on the ethical considerations and potential psychological impact of the generated images?', 'How do the authors plan to address the heavy computational requirements and carbon footprint of the model?', ""Can the evaluation metrics be expanded to provide a more comprehensive assessment of the model's performance?""]","[""The model's performance may degrade when applied to images outside of the training distribution, such as those with unique architectural styles or natural landscapes."", 'There is a risk of the generated images being used to spread misinformation or cause unwarranted alarm.', 'The model may not generalize well to all types of street scenes due to limited diversity in the real-world dataset.', 'High computational cost and environmental impact, which the authors acknowledge but could address more deeply.', 'The lack of ground-truth data limits the robustness of the evaluation.', 'The potential negative societal impact of generating realistic images of floods is not sufficiently addressed.', ""Failure cases of the Masker are not fully addressed, limiting the model's robustness in diverse scenarios.""]",True,3,3,3,5,4,"['Addresses a significant societal issue related to climate change.', 'Novel combination of unsupervised domain adaptation and conditional image generation.', 'Well-organized and clearly written.', 'Robust methodology with detailed ablation studies.', 'Publicly available dataset and code.']","['Evaluation could be more comprehensive, particularly in comparison to state-of-the-art methods.', 'Potential ethical concerns regarding the misuse of generated images are not thoroughly addressed.', 'Human evaluation may suffer from biases, and the limitations of the current approach are not sufficiently discussed.', 'High computational cost, raising concerns about environmental impact.', 'Lack of ground-truth data for robust evaluation.', 'Dense and challenging to follow due to extensive jargon and complex figures.', ""Insufficient evidence of the model's impact on actual climate change awareness and behavior change.""]",4,3,3,3,Reject
FKp8-pIRo3y,"The paper introduces Hindsight Goal Selection for Demo-Driven Reinforcement Learning (HinDRL), a method aimed at improving sample efficiency in solving long-horizon dexterous manipulation tasks. HinDRL combines demonstration-driven reinforcement learning with hindsight relabelling to guide exploration along task-specific goal distributions derived from successful demonstrations. The method is evaluated on several complex robotics manipulation tasks, showing that it can significantly reduce the number of required demonstrations and improve performance compared to strong baselines.","['Can the authors provide a clearer explanation of the methodology, especially the equations and algorithms?', 'How does HinDRL compare with other state-of-the-art methods not included in the paper?', 'Can the authors better highlight the novelty of their approach?', 'Can the authors provide more details on the process of selecting the number of hindsight goal samples for different tasks?', 'How does the approach generalize to other types of tasks beyond those presented in the paper?', 'Can the authors discuss any potential negative societal impacts of their work?', 'Can the authors provide more details on the scalability of the method to real-world applications?', 'How does the method perform with a significantly larger number of demonstrations?', 'Can the authors clarify the performance metrics used in the experiments?', 'How does the approach perform with purely learned representations without any hand-engineered features?', 'What are the potential limitations and societal impacts of the proposed method?', 'How does the method perform in environments with significantly higher noise levels?']","['The clarity of the methodology section needs improvement.', 'Comparison with more state-of-the-art methods is necessary.', 'The robustness and generalizability of the approach to other types of tasks remain unclear.', 'The method relies on a set of successful demonstrations, which might not always be available or easy to obtain.', 'The complexity of the tasks and the reliance on demonstrations might limit the scalability of the method to real-world applications.', 'The impact of the quality of the encoder on the overall performance needs further investigation.', 'The paper relies heavily on hand-engineered representations, which may limit the generalizability of the approach.', 'The potential negative societal impacts of deploying such methods in real-world settings are not discussed.']",False,3,2,3,6,4,"['Addresses a significant problem in reinforcement learning and robotics, particularly sparse rewards and long-horizon tasks.', 'Proposes a novel combination of demonstration-driven RL and hindsight goal selection.', 'Extensive experimental evaluation on several complex tasks.', 'Shows significant improvement in performance and sample efficiency over strong baselines.']","['Dense and sometimes unclear explanations, particularly in the methodology section.', 'Insufficient comparison with more state-of-the-art methods.', 'The novelty could be better highlighted.', 'Concerns about the scalability of the method to real-world applications.', 'Limited discussion on the potential negative societal impacts of the work.']",3,3,2,3,Reject
GugZ5DzzAu,"The paper extends the MARINA method for distributed non-convex optimization by introducing correlated compressors (PermK) and the concept of Hessian variance. Theoretical improvements in communication complexity are demonstrated, and the results are supported by experiments on synthetic and real-world datasets.","['Can the authors provide more details on the potential limitations of their approach?', 'Could the authors discuss any potential negative societal impacts of their work?', 'Could the authors provide more detailed explanations and examples of the AB inequality and its implications?', 'How does the practical performance of the PermK compressor compare to other state-of-the-art methods in more diverse real-world scenarios?', 'Can the authors further elaborate on the potential applications and limitations of the Hessian variance concept?', 'Can the authors provide more details on the implementation of permutation compressors in real-world scenarios?', 'How sensitive are the results to the choice of the parameter p in MARINA?', 'Can you provide more details on the practical implementation and overhead of PermK?', 'How do the methods perform on other real-world datasets beyond MNIST?', 'Can you clarify the steps in the experimental setup to improve reproducibility?', 'Can the authors provide more intuitive explanations for the theoretical results?', 'How practical is the assumption of independent random seeds across distributed nodes?']","['The paper primarily relies on synthetic experiments and a single real-world dataset. More diverse real-world applications would strengthen the validation.', 'The clarity of some theoretical notations and assumptions needs improvement.', 'The assumption of independent random seeds might not hold in real-world scenarios, potentially affecting the reproducibility of the results.', 'Theoretical improvements are significant under specific conditions (e.g., low Hessian variance). Clarification on the prevalence of such conditions in practical scenarios would be beneficial.']",False,3,3,3,7,4,"['Introduction of a new class of correlated compressors (PermK).', 'Novel concept of Hessian variance, refining the analysis of MARINA.', 'Significant improvement in communication complexity.', 'Theoretical results are supported by experimental validation.', 'Clear and well-organized presentation.']","['Clarity issues in the presentation of complex mathematical derivations.', 'Limited real-world experiments; more practical applications would enhance the significance.', 'Some notations and assumptions are introduced without adequate explanation.', 'Potential negative societal impacts and limitations could be discussed in more detail.']",4,3,3,3,Accept
RQ428ZptQfU,"The paper introduces VaDeSC, a novel semi-supervised probabilistic approach for clustering survival data using deep generative models and variational inference. The method leverages recent advances in stochastic gradient variational inference to uncover the underlying distribution of explanatory variables and censored survival times. The authors evaluate VaDeSC on synthetic, semi-synthetic, and real-world datasets, demonstrating improved clustering performance and competitive time-to-event predictions compared to existing methods.","['How does VaDeSC significantly advance beyond existing methods like DSM and SCA?', 'Can the authors provide a more detailed empirical validation, particularly for the comparison with profile regression?', 'What are the practical implications of the discovered clusters in clinical decision-making?', 'Can the authors discuss the broader ethical implications of deploying such models in real-world clinical settings?', 'Can the authors provide more details on the interpretability of the model, especially in a clinical context?', 'How sensitive is the model to the choice of the number of mixture components?', 'Can the authors elaborate on the computational complexity compared to the baselines?', 'How does the method perform when the number of clusters is not known a priori?', 'Could the authors provide more details on the computational efficiency and scalability of the proposed method?', 'How sensitive is the method to the choice of hyperparameters?', 'Can the authors provide more detailed discussion on the limitations of the proposed method?', 'What are the potential negative societal impacts of this work?', 'Can the authors offer more insights into the practical applications of VaDeSC in real-world scenarios?', 'Can the authors provide a more detailed theoretical analysis of the proposed method?', 'How does the method perform on additional real-world datasets with varying characteristics?', 'Are there ways to make the number of mixture components adaptive rather than fixed a priori?', 'Could the authors elaborate on the interpretability of the model in medical contexts?']","['The method requires fixing the number of mixture components a priori.', 'The relationship between raw features and survival outcomes remains unclear.', 'The empirical validation is limited due to computational constraints, particularly in comparison with profile regression.', 'Limited interpretability might hinder its adoption in clinical settings.', 'Potential negative impacts of clustering patients incorrectly and its impact on medical decisions should be discussed more thoroughly.', 'Further work is needed to improve the interpretability and a fully Bayesian treatment of global parameters.']",False,3,3,3,5,4,"['Novel combination of variational inference and survival analysis.', 'Comprehensive experimental validation on synthetic, semi-synthetic, and real-world datasets.', 'Potential for significant impact in medical settings, particularly in precision medicine.']","['The novelty and advancement beyond existing methods like DSM and SCA need clearer articulation.', 'Empirical validation is not comprehensive; the comparison with profile regression is limited due to computational constraints.', 'The paper is densely written and could benefit from a clearer and more structured presentation.', 'Lacks a detailed discussion on the practical implications and impact of the findings in real clinical settings.', 'Broader ethical considerations of deploying such models in clinical settings are not addressed.', 'Limited interpretability of the model, especially in a clinical context.', 'Requires fixing the number of mixture components a priori.', 'Incremental novelty given reliance on existing deep generative models.', 'Limited discussion on the computational efficiency and scalability.', 'Potential negative societal impacts are not thoroughly discussed.']",3,3,3,3,Reject
5Qkd7-bZfI,"The paper investigates how population heterogeneity, specifically in learning speeds, impacts the structure and stability of emergent languages in neural agents using a Lewis referential game. The authors show that heterogeneity resolves an observed contradiction between sociolinguistic studies and neural simulations regarding the effect of population size on language structure.","['How do the authors ensure that the observed effects are due to heterogeneity in learning speeds and not other confounding factors?', 'Would similar results be observed with other types of heterogeneity (e.g., memory capacity, network architecture)?', 'Can the authors provide more theoretical insights into why heterogeneity in learning speeds leads to more structured languages?', 'Have the authors considered other forms of heterogeneity beyond learning speeds? If so, what are the results?', 'How generalizable are the findings to more complex communication tasks beyond the Lewis game?', 'Can the authors elaborate on the ecological validity of their heterogeneity setup?']","['Results are specific to the Lewis game and learning speed heterogeneity.', 'Experimental setup is complex, making replication difficult.', 'Potential misuse of emergent communication systems in AI could have societal implications.', 'The study is limited to the Lewis game, which may not generalize to other types of emergent communication tasks.', 'Potential negative societal impacts are not thoroughly discussed.', 'The experimental setup may not capture all forms of population heterogeneity present in real-world scenarios.', 'The study primarily focuses on learning speed and does not consider other forms of heterogeneity.', 'The results might not generalize to other emergent communication games or real-world scenarios.', 'The artificial nature of the heterogeneity setup may limit the applicability of the findings.', 'Theoretical underpinnings for the observed phenomena are not robustly developed.', 'Results may not generalize to more complex or real-world settings without further validation.']",False,3,3,3,4,4,"['Addresses a significant gap in emergent communication literature.', 'Employs thorough and systematic experimental methods.', 'Well-organized and clearly described experiments.', 'Findings could influence future research in the field.', 'Proposes a novel hypothesis that heterogeneity in agent populations can lead to more structured and stable languages.']","['Complexity and number of parameters make reproducibility challenging.', 'Findings are based on a specific game setup and particular heterogeneity factors.', 'Lacks a strong theoretical underpinning to explain the observed effects.', 'Additional statistical tests would enhance robustness of conclusions.', 'Limited novelty as it mainly extends existing work by adding heterogeneity parameters.', 'Results presentation could be more concise and focused.', 'The significance of the findings may not be groundbreaking.', 'Potential confounding factors such as network capacity and communication graph topology are not entirely ruled out.', 'Heterogeneity setup is somewhat artificial and specific to the Lewis Game, limiting ecological validity.']",3,3,3,3,Reject
0JzqUlIVVDd,"The paper proposes a novel domain adaptation method using reverse Kullback-Leibler (KL) divergence to align representations between the source and target domains. The approach is theoretically grounded, deriving a generalization bound for the target loss, and shown to be efficient and stable in practice, outperforming several baseline methods in various experiments.","['How does the method perform when the conditional distribution changes significantly between the source and target domains?', 'Can the approach be extended to handle multi-source domain adaptation scenarios effectively?', 'Can the authors clarify how the assumptions made impact the practical applicability of the method?', 'Are there any scenarios where the proposed method might fail?', 'Could the authors provide more details on the computational complexity compared to other methods?', 'Can the authors provide more details on the potential limitations and negative societal impacts of their method?', 'Could the authors clarify the experimental settings, particularly the choice of hyperparameters and the implementation details?', 'Can the authors provide more practical insights or case studies on how their method can be applied to real-world tasks?', 'Can the authors clarify and simplify some of the mathematical derivations and proofs for better readability?']","['Method might not perform well when the conditional distribution changes significantly between domains.', 'Estimator bias in KL term could be problematic in certain scenarios.', 'The practical implications of the assumptions made need further clarification.', 'Potential computational overheads in large-scale datasets.', 'Potential negative societal impacts are not sufficiently explored or addressed.']",False,3,3,3,7,4,"['Novel approach using reverse KL divergence for domain adaptation.', 'Sound theoretical derivation and robust empirical results.', 'Efficient estimation of KL divergence without additional networks.', 'Addresses a significant problem with practical implications.']","['Assumes conditional distribution does not change significantly.', 'Estimator for KL term introduces bias.', 'Clarity issues in mathematical derivations.', 'Limited discussion on practical impacts and assumptions.', 'Insufficient ablation studies to understand hyperparameter effects.', 'Potential limitations and negative societal impacts are not adequately discussed.']",4,3,3,3,Accept
-6me0AsJVdu,"The paper introduces Mutation Validation (MV), a novel model validation method for supervised learning that uses mutated training labels instead of a validation or test set. The method is evaluated across 8 learning algorithms, 18 datasets, and 5 hyperparameter tuning tasks, showing promising results in model selection and hyperparameter tuning stability.","['Can the authors provide more detailed theoretical justifications for the MV metric beyond empirical observations?', 'How does MV perform on datasets with severe class imbalance or highly noisy data?', 'What are the computational complexities and resource requirements for MV compared to traditional validation methods?', 'How does MV compare to other state-of-the-art model validation techniques beyond cross-validation and test accuracy?', 'Can you provide more real-world application examples to better demonstrate the practical utility of MV?', 'What are the potential limitations of MV, and how can they be mitigated?', 'Can the authors discuss any potential limitations or negative societal impacts of using MV?']","['The paper does not explore the impact of MV on datasets with significant noise or class imbalance.', 'Potential ethical concerns related to the misuse of MV in critical applications where overfitting detection is crucial.', 'Theoretical foundations for MV are not well-explained in the main text.', 'The empirical evaluation is extensive but lacks sufficient real-world applications to demonstrate practical utility.']",False,2,2,3,4,4,"['Introduction of a novel concept by applying software testing techniques to model validation.', 'Comprehensive empirical evaluation across multiple datasets and learning algorithms.', 'Demonstrated potential of MV to improve model selection and hyperparameter tuning stability.']","['Theoretical foundations of MV are not robustly established and rely heavily on empirical observations.', 'The paper does not adequately discuss the limitations and potential negative societal impacts of MV.', 'Clarity issues in the presentation, with complex mathematical notations and dense figures that are difficult to interpret.', 'Reproducibility concerns due to lack of detailed experimental setup and parameters.', 'Limited discussion on the impact of MV on datasets with severe class imbalance or highly noisy data.']",3,2,2,3,Reject
eIvzaLx6nKW,"The paper introduces Multi-Domain Self-Supervised Learning (MDSSL), a novel technique for contrastive self-supervised learning across multiple diverse datasets. The authors propose a three-level hierarchical loss function to enhance representation learning and generalization. They demonstrate significant improvements over single-domain and multi-domain baselines, particularly in terms of top-1 accuracy and resource efficiency.","['Could the authors provide more details on how the clustering thresholds were empirically determined?', 'How does the approach scale with a larger number of domains or more diverse datasets?', 'Can the authors discuss potential biases in the datasets used and how MDSSL might amplify or mitigate these biases?', 'What are the computational requirements for training MDSSL on larger datasets?', 'How does the proposed hierarchical loss function compare to other multi-domain self-supervised learning techniques?', 'Can the authors provide more detailed ablation studies to isolate the effects of each component of the hierarchical loss?', 'How robust are the results across different datasets and domain configurations?', 'Can the authors clarify the exact formulation and intuition behind the three-level hierarchical loss function?', 'How sensitive is the performance of MDSSL to the choice of hyperparameters, particularly λ1 and λ2?', 'Are there any plans to test the approach on non-image datasets to validate its generalizability?', 'How does the clustering approach perform in the presence of highly similar domains?', 'Can the literature review be made more concise for better readability?', 'Can the authors provide a more detailed theoretical analysis of the proposed hierarchical loss function?', 'How does MDSSL perform with significantly larger and more diverse datasets?', 'What are the limitations in clustering accuracy, and how does it impact the overall performance of MDSSL?']","['The paper does not extensively discuss potential biases in the datasets used.', 'Scalability with a larger number of domains or datasets is not thoroughly explored.', 'The complexity of the approach might limit its practical applications in real-world scenarios.', 'Potential negative societal impacts are not addressed in detail.', 'The approach may not extend well to non-image datasets without further validation.', 'The robustness of the clustering approach in highly similar domains could be further analyzed.', 'The paper relies heavily on the empirical results without a strong theoretical backing.', ""The clustering method's accuracy in scenarios without domain labels is crucial but not deeply analyzed."", 'Potential scalability issues with increasing numbers of datasets are not fully addressed.']",False,3,2,3,6,4,"['Addresses a significant problem in multi-domain representation learning.', 'Introduces a novel hierarchical loss function.', 'Demonstrates substantial improvements in top-1 accuracy and generalization.', 'Extensive experimental validation with diverse datasets.', 'Proposes a useful extension for scenarios without domain labels using clustering techniques.']","['Complexity of the approach might hinder practical applications.', 'Potential scalability issues with a large number of domains.', 'Limited discussion on the potential negative societal impacts and biases.', 'Some mathematical formulations lack clarity.', 'Reproducibility of results might be challenging despite the provided code.', 'The novelty of the hierarchical loss function may be limited as it builds on existing contrastive learning techniques.', 'Experiments are mostly limited to image datasets; other modalities are not explored.', 'Hyperparameter selection process lacks detailed justification and sensitivity analysis.', 'Literature review could be more concise.']",3,3,2,3,Reject
xnYACQquaGV,"The paper introduces Neural-LinUCB, a neural contextual bandit algorithm that leverages deep representation learning and shallow exploration. The algorithm uses the last hidden layer of a deep ReLU neural network to transform raw feature vectors and employs an upper confidence bound (UCB) approach in the last linear layer for exploration. The authors provide theoretical analysis showing sublinear regret and present experimental results demonstrating the algorithm's effectiveness and computational efficiency over existing methods.","['Can the authors provide more intuitive explanations or visualizations to support the theoretical results?', 'Have the authors considered a broader range of datasets and baselines for empirical evaluation? If not, why?', 'Can the authors clarify the assumptions made in the theoretical analysis and justify their practicality?', 'How sensitive is the performance of Neural-LinUCB to the choice of hyperparameters like the step size ηq and the width of the neural network?', 'Would the algorithm still perform well if the assumptions were relaxed or not fully met in practice?']","[""The paper's theoretical analysis relies on dense and potentially impractical assumptions."", ""The empirical evaluation is limited in scope, which may not fully demonstrate the algorithm's generalizability."", 'The complexity of the proofs may hinder understanding and reproducibility for some readers.']",False,3,3,3,6,4,"['Novel approach combining deep representation and shallow exploration.', 'Theoretical guarantees with sublinear regret.', 'Empirical results show improved performance and computational efficiency.']","['The assumptions and theoretical analysis are dense and may not be fully justified.', 'Limited empirical evaluation with a narrow set of datasets and baselines.', 'Clarity of the presentation can be improved, especially in the detailed sections of the algorithm and proofs.']",3,3,3,3,Accept
qQuzhbU3Gto,"The paper proposes an edge-independent graph generative model that can capture heterophilous structures in graphs and produce interpretable nonnegative embeddings. The model combines nonnegative matrix factorization with logistic PCA and optimizes effectively on real-world graphs using gradient descent on a cross-entropy loss. The paper demonstrates the model's expressiveness theoretically and its effectiveness empirically in tasks such as multi-label clustering, link prediction, and network representation.","['Can the authors provide more details on the computational complexity and scalability of the proposed model?', 'How does the model perform on larger datasets, and what are the practical limitations in terms of size and runtime?', ""Could the authors elaborate on the initialization scheme for nonnegative factors and its impact on the model's performance?"", 'Can the authors provide more detailed explanations of the training algorithm’s steps?', 'What are the potential limitations and negative societal impacts of this work?', ""How does the model's performance vary with different types of graphs (e.g., sparse vs. dense)?"", 'What are the computational complexities of the three stages of the optimization algorithm?', 'How does the proposed model compare with other state-of-the-art methods in more detail?', 'Can the authors clarify the theoretical proofs provided in Section 4?']","['The paper does not discuss the limitations related to the scalability and computational efficiency of the model.', 'Potential negative societal impacts are not addressed, such as biases that might be amplified through community detection.', ""The model's effectiveness on extremely large graphs is not discussed."", 'The potential negative societal impacts of using graph generative models in sensitive applications are not addressed.', 'The societal impacts of using this model, such as privacy concerns or biases in detected communities, are not addressed.']",False,3,3,3,5,4,"['Addresses both heterophily and homophily, going beyond existing models that assume homophily.', 'Nonnegative embeddings provide interpretable results in terms of community participation.', ""Theoretical results demonstrate the model's expressiveness and ability to exactly reconstruct graphs under certain conditions."", 'Empirical results show competitive performance in multi-label clustering and link prediction tasks.']","['The explanation of the model and its optimization process is dense and could be clearer.', 'The novelty might be limited as it combines existing techniques (nonnegative matrix factorization and logistic PCA) rather than introducing fundamentally new methods.', 'The paper does not thoroughly address potential limitations or negative societal impacts of the proposed model.', 'The comparison with other models could be more comprehensive, especially regarding scalability and computational efficiency.']",3,3,3,3,Reject
SYuJXrXq8tw,"The paper introduces two methods to incorporate sparsity into adversarial training to improve robust generalization: (i) Robust Bird, which uses static sparsity by identifying critical sparse subnetworks early in training, and (ii) Flying Bird (and Flying Bird+), which uses dynamic sparsity by allowing the sparse subnetwork to adapt its connectivity pattern during training. The methods are validated through extensive experiments on multiple network architectures and datasets, showing significant improvements in robust generalization and computational efficiency.","['Can the authors provide more theoretical insights into why the proposed methods work?', 'What are the potential limitations of the proposed methods?', 'Could there be any negative societal impacts from adopting these methods?', 'Can the authors provide more detailed pseudocode or implementation details for RB and FB?', 'How do the proposed methods compare to other state-of-the-art adversarial training techniques in terms of training time and computational resources?', 'How sensitive are the results to different hyperparameter settings?', 'Can the methods be generalized to other types of adversarial attacks or defense mechanisms?']","['The paper does not provide a detailed discussion of potential limitations and negative societal impacts.', 'Theoretical underpinning of the proposed methods is limited, relying mainly on empirical evidence.', ""The methods' applicability to other domains beyond image classification is not explored."", 'Potential scalability issues with larger datasets and more complex models.']",False,3,3,3,7,4,"['Addresses a significant problem in adversarial training: the robust generalization gap.', 'Proposes innovative methods (Robust Bird, Flying Bird, and Flying Bird+) to incorporate sparsity.', 'Extensive experimental validation on various datasets and architectures.', 'Significant improvements in robust generalization and computational efficiency.', 'Clear and comprehensive presentation of methods and results.']","['Relies heavily on experimental results without much theoretical underpinning.', 'Dynamic sparsity approach (Flying Bird+) could benefit from more detailed analysis and discussion.', 'Potential limitations and negative societal impacts are not addressed adequately.', 'Methodology could be clearer, particularly the algorithms for RB and FB.', 'Reproducibility of results may be challenging without more specific implementation details.']",3,3,3,3,Accept
O-r8LOR-CCA,"The paper introduces a novel open-world semi-supervised learning (SSL) setting where novel classes may appear in the unlabeled test data. The authors propose ORCA, a method that uses an uncertainty adaptive margin mechanism to handle the class distribution mismatch between labeled and unlabeled data. The paper demonstrates significant improvements over baseline methods through comprehensive experiments on multiple datasets.","['Can the authors provide more detailed explanations and diagrams for complex concepts to improve clarity?', 'How well does ORCA generalize to other types of data or tasks beyond image classification and single-cell annotation?', 'Can the authors provide more details on the extensions and implementations of the baseline methods to ensure fair comparisons?', 'How does ORCA handle highly imbalanced datasets in practice?', 'Can the authors provide more details on the computational complexity of ORCA compared to the baselines?']","['The paper could benefit from a clearer explanation of complex concepts and a more detailed discussion on the generalization of the method to other tasks and data types.', 'The societal impact section is missing, which should address the ethical considerations of deploying ORCA in real-world scenarios.', 'The complexity of the method may hinder its practical applicability in real-world scenarios.']",False,4,3,4,7,4,"['Addresses a realistic and important problem in semi-supervised learning.', 'Introduction of the uncertainty adaptive margin mechanism in ORCA.', 'Comprehensive evaluation and significant improvements shown across multiple datasets.', 'Technically sound with appropriate methods.']","['The paper is dense with technical details, making it difficult for readers to follow.', 'Limited discussion on the generalization of the method to other data types or tasks beyond image classification and single-cell annotation.', 'Extended baseline methods should be clearly described and justified to ensure fair comparisons.', 'Potential overfitting to specific datasets due to extensive hyperparameter tuning.', 'The complexity of the method may hinder its practical applicability in real-world scenarios.']",4,4,3,4,Accept
9u5E8AFudRx,"The paper introduces Help Me Explore (HME), a protocol that combines social and autotelic learning for goal-conditioned RL agents. It also presents GANGSTR, an agent that uses GNNs and a semantic graph to decompose complex goals. The authors demonstrate that even minimal social interventions can significantly improve the learning outcomes of autotelic agents.","['Could the authors provide more details on the potential real-world applications of their approach?', 'How does the performance of GANGSTR compare to other state-of-the-art methods in more complex or real-world environments?', 'What are the limitations in terms of scalability when increasing the number of objects or complexity of the tasks?', 'Can the authors provide more detailed comparisons with other graph-based and non-graph-based RL methods?', 'Can the authors provide more details on the construction and use of the semantic graph?', 'How does GANGSTR perform in environments other than the Fetch Manipulate domain?', 'What are the potential ethical considerations and societal impacts of developing socially guided autotelic agents?', ""Can the authors provide more details on how the simulated social partner's knowledge is modeled and validated?"", 'How do the authors plan to address the potential gap between simulated and real-world social interactions?', 'Can the authors provide more detailed descriptions of the experimental setup and the hyperparameters used?']","['The paper should discuss the scalability of the approach to more complex environments and tasks.', 'Potential negative societal impacts, such as the misuse of autonomous agents in critical areas, should be addressed.', 'The complexity of the method might hinder its practical applicability.', 'Potential reproducibility issues due to the intricate setup and hyperparameter tuning.', 'Limited discussion on the generalization of the approach to real-world scenarios.', ""Dependence on the accuracy of the simulated social partner's knowledge.""]",False,3,3,3,7,4,"['Novel integration of social interventions with autotelic learning.', 'Use of a semantic graph to decompose complex goals.', 'Thorough experimental evaluation demonstrating the effectiveness of the proposed methods.', 'Potential for significant impact in AI and robotics.']","['Complexity of the proposed methods may limit accessibility and reproducibility.', 'Reliance on synthetic environments might limit generalizability.', 'Technically dense presentation could be challenging for some readers.', 'Insufficient evaluation metrics and robustness checks.', 'Limited discussion on potential negative societal impacts.', 'Dependence on simulated social partner which may not generalize to real-world scenarios.']",4,3,3,4,Reject
EYCm0AFjaSS,"The paper introduces ZerO, a deterministic initialization scheme for residual networks that uses only zeros and ones. By adding extra skip connections and applying Hadamard transforms, the authors address the dead neuron problem and training degeneracies associated with zero initialization. Experiments on CIFAR-10 and ImageNet demonstrate competitive performance and improved reproducibility.","['Have the authors tested ZerO initialization on other types of neural network architectures beyond ResNet?', 'Can the authors provide more details on the computational overhead introduced by the Hadamard transforms?', 'How does ZerO perform on other tasks beyond image classification, such as natural language processing or reinforcement learning?', 'What are the implications of ZerO initialization for very deep networks (e.g., ResNet-152) or very wide networks?', 'Can the authors provide more comprehensive ablation studies to validate the effectiveness of each component of ZerO?', 'What are the potential limitations or scenarios where ZerO might not perform well?']","['The experiments are limited to specific architectures and datasets, which may not generalize well to other settings.', 'The paper does not fully explore the computational overhead introduced by the Hadamard transforms.', 'Potential negative societal impacts are not explicitly discussed.', 'The paper primarily focuses on image classification tasks, limiting its broader applicability.', 'The impact of the Hadamard transform on performance needs more rigorous validation.']",False,3,2,3,4,4,"['Novel deterministic initialization method using zeros and ones.', 'Addresses key issues with zero initialization through skip connections and Hadamard transforms.', 'Improves reproducibility and allows training without batch normalization.', 'Clear and well-organized presentation.']","['Experimental validation is limited to specific architectures (e.g., ResNet) and datasets (e.g., CIFAR-10, ImageNet).', 'Potential overfitting to the chosen architectures and datasets.', 'Some theoretical explanations are dense and may be difficult for non-experts to follow.', ""The slight performance degradation in some cases raises questions about the method's generalizability."", 'Lack of clarity in mathematical derivations and experimental setups.', 'Insufficient validation with broader benchmarks and ablation studies.', 'Limited demonstration of broader applicability beyond image classification.', 'The novelty of adding skip connections and Hadamard transforms could be considered incremental.', 'The paper does not adequately address potential limitations and negative societal impacts.', 'Clarity issues, such as complex mathematical notations and insufficient explanations of key concepts.']",3,3,2,3,Reject
MTsBazXmX00,"The paper proposes a novel method for target propagation in neural networks, focusing on recurrent neural networks (RNNs). It introduces regularized inversion and linearized propagation as key computational components, claiming improved efficiency for long sequences compared to traditional back-propagation (BP). The authors provide theoretical comparisons of computational complexity and empirical results on synthetic and real datasets.","['Can the authors provide more extensive benchmarks to validate their claims?', 'How does the proposed method perform on a wider variety of tasks and datasets?', 'Can the authors clarify the theoretical underpinnings of their method, providing more rigorous proofs for their claims?', 'How does the method perform compared to other recent advancements in RNN training, such as those addressing vanishing/exploding gradients?', 'Can the authors clarify the mathematical formulations and provide more intuitive explanations for the proposed method?', 'Can the authors provide more details on the experimental setup and hyperparameters used?', 'How is the regularization term chosen, and how sensitive are the results to this parameter?', 'Can the authors include a comparison with more advanced variants of BP that address the exploding/vanishing gradient problem?', 'What are the potential negative societal impacts of this work, and how can they be mitigated?']","[""The method's applicability is limited to specific types of neural networks and tasks."", 'Potential computational overhead due to the calculation of inverses.', 'The need for regularization parameters, which may require careful tuning.', 'The experimental validation is limited to specific tasks and datasets, which may not generalize well to other applications.', 'The choice and impact of the regularization term are not thoroughly discussed.', 'There is a lack of discussion on the potential negative societal impacts of the proposed approach.']",False,2,2,2,4,4,"['Introduces a clear and structured approach to an alternative propagation method.', 'Provides empirical results suggesting improved performance on certain tasks.', 'Addresses the challenge of training RNNs on long sequences.', 'Theoretical comparisons of computational complexity between TP and BP are provided.']","['Limited originality, mainly combining existing techniques rather than introducing fundamentally new concepts.', 'Experimental evaluation is narrow and lacks comprehensive benchmarks.', 'Theoretical analysis is not entirely convincing, with some claims lacking rigorous proof.', 'The paper is densely written and difficult to follow in places, reducing clarity.', 'Limited significance and potential impact on the broader field.', ""The method's applicability to non-RNN architectures and real-world large-scale datasets is not explored."", 'The paper does not adequately address the potential limitations and negative societal impacts of the proposed method.']",2,2,2,2,Reject
gjNcH0hj0LM,"The paper introduces the Temporal Coherence-based Label Propagation (TCLP) framework for active learning on time-series data. TCLP leverages temporal coherence, where consecutive data points share labels, to propagate queried labels to adjacent points within estimated segments. The framework aims to reduce labeling costs and improve classification accuracy. The authors validate TCLP through extensive experiments across various datasets, showing significant improvements in classification accuracy compared to other methods.","['How robust is TCLP to incorrect segment estimations, and how does it handle edge cases where temporal coherence is weak?', 'Can the authors provide more details on the choice of parameters for the plateau model and their impact on performance?', 'How does TCLP perform in scenarios with varying degrees of label sparsity?', 'What are the computational overheads of TCLP compared to traditional active learning methods?', 'Can you provide more details on the assumptions made in the theoretical analysis?', 'Could you elaborate on potential negative societal impacts of TCLP?', 'Can the authors provide more theoretical depth and mathematical proofs for their methods?', 'How does TCLP perform on different types of time-series data beyond the ones tested?', 'Can the authors provide more practical examples or case studies to demonstrate real-world applicability?', 'Can the authors provide more details on the computational complexity and practical implementation challenges of TCLP?', 'How does the performance of TCLP vary with different hyperparameter settings?', 'Can the authors discuss potential limitations and negative societal impacts in more detail?', 'How does TCLP perform in scenarios where the temporal coherence is weak or inconsistent?', 'What are the potential limitations or edge cases where TCLP might not perform well?']","['The paper does not adequately address the potential negative impacts of incorrect segment estimations.', 'There is a lack of discussion on the limitations of the proposed method in different types of time-series data.', 'The impact of label sparsity on the performance and reliability of TCLP needs further exploration.', 'The paper does not address scenarios where temporal coherence is weak or non-existent.', 'Limited discussion on potential negative societal impacts.', 'The paper does not thoroughly address the limitations of the proposed method in different real-world scenarios.', 'Potential negative societal impacts are briefly mentioned but not deeply analyzed.', 'The paper does not sufficiently address potential limitations such as the dependency on accurate segment length estimation and the complexity of the method.', 'Potential negative societal impacts, such as misapplication in sensitive domains, are not discussed.', 'The paper does not discuss the potential impact of incorrectly propagated labels and how they might affect the overall performance.', ""There is no thorough analysis of the method's performance in real-world scenarios where temporal coherence may not be as strong as in the datasets used in the experiments."", 'The societal impact of reducing labeling efforts in time-series data applications is not addressed.']",False,3,3,3,5,4,"['Novel approach that leverages temporal coherence for label propagation in time-series data.', 'Comprehensive experimental evaluation across several datasets and comparison with existing methods.', 'Detailed breakdown of the proposed method, including segment estimation and sparsity-aware label propagation.', 'Addresses a significant problem in time-series data labeling by reducing the labeling cost.']","['The theoretical foundation for the proposed approach is not well-established.', 'Some aspects of the methodology, such as the specific parameters and their settings, are not adequately justified.', 'Potential risks and limitations, including the impact of incorrect segment estimation, are not thoroughly discussed.', 'The clarity of the paper is hampered by overly complex explanations and lack of concise definitions.', 'Reproducibility concerns due to incomplete details on experimental setup and hyperparameters.']",3,3,3,3,Reject
wu5yYUutDGW,"The paper introduces a Boundary-aware Self-Supervised Learning (BaSSL) framework for video scene segmentation. BaSSL employs pseudo-boundary discovery using dynamic time warping (DTW) and proposes three novel pretext tasks: Shot-Scene Matching (SSM), Contextual Group Matching (CGM), and Pseudo-boundary Prediction (PP). The approach demonstrates state-of-the-art performance on the MovieNet-SSeg benchmark.","['Can the authors provide more details on the DTW-based pseudo-boundary discovery process?', 'Have the authors considered validating the approach on additional datasets beyond MovieNet-SSeg?', 'How does the model handle overfitting to pseudo-boundaries during extended pre-training?', 'How does the proposed method perform in real-time applications given its computational complexity?', 'Are there any plans to extend the framework to other video understanding tasks?', 'How does the system handle videos with rapid scene changes or highly dynamic content?', 'Can the authors provide more detailed explanations or visualizations for the DTW-based pseudo-boundary discovery method?', 'How does the model perform on different types of videos (e.g., documentaries vs. movies)?', 'What are the computational costs associated with training and inference using the proposed method?', 'Can the authors discuss potential limitations or failure cases of the proposed framework in more detail?', 'How does the method perform on other video scene segmentation datasets besides MovieNet-SSeg?', 'Can the approach handle scenarios where pseudo-boundaries significantly deviate from actual scene boundaries?', 'What are the computational requirements for training the BaSSL framework?', 'Can the authors clarify the specific contributions of the DTW in the pseudo-boundary discovery compared to traditional methods?', 'How does the model handle cases where visual cues are extremely similar across different scenes? Are there failure cases?', 'What are the computational costs associated with the proposed method, especially with longer videos?']","['The approach may consume significant computational resources.', 'There is potential for the model to inherit biases from the training data.', 'The reliance on pseudo-boundaries might introduce inaccuracies if these do not align well with true scene boundaries.', 'The approach may require significant computational resources, which could be a barrier for practical deployment.', ""Potential biases in the training data could be reflected in the model's performance.""]",False,3,3,3,7,4,"['Novel approach combining self-supervised learning with boundary-aware pretext tasks.', 'Comprehensive experimental validation demonstrating state-of-the-art performance.', 'Detailed analysis and ablation studies showing the contribution of each component.', 'Well-organized and clearly written.', 'Innovative use of dynamic time warping for pseudo-boundary discovery.']","['Clarity on the DTW-based pseudo-boundary discovery method could be improved.', 'Limited validation on datasets other than MovieNet-SSeg.', 'Potential overfitting to the pseudo-boundaries during longer pre-training.', 'Complexity in the proposed methodology might hinder real-world applicability.', 'Limited discussion on potential negative societal impacts or biases.', 'The computational cost of the proposed method is not thoroughly analyzed.']",4,3,3,3,Accept
qyzTEWWM0Pp,"The paper proposes Multiresolution Equivariant Graph Variational Autoencoders (MGVAE), a hierarchical generative model for learning and generating graphs in a multiresolution and permutation-equivariant manner. The model partitions graphs into clusters at each resolution level and employs higher-order message passing for encoding and decoding. The paper demonstrates competitive results across multiple tasks, including molecular generation, link prediction, and unsupervised molecular representation learning.","['Can the authors provide a more detailed explanation of the clustering procedure?', 'How does MGVAE compare to existing hierarchical graph models in terms of computational efficiency?', 'Can the authors provide more details on the experimental setup, including the datasets and evaluation metrics used?', 'How does MGVAE compare to more recent state-of-the-art models in the field?', 'What are the computational requirements for training and inference with MGVAE?', ""Could additional evaluation metrics be provided to give a more comprehensive assessment of the model's performance?"", 'How does the model perform when trained on larger datasets?', ""Can the authors provide more detailed theoretical analysis and proofs for the claims made about the model's performance and properties?"", 'How does MGVAE compare to other state-of-the-art methods in tasks like unsupervised molecular property prediction?', 'Can the authors clarify the steps involved in the clustering procedure and how it ensures permutation equivariance?', 'Can the authors provide a more detailed explanation and visualization of the hierarchical clustering process?', 'What are the computational complexities of the proposed method compared to simpler baselines?', 'Can the authors provide additional experiments to better demonstrate the scalability of the method?', 'How does the computational complexity of MGVAE compare to other state-of-the-art graph generative models?', 'Can the model handle very large graphs, and if so, what are the limitations in terms of memory and computational power?', 'How would the model perform on dynamic or temporal graphs?']","['The paper does not adequately address the limitations of the proposed model.', 'Potential scalability issues with the hierarchical approach are not discussed.', 'The impact of hyperparameter choices on model performance is not explored.', ""The model's complexity may limit its adoption and reproducibility."", 'Training on small subsets of datasets might affect generalizability.', 'Limited comparisons with recent state-of-the-art models.', 'Potential negative societal impacts, especially in terms of misuse for generating synthetic data, are not addressed.']",False,2,2,3,5,4,"['Novel approach to graph representation and generation.', 'Addresses permutation equivariance in hierarchical graph models.', 'Achieves competitive results in several tasks.', 'Solid theoretical foundation with detailed definitions, algorithms, and mathematical formulations.', 'Versatile applications in molecular generation and image generation.']","['Poorly written and organized, making it difficult to follow.', 'Complex formulation and implementation, which could hinder adoption and reproducibility.', 'Limited comparison with recent state-of-the-art models.', 'Experimental setup and results are not well-documented.', 'Mathematical formulations are dense and not well-explained.', 'Insufficient comparison with state-of-the-art methods, especially in the unsupervised molecular property prediction task.', 'Lacks thorough theoretical analysis to support some of the claims.', 'Potential scalability issues with the hierarchical approach are not discussed.']",3,2,2,3,Reject
ks_uMcTPyW4,"The paper proposes a model-based reinforcement learning framework that incorporates efficient active feature acquisition for partially observable environments using a sequential variational autoencoder (VAE). The approach is tested on a control task and a medical simulator, showing improvements over conventional baselines.","['Can the authors provide more details on how their method differs from and improves upon existing sequential VAE approaches?', 'How were the hyperparameters for the experiments chosen and how sensitive are the results to these choices?', 'What measures were taken to ensure the robustness of the experimental results across different seeds and settings?', 'Can the authors provide more detailed comparisons with other state-of-the-art methods?', 'How does the proposed sequential VAE specifically differ from existing VAE approaches in similar contexts?', 'Can the authors provide more diverse evaluation domains to generalize the findings?', 'Could the authors include more comprehensive ablation studies to better understand the contributions of the different components?']","['The paper should discuss the generalizability of the results to other domains beyond the two tested.', 'Potential negative societal impacts, particularly in the medical domain, need more thorough examination.', 'The high reliance on accurate VAE pretraining may limit the applicability in real-time scenarios.', 'Potential biases in medical domain experiments due to the use of simulated data.']",True,3,3,3,5,4,"['Original integration of active feature acquisition and reinforcement learning.', 'Novel use of sequential variational autoencoders for representation learning in partially observable settings.', 'Thorough experimental evaluation in two domains.']","['Insufficient discussion on novelty compared to existing works.', 'Limited evaluation domains; more diverse tasks would strengthen the results.', 'Complex methodological details that could be clearer.', 'Potential ethical concerns, especially in medical applications, are not fully addressed.', 'Insufficient details on experimental setup and hyperparameters, hindering reproducibility.', 'Lack of comprehensive ablation studies to understand the contribution of different components.']",3,3,3,3,Reject
qEGBB9YB31,The paper introduces a novel parameter-space saliency map approach focusing on network parameters instead of input features to identify and rectify erroneous decisions made by neural networks. The authors validate their approach through experiments showing improved predictions when salient parameters are turned off and fine-tuning salient parameters corrects errors on similar samples. An input-space counterpart is also introduced to demonstrate how image features cause network components to malfunction.,"['Can the method be generalized to other types of neural networks beyond CNNs?', 'How does the proposed method compare with other state-of-the-art explainability methods?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'How can the practical significance of the findings be better demonstrated?', 'Can the authors improve the clarity of the figures and descriptions?']","['The method is only validated on image datasets and CNNs, which may limit its generalizability to other types of neural networks.', 'There is limited discussion on the potential negative societal impacts of the proposed method.', 'The practical utility of the method in real-world applications needs more substantial evidence.', 'Generalizability across different types of neural networks and tasks beyond image classification needs to be addressed.']",False,3,3,3,4,4,"['Novel approach to saliency by focusing on network parameters.', 'Comprehensive experimental validation on multiple datasets.', 'Clear and well-organized presentation.', 'Potentially significant impact on understanding and correcting neural network behavior.']","['Limited discussion on potential limitations and negative societal impacts.', 'Only experiments on image datasets and CNNs are conducted, which may limit generalizability.', 'No comparison with other state-of-the-art explainability methods.', 'Certain sections are dense and could benefit from clearer explanations.', 'Practical utility in real-world applications needs more robust evidence.']",3,3,3,3,Reject
eqaxDZg4MHw,"The paper investigates the generalization gap in visual reinforcement learning (RL) through a large-scale empirical study using procedurally generated video games. It evaluates existing methods such as data augmentation, domain confusion, and auxiliary tasks, and provides new insights on why the generalization gap persists. The paper suggests that task-informed data augmentation and simple auxiliary tasks can improve generalization and emphasizes the importance of hyperparameter tuning.","['Could the authors provide more details on the specific hyperparameters used for each game?', 'How do the findings relate to real-world applications beyond video games?', 'Can the authors elaborate on the potential negative societal impacts of their work?', 'Can the authors provide more theoretical grounding for their empirical findings?', 'How do the proposed methods compare to other state-of-the-art techniques in different RL environments?', 'What are the practical implications and limitations of applying the proposed methods in real-world RL tasks?', 'How were the evaluation metrics chosen, and why are they appropriate for this study?', 'Can the authors elaborate on the specific limitations of their proposed auxiliary tasks?', 'How can the proposed methods be applied in other domains beyond visual reinforcement learning?', 'Can the proposed auxiliary tasks be generalized to other types of RL environments?', 'How feasible is it to perform task-specific augmentations in real-world applications?', 'What are the specific limitations of the proposed methods when scaling to more complex environments?']","['The paper primarily focuses on video games, which may limit the generalizability of the findings to other domains.', 'The impact of hyperparameter tuning is significant, but the paper does not offer a systematic method for this.', 'Potential negative societal impacts are not thoroughly discussed.', 'The study heavily relies on empirical results without strong theoretical backing.', 'The findings are specific to the ProcGen suite and may not generalize to other domains.', 'The reliance on task-specific augmentations limits the general applicability of the findings.', 'The need for extensive hyperparameter tuning makes it less practical for real-world applications.']",False,3,2,2,4,4,"['Comprehensive empirical study with a large-scale experimental setup.', 'Provides valuable insights into the limitations of current techniques.', 'Proposes practical suggestions for future research avenues.', 'Detailed experimental evaluation with robust results.']","['Lacks significant originality; many findings reiterate known challenges.', 'Some sections are not clearly written, making it hard to follow the arguments.', 'The proposed solutions are relatively incremental and not groundbreaking.', 'Experimental results show only moderate improvements over baseline methods.', 'Heavy reliance on empirical studies without providing a clear theoretical framework.', 'Insufficient discussion on the practical implications and limitations of the proposed methods.', 'Potential negative societal impacts are not thoroughly discussed.']",2,3,2,2,Reject
hyuacPZQFb0,"The paper presents ADATIME, a systematic evaluation suite for benchmarking unsupervised domain adaptation (UDA) methods on time series data. It standardizes backbone neural network architectures, preprocessing, and datasets to ensure fair evaluation. It also proposes realistic model selection strategies that do not rely on labeled target data. The paper evaluates 10 state-of-the-art methods using 4 datasets and investigates the performance of visual UDA methods adapted to time series data.","['How were the hyper-parameters chosen for the different UDA methods?', 'Can you provide more details on how the standardization of datasets and preprocessing was achieved?', 'Have you considered evaluating the methods using different backbone networks to assess the robustness of the findings?', 'Can the authors provide more detailed mathematical formulations for the methods evaluated?', 'What steps can be taken to reduce the high variance in performance across different cross-domain scenarios?', 'Can the authors clarify the contributions of their proposed model selection strategies compared to existing ones?', 'How does the proposed approach compare to other existing TS-UDA methods in terms of performance?', 'Can you elaborate on the potential negative societal impacts of your work?', 'Can the authors address potential ethical concerns related to the use of time series data, especially in healthcare?']","['The paper primarily focuses on the evaluation of existing methods rather than proposing new methods.', 'The high variance in some results indicates potential instability in the experiments.', 'Potential societal impacts, such as biases introduced through domain adaptation, are not addressed.', 'The paper does not adequately discuss the limitations of the proposed approach.', 'Potential ethical concerns related to the use of time series data, especially in healthcare, are not adequately addressed.']",True,3,3,2,4,4,"['Addresses a significant gap in the literature by focusing on time series UDA.', 'Introduces a standardized evaluation suite (ADATIME) to ensure fair comparisons.', 'Proposes realistic model selection strategies that do not require labeled target data.', 'Conducts extensive experiments on multiple datasets, providing a comprehensive evaluation.']","['The paper does not introduce a new UDA method.', 'Some evaluation results show high variance, indicating potential instability.', 'Reliance on a single backbone network (1D-CNN) may limit the generalizability.', 'Lacks detailed mathematical formulations for some methods.', 'Could benefit from clearer presentation and organization, especially in the experimental results section.', 'Potential ethical concerns related to the use of time series data, especially in healthcare, are not adequately addressed.']",2,3,3,3,Reject
RjMtFbmETG,"The paper introduces a new soft-greedy operator called resmax for reinforcement learning. Resmax aims to combine the strengths of ε-greedy and softmax while avoiding their weaknesses. Theoretical properties of resmax are analyzed, and empirical results are provided to show its performance in tabular and deep RL settings.","['Can the authors provide more details on the specific hyperparameter tuning process for resmax?', 'How does resmax compare to other advanced exploration strategies not covered in the paper?', 'Can the authors clarify the mathematical notation used in the proofs, especially in Section 5?', 'What are the computational overheads associated with resmax compared to ε-greedy and softmax?', 'How does resmax handle environments with high-dimensional state and action spaces?']","['The paper does not discuss potential negative societal impacts of the proposed method.', 'The empirical validation is somewhat limited and lacks comparison to a broader set of baseline methods.', 'The computational complexity and efficiency of resmax in large-scale settings are not thoroughly discussed.']",False,3,2,3,5,4,"['Proposes a novel soft-greedy operator that addresses limitations of existing methods.', 'Theoretical analysis proving that resmax is a non-expansion operator.', 'Empirical validation across various environments, including tabular and function approximation settings.']","['The clarity of the paper is lacking; many sections are difficult to follow.', 'The experimental results are not thoroughly explained and some key details are missing.', 'The presentation of the mathematical notation and proofs is not always clear.', 'Limited comparison to other state-of-the-art exploration strategies beyond ε-greedy and softmax.', 'Potential negative societal impacts and ethical considerations are not comprehensively addressed.']",3,3,2,3,Reject
UgNQM-LcVpN,"The paper introduces a modulation layer inspired by biological neuromodulation to improve neural network robustness against missing data. This modulation layer adjusts the weights of fully-connected layers based on input reliability, which are learned through a multi-layer perceptron. The authors validate their approach through experiments on multiple datasets, showing improved or comparable performance to traditional methods, especially in the presence of missing data.","['Can the authors provide more details on the modulation function and its training process?', 'How does the modulation layer affect the computational complexity of the model?', 'Can the authors provide a more detailed statistical analysis of the results, including the significance of improvements over baselines?', 'Can the authors provide more rigorous theoretical justification for the modulation mechanism?', 'Why were certain state-of-the-art methods not included in the comparisons?', 'How do the authors address the added complexity and potential overfitting introduced by the modulation network?', 'Can the authors provide more detailed insights into the computational overhead introduced by the modulation layer?', 'How does the modulation layer perform in larger, more complex datasets?', 'Can the authors clarify the impact of the modulation layer on the training time?', 'Is there any risk of overfitting due to the additional parameters introduced by the modulation network?', 'Can the authors provide more details on the specific architectures and hyperparameters used for the modulation network?', 'How does the modulation layer interact with other layers in the neural network? Are there any constraints or best practices?', 'Can the authors clarify the statistical significance of the results? Some performance gains appear marginal.', 'Can the authors provide more details on the hyperparameter tuning process for the modulation network?', 'How does the performance of the proposed method compare with the latest state-of-the-art imputation techniques?', 'Could the authors elaborate on the theoretical underpinnings of the modulation layer and how it relates to traditional attention mechanisms?']","['The paper does not adequately address the limitations of the proposed method, such as potential overfitting due to additional parameters.', 'There is a lack of discussion on the potential negative societal impacts, such as the amplification of biases in datasets with missing data.', 'The method adds a significant number of parameters, increasing the risk of overfitting, especially on smaller datasets.', 'The approach may not generalize well to other types of neural network architectures beyond fully connected layers.', 'Limited exploration of computational overhead and impact on training time.', 'Mixed results across different tasks and datasets.', 'The lack of large, publicly available tabular datasets with high missingness limits the generalizability of the findings.', 'The method is primarily tested on fully connected layers; its applicability to other architectures like convolutional or recurrent layers is not explored.']",False,2,2,2,4,4,"['The idea of dynamically modulating weights based on input reliability is novel and inspired by biological processes.', 'Addresses an important issue in machine learning: robustness to missing and noisy data.', 'Comprehensive experiments across different tasks and datasets.', 'Potentially useful for high-stakes applications like healthcare where data quality can be variable.']","['The paper lacks clarity in the description of the methods and experiments, making it difficult to reproduce results.', 'Theoretical analysis is weak and lacks rigorous justification for the proposed approach.', 'Experimental results are not consistently superior to all baseline methods.', 'Limited discussion on the computational overhead introduced by the modulation layer.', 'Potential overfitting issues not thoroughly addressed.', 'Ethical considerations and limitations are not adequately addressed.']",3,2,2,3,Reject
kcrIligNnl,"The paper introduces a new method for molecular conformation generation that directly generates the 3D coordinates of atoms, avoiding the potential conflicts in distance-based methods. The authors use a variational auto-encoder framework and a loss function invariant to rotations and translations. Experiments on four datasets demonstrate the method's superior performance over existing baselines.","['How does the method perform on even larger datasets beyond those tested?', 'Can the authors provide more details on computational efficiency compared to other methods?', 'Are there any potential negative societal impacts or ethical concerns related to this work?', 'How sensitive is the proposed method to the choice of hyperparameters?', 'Can the method be extended to handle even larger and more complex molecular structures?', 'How does the method perform on datasets with different types of molecular conformations not covered in the current experiments?', 'Can the authors provide more details on the specific architectures used for ϕ2D, ϕ3D, and ϕdec?', 'How does the model ensure that the generated conformations are physically plausible?', 'Could the authors discuss any potential limitations or failure cases in more depth?', 'Can you provide more insights into the failure cases and how often they occur?', 'How would the method perform on different types of molecular datasets not included in the experiments?', 'Can you justify the choice of iterative refinement and its specific architecture more thoroughly?', 'Can the authors provide more detailed ablation studies to understand the impact of each model component?', 'What are the potential limitations and negative societal impacts of this work?', 'How reproducible are the results, and what steps have been taken to ensure reproducibility?']","['The model struggles with certain molecular structures, such as rotatable rings.', 'Scalability to extremely large datasets is not fully demonstrated.', 'Potential negative societal impacts are not discussed.', 'The paper does not discuss in detail the potential limitations of directly generating coordinates, such as handling very large molecules or highly flexible molecules.', 'Potential negative societal impacts, such as misuse in drug design, are not adequately addressed.', 'The paper does not fully explore the limitations of the method, especially in terms of generalizability to other datasets.', 'The discussion on the reproducibility of the results is limited.']",False,3,3,3,6,4,"['Novel approach that directly generates atomic coordinates.', 'Avoids limitations of traditional distance-based methods.', 'Comprehensive experimental evaluation on four datasets.', 'State-of-the-art performance on several benchmarks.', 'Computationally efficient compared to existing methods.']","['Scalability and robustness on very large datasets are not thoroughly investigated.', 'Some failure cases are observed, particularly with rotatable rings in molecules.', 'The impact on computational efficiency should be more comprehensively analyzed.', 'Potential negative societal impacts and ethical concerns are not adequately addressed.', ""The methodology section is somewhat unclear, especially the detailed workings of the model's components."", 'The novelty of using advanced architectures like GATv2 and GN blocks is limited since these are well-established models.', 'The paper lacks a comparison with more recent methods beyond the ones cited.', 'Limited exploration of failure cases and deeper analysis.', 'Justification for iterative refinement and architectural choices could be stronger.', 'Generalizability to different types of molecules or settings not thoroughly discussed.', 'Lacks detailed ablation studies on the impact of various model components.', 'Reproducibility of results is not thoroughly discussed.']",4,3,3,3,Reject
Ub1BQTKiwqg,"The paper proposes a novel method for training sparse neural networks by decoupling the forward and backward paths and applying soft-thresholding to the weights. This approach aims to reduce training cycles and improve model accuracy at high pruning rates. The method is validated on ResNet-50 using the ImageNet dataset, showing improved accuracy compared to existing single-cycle pruning approaches.","['Can the authors provide more details on the experimental setup, including hyperparameters, dataset splits, and specific training configurations?', 'How does the proposed method compare to other recent advancements in pruning techniques not mentioned in the paper?', 'Can the authors discuss the potential limitations and negative societal impacts of their method in more detail?', 'Can the authors provide more detailed steps or pseudo-code to enhance the clarity and reproducibility of the proposed method?', 'Have the authors tested the method on different architectures and datasets beyond ResNet-50 and ImageNet to demonstrate generalizability?', 'What are the potential limitations and negative societal impacts of this method?', 'Can the authors provide more detailed experimental results across different datasets and architectures?', 'How does the proposed method perform in terms of computational efficiency and resource usage compared to other state-of-the-art methods?', 'Can the methodology be explained in more detail to enhance reproducibility?', 'Can the authors provide more details on the theoretical justifications behind the proposed method?', 'How does the method perform with a larger number of seeds to ensure statistical significance of the results?', 'Could you provide a more detailed theoretical analysis explaining why soft-thresholding is more effective than hard-thresholding?', 'Have you considered applying your method to other architectures and datasets beyond ResNet-20/VGG-13 on CIFAR-10 and ResNet-50 on ImageNet?', 'What are the potential societal impacts of your method, especially in terms of computational efficiency and energy consumption?']","['The paper does not sufficiently address the limitations of the proposed method, such as potential challenges in generalizing to different architectures and datasets.', 'The potential negative societal impacts of creating highly sparse models, such as biases in model predictions, are not discussed.', ""The method's generalizability to different architectures and datasets is not well-documented."", 'The potential impact on training time and computational resources for very large-scale models is not discussed.', 'The societal and ethical implications of deploying highly sparse models in critical applications are not considered.', 'The limited number of seeds used in experiments affects the statistical significance of the results.', 'Potential negative societal impacts are not discussed in detail.']",False,2,2,3,5,4,"['The proposed method offers a novel approach to training sparse neural networks by decoupling the forward and backward paths.', 'The use of soft-thresholding instead of hard-thresholding ensures a smoother evolution of weights, potentially improving stability during training.', 'The method demonstrates improved model accuracy at high pruning rates compared to existing single-cycle pruning approaches.']","['The paper lacks a thorough comparison with a diverse set of state-of-the-art pruning methods beyond the few mentioned.', 'The experimental setup is not described in sufficient detail to ensure reproducibility.', 'The paper does not adequately address potential limitations and negative societal impacts of the proposed method.', 'The clarity of the presentation is compromised by several grammatical errors and unclear explanations, making it difficult to follow the methodology and results.', 'Limited seeds (only 3) used in experiments, affecting statistical significance.', 'Code availability only after publication reduces reproducibility during the review process.']",3,2,2,3,Reject
BRFWxcZfAdC,"The paper proposes a novel approach to lossy compression under distributional shift, formulated as an entropy-constrained optimal transport problem. It provides theoretical expressions for the tradeoff between compression rate and distortion and validates the theory through experiments on MNIST and SVHN datasets. The work has potential implications for improving compression techniques in scenarios with distributional shifts.","['Can the authors provide more intuitive explanations or visualizations for the theoretical results?', 'How does the proposed method compare with state-of-the-art lossy compression techniques in terms of rate-distortion performance?', 'What are the potential societal impacts and limitations of the proposed approach?', 'Can the authors provide more details on the computational complexity of their approach?']","['The paper does not thoroughly discuss the potential societal impacts and limitations of the proposed approach.', 'The computational complexity of the proposed method is not discussed in detail.']",False,3,2,3,5,4,"['Novel approach to lossy compression under distributional shifts.', 'Thorough theoretical analysis with multiple theorems and proofs.', 'Experimental validation on real-world datasets (MNIST and SVHN).', 'Demonstrates the utility of shared randomness in improving distortion-rate tradeoffs.']","['Theoretical sections are dense and might be difficult for some readers to follow.', 'Experimental section lacks sufficient benchmarks against state-of-the-art methods.', 'Potential societal impacts and limitations are not thoroughly discussed.', 'Clarity and organization of the paper could be improved.']",3,3,2,3,Reject
_ixHFNR-FZ,"The paper explores the relationship between adversarial robustness and domain transferability, arguing that robustness is a byproduct of regularization rather than the cause of generalization. It provides a theoretical framework, sufficient conditions for transferability, and extensive empirical validation.","['Can you provide more intuitive explanations or visualizations to help understand the theoretical framework?', 'Are there any practical guidelines for applying this theoretical framework in real-world scenarios?', 'Can you discuss potential negative societal impacts in more detail?', 'How do the authors address the potential overfitting of their theoretical framework to specific conditions?', 'Could the authors extend their experiments to more diverse datasets and model structures to strengthen their claims?']","['The paper does not fully explore all possible scenarios where robustness and transferability might interact differently.', 'The complexity of the theoretical framework may limit its practical applicability.', 'The paper could benefit from more diverse datasets and model structures to test the generalizability of their claims.', 'The theoretical framework is quite dense and might be difficult for a broader audience to grasp.', 'The experiments are extensive but could be better organized to highlight key findings.', 'The paper does not discuss potential negative societal impacts of its findings.']",True,3,2,3,6,4,"['Novel exploration of the relationship between robustness and transferability.', 'Development of a new theoretical framework with sufficient conditions for domain transferability.', 'Extensive empirical validation supporting the theoretical claims.', 'Challenges common assumptions in the field, providing new insights.']","['Complex theoretical framework that may be difficult for practitioners to understand and apply.', 'Some parts of the paper lack clarity and could be more concise.', 'Limited exploration of all possible scenarios where robustness and transferability might interact differently.', 'Experiments are limited to specific datasets and models, questioning generalizability.']",4,3,2,3,Reject
C4o-EEUx-6,"The paper introduces Flashlight, an open-source library designed to spur innovation in machine learning frameworks. It focuses on providing a lightweight, modular, and customizable approach that facilitates quick prototyping and experimentation with novel machine learning paradigms. Flashlight aims to reduce the engineering burden on researchers and enable rapid iteration, with benchmarks showing competitive performance against established frameworks like TensorFlow and PyTorch.","['Can the authors provide more details or case studies on real-world applications of Flashlight beyond benchmarks?', 'How does Flashlight handle potential negative societal impacts and ethical considerations in ML research?', 'Can the authors elaborate on the limitations of Flashlight in comparison to existing frameworks?', 'How does Flashlight handle edge cases or less common ML models?', 'Are there any limitations in supporting specific hardware accelerators?']","['The paper does not sufficiently discuss the potential negative societal impacts of the work.', 'The limitations of Flashlight, especially in comparison to established frameworks, are not thoroughly explored.', 'Limited evaluation scope; more real-world applications and diverse ML tasks should be included.', 'Flashlight is not intended for out-of-the-box production use, which could limit its real-world application.']",False,3,3,3,6,4,"['Addresses a significant gap by targeting systems researchers.', 'Focuses on modularity and simplicity, which are well-articulated.', 'Comprehensive performance benchmarks showing competitive results.', 'Open-source, promoting transparency and collaboration.']","['Lacks detailed experimental validation of real-world use cases.', 'Does not adequately discuss potential societal impacts and limitations.', 'Comparison with existing frameworks could benefit from more contextual use cases.', 'Limited novelty in terms of core architecture; modularity and customization are not new concepts.']",3,3,3,3,Reject
TBWA6PLJZQm,"The paper introduces two new benchmark datasets, CIFAR-10N and CIFAR-100N, which provide human-annotated noisy labels for CIFAR-10 and CIFAR-100. The authors collect these labels using Amazon Mechanical Turk and analyze the patterns of real-world noisy labels. They benchmark existing methods on these datasets and highlight the differences between human and synthetic label noise.","['How do the authors ensure the quality and consistency of human annotations?', 'What measures were taken to mitigate the variability in human annotations?', 'Can the authors provide more details on the reproducibility of the data collection process?', 'Could the authors provide more details on the differences in annotation procedures between CIFAR-10H and CIFAR-10N?', 'What measures were put in place to ensure the quality of annotations from Amazon Mechanical Turk workers?', 'How do the authors plan to update and maintain the CIFAR-N datasets and leaderboards?', 'What potential negative societal impacts could arise from the use of noisy labels in real-world applications?', 'How scalable are the methods evaluated in this paper for larger datasets beyond CIFAR-10 and CIFAR-100?', 'Can the findings be generalized to other types of noise beyond image classification tasks?', 'Could the authors provide more details on the experimental setup and hyperparameters used for the empirical evaluations?']","['The paper does not fully address the potential variability in human annotations, which could affect the generalizability of the findings.', 'There is a lack of discussion on the limitations of using Amazon Mechanical Turk for data collection.', 'The potential negative societal impacts, such as biases in the collected data and the working conditions of crowd-sourced annotators, are not discussed in detail.', 'The scalability of the methods to larger datasets or different domains is not discussed.', 'The findings may not fully generalize to other types of noise or tasks beyond image classification.']",False,3,3,3,6,4,"['Introduction of new benchmark datasets with real-world noisy labels for CIFAR-10 and CIFAR-100.', 'Thorough analysis of the patterns of human-generated noisy labels.', 'Comprehensive empirical evaluation comparing human-annotated noise with synthetic noise.', 'Insightful observations on the memorization behavior of deep neural networks.']","['Potential variability and quality issues in human annotations.', 'Lack of a comprehensive discussion on the limitations of the approach.', 'Reproducibility concerns regarding the data collection process.', 'Theoretical analysis supporting the instance-dependent noise patterns is not very deep.', 'Some parts of the paper could benefit from better organization and clarity.', 'Ethical considerations around crowd-sourcing the annotations (e.g., worker conditions) are not comprehensively addressed.']",3,3,3,3,Accept
6u6N8WWwYSM,"The paper introduces ReCo, a contrastive learning framework aimed at improving semantic segmentation by focusing on hard negative pixel samples. ReCo is designed to be easy to implement and enhances performance, particularly in semi-supervised settings with limited labels. The authors demonstrate ReCo's effectiveness through extensive experiments and comparisons with state-of-the-art methods.","['How does ReCo compare with other contrastive learning methods in terms of computational efficiency?', 'Can the authors provide more detailed explanations of the experimental setup?', 'What are the specific limitations of ReCo, and how might they impact its applicability?', 'How does the method generalize to other types of segmentation tasks or different domains outside of the datasets tested?', 'Can the authors provide more ablation studies to assess the contribution of each component in the ReCo framework?', 'Could the authors include more experiments to substantiate the claims of minimal additional memory footprint?', 'Can the authors clarify the process of active sampling in more detail, possibly with an illustrative example?', 'Can the authors clarify the specific hyperparameters used for different datasets and how sensitive ReCo is to these parameters?', 'How does ReCo compare to other state-of-the-art methods when evaluated on additional benchmarks or real-world applications?']","['The paper does not thoroughly discuss the potential limitations of ReCo, such as its scalability to larger datasets or more complex segmentation tasks.', 'The ethical implications of using ReCo in applications like autonomous driving or surveillance are not addressed.', 'The method may not generalize well to tasks or domains significantly different from those tested.', 'The reliance on specific datasets could limit the perceived applicability of the approach.', ""Sparse sampling could miss important pixel-level details in some contexts, potentially limiting the method's effectiveness."", 'The paper does not sufficiently address the potential computational overhead introduced by ReCo.']",False,3,2,3,6,4,"['Novel approach using regional contrastive learning for semantic segmentation.', 'Significant performance improvements in semi-supervised settings with few labels.', 'Extensive experimental results showing performance improvements.', 'Detailed ablation studies and visualizations.']","['The originality of the method could be better distinguished from existing contrastive learning techniques.', 'The clarity of the experimental setup and specific contributions of ReCo need improvement.', 'Potential limitations and ethical concerns are not thoroughly addressed.', 'The paper does not provide sufficient information for reproducibility.', 'Limited discussion on the generalizability of the approach to other domains or tasks.', 'Claims about minimal additional memory footprint are not rigorously substantiated with experiments.']",3,3,2,3,Reject
t5s-hd1bqLk,"The paper introduces a novel approach for conditioning neural networks using learned activation functions, aiming to reduce model size while maintaining or improving performance. The method is evaluated on personalized sound enhancement (PSE) and personalized automatic speech recognition (PASR) tasks, demonstrating competitive performance and significant model size reduction. The approach shows promise for resource-efficient on-device deployment.","['How does the method generalize to non-audio domains such as image or text processing?', 'Can the authors provide more details on the hyperparameter settings and training protocols to ensure reproducibility?', 'Have the authors considered the potential negative societal impacts or ethical considerations of their approach?', 'Can the authors provide more detailed comparisons with existing state-of-the-art methods in terms of performance and model size?', 'Can the authors clarify the initialization choices for the learned activation functions and their impact on performance?', 'What are the potential limitations and societal impacts of this approach?', 'What are the potential risks and ethical considerations associated with personalized models, and how can they be mitigated?']","['Evaluations are limited to supervised audio domains.', 'Potential performance issues with noisy enrollment data.', 'Lack of exploration into other application domains.', 'Potential negative societal impacts, such as privacy concerns with personalized models, are not thoroughly discussed.']",True,3,3,3,6,4,"['Novelty in using learned activation functions for conditional neural networks.', 'Competitive performance and significant model size reduction.', 'Comprehensive experiments across multiple datasets and model architectures.', 'Efficiency in terms of model size and computational requirements.']","['Experiments are limited to audio processing domains, raising questions about generalizability.', 'Clarity issues in presenting the method and results.', 'Lack of in-depth analysis explaining why learned activation functions perform better.', 'Insufficient details on hyperparameter settings and training protocols, hindering reproducibility.', 'Incomplete discussion on limitations and societal impacts.', 'Lack of discussion on potential negative societal impacts or ethical considerations.']",4,3,3,3,Reject
1L0C5ROtFp,"The paper introduces a method for unsupervised learning of counterfactual reasoning in physical processes using videos. The method combines dense features, 2D keypoints, and additional latent vectors per keypoint to capture the dynamics of physical processes. A new benchmark, Filtered-CoPhy, is proposed to evaluate the model, which shows improvements over existing baselines in physics-inspired machine learning and video prediction.","['Can the authors provide a more detailed explanation of the methodology, particularly the training process and the architecture of the dynamic model?', 'How do the authors justify the choice of evaluation metrics and the experimental setup?', 'Can the authors provide more evidence of the significance of their contributions, particularly in real-world applications?', 'Are there plans to extend the evaluation on more real-world datasets?', 'Can the authors provide a clearer articulation of the novel contributions of their method?', 'How does the proposed method compare to the baselines in terms of computational complexity?', 'Can the method be simplified or made more reproducible for the broader community?', 'What are the limitations of the method when applied to real-world data beyond the provided experiments?', 'Can you provide more details on the generalization of your method to real-world scenarios? How well does it perform on real-world datasets compared to synthetic ones?', 'How do you ensure the reproducibility of your method given its complexity? Are there any specific guidelines or resources provided to help other researchers implement your approach?', 'Can the authors provide more theoretical insights into why their hybrid latent representation is expected to perform well for counterfactual predictions?', 'How does the model handle noise and occlusions in the real-world data?', 'What are the potential societal impacts or ethical concerns associated with this work?']","['The paper does not address the limitations of the proposed method, particularly in terms of scalability and real-world applicability.', 'The potential negative societal impacts of the method are not discussed.', 'The complexity of the method might make it difficult for others to reproduce the results.', 'The evaluation on real-world data is limited, which raises concerns about the generalizability of the method.', ""The method's complexity might hinder reproducibility."", 'Limited real-world applicability demonstrated in the experiments.']",False,3,2,3,5,4,"['The combination of dense features, 2D keypoints, and additional latent vectors is a novel approach for modeling physical dynamics.', 'The new benchmark, Filtered-CoPhy, adds value to the research community by providing a challenging dataset for evaluating counterfactual reasoning in videos.', 'The authors provide a thorough comparison with state-of-the-art methods, demonstrating the effectiveness of their approach.', 'Addresses a challenging and important problem in counterfactual reasoning and physics-based video prediction.', 'Extensive experimental results and comparison to various baselines.']","['The clarity of the methodology is lacking in several areas, making it difficult to reproduce the results.', 'The experimental setup and evaluation metrics are not adequately justified.', 'The significance of the contributions is not clearly demonstrated, particularly in real-world applications.', 'The paper lacks a detailed discussion of the limitations and potential negative societal impacts of the proposed method.', 'Complex method with multiple components, which might be difficult to reproduce.', 'Limited evaluation on real-world data.', 'Dense and somewhat challenging to follow, which could hinder understanding and replicability.', 'Novelty of the method could be more clearly articulated.', 'Explanation of dataset constraints might be convoluted for some readers.', 'Complexity and reproducibility of the proposed method could be an issue.']",4,3,2,3,Reject
ZFIT_sGjPJ,"The paper proposes a data-dependent randomized smoothing technique to improve the certified robustness of deep neural networks. By optimizing the variance of the Gaussian distribution for each input, the authors claim enhanced certification radii and improved certified accuracy over existing methods. The approach is applied to several smoothing techniques, demonstrating consistent improvements in certified accuracy on CIFAR10 and ImageNet datasets.","['Can the authors provide more insights into the practical significance of the improvements? How do these improvements translate to real-world applications?', 'The paper mentions memory-based certification but does not provide a detailed comparison with existing certification methods. Can the authors elaborate on this?', 'Can the authors discuss any potential negative impacts or limitations of their proposed method in more detail?', 'Can the authors provide more theoretical analysis or proofs to support the proposed methods?', 'How does the memory-based approach scale with larger datasets and higher-dimensional inputs?', 'Can the authors discuss potential negative societal impacts and ethical considerations of their methods?', 'Can the authors improve the clarity of the explanation of the memory-based certification method?', 'Could the authors provide more detailed pseudocode or implementation details for the memory-based certification method?', 'How does the method perform with non-Gaussian smoothing distributions or different norms (e.g., ℓ1 or ℓ∞)?', 'What are the memory and computational overheads introduced by the memory-based approach, and how do they scale with larger datasets?', 'Can the authors provide more details on the computational overhead introduced by the memory-based certification algorithm?', 'How does the method scale with larger models and datasets beyond CIFAR10 and ImageNet?', 'Can the authors provide more clarity on the experimental setup, particularly the hyperparameters used for the optimization?', 'How does the proposed method compare to other state-of-the-art robustness certification methods beyond the ones mentioned?', 'What are the potential ethical considerations and broader impacts of deploying the proposed approach in real-world scenarios?']","['The proposed method may increase computational complexity due to the optimization process for each input.', 'The improvements are context-specific and may not generalize well to other datasets or tasks.', 'The paper does not adequately address the scalability and efficiency of the memory-based approach.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'The memory-based certification method may introduce significant computational and memory overhead.', 'Potential challenges in applying the method to different types of smoothing distributions or norms.', 'The complexity and scalability of the proposed method for large-scale deployment are not fully addressed.', 'Potential computational overhead introduced by the memory-based certification algorithm.', ""The proposed method's performance and applicability to other types of adversarial attacks and perturbations are not thoroughly explored."", 'The broader impacts and potential negative societal impacts of the work are not fully addressed.']",False,3,3,3,5,4,"['The paper introduces a novel idea of data-dependent smoothing, which optimizes smoothing parameters for each input.', 'Empirical results show consistent improvements in certified accuracy across multiple datasets and smoothing techniques.', 'The proposed method is generic, parameter-free, and easy to implement.']","['The contribution is incremental and builds on existing techniques rather than presenting a fundamentally new approach.', 'The improvements, while present, are not substantial enough to justify publication in a top-tier venue.', 'The paper is lengthy and includes extensive appendices, which might obscure the main contributions and insights.', 'The broader applicability and significance of the proposed method are not well-justified.', 'Lacks substantial theoretical analysis or proofs.', 'Scalability and efficiency of the memory-based approach are questionable.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'Clarity of the paper could be improved, particularly in explaining the memory-based certification method.']",3,3,3,3,Reject
uEBrNNEfceE,"The paper presents a novel approach to the linear-quadratic dual control problem by introducing a safe switched control strategy and Markov parameter inference based on cross-correlation. The proposed method guarantees asymptotic optimality almost surely, addressing the exploration-exploitation dilemma in online adaptive control. Theoretical contributions include proving the almost sure convergence rates for both parameter inference error and control performance suboptimality gap. Simulation results demonstrate the effectiveness of the approach.","['Can the authors provide more details on the computational complexity and scalability of the proposed algorithm?', 'How does the proposed approach perform on different types of systems beyond the Tennessee Eastman Process?', 'What are the potential negative societal impacts of this work, and how do the authors plan to mitigate them?', 'Can the authors provide more details on the practical implementation of the proposed algorithm?', 'How does the proposed method compare empirically with existing state-of-the-art methods?', 'What are the potential broader impacts of this work on the ML and control communities?', 'Could the authors provide more intuitive descriptions of the core ideas and methods to enhance clarity?', 'Are there plans for more extensive empirical validation beyond the current industrial process example?', 'How does the proposed method compare with other existing methods in terms of computational complexity and practical implementation?', 'Can you provide a comparison of the computational efficiency of your method with state-of-the-art approaches?', 'How would your method handle real-world scenarios with more complex dynamics and noise profiles?', 'Can you elaborate on the potential limitations of your approach in practical applications?', 'How practical is the assumption of a known stabilizing controller in real-world scenarios?']","['The authors did not address potential negative societal impacts comprehensively.', 'The experimental validation on a single industrial process might limit the generalizability of the findings.', ""The algorithm's performance in real-world settings is not thoroughly evaluated."", 'The potential negative societal impacts of the proposed method are not discussed.', 'The complexity and density of the paper might limit its accessibility and practical adoption.', 'The empirical validation is somewhat limited and would benefit from being more comprehensive.', 'The method may be computationally intensive.', 'The real-world applicability is not thoroughly demonstrated.', 'The assumption of a known stabilizing controller may limit the applicability in practice.', 'The paper could better discuss the practical computational complexity of the proposed algorithm.']",False,3,3,3,6,4,"['Proposes a novel safe switched control strategy.', 'Guarantees almost sure asymptotic optimality.', 'Detailed theoretical analysis and proofs provided.', 'Addresses a significant problem in online adaptive control with rigorous theoretical guarantees.', 'Ensures safety through a well-defined switching strategy.', 'Theoretical results on convergence rates are backed by detailed proofs.', 'Simulation results demonstrate the effectiveness of the proposed approach.']","['Experimental validation is limited to a specific industrial process.', 'Potential negative societal impacts are not thoroughly discussed.', 'Practical implementation details such as computational complexity and scalability are not comprehensively addressed.', 'Some mathematical sections are dense and might be hard to follow for a broader audience.', 'Clarity of exposition can be improved, especially in the problem formulation and algorithm description sections.', 'Comparison with existing methods is limited to theoretical aspects, lacking empirical benchmarks.', 'Potential impact on broader ML and control communities is not thoroughly discussed.', 'The proposed algorithm and its theoretical framework are complex, potentially limiting accessibility and practical implementation.', 'The paper is dense and sometimes difficult to follow, particularly in sections with heavy mathematical formalism.', 'The empirical evaluation is somewhat limited and would benefit from more extensive validation across diverse scenarios.', 'Potential computational intensity of the proposed algorithm due to switching and continuous parameter estimation.', 'Lack of thorough comparison with state-of-the-art methods regarding computational efficiency.', 'Dense theoretical analysis that may be challenging for practitioners to follow.', 'Limited demonstration of real-world applicability beyond the provided simulation example.', 'Assumes a known stabilizing controller, which may not always be practical.']",4,3,3,3,Reject
JGO8CvG5S9,The paper introduces a theoretical framework for constrained universal approximation using transformer networks. It provides proofs for the existence of probabilistic transformers that can approximate any function within a compact constraint set. The paper also extends the classical universal approximation theorems to the case of constrained learning and provides a new deep neural version of Berge's Maximum Theorem.,"['Can you provide more details on the practical implementation of the proposed probabilistic transformer networks?', 'How do the proposed methods perform in comparison to existing constrained learning approaches?', 'Can you provide some empirical results to validate the theoretical findings?']","['The paper does not provide empirical validation of the theoretical results.', 'The proposed methods may be computationally intensive due to the use of probabilistic attention mechanisms.']",False,3,3,3,5,4,"['Novel theoretical contributions in the area of constrained learning.', 'Extension of classical universal approximation theorems to constrained cases.', 'Introduction of probabilistic attention mechanisms to handle non-convex constraints.']","['The paper is highly theoretical and may be difficult to follow for readers not well-versed in the underlying mathematical concepts.', 'Lack of experimental evaluation to demonstrate the practical applicability of the proposed methods.', 'Clarity of the proofs and explanations could be improved, particularly in the more complex sections.']",4,3,3,3,Reject
IEsx-jwFk3g,"The paper introduces ReBraiD, a graph neural network model designed to capture dynamic brain activities using fMRI and DWI data. It employs novel techniques including sample-level adaptive adjacency matrix learning and multi-resolution inner cluster smoothing, coupled with integrated gradients for interpretability. Extensive experiments are conducted to demonstrate the model's superiority in classifying brain states and interpreting brain dynamics.","['Have you considered testing the model on datasets other than CRASH to validate its generalizability?', 'Can you provide more details on the practical implementation challenges and how they might be addressed?', 'What are the potential real-world applications of your model, and have you considered any clinical validation?', 'Can the authors clarify the specific novel contributions of their techniques compared to existing methods?', 'How do the authors plan to address potential negative societal impacts of their work?', 'Can the authors provide more detailed explanations on the limitations of their model?', 'Can the authors provide more details on how the adaptive adjacency matrix is learned and its computational complexity?', 'How robust are the results to different initializations and data splits?', 'Can the authors provide a clearer explanation of the inner cluster smoothing process with more intuitive examples?', 'Are there any potential negative societal impacts of this work, and how can they be mitigated?', 'How does the proposed method compare to other state-of-the-art methods in terms of both performance and computational efficiency?', 'Can the authors provide more detailed descriptions of the datasets used and how they were preprocessed?', 'What specific steps were taken to ensure the reproducibility of the experiments?', 'Can the authors provide more clarity on the implementation details of the adaptive adjacency matrix learning?', 'How can the results be reproduced, and are there any publicly available codes or datasets?', 'Have the authors considered the potential negative societal impacts of their work?', 'Can the authors elaborate on ethical considerations related to the use of brain data?']","[""The model's complexity might make it challenging for reproducibility and practical implementation."", 'The scope of experiments is limited to the CRASH dataset.', 'The paper could benefit from more discussion on real-world applications and validation in clinical settings.', ""The model's potential limitations in generalizability and scalability are not discussed."", 'Potential negative societal impacts of the work are not addressed.', 'The paper does not clearly discuss the limitations of the proposed method, such as computational complexity and scalability.', 'Potential negative societal impacts, such as misuse of brain state classification, are not addressed.', 'Further discussion on the scalability of the proposed method is needed.', 'The paper lacks a detailed discussion on the reproducibility of results.', 'Ethical considerations related to the use of brain data are not discussed.']",True,3,2,3,4,4,"['Introduction of novel techniques like sample-level adaptive adjacency matrix learning and multi-resolution inner cluster smoothing.', 'Comprehensive experimental validation and ablation studies.', 'Potentially impactful for understanding brain dynamics.', 'Use of integrated gradients for interpretability.']","['Complexity of the model might pose challenges for reproducibility and practical implementation.', 'Experiments are limited to a specific dataset, raising concerns about generalizability.', 'Clarity and organization of the paper need significant improvement.', 'Insufficient discussion on limitations, potential negative societal impacts, and ethical considerations.', 'Reproducibility concerns: Code and data are not provided.']",3,3,2,3,Reject
WLEx3Jo4QaB,"The paper proposes a method called GCOND for condensing large-scale graphs into smaller synthetic graphs while maintaining the performance of Graph Neural Networks (GNNs). The approach uses gradient matching to optimize the condensation process, ensuring that the training trajectory on the condensed graph mimics that on the original graph. Extensive experiments demonstrate significant data reduction with minimal accuracy loss across various datasets.","['Can the authors provide more details on the specific steps taken to ensure the reproducibility of the experiments?', 'How does the method perform on other graph-related tasks beyond node classification?', 'Can the authors elaborate on any limitations or potential negative societal impacts of the proposed method?', 'How does the method handle potential overfitting given the high complexity of the parameterization?', 'Can the authors provide additional comparisons with other state-of-the-art graph reduction techniques?', 'What are the trade-offs in terms of computational cost and memory usage for different datasets?']","['The method may not generalize well to other graph-related tasks beyond node classification.', 'The condensation process could potentially introduce biases or lose important structural information in the graph.', 'The potential for overfitting due to the complex parameterization of the condensed graph.', 'The scalability of the method to even larger graphs or different types of graphs (e.g., those with different structural properties).', 'The impact of the choice of GNN architecture on the effectiveness of the condensation process.']",False,3,2,3,6,4,"['Addresses a significant problem in scaling GNNs to large graphs.', 'Proposes a novel application of gradient matching for graph condensation.', 'Extensive experimental evaluation on multiple datasets showing promising results.', 'Release of code to ensure reproducibility.']","['The methodology section lacks some details, particularly in how the gradient matching loss is computed and optimized.', 'The experimental setup could be better described, especially in terms of hyperparameter tuning and choice of baseline methods.', 'Potential overfitting issues not thoroughly addressed.', 'Limited generalizability to other graph-related tasks beyond node classification.', 'The paper is densely written and lacks clarity in several sections.']",3,3,2,3,Reject
8Wdj6IJsSyJ,"The paper proposes a fully differentiable model discovery algorithm that integrates neural network-based surrogates with Sparse Bayesian Learning (SBL), aiming to autonomously discover differential equations underlying a dataset. The authors extend Physics Informed Neural Networks (PINNs) to various types of neural network architectures and introduce a Physics Informed Normalizing Flow (PINF) for direct density model learning from single particle data.","['Can the authors provide more details on the implementation of the dynamic prior and how it impacts the learning dynamics?', 'How does the proposed method compare in terms of computational efficiency with other state-of-the-art methods?', 'Could the authors elaborate on the limitations and potential failure cases of the proposed method?', ""Can the authors provide more theoretical justification for the choice of hyperparameters and their impact on the model's performance?"", 'How does the proposed method scale with larger datasets or more complex differential equations?', 'Can the authors provide a clearer explanation of the concept of Physics Informed Normalizing Flows (PINFs) and its significance?', 'Can the authors provide a more thorough comparison with other existing methods?', 'What is the rationale behind the chosen hyperparameters and priors?', 'Can the authors provide a stronger theoretical justification for the dynamic prior?', 'Can the authors elaborate on the potential negative societal impacts of their work?']","['The paper does not thoroughly address the potential computational overhead introduced by the fully differentiable approach.', 'The robustness of the method in extremely high noise scenarios or with very sparse data is not extensively validated.', 'Potential ethical implications of the method, particularly in sensitive applications, are not discussed.', 'The method relies on several hyperparameters that need to be carefully tuned, and the impact of these hyperparameters on the performance is not fully explored.', 'The approach may not scale well with larger datasets or more complex differential equations without significant computational resources.']",False,3,2,3,7,4,"['The integration of SBL with PINNs to create a fully differentiable model discovery algorithm is novel.', 'The use of PINFs for density modeling from single particle data is a novel application.', 'Comprehensive experiments on several datasets demonstrating the robustness and accuracy of the proposed method.', 'Robust performance on various datasets, including noisy and sparse data.']","['The paper is dense and challenging to follow, which may hinder reproducibility and understanding of the proposed methods.', 'Theoretical justifications for some of the choices made in the model design are not thoroughly discussed.', 'The impact of the hyperparameters on the performance of the model is not fully explored.', 'The evaluation, though extensive, could benefit from clearer presentation and more structured results to substantiate claims effectively.', 'Potential scalability concerns due to the computational complexity of the proposed method.', 'Limited discussion on potential negative societal impacts.']",3,3,2,4,Reject
UJ9_wmscwk,"The paper proposes GLIE, a Graph Neural Network (GNN) for influence estimation, and integrates it into several influence maximization strategies. The methods are evaluated on both synthetic and real-world graphs, showing competitive performance.","['Can the authors provide more rigorous proofs for the theoretical claims regarding submodularity and monotonicity?', 'How does the performance of the proposed methods compare to state-of-the-art baselines on additional real-world datasets?', 'Can the authors clarify the computational overhead and scalability of the proposed methods?', 'How does GLIE handle dynamic changes in the network structure during real-time applications?', 'Can the authors provide more details on the computational resources required for training and inference on larger graphs?', 'How would the proposed methods perform on graphs with different types of edge weights and influence probabilities?', 'Can the authors provide more details on how the computational overhead of GLIE-CELF and GRIM can be mitigated?', 'Can the methodology section be clarified, especially the parts involving the mathematical formulations?']","['The methods may incur significant computational overhead, particularly for very large graphs.', 'Potential ethical concerns related to the manipulation of social media for influence maximization.', 'The theoretical claims regarding submodularity and monotonicity need more rigorous proof.', 'The experiments are limited to specific graph types, and generalizability is not well demonstrated.', 'Potential misuse in social media manipulation is a critical issue that needs deeper exploration.']",True,3,3,3,6,4,"['Novel application of GNNs to influence estimation and maximization.', 'Comprehensive set of experiments showcasing the potential of the methods.', 'Addresses a significant problem in combinatorial optimization over graphs.', 'Shows potential for scaling to larger graphs.']","['Theoretical claims regarding submodularity and monotonicity are not fully substantiated.', 'The paper is dense and could benefit from better organization and clarity.', 'Some experimental results lack sufficient explanation and context.', 'Reproducibility is not fully ensured despite the provided code.', 'Computational overhead could be prohibitive.', 'Limited experimentation on specific types of graphs.', 'Potential negative societal impacts are not deeply explored.']",3,3,3,3,Reject
d2XZsOT-_U_,"The paper introduces a Transformer-based model for predicting the outcomes of pairwise competitions using historical game data. The model uses embeddings of players' histories and demonstrates improved performance over existing methods like Elo, Glicko, and others on datasets from Chess, Baseball, and Ice Hockey.","['Can the authors provide more justification for their choice of Transformer architecture and hyperparameters?', 'How does the model handle ties in the datasets other than chess?', 'What are the specific computational costs compared to traditional methods?', 'Can the authors provide more details on the mathematical formulation and theoretical justifications for their approach?', 'How does the model handle scenarios with missing or incomplete historical data?', 'Can the authors elaborate on the potential ethical concerns and how they plan to address them?', 'Can the authors provide more details on the implementation and hyper-parameters used?', 'How does the model perform on datasets with different characteristics, such as non-sport competitions?', 'What are the potential biases introduced by using historical data, and how can they be mitigated?', 'Can the authors provide more detailed implementation steps to ensure reproducibility?', ""What criteria were used for selecting the hyperparameters, and how sensitive is the model's performance to these choices?"", 'Can the authors elaborate on how the model could be extended to multi-way competitions?']","['The model does not handle multi-player competitions well.', 'Difficulty in interpreting results due to lack of scalar skill computation.', 'Potential biases and ethical concerns related to the use of historical data.', 'The paper does not address the implications of using this model in different cultural or societal contexts.', 'Possible negative societal impacts of using such models in competitive environments are not discussed adequately.']",True,3,2,3,4,4,"['Novel approach using Transformer-based history embeddings.', 'Comprehensive evaluation on multiple real-world datasets.', 'Capable of making accurate predictions even for new players with limited history.', 'Incorporates contextual information seamlessly.']","['Lack of sufficient explanation and justification for architectural and hyperparameter choices.', 'Results are not significantly better than strong baselines in some cases.', ""The method's applicability to multi-player competitions is not addressed."", 'Clarity issues in some sections, making it hard to follow.', 'Insufficient transparency in the implementation details, making reproducibility challenging.', 'Potential biases and ethical concerns related to the use of historical data.']",3,3,2,3,Reject
HHpWuWayMo,The paper introduces a new adversarial attack framework called cMBA (model-based attack on c-MARL) for multi-agent reinforcement learning (MARL) in continuous action spaces. The approach involves learning a dynamics model of the environment and using it to generate state perturbations that degrade team performance. The authors evaluate their method on multiple MuJoCo environments and demonstrate that it outperforms baseline methods.,"['Can the authors provide more details on the optimization process used in Algorithm 1 and 3?', 'How does the choice of dynamics model architecture impact the robustness of the attack?', 'Can the authors elaborate on how they ensure the reproducibility of their experiments?', 'What are the potential negative societal impacts of this research, and how can they be mitigated?', 'Can the authors provide more clarity on the problem formulation and the algorithms described in the paper?', 'How does the proposed approach compare with other state-of-the-art adversarial attack methods in reinforcement learning?', 'How does the performance of the learned dynamics model vary across different environments?', 'Can the authors provide more details on the training process for the dynamics model?', 'What are the implications of using adversarial attacks in real-world MARL applications?', 'Can you provide more details on the hyperparameters and experimental setup to improve reproducibility?', 'Why were Uniform and Gaussian noise chosen as baselines? Are there more robust baselines that can be used for comparison?', 'Can you clarify some of the mathematical formulations, especially the optimization problem?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'How do you address the ethical implications and potential misuse of adversarial attacks in MARL?', 'Can the authors clarify the specific novel contributions of their attack framework compared to existing adversarial attack methods in reinforcement learning?', ""How does the learned dynamics model's accuracy affect the effectiveness of the adversarial attacks?"", 'Could the authors provide more discussion on the ethical implications of their work?']","['The paper does not sufficiently address potential negative societal impacts of adversarial attacks in multi-agent systems, especially in safety-critical applications.', 'The clarity of the methodological descriptions could be improved to aid reproducibility.', 'The victim selection strategy is not thoroughly justified and may not be significantly novel.', 'The choice of baselines might not be robust enough to demonstrate the superiority of the proposed method.', 'The paper does not adequately discuss potential limitations of the proposed approach, such as the reliance on the accuracy of the learned dynamics model.', 'There is a lack of discussion on the ethical considerations and potential societal impacts of adversarial attacks on reinforcement learning systems.']",True,2,2,2,4,4,"['Novelty in addressing adversarial attacks in c-MARL with continuous action spaces.', 'Well-structured approach combining learned dynamics model with optimization for perturbations.', 'Extensive experimental evaluation across multiple environments.', 'Demonstrated effectiveness of the proposed method compared to baselines.']","['Some methodological descriptions lack clarity, particularly around the optimization process and the training of the dynamics model.', 'Limited discussion on potential negative societal impacts and ethical considerations.', 'Absence of comparison with more recent related works in the field.', 'Certain design choices, such as the selection of victim agents, could be elaborated further.', 'Reproducibility is a concern due to the lack of detailed hyperparameters and experimental setup.', 'The choice of baselines (Uniform and Gaussian noise) might not be robust enough to demonstrate the superiority of the proposed method.', 'The originality of the victim selection strategy is questionable and not well-justified.', 'Limited novelty beyond combining existing techniques.']",3,2,2,3,Reject
WPI2vbkAl3Q,The paper presents a theoretical framework for understanding the learning dynamics of Stochastic Gradient Descent (SGD) on structured features. It derives exact expected test errors for both Gaussian and arbitrary feature structures and validates these theoretical predictions on real datasets such as MNIST and CIFAR-10. The authors explore the implications of feature structure on optimal batch sizes and computational efficiency.,"['Can the authors provide more intuitive explanations for their theoretical findings to enhance clarity?', 'How robust are the theoretical results when applied to more complex, real-world datasets beyond MNIST and CIFAR-10?', 'What are the limitations of the proposed theory, and how might it be extended or improved in future work?', 'Is there a formal proof or additional theoretical work that could support the generalizability of the results to non-Gaussian feature distributions?', 'Can the theory be extended to other optimization algorithms beyond SGD?', 'How do the results compare with recent advancements in understanding SGD dynamics in neural networks?', 'Can the clarity of the mathematical derivations be improved for better accessibility?', 'How do the theoretical results generalize to other types of neural network architectures?', 'What are the potential negative societal impacts of this work?', 'Can the authors provide more details on the reproducibility of the experiments?', 'Have the authors considered validating their theory on more diverse datasets?', 'How accessible do the authors believe their work is to the broader ML community?']","['The paper does not discuss the potential limitations of the Gaussian approximation in real-world scenarios.', 'The societal impact of the work, including potential negative consequences, is not addressed.', 'The generalizability to non-Gaussian features is not formally proven.', 'Empirical validation is limited to a few datasets.', 'The theoretical results may not generalize to all neural network architectures.', 'The complexity of the theoretical framework may limit its accessibility.']",False,3,2,3,5,4,"['Provides a thorough theoretical framework for understanding the dynamics of SGD with structured data.', 'Extends theory to practical scenarios and validates with experiments on real datasets.', 'Addresses an important problem in understanding SGD dynamics.', 'Includes detailed derivations and extensive references.']","[""Clarity: The paper's complex derivations and theoretical explanations can be difficult to follow, which may hinder understanding for a broader audience."", 'Practical applicability: The practical relevance of some theoretical results, such as the exact conditions for Gaussian approximations, is not fully explored.', 'Generalizability to non-Gaussian feature distributions lacks formal proof and relies on empirical validation.', 'Experiments are limited to a few datasets, which may not be sufficient for broad applicability.', 'Heavy theoretical focus may limit immediate practical impact.', 'Reproducibility details are insufficiently discussed.']",4,3,2,3,Reject
YZHES8wIdE,"The paper presents a Generative Planning Method (GPM) for reinforcement learning, which generates multi-step action plans to improve exploration efficiency. The method is designed to generate temporally coordinated plans that adapt over time, aiming to provide better exploration than single-step actions. The authors demonstrate the effectiveness of their approach on a variety of benchmark environments and provide experimental results showing improvements over baseline methods.","['Could the authors provide more details on the computational complexity of GPM compared to baseline methods?', 'How sensitive is GPM to the hyperparameters, such as plan length and target commitment length?', 'Can the authors provide a theoretical justification or analysis for the observed improvements in exploration efficiency?', 'How does GPM perform in more complex and real-world environments, and are there any limitations observed in such settings?', 'Can you provide more details on how the plan value function is initialized and trained?', 'Can GPM be applied to discrete action spaces, and if so, how would the method need to be adapted?', 'How does the proposed method compare with more recent and advanced baselines?', 'Can the authors provide more detailed analysis on tasks where the method does not perform well?', 'What are the specific limitations and how can they be addressed in future work?', 'How does the proposed method compare with hierarchical RL and model-based RL in terms of both performance and computational complexity?', 'Can the authors provide more detailed statistical analysis of the experimental results, including confidence intervals and significance tests?', 'What are the potential negative societal impacts and ethical considerations of the proposed method?', 'Can you provide a more detailed theoretical analysis to support the claims made in the paper?', 'How does the method scale with high-dimensional action spaces, and what are the computational requirements?', 'Can you provide more details on the marginal improvements observed in some tasks compared to baseline methods?', 'What are the potential negative societal impacts of this work, and how do you plan to mitigate them?']","['The paper does not thoroughly explore the potential negative societal impacts of the proposed method. For instance, the use of such planning methods in autonomous driving could have safety implications.', 'There is limited discussion on the scalability of GPM to very large action spaces or high-dimensional state spaces.', 'The theoretical foundations of the proposed method need more elaboration.', 'The discussion on potential negative societal impacts and limitations is insufficient.']",True,3,2,3,5,4,"['The concept of generating multi-step action plans for RL is novel and could potentially address the inefficiency of single-step exploration.', 'The paper includes comprehensive experimental results across different tasks, showing that GPM outperforms several baseline methods.', 'The authors provide a clear motivation for their approach, connecting planning and model-free RL in a novel way.', ""The method's ability to generate interpretable plans is highlighted, which could be beneficial for applications requiring transparency.""]","['The paper is quite dense and can be challenging to follow, particularly in the technical sections describing the algorithms and their implementation.', 'Some of the claims regarding the superiority of GPM are not fully substantiated with theoretical analysis.', 'The experimental evaluation, while extensive, could benefit from more diverse and complex environments to fully demonstrate the robustness of GPM.', 'The paper could do a better job of situating itself within the broader RL and planning literature, particularly in terms of related work.', 'Potential negative societal impacts and ethical considerations are not adequately addressed.']",3,3,2,3,Reject
o6dG7nVYDS,The paper presents a learning-theoretic generalization bound for domain generalization (DG) and hypothesizes that existing methods' performance variability can be explained by an empirical risk-predictor complexity trade-off. The authors validate their hypothesis through empirical results on the DomainBed benchmark using linear models and shallow neural networks. They recommend a model selection strategy using cross-validation for optimal DG performance.,"['Can the theoretical results be extended to more complex neural network architectures?', 'What are the practical implications of the findings for real-world applications?', 'How does the proposed theoretical bound compare with existing bounds in the literature? What are the specific differences and advantages?', 'How well do the findings generalize to more complex neural network architectures beyond the linear models and pre-computed features used in the experiments?', 'How does the proposed domain-wise cross-validation strategy compare with other existing model selection methods in DG?', 'How do the authors envision their model selection strategy being applied in practice, especially for large-scale deep learning models?', 'Could the authors provide more details on the computational feasibility and efficiency of the proposed approach for large-scale datasets and models?']","['The reliance on linear models and shallow neural networks for empirical validation may limit the applicability of the results to more complex models.', 'Challenges in accurately tuning neural network hyperparameters due to the stochastic nature of neural network training.', 'Limited diversity in experimental settings and comparisons with existing methods.', 'The paper lacks a detailed discussion on potential negative societal impacts, such as the consequences of misgeneralization in high-stakes applications.']",False,3,3,3,7,4,"['Novel theoretical insights into DG using Rademacher complexity.', 'Thorough empirical validation using controlled experiments with linear models and shallow neural networks.', 'Comprehensive analysis of various DG methods.', 'Practical recommendations for model selection strategy.']","['Reliance on linear models and shallow neural networks for theoretical validation, limiting generality to more complex neural network architectures.', 'Need for clearer explanation of practical implications for real-world applications.', 'Limited diversity in experimental settings and comparisons with existing methods.', 'The paper could benefit from a more detailed discussion of potential limitations and societal impacts.']",3,3,3,3,Accept
dtYnHcmQKeM,"The paper introduces the Physics-Informed Neural Operator (PINO), which combines operator learning and physics-informed optimization to solve partial differential equations (PDEs). PINO aims to improve convergence rates and accuracy while maintaining computational efficiency. The method leverages pre-trained neural operators as ansatzes for test-time optimization, combining data-driven and physics-informed constraints. Extensive experimental validation is provided across various PDE problems, demonstrating significant improvements over existing methods.","['Can the authors provide more detailed comparisons with other advanced methods like LAAF-PINN and SA-PINN?', 'What are the specific limitations of PINO, and how might they affect its broader applicability?', 'Could the authors elaborate on the potential negative societal impacts of deploying PINO in real-world applications?', 'How does PINO perform on PDEs not included in the experimental section?', 'Can the authors provide a theoretical analysis of the optimization landscape for PINO?', 'How sensitive is the model to the choice of hyperparameters?', 'Can the authors provide a more detailed comparison with existing hybrid methods that combine physics-informed and data-driven approaches?', 'What are the computational resource requirements for pre-training the operator and for test-time optimization?', 'How does PINO perform on real-world large-scale PDE problems that were not covered in the experiments?', 'Can the authors provide a clearer differentiation between PINO and existing methods such as PINN-DeepONet and Physics-constrained modeling?', 'Can the authors include a more detailed explanation of the experimental setup and hyperparameters used in the evaluation?', 'How does PINO perform compared to other state-of-the-art methods on a broader range of PDE problems?', 'Can the authors explain the choice of specific PDE problems for evaluation and whether these choices generalize to other types of PDEs?', 'Can you provide more details on the computational complexity and scalability of PINO compared to existing methods?']","['The potential for high computational cost during the test-time optimization phase.', 'Dependence on the quality and quantity of training data for the pre-training phase.', 'Possible challenges in extending PINO to highly irregular geometries.', 'The method relies heavily on pre-training, which may not always be feasible.', 'The approach may not scale well for very high-dimensional PDEs.', 'Potential negative societal impact if used in critical applications without thorough validation.', 'The scalability of PINO to extremely large-scale problems was not extensively tested.', 'Potential limitations in generalizability to other types of PDEs not covered in the experiments.', 'Possible over-reliance on specific datasets used for training and evaluation.', 'The computational complexity of the method is not thoroughly discussed.']",False,3,2,3,6,4,"['Innovative combination of operator learning and function optimization.', 'Extensive experimental validation on multiple PDEs.', 'Promising results showing improved accuracy and convergence over existing methods.', 'Detailed theoretical explanation and clear problem formulation.']","['The paper is dense and complex, making it challenging for readers to follow without substantial background knowledge.', 'Limited discussion on the potential limitations and negative societal impacts of the proposed method.', 'Comparisons with other state-of-the-art methods like LAAF-PINN and SA-PINN are included but not deeply analyzed.', 'Potential over-reliance on specific experimental setups and parameters.', 'Lack of theoretical analysis to support the empirical findings.', 'Potential overfitting due to extensive use of hyperparameters and tuning.', 'Limited discussion on the scalability and generalizability of the approach to other types of PDEs.']",3,3,3,3,Reject
z8xVlqWwRrK,"The paper introduces Event-based Variational Distributions for Exploration (EVaDE) in Model-Based Reinforcement Learning (MBRL). EVaDE comprises three novel event-based convolutional layers designed to facilitate exploration in object-based domains. The effectiveness of EVaDE is demonstrated on a suite of 12 Atari games, showing significant improvement over existing methods in a low data regime.","['Can the authors provide more details on how the EVaDE layers were implemented?', 'How generalizable are the results beyond the Atari game domain?', 'Can the authors discuss the potential limitations and negative societal impacts of their approach in more detail?', 'Can the authors provide more theoretical insights into why EVaDE performs better?', 'How does EVaDE compare with other state-of-the-art exploration methods in reinforcement learning?', 'What are the limitations of EVaDE in non-object-based environments?', 'Can you provide more details on the computational overhead introduced by the EVaDE layers?']","['The paper does not discuss the potential limitations and negative societal impacts of the proposed approach adequately.', 'It is heavily focused on Atari games, which may limit the generalizability of the results.', 'The method may not generalize well to environments that are not object-based.', 'Scalability to larger and more complex environments is not discussed.']",False,3,2,3,5,4,"['Addresses an important problem in MBRL by focusing on exploration using domain knowledge.', 'Introduces three novel event-based convolutional layers with detailed theoretical explanations.', 'Empirical results show significant improvement over existing methods on several Atari games in a low data regime.', 'Innovative approach leveraging event-based variational distributions.', 'Thorough comparative analysis with significant performance improvements.']","['Clarity of the paper could be improved, especially in the implementation details of the EVaDE layers.', 'Heavily focused on the Atari game domain, which may limit the generalizability of the results.', 'Lacks a thorough discussion on limitations and potential negative societal impacts.', 'Limited discussion on the scalability and generalizability to other environments.', 'Comparative analysis with more state-of-the-art methods is needed.']",3,3,2,3,Reject
ODnCiZujily,"The paper proposes DeepSplit, a novel method leveraging operator splitting and ADMM to solve large-scale convex relaxations for the verification of deep neural networks. The method is demonstrated to provide tighter bounds on the worst-case performance of neural networks while being scalable and parallelizable, with promising results on CIFAR10 and Atari game tasks.","['Can the authors provide more details on the potential limitations of the proposed method?', 'How does the method perform on different types of neural network architectures beyond those tested?', 'Are there any computational bottlenecks or scalability issues that the authors foresee with larger networks?', 'Can the authors provide more details on potential negative societal impacts of their work?', 'Could the authors simplify or better summarize the implementation details for different types of layers?', 'How does the method handle environments with limited computational resources (e.g., without GPU acceleration)? Are there any optimizations or approximations that could be applied in such cases?']","['The paper does not thoroughly discuss the limitations of the proposed method in terms of its applicability to different network architectures and potential computational bottlenecks.', 'Potential negative societal impacts are not thoroughly discussed.', ""The reliance on GPUs for acceleration might limit the method's applicability in environments without high computational resources."", 'The technical complexity of the method could pose challenges for practitioners without a strong background in optimization and verification.']",False,4,3,4,7,4,"['Addresses significant challenge in neural network verification scalability.', 'Modular and parallelizable method using GPU.', 'Substantial improvements in certified robustness for image classification and reinforcement learning tasks.', 'Comprehensive comparison with state-of-the-art techniques.', 'Effective use of GPU acceleration for faster computation.']","['Highly technical and may be challenging for readers without a strong background.', 'Experimental results are limited to specific tasks.', 'Lacks thorough discussion of limitations, particularly in terms of applicability and computational bottlenecks.', 'Limited discussion on the potential negative societal impacts of the method.', 'Comparison with baseline methods could be more comprehensive, especially for larger networks.']",4,4,3,4,Accept
morSrUyWG26,"The paper introduces AutoOED, an automated platform for optimal experimental design using multi-objective Bayesian optimization (MOBO). It features a novel asynchronous optimization strategy called Believer-Penalizer (BP) and offers a modular framework with a user-friendly GUI. The platform's performance is demonstrated on standard benchmark problems and real-world applications, showcasing its ability to efficiently guide experiments towards Pareto optimal solutions.","['Can the authors provide more detailed ablation studies to highlight the specific advantages of the BP strategy?', 'How does the BP strategy specifically improve over existing asynchronous methods like KB and LP?', 'What are the potential limitations and negative societal impacts of AutoOED?', 'How does AutoOED handle noisy or incomplete data in real-world experiments?', 'Can the authors provide a more rigorous theoretical justification for the BP strategy?', 'How does AutoOED perform on more diverse sets of benchmark problems compared to existing platforms?', 'Could the authors provide more details on the technical implementation of the BP strategy?', 'How does the performance of AutoOED compare to other platforms in real-world applications beyond the benchmarks used?', 'Can the authors provide more real-world examples to demonstrate the broader applicability of AutoOED?', 'How does AutoOED handle ethical and societal impacts, especially in sensitive applications?', 'Can the authors provide more details on the real-world application examples and their significance?', 'How does AutoOED compare with state-of-the-art methods in terms of computational efficiency and scalability?', 'Can the authors elaborate more on the BP strategy and its theoretical foundations?', 'What are the limitations of the BP strategy in practice?']","[""Potential over-reliance on the surrogate model's predictions, which may lead to suboptimal solutions if the model is inaccurate"", ""Scalability concerns for very high-dimensional problems, which may affect the platform's performance"", 'Possible challenges in integrating with diverse experimental setups, limiting its applicability in some domains', 'The paper does not sufficiently address the potential limitations of the BP strategy, such as its performance in highly noisy environments.', 'The discussion on the negative societal impacts of the platform is minimal, which is important for ethical considerations.', 'There is a lack of detailed justification for some experimental setups and hyperparameter choices, which affects the reproducibility of the results.']",False,3,3,3,6,4,"['Novel asynchronous optimization strategy (BP) that combines the strengths of Kriging Believer (KB) and Local Penalization (LP)', 'User-friendly GUI for non-experts, making the platform accessible to a broader audience', 'Modular framework for easy extension and evaluation of different MOBO algorithms', ""Comprehensive empirical evaluations on benchmark problems and a real-world experiment, demonstrating the platform's robustness and applicability""]","['Limited discussion on the novelty and robustness of BP strategy compared to existing methods', 'Insufficient clarity in some explanations and figures, making it difficult to fully understand the methodology', 'Lack of detailed ablation studies to highlight specific advantages of BP over other asynchronous methods', 'Inadequate discussion on potential limitations and ethical considerations of the platform']",3,3,3,3,Reject
-TSe5o7STVR,"The paper proposes LaMer, a novel self-supervised text style transfer framework that improves performance on non-parallel datasets. It leverages large-scale language models and mines roughly parallel expressions to enhance training. LaMer outperforms existing methods on sentiment, formality, and political stance transfer tasks, with strong results in transfer accuracy, content preservation, and fluency.","['Can the authors provide more details on the computational cost and scalability of LaMer?', 'How does LaMer handle highly noisy non-parallel datasets, and what are the failure modes?', 'Can the authors elaborate on the ethical considerations and potential negative impacts of deploying LaMer in real-world scenarios?']","['The scalability and computational cost of the proposed method are not discussed.', 'Potential ethical concerns and negative societal impacts are acknowledged but not thoroughly explored.', 'Details on hyperparameter tuning and experimental setup are insufficient for reproducibility.']",True,3,3,3,6,4,"['Innovative approach for utilizing self-supervision in non-parallel datasets.', 'Significant performance improvements over existing models on multiple tasks.', 'Introduction of a new dataset for political stance transfer.', 'Comprehensive evaluation including human assessments.']","['Methodology, particularly the mining and alignment process, lacks clarity.', 'Insufficient discussion on computational cost and scalability.', 'Ethical concerns and potential negative impacts are acknowledged but not deeply explored.', 'Reproducibility concerns due to insufficient details on hyperparameters and experimental setup.']",3,3,3,3,Reject
i--G7mhB19P,"The paper investigates the inductive biases and generalization properties of Natural Gradient Descent (NGD) compared to Euclidean Gradient Descent (EGD) in deep linear models and matrix factorization tasks. The authors provide theoretical insights and experimental results demonstrating that NGD often fails to generalize as effectively as EGD, despite its invariance to reparametrization.","['Can the authors provide more insights into how the findings might extend to non-linear models?', 'Could more experiments be conducted on practical deep learning tasks to validate the claims?', 'What are the potential limitations and negative societal impacts of using NGD in real-world applications?', 'Can the authors provide more intuitive explanations for some of the dense mathematical notations used in the theoretical sections?', 'What is the computational cost of NGD compared to EGD in practical applications?']","['The paper does not adequately discuss the limitations of the work, particularly in terms of the scope of models evaluated (mainly linear models).', 'Potential negative societal impacts of the proposed techniques are not addressed.', 'The experiments are limited to specific model architectures and types of data, which might not generalize to a broader range of settings.', 'There is no discussion on the computational cost of NGD compared to EGD, which is a practical consideration for real-world applications.']",False,3,2,3,4,4,"['Addresses a significant and underexplored aspect of optimization in deep learning.', 'Provides both theoretical and empirical evaluations to support claims.', 'Development of efficient algorithms for exact natural gradient computation.']","['Clarity is hindered by dense mathematical notation and complex explanations.', 'Experimental validation is limited in scope and may not generalize well to more practical deep learning tasks.', 'Insufficient discussion on the limitations and potential negative societal impacts.', 'Does not deeply explore the computational costs associated with NGD.']",3,3,2,3,Reject
zyrhwrd9EYs,The paper introduces a new mechanism called Mixed Confounded Missingness (MCM) to handle missing data in treatment effect estimation. It proposes selective imputation as a solution to improve the performance of treatment effect models. The method is theoretically motivated and empirically validated using synthetic datasets.,"['Can the authors provide a more accessible explanation of MCM?', 'How does the method perform on real-world datasets?', 'Can the authors simplify the theoretical part and provide stronger proofs?', 'Can the authors compare their method with a broader range of baseline methods?', 'How does selective imputation perform with more complex real-world datasets?', 'Can the authors elaborate on the potential limitations and edge cases where selective imputation might fail?', 'How are the theoretical proofs connected to the empirical results?', 'What are the potential societal impacts and limitations of the proposed method?']","['The paper does not address how the method performs on real-world data.', 'Theoretical claims are not well-supported by proofs.', 'The explanation of MCM is complex and hard to follow.', 'The empirical validation relies heavily on synthetic data, which might not fully capture real-world complexities.', 'Potential negative societal impacts and ethical considerations of using selective imputation in critical fields like healthcare are not discussed.']",False,3,2,3,5,4,"['Addresses a critical issue in treatment effect estimation.', 'Introduces a novel mechanism (MCM) for handling missing data.', 'Proposes a theoretically motivated solution (selective imputation).', 'Empirical validation shows promising results across different learners and missingness scenarios.']","['Theoretical part is overly complex and lacks strong proofs.', 'Relies heavily on synthetic data for validation.', 'No application to real-world data.', 'Verbose presentation that could be clearer.', 'Insufficient clarity on novelty and comparison with existing methods.', 'Empirical results need more robust statistical evidence and broader datasets.', 'Theoretical proofs are not well connected to empirical results.', 'Lacks comprehensive discussion on potential societal impacts and limitations.']",3,3,2,3,Reject
NZQ8aTScT1-,"The paper introduces a theoretical framework to understand the learning dynamics of neural networks, focusing on convolutional neural networks (CNNs). It presents the concept of learning indices, combining spatial and frequency indices to characterize the eigenstructure of neural kernels. The paper aims to explain the superior performance of deep CNNs through this framework.","['Can the authors provide more empirical evidence to support their theoretical claims?', 'How do the proposed concepts apply to other types of neural network architectures such as RNNs or GNNs?', 'Can the authors simplify the presentation of their theoretical framework for better readability?', 'How can the insights from this paper be applied to practical neural network design?', 'Are there any plans to validate the theoretical claims on larger, more diverse datasets?', 'Can the authors provide code or more detailed pseudocode to enhance reproducibility?', 'What are the practical implications of the theoretical findings, and how can they be applied to improve neural network designs?']","['The paper assumes a high level of mathematical maturity, which may limit its accessibility.', 'The focus is mainly on CNNs, and the generality to other architectures is not demonstrated.', 'Practical applications and implications of the findings are not fully explored.', 'The paper does not sufficiently address the limitations of the proposed theoretical framework.', 'There is a lack of discussion on the potential negative societal impact of the work.']",False,3,3,3,5,4,"['Novel theoretical insights into the learning dynamics of neural networks.', 'Introduction of learning indices combining spatial and frequency aspects.', 'Rigorous mathematical analysis.', 'Potential to improve the understanding of CNN architectures.']","['Dense and difficult to follow, especially for non-experts.', 'Limited and not sufficiently comprehensive empirical validation.', 'Insufficient comparison with related work.', 'Lack of details on experimental setup and code for reproducibility.', 'Practical implications and impact are not clearly articulated.', 'Theoretical framework is overly complex without intuitive explanations.']",4,3,3,4,Reject
IEKL-OihqX0,"The paper introduces a novel method called Ratio Matching with Gradient-Guided Importance Sampling (RMwGGIS) for learning discrete Energy-Based Models (EBMs). The method leverages the gradient of the energy function to guide importance sampling, aiming to reduce computational and memory inefficiencies associated with traditional ratio matching techniques. The authors provide theoretical backing and empirical results on synthetic data, graph generation, and Ising models to demonstrate the effectiveness of their approach.","['Can the authors provide more detailed ablation studies to isolate the effects of different components of the proposed method?', 'Could the authors elaborate on the theoretical justification for the stochastic optimization benefits observed in their method?', 'Are there any potential negative societal impacts or ethical considerations associated with the use of gradient-based techniques in this context?', 'How does RMwGGIS perform on datasets with dimensions higher than those tested?', 'Can the authors provide more insights into the trade-offs between the biased and unbiased versions of RMwGGIS?', 'What are the potential limitations or failure cases of RMwGGIS in practical applications?', 'Can the authors provide additional empirical validation on larger datasets to further substantiate the scalability claims?', 'How does the proposed method compare to other state-of-the-art methods in terms of practical applicability and ease of implementation?', 'Could the authors clarify some of the dense theoretical sections to make the paper more accessible to a broader audience?', 'Can the authors provide more comprehensive comparisons with other state-of-the-art methods?', 'Could the authors elaborate on the theoretical justifications for the biased version of RMwGGIS performing better than the unbiased version?', 'What are the potential negative societal impacts of this work and how can they be mitigated?', 'Can the authors provide more clarity on the derivation of Eq. (6)?', 'How does RMwGGIS perform on more complex, real-world datasets?', 'What are the limitations in terms of the highest data dimensionality that RMwGGIS can handle efficiently?']","['The paper could benefit from additional theoretical analysis to justify the observed empirical performance improvements.', 'Potential ethical implications of gradient-based techniques are not discussed.', 'The scalability for extremely high-dimensional data needs further exploration.', 'The trade-offs between biased and unbiased versions of RMwGGIS require more discussion.', ""The method's performance on more complex, real-world datasets is not evaluated.""]",False,3,3,3,7,4,"['Addresses a significant computational challenge in learning discrete EBMs.', 'Innovative use of gradient information for importance sampling in discrete data contexts.', 'Comprehensive theoretical backing and detailed derivations.', 'Extensive experimental validation across multiple domains.', 'Significant improvements in efficiency and effectiveness compared to baseline methods.']","['The paper is dense and can be difficult to follow, particularly in the theoretical sections.', 'Some claims about scalability and efficiency could benefit from additional empirical validation on larger datasets.', 'The proposed method introduces additional complexity, potentially limiting its practical applicability.', 'Potential ethical considerations are not thoroughly discussed despite the extensive use of gradient-based techniques.']",4,4,3,3,Accept
ZOcX-eybqoL,The paper proposes a framework for lifelong reinforcement learning (RL) that leverages logical composition to enable an RL agent to determine whether a new task can be solved using existing skills or if a new skill should be learned. The authors provide theoretical results bounding the performance of transferred policies and the number of tasks needed to generalize over a distribution. Experimental validation is provided in several RL domains.,"['Can the authors provide more intuitive explanations for their theoretical results?', 'How does the proposed method compare to other recent advancements in lifelong RL beyond the methods mentioned?', 'Can the authors clarify the practical implications of the theoretical bounds provided?', 'How does the approach handle tasks that are not easily expressible in Boolean logic?', 'How does the framework perform as the complexity and the number of tasks increase?', 'Why were specific baselines chosen for comparison, and how do they justify the superiority of the proposed method?', 'Can the proposed framework be extended to handle tasks with non-binary goal rewards?', 'How does the approach perform in environments with more complex dynamics or larger state spaces?', 'What potential negative societal impacts could arise from the deployment of this framework?', 'Have the authors considered validating the approach in more diverse domains?', 'Can the theoretical bounds be tightened with some assumptions on the task distribution?', 'Can you provide more detailed proofs for the theoretical results?', 'How were the hyperparameters chosen for the experiments?', 'Can you provide more details on the experimental setup and results, especially in the Four Rooms domain?', 'What are the potential negative societal impacts of your work, and how do you plan to mitigate them?']","['The approach assumes binary goal rewards, which may not cover all RL tasks.', 'The experiments are limited to specific domains; broader validation is needed.', 'Potential negative societal impacts are not addressed in the paper.', 'Theoretical results need more detailed proofs and explanations.', 'The experimental setup and results are not thoroughly explained.']",False,3,3,3,5,4,"['Innovative use of logical composition in RL.', 'Theoretical guarantees on performance and generalization.', 'Empirical validation in various RL domains.']","['Limited novelty in extending existing frameworks.', 'Complexity in understanding and implementation.', 'Insufficient discussion on limitations and societal impacts.', 'Experimental results do not convincingly demonstrate significant practical improvements.', 'Certain sections are overly complex and difficult to follow.']",3,3,3,3,Reject
hUr6K4D9f7P,"The paper proposes Weighted Truncated Adversarial Weight Perturbation (WT-AWP) to improve generalization in Graph Neural Networks (GNNs). It identifies and addresses the vanishing-gradient issue in traditional Adversarial Weight Perturbation (AWP) techniques by limiting perturbations to certain layers and introducing a weighted combination with the standard loss. The authors provide theoretical analysis, derive new generalization bounds for non-i.i.d. graph data, and demonstrate improved performance and robustness across various GNNs and tasks.","['Can the authors provide more insights into the choice of hyperparameters λ and ρ? How sensitive are the results to these parameters?', 'Are there any specific applications where WT-AWP might not be suitable or could introduce new challenges?', 'Can the authors discuss the potential negative societal impacts and fairness implications of their method in more detail?', 'How does WT-AWP compare to other regularization techniques outside of AWP, such as dropout or weight decay?', 'Can the authors provide more details on the computational overhead introduced by WT-AWP?']","['The paper does not adequately address the potential negative societal impacts and fairness implications of the proposed method.', 'The complexity of the theoretical derivations may limit the accessibility and reproducibility of the work.', 'The dense and complex nature of the paper may hinder understanding and reproducibility.']",False,3,2,4,7,4,"['Identification and mitigation of the vanishing-gradient issue in AWP.', 'Theoretical contributions including a new generalization bound for GNNs.', 'Extensive empirical validation showing consistent improvements in both natural and robust generalization.', 'Addresses a novel problem specific to GNNs and weight perturbation.']","['The paper is overly dense and could benefit from clearer organization and presentation.', 'The novelty is somewhat incremental, building upon existing AWP techniques with modifications that, while effective, are conceptually straightforward.', 'Lack of detailed discussion on potential negative societal impacts and fairness implications.', 'Limited discussion on the computational overhead introduced by WT-AWP.', 'Some experimental details and hyperparameter choices could be better justified.']",3,3,2,3,Accept
1xXvPrAshao,"The paper introduces MEME, a Mutually supErvised Multimodal VAE, which leverages mutual supervision to model the joint distribution of heterogeneous data. This approach allows learning from partially observed data, outperforming existing methods on standard benchmarks.","['Can the authors provide more clarity on the derivation of the objective, particularly the bidirectional ELBO?', 'How sensitive is the model to the choice of pseudo-samples in the VampPrior?', 'Are there any specific limitations or failure cases of MEME that the authors observed during experimentation?', 'Can you provide more empirical results for cases with more than two modalities?', 'Could you elaborate on the potential negative societal impacts of the proposed method?', 'How does MEME perform on datasets other than MNIST-SVHN and CUB?', 'Could the authors provide more details on the computational complexity and runtime of MEME compared to baseline methods?', 'Can the authors clarify the reasons for choosing Gaussian distributions for comparisons while other baselines use Laplace distributions?', 'Can the authors provide more details on the potential scalability of MEME to more than two modalities?', 'How does MEME perform compared to other state-of-the-art methods not mentioned in the paper?', 'Can you provide more intuitive explanations or diagrams for the mutual supervision mechanism?', 'Do you have any empirical results for scenarios with more than two modalities?', 'How does the performance of MEME compare in terms of computational efficiency?']","['The dependence on the VampPrior and the choice of the number of pseudo-samples could impact performance.', 'Reproducibility might be an issue despite the provided codebase, as the implementation details are complex.', 'The method relies on pseudo-samples, which may increase computational overhead.', 'The results are limited to two datasets, and further validation on more diverse datasets is needed.', 'The paper does not address potential negative societal impacts explicitly.', 'The complexity of the mutual supervision mechanism might hinder its adoption.']",False,3,3,3,7,4,"['Novel approach leveraging mutual supervision for multimodal VAEs.', 'Addresses the challenge of partially observed data effectively.', 'Extensive experimental evaluation demonstrating superiority over baselines.', 'Clear exposition of the method and its benefits.']","['Some theoretical justifications are not entirely clear, particularly the bidirectional ELBO derivation.', 'Reproducibility might be challenging despite the provided codebase due to complex implementation details.', 'Limited empirical results beyond the bi-modal case.', 'Potential scalability issues for more than two modalities.', 'Complex mathematical derivations may be challenging for some readers.']",4,3,3,4,Accept
IhkSFe9YqMy,"The paper proposes an improvement to experience replay in deep reinforcement learning by focusing on key states and recent transitions. The proposed Experience Replay More (ERM) method involves identifying key states where the agent has struggled and prioritizing these states in the replay buffer to enhance learning efficiency. The method is tested on several Mujoco tasks using DDPG, TD3, and SAC algorithms, showing performance improvements.","['How exactly are key states defined and identified during training?', 'Can the authors provide more details on the hyperparameters used, especially for the ERM method?', 'What measures were taken to ensure the robustness and reliability of the experimental results? Are there statistical tests to support the claims?', 'How does ERM differ from Prioritized Experience Replay (PER) in terms of both concept and performance?', 'Can the authors provide confidence intervals or statistical tests to validate the significance of the reported improvements?', 'What are the potential limitations of ERM, and how might it impact the generalizability of the results?']","[""The method's dependency on correctly identifying key states could limit its applicability to different environments."", 'Potential computational overhead in identifying and managing key states and separate buffers.', 'The impact of ERM on long-term policy stability and potential biases introduced by non-uniform sampling.', 'The paper does not adequately discuss the limitations of the ERM approach or its potential negative societal impacts.', 'There is no discussion on how the method scales to more complex environments or different types of tasks.']",False,2,2,2,3,4,"['Novel approach to experience replay prioritization by focusing on key states and recent transitions.', 'Demonstrates improved performance on several challenging Mujoco tasks.', 'Combines well with multiple reinforcement learning algorithms, including DDPG, TD3, and SAC.']","['The definition and identification of key states and their importance are not rigorously justified.', 'The clarity of the paper is lacking; several sections are difficult to follow, and the explanations are not always clear.', 'Experimental results, while promising, need more comprehensive comparisons and statistical validation.', 'Reproducibility of the results is questionable due to insufficient details on hyperparameters and experimental setups.', 'The novelty of ERM compared to existing methods like Prioritized Experience Replay (PER) is not convincingly argued.', 'The paper lacks a detailed discussion of limitations and potential negative societal impacts.']",2,2,2,3,Reject
FpKgG31Z_i9,"The paper introduces a novel meta-algorithm called learning rate grafting, which transfers the implicit step size schedule of a tuned optimizer to a new optimizer, aiming to preserve empirical performance and reduce computational cost. The paper demonstrates the effectiveness of this technique through extensive experiments on state-of-the-art models in vision and language tasks.","['Can you provide more theoretical background and justification for the grafting technique?', 'How do you address the variability in performance due to random initialization in your experiments?', 'Can you discuss the potential ethical implications of the resource-intensive training required for your experiments?', 'How does the performance of grafting vary across different types of neural network architectures and datasets?', 'Can the authors provide more detailed instructions or code to ensure the reproducibility of their experiments?', 'How does the proposed method compare with other state-of-the-art optimization techniques in terms of performance and computational cost?']","['The paper does not adequately address the potential negative societal impact of the resource-intensive training required for the experiments.', 'The theoretical grounding for the proposed method is weak, and more rigorous analysis is needed.', ""The experimental results are limited to certain models and tasks, which may not fully represent the method's effectiveness."", 'The paper lacks a detailed discussion on the limitations and failure modes of the proposed method.', 'The resource-intensive nature of the experiments raises concerns about the environmental impact and accessibility for researchers with limited resources.']",False,2,3,3,5,4,"['Addresses a practical problem in deep learning optimization.', 'Provides a novel technique for transferring learning rate schedules.', 'Demonstrates the effectiveness of the proposed method through extensive experiments.']","['Theoretical grounding for the method is not robust, lacking rigorous analysis.', 'Some experimental results lack detailed statistical analysis and significance testing.', 'Potential ethical implications of resource-intensive training are not adequately discussed.', 'Limited diversity in the experimental setup; more datasets and models should be tested to generalize findings.', 'The presentation of the meta-algorithm and experimental details could be clearer to ensure reproducibility.', 'The paper does not provide sufficient comparisons with other state-of-the-art optimization techniques.']",3,2,3,3,Reject
eo1barn2Xmd,"The paper proposes SLIM-QN, a stochastic quasi-Newton optimizer designed to train large-scale deep neural networks efficiently. SLIM-QN aims to reduce the computational cost and improve the convergence stability of existing second-order methods by using momentum and adaptive damping in Hessian updates. The paper includes theoretical convergence guarantees and empirical evaluations on various datasets and network architectures.","['Can the authors clarify the novelty of SLIM-QN in comparison to closely related methods that already incorporate momentum and damping?', 'Are there any plans to evaluate SLIM-QN on a more diverse set of models and datasets?', 'Can the authors provide more insights or experiments on the practical scalability of SLIM-QN in distributed systems?', 'How does SLIM-QN perform on other domains beyond computer vision, such as natural language processing or reinforcement learning?', 'Can the authors provide more detailed guidelines or code snippets to aid in the reproducibility of SLIM-QN?', 'Could the authors clarify the impact of different hyperparameters on the performance and stability of SLIM-QN?', 'How does SLIM-QN compare with other state-of-the-art optimizers that are not based on second-order methods?', 'Can the authors provide more details on the scalability of SLIM-QN for very large models like BERT or GPT?', 'Are there any practical guidelines for choosing the hyperparameters for SLIM-QN?']","['The paper acknowledges that SLIM-QN has not been extensively tested on very large datasets or models beyond certain benchmarks.', 'Potential negative societal impacts are not explicitly addressed, but the focus on optimization methods suggests minimal direct societal impact.', 'The complexity of the method might pose challenges for implementation and reproducibility.', 'The empirical evaluation is predominantly focused on computer vision tasks, which might limit the perceived applicability of SLIM-QN.', ""The method's performance might be sensitive to hyperparameter choices, which could limit its applicability without extensive tuning."", 'The approach may still be computationally intensive for very large models or datasets.', 'Potential negative societal impacts are not thoroughly discussed, such as the environmental cost of training large models.']",False,3,3,3,6,4,"['Addresses significant issues in second-order optimization methods.', 'Theoretical proofs and comprehensive empirical analyses support the claims.', 'Implementation details and hyperparameters are well-documented, facilitating reproducibility.', 'Incorporates well-established techniques (momentum and damping) to improve stability and efficiency.', 'Provides rigorous theoretical analysis and proofs for convergence guarantees.', 'Empirical results demonstrate significant improvements in convergence speed and computational efficiency.']","['The novelty of SLIM-QN may be incremental as it builds on existing methods with momentum and damping mechanisms.', 'Empirical evaluations are limited to a few datasets and models. More diverse experiments could strengthen the paper.', 'The practical adoption and scalability in distributed systems need further validation.', 'The paper is dense and could be clearer in its presentation.', 'The complexity of the method might pose challenges for reproducibility despite the provided details.', 'Limited discussion on potential limitations and broader impacts, particularly in terms of scalability to extremely large models and datasets.']",3,3,3,3,Reject
dg79moSRqIo,"The paper introduces Discovery of Incremental Skills (DISk), a novel framework for unsupervised skill discovery in reinforcement learning. DISk learns skills incrementally, allowing for better adaptability in non-stationary environments and preventing catastrophic forgetting. The authors demonstrate that DISk outperforms existing methods in both evolving and static environments through various experiments.","['Can the authors provide more details on the computational complexity of DISk compared to existing methods?', 'How does DISk perform in real-world environments with high-dimensional state spaces?', 'Can the authors elaborate on the choice of hyperparameters and their impact on the results?', 'Can the authors provide more detailed explanations and justifications for the choice of independent policies for each skill?', 'How does the computational cost of DISk compare to other state-of-the-art methods?', 'Can the authors provide more insights into the scalability of the approach for more complex environments?', 'How does DISk perform in more diverse and complex environments beyond the ones tested?', 'What are the potential negative societal impacts or ethical considerations of deploying DISk in real-world settings?']","['The method might be computationally expensive due to the need to train independent policies for each skill.', 'Performance on simpler tasks is not as significant as on more complex tasks.', 'The paper does not adequately address the potential computational overhead of maintaining separate neural networks for each skill.', 'Potential negative societal impacts are not discussed in detail.', 'The clarity of the mathematical formulations needs improvement to make the paper more accessible to a broader audience.', ""The reliance on independent policies for each skill may limit the approach's applicability in real-world scenarios.""]",False,3,3,3,6,4,"['Novel approach to skill discovery by learning incrementally.', 'Addresses the issue of catastrophic forgetting in non-stationary environments.', 'Extensive experimental results supporting the claims.', 'Clearly written and well-organized paper.', 'Publicly available code and videos for reproducibility.']","['Some sections could benefit from additional explanations and simplifications.', 'The impact on simpler tasks like HalfCheetah is not as significant as on more complex tasks.', 'The method might be computationally expensive due to the need to train independent policies for each skill.', 'Scalability concerns: Incremental learning with independent neural networks for each skill might not scale well with a large number of skills.', 'Reproducibility: Although the code is provided, the paper lacks sufficient details on hyperparameter tuning and other experimental settings.', 'Limited discussion on the potential negative societal impact and broader implications of the proposed method.']",3,3,3,3,Reject
DrCsriMQ1o,"The paper introduces a novel approach to generating counterfactual explanations using gradient-based methods with tractable probabilistic models, specifically RAT-SPNs. The approach involves a two-step process where an initial unconstrained counterfactual is generated and then adapted to higher density regions. The proposed method aims to overcome limitations of existing methods, such as speed and realism of counterfactuals. Empirical evaluations on datasets like MNIST, German credit dataset, Adult-Income, and Caltech-UCSD Birds demonstrate the advantages of the approach.","['How does the proposed method compare with other state-of-the-art methods not included in the evaluation?', 'Can the authors provide more details on the scalability of the approach to other high-dimensional datasets?', 'What are the potential ethical implications of using this method for generating counterfactuals in sensitive domains?', 'Can the authors provide more theoretical justifications for the chosen hyperparameters?', 'How does the approach perform on other types of datasets, such as time-series or text data?', 'Can the authors provide more quantitative metrics for the realism of counterfactuals beyond visual appeal?']","['The paper does not address the potential negative societal impacts of generating counterfactuals, especially in sensitive areas such as finance and healthcare.', 'There is a lack of discussion on the limitations of the method when applied to different types of datasets or models.', 'The scalability and generalization of the method to different types of datasets are not fully explored.', 'Ethical considerations and the impact of generating counterfactuals on privacy and fairness are not discussed.']",False,3,3,3,6,4,"['Proposes a novel combination of gradient-based methods with tractable probabilistic models.', 'Empirical results show faster computation times and more realistic counterfactuals.', 'The approach is evaluated on a variety of datasets, including complex and high-dimensional ones.']","['The novelty is mainly in the use of RAT-SPNs, and there is limited comparison with state-of-the-art techniques.', ""The paper's clarity could be improved; several sections are dense and contain potential typographical errors."", 'Evaluation is somewhat narrow, lacking broader applicability across different types of datasets.', 'Ethical and societal impacts are not discussed in detail.', 'Limited theoretical justification for the two-step gradient approach.', 'Potential limitations, such as the scalability and generalization of the proposed method, are not fully explored.']",3,3,3,3,Reject
UseMOjWENv,"The paper introduces MIDI-DDSP, a hierarchical model for music synthesis that aims to provide both realistic audio generation and detailed user control. The model is structured into three levels (notes, performance, synthesis) and leverages differentiable digital signal processing (DDSP) to achieve high-fidelity audio synthesis. The approach is validated through quantitative experiments and listening tests, showing its ability to reconstruct high-fidelity audio, predict performance attributes, and generate realistic audio from novel note sequences.","['Can the model be extended to handle polyphonic music?', 'How does the model performance compare to more recent state-of-the-art methods not included in the paper?', ""What additional metrics could be used to evaluate the model's performance comprehensively?"", 'What are the computational requirements for training and inference?', 'How does the model perform with recordings of professional musicians compared to student musicians?', 'What measures have been taken to ensure the diversity and representativeness of the URMP dataset?', 'Can the authors provide more explicit discussion on potential societal impacts and ethical considerations of their work?', 'Is the model capable of real-time performance synthesis?', 'How does the model perform with less common instruments not included in the training set?']","['The model is limited to monophonic instruments, restricting its use in more complex musical pieces.', 'The training process involves multiple stages and hyperparameters, which could be a barrier for replication and practical use.', 'Potential misuse for generating music that could be mistaken for human performance, raising issues about authenticity and copyright.', 'Potential overfitting to the specific characteristics of the URMP dataset.', 'Lack of comprehensive ablation studies to validate the individual contributions of each component.']",False,3,3,3,7,4,"['Novel hierarchical model providing multiple levels of control.', 'Interpretable mid-level expression controls.', 'Extensive evaluation through quantitative experiments and listening tests.', 'Demonstration of realistic audio synthesis for multiple instruments.', 'Open resources including code, audio examples, and a Colab demo.']","['Complex architecture and training process.', 'Training limited to monophonic instrument recordings.', 'Baseline comparisons could be more diverse.', 'Evaluation could benefit from additional metrics.', 'Potential data biases due to the use of a single dataset (URMP).', 'Lack of explicit discussion on societal impacts and ethical considerations.']",4,4,3,4,Accept
kiNEOCSEzt,The paper presents a method to estimate and penalize the shifts in user preferences induced by recommender systems (RS). The authors introduce the notion of 'safe shifts' and propose metrics to evaluate and optimize RSs to avoid manipulative behaviors. They validate their approach using simulated user behavior data.,"['How well does the simulated environment represent real-world user behavior?', 'Can the method be effectively applied to real-world data and users?', 'How sensitive is the method to inaccuracies in the learned user models?', 'How feasible is it to obtain the necessary user interaction data and correct choice model in real-world settings?', ""Can the authors provide more details on how 'safe shifts' can be defined comprehensively?"", 'What are the computational requirements for training the proposed models, and how scalable is the approach?', 'Have the authors considered potential biases introduced by the simulated environment compared to real-world scenarios?', 'How would the proposed methodology handle situations where the user choice model is not available or is inaccurate?', 'How do the authors plan to validate their approach in real-world settings given the reliance on simulated data?']","['The simulated environment may not capture the full complexity of real-world user behavior.', 'The method relies on accurate user choice models, which may not always be available.', 'The approach remains untested on real-world data.', ""The definition of 'safe shifts' is not fully comprehensive and raises ethical questions."", 'Training complex neural network models can be computationally intensive and may require large datasets.', 'The need for extensive and diverse data to capture complex user dynamics.']",False,3,3,3,5,4,"['Addresses a critical issue in recommender systems regarding the influence on user preferences.', ""Introduction of 'safe shifts' provides a novel way to define and measure safe user preference shifts."", 'The use of simulations to validate the proposed method.', 'Technically sound and well-grounded in theoretical concepts.', 'Clearly written and well-organized.']","['The simulated environment may not fully capture the complexity of real-world user behavior.', 'Assumes access to user choice models, which may not always be available or accurate.', ""The method's applicability to real-world data and users remains untested."", ""The definition of 'safe shifts' is not comprehensive and leaves open philosophical and ethical questions."", 'The methodology involves training complex neural network models, which can be computationally intensive.']",3,3,3,3,Reject
gLqnSGXVJ6l,The paper proposes a framework for solving the Vehicle Routing Problem with Time Windows (VRPTW) using neural networks and reinforcement learning. The approach utilizes an attention model to predict near-optimal distributions and optimizes parameters using a stochastic policy gradient in a reinforcement learning environment. The model is evaluated using synthetic data and compared against existing baselines.,"['Can the authors provide more detailed comparisons with additional real-world datasets?', 'How does the model perform against more recent baselines not covered in the paper?', 'What are the potential limitations and negative societal impacts of this approach?', 'Can the authors provide more details on the reinforcement learning setup, specifically the policy gradient and reward mechanism?', 'How does the model perform on larger, more complex instances beyond the synthetic data used?', 'Can the authors clarify the novelty of their approach in relation to existing works?', 'What are the specific hyperparameters used in training and how were they selected?', 'Can the authors elaborate on the computational complexity and scalability of their approach?']","['The paper does not discuss the limitations of the synthetic data used for evaluation.', 'Potential negative societal impacts of the approach, such as job displacement in logistics, are not addressed.', 'The approach may not generalize well to real-world scenarios given the reliance on synthetic data.', 'Computational complexity and scalability for very large instances are not discussed.']",False,2,2,2,3,4,"['Addresses a relevant and challenging problem in combinatorial optimization.', 'Combines neural networks with reinforcement learning, which is a novel approach to solve VRPTW.', 'Provides a detailed explanation of the model architecture and training process.']","['The clarity of the paper is lacking; some sections are densely packed with technical details that are hard to follow.', 'The evaluation is limited to synthetic data and does not include diverse real-world datasets or recent baselines.', 'The paper does not adequately discuss limitations or potential negative societal impacts.', 'Some claims are not well-supported by theoretical analysis or robust experimental results.', 'Limited originality, as it builds heavily on existing works.', 'Incremental contribution by extending existing methods rather than introducing fundamentally new techniques.']",2,2,2,2,Reject
5XmLzdslFNN,"The paper presents a method for compositional lifelong RL using modular neural networks. The proposed approach decomposes complex tasks into reusable subproblems, enabling fast learning and knowledge transfer across tasks. The paper introduces two evaluation domains and shows empirical results demonstrating the efficacy of the proposed method.","['How does the method handle tasks where the decomposition into subproblems is not obvious?', 'Can the approach be adapted to handle dynamic tasks where the task structure changes over time?', 'What are the computational requirements for the proposed method, especially in terms of search complexity for module combinations?', 'Can the authors provide more detailed comparisons with related work in modular and lifelong RL?', 'How sensitive is the method to changes in architectural choices and hyper-parameters?', 'Can the authors test the method on a broader range of RL benchmarks to demonstrate generalizability?', 'How does the proposed method compare to state-of-the-art lifelong RL methods in more diverse and complex domains?', 'Can the authors provide a more thorough theoretical analysis to support the empirical findings?', 'How can the method be scaled to handle a larger number of modules and task combinations efficiently?', 'Can the heuristic search for module combination be replaced with a more scalable approach?', 'What are the potential negative societal impacts of this work?']","['The scalability of the method with respect to the number of modules remains an open question.', 'The reliance on predefined decompositions may limit the applicability to tasks where such decompositions are not clear.', 'Potential negative societal impacts are not thoroughly discussed, especially in terms of deployment in real-world applications.', 'Heavy reliance on architectural and hyper-parameter choices.', 'Incremental improvements may limit broader impact.', 'Potential negative impact on interpretability and transparency of the learned modules.']",False,3,3,3,6,4,"['The modular approach to lifelong RL is a novel and promising direction.', 'The method is well-motivated by the need to handle complex tasks through decomposition.', 'The empirical results demonstrate significant improvements in learning efficiency and knowledge retention.', 'The paper provides comprehensive experiments in both discrete and robotic manipulation tasks.', 'Clear formulation of the compositional RL problem and graph-based formalism.']","['The search for module combinations may not scale well with an increasing number of modules.', 'The method relies on some assumptions about task decomposition that may not hold in all applications.', 'Limited discussion on the generalizability of the method beyond the specific tasks and settings evaluated.', 'Heavy reliance on specific architectural choices and hyper-parameters.', 'The paper could benefit from a more detailed comparison with related work in modular and lifelong RL.', 'The descriptions are sometimes convoluted, hindering readability and understanding.', 'Inadequate discussion of potential societal impacts and ethical considerations.']",3,3,3,4,Reject
fEcbkaHqlur,"The paper introduces a functional regularization method to augment the squared Bellman error in Deep Q-Learning (DQL). This approach aims to address the instability caused by fast-changing target Q-values in traditional target networks, providing a faster and more stable alternative. The authors validate their approach with empirical results on the Four Rooms environment and a subset of Atari games, demonstrating improvements in sample efficiency and performance.","['Can the authors provide more details on how the regularization parameter κ was tuned in different environments?', 'How does the proposed method perform in more complex or real-world environments beyond the Atari suite?', 'Can the authors discuss the computational overhead introduced by the functional regularization compared to traditional target networks?', 'Can the authors provide more detailed theoretical analysis and validation of the proposed FR technique?', 'Can the authors provide more details on the experimental setup, particularly for the Atari games?', 'Can you provide more insights into the potential limitations or downsides of the proposed functional regularization method?', 'Can the authors offer a more intuitive explanation of the functional regularization approach?']","['The paper does not thoroughly discuss the limitations of the proposed approach, such as potential overfitting to specific environments or the computational cost.', 'The potential negative societal impacts of this work, such as its application in potentially harmful domains, are not addressed.']",False,3,3,3,5,4,"['Addresses a well-known problem in DQL, instability due to fast-changing target Q-values.', 'Proposes a novel functional regularization approach, which allows the use of up-to-date parameters and explicit control of regularization.', 'Demonstrates empirical improvements in several environments, including Atari games.', 'Provides a solid theoretical foundation, with detailed explanations and derivations.']","['The clarity and organization of the paper need improvement; some sections are difficult to follow.', 'The novelty of the approach could be questioned as it builds on existing techniques like target networks and weight regularization.', 'The experimental results, although promising, are limited to a small subset of environments and might not generalize to broader applications.', 'Potential limitations and negative societal impacts are not thoroughly discussed.']",3,3,3,3,Reject
RMv-5wMMrE3,"The paper proposes Cell2State, a method for learning low-dimensional state representations from gene-expression transitions using single-cell barcoding data. The approach combines concepts from dynamical systems, kernel machine learning, and low-rank optimization. The method is tested on real and synthetic datasets, showing its utility in predicting cell dynamics and identifying stable cell clusters.","['Can the authors provide more intuitive explanations for the mathematical formulations?', 'How does the method compare with additional baseline methods?', 'What are the potential limitations and ethical considerations of this work?', 'Can the authors provide more comprehensive empirical validation, possibly including additional datasets and comparison with more baseline methods?', 'Can the authors clarify the theoretical analysis, perhaps with more intuitive explanations or supplementary material?']","['The potential limitations are not thoroughly discussed.', 'There is a risk of overfitting due to the high dimensionality of gene-expression data.', 'The paper does not address the scalability of the method to very large datasets.', 'Potential negative societal impacts are not discussed.']",False,3,2,3,5,4,"['Addresses a novel and significant problem in single-cell genomics.', 'Combines multiple advanced techniques innovatively.', 'Promising experimental results on real and synthetic datasets.', 'Theoretical foundation supporting the method.']","['Complex mathematical formulation lacks intuitive explanations.', 'Limited comparison with baseline methods.', 'Insufficient discussion on limitations and ethical considerations.', 'Dense and difficult-to-follow presentation.', 'Limited empirical validation with a narrow scope of experiments.']",4,3,2,3,Reject
DfMqlB0PXjM,"The paper introduces Hierarchical Divnoising (HDN), an unsupervised image denoising and artifact removal method based on hierarchical Variational Autoencoders (VAEs). HDN is designed to be more expressive and interpretable, allowing for the removal of structured noise in microscopy images without supervision. The method achieves state-of-the-art results on twelve benchmark image denoising datasets and demonstrates its effectiveness on three real microscopy datasets.","['Can the authors provide more details on how the proposed method can be generalized to domains outside microscopy?', 'How does the computational efficiency of HDN compare to other state-of-the-art methods in large-scale datasets?', 'Can the authors discuss any potential ethical concerns or negative societal impacts of their work?', 'Can you provide more justification for certain architectural choices, such as the specific number of latent layers and residual blocks?', 'Could you elaborate on the potential challenges in reproducing your results given the complexity of the model?', 'Can the authors clarify the training procedure and hyperparameter selection in more detail?']","[""The method's generalizability to domains outside microscopy is not well-explored."", 'Potential negative societal impacts and ethical concerns are not addressed.', 'Reproducibility of the method might be challenging due to its complexity.', 'Computational overhead and efficiency are not thoroughly discussed.']",True,4,3,4,7,4,"['Proposes a new and more expressive HVAE-based architecture for image denoising.', 'Extensive experimental validation on 12 benchmark datasets and 3 real-world microscopy datasets.', 'Demonstrates state-of-the-art performance in unsupervised denoising and artifact removal.', 'Provides interpretability of the hierarchical latent space, which is leveraged for structured noise removal.', 'The approach does not require paired high and low-quality training data, making it suitable for real-world applications.']","['The originality of using HVAE for image denoising is not entirely novel.', 'The paper is densely written and could benefit from clearer explanations and organization.', 'Ethical concerns and potential negative societal impacts are not well-addressed.', 'The general applicability to domains outside microscopy is less clear.', 'The computational efficiency of HDN is not as high as simpler models, which could be a concern for practical applications.', 'Some architectural choices are not sufficiently justified.', 'The method seems slightly over-engineered, posing potential reproducibility challenges.']",4,4,3,4,Accept
R612wi_C-7w,"The paper presents the Resetting Path Integrator (RPI), a recurrent neural network architecture designed for spatial navigation through path integration by fusing visual and proprioceptive signals. The model introduces direct and inverse environment models, allowing for effective path integration and resetting to prevent error accumulation. Extensive experiments demonstrate the model's superior performance and interpretability compared to LSTM networks.","['Can the authors discuss the potential limitations of the proposed approach?', 'What are the potential negative societal impacts of this work?', 'How does the computational complexity and scalability of the RPI model compare to existing approaches?', 'How well would the model generalize to more complex real-world environments?', 'Can the authors provide more details on the hyperparameter tuning process for both RPI and LSTM networks?', 'How does the RPI perform in more complex and realistic 3D environments?', 'What are the potential limitations of the proposed approach in real-world applications?', 'How does the model handle scenarios with different types of noise in the proprioceptive and visual signals?', 'Can the authors clarify the mathematical formulation and provide more details on the experimental setup?', 'Can the authors provide more rigorous evaluation metrics and comparisons to validate the robustness of the RPI model?', 'Are there any potential limitations or edge cases where the RPI model may not perform well?', 'How does the RPI model generalize to different types of environments or more complex spatial navigation tasks?', 'Can the authors provide more detailed analyses on the robustness of RPI against different types of noise and perturbations?']","['The paper lacks a thorough discussion of potential limitations and negative societal impacts.', 'Experiments are limited to simplified 2D environments, which may not fully generalize to more complex real-world scenarios.', 'No detailed analysis of computational complexity and scalability compared to existing approaches.', 'Potential negative societal impacts, such as misuse in surveillance or autonomous weaponry, are not discussed.']",False,3,3,3,6,4,"['Novel approach combining direct and inverse environment models for path integration.', 'Extensive experimental evaluation with superior performance compared to LSTM networks.', 'Addresses a significant problem in spatial navigation and cognitive map formation.', 'The model offers more interpretable internal states.']","['Lacks discussion of potential limitations and negative societal impacts.', 'Experiments are limited to simplified 2D environments, which may not fully generalize to more complex real-world scenarios.', 'Does not provide a detailed analysis of computational complexity and scalability.', 'The paper is densely written and difficult to follow in parts.', 'Experimental evaluation lacks rigor and variety in testing different architectures.']",3,3,3,3,Reject
Zq2G_VTV53T,"The paper introduces FastSHAP, a method for real-time Shapley value estimation using a learned explainer model. The method leverages a weighted least squares objective function for efficient training, bypassing the need for a large ground truth Shapley value dataset. Experiments demonstrate that FastSHAP offers significant speed improvements over existing methods while maintaining accuracy in both tabular and image datasets.","['Can the authors provide more detailed experimental validation of the strategies to reduce gradient variance?', 'How does FastSHAP compare to non-Shapley-based explanation methods in terms of accuracy and computational efficiency?', 'What are the limitations of the optimization process in practice, and how do they affect the performance of FastSHAP?', 'Can additional metrics or user studies be provided to validate the quality of image explanations?', 'Can the authors provide more details on the efficiency regularization technique and its impact on the performance of FastSHAP?', ""How does FastSHAP perform under different training data sizes, and is there a threshold below which the method's accuracy significantly degrades?"", 'Can the authors discuss potential limitations and negative societal impacts of using FastSHAP in various applications?', 'Can the authors provide more details on the hyperparameters used for the tabular and image datasets?', 'How does FastSHAP perform on larger, more complex datasets beyond those tested?', 'What are the potential limitations and negative societal impacts of FastSHAP?', 'How does FastSHAP compare with other recent methods in terms of robustness to different model architectures?', ""Are there any specific scenarios or datasets where FastSHAP's performance significantly deteriorates?"", 'Could the authors provide more intuitive explanations or pseudocode to enhance clarity?', 'Can the authors provide more detailed pseudo-code or algorithmic steps for the implementation of FastSHAP?', 'How does FastSHAP perform in terms of scalability for extremely large datasets or models?', 'What are the possible misuses or negative societal impacts of FastSHAP, and how can these be mitigated?']","['The paper does not adequately discuss the limitations of the optimization process in practical scenarios.', 'Potential negative societal impacts, such as the misuse of model explanations, are not addressed.', 'The method may not generalize well to all types of data, particularly more complex, high-dimensional datasets.', 'The efficiency gains might come at the cost of some accuracy, which could be critical in certain applications.', 'Potential biases introduced by the learned explainer model need more discussion.', 'The impact of hyperparameters on the final performance should be explored in more detail.', 'The explanation of the mathematical derivations could be simplified or supplemented with more intuitive descriptions.']",False,3,3,3,6,4,"['The concept of using a learned model to estimate Shapley values in a single forward pass is innovative.', 'Significant speed improvements over traditional Shapley value calculation methods are demonstrated.', 'The approach is model-agnostic and can be applied to different types of data, including tabular and image datasets.', 'Comprehensive experiments comparing FastSHAP with various baseline methods on multiple datasets.', 'The authors provide code and detailed descriptions of experiments, enhancing reproducibility.']","['The practical aspects and limitations of the optimization process are not thoroughly discussed.', 'The strategies to reduce gradient variance could benefit from more detailed experimental validation.', 'The paper could include a broader comparison with other state-of-the-art explanation methods beyond Shapley-based approaches.', 'The qualitative evaluation of image explanations is somewhat subjective, and additional metrics or user studies could strengthen the claims.', 'The paper does not discuss potential negative societal impacts, such as the misuse of model explanations.']",3,3,3,4,Accept
VyZRObZ19kt,"The paper proposes a mathematically-grounded framework for dynamically adjusting the ϵ parameter in learned indexes to better accommodate varying data characteristics across different localities. The framework, termed ϵ-learner, leverages theoretical bounds to optimize the space-error trade-off, leading to improved index performance. Extensive experiments on multiple datasets validate the effectiveness and efficiency of the proposed method.","['Can you provide more details on the computational overhead introduced by the ϵ-learner module? How does it scale with larger datasets?', 'How would the proposed framework integrate with existing database systems? Are there any specific requirements or modifications needed?', 'Can you elaborate on the potential limitations of the framework, especially in scenarios with highly dynamic or unpredictable data distributions?']","['The authors have not deeply explored the potential limitations in highly dynamic or unpredictable data distributions.', 'There is a lack of detailed discussion regarding the integration with existing database systems and the computational overhead introduced by the dynamic adjustment mechanism.']",False,4,3,4,8,4,"['Innovative approach to dynamically adjust the ϵ parameter in learned indexes.', 'Strong theoretical foundation with detailed proofs and bounds.', 'Extensive experimental validation on multiple datasets showing significant improvements over state-of-the-art methods.', 'Ablation studies and case studies provide deeper insights into the working and benefits of the proposed framework.']","['The paper is dense and some mathematical derivations could be made more accessible.', 'Limited discussion on the computational complexity and potential overheads introduced by the dynamic adjustment mechanism.', 'Implementation details, especially regarding the integration with existing systems, could be more thoroughly discussed.']",4,4,3,4,Accept
ZDYhm_o8MX,"The paper introduces Neural Manifold Clustering and Embedding (NMCE), a method for clustering data points based on manifold structures and learning to parameterize each manifold as a linear subspace in a feature space. The approach combines data augmentation with Maximum Coding Rate Reduction (MCR²) to achieve state-of-the-art performance on several benchmarks, including CIFAR-10 and CIFAR-20. The paper also explores the relationship between NMCE and self-supervised learning methods.","['Can the authors provide more theoretical justification for the effectiveness of the proposed data augmentation strategy?', 'How sensitive is the performance of NMCE to the choice of data augmentation techniques?', 'Can the authors include more ablation studies to isolate the contributions of different components of NMCE?', 'Are there any specific limitations or potential negative societal impacts associated with NMCE that the authors have not discussed?', 'Can the authors provide more intuitive explanations or visual aids to help readers better understand the core concepts and methodology?', 'How does the method perform on non-image datasets or real-world applications beyond the provided benchmarks?', 'What are the computational requirements for training NMCE on large-scale datasets?', 'Could the authors elaborate on the choice of evaluation metrics and provide a rationale for their selection?']","['The paper should include a more detailed discussion on the limitations of NMCE, such as its sensitivity to data augmentation techniques and computational complexity.', 'Potential negative societal impacts, such as biases in clustering results based on the training data, should be addressed.', 'Scalability: The proposed method may have scalability issues due to the computational complexity of the MCR² objective, especially for large datasets.', 'Generalization: The paper does not fully address how well the method generalizes to different types of data, particularly beyond image datasets.', 'The multistage training procedure may be resource-intensive, which could limit practical applicability.', 'The method relies heavily on data augmentation, which may not be applicable or effective in all scenarios.']",False,2,2,3,4,4,"['Combines data augmentation with MCR² to develop a novel manifold clustering method.', 'Achieves state-of-the-art performance on several benchmarks.', 'Shows significant improvement over existing methods on high-dimensional image datasets.', 'Provides a meaningful and interpretable feature space.', 'Theoretical foundation for the necessity of geometric constraints in neural manifold clustering.']","['Insufficient theoretical backing for some claims, particularly the effectiveness of the proposed data augmentation strategy.', 'Lack of clarity in the methodology, making it difficult for readers to reproduce results.', 'Experimental results lack comprehensive ablation studies and comparisons with more baseline methods.', 'The paper could benefit from a more detailed discussion on the limitations and potential negative societal impacts.', 'Some parts of the paper are overly complex and difficult to follow.', 'The multistage training procedure might be cumbersome and resource-intensive.', 'Reproducibility is a concern due to lack of comprehensive details on experimental setup and hyperparameters.']",3,2,2,3,Reject
ziRLU3Y2PN_,The paper introduces a new family of texture synthesis models based on wavelet transforms and a generalized rectifier non-linearity. It aims to combine the interpretability of wavelet-based models with the high-quality synthesis capabilities of CNN-based models. The proposed model significantly improves the visual quality of classical wavelet-based models and is competitive with state-of-the-art CNN-based models.,"['Can you provide more quantitative metrics to evaluate the quality of the synthesized textures?', 'How does the choice of wavelet family specifically impact the results?', 'Can you elaborate on how you address memorization effects in more detail?', 'How does the proposed model perform on textures with more complex geometric structures compared to the examples provided?', 'Can the approach be extended or adapted for applications beyond texture synthesis, such as image denoising or super-resolution?']","['The potential for memorization effects in non-stationary images.', 'Limited exploration of different wavelet families and their impact.', 'The evaluation relies heavily on visual inspection, which can be subjective.', ""Potential overfitting and memorization effects could limit the method's generalizability."", 'Computational efficiency and scalability are not addressed, which could be a concern for practical applications.']",False,3,2,3,6,4,"['Combines the strengths of wavelet-based and CNN-based models.', 'Significantly improves visual quality over classical wavelet models.', 'Provides insights into the trade-offs between quality and diversity.', 'Extensive comparisons with state-of-the-art models.', 'Code is made publicly available for reproducibility.']","['The paper is dense and difficult to follow in some sections.', 'The evaluation could be more thorough, especially in terms of quantitative metrics.', 'Potential memorization effects are not fully addressed.', 'The impact of different wavelet families and parameters could be explored in more detail.', 'The novelty of combining wavelets with CNN-like structures is somewhat limited.', 'Details on experimental settings and parameters are not comprehensively provided.', 'Focuses primarily on texture synthesis with limited exploration of applications in other domains.', 'Potential overfitting and memorization issues are not thoroughly addressed.', 'Limited discussion on computational efficiency and scalability of the proposed method.', 'The paper lacks a comprehensive comparison with a broader range of existing methods.']",3,3,2,3,Reject
Czsdv-S4-w9,"The paper introduces DIGAN, a novel generative adversarial network for video generation that utilizes implicit neural representations (INRs) to model videos as continuous signals. This approach aims to improve the scalability and quality of generated videos by reducing computational complexity and better capturing temporal dynamics. The authors demonstrate the effectiveness of DIGAN through extensive experiments, showing significant improvements over state-of-the-art methods in various benchmarks.","['Can you provide more details on the potential ethical concerns and how they might be mitigated?', 'What are the specific limitations of DIGAN in terms of scalability and applicability to different types of video data?', 'How does the method perform on real-world, large-scale video datasets beyond the ones tested?', 'Could the authors provide more details on how the temporal dynamics are incorporated into the motion features?', 'How does DIGAN compare with the latest autoregressive models and Transformers in video generation?', 'Can the authors clarify how DIGAN would perform on more diverse and less controlled datasets?', 'How does DIGAN handle potential artifacts or inconsistencies in real-world video data?', 'Can the authors provide more empirical evidence supporting the claimed efficiency and scalability benefits?', 'How does the discriminator handle very long sequences, and what are its limitations?']","['The paper acknowledges the potential misuse of generated videos for unethical purposes but does not provide concrete measures to address this issue.', 'The complexity of the method might limit its reproducibility and wider adoption in the research community.', 'Limited evaluation on diverse datasets.', 'Potential overfitting issues are not thoroughly discussed.']",True,3,3,3,6,4,"['Innovative application of implicit neural representations (INRs) for video generation.', 'Significant improvement in benchmarks such as FVD on UCF-101 and other datasets.', 'Comprehensive experiments demonstrating various capabilities like long video synthesis, time interpolation, and non-autoregressive generation.']","['The complexity of the method might hinder reproducibility and wider adoption.', 'Potential ethical concerns related to generating fake videos are not thoroughly addressed.', 'Limited discussion on the limitations and potential negative societal impacts of the work.', 'Clarity issues in some sections, especially in technical explanations.', 'Evaluation dependent on specific datasets, might not generalize well.', 'Insufficient comparative analysis with concurrent works like StyleGAN-V.']",4,3,3,3,Reject
18Ys0-PzyPI,"The paper introduces ODITS, a reinforcement learning framework designed for ad hoc teamwork under partial observability. ODITS learns latent variables to represent teamwork situations and dynamically adapts to new teammates. Extensive experiments show that ODITS outperforms several baselines in different ad hoc teamwork environments.","['How does ODITS scale with increasing team sizes and more complex environments?', 'Can the authors provide more detailed explanations or examples for the mutual information loss function derivation?', 'What are the computational requirements for training and evaluating ODITS in the provided experiments?', 'Can the authors provide more detailed analysis on the influence of policy set diversity on the performance of ODITS?', 'Can the authors provide more detailed explanations of the proxy encoder and decoder mechanisms?', 'How does ODITS perform in environments with significantly larger team sizes?', 'Can the authors discuss the impact of different hyperparameters on the performance of ODITS?', 'How is the diversity of the training policies ensured and quantified?', 'Could you provide more details on the hyperparameter tuning process?', 'Can the authors provide more clarity on how their approach significantly differs from existing methods using latent variables?', ""Can the authors provide more details on the experimental setup, particularly on how the teammates' policies were trained and selected?"", 'What are the potential limitations and negative societal impacts of the proposed method?']","['The scalability of ODITS to larger team sizes and more complex environments needs further exploration.', 'The diversity and representativeness of the training policy sets significantly influence performance, which is not fully characterized.', 'Potential negative societal impacts are not discussed.']",False,3,3,3,6,4,"['Addresses a significant problem in ad hoc teamwork.', 'Proposes a novel method to learn and adapt to new teammates dynamically.', 'Extensive experimental validation showing superior performance.', 'Well-organized and comprehensive coverage of related work.']","['Scalability to larger and more complex environments is unclear.', 'Some mathematical derivations, particularly the mutual information loss function, lack clarity.', 'Potentially high computational requirements.', 'The paper is dense and could benefit from clearer explanations and more illustrative figures.', 'Limited diversity in experimental tasks to fully establish the robustness of the proposed method.', 'Theoretical justifications could be more thoroughly elaborated.', 'The novelty of the approach is not entirely clear compared to existing methods.', 'The technical soundness is questionable in some areas, with complex and unclear mathematical derivations.', 'The discussion on limitations and potential negative societal impacts is inadequate.']",3,3,3,3,Accept
0DcZxeWfOPt,"The paper introduces Model Editor Networks with Gradient Decomposition (MEND), a method for fast and efficient post-hoc editing of large pre-trained models. MEND uses small auxiliary networks to transform gradients obtained from fine-tuning, allowing for targeted edits without overfitting. The method is validated on several large language models, showing superior performance compared to existing approaches.","['How does MEND perform on models with more than 100 billion parameters?', 'What are the limitations of the low-rank gradient assumption in different model architectures?', 'Can the authors provide more details on the potential misuse of MEND and how it can be mitigated?', 'Can the authors provide more discussion on the potential limitations of using low-rank gradient decomposition?', 'Could the authors elaborate on the potential negative societal impacts of this method and how they might be mitigated?', 'How does MEND perform on architectures other than transformers?', 'Can the authors provide more details on the initialization and normalization techniques used for MEND?', 'How does MEND compare to other methods on a wider range of tasks and benchmarks?', 'Can the authors elaborate on potential failure cases and how they might be mitigated?', 'Can you provide more detailed theoretical analysis?', 'How were the examples chosen for the empirical results?', 'Can you elaborate on potential negative societal impacts?', 'Could you provide more details on the reproducibility of the experiments?', 'Can the authors provide more details on potential failure cases and limitations in real-world scenarios?', 'How does MEND handle different types of edits, such as reducing toxic outputs or altering control policies in robotics?', 'Can the authors elaborate on the ethical considerations and potential misuse of model editing techniques?', 'What are the specific challenges faced when scaling MEND to models with over 100 billion parameters?']","['The scalability to extremely large models is not empirically validated.', 'The reliance on low-rank gradient structures may limit the generalizability of the method.', 'The potential for misuse is a significant concern that needs to be addressed in more detail.', 'Potential for over-generalization in edits.', 'Brief treatment of negative societal impacts.', 'Empirical results might be cherry-picked.', 'The paper could benefit from a deeper discussion on the limitations and potential negative societal impacts of model editing.', 'Failure cases and practical challenges in deployment are not thoroughly addressed.']",True,3,3,3,7,4,"['Addresses a significant problem in maintaining and updating large pre-trained models.', 'Comprehensive experiments demonstrate the effectiveness of MEND across various models and tasks.', 'The paper is well-organized and clearly written, making it easy to follow the proposed approach.', 'The approach is computationally efficient, making it feasible for very large models.', 'Novel method for scalable and efficient model editing.', 'Strong empirical results demonstrating effectiveness on large models.', 'Potentially high impact for maintaining and updating large pre-trained models.']","['The scalability to models with hundreds of billions of parameters is claimed but not empirically validated.', 'The approach relies heavily on the assumption that gradients have low-rank structures, which might not hold for all model architectures and tasks.', 'There is a potential risk of misuse, as the method could be used to introduce backdoors or other malicious behaviors into models.', 'Lacks detailed theoretical analysis.', 'Some empirical results may be cherry-picked.', 'Brief discussion on potential negative societal impacts.', 'Reproducibility section could include more specifics.']",3,3,3,3,Accept
mF5tmqUfdsw,"The paper proposes the Zeroth-Order Actor-Critic (ZOAC) algorithm, which combines zeroth-order optimization methods with first-order policy gradient methods within an actor-critic framework. The proposed method aims to leverage the robustness and exploration capabilities of zeroth-order methods while maintaining the sample efficiency of first-order methods. The authors evaluate ZOAC on several continuous control benchmarks, demonstrating its advantages over baseline algorithms in terms of sample efficiency, final performance, and robustness.","['Can the authors provide more detailed derivations for the proposed gradient estimators?', 'How does ZOAC compare to other recent hybrid methods combining zeroth-order and first-order techniques?', 'What are the potential limitations of ZOAC in terms of scalability and applicability to different types of RL problems?', 'Can you provide more details about the choice of hyperparameters and their impact on the results?', 'How does ZOAC perform in discrete action spaces or environments with sparse rewards?', 'Can the authors provide more practical examples where ZOAC significantly outperforms existing methods?', 'How does the complexity of ZOAC affect its scalability and deployment in real-world applications?', 'Could the authors provide a clearer explanation or visualization to help readers understand the core concepts and methodology?', 'Can the authors provide more intuitive explanations of the theoretical derivations?', 'How robust are the improvements observed in the experiments across different problem settings and hyperparameter configurations?', 'Can the authors clarify the potential limitations and negative societal impacts of their work?']","['The paper does not thoroughly address the limitations of the proposed method, such as its scalability to high-dimensional problems or the potential impact of the choice of hyperparameters.', 'There is no discussion of the potential negative societal impacts of deploying ZOAC in real-world applications.', 'The paper does not fully address the potential challenges in scaling and deploying ZOAC in real-world applications.', 'Additional clarity is required to make the paper accessible to a broader audience.']",False,3,2,3,5,4,"['Interesting combination of zeroth-order and first-order methods in RL.', 'Thorough experimental evaluation across multiple benchmarks.', 'Demonstrates improved performance and robustness compared to baseline algorithms.', 'Theoretical derivations supporting the proposed approach.', 'Detailed analysis of variance reduction and robustness.', 'Ablation studies demonstrating the importance of different components.']","['Clarity issues in the methodology and derivations.', 'Limited novelty compared to existing hybrid approaches.', 'Insufficient discussion of potential limitations and negative societal impacts.', 'Lack of thorough comparison with other state-of-the-art hybrid methods.', 'Experimental results could be more extensive and cover a wider range of environments.', 'The paper is dense and some sections could benefit from clearer explanations.', 'Reproducibility is partially dependent on the release of the code, which is not yet available.', 'Complexity of the proposed method might hinder reproducibility.', 'Practical impact and broader applicability are not fully demonstrated.']",3,3,2,3,Reject
4l5iO9eoh3f,"The paper presents a supervised learning framework for solving the Capacitated Vehicle Routing Problem (CVRP) with a fixed fleet size. The approach constructs complete tour plans from scratch, leveraging a permutation invariant model. The authors claim that their method is faster to train and achieves competitive results compared to state-of-the-art reinforcement learning (RL) approaches, particularly when considering fixed vehicle costs.","['Can the authors provide more details on the training and evaluation datasets used?', 'How does the proposed method perform on larger problem instances beyond 100 customers?', 'Can the authors discuss any potential limitations or negative societal impacts of their approach?', 'How well does the model generalize to real-world data as opposed to generated datasets?', 'What are the specific computational limitations when scaling to larger problem sizes?', 'Can the authors provide more details on the potential negative societal impacts of their work?', 'Can the authors provide more details on the generalization capabilities of the proposed model to other problem sizes?', 'How does the proposed method compare to other supervised learning methods not mentioned in the paper?', 'Can the authors clarify the specific contributions of the proposed model compared to the original Permutation Invariant Pooling Network?', 'Can you provide more detailed explanations or visualizations for the methodology, especially the decoding procedure?', 'How does the method perform without the post-processing steps? Are the results significantly different?', 'Can you elaborate more on the potential negative societal impacts or limitations of your approach?', 'Can the authors provide more details on the training time comparison and computational resources used?', 'How does the model perform on larger, real-world datasets?', 'What are the main limitations of the proposed approach in practical applications?']","['The paper does not discuss potential limitations such as scalability to larger problem instances.', 'The impact of fixed fleet size constraints on solution quality is not thoroughly analyzed.', 'Potential negative societal impacts such as job displacement in logistics sectors are not addressed.', ""The model's scalability to larger problem sizes is a limitation that needs to be addressed."", 'The reliance on generated datasets may limit the applicability of the findings to real-world scenarios.', 'The potential negative societal impacts of optimizing vehicle routing in logistics, such as job displacement or increased environmental impact, are not discussed.', 'The model may not generalize well to other problem sizes or distributions not seen during training.', 'Potential negative societal impact includes job displacement in logistics due to automation.']",False,3,2,3,5,4,"['Addresses a practical and important problem in logistics.', 'Proposes a novel supervised learning framework for the CVRP with a bounded fleet size.', 'The method is faster to train compared to RL-based methods.', 'Achieves competitive results in terms of cost and fleet size utilization.', 'Comprehensive experimental evaluation comparing the method against state-of-the-art RL approaches.', 'Incorporates vehicle costs into the evaluation, which is a realistic consideration.']","[""The paper's clarity and organization could be improved, especially in the methodological sections."", 'Evaluations and comparisons with state-of-the-art methods are somewhat limited and lack sufficient detail.', 'Does not adequately address potential limitations and negative societal impacts.', 'Scalability to larger problem instances is questionable.', 'Relies on generated datasets and near-optimal target instances, which may not reflect real-world scenarios.', 'Some sections are dense and could benefit from further clarification.', 'Heavily builds upon existing architectures with relatively minor modifications.', 'Some claims, particularly regarding the effectiveness of post-processing and generalizability, need further validation.', 'Experimental results are not fully convincing; improvements over baselines are marginal in some cases.', 'No significant theoretical contributions or novel algorithms introduced.']",3,3,2,3,Reject
dEOeQgQTyvt,"The paper introduces SEAL, a framework that uses structured energy networks (SEN) as dynamic loss functions for training feedforward networks in multi-label classification tasks. SEAL adapts the energy function dynamically to better guide the feedforward network during training. The framework is tested with different types of energy losses across various datasets, showing superior performance over traditional methods. The authors also propose a variant using noise contrastive ranking (NCE) loss, which demonstrates the best performance among the studied variants.","['Can the authors provide more details on the dynamic adjustment mechanism for the energy function?', 'How does SEAL perform in other structured prediction tasks beyond multi-label classification?', 'What are the limitations of using structured energy networks as dynamic loss functions?', 'Can the authors provide more insights into the potential societal impacts of this work?', 'Can the authors provide more detailed explanations of the model architecture and training procedure?', 'What are the specific hyperparameters used in the experiments?', 'How do the authors address the potential overfitting issue with SEAL?', 'Can the authors provide more clarity on the training process and hyperparameter tuning?', 'What measures were taken to ensure that the improvements were not due to overfitting, especially on genbase?', 'Can the authors provide a clearer explanation or a diagram to better illustrate the dynamic loss calculation process in SEAL?', 'What are the potential limitations of SEAL in terms of scalability and generalization to other tasks beyond multi-label classification?', 'Could the authors discuss any potential negative societal impacts or ethical considerations associated with the use of SEAL?']","['The paper should discuss the limitations of using structured energy networks in dynamic settings.', 'Potential negative societal impacts, such as biases introduced by the model, are not addressed.', 'The high number of parameters may lead to overfitting.', ""The framework's complexity may hinder its adoption in practical applications."", 'Lack of discussion on the potential negative societal impacts or ethical concerns.', 'There is no mention of the scalability of SEAL to larger datasets or more complex tasks.']",False,3,2,3,4,4,"['Novel use of structured energy networks as dynamic loss functions.', 'Comprehensive empirical evaluation across multiple datasets.', 'Demonstrates superior performance over traditional methods.', 'Flexibility in using various types of energy losses.']","['Clarity issues in the mathematical derivations and algorithmic steps.', 'Insufficient discussion on the limitations and potential societal impacts.', 'The description of the dynamic adjustment mechanism for the energy function lacks detail.', 'Reproducibility concerns due to the complexity of the proposed method.', 'Potential overfitting to specific datasets, particularly genbase.', 'Lack of rigorous statistical analysis to support claims.']",3,3,2,3,Reject
4Ycr8oeCoIh,"The paper investigates the process of finetuning pretrained GANs, focusing on the roles of pretrained generators and discriminators. It provides practical guidelines for selecting suitable GAN checkpoints and validates its findings through extensive experiments with the StyleGAN2 architecture.","['Can the findings be generalized to other GAN architectures beyond StyleGAN2?', 'Is there a theoretical framework that supports the empirical observations made in the paper?', 'What are the potential negative societal impacts of improved GAN finetuning, and how can they be mitigated?', 'How does the proposed method for selecting pretrained checkpoints compare to simpler heuristics or existing methods in terms of computational efficiency and effectiveness?', 'Can the authors provide more empirical results on other GAN architectures to generalize the findings beyond StyleGAN2?', 'What are the implications of these findings for real-world applications of GANs in terms of performance and resource usage?', 'Can the authors provide more theoretical insights into the mechanisms of GAN finetuning?', 'How do the proposed methods compare with other recent approaches in GAN finetuning in terms of performance and computational cost?', 'Are there any specific limitations or failure cases observed in the experimental validation?', 'Can the authors provide more rigorous proof for the claims made in the synthetic data experiments?', 'How do the authors justify the assumptions made in the synthetic experiments?', 'Could the authors provide more intuitive explanations for the complex parts of the paper?']","['The study focuses on StyleGAN2, which may limit the generalizability of the findings to other GAN architectures.', 'The paper lacks a rigorous theoretical framework to support some of its empirical findings.', 'Potential negative societal impacts of improved GAN finetuning are not adequately discussed.', 'The paper does not sufficiently address the computational cost and practical feasibility of the proposed method for selecting pretrained checkpoints.', 'The paper primarily relies on correlations rather than proving causality.']",False,3,3,3,6,4,"['Comprehensive analysis of GAN finetuning mechanisms.', 'Clear explanation of the roles of pretrained generators and discriminators.', 'Practical guidelines for selecting pretrained GAN checkpoints.', 'Extensive experimental validation across multiple datasets.', 'Availability of code and pretrained models for reproducibility.']","['Lack of rigorous theoretical backing for some claims, relying heavily on empirical evidence.', 'The focus on only one specific GAN architecture (StyleGAN2) may limit the generalizability of the findings.', 'The clarity of the paper suffers due to dense technical jargon and insufficient explanation of key concepts.', 'Some experimental results and claims are not convincingly supported by statistical rigor or comprehensive baselines.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",3,3,3,3,Accept
O5Wr-xX0U2y,"The paper proposes a novel deep reinforcement learning algorithm for risk-averse dynamic decision-making problems, with a focus on equal-risk pricing and hedging of financial derivatives. The algorithm extends the deep deterministic policy gradient (DDPG) method to use dynamic expectile risk measures, aiming to produce time-consistent hedging strategies.","['Can you provide detailed proofs or theoretical guarantees for the convergence and optimality of the proposed algorithm?', 'How does the proposed method perform on real-world financial data compared to synthetic data?', 'Can you provide insights into the choice of hyperparameters and their sensitivity?', 'How does the proposed method compare to other state-of-the-art risk-averse RL methods in different domains?', 'Can you provide more intuitive explanations of the methodology?', 'What are the limitations and potential negative societal impacts of this approach?']","['Reliance on synthetic data may limit generalizability to real-world scenarios.', 'Does not address computational complexity and scalability for larger datasets or more complex financial instruments.', 'Potential negative societal impacts related to financial risk management, such as systemic risk, are not discussed.']",False,2,2,2,4,4,"['Addresses a significant problem in financial risk management with practical relevance.', 'Introduces a novel extension of the DDPG algorithm to a risk-averse setting using dynamic expectile risk measures.', 'Experimental results indicate that the proposed algorithm outperforms existing methods using static risk measures in producing time-consistent hedging strategies.']","['Lacks rigorous theoretical proofs for convergence and optimality.', 'Relies heavily on synthetic data, which may not capture real-world complexities.', 'Clarity issues in the mathematical formulation and algorithmic steps.', 'Insufficient comparative analysis with existing methods.', 'Lacks validation on real-world data.', 'Inadequate discussion on limitations and potential negative societal impacts.']",3,2,2,3,Reject
tFgdrQbbaa,"The paper provides a theoretical analysis of generalization performance in continual learning using the Neural Tangent Kernel (NTK) regime. It introduces concepts such as self-knowledge transfer and forgetting, and validates theoretical findings through empirical experiments on synthetic data and practical deep learning models.","['Can the authors provide more practical experimental settings beyond NTK regime?', 'How do the theoretical findings apply to real-world continual learning scenarios?', 'Can the paper address potential negative societal impacts or ethical concerns?', 'Can the authors provide more clarity on the assumptions made in their theoretical analysis?', 'How does the proposed analysis compare to other state-of-the-art methods in terms of practical applicability?', 'Can the authors discuss the potential limitations and negative societal impacts of their work in more detail?', 'Can the empirical validation be extended to more diverse datasets and architectures to strengthen the claims?', 'How would the findings change when applying the theoretical insights to non-NTK regimes or more complex neural architectures?', 'Are there specific strategies or modifications to current continual learning algorithms that could mitigate the identified negative transfer and forgetting phenomena?', 'Could the authors elaborate on potential limitations when applying their findings to architectures beyond those empirically tested?', 'Can the authors provide more detailed explanations of the mathematical derivations?', 'How do the results compare with existing methods in continual learning?', 'Can the authors include more comprehensive empirical evaluations using real-world datasets?']","['The paper does not explore practical settings extensively beyond NTK regime.', 'Potential negative societal impacts or ethical concerns are not discussed.', 'The complexity of the mathematical formulations might limit the accessibility of the paper.', 'Empirical validations are primarily focused on specific settings, which might not generalize well to all practical scenarios.', 'The NTK regime, while useful for theoretical insights, may not capture the full complexity of modern deep learning architectures.']",False,3,2,3,6,4,"['Rigorous theoretical approach using statistical mechanical analysis.', 'Novel insights into positive/negative transfer and self-knowledge transfer/forgetting.', 'Empirical results supporting theoretical claims.']","['Complex mathematical notations reduce clarity for a broader audience.', 'Limited experimental validation beyond NTK regime.', 'Inadequate discussion on potential negative societal impacts or ethical concerns.', 'The clarity of presentation is lacking in some sections, making it difficult to follow.', 'The novelty of the contributions is somewhat incremental as it builds on existing NTK formulations.', 'NTK regime may not fully capture the complexities of modern deep learning architectures in practical settings.']",3,3,2,3,Reject
JYQYysrNT3M,"The paper introduces the Online-ReOpt algorithm for reinforcement learning with vectorial rewards, focusing on ex-post max-min fairness. Theoretical guarantees and experimental validations are provided to demonstrate the efficacy of the proposed method.","['Can the authors provide more details on the optimization oracle and its practical implementation?', 'How does the proposed method generalize to other types of environments beyond the queuing network?', 'Can the authors discuss the computational complexity of the Online-ReOpt and Offline-ReOpt algorithms in more detail?', 'Are there specific related works that the authors did not discuss which might be relevant to this study?', 'Can the authors clarify the key differences between the proposed algorithm and existing ex-ante fairness algorithms?', 'How does the proposed method compare with more contemporary RL methods in terms of computational efficiency?', 'What are the potential limitations of the proposed approach in larger and more complex environments?', 'Could the authors provide more details on how the optimization oracle is implemented in practice?', 'How generalizable are the experimental results to other domains beyond the queuing network scenario?', 'Can the authors elaborate on any potential limitations or drawbacks of the proposed Online-ReOpt algorithm in real-world applications?', 'Are there any specific strategies to mitigate the computational cost of the online algorithm during its execution?', 'How does the performance of Online-ReOpt scale with larger state and action spaces?', 'Can the authors provide more intuition or examples to illustrate the key differences between ex-ante and ex-post max-min fairness?', 'How sensitive is the algorithm to the choice of the optimization oracle and its parameters?', 'Are there any real-world applications where the proposed method has been tested or could be particularly beneficial?', 'Can the authors provide more clarity on the specific differences and advantages of their approach compared to existing ex-ante fairness methods?', 'What are the potential limitations and societal impacts of this approach?']","['Dependence on an optimization oracle may not be feasible for all applications.', 'Experiments are limited to a single type of environment, which may not demonstrate the generalizability of the method.', 'Potential negative societal impacts of enforcing fairness in RL are not discussed.', 'Practical scalability to larger, more complex problems is unclear.', 'The need for an optimization oracle and the multiplicative weight update method may limit applicability in real-time or resource-constrained environments.', 'Dense writing and complex mathematical formulations may hinder accessibility for a broader audience.']",False,3,2,2,4,4,"['Novel differentiation between ex-ante and ex-post max-min fairness.', 'Introduction of the Online-ReOpt algorithm and its offline variants.', 'Strong theoretical analysis and regret bounds.', 'Experimental validation demonstrating the effectiveness of the proposed method.']","['Reliance on an optimization oracle limits practical applicability.', 'Experimental validation is limited to a queuing network example.', 'Some related work is not adequately discussed.', 'Generalization beyond the provided example is not well demonstrated.', 'Lacks clarity in several sections, making it difficult to understand the methodology.', 'Limited comparison with state-of-the-art methods, questioning the significance of results.', 'Theoretical guarantees are complex and not easily interpretable.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.']",3,3,3,2,Reject
2s4sNT11IcH,"The paper presents a convergence analysis of deep learning with differential privacy (DP) using the neural tangent kernel (NTK) framework. It introduces a new clipping method called global clipping, which aims to improve convergence and calibration compared to local clipping. The paper provides theoretical insights and empirical results across various datasets to demonstrate the effectiveness of the proposed method.","['Can the authors provide more intuitive explanations for the theoretical results, particularly regarding the NTK framework and its implications for DP training?', 'How does the proposed global clipping method compare to other advanced DP optimization techniques not discussed in the paper?', 'What are the potential limitations and negative societal impacts of using global clipping in practice?', 'Can the authors provide more empirical results on a wider range of network architectures and tasks to validate the generalizability of the proposed method?']","['The paper does not discuss the potential limitations of global clipping in terms of scalability and applicability to various network architectures.', 'The negative societal impacts of the proposed method, such as potential misuse or ethical concerns, are not addressed.', 'The empirical validation is limited in scale and does not cover a wide range of network architectures or tasks.']",False,3,2,3,6,4,"['The paper addresses an important problem in the intersection of differential privacy and deep learning.', 'Novel theoretical framework using NTK to analyze convergence in DP deep learning.', 'Introduction of the global clipping method, which theoretically improves convergence and calibration.', 'Empirical results on multiple datasets showing improved performance with global clipping.']","['The theoretical exposition is dense and may be hard to follow for readers unfamiliar with NTK and differential privacy.', 'Empirical validation is limited in scale and does not cover a wide range of network architectures or tasks.', 'The potential limitations and negative societal impacts of the proposed method are not thoroughly discussed.', 'The paper does not provide a clear comparison with other state-of-the-art DP optimization techniques beyond local clipping.']",3,3,2,3,Reject
6-lLt2zxbZR,"The paper investigates the use of pseudo-log-likelihoods (PLLs) for scoring natural language tasks, focusing on zero-shot performance with the ALBERT model. The authors claim state-of-the-art results on several common sense reasoning benchmarks without fine-tuning, arguing that the model's performance is due to its compositionality and robustness.","['How does the zero-shot method compare to fine-tuned models across all datasets?', 'Can the authors provide a more detailed analysis of the computational cost?', 'What are the potential ethical concerns and limitations of this approach?', 'Can the authors provide more detailed information on the implementation specifics to improve reproducibility?', 'How do the authors address the high computational cost associated with their approach?', 'Can the authors clarify the inconsistencies in the reported results across different tables and datasets?', 'Can the authors provide more details on the experimental setup, including hyperparameter settings and computational resources used?', ""How do the authors justify the claim of compositionality being the reason for the model's performance?"", 'Could the authors elaborate on the specific adversarial settings used to test the robustness of the approach?', 'What are the main limitations of the proposed approach, and how do they plan to address them in future work?', 'How does the performance of their approach compare on other common sense reasoning datasets not mentioned in the paper?', 'Can the authors elaborate on the potential limitations and ethical implications of their approach?']","['The paper does not thoroughly analyze the computational cost, which could be a significant limitation in practical applications.', 'Potential ethical concerns and limitations are not adequately addressed.', ""The approach's robustness to adversarial settings is highlighted, but more details on these settings and their impact on performance would be beneficial."", 'The high computational cost limits practical applicability.', 'Potential negative societal impact due to the resource-intensive nature of the approach.']",False,2,2,3,4,4,"['Novel application of PLLs to natural language scoring.', 'Achieves state-of-the-art results on several benchmarks.', 'Robust performance across various common sense reasoning tasks.', 'Provides datasets and code for reproducibility.']","['High computational cost due to extensive GPU time requirements.', 'Dense writing and complex explanations may hinder accessibility.', 'Limited practical applicability due to computational demands.', 'Comparison with fine-tuned models is not sufficiently addressed.', 'Clarity and organization of the paper could be improved.', 'Potential ethical concerns and limitations are not adequately discussed.', 'Reproducibility is a concern due to the lack of detailed implementation specifics.', 'Inconsistencies in the reported results across different sections of the paper.']",3,2,2,3,Reject
cD0O_Sc-wNy,"The paper proposes a method for replay scheduling in continual learning using Monte Carlo Tree Search (MCTS). The idea is to learn the optimal time to replay tasks to mitigate catastrophic forgetting, inspired by human learning techniques like spaced repetition. The authors demonstrate significant improvements in performance over several baseline methods across multiple benchmark datasets.","['Can you provide more details on the computational complexity and scalability of the proposed MCTS method?', 'How sensitive is the performance to the choice of hyperparameters, and how were they selected?', 'Could you elaborate on how this method can be adapted or simplified for real-world applications?', 'What are the potential negative societal impacts or ethical considerations associated with this work?', 'Can the authors provide more theoretical justification for the choices made in their method?', 'How does the computational cost of the proposed method compare to other continual learning approaches?', 'Can the authors provide more insights into the scalability of their approach, especially with larger datasets and more tasks?', 'Could the authors provide more details on the computational cost and scalability of RS-MCTS for larger and more complex datasets?', 'Can the authors provide more insights or theoretical analysis on why learning the replay schedule improves performance?', 'What are the hyperparameter settings for RS-MCTS, especially for the exploration constant in UCT and the memory size for each dataset?', 'How does the proposed method compare with other state-of-the-art continual learning methods such as GEM, EWC, or HAT?', 'What is the computational overhead of using RS-MCTS compared to simpler baselines?', 'Can the authors provide more insights into the decision-making process of the Monte Carlo tree search, possibly with more visualizations?']","['The paper briefly mentions the potential scalability issues with MCTS, but more details are needed.', 'The sensitivity to hyperparameters and the process of their selection could be elaborated.', 'A more in-depth discussion on ethical considerations and negative societal impacts is necessary.', 'The method may not scale well to very large datasets due to the computational cost of the tree search.', 'The paper does not provide sufficient discussion on the potential negative societal impacts of the proposed method.', 'The generalizability of the method to other types of tasks or settings is not well-explored.', 'Reproducibility is hindered by the lack of detailed hyperparameter settings and training times.']",False,3,3,3,6,4,"['Novel approach using MCTS for replay scheduling.', 'Inspired by proven human learning techniques.', 'Thorough experimental evaluation across multiple datasets.', 'Demonstrates consistent improvements over baselines.', 'Potentially significant impact on the field of continual learning.']","['Complexity and scalability of MCTS may limit practical applicability.', 'Requires careful tuning of hyperparameters.', 'The explanation of MCTS might be too complex for a broader audience.', 'Limited discussion on negative societal impacts or ethical considerations.', 'Lack of theoretical analysis and justification for the choices made in the method.', 'The paper is not very clear in explaining the MCTS setup and how it integrates with the continual learning framework.', 'The presentation could be improved for better readability and understanding.', 'The experimental results, while promising, may not be generalizable across all scenarios.', 'Insufficient clarity in the description of the methodology and experimental setup.', 'Limited comparison with state-of-the-art continual learning methods beyond ETS and heuristic baselines.', 'Lack of details on hyperparameter tuning and training duration, affecting reproducibility.']",4,3,3,3,Reject
dtt435G80Ng,"The paper introduces Centered Symmetric Quantization (CSQ) for extremely low-bit (2-3 bit) neural networks, addressing the asymmetry in conventional linear quantization (CLQ). The authors propose a method for efficient hardware implementation of CSQ and provide analytical and empirical validation of CSQ's performance on CIFAR-10 and ImageNet datasets.","['Can the authors provide more details on the experimental setup and hyperparameters used for training?', 'Have the authors considered the potential impact of CSQ on other types of neural network architectures beyond ResNet and MobileNet?', 'How does CSQ perform in real-world deployment scenarios, particularly in terms of latency and power consumption?', 'How does CSQ compare to other advanced quantization methods in terms of hardware implementation complexity?', 'Can the authors provide more detailed comparisons with a broader range of state-of-the-art quantization methods?', 'Can the authors simplify or better explain the theoretical and experimental sections to improve readability?', 'Can the authors provide more detailed explanations and visualizations of the CSQ method, particularly the hardware implementation?']","['The paper primarily focuses on 2-bit precision, and the advantages of CSQ diminish as precision increases.', 'The hardware implementation details may not be sufficient for reproducibility.', 'Potential negative societal impact is not discussed in depth.', 'The paper does not sufficiently address the limitations regarding the integration of CSQ with other quantization-aware training methods.', 'Potential hardware overhead, although claimed to be minimal, is not thoroughly analyzed.', 'The empirical results are limited to specific datasets and architectures, raising questions about generalizability.']",False,3,2,2,5,4,"['Addresses a specific problem in low-bit neural network quantization by proposing CSQ.', 'Empirical results show that CSQ outperforms CLQ at 2-bit precision.', 'Detailed analysis of quantization error and representational capacity.', 'Proposes an efficient hardware implementation compatible with existing BNN hardware.']","['Limited novelty as similar quantizers have been used in previous works.', 'Marginal performance gains at 3-bit and higher precisions.', 'Results may not generalize well across different datasets or architectures.', 'Potential reproducibility concerns, as the paper lacks detailed descriptions of experimental setups and hyperparameters.', 'The impact of CSQ is less significant beyond 2-bit precision.', 'The paper does not sufficiently address the practical challenges and trade-offs in implementing CSQ in hardware.', 'Writing and organization could be improved for better clarity.', 'Theoretical and experimental sections are dense and may be difficult to follow for readers not deeply familiar with quantization techniques and hardware implementations.', 'The paper does not provide a clear comparison with more recent state-of-the-art quantization methods beyond those listed.', 'The discussion on the limitations and potential negative societal impacts is minimal.']",2,3,2,3,Reject
LtI14EpWKH,"The paper introduces Tessellated 2D Convolutional Networks (TCNN) to enhance adversarial robustness in image classification tasks. The approach involves partitioning input images into non-overlapping regions and processing them separately through parallel branches of a CNN. Different tessellation schemes like regular grid tiling, non-uniform rectangles, and Mondrian partitioning are evaluated. The empirical results indicate improved robustness against FGSM and PGD attacks compared to standard CNNs.","['Could the authors provide a theoretical explanation for why tessellated networks are more robust to adversarial attacks?', 'How does the performance of TCNN compare with state-of-the-art adversarial defenses beyond FGSM and PGD?', 'What are the potential drawbacks of using tessellated networks, especially in terms of computational complexity and performance on clean data?', 'How does the proposed method perform on more complex datasets and network architectures (e.g., ImageNet, ResNet)?', 'How was the value of k (number of sub-rectangles) chosen for the different tessellation methods?']","['The paper does not address the computational complexity of tessellated networks.', 'Potential trade-offs between robustness and performance on clean data are not thoroughly explored.', 'The impact of the choice of tessellation scheme on different types of adversarial attacks is not fully studied.', 'The experiments are limited to relatively simple datasets (Fashion MNIST and CIFAR-10).', 'The approach may not scale well to more complex datasets and network architectures.', 'Potential negative societal impacts are not discussed.']",False,2,2,2,4,4,"['Innovative use of tessellation to improve adversarial robustness.', 'Empirical results show improved performance against common adversarial attacks.', 'Comprehensive evaluation with different tessellation patterns.']","['Lacks strong theoretical justification for the effectiveness of tessellated networks.', 'Experiments are limited and do not thoroughly explore potential drawbacks.', 'Comparison with state-of-the-art adversarial defenses is inadequate.', 'Poor organization and formatting issues make the paper difficult to follow.', 'Limited experimental validation with only two datasets and no comparison with stronger adversarial defenses.']",3,2,3,3,Reject
xspalMXAB0M,"The paper introduces a boosting algorithm for reinforcement learning, leveraging techniques from supervised learning to improve weak learners iteratively. It provides theoretical guarantees on the sample complexity and running time, independent of the number of states.","['How can the assumptions about the availability of weak learners be relaxed for practical applications?', 'Are there any preliminary experimental results to support the theoretical claims?', 'How does the proposed algorithm perform compared to existing RL algorithms?', 'What is the impact of different weak learners on the overall performance?', 'How scalable is the proposed approach for large-scale problems?', 'Can the authors provide more detailed explanations of the key concepts and assumptions, such as the use of the Frank-Wolfe method and the weak learning model?', 'How does the proposed method compare with existing state-of-the-art reinforcement learning algorithms in practice?', 'Can the authors include more empirical evaluations to demonstrate the practical impact of the proposed approach?', 'Can the authors provide more intuitive explanations or visualizations to improve the readability of the paper?']","['The need for a weak learner with a multiplicative approximation guarantee.', 'Assumptions about the availability of efficient exploration schemes.', 'Potential computational overheads due to the iterative nature of the proposed method.', 'The scalability of the approach for large-scale problems is not discussed.', 'Potential negative societal impacts of deploying RL systems are not considered.']",False,3,2,3,4,4,"['Innovative approach applying boosting to reinforcement learning.', 'Theoretical guarantees provided for the algorithm.', 'Addresses the non-convex nature of the value function in RL.']","['Assumptions about the availability of weak learners and efficient exploration schemes may be unrealistic.', 'Clarity of the presentation needs improvement.', 'Lack of empirical validation.', 'Heavy reliance on existing techniques without sufficient innovation in core methodology.', 'Insufficient discussion of limitations and potential negative societal impacts.']",3,3,2,3,Reject
p7LSrQ3AADp,"The paper introduces a nine-dimensional framework for characterizing and comparing saliency methods in machine learning. The framework is divided into three categories: methodology, sensitivity, and perceptibility, aiming to provide a more granular understanding beyond the traditional notion of faithfulness. The concept of 'saliency cards' is proposed for standardized documentation, and the framework is demonstrated through practical use cases, including a detailed study in radiology.","['How do the authors justify the orthogonality of the proposed dimensions?', 'Can the authors provide experimental validation or case studies to demonstrate the practical utility of the framework?', 'How does this framework compare to other existing frameworks for evaluating saliency methods?', 'How do you propose to handle the subjectivity inherent in weighing different dimensions?', ""Can you clarify and formalize concepts like 'perceptual correspondence' more rigorously?"", 'How were the nine dimensions chosen, and could there be potential biases?', 'What are the ethical implications of using different saliency methods in high-stakes settings?']","['Potential overlap between dimensions.', 'Lack of experimental validation.', 'Some dimensions lack quantitative metrics.', 'Potential biases in the dimensions chosen.', 'Ethical considerations are not thoroughly explored.']",False,2,3,2,5,4,"['Comprehensive approach to categorizing saliency methods.', ""Introduction of 'saliency cards' for standardized documentation."", 'Potential utility in aiding the selection and application of saliency methods.', 'Practical use cases and examples, including a detailed study in radiology.']","['Lack of rigorous experimental validation.', 'Some dimensions are subjective and hard to measure.', 'Potential overlap between some of the proposed dimensions.', 'Limited discussion on quantitative metrics for some dimensions.', 'Ethical considerations are not thoroughly explored.']",3,2,3,3,Reject
VFBjuF8HEp,"The paper introduces Differentiable Diffusion Sampler Search (DDSS), which optimizes fast samplers for pre-trained diffusion models by differentiating through sample quality scores. It presents the Generalized Gaussian Diffusion Models (GGDM) as a flexible family of non-Markovian samplers. The method improves sample quality and efficiency, as demonstrated on various datasets.","['Can the authors provide more detailed explanations or visual aids for complex equations and theorems?', 'What are the potential limitations of the proposed method when applied to larger, more diverse datasets?', 'Can you provide more theoretical insights or justifications for why DDSS and GGDM outperform existing methods?', 'Are there any other baselines you could include in the experiments for a more comprehensive comparison?', 'Could you simplify or further explain the mathematical notations and proofs to make them more accessible to a broader audience?', 'How does the method perform on tasks other than image generation, such as text or audio?', 'Can the authors discuss the potential societal impacts of this research in more detail?', 'Can you provide more details on how the choice of perceptual loss affects the generalization of the method?', 'Have you considered the potential negative societal impacts of making high-quality image generation more accessible and efficient?', 'How does the computational cost of DDSS compare to other optimization methods in practice?', 'Can the approach be generalized to other types of data beyond images, such as audio or text?']","['The paper addresses potential limitations related to the complexity of the dataset and the number of inference steps.', 'The high computational cost associated with gradient rematerialization is mentioned but not deeply explored.', 'The method still faces challenges in finding high-quality samplers with very few inference steps (e.g., K < 10).', 'The relative improvement on more diverse datasets like ImageNet is less pronounced compared to CIFAR10.', 'The high memory or computation requirements for backpropagating through the sampling chain could be a limitation.', 'The potential mismatch between the training objective and sample quality is not thoroughly explored.', 'Potential negative societal impacts, such as misuse in generating fake media, are not discussed.', 'The method is highly dependent on the choice of perceptual loss, which may affect its generalization to other applications.', 'The paper lacks a detailed discussion on the potential negative societal impacts of the work.', 'The paper does not fully address the theoretical guarantees for GGDM.', 'There is potential computational inefficiency due to the reliance on gradient rematerialization.', 'The approach is primarily validated on image data, with limited discussion on its applicability to other data types.']",False,3,3,3,7,4,"['Presents a novel method (DDSS) for optimizing fast samplers.', 'Introduces Generalized Gaussian Diffusion Models (GGDM).', 'Demonstrates significant improvements in sample quality and efficiency over existing baselines.', 'Compatible with any pre-trained diffusion model without requiring fine-tuning.', 'Addresses the inefficiency of diffusion models during sampling.', 'Thorough experimental evaluation on multiple datasets.']","['Some complex equations and theorems could benefit from additional explanatory text.', 'The impact of the proposed method on larger, more diverse datasets is less pronounced.', 'Lacks deeper theoretical justifications for the observed performance improvements of DDSS and GGDM.', 'Could include more baselines for a comprehensive comparison.', 'Some sections, especially the mathematical notations and proofs, are dense and may be challenging for readers unfamiliar with the topic.', 'The potential negative societal impacts and limitations are not adequately addressed.']",4,3,3,4,Accept
jE_ipyh20rb,"The paper presents FEDPROF, a novel algorithm for optimizing Federated Learning (FL) by profiling data representations to selectively involve clients based on the quality of their data. The approach aims to mitigate the impact of low-quality data on the global model's convergence and accuracy. The authors provide theoretical proofs for the Gaussian distribution of neural network representations and conduct extensive experiments demonstrating the effectiveness of FEDPROF.","['Can the authors provide more details on the assumptions made in the theoretical proofs?', 'How does FEDPROF compare with more recent state-of-the-art methods in FL?', 'Can the authors discuss the potential negative societal impacts of their approach?', 'Can the authors provide a more intuitive explanation of the theoretical proofs?', 'Are there any specific scenarios where the proposed method may not perform well?', 'How does FEDPROF handle potential adversarial attacks?', 'How sensitive is FEDPROF to the choice of the preference factor α? Have the authors experimented with different values of α, and if so, how does it impact the results?', 'How does FEDPROF handle situations where the quality of local data changes over time? Can the algorithm adapt to such changes, and if so, how?', 'Can the authors provide more details on the computational overhead introduced by the profiling and matching scheme? How does it compare to the overall training time?', 'Can the authors provide more details on how the theoretical analysis translates to the practical benefits observed in experiments?', 'Can the authors clarify the methodology used for generating and evaluating the representation profiles?', 'Can the authors provide more rigorous validation for the theoretical proofs and assumptions?', 'How well does the algorithm perform on a wider range of real-world scenarios beyond the provided experiments?', 'Can the authors clarify the justification for using Gaussian assumptions in data representation?', 'How does homomorphic encryption impact the performance and complexity of the proposed method?']","['The paper does not discuss the potential biases introduced by selectively involving clients based on their data quality.', 'The scalability of FEDPROF to very large-scale FL settings is not addressed.', 'The security and privacy implications of profiling data representations are not thoroughly examined.', 'The complexity of the theoretical proofs might limit the accessibility of the paper.', 'Potential negative societal impacts are not thoroughly discussed.', 'The experimental setup may not fully represent all practical FL scenarios.', 'Selective participation may lead to fairness issues, where certain clients are consistently excluded from the training process.', 'The authors should address the limitations of their approach, such as the assumption of Gaussian distribution for data representations and the potential difficulties in accurately profiling data representations.', 'The theoretical analysis assumes ideal conditions that may not hold in real-world scenarios.', 'The theoretical assumptions might not hold for all types of data and neural network architectures.', 'The experimental setup might not be representative of all real-world scenarios.', 'The use of Gaussian assumptions and homomorphic encryption needs further justification and clarity.']",False,2,2,2,4,4,"['Novel approach to handling low-quality data in FL.', 'Theoretical proofs for the Gaussian distribution of representations.', 'Extensive experiments showing significant improvements in convergence and accuracy.', 'Addresses a practical and pertinent problem in FL.', 'Well-motivated and supported by theoretical analysis.']","['Lack of clarity in theoretical proofs and algorithm description.', 'Related work section is not exhaustive.', 'Potential negative societal impacts are not adequately discussed.', 'Experiments lack some critical baselines and comparisons with recent state-of-the-art methods.', 'Theoretical proofs are complex and may not be easily understood by a wider audience.', 'The paper is not well-organized, making it difficult to follow the main ideas and contributions.', 'Some sections, such as the proofs and experimental details, are overly complex and could benefit from simplification.', 'The theoretical contributions are not robustly connected to the practical benefits observed in experiments.', 'Some parts of the methodology and results are not clearly explained, affecting reproducibility.']",3,2,2,3,Reject
YLglAn-USkf,"The paper investigates the zero-shot learning capabilities of BERT-family models using different prompting strategies. It proposes the Multi-Null Prompt strategy and conducts an empirical study across 20 datasets, showing promising results on some datasets but highlighting limitations in language understanding tasks.","['Can the authors provide more theoretical insights into why the Multi-Null Prompt strategy works?', 'How does the proposed method perform on a wider range of NLP tasks beyond the ones tested?', 'Are there any potential limitations or biases introduced by the Multi-Null Prompt strategy?', 'Why were the specific datasets chosen for this study? How do they represent the broader range of potential applications for zero-shot learning?', 'Can the authors compare their results with other state-of-the-art zero-shot learning techniques to better contextualize their findings?', 'What are the broader implications of the findings for real-world applications?', 'How do the authors plan to address the identified limitations in future work?']","['The paper adequately addresses some limitations but could explore more on the potential biases and generalizability of the proposed methods.', 'Potential negative societal impacts are not explicitly discussed.', 'The use of large pre-trained language models can have significant environmental and ethical implications.']",False,2,2,3,4,4,"['Explores a relatively under-explored area of zero-shot learning with BERT models.', 'Proposes a simple yet effective Multi-Null Prompt strategy.', 'Provides comprehensive empirical results showing promising improvements.', 'Well-structured paper with clear sections and contributions.']","['Relies on a limited number of datasets, potentially limiting generalizability.', 'Lacks theoretical insights or validations beyond empirical results.', 'Some sections could benefit from clearer explanations for broader accessibility.', 'Insufficient exploration of limitations and potential negative societal impacts.', 'Lack of clarity in experimental setup and choice of datasets.', 'The significance of findings is diluted by the lack of comparison with other state-of-the-art zero-shot learning techniques.', 'Some experimental results, especially on NLU benchmarks, are not very promising.']",3,2,2,3,Reject
mFpP0THYeaX,"The paper proposes GIFT, a method for gradual domain adaptation when intermediate distributions are absent. GIFT creates virtual samples by interpolating representations of examples from source and target domains. The paper demonstrates that iterative self-training can form a natural curriculum for gradual adaptation and shows the effectiveness of GIFT in both synthetic and real-world benchmarks. The potential societal impact includes overfitting to synthetic shifts, which might not generalize well to real-world scenarios.","['Can the authors provide more details on how the interpolation coefficient λ is scheduled?', 'How does the performance of GIFT compare to other state-of-the-art domain adaptation methods?', 'Can the authors clarify the computational overhead introduced by the GIFT method?', 'Can the authors provide more intuition or theoretical justification for the choice of interpolation strategy?', 'Can you provide more details on the hyperparameter tuning process and how you ensure that GIFT does not overfit to specific settings?', 'Have you tested GIFT on additional datasets beyond the ones mentioned in the paper to validate its robustness?', 'How does the method perform on non-image data or other tasks beyond classification?', 'What are the computational costs associated with the proposed alignment strategies?']","['The method relies on the assumption that linear interpolation between source and target representations is meaningful, which may not always hold.', 'The method might not generalize well to all real-world scenarios due to reliance on synthetic data.', 'The approach has been tested primarily on image classification tasks; it is unclear how well it generalizes to other domains and tasks.', 'Potential negative societal impact includes overfitting to certain types of synthetic shifts which might not generalize well to real-world scenarios.', 'The computational complexity of the alignment strategy could be high.']",False,3,2,3,5,4,"['Addresses an important problem in domain adaptation.', 'Proposes a novel method (GIFT) for generating virtual intermediate samples.', 'Shows that iterative self-training naturally forms a curriculum.', 'Extensive experimental evaluation on synthetic and real-world benchmarks.']","['The clarity of the paper needs improvement, especially in the explanation of the GIFT algorithm.', 'Experimental setup details are scattered and not well-organized.', 'The significance of the contributions is not well-articulated.', 'Limited novelty in the idea of using interpolation for domain adaptation.', 'The experiments rely heavily on synthetic data, which might not fully generalize to real-world scenarios.', 'Lacks detailed comparison with other state-of-the-art methods in domain adaptation.', ""Theoretical justifications for GIFT's performance are not sufficiently detailed."", 'Potential overfitting of hyperparameters is not adequately addressed.']",3,3,2,3,Reject
q4HaTeMO--y,"The paper explores the equivalence between Deep Equilibrium Models (DEQs) and Deep Declarative Networks (DDNs), presenting a theoretical result that demonstrates this equivalence under certain conditions. The authors propose an initialization scheme for DEQs based on this equivalence, which empirically improves training stability and performance over random initialization.","['Can the authors provide more intuitive explanations or examples to help readers understand the implications of their theoretical results?', 'How does the proposed initialization scheme compare with other state-of-the-art initialization methods for DEQs?', 'Can the authors expand the empirical evaluation to include more diverse tasks and datasets?', 'Can the authors provide more comparison with baseline methods in empirical evaluations?', 'How does the proposed initialization scheme scale with very large datasets and models?', 'Can the authors provide more intuitive explanations or visualizations to improve clarity?', 'Have the authors considered a broader range of tasks and architectures for empirical validation?', 'What are the potential limitations of the proposed initialization scheme, and how might it impact different types of DEQ models?', 'Can the authors provide more details on the choice of kernels and their impact on the generality of the results?', 'Are there any potential limitations or scenarios where the proposed equivalence might not hold?']","['The paper does not sufficiently discuss potential negative societal impacts of the work.', 'The empirical evaluation is limited in scope and may not fully demonstrate the practical benefits of the proposed method.', 'The paper assumes that readers have a strong background in theoretical machine learning, making it less accessible to a broader audience.', 'The empirical results, while promising, are limited in scope and do not fully explore the practical implications of the proposed methods.', 'The empirical results are based on specific kernel choices and regularization parameters, which might limit the generality of the approach.', 'The complexity of the theoretical proofs and empirical setups might limit the accessibility for a broader audience.']",False,3,3,3,6,4,"['Strong theoretical contribution demonstrating the equivalence between DEQs and DDNs.', 'Empirical results showing improved training stability and performance with the proposed initialization scheme.', 'Reproducibility is supported by provided code and detailed instructions.', 'Rigorous mathematical proofs and derivations.']","['The paper is highly technical and may be difficult for readers not deeply familiar with DEQs and DDNs.', 'Clarity could be improved, particularly in explaining the implications of the theoretical results.', 'Empirical results are limited in scope and do not compare the proposed method with state-of-the-art models.', 'Discussion on potential negative societal impacts is lacking.', 'Ethical considerations are minimally addressed.', 'Practical applicability and scalability of proposed methods are not thoroughly explored.']",4,3,3,4,Reject
FPCMqjI0jXN,"The paper introduces Domino, a slice discovery method (SDM) that uses cross-modal embeddings and an error-aware mixture model to identify and describe systematic errors in machine learning models. It proposes a quantitative evaluation framework for assessing SDMs and demonstrates Domino's effectiveness across 1,235 slice discovery settings in three domains (natural images, medical images, and time-series data).","['Can the authors provide more details on how the evaluation framework accounts for the diversity of potential real-world scenarios?', 'How does Domino handle biases in cross-modal embeddings, especially those sourced from the web?', 'Can the authors clarify the initialization process for the mixture model and its impact on performance?', 'How does Domino perform when the strength of the slice (α) is very low? Are there any strategies to improve performance in such cases?', 'Can the authors discuss the potential limitations of using pre-trained cross-modal embeddings in more specialized domains where such embeddings might not be available or effective?', 'Can the authors provide additional baselines and comparisons to further validate the performance improvements of Domino?', 'How do the authors plan to address the potential negative societal impacts and ethical concerns associated with using cross-modal embeddings trained on web data?', 'How does the performance of Domino change when applied to real-world datasets without synthetic controls?', 'What steps can be taken to mitigate the potential biases in the cross-modal embeddings used?', 'Can the authors provide more insights into the practical applicability and scalability of the proposed method?']","['The potential biases in cross-modal embeddings sourced from the web are a significant concern, as they may influence the identification of slices.', 'The evaluation framework may not fully represent the diversity and complexity of real-world applications, limiting the generalizability of the results.', 'The reliance on pre-trained cross-modal embeddings might limit the applicability of Domino in domains where such embeddings are not available or effective.', 'The scalability of the proposed method to very large datasets or real-world applications is not thoroughly discussed.']",True,3,3,3,4,4,"['Addresses the lack of quantitative evaluation frameworks for SDMs.', 'Proposes a novel method leveraging cross-modal embeddings and an error-aware mixture model.', 'Demonstrates significant improvements in identifying coherent, underperforming slices compared to prior methods.', 'Provides natural language descriptions for identified slices, enhancing interpretability.', 'Extensive experimental results across various datasets and tasks.']","['The novelty of the cross-modal embeddings approach may be overstated, given prior work in related areas.', 'The evaluation framework, while comprehensive, might not fully capture the complexity of real-world applications.', 'Potential biases in the embeddings sourced from the web are acknowledged but not thoroughly addressed.', 'The clarity of the methodology section could be improved, particularly regarding the implementation details of the error-aware mixture model.', 'Reproducibility may be hindered by the complexity of the methods and the need for domain-specific corpora for text descriptions.', 'Limited discussion on the practical applicability and scalability of the proposed method.']",4,3,3,3,Reject
5hLP5JY9S2d,"The paper investigates the relationship between closed-set classifier accuracy and open-set recognition (OSR) performance, demonstrating that improvements in closed-set accuracy lead to better OSR metrics. It proposes using maximum logit score (MLS) for OSR and introduces the Semantic Shift Benchmark to better assess semantic novelty, achieving state-of-the-art performance on several benchmarks.","['Can the authors provide more theoretical insights into why improving closed-set accuracy enhances OSR performance?', 'How does the proposed approach perform in domains other than image recognition?', 'Can the Semantic Shift Benchmark be applied to other types of data, such as text or audio?', ""Can the authors provide more details on the construction of the 'Semantic Shift Benchmark'? How were the semantic distances calculated?"", 'What are the potential limitations of using the maximum logit score (MLS) as an open-set indicator?', 'How does the proposed method handle cases where the closed-set accuracy saturates but the open-set performance still needs improvement?', 'Can the authors provide more detailed explanations of the experimental settings and choices?', 'Are there scenarios where specialized OSR methods might still be necessary?', 'How do the authors suggest mitigating the potential negative societal impacts of over-relying on closed-set classifiers in critical applications?', 'Can the authors explore alternative OSR methods that do not rely on enhancing closed-set accuracy?', 'How does the proposed approach compare to more recent state-of-the-art methods not included in the paper?', 'Can you include more details on the performance of different architectures on the Semantic Shift Benchmark?']","['Theoretical justification for the correlation between closed-set accuracy and OSR performance could be stronger.', ""The approach's applicability to domains other than image recognition is not demonstrated."", 'The proposed method relies heavily on the assumption that improving closed-set accuracy will always lead to better open-set performance, which may not hold in all cases.', ""The 'Semantic Shift Benchmark' may not cover all possible types of open-set scenarios, limiting its generalizability."", 'Potential negative societal impacts, such as the misuse of OSR models in surveillance or biased decision-making, are not deeply analyzed.', 'The paper underestimates the value of specialized OSR methods in certain contexts.', 'Potential negative societal impacts of over-relying on closed-set classifiers are not thoroughly discussed.', 'The results are largely confined to image classification tasks, limiting the generalizability to other domains.', 'Theoretical justification for the observed correlation between closed-set and open-set performance could be expanded.']",False,3,3,3,4,4,"['Thorough empirical analysis showing the correlation between closed-set and open-set performance.', 'Introduction of the Semantic Shift Benchmark for better evaluation of semantic novelty.', 'State-of-the-art performance on multiple benchmarks using proposed methods.', 'Comprehensive experimental validation across multiple datasets and settings.', 'Detailed experimental setup and reproducibility with publicly available code.']","['Limited novelty as the approach mainly leverages existing concepts.', 'Heavy reliance on empirical results with weaker theoretical underpinning.', 'Incremental contribution might limit broader impact.', 'The paper could be clearer in its presentation, especially in some of the mathematical formulations and experimental setups.', 'Potential overemphasis on improving closed-set performance as the primary means to enhance OSR.', 'Limited exploration of alternative OSR methods beyond enhancing closed-set accuracy.', 'Results primarily focus on image classification tasks; applicability to other domains is not thoroughly explored.']",3,3,3,3,Reject
JHXjK94yH-y,"The paper introduces Adversarial Surprise (AS), a novel unsupervised reinforcement learning method that balances exploration and control through an adversarial game between two policies: Explore and Control. The Explore policy seeks to maximize surprise, while the Control policy aims to minimize it. The method is supported by theoretical analysis and empirical results demonstrating its superiority over state-of-the-art methods in exploration and zero-shot transfer tasks.","['Can the authors provide a more intuitive explanation of the theoretical results and their implications?', 'How sensitive is the method to the choice of hyperparameters, such as the length of the Explore and Control policy turns?', 'Have the authors considered environments with different types of stochastic elements to test the generality of their method?', 'Can the authors provide more details on the implementation, particularly the neural network architectures and training procedures?', 'How do the computational requirements of AS compare to the baselines in terms of runtime and resources?']","['The assumptions in the theoretical framework may not always hold and need further exploration.', ""The method's sensitivity to hyperparameters should be discussed further."", 'Potential scalability issues in more complex or varied environments are not discussed.', 'Negative societal impacts are not comprehensively addressed; for instance, the impact of autonomous agents acting unpredictably in real-world settings.']",False,3,3,3,6,4,"['Novel approach combining adversarial principles with intrinsic motivation.', ""Strong theoretical proofs supporting the method's effectiveness in state exploration."", 'Comprehensive empirical results showing superior performance in exploration and zero-shot transfer.', 'Detailed comparison with multiple state-of-the-art methods.']","['Theoretical sections are dense and somewhat difficult to follow.', 'The assumptions for theoretical proofs might be restrictive in practical scenarios.', 'Empirical evaluation is limited to specific environments; more diverse testing is needed.', 'Potential reproducibility issues based on the provided information.', 'High computational resources required for experiments may limit reproducibility.']",4,3,3,3,Accept
js62_xuLDDv,"The paper investigates fairness in deep metric learning (DML), particularly when trained on imbalanced data. It introduces a benchmark called finDML to evaluate fairness and a method named Partial Attribute De-correlation (PARADE) to mitigate bias in DML representations. The authors show that commonly used DML methods exhibit significant bias, even when downstream classifiers are trained on balanced data. PARADE aims to reduce these biases by de-correlating feature representations from sensitive attributes.","['Can the authors provide more details on the experimental setup, particularly how the datasets were manipulated to create imbalances?', 'How does PARADE compare with other state-of-the-art fairness mitigation techniques not discussed in the paper?', 'Can the authors provide more insights into the limitations and potential negative societal impacts of their work?', 'Can the authors provide more details on the implementation of PARADE and its comparison with other fairness methods?', 'How do the proposed fairness definitions in finDML compare to existing fairness metrics in the literature?', 'Can the authors clarify the choice of datasets and whether other datasets would yield similar results?']","['The paper briefly mentions but does not thoroughly explore the potential limitations of PARADE, such as its dependency on pre-defined sensitive attributes.', 'The societal impact of using DML in sensitive applications like facial recognition is acknowledged but not deeply analyzed.', 'The method may not generalize well across different types of data and tasks.', 'Potential negative societal impacts, especially in the context of facial recognition, are not thoroughly discussed.']",False,3,2,3,5,4,"['Addresses an important and relatively unexplored problem in DML.', 'Proposes a novel benchmark (finDML) for evaluating fairness in DML.', 'Introduces a new method (PARADE) to mitigate bias in DML representations.', 'Comprehensive experimental evaluation on multiple datasets.']","[""The paper's clarity could be improved, particularly in the explanation of the experimental setup and results."", 'Limited discussion on the potential limitations and generalizability of the proposed methods.', 'The effectiveness of PARADE is not consistently demonstrated across all datasets.', 'Ethical considerations are mentioned but not deeply explored.', 'The novelty of PARADE might be limited as it builds on existing de-correlation techniques.', 'The evaluation could benefit from additional baselines and a more detailed analysis of the results.']",3,3,2,3,Reject
rS9t6WH34p,"The paper presents ObSuRF, a method for decomposing 3D scenes into objects via unsupervised volume segmentation using Neural Radiance Fields (NeRFs). ObSuRF encodes a single image into a set of latent vectors, each representing an object, and uses these vectors to condition NeRF decoders. The method introduces a novel loss function for efficient training on RGB-D inputs without ray marching and is evaluated on both 2D and 3D benchmarks, showing promising results.","['How does ObSuRF compare to other recent methods for unsupervised 3D segmentation?', 'Can the authors provide more detailed derivations and explanations for the methodology?', 'What is the impact of each component of ObSuRF? Ablation studies would be helpful.', 'Can you provide more rigorous justification for the Poisson process derivation and its application to NeRFs?', 'How does your method fundamentally differ from the concurrent work by Yu et al. (2021b)?', 'Can you provide more evidence or benchmarks to support the claimed reduction in computational complexity?', 'Can you provide more details on the implementation of the overlap loss and its impact on the results?', 'How do different hyperparameters affect the performance of ObSuRF?', 'What are the limitations of the method, especially concerning the reliance on RGB-D data?', 'Can you clarify how your approach differs from the concurrently developed systems mentioned?', 'What are the specific limitations of your method when applied to real-world data?', 'How do you plan to address the potential negative societal impacts of your work?', 'Can the authors provide more clarity on the specific contributions of their method compared to existing techniques?', 'How does the method perform on real-world datasets as opposed to synthetic ones?', 'What are the potential limitations and negative societal impacts of this method?']","['The method relies on RGB-D data, which may not always be available in real-world scenarios.', 'Potential negative societal impacts, such as privacy concerns, are not addressed.', 'The paper does not adequately address potential limitations and negative societal impacts. Specifically, it relies heavily on synthetic datasets, which may not translate well to real-world scenarios.']",False,3,3,3,6,4,"['Addresses an important problem in 3D scene understanding.', 'Combines NeRF and slot attention in a novel way for unsupervised segmentation.', 'Novel loss function that significantly reduces computational costs.', 'Extensive experimental validation on both 2D and 3D datasets.']","['The methodology is a combination of well-known techniques, limiting the originality.', 'Some sections of the paper are dense and difficult to follow.', 'Missing comparisons to closely related work and ablations for all components of the model.', 'Relies on synthetic datasets, limiting real-world applicability.', 'Does not thoroughly address limitations and negative societal impacts.']",3,3,3,4,Reject
VqzXzA9hjaX,"The paper presents a novel approach to combine multiple analytical optimizers into a single, stronger optimizer through a process termed 'Optimizer Amalgamation.' The authors propose three amalgamation schemes: Mean Amalgamation, Min-Max Amalgamation, and Optimal Choice Amalgamation. They also introduce techniques to stabilize the amalgamation process by adding random or adversarial perturbations. Extensive experiments are conducted to demonstrate the efficacy of the proposed methods.","['Can the authors provide more theoretical insights into why the proposed amalgamation mechanisms are expected to work?', 'How does the proposed optimizer amalgamation perform on more complex, real-world tasks?', 'What are the computational costs associated with the amalgamation process, especially for large teacher pools?', 'Can the authors provide more detailed results on the scalability of their approach?', 'Can the authors clarify the trade-offs between the different amalgamation mechanisms?', 'Can the authors provide more detailed statistical analysis to support the experimental claims?', 'What are the potential limitations of the proposed amalgamation techniques?', 'How do the authors plan to address any ethical concerns related to their work?', 'Can the authors provide more clarity on the differences between their approach and existing learning to optimize methods?', 'How generalizable is the proposed amalgamated optimizer to significantly different tasks or much larger models?', 'What specific steps can be taken to reduce the computational cost of the proposed method?', 'Can the authors provide more detailed explanations and clarifications for the mathematical formulations and algorithms?', 'Can the authors provide more comprehensive experimental results, including more diverse datasets and settings?', 'How does the proposed approach compare to other existing learning-to-optimize methods in terms of computational cost and practicality?']","['The proposed methods are primarily evaluated on relatively small-scale problems, which may limit their applicability to larger, real-world tasks.', 'The paper does not address the potential negative societal impacts of the proposed methods.', 'The scalability of the method to larger models and datasets is not fully explored.', 'The robustness of the amalgamated optimizer across different problem domains is not thoroughly validated.', 'Potential negative societal impacts, such as increased computational costs and energy consumption, should be considered.', 'The high computational cost of the proposed method may limit its practical applicability.', 'Generalizability to significantly different tasks or larger models is not convincingly demonstrated.']",False,2,2,3,4,4,"['Novel concept of combining multiple optimizers into a single, learnable optimizer.', 'Thorough experimentation across various datasets and architectures.', 'Detailed analysis of the stability of the amalgamation process.', 'Code and pre-trained models are made publicly available.']","['The paper is densely written and difficult to follow, especially in the methodological sections.', 'Lack of sufficient theoretical justification for the proposed amalgamation mechanisms.', 'Experiments primarily focus on relatively small-scale problems; limited evaluation on large-scale or real-world tasks.', 'The impact of the proposed methods on state-of-the-art benchmarks is not clearly demonstrated.', 'Scalability concerns with the proposed methods.', 'Potential issues with the robustness of the amalgamated optimizer.', ""Some aspects of the methodology appear to build heavily on existing 'learning to optimize' techniques, reducing the perceived novelty."", 'Insufficient discussion of potential limitations and ethical concerns.', 'Lack of detailed statistical analysis to support experimental claims.', 'High computational cost of the proposed method.']",3,3,2,3,Reject
vdbidlOkeF0,"The paper introduces the Scaled Density Ratio Estimator (SDRE), a novel method for density ratio estimation that leverages scaling densities and multi-class logistic regression to estimate density ratios accurately. The method addresses the limitations of existing methods, especially in the presence of both First Order Discrepancy (FOD) and Higher Order Discrepancy (HOD). The approach is theoretically justified and empirically validated on synthetic and real datasets, demonstrating improvements over state-of-the-art methods.","['Can the authors provide more details on the construction of the scaling measures, especially the overlapping distribution?', 'Are there any theoretical bounds on the estimation accuracy of SDRE?', 'How sensitive is the method to the choice of the scaling measure m?', 'Can the authors provide more detailed proofs and justifications for the theoretical claims?', 'How does the computational efficiency of SDRE compare to existing methods in practice?', 'Can the authors provide bounds on the estimation errors of SDRE?', 'Are there any practical guidelines for selecting or constructing the scaling measure m?', 'How does the method perform on tasks where the scaling measure m is not well chosen or is suboptimal?', 'Can the authors discuss potential negative societal impacts in more detail?', 'How does SDRE perform in scenarios where the distributions p and q have complex, multimodal structures?']","['The paper does not provide theoretical bounds on the estimation accuracy.', 'The method relies on the choice of a suitable scaling measure m, which may not always be straightforward to determine.', 'The clarity of the presentation could be improved.', 'The scaling measure m is not learned but provided, which could limit the general applicability of the method.', 'Potential negative societal impacts are briefly mentioned but not discussed in depth.', 'The scalability and computational efficiency of SDRE in very high-dimensional settings are not well explored.', 'The method may have limitations in handling distributions with complex, multimodal structures.']",False,3,3,3,6,4,"['Addresses a significant problem in density ratio estimation.', 'Novel use of scaled-Bregman divergence for density ratio estimation.', 'Thorough empirical evaluations and comparisons with state-of-the-art methods.', 'Theoretical justifications and practical demonstrations of the method.']","['Some sections lack clarity and detailed explanations, making it difficult to follow.', 'The novelty of the scaling measure constructions is somewhat limited as they borrow from existing methods.', 'No theoretical bounds provided for the estimation accuracy.', 'Heavy reliance on empirical results without sufficient theoretical guarantees.', 'Scalability and computational efficiency are not thoroughly demonstrated.', 'Potential negative societal impacts are acknowledged but not deeply explored.']",4,3,3,4,Reject
7AzOUBeajwl,"The paper introduces a method for text style transfer that addresses confounding factors by learning invariant style classifiers and orthogonal classifiers. The approach is tested on synthetic and real-world datasets, showing improvements in preserving non-style attributes while transferring style.","['Can the authors provide more details about the training process, including hyperparameter settings and computational resources used?', 'How does the proposed model handle cases where the confounding factors are not easily separable from the style?', 'Can the authors elaborate on the potential negative societal impacts and propose mitigation strategies?', 'How does the proposed method compare with other state-of-the-art style transfer methods not included in the current experiments?', 'Can you provide more details on the hyperparameter tuning process for the invariant classifiers?', 'How does the method perform on other style transfer tasks beyond sentiment transfer?', 'What are the potential limitations and failure cases of the proposed approach?', 'Can the authors provide more details on the technical implementation of the invariant classifiers?', 'How were the hyperparameters chosen for the experiments?', 'Can the authors elaborate on the failure cases and limitations of their approach?', 'Why is there no discussion on the potential negative societal impacts or ethical concerns associated with this work?', 'How robust is the proposed method to different types of confounders beyond the ones tested in the paper?', 'Can the authors provide more details on the training and evaluation procedures, particularly for the human evaluations?', 'How does the method perform on longer and more complex sentences?']","['The paper does not fully address how the model would handle highly entangled confounding factors and styles.', 'The evaluation metrics could benefit from more comprehensive human evaluations and additional metrics for content preservation.', 'The paper acknowledges the potential for misuse in spreading misinformation but does not deeply discuss mitigation strategies.', 'The experimental validation is somewhat limited in scope regarding datasets and comparison with other state-of-the-art methods.', 'The paper does not discuss the potential limitations and failure modes of the proposed method in detail.', 'Limited evaluation on sentiment transfer tasks; additional experiments on other style transfer tasks would be beneficial.', 'Potential negative societal impacts and ethical concerns are not discussed.', 'The paper does not adequately address the limitations of the proposed method, such as its reliance on synthetic tasks and the potential for generating biased or harmful text.']",True,3,2,3,5,4,"['Novel approach that addresses a real-world problem often ignored in style transfer tasks.', 'Significant performance improvements over existing methods in both synthetic and real-world datasets.', 'The methodology is well-motivated and leverages invariant risk minimization.']","['The methodology section is not sufficiently clear, making it difficult to reproduce the results.', ""The evaluation metrics used for assessing the model's performance could be more comprehensive."", 'Potential negative societal impacts, particularly around misinformation, are mentioned but not adequately addressed.', 'The novelty is partially based on existing techniques like IRM, which may limit its originality.', 'The scope of datasets and comparison with other state-of-the-art methods could be expanded.']",3,3,2,3,Reject
nsjkNB2oKsQ,"The paper proposes a novel framework for handling delayed rewards in reinforcement learning (RL). It introduces a new Q-function formulation and an HC-decomposition rule to improve training efficiency and stability. Theoretical guarantees are provided, and extensive experiments demonstrate the effectiveness of the proposed methods.","['Can the authors provide more intuitive explanations for the theoretical guarantees?', 'How sensitive are the proposed methods to the choice of hyperparameters?', 'Can the authors provide more details on the experimental setup to ensure reproducibility?', 'How does the proposed method compare with existing RL methods in terms of computational complexity?', 'Can the authors provide more detailed analysis and discussion of the experimental results?', 'Are there any potential limitations or negative societal impacts of the proposed methods?', 'How does the HC-decomposition technique compare to other decomposition methods in terms of computational complexity?', 'Can the authors provide more details on the practical implications and potential applications of the proposed methods?', 'How does the proposed method perform on discrete action spaces or other types of environments beyond continuous control?']","['The complexity of the proposed methods may limit their applicability in real-world scenarios.', 'The paper does not fully address the potential impact of hyperparameter selection on the performance of the proposed methods.', 'The theoretical analysis, while promising, is dense and may be difficult for readers to follow.', 'The experimental validation, although extensive, could benefit from more detailed analysis and discussion.', 'Potential limitations and negative societal impacts are not thoroughly addressed.', 'The proposed framework may not generalize well to all real-world settings with delayed rewards.', 'Potential computational overhead introduced by the HC-decomposition technique.']",False,3,3,3,7,4,"['Addresses a relatively unexplored problem in RL.', 'Introduces a novel Q-function formulation and HC-decomposition framework.', 'Provides theoretical guarantees for the proposed methods.', 'Presents extensive experimental results demonstrating the effectiveness of the methods.']","['The paper is dense and complex, making it challenging to follow.', 'Some claims, especially regarding the theoretical guarantees, need more intuitive explanations.', 'The experimental setup and results, while extensive, could benefit from additional clarity and detail to ensure reproducibility.', 'Limited discussion on potential negative societal impacts.']",4,3,3,3,Reject
2hMEdc35xZ6,"The paper presents Defect Transfer GAN (DT-GAN), a novel GAN-based approach designed to generate diverse synthetic defect images for data augmentation in scenarios with limited defective samples. The method builds on StarGAN v2 and introduces style-content separation and foreground-background disentanglement to enhance the quality and variability of generated images. Experiments on industrial datasets show significant gains in defect detection tasks using the synthetic data generated by DT-GAN.","['Can you provide more details on the potential limitations and negative societal impacts of your approach?', 'How does DT-GAN handle extremely rare defect types that were not seen during training?', 'What are the computational requirements for training DT-GAN compared to other GAN-based methods?', 'Can the proposed method be generalized to other datasets or domains outside of the SDI dataset?', 'How does the model perform on other types of defects that are not represented in the SDI dataset?', 'Can the authors provide more details on the exact modifications made to the StarGAN v2 architecture?', 'How does DT-GAN handle cases where the defect patterns in the source and reference images are highly dissimilar?', 'What are the potential negative societal impacts of the proposed method, and how can they be mitigated?', 'Can the authors clarify the training time and computational resources required for DT-GAN?', 'How does the performance of DT-GAN compare with other GANs when trained on a more diverse set of datasets?', 'What are the potential negative societal impacts of using synthetic data in defect detection?', 'Can the authors provide more details on how the method scales to different types of defects and industrial settings?', 'How does the proposed method perform on other datasets or in different industrial contexts?', 'Can the authors clarify some of the more technical aspects to improve accessibility for a broader audience?']","['The paper does not adequately address potential limitations or negative societal impacts, such as the misuse of synthetic data in quality control or manufacturing.', 'The handling of extremely rare defect types that were not seen during training is not discussed.', 'The heavy reliance on the SDI dataset limits the generalizability of the results.', 'The paper does not address how the model performs on defects not represented in the SDI dataset.', 'The potential negative societal impacts of generating synthetic images, such as misuse in deceptive contexts, are not addressed.', 'The methodology is complex and may be difficult to reproduce without further details.', 'The robustness and scalability of the approach to different types of defects and industrial settings are not fully explored.']",False,3,2,3,5,4,"['Innovative use of style-content separation and foreground-background disentanglement in GANs.', 'Addresses a real-world problem in automated visual inspection with limited defective samples.', 'Comprehensive experimental evaluation demonstrating improvements in defect detection tasks.', 'Effective ablation study demonstrating the importance of different components of the model.']","['The core methodology heavily relies on existing frameworks like StarGAN v2, with only incremental improvements.', 'Evaluation metrics (FID, KID) and qualitative assessments, while thorough, do not show groundbreaking improvements.', 'Dense and overly detailed explanations may overwhelm readers.', 'Limited discussion on potential limitations and negative societal impacts.', 'Heavy reliance on the SDI dataset, potentially limiting the generalizability of the results.', 'The clarity of the methodology section is lacking, making it difficult to understand the exact modifications and contributions.', 'Reproducibility is a concern as the code and dataset are not yet available.']",3,3,2,3,Reject
uHv20yi8saL,The paper introduces a theoretical framework for monotonic improvement guarantees in decentralized PPO for cooperative Multi-Agent Reinforcement Learning (MARL) under non-stationary conditions. It provides a theoretical foundation for the empirical success of IPPO and MAPPO by enforcing a centralized trust region constraint. The paper includes detailed theoretical analysis and empirical results validating the proposed hypotheses.,"['Can the authors provide more intuitive explanations for some of the dense theoretical content?', 'Are there any practical scenarios where the assumptions made in the theoretical analysis might not hold?', 'Could additional baselines be added to the empirical analysis for better contextualization?', 'Can the proposed theoretical analysis be extended to other MARL methods beyond IPPO and MAPPO?', 'Are there any specific challenges or limitations when applying the proposed trust region constraint to environments other than SMAC?', 'How sensitive are the empirical results to different hyperparameter settings, and what guidelines can be provided for practitioners?', 'Can the authors provide more intuition on how the clipping range should be tuned in practical, real-world MARL applications?', 'Have the authors considered other MARL benchmarks besides SMAC to further validate their theoretical claims?', 'What are the potential negative societal impacts of this work?', 'How does the proposed method compare to other state-of-the-art methods not mentioned in the paper?']","['The reliance on certain assumptions in the theoretical analysis.', 'The empirical results could be expanded with additional baselines and broader experimental scenarios.', 'The complexity of the theoretical analysis might limit its accessibility to a broader audience.', 'The paper does not discuss the potential negative societal impacts of the proposed approach.', 'There is a need for more practical guidance on tuning hyperparameters in real-world scenarios.']",False,3,3,4,7,4,"['Addresses a significant gap in MARL theory.', 'Provides a novel theoretical analysis for non-stationary transition dynamics in decentralized MARL.', 'Comprehensive empirical results supporting the theoretical claims.', 'Offers a theoretical foundation for proximal ratio clipping based on the number of agents.', 'Significant insights into the performance of IPPO and MAPPO, with practical guidelines for hyperparameter tuning.']","['Dense and challenging for readers without a strong MARL background.', 'Reliance on assumptions that may not hold in all practical scenarios.', 'Empirical analysis could benefit from additional baselines and broader experimental scenarios.', 'Theoretical proofs are complex and may require additional simplification or intuitive explanations.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",4,3,3,4,Accept
5FUq05QRc5b,"The paper provides a theoretical framework for understanding latent correlation-based multiview learning and self-supervised learning from an identifiability perspective. It introduces a generative model to explain how these methods can extract shared components and proposes regularizations to disentangle private components. The paper also includes finite sample analysis and practical implementation details, validated through experiments.","['Can the authors provide clearer and more detailed explanations for their proofs, particularly Theorems 1 and 2?', 'How robust are the experimental results? Can additional datasets and more extensive experiments be included?', 'What are the practical implications of the proposed method? Can the authors provide examples or case studies?', 'Can the authors provide more details on how the proposed methods perform on a wider range of real-world datasets?', 'Could the paper include more comparisons with state-of-the-art methods in the experiments?', 'Can the authors clarify some of the more complex theoretical concepts to make them more accessible to a broader audience?']","['The paper does not adequately address the limitations of the proposed method, particularly in terms of computational complexity and scalability.', 'Potential negative societal impacts are not discussed.', 'The practical applicability of the theoretical results is not well demonstrated.', 'The assumptions made in the theoretical analysis might not always hold in practical scenarios.']",False,3,2,3,5,4,"['Strong theoretical contribution with detailed proofs and finite sample analysis.', 'Novel approach to understanding and improving multiview and self-supervised learning methods.', 'Thorough experimental validation on synthetic and real datasets.']","['The clarity and organization of the paper could be improved.', 'The experimental results are limited and do not convincingly support the theoretical claims.', 'The practical implications and significance of the contributions are not well articulated.', 'Complex theoretical concepts could be explained more clearly for accessibility.']",3,3,2,3,Reject
Py8WbvKH_wv,"The paper introduces DRIBO, a novel technique for robust deep reinforcement learning using a Multi-View Information Bottleneck (MIB) approach. The proposed method aims to learn representations that focus on task-relevant dynamics and discard task-irrelevant information. The approach is validated with experiments on the DeepMind Control Suite and Procgen benchmarks, demonstrating state-of-the-art performance.","['Can the authors provide more details on the computational complexity of their method compared to existing approaches?', 'How sensitive is the proposed method to the choice of hyperparameters, especially the β parameter in the DRIBO loss?', 'Can you provide more intuitive explanations for the theoretical concepts and proofs to improve clarity?', 'Have you considered testing DRIBO on more diverse and complex environments to further validate its robustness and generalization capabilities?', 'What are the potential negative societal impacts and ethical considerations of applying DRIBO in real-world scenarios?', 'Can you provide more details on how DRIBO would perform in real-world scenarios?', 'Could you include more diverse baselines in your comparisons?', 'Can you provide more detailed ablation studies to isolate the impact of each component of DRIBO?']","['The method may not capture local features effectively, which can be a limitation in certain environments.', 'The current implementation only considers global mutual information, which might not be sufficient for all types of tasks.', 'The paper does not sufficiently address potential negative societal impacts and ethical considerations.', 'The empirical validation is limited to specific benchmarks and could benefit from more diverse and complex environments.', 'The complexity of the approach may hinder its adoption.']",False,3,3,3,6,4,"['Addresses a significant problem in reinforcement learning.', 'Proposes a novel method that is theoretically sound.', 'Comprehensive experiments demonstrate the efficacy of the approach.', 'Demonstrates state-of-the-art performance on challenging benchmarks.', 'Theoretical contributions include a novel MIB objective tailored for the sequential nature of RL.']","['The paper is dense and may be difficult for readers to follow.', 'The explanation of the MIB objective and its application to RL could be clearer.', 'Empirical results could benefit from more extensive comparisons with additional baselines.', 'Theoretical aspects are dense and challenging to follow.', 'Insufficient discussion on potential negative societal impacts and ethical considerations.', 'The clarity and quality of presentation could be improved, especially in the explanation of complex concepts.', 'The approach introduces significant complexity.', 'The applicability and performance in real-world scenarios are not addressed.', 'More detailed ablation studies would strengthen the claims about the importance of each component.']",4,3,3,3,Accept
R11xJsRjA-W,"The paper investigates the relationship between out-of-distribution (OOD) generalization and membership privacy in machine learning models. It finds that better OOD generalization does not necessarily imply better privacy. Instead, the privacy benefits are more related to the extent to which a model captures stable features. The paper provides empirical evidence from synthetic and real-world datasets to support its claims.","['Can the authors provide more theoretical insights or frameworks to support their empirical findings?', 'How do the authors suggest practitioners measure stable features in real-world applications where ground-truth is not known?', 'Can the authors clarify the practical implications of their findings for deploying ML models in sensitive domains?', 'How can the proposed methods be generalized to other types of privacy attacks?', 'What are the practical implications of the assumptions made, such as access to ground-truth pairs in Perfect-Match?']","['The paper could benefit from a stronger theoretical framework to support empirical findings.', ""The study's reliance on empirical results means it may not generalize well to all contexts."", 'Potential ethical concerns related to privacy in real-world applications are not deeply explored.', 'The assumptions made in certain methods (e.g., Perfect-Match) may limit their practical applicability.']",False,3,3,3,4,4,"['Novel investigation of the relationship between OOD generalization and membership privacy.', 'Thorough empirical study with multiple datasets.', 'Suggests using membership inference robustness as an additional metric for DG models.', 'Addresses an important and relatively unexplored intersection between OOD generalization and privacy.', 'Novel findings that stable features are a key indicator of privacy robustness.']","['Limited theoretical contributions.', 'High reliance on empirical results without a strong conceptual framework.', 'Some sections are dense and lack clarity.', 'The connection between theoretical claims and empirical results could be more robustly established.', 'Complex experimental setup may hinder reproducibility.']",3,3,3,3,Reject
5xEgrl_5FAJ,"The paper introduces BiBERT, a novel approach to fully binarize BERT, addressing the performance drop caused by information degradation in the attention mechanism and optimization direction mismatch. The proposed Bi-Attention structure maximizes representation information, and the Direction-Matching Distillation (DMD) scheme optimizes the model accurately. Extensive experiments on the GLUE benchmark show that BiBERT outperforms existing quantized BERT models.","['Can you provide more details on the hyperparameters and training setup?', 'How does BiBERT compare with more recent state-of-the-art quantized BERT models?', 'Can you clarify the mathematical formulations in the Bi-Attention section?', 'Could the authors provide more intuitive explanations for Bi-Attention and DMD?', 'How does BiBERT perform in terms of latency in real-world deployment scenarios?', 'Could the authors compare BiBERT with more baseline methods to strengthen the empirical validation?', 'How does the Bi-Attention structure compare to other attention mechanisms in terms of computational overhead during training and inference?', 'Can the authors provide more insights into how the Direction-Matching Distillation scheme could be generalized to other NLP models?', 'How does BiBERT perform on tasks not included in the GLUE benchmark?', 'What are the potential limitations or failure modes of the proposed approach?', 'Can the proposed methods be applied to other transformer models beyond BERT?', 'Can the authors provide more rigorous theoretical justifications for the proposed Bi-Attention and DMD methods?', 'How do the proposed methods compare with other state-of-the-art binarization techniques in terms of computational efficiency and performance?', 'Can the authors include more comprehensive ablation studies to isolate the effects of each component of their method?']","['The complexity of the proposed methods may limit their adoption in practice.', 'The paper lacks a detailed discussion on potential negative societal impacts.', 'The potential negative societal impacts of reduced model accuracy in critical applications should be discussed.']",False,3,3,3,5,4,"['The topic is highly relevant and important in the field of NLP.', 'Innovative technical contributions with Bi-Attention and DMD.', 'Comprehensive empirical validation with extensive experiments on the GLUE benchmark.']","['The paper is dense and challenging to read, especially in sections with mathematical formulations.', 'Additional comparisons with more recent state-of-the-art methods could strengthen the claims.', 'More detailed descriptions of the experimental setup, including hyperparameters and training details, could improve reproducibility.', 'The paper lacks a detailed discussion on potential negative societal impacts.']",4,3,3,4,Reject
iGffRQ9jQpQ,"The paper introduces a novel semi-supervised learning (SSL) framework called Self-interested Coalitional Learning (SCL), which aims to improve SSL by addressing over-reliance on labeled data and error accumulation in pseudo-labeling. The framework constructs a semi-cooperative game between a main SSL task and an auxiliary task of inferring label observability. The paper provides theoretical derivations and empirical evaluations to support the effectiveness of SCL.","['How does SCL compare with more recent state-of-the-art SSL methods beyond those mentioned in the paper?', 'Can the theoretical derivation of the additional loss term be validated with more rigorous proofs or empirical evidence?', 'How sensitive is the performance of SCL to the choice of hyperparameters, particularly the weight parameter α?', 'Can the authors provide more intuitive explanations or examples to make the mathematical derivations more accessible?', 'What are the potential limitations of the SCL framework, and how could they impact real-world applications?', 'Could the authors discuss any potential negative societal impacts of their work?', 'Can the authors provide more details on the complexity and computational cost of SCL?', 'What are the specific hyperparameter settings used in the experiments, and how were they chosen?']","['The empirical improvements, though consistent, are not always substantial compared to baseline methods.', 'The theoretical derivation of the loss term could be more rigorously validated.', 'Certain sections of the paper are dense and could benefit from clearer explanations.', 'The paper does not thoroughly discuss the limitations of the proposed method.', 'Potential negative societal impacts, such as biases in the pseudo-labels generated, are not addressed.', 'The dual-task optimization may introduce implementation complexity.', 'The framework requires comprehensive parameter tuning (e.g., the weight parameter α).', 'The paper does not adequately address potential negative societal impacts.', 'Complexity of the framework might limit its practical applicability in real-world scenarios.']",False,3,3,3,6,4,"['Novel framework combining main SSL task with an auxiliary task for label observability.', 'Theoretical connections to loss reweighting on noisy labels.', 'Comprehensive empirical evaluation across multiple SSL tasks.', 'Demonstrates improved robustness and performance in various settings.', 'Framework is general and can be applied to a variety of semi-supervised learning algorithms.']","['The idea of using auxiliary tasks in SSL is not entirely new and could be better differentiated from existing work.', 'The theoretical derivation of the loss term could be more rigorously validated.', 'Lacks detailed comparison with more recent state-of-the-art SSL methods.', 'Certain sections are dense and could benefit from clearer explanations.', 'Empirical improvements, though consistent, are not always substantial compared to baseline methods.', 'Mathematical derivations may be challenging to understand for readers without a strong mathematical background.', 'Limited discussion on limitations and potential negative societal impacts of the work.', 'Complexity in implementation due to dual-task optimization.', 'Some experimental details, such as hyperparameter settings and implementation specifics, are missing or not fully elaborated.']",3,3,3,3,Reject
bVT5w39X0a,"The paper introduces a Bayesian Relational Generative Model for scalable multi-modal learning, called multi-modal Relational Neural Process (mRNP). This model aims to address issues in existing multi-modal generative approaches by learning a graph of dependencies between samples across multi-modal data types and using a mixture-of-graphs (MoG) for joint posterior approximation. The paper claims improvements in prediction accuracy and uncertainty estimates over state-of-the-art methods.","['Can the authors provide more details on the scalability of the proposed method with very large datasets?', 'How do the authors ensure that the model does not perpetuate biases present in the training data, especially in sensitive applications like healthcare?', 'Can the authors provide more intuitive explanations or diagrams to improve clarity?', 'How does the method perform with varying sizes and qualities of the reference set?', 'Can the authors discuss potential negative societal impacts, particularly in the context of healthcare data?', 'Are there any additional experiments planned to cover more diverse scenarios and applications?', 'How does the model perform in real-time applications, particularly in terms of computational efficiency?', 'Can the authors provide more details on the hyperparameters and experimental setups to improve reproducibility?', 'How does the choice of reference samples (XR) affect the performance of mRNP, and is there a strategy for selecting these samples?']","['The scalability of the proposed method with very large datasets is not thoroughly discussed.', 'Ethical considerations need to be addressed, especially in healthcare applications.', 'Performance highly dependent on the quality and size of the reference set.', ""The model's complexity and scalability need further clarification."", ""More diverse experimental validation is required to fully establish the model's applicability."", 'Potential negative societal impacts have not been extensively discussed.', 'Limited details on hyperparameters and experimental setups hinder reproducibility.']",False,3,2,3,6,4,"['Novel combination of neural networks and stochastic processes for multi-modal learning.', 'High-quality theoretical analysis and empirical validation showing improved performance over state-of-the-art methods.', 'Potentially high impact on various fields requiring robust multi-modal learning.']","['Complex and dense mathematical exposition that is challenging to follow.', 'Scalability concerns with large datasets are not thoroughly discussed.', 'Insufficient discussion on potential negative societal impacts, particularly in sensitive applications like healthcare.', 'Limited details on hyperparameters and experimental setups hinder reproducibility.']",4,3,2,3,Reject
I2Hw58KHp8O,"The paper proposes the Conditional Masked Language Model with Correction (CMLMC) to improve non-autoregressive (NAR) translation models. It addresses issues of token indistinguishability and training-inference mismatch, showing significant performance improvements without the need for distillation. The model introduces modifications to the decoder and a novel correction loss, demonstrating state-of-the-art performance on multiple datasets.","['How does the proposed method perform on other sequence generation tasks beyond translation?', 'Can the authors provide more details on the computational overhead introduced by the masked attention layers and feed-forward networks?', 'How does the model perform with fewer iterations of the iterative refinement process?', 'Can the authors provide more theoretical insights into why the proposed architectural changes and loss functions lead to significant improvements?', 'Can more detailed ablation studies be provided to better understand the individual contributions of each modification?', 'What are the potential limitations of the proposed approach in real-world applications?', 'Can the authors discuss any potential negative societal impacts of their work?', 'How does the performance of CMLMC compare to AR models in terms of inference speed?', 'Are there any specific scenarios where CMLMC does not perform well compared to other NAR models?']","['The potential negative societal impacts of the work are not fully addressed.', ""Limited exploration of the method's generalizability to tasks other than translation."", 'The computational overhead and its impact on scalability for large datasets are not thoroughly discussed.', 'The increased complexity of the model may hinder its adoption in practical applications.']",False,3,3,3,7,4,"['Addresses key performance bottlenecks in NAR models.', 'Demonstrates significant empirical improvements over existing methods.', 'Detailed experimental validation on multiple datasets.', 'Proposes a novel loss function for error correction.', 'Eliminates the need for knowledge distillation in NAR models.']","['Potential overfitting to specific datasets.', 'Unclear generalizability to other tasks beyond NAR translation.', 'Additional computational overhead due to architectural modifications.', 'Limited discussion on the negative societal impacts of the work.', 'Some technical details could be explained more clearly.', 'The paper could benefit from a more detailed ablation study to isolate the impact of each modification.']",3,3,3,3,Accept
bilHNPhT6-,"The paper introduces Distillation of a Mixture of Experts (DiME), a novel multi-objective reinforcement learning (MORL) algorithm aimed at improving offline RL and finetuning scenarios. The authors critique traditional linear scalarization (LS) methods and propose DiME as a superior alternative, supported by theoretical derivations and empirical evaluations. DiME is shown to outperform existing methods through theoretical derivations and empirical experiments.","['Can the authors provide more details on how to set the hyperparameters for DiME, especially the trade-off parameter?', 'Are there any specific types of tasks or environments where DiME might not perform as well as indicated in the paper?', 'Can the authors clarify the computational cost of training DiME compared to other methods?', 'Can you provide more insights into the computational complexity and resource requirements of DiME compared to LS?', 'Have you explored the application of DiME in other real-world RL scenarios beyond the specified benchmarks?', 'How sensitive is DiME to the choice of hyperparameters, particularly the trade-off parameter α?', 'Can the authors provide more details on the potential limitations of DiME?', 'How does DiME perform in real-world applications with noisy data?', 'Can the authors discuss potential negative societal impacts of their approach?', 'Can the authors provide more detailed explanations or visualizations to improve the clarity of the methodology?', 'Are there any specific scenarios where DiME might not perform well?', 'How does DiME handle environments with significantly different scales of objectives?', 'Can the authors provide more details on the scalability of DiME, especially for large-scale RL problems?', 'When will the code be open-sourced to ensure reproducibility?']","['The authors should provide more discussion on the limitations of DiME, particularly in terms of scalability and generalizability to different RL tasks.', 'Potential negative societal impacts are not discussed in the paper. The authors should consider addressing this aspect in future work.', 'The complexity and scalability of DiME need to be addressed in future work.', 'More detailed comparative analysis with other advanced MORL methods would strengthen the paper.']",False,3,3,4,7,4,"['Clear motivation for using MORL to address challenges in RL.', 'Introduction of a new and theoretically grounded algorithm (DiME).', ""Empirical results showing DiME's superior performance over state-of-the-art methods."", 'Thorough experimental evaluation on multiple RL tasks and benchmarks.', 'Novel perspective on RL as a MORL problem.', 'Potentially impactful in advancing RL methodologies.']","['Complexity of the proposed method, which may hinder practical adoption.', 'Potential difficulty in reproducing results due to the lack of open-sourced code at the time of writing.', 'Some experimental results might not generalize well to different tasks or environments.', 'The paper is dense and could benefit from clearer explanations in some sections, particularly the derivations and algorithmic details.', 'High complexity of the proposed method might hinder reproducibility.', 'Limited discussion on the limitations and potential negative societal impacts.']",4,4,3,4,Accept
LQCUmLgFlR,The paper investigates the relationship between optimal early stopping time and model dimension/sample size in linear regression and deep neural networks. It provides theoretical results demonstrating different behaviors depending on whether the model is overparametrized or underparametrized. The authors also present experimental results to validate their theoretical findings.,"['Can the authors provide more rigorous validation of their theoretical results?', 'How do the findings compare with existing work on early stopping and double descent in more detail?', 'Can the authors clarify the mathematical notation and improve the explanations in the theoretical sections?', 'Have the authors considered applying their theoretical findings to a broader range of neural network architectures and datasets?', 'Could the authors discuss any potential negative societal impacts of their work in more detail?', 'Can the authors provide more details on the experimental setup for deep learning models?', 'How does the proposed method scale with very large datasets and models?', 'What are the specific hyperparameters and settings used in the experiments?', 'How do the authors justify the use of linear models for the theoretical analysis when deep learning models are inherently non-linear?', 'Can the authors provide additional experimental results on more diverse and realistic datasets?', 'How do the proposed methods perform under different types of noise and data distributions?']","['The paper does not thoroughly address potential negative societal impacts of its findings.', 'The practical applicability of the theoretical results in real-world scenarios is not fully explored.', 'Theoretical results may not directly translate to all practical scenarios.', 'The experiments may not cover all possible model architectures and datasets.', 'Potential negative societal impacts are not extensively discussed.']",False,3,2,3,4,4,"['Addresses an important and timely problem in machine learning.', 'Provides a theoretical framework to understand early stopping in overparametrized and underparametrized settings.', 'Experimental results are included to validate theoretical claims.']","['The novelty of the contributions may be incremental given existing works on early stopping and double descent.', 'Theoretical proofs and explanations are not always clear or rigorously validated.', 'Empirical results are not particularly strong or convincing.', 'The paper is dense and difficult to follow, with complex mathematical notation and explanations.', 'Limited discussion on societal impacts and practical applicability.']",3,3,2,3,Reject
rbFPSQHlllm,"The paper proposes AutoMO-Mixer, a model for medical image diagnosis that aims to balance sensitivity and specificity using multi-objective optimization, Bayesian optimization, and Evidential Reasoning (ER). The model is evaluated on two public datasets (brain tumor MRI and COVID-19 CT images) and claims to outperform traditional Mixer and CNN models.","['Can the authors provide more detailed explanations and visual aids for the training and testing stages?', 'How does the model performance vary with different values of hyperparameters?', 'What are the potential ethical implications of deploying this model in real-world scenarios?', 'Can the authors provide more details on the iterative multi-objective immune algorithm?', 'How are the weights for Pareto-optimal models calculated in more detail?', 'Can the authors provide variance or confidence intervals for the experimental results?', 'How were the ranges for the hyperparameters determined?', 'Can the authors include more datasets to validate the generalizability of the proposed method?', 'How does the proposed method compare to more recent state-of-the-art models in medical image analysis?', 'What measures are in place to prevent overfitting given the small dataset sizes?', 'Can the authors discuss the computational complexity and efficiency of their method?']","['Limited dataset evaluation might not generalize well to other medical image diagnosis tasks.', 'Potential ethical concerns regarding the deployment of automated diagnosis systems without human oversight.', 'The paper does not address the potential for overfitting given the relatively small size of the datasets used.', 'There is no discussion on the computational complexity and efficiency of the proposed method.', 'The societal impact of misdiagnoses, even with improved sensitivity and specificity, is not discussed.']",False,2,2,2,4,4,"['Addresses the critical issue of balancing sensitivity and specificity in medical diagnosis.', 'Proposes a novel combination of multi-objective optimization, Bayesian optimization, and Evidential Reasoning.', 'Shows promising experimental results on two public datasets.']","['The paper is poorly organized and has grammatical errors, making it difficult to understand.', 'Several methodological and technical details are unclear or insufficiently supported by theoretical or experimental analysis.', 'The novelty is limited as the concepts of balancing sensitivity and specificity, Bayesian optimization, and ER approach are not new.', 'Limited evaluation datasets; results are not validated on a diverse range of medical image datasets.', 'No discussion on limitations and potential negative societal impacts.']",3,2,2,3,Reject
ms7xJWbf8Ku,"The paper proposes efficient packing algorithms, SPFHP and NNLSHP, to minimize padding in BERT pretraining, achieving a 2x speed-up. The methods are validated on the Wikipedia dataset and show significant efficiency improvements. The paper also describes adjustments to the BERT model and hyperparameters to maintain accuracy with the packed datasets.","['How do the proposed packing methods perform on datasets other than Wikipedia, such as domain-specific corpora?', 'Can the packing algorithms be adapted for other NLP models beyond BERT, such as GPT or T5?', 'What are the practical challenges in implementing the proposed adjustments to the BERT model in widely-used frameworks like Hugging Face Transformers?', 'Can the authors provide more detailed pseudocode or implementation steps for reproducibility?', 'How would the proposed methods perform on datasets with different characteristics than Wikipedia and GLUE?', 'Can the authors discuss any potential negative societal impacts in more detail?']","['The paper does not fully address the limitations of the packing methods when applied to different datasets or NLP models.', 'Potential negative societal impacts related to the environmental cost of large-scale NLP training are acknowledged but not deeply explored.', 'The methods are primarily tested on Wikipedia and GLUE datasets; broader applicability is not thoroughly discussed.', 'Implementation complexity might pose challenges for other researchers.']",False,3,2,3,4,4,"['Novel approach to minimize padding in BERT pretraining, potentially leading to significant speed-ups.', 'Thorough experimental evaluation with detailed analysis of the packing algorithms and their impact on performance.', 'Clear description of the methods and adjustments needed for the BERT model.', 'Potential for reducing computational costs and environmental impact of NLP training.']","['The clarity of the paper is hampered by the dense and technical description, making it challenging for non-experts to follow.', 'The generalizability of the results to other datasets and NLP models is not thoroughly explored.', 'Potential ethical concerns related to the environmental impact and accessibility of computational resources are not fully addressed.', 'Some experimental results, such as the impact on downstream tasks and practical implementation challenges, are not sufficiently detailed.']",3,3,2,3,Reject
nwKXyFvaUm,"The paper introduces DivFL, a client selection strategy for federated learning that uses submodular maximization to select diverse clients. This aims to improve convergence, learning efficiency, and fairness. Theoretical analysis and extensive empirical evaluations are provided.","['How robust are the theoretical guarantees under practical deviations from the assumptions?', 'Can the authors provide more details on the potential negative societal impacts of their approach?', 'How does DivFL perform under different levels of data heterogeneity and in more diverse practical settings?', 'How does the method scale with the number of clients, especially in extremely large federated learning settings?', 'Can you provide more details on the communication overhead and how it affects practical implementation?', 'Are there results on more complex models or larger datasets to further validate the approach?', 'Can the authors provide more details on the communication-efficient variant of DivFL and its practical implementation?', 'How does DivFL perform compared to other state-of-the-art client selection methods not covered in this paper?', 'What are the potential limitations and societal impacts of DivFL, especially in terms of fairness and privacy?', 'How does the method perform with significantly larger client pools?', 'What are the computational overheads associated with the submodular maximization in practical deployments?', 'How does the method handle clients with drastically different computational capabilities?', 'Can the authors provide more intuition behind the mathematical derivations to improve clarity?', 'What are the computational overheads of the proposed method compared to traditional client selection methods?', 'How does the method perform in highly dynamic environments where client availability and data distribution change frequently?']","['Theoretical assumptions may not hold in real-world scenarios.', 'Scalability with the number of clients and communication overhead.', 'Need for gradient information from all clients could be impractical.', 'Lack of testing on very large datasets or more complex models.', 'Practical implementation and scalability of the communication-efficient variant need more elaboration.', 'Robustness of empirical results could be improved with more ablation studies and comparisons with a wider range of baselines.', 'Assumptions on periodic gradient updates may not be feasible in all scenarios.', 'Potential suboptimality due to stale gradients.', 'Computational overheads of the submodular maximization approach.', 'Real-world applicability and computational complexity not fully addressed.', 'Practical implications in dynamic environments are not explored.']",False,3,2,3,6,4,"['Novel use of submodular maximization for client selection.', 'Theoretical convergence analysis.', 'Extensive empirical evaluation on synthetic and real datasets.', 'Communication-efficient variant enhances practical applicability.']","['Theoretical analysis relies on assumptions that may not hold in practice.', 'Empirical results may suffer from potential overfitting.', 'Lack of detailed discussion on potential negative societal impacts.', 'Presentation could be clearer, especially in experimental results.', 'Scalability concerns due to the need for gradient information from all clients.', 'Practical challenges in real-world federated learning environments.', 'Lack of results on very large datasets or more complex models.', 'Complex mathematical derivations may not be accessible to all readers.']",4,3,3,3,Reject
anbBFlX1tJ1,"The paper introduces Boosted Curriculum Reinforcement Learning (BCRL), which approximates the action-value function as a sum of residuals trained on each task in the curriculum. This approach aims to increase the representativeness of the function approximator as new tasks are presented, promoting expressiveness and reusability of previous action-values. The paper provides a theoretical analysis within the approximate value iteration framework and empirical evaluations demonstrating the benefits of BCRL.","['Can you provide more details on the empirical setup and choice of baselines?', 'What are the computational overheads of BCRL compared to regular curriculum RL?', 'How does BCRL scale with the number of tasks and complexity of the function approximators?', 'Can the authors provide more empirical evidence across a broader range of environments to demonstrate the robustness of BCRL?', 'How does BCRL compare with other state-of-the-art curriculum RL methods in more complex, real-world tasks?', 'Can the authors simplify or better explain the theoretical contributions to make the paper more accessible?', 'Can the authors provide more intuitive explanations for the theoretical results to improve clarity?', 'How does BCRL perform in more complex and diverse benchmarks compared to recent state-of-the-art curriculum RL methods?', 'Can the authors discuss potential limitations or scenarios where BCRL might not perform well?', 'How does BCRL scale to more complex and diverse RL environments?', 'Could you provide more details on the computational cost of BCRL compared to other methods?', 'How does the choice of tasks in the curriculum affect the performance of BCRL?']","['The approach might be computationally intensive and may not scale well with a large number of tasks.', 'Potential issues with the practical applicability of the method due to its complexity.', 'The empirical validation seems controlled and might not cover a wide range of real-world scenarios.', 'The increased complexity due to the sum of residuals might lead to computational challenges in very long task sequences.', 'Limited evaluation on diverse and complex RL environments.']",False,3,2,3,5,4,"['Novel combination of boosting and curriculum RL.', 'Theoretical analysis supporting the proposed method.', 'Empirical results demonstrating improved performance.']","['Dense mathematical details that are hard to follow.', 'Lack of clarity in some sections, particularly in proofs and theoretical discussions.', 'Insufficient discussion on computational overhead and scalability.', 'Limited discussion on limitations and potential negative societal impacts.', 'Empirical validation may not sufficiently cover real-world scenarios.']",3,3,2,3,Reject
JVWB8QRUOi-,"The paper proposes a novel learning framework to promote stable cooperation in sequential social dilemmas (SSDs) by leveraging homophilic incentives. The authors identify second-order social dilemmas (2nd-SDs) as a key challenge and suggest using homophily to solve it. The proposed method is validated through theoretical analysis, a motivating example, and empirical experiments on SSDs like Cleanup and Harvest.","['Can the authors provide more detailed implementation steps to improve reproducibility?', 'How does the complexity of the proposed method affect its practical applicability?', 'Can the authors clarify the intuition behind some of the key equations and theoretical analyses?', 'How does the proposed method perform in real-world applications or more complex environments?', 'What are the computational requirements for the proposed approach?', 'Can the authors provide more clarity on the experimental setup and the interpretation of results?', 'How does the proposed method perform in environments with limited observability?', 'Can the authors provide more rigorous mathematical proofs for the claims made in complex scenarios?', 'How does the method handle delayed reward influences in the learning process?', 'Can the authors provide more details on the computational requirements and scalability of the proposed method?', 'How does the method perform in environments significantly different from the ones tested in the paper?', 'Can the authors provide more intuitive explanations or visualizations to help understand the theoretical analyses?']","[""The method requires observing other agents' environmental actions and their incentivizing actions towards all other agents, which might not always be feasible."", 'The effects of incentivizing actions could be delayed, potentially slowing down learning.', ""The approach's complexity might limit its practical applicability."", ""The experimental results are promising, but the methodology's generalizability is uncertain."", 'The formal analysis is dense and may not be accessible to all readers.', 'The complexity of the experimental setup and analysis could hinder reproducibility.', 'Lack of extensive theoretical proof in more complex settings.', 'No discussion on ethical considerations or potential societal impact.', 'The empirical validation is limited to specific scenarios and may not generalize well to all SSDs.', 'Theoretical analysis lacks rigor in some parts, making the claims less robust.', 'The potential delayed reward influence in incentivizing actions could lead to slow learning.', 'The complexity of the method might hinder its applicability in real-world scenarios without significant computational resources.']",False,3,2,3,5,4,"['Novel approach to promoting stable cooperation in SSDs.', 'Thorough theoretical analysis and motivating example.', 'Extensive experiments demonstrating the effectiveness of the proposed method.', 'Addresses an important problem in multi-agent reinforcement learning (MARL).']","['Some parts of the paper are unclear and difficult to follow.', 'Potential reproducibility issues due to complex method and lack of detailed implementation steps.', 'The proposed method is quite complex and might be difficult to implement for practitioners.', 'Dense and difficult-to-follow narrative.', 'Complex formal analysis that may not be fully comprehensible to all readers.', 'Implementation details are obfuscated, affecting reproducibility and evaluation.', 'Practical applicability of the proposed method remains uncertain.', 'Heavy reliance on empirical validation with limited theoretical proof in complex settings.', 'Lack of discussion on ethical implications and potential social impact.']",3,3,2,3,Reject
dEelotBE6e2,"The paper proposes a defense against backdoor attacks in neural networks using ensembles of weak learners. It introduces a novel iterative training procedure to identify and exclude poisoned data based on a bootstrapped measure of generalization. The approach is theoretically grounded in the concept of self-expanding sets and empirically validated on CIFAR-10, showing significant improvement over existing defenses.","['Can the method generalize to other datasets beyond CIFAR-10?', 'How does the method perform under different backdoor attack types?', 'What are the computational overheads compared to existing defenses?', 'How does the method handle cases where poisoned and clean data are not easily separable?', 'How do the theoretical assumptions hold up in more complex and varied real-world datasets?', 'Can the method be optimized to reduce computational complexity and improve practical applicability?', 'How does the proposed method compare with more recent defenses introduced in the literature post-2019?', 'Can the authors provide more detailed explanations and clarifications for the Inverse Self-Paced Learning algorithm?', 'Can additional baselines be included for comparison?']","['Needs more discussion on potential overfitting to specific datasets.', ""Lacks exploration of the method's performance under diverse backdoor attack scenarios."", 'Limited analysis of computational complexity and scalability.', 'Insufficient discussion on broader societal impacts and ethical considerations.', 'Theoretical assumptions may not be practical in all real-world scenarios, which could limit the generalizability of the method.', 'The high computational cost of the method should be addressed with possible optimizations or alternatives.', 'A broader comparison with recent methods is necessary for a comprehensive evaluation.']",False,3,3,3,6,4,"['Novel concept of self-expanding sets.', 'Theoretical grounding and proofs provided.', 'Comprehensive experimental evaluation demonstrating significant improvements over existing defenses.', 'Addresses a critical security issue in machine learning deployment.']","['Clarity issues in presenting complex theoretical concepts.', 'Potential overfitting to CIFAR-10 dataset.', 'Limited discussion on generalization to other datasets and real-world scenarios.', 'Insufficient discussion on limitations and societal impacts.', 'Complex methodology with several assumptions that are not thoroughly validated.', 'The approach might be computationally intensive due to the iterative nature of the algorithm.']",4,3,3,3,Reject
FndDxSz3LxQ,"The paper presents a novel distributed algorithm for training Graph Neural Networks (GNNs) called 'Learn Locally, Correct Globally' (LLCG). The method aims to reduce communication and memory overhead by training GNNs locally on subgraphs and refining the model globally to correct errors due to the lack of global graph structure in local models. The paper includes theoretical analysis to show the convergence of the method and extensive empirical validation on real-world datasets.","['Could the authors provide a direct link to the GitHub repository with detailed instructions for reproducing the experiments?', 'Can the authors elaborate on the hyperparameter tuning process and provide more details on the hardware configuration used for experiments?', ""Could the authors clarify why certain existing methods' results could not be reproduced and how this might affect the comparison?"", 'Can you provide more details on the scalability of LLCG to extremely large graphs?', 'How does LLCG perform compared to other state-of-the-art methods not included in the baselines?', 'Can you elaborate on the potential negative societal impacts of your work?', 'Can you elaborate on the trusted server assumption and potential alternatives if such a server is not available?', 'How does the method perform with highly heterogeneous graphs in terms of node features and connectivity?', 'What are the computational overheads associated with the global server corrections, and how do they scale with the size of the graph?', 'How does LLCG perform in a real-world distributed environment with actual network latency?', 'What are the limitations of the proposed method in terms of scalability and model complexity?']","['The paper mentions that some results of existing methods could not be reproduced, which could affect the robustness of the experimental comparisons.', 'There are concerns about reproducibility due to the lack of specific details or links to the provided GitHub repository.', 'The paper does not adequately discuss the potential negative societal impacts of the work, such as privacy concerns in distributed settings.', 'The scalability of LLCG to extremely large graphs is not thoroughly evaluated.', 'The method relies on a trusted server for global corrections, which might not be practical in all settings.', 'Assumptions in the theoretical analysis may not hold universally, potentially affecting the generalizability of the results.', 'The complexity of real-world implementation and integration with existing distributed systems is not fully addressed.', ""The method's complexity might limit its scalability to very large graphs."", 'Real-world applicability might be constrained due to the simulated experimental setup.']",False,3,3,3,6,4,"['The paper introduces a novel approach to distributed GNN training that effectively addresses communication and memory overhead issues.', 'It provides a rigorous theoretical analysis on the convergence of the proposed method.', 'Extensive experiments on real-world datasets demonstrate the efficiency and effectiveness of the proposed method compared to existing baselines.']","['Reproducibility concerns due to the lack of specific details or links to the provided GitHub repository.', 'The paper mentions difficulties in reproducing results from some existing methods, raising questions about the robustness of the experimental setup.', 'Some implementation details, such as hyperparameter tuning and hardware configuration, are insufficiently detailed.', 'The novelty of the method could be emphasized more clearly.', 'Theoretical analysis needs to be strengthened.', 'Potential negative societal impacts are not adequately discussed.', 'Limited discussion on the scalability to extremely large graphs.', 'The paper assumes access to a trusted server, which might not be feasible in all scenarios.', 'The complexity and practicality of implementing LLCG in real-world distributed systems are not thoroughly discussed.', 'Some assumptions in the theoretical analysis (e.g., stochastic gradient variance bounds) may not hold in practical scenarios.', 'Experimental setup uses simulated distributed environments, which may not fully capture real-world scenarios.']",3,3,3,3,Reject
HRL6el2SBQ,"The paper proposes intra-class mixup supplemented with angular margin to improve out-of-distribution (OoD) detection. The method aims to reduce angular spread in latent representations of in-distribution (ID) data, thereby improving separability from OoD data. The approach shows empirical improvements in AUROC performance over empirical risk minimization (ERM) and inter-class mixup methods.","['Can the authors provide a more rigorous theoretical justification for the use of angular margin?', 'How is the angular margin computed in practice, and what are the computational costs associated with it?', 'Can the authors provide more details on the experimental setup, such as dataset splits, hyperparameter settings, and hardware used?', 'How does the proposed method perform on other types of neural networks besides ResNet18?', 'Can the authors discuss any potential limitations or failure cases of the proposed method?', 'How does the proposed method perform on non-image datasets, such as text or tabular data?', 'What are the potential negative impacts of using intra-class mixup in real-world applications?']","['The paper does not thoroughly discuss the computational costs or potential negative impacts of the proposed method.', 'The potential negative societal impacts, such as biases introduced by the intra-class mixup, are not discussed.', 'The paper does not address the potential limitations of the proposed approach, such as its scalability to larger datasets or its applicability to different types of data.']",False,3,3,3,6,4,"['Novel combination of intra-class mixup and angular margin for OoD detection.', 'Empirical results demonstrate improvement in AUROC performance over baseline methods.', 'Comprehensive experimental evaluation.', 'Clear problem definition and motivation.']","['The theoretical justification for the proposed method is weak and lacks rigor.', 'The exact computation and definition of angular margin are not clearly explained.', 'The experimental setup and methodology are not clearly presented, making it difficult to fully understand and reproduce the results.', 'Limited discussion on potential limitations and societal impacts.', 'Some sections of the paper, particularly the results tables, are cluttered and hard to follow.']",3,3,3,3,Reject
t1QXzSGwr9,"The paper proposes a novel framework for image classification using quantum neural networks (QNNs) with a new encoding mechanism that allows for the classification of larger images (up to 16x16 pixels) on quantum systems. The main contributions include a new image encoding scheme, the introduction of CRADL and CRAML QNN layers, and experimental results showing comparable accuracy to classical neural networks on smaller images.","['Can you provide more details on the error analysis for the 16x16 images?', 'How does the performance of your method scale with even larger images?', 'Have you considered the impact of noise and other quantum hardware limitations on your results?', 'How does the proposed method compare with more advanced classical models like convolutional neural networks (CNNs) or other state-of-the-art methods?', 'What are the specific challenges and potential solutions for scaling the proposed method to even larger image sizes?', 'Can the authors provide more details on the stability issues observed when using further compression?', 'Can the authors provide more detailed comparisons with classical methods on larger datasets?', 'What are the specific challenges in scaling this approach to more complex datasets and higher resolutions?', 'Can the authors discuss potential strategies to mitigate the exponential complexity in qubit requirements?', 'What are the implications of the results for practical quantum computing applications?', 'Can the authors provide more details on the potential scalability of the method?', 'How does the proposed encoding mechanism compare to other recent advances in quantum image compression?', 'What are the specific limitations of the current quantum hardware that affected the experiments?', 'Can the authors provide more details on the computational complexity and scalability of their approach?']","['The performance on larger images is not competitive with classical methods.', 'The paper does not address the impact of quantum hardware limitations, such as noise and decoherence, on the results.', 'The work is limited to small-scale experiments on the MNIST dataset.', 'There are significant challenges in practical implementation due to the exponential increase in the number of qubits required.', 'The paper lacks a comprehensive discussion on the limitations and potential negative societal impacts of the proposed methods.', 'The evaluation is limited to a personal laptop, which may not scale to larger datasets or more complex tasks.', 'The compression technique for reducing qubits results in degraded performance, indicating a trade-off that needs further exploration.', 'Potential negative societal impacts of quantum computing advancements, such as ethical concerns around quantum technology, should be discussed.']",False,2,3,2,3,4,"['Innovative approach to extend QNNs to larger images.', 'Introduction of novel QNN layers (CRADL and CRAML).', 'Potential for significant advancements in quantum machine learning.']","['Performance on larger images (16x16) is not competitive with classical methods.', 'Lack of detailed error analysis and robustness checks.', 'The paper is dense and occasionally hard to follow, especially in terms of mathematical notation.', 'Limited evaluation on a small dataset and few experiments.', 'Practical challenges in physical realization due to exponential complexity in qubit requirements.', 'The results are not convincingly better than classical methods, given the current limitations of quantum computing.']",3,2,3,2,Reject
e0uknAgETh,The paper investigates the vulnerability of Spiking Neural Networks (SNNs) to adversarial attacks by adapting existing white-box attack algorithms for event-based visual data. It tests these methods on the N-MNIST and IBM Gestures datasets and validates them on neuromorphic hardware. The study finds that these attacks can successfully mislead SNNs with minimal perturbations.,"['Can you provide more details on how the attack methods were adapted specifically for event-based data?', 'What are the broader implications of these findings for the deployment of SNNs in real-world applications?', 'How do the results compare with other state-of-the-art adversarial attack methods not discussed in the paper?', 'Can the authors provide more details on the neuromorphic hardware used for validation, including its specifications and limitations?', 'How do the proposed adaptations of the attack algorithms compare to other possible adaptations or novel algorithms designed specifically for SNNs?', 'Can the authors include more ablation studies to better understand the contributions of different components in their approach?', 'What are the potential defenses against the proposed adversarial attacks, and how effective might they be?', 'Can the authors provide more details on the practical implications of their findings in real-world scenarios?', 'What potential defenses could be developed against these adversarial attacks?', 'How does the performance of the proposed attacks compare to state-of-the-art methods in terms of computational efficiency?', 'How can the proposed attack methods be extended or adapted for real-time applications?', 'What are the specific challenges in applying these adversarial attacks to other types of neuromorphic sensors (e.g., auditory or tactile)?', 'Can the authors elaborate on potential defense mechanisms and their effectiveness in mitigating the demonstrated attacks?', 'Can the authors provide more details on the construction and evaluation of adversarial patches?', 'What are the potential societal impacts of deploying vulnerable SNNs in real-world applications?', 'Can the authors discuss additional defense mechanisms that could be explored beyond the preliminary TRADES method?']","['The paper does not thoroughly discuss the limitations of the proposed methods, particularly in terms of scalability and generalizability.', 'Potential negative societal impacts, such as the misuse of adversarial attacks in critical systems, are not adequately addressed.', 'The paper does not sufficiently discuss potential defenses against the proposed adversarial attacks, which is crucial for practical applications.', 'There is a potential conflict of interest, as some authors are employed by the neuromorphic chip manufacturer, which could bias the results.', 'The paper does not fully explore the real-world implications of the proposed attacks.', 'The ethical considerations section is brief and does not comprehensively address the potential negative societal impacts of the work.', 'The evaluation is limited to a few datasets, which might not fully capture the robustness of the proposed methods.']",False,3,2,3,5,4,"['Addresses a novel and relevant problem of adversarial attacks in the context of spiking neural networks and event-based data.', 'Adapted existing attack algorithms to suit the discrete and temporal nature of event-based data.', 'Validated the attacks on neuromorphic hardware, demonstrating practical relevance.', 'Comprehensive experiments on multiple datasets including NMNIST and IBM Gestures.', ""Provides detailed results and analysis of the attacks' effectiveness and scalability.""]","['Clarity issues, particularly in the methods and results sections.', 'Limited discussion on the broader implications and applications of the findings.', 'Incomplete discussion on limitations and potential negative societal impacts.', 'The novelty of the contributions is somewhat limited, as it mostly involves adapting existing algorithms.', 'The evaluation could be more comprehensive, including comparisons with more baselines and ablation studies.', 'Does not sufficiently address potential defenses or mitigation strategies against the proposed attacks.']",3,3,2,3,Reject
8XM-AXMnAk_,"The paper proposes dynamicAL, a theory-driven deep active learning method that selects samples to maximize training dynamics, leveraging the Neural Tangent Kernel (NTK) framework to improve generalization. Theoretical analyses and empirical results are provided to support the effectiveness of the method.","['How does the performance of dynamicAL change with different network architectures that are not ultra-wide?', 'Can the authors provide more details on the computational complexity and runtime comparisons with baselines?', 'What are the potential limitations and negative societal impacts of dynamicAL?', 'Can the authors provide more insights into how dynamicAL performs on non-image datasets?', 'How does pseudo-labeling affect the performance of dynamicAL in the presence of noisy labels?']","['The method relies on the NTK framework, which may limit its applicability to ultra-wide networks.', 'The empirical results do not demonstrate a clear and consistent advantage over state-of-the-art methods in all tested settings.', 'There is no discussion on the potential negative societal impacts of the proposed method.', ""The method's reliance on pseudo-labeling might introduce biases, especially in noisy label scenarios."", 'Complex theoretical concepts may limit accessibility to a broader audience.', 'The approach assumes a relatively small initial set, which might not always be feasible.', 'Scalability issues in real-world scenarios where retraining might be necessary.']",False,3,3,3,6,4,"['Theoretical foundation using the NTK framework.', 'Scalable method employing pseudo-labeling and subset approximation.', 'Empirical results show some improvement over several baselines.']","['Heavy reliance on the NTK framework, which may not always apply in practical deep learning settings.', 'Clarity issues, making the paper difficult to follow.', 'Limited novelty in approximation techniques.', 'Potential biases due to pseudo-labeling, especially with noisy labels.', 'Lack of thorough discussion on limitations and societal impacts.']",3,3,3,3,Reject
qZNw8Ao_BIC,"The paper investigates the robustness of Vision Transformers (ViTs) and identifies a reliance on non-robust features. It proposes patch-based negative augmentation techniques to reduce this reliance, demonstrating improved robustness across various benchmarks without sacrificing in-distribution accuracy.","['Can you provide more detailed explanations of the mathematical formulations?', 'Have you tested the proposed methods on datasets other than the ones mentioned (ImageNet-A, ImageNet-C, ImageNet-R)?', 'Can the range of negative transformations be expanded to include more diverse types?', 'Can the authors provide more details on the potential limitations of their approach?', 'How do the authors envision the societal impact of deploying robust ViTs in real-world applications?', 'Could the proposed method be extended to other types of neural network architectures?', 'Can the authors provide more details on the choice of hyperparameters and their impact on the results?', 'Are there any specific failure cases or limitations observed with the proposed negative augmentation technique?', 'Could you elaborate on how your method compares with other state-of-the-art robustness techniques for ViTs?']","['The paper primarily focuses on a few types of patch-based transformations. A broader range could provide more insights.', ""The robustness improvements are shown on specific benchmarks, and it's uncertain if these generalize well."", 'The paper does not thoroughly discuss the potential negative societal impacts of making models more robust, such as misuse in surveillance or biased decision-making.', 'The robustness improvement is demonstrated on ImageNet-based benchmarks, but it is unclear if the method generalizes well to other datasets or tasks.', 'The paper could discuss more about the computational overhead introduced by the negative data augmentation.']",False,3,3,3,7,4,"['Identifies a unique weakness in ViTs related to non-robust feature reliance.', 'Proposes a novel training method using patch-based negative augmentations.', 'Shows consistent improvement in robustness across multiple benchmarks.', 'Complementary to existing positive augmentation techniques.', 'Comprehensive and well-conducted experiments.']","['The paper is dense and complex, making it challenging to follow.', 'Limited scope of negative transformations.', 'Potential overfitting to specific robustness benchmarks.', 'Limited discussion on societal implications of robust vision models.', 'Some sections lack clarity, especially in the detailed methodology and parameter settings.']",4,3,3,4,Accept
RLtqs6pzj1-,"The paper introduces FreeTickets, a framework for creating efficient deep learning ensembles using dynamic sparse training (DST). The approach involves training sparse neural networks from scratch and using these subnetworks to form an ensemble. The authors present two methods: DST Ensemble, which trains multiple sparse networks independently, and EDST Ensemble, which generates multiple subnetworks sequentially in a single training run. The framework achieves superior performance in terms of prediction accuracy, uncertainty estimation, out-of-distribution robustness, and computational efficiency compared to traditional dense ensembles.","['Can the authors provide more details on the impact of different hyperparameters on the performance of FreeTickets?', 'How does the performance of FreeTickets vary across different datasets and tasks?', 'Are there any specific strategies to improve the scalability of the proposed methods for very large models?', 'Can the authors provide more theoretical insights into why sparse subnetworks achieve high diversity and performance?', 'How generalizable are the results to other neural network architectures and datasets not covered in the experiments?', 'What are the potential negative societal impacts of the proposed methods, if any?']","['The paper does not extensively explore the performance of FreeTickets on a variety of datasets and tasks.', 'Reproducibility might be challenging due to the complex nature of dynamic sparse training methods.', 'The impact of hyperparameters on performance is not thoroughly discussed.', 'The paper could benefit from a deeper theoretical analysis to explain the observed empirical results.', 'Limited discussion on the generalizability of the methods to different architectures and datasets.', 'Potential ethical concerns related to the environmental impact of training large-scale models could be addressed more thoroughly.']",False,3,3,3,7,4,"['Novel and efficient approach to ensemble learning using dynamic sparse training.', 'Thorough experimental validation demonstrating significant improvements in multiple performance metrics.', 'Clear and well-organized presentation of methods and results.', ""Detailed analysis of subnetworks' diversity and ensemble performance."", 'Public release of source code to facilitate reproducibility.']","['Limited discussion on the impact of hyperparameters on performance.', 'Reproducibility may be challenging due to the complexity of DST methods.', 'The performance on other datasets and tasks is not extensively explored.', 'Potential scalability issues for extremely large models or datasets.', 'Limited theoretical analysis explaining why sparse subnetworks achieve high diversity and performance.', 'Some sections of the paper, especially algorithmic details, could be clearer.', 'Potential negative societal impacts and limitations are not adequately addressed.']",4,3,3,3,Accept
kHNKTO2sYH,"The paper proposes Clean Subspace Variational Autoencoder (CLSVAE), a novel semi-supervised model for detecting and repairing systematic outliers in datasets. The method partitions the latent space into clean and dirty subspaces and demonstrates superior performance with minimal labeled data. Experiments are conducted on three image datasets, showing improved results over several baseline models.","['Can the authors provide more details on the limitations and potential negative societal impacts of their work?', 'How does the proposed model perform on non-image data or real-world datasets?', 'Can the authors clarify the practical significance and broader impact of their method?', 'Can the authors provide more details on the computational complexity and runtime of CLSVAE compared to the baselines?', 'What measures are taken to ensure the reproducibility of the results?', 'Can you provide more intuitive explanations or illustrations for the method?', 'Have you considered testing the method on a broader range of datasets?', 'Can you discuss the computational complexity of CLSVAE compared to other methods?', 'What measures have been taken to ensure the scalability of the model to larger datasets?', 'Can the authors elaborate on the potential limitations or biases introduced by the specific choice of datasets?']","['The paper does not adequately address the limitations and potential negative societal impacts.', ""The method's robustness in real-world applications with varied data types is not demonstrated."", 'Potential issues with scalability and computational efficiency are not addressed.', 'The impact of the model on non-image data is not explored.', 'The experiments are limited to image datasets, so the applicability to other types of data is not demonstrated.', 'There is a need for more discussion on the potential biases introduced by the specific choice of datasets and systematic errors.']",False,3,2,3,6,4,"['Novel approach to partitioning latent space into clean and dirty subspaces.', 'Thorough experimental validation on multiple datasets.', 'Effective performance with minimal labeled data.', 'Addresses an important problem in data cleaning.']","['Limited discussion on potential limitations and negative societal impact.', 'Overly dense and complex presentation, making it difficult to follow.', 'Focus on image data limits the generalizability of the conclusions.', 'Practical significance and broader impact are not clearly articulated.', 'Complexity of the model and potential difficulty in reproduction.', 'Insufficient clarity in some sections of the paper, making it harder to follow.', 'Comparison with state-of-the-art methods could be more comprehensive.', 'Lacks discussion on computational complexity.']",3,3,2,3,Reject
izj68lUcBpt,"The paper introduces Temporally-Adaptive Convolutions (TAdaConv) for video understanding, which dynamically calibrates convolution weights for each frame based on its temporal context. The method is evaluated on multiple video action recognition and localization benchmarks, showing significant improvements over state-of-the-art methods with minimal computational overhead.","['Can the authors provide more detailed theoretical justifications for the proposed method?', 'Could the calibration weight generation process be explained with more clarity and additional diagrams?', 'What are the potential limitations and negative societal impacts of this work?', 'Can the authors provide more details on the initialization strategy for calibration weights and its impact on performance?', 'How does TAdaConv perform in scenarios where pre-trained models are not available or applicable?', 'Can the authors discuss any potential negative societal impacts of their work?', 'How does the method perform on smaller datasets or in resource-constrained environments?']","['The paper does not sufficiently address the potential negative societal impacts of its method.', 'Theoretical justifications for the proposed approach are lacking in depth.', 'The initialization strategy may not be effective for all types of video data.', 'The method may not generalize well to other types of temporal data outside of video understanding.']",False,3,3,3,7,4,"['Innovative approach to temporal modeling by dynamically adapting convolution weights based on temporal context.', 'Demonstrates significant improvements on multiple video action recognition benchmarks.', 'Plug-and-play nature allows easy integration into existing models.', 'Comprehensive experimental evaluation on multiple large-scale video datasets.', 'Detailed ablation studies and plug-in evaluations showing the impact of various components of the proposed method.']","['Mathematical formulations and theoretical justifications could be more rigorous.', 'Some explanations, particularly around calibration weight generation, could be clearer.', 'Limited discussion on potential negative societal impacts.', 'Missing experimental details and ablations that could affect reproducibility.', 'Reliance on existing pre-trained models might limit applicability in certain scenarios.']",3,3,3,4,Accept
dzZQEvQ6dRK,"The paper explores the use of contrastive learning methods, specifically BYOL, for disentangled representation learning. The authors introduce the concept of 'group disentanglement' and empirically demonstrate its effectiveness on multiple benchmarks, including both synthetic and real-world datasets.","['Can the authors provide a stronger theoretical basis for the observed disentanglement properties?', ""How does 'group disentanglement' fundamentally differ from existing concepts?"", 'Can the authors provide more clarity on the limitations of their approach, especially regarding real-world applicability?', 'How sensitive are the results to changes in hyperparameters?', ""Can you elaborate on the potential practical applications of 'group disentanglement' in real-world scenarios?"", 'How does the method perform on datasets not included in the paper?', ""Can you provide a more formal definition of 'group disentanglement'?"", 'Are there theoretical insights that can support the observed empirical results?', 'Can you discuss any potential limitations or failure modes of the proposed approach?', 'What specific steps can be taken to improve the clarity and reproducibility of the methodology?', ""How can 'group disentanglement' be generalized and applied to other models or datasets?"", 'What are the specific limitations of the proposed approach in terms of scalability and robustness?', 'Why does the method perform poorly on certain benchmarks like Shapes3D?', ""How does 'group disentanglement' compare to traditional disentanglement in practical downstream tasks?""]","['The study heavily relies on synthetic datasets, which may not fully capture the complexity of real-world scenarios.', 'The theoretical foundation for the findings is weak, relying mainly on empirical evidence.', ""The paper does not address the potential limitations of the 'group disentanglement' concept."", 'There is no discussion on the possible negative societal impacts of the proposed method.', 'The scalability of the proposed method to even larger real-world datasets remains uncertain.', 'The method may not generalize well to all types of datasets, as shown by the poor performance on Shapes3D.']",False,3,3,3,5,4,"['Addresses an important problem in representation learning.', 'Comprehensive empirical evaluation on multiple benchmarks.', ""Introduction of the concept of 'group disentanglement.'"", 'Evaluation on both synthetic and real-world datasets.']","['Weak theoretical foundation for why and how contrastive methods achieve disentanglement.', ""The novelty of 'group disentanglement' is questionable."", 'Heavy reliance on synthetic datasets.', 'Dense and sometimes unclear exposition.', 'Inadequate discussion of limitations and generalizability.', 'Mixed performance on different benchmarks, questioning generalizability.']",3,3,3,3,Reject
bgAS1ZvveZ,"The paper introduces a novel method for reinforcement learning by using a lower bound on the value function to improve the Bellman value target. This approach is theoretically proven to converge to the optimal value in the tabular case and demonstrates improved sample efficiency in various tasks, including Atari games, FetchEnv tasks, and physically simulated car tasks. The method is compared against baselines like TD3, SAC, and HER.","['Can the authors provide more clarity on how the method performs in stochastic environments?', 'How does the method compare statistically to the baselines across multiple runs?', 'Can the authors elaborate on any potential limitations or negative impacts of this method?', 'Can the authors provide more details on the practical implementation of lower bounds in non-deterministic environments?', 'How does the performance of the proposed method compare with other recent advancements in value estimation techniques?', 'Can you provide more details on the computational overhead introduced by the proposed method compared to the baselines?', 'How does the proposed method perform in highly stochastic environments where the empirical returns might not be reliable lower bounds?', 'Can the proposed method be integrated with other advanced RL techniques such as model-based RL or meta-learning?', 'Are there any specific types of tasks or environments where the proposed method fails to provide significant improvements?', 'Can the authors provide more ablation studies to isolate the contributions of different components?', 'How does the method compare with other state-of-the-art RL techniques not included in the paper?', 'Can the authors provide more detailed empirical results to support the claim of improved learning speed?', 'Could the authors elaborate on any potential negative societal impacts of the proposed method?']","[""The method's applicability to stochastic and partially observable environments is not clear."", 'The potential for value overestimation in stochastic environments needs more investigation.', 'The paper lacks a detailed discussion on the computational complexity of the proposed method.', 'The approach relies on deterministic environments for some lower bounds, limiting its applicability.', 'Practical implementation complexity in non-deterministic environments.', 'Potential overestimation issues in stochastic environments as discussed in the paper.', 'The use of empirical returns as lower bounds in stochastic environments can lead to overestimation.', 'The impact on computational efficiency and scalability is not thoroughly discussed.', 'The potential negative societal impacts are not addressed in detail.']",False,3,3,3,5,4,"['The method is novel and theoretically sound for tabular RL.', 'Extensive experiments across various tasks show improved sample efficiency.', 'The method requires minimal additional computation and no parameter tuning.', 'Well-documented comparison with several existing RL baselines.', 'Theoretical proof of convergence to the optimal value.', 'Clear reproducibility statement and detailed hyperparameter settings.']","[""The paper's clarity and organization could be improved, especially in the theoretical sections."", 'The practical applicability in stochastic environments is not sufficiently addressed.', 'The empirical results, while promising, lack thorough statistical analysis.', 'The paper does not adequately discuss limitations and potential negative impacts.', 'Dependence on deterministic environments for some lower bounds.', 'Complex practical implementation for estimating bounds in non-deterministic tasks.', 'Limited diversity in evaluation metrics.', 'Might benefit from including more recent baselines for a fair comparison.', 'Insufficient discussion on the assumptions and limitations of using empirical returns as lower bounds, especially in stochastic environments.']",3,3,3,3,Reject
biyvmQe5jM,"The paper introduces ABEL, an automatic learning rate scheduler that uses weight norm dynamics to determine when to decay the learning rate. It shows that complex learning rate schedules are beneficial mainly when the weight norm exhibits bouncing behavior. ABEL is proposed as a robust alternative that adapts to these dynamics, reducing the need for extensive hyperparameter tuning. The paper provides extensive experiments in vision, NLP, and RL to support these claims. The authors argue that ABEL performs comparably to fine-tuned schedules and is more robust with respect to its parameters.","['Can you provide a more robust theoretical justification for the connection between weight norm bouncing and the necessity for learning rate decay?', 'Have you tested ABEL in scenarios with different types of neural network architectures and datasets not covered in the paper?', 'Can you elaborate on any potential limitations or edge cases where ABEL might not perform well compared to traditional learning rate schedules?', 'Can you provide more details on the specific hyperparameters used for ABEL in each of the experiments?', 'How does ABEL perform compared to other adaptive learning rate methods not covered in this paper?']","['The paper does not address potential edge cases or limitations where ABEL might not perform as intended.', 'The societal impact of this work is not discussed, although it is likely minimal given the nature of the research.', 'Potential computational overhead of monitoring the weight norm is not addressed.']",False,3,3,3,5,4,"['Addresses a relevant and practical problem in deep learning optimization.', 'Provides substantial empirical evidence through experiments on various tasks.', 'Introduces a novel adaptive method (ABEL) that potentially reduces the need for manual tuning of learning rate schedules.', 'Robustness to hyperparameter variations.']","['The theoretical justification for the connection between weight norm bouncing and learning rate decay is weak.', 'The empirical results show that ABEL performs comparably to existing methods but does not demonstrate significant improvement.', 'The scope of experiments, while extensive, may not cover all relevant scenarios and variations in hyperparameters.', 'Dense and somewhat unclear writing.', 'Unclear generalization to other tasks.', 'Limited comparisons with other adaptive learning rate methods.', 'Insufficient detail for reproducibility.']",3,3,3,3,Reject
nkaba3ND7B5,"The paper introduces a formalism and benchmark for Autonomous Reinforcement Learning (ARL), named EARL, which aims to bridge the gap between episodic RL and real-world continual learning scenarios. The benchmark includes diverse tasks reflecting real-world challenges and evaluates existing RL algorithms, highlighting their limitations in ARL settings.","['Can the authors provide more details on the task descriptions and evaluation metrics?', 'How do the proposed benchmarks compare to other existing benchmarks in terms of difficulty and diversity?', 'What safety measures are considered for the deployment of autonomous systems in real-world scenarios?', 'Can you provide more details on the potential negative societal impacts of ARL?', 'Could you clarify the differences between the deployment and continuing evaluation protocols with more concrete examples?', 'Are there any plans to propose new algorithms specifically designed for ARL in future work?', 'Can the authors provide more detailed analysis of why existing methods fail on the proposed tasks?', 'How do the proposed benchmarks compare to other non-episodic RL benchmarks in terms of difficulty and relevance?', 'Can the authors clarify the design choices for the benchmark tasks and their relevance to real-world applications?', 'Can the authors provide more details on the generalizability of their results to real-world scenarios?', 'How do the authors plan to handle potential negative societal impacts, such as the misuse of autonomous RL systems?', 'Can the authors provide more detailed explanations of the limitations of the current benchmarks and how they plan to address them in future work?', 'How do the authors envision the ARL framework being adopted by the broader RL community? Are there plans for extensive validation or community challenges?', 'Can the authors elaborate on the potential negative societal impacts of deploying autonomous RL systems and how these can be mitigated?']","['The paper does not propose new algorithms or significant improvements over existing methods.', 'Theoretical analysis is lacking to support the claims made.', 'The potential negative societal impacts of deploying autonomous systems without adequate safety measures are not sufficiently addressed.', 'The experiments are limited to simulated environments, which may not fully capture the challenges of real-world applications.']",True,3,2,3,5,4,"['Addresses a crucial gap between episodic RL and real-world continual learning scenarios.', 'Provides a structured formalism and benchmark (EARL) for ARL.', 'Includes diverse tasks that mimic real-world challenges.', 'Highlights the limitations of existing RL algorithms in ARL settings.']","['Limited novelty in the proposed methods; mainly focuses on benchmarking.', 'Insufficient theoretical analysis to support claims.', 'Unclear descriptions of some tasks and evaluation metrics.', 'Potential ethical concerns related to the deployment of autonomous systems without adequate safety measures.', 'The paper is dense and could benefit from better organization and clarity.']",3,3,2,3,Reject
OqlohL9sVO,The paper proposes a novel image retrieval method called UGALR that unifies global and local features using a single-stage pipeline. The method integrates local attention mechanisms through a Local Attention Learning Module (LALM) and uses CNN-based homography transformations to improve retrieval accuracy and efficiency. The authors claim that UGALR achieves state-of-the-art performance on Revisited Oxford and Paris datasets while being more efficient in terms of memory and speed.,"['Can the authors provide more details on the implementation of the LALM block and the specific architecture used in the backbone network?', 'How does the method perform on other benchmark datasets beyond Revisited Oxford and Paris?', 'Can the authors justify the choice of intermediate supervision and its weight in the total loss function?', 'What are the potential negative societal impacts of the proposed method, and how do the authors plan to mitigate them?', 'Can the authors provide more details on the training process, including data augmentation techniques and hyperparameter settings?']","['The paper does not discuss the potential negative societal impacts or ethical considerations of the proposed method.', 'The generalizability of the results is questionable due to the limited number of datasets used in the experiments.', 'The clarity of the methodology section needs improvement to ensure reproducibility.', 'The choice of intermediate supervision and its weight in the total loss function need more justification.']",False,3,2,3,5,4,"['The proposed method addresses a significant issue in image retrieval by unifying global and local features in a single-stage pipeline.', 'The integration of spatial and channel attention mechanisms is well-motivated and demonstrates improved performance.', 'Extensive experiments show that UGALR outperforms state-of-the-art methods in terms of both accuracy and efficiency.', 'The ablation studies provide insights into the contributions of different components of the proposed method.']","['The paper lacks clarity in the presentation of the methodology, making it difficult to reproduce the results.', 'The experimental setup is limited to only two datasets, which raises concerns about the generalizability of the results.', 'The paper does not adequately address potential negative societal impacts or ethical considerations.', 'Intermediate supervision and some design choices in the methodology need more justification.']",3,3,2,3,Reject
cLcLdwOfhoe,"The paper proposes FEDLITE, a scalable approach for federated learning on resource-constrained clients. It introduces a combination of vector quantization and gradient correction to reduce communication costs significantly. The paper provides both theoretical analysis and empirical evaluations on datasets like FEMNIST, SO Tag, and SO NWP.","['Can the authors provide more details on how the proposed method performs compared to other state-of-the-art federated learning methods not included in the paper?', 'What is the computational overhead introduced by the proposed vector quantization and gradient correction techniques?', 'How would the method perform on larger and more diverse datasets beyond those used in the paper?', 'Can you provide more details on the hyperparameter tuning process?', 'Have you considered the potential negative societal impacts of your method?', 'Can you expand the related work section to include more recent advancements in federated learning?', 'How does the proposed method compare with other state-of-the-art FL methods in terms of computational efficiency and accuracy?', 'Can the authors provide more details on the potential negative societal impacts and limitations of their method?', 'How does the method perform on real-world applications beyond the standard datasets used in the experiments?', 'Can the authors provide more insights into the choice of hyperparameters, especially the value of λ?', 'Can the authors provide a clearer, step-by-step explanation of the vector quantization and gradient correction techniques?', 'How does FEDLITE perform on other types of neural networks and tasks beyond those tested?', 'Can the authors elaborate on the potential negative societal impacts and how they might be mitigated?', 'Can the authors provide more detailed explanations of the assumptions made in the theoretical analysis?', 'How does the performance of FEDLITE vary with different types of neural network architectures?', 'What are the potential limitations or challenges when applying this method in real-world scenarios?']","['The paper does not address the potential negative societal impacts of federated learning, such as privacy risks and data security.', 'The practical implementation details are limited, which might affect reproducibility.', 'Does not adequately address the limitations of the proposed method, particularly in terms of scalability and real-world applicability.', 'Potential negative societal impacts, such as privacy concerns and the environmental impact of increased computation, are not discussed.', 'The method may not generalize well to all types of neural networks and tasks.', 'The impact of non-IID data distributions on the performance of FEDLITE is not extensively analyzed.']",False,3,3,3,7,4,"['Novel combination of vector quantization and gradient correction for communication efficiency.', 'Extensive empirical evaluation showing significant communication cost reduction.', 'Theoretical analysis explaining the benefits of the gradient correction technique.']","['Some parts of the paper are dense and may be difficult to follow.', 'Limited comparative baselines with other state-of-the-art methods.', 'Lack of detail about the practical implementation and computational overhead.', 'Experiments conducted on a limited set of standard datasets.', 'Does not adequately address potential negative societal impacts and limitations.']",3,3,3,4,Reject
FZoZ7a31GCW,"The paper introduces Draupnir, a deep generative model for ancestral sequence reconstruction using a tree-structured Ornstein-Uhlenbeck process as a prior for a variational autoencoder. The model aims to improve representation learning of biological sequences by explicitly incorporating evolutionary information. The paper demonstrates that Draupnir performs comparably or better than existing ASR methods and conducts ablation studies to assess various components of the model.","['Can the method be scaled to handle genomic-scale data efficiently without significant loss in accuracy?', 'How does the model handle sequence families with high levels of divergence?', 'Could you clarify the computational resources required for training Draupnir on larger datasets?', 'Could the authors provide more detailed hyperparameter settings and training details?', 'How does Draupnir compare to other deep learning-based ASR methods beyond state-of-the-art phylogenetic methods?', 'Can the authors elaborate on the scalability of Draupnir to larger, genome-scale datasets?', 'Can the authors provide more detailed explanations for the mathematical derivations, especially in Section 4.4?', 'How does the model perform on larger, more diverse datasets beyond the ones used in the paper?', 'Can the authors discuss potential negative societal impacts and ethical considerations in more depth?', ""How were the hyperparameters selected, and what impact do they have on the model's performance?"", 'Can this model be generalized to other types of biological data, such as RNA sequences?', 'What are the potential limitations and edge cases where Draupnir might not perform well?']","['Current limitations in scalability to genomic-scale data.', 'Limited discussion on potential negative societal impact.', ""The model's performance on larger, more complex datasets is not thoroughly evaluated."", 'The reliance on pre-computed multiple sequence alignments (MSAs) could limit applicability.', 'The paper mentions potential extensions to genomic-scale datasets and latent phylogenetic trees but does not explore these in depth.', 'The ethical considerations and potential negative societal impacts of the work are not thoroughly discussed.', 'Potential computational intensity of the approach.']",False,3,3,3,6,4,"['Original approach using a tree-structured Ornstein-Uhlenbeck process as a prior for a VAE.', 'Thorough methodology and detailed explanation.', 'Well-organized and clearly written.', 'Potential significant impact on phylogenetics and protein engineering.', 'Promising results in benchmarking against state-of-the-art methods.', 'Comprehensive ablation studies to evaluate different components of the model.']","['Potential bias in evaluation towards datasets favoring the proposed method.', 'Complexity may limit accessibility and practical applicability.', 'Concerns about scalability to genomic-scale data.', 'Focus on single protein families might limit generalizability.', 'Dense presentation; clarity of methodology can be improved.', 'Lack of detailed comparison with other deep learning-based ASR methods.', 'Some sections lack detailed explanations, especially the mathematical derivations.', 'Incomplete details on training process and hyperparameter selection.', 'Unclear generalizability to other types of biological data.', 'Limited discussion on potential negative societal impacts and ethical considerations.']",4,3,3,3,Reject
8rCMq0yJMG,The paper proposes a method called Source-Target Unified Knowledge Distillation (STU-KD) aimed at improving inference accuracy of compact models on edge devices in federated learning environments. The method involves adapting a large source model to the target data in a memory-efficient manner using lite residual hypothesis transfer and then transferring the knowledge to a compact model using collaborative knowledge distillation. STU-KD also integrates secure aggregation to ensure data privacy.,"['Can the authors provide more theoretical analysis of the proposed methods?', 'How does the performance of STU-KD vary with different network architectures?', 'Could the authors provide more details on the lite residual hypothesis transfer mechanism?', 'How does STU-KD perform on more diverse datasets and in additional real-world scenarios?', 'Can you elaborate on the potential negative societal impacts and broader ethical considerations of your approach?', 'How does the performance of STU-KD change with different edge device capabilities?', 'Can the method be extended to other types of models beyond those tested?', 'How does the communication cost of STU-KD compare to traditional federated learning methods?', 'Can the authors provide more details on the hyperparameters and model configurations used in the experiments?', 'How does the proposed approach compare with other recent methods not included in the paper?', 'Can the authors include ablation studies to isolate the contribution of each component of the proposed approach?', 'How does the proposed method perform on real-world edge devices compared to simulated environments?']","['The paper does not address the potential negative societal impacts in sufficient detail.', 'The approach might not generalize well to all types of edge devices with varying computational and memory constraints.', 'Limited real-world scenario testing.', 'The method may be computationally intensive for extremely resource-constrained devices.', 'The integration of secure aggregation is mentioned but not deeply evaluated for its impact on overall performance.']",False,3,3,3,6,4,"['Addresses a critical problem in federated learning and edge computing.', 'Proposes a novel combination of techniques (lite residual hypothesis transfer and collaborative knowledge distillation).', 'Extensive experimental validation showing significant improvements in performance.', 'Incorporates privacy-preserving mechanisms.']","['The paper lacks a rigorous theoretical analysis of the proposed methods.', 'Some parts of the methodology, such as the exact working of the lite residual hypothesis transfer, are not explained in detail.', 'The clarity of the paper could be improved, especially in the methodology section.', 'Potential negative societal impacts are not discussed in sufficient detail.', 'Limited real-world scenario testing.', 'Requires a more thorough comparison with additional recent methods.', 'Lacks comprehensive ablation studies to isolate the contribution of each component.']",4,3,3,4,Reject
So6YAqnqgMj,"The paper 'EIGENGAME UNLOADED' introduces µ-EigenGame, an unbiased stochastic update for the EigenGame algorithm. The authors claim that µ-EigenGame enjoys greater parallelism, better convergence properties, and higher accuracy compared to the original EigenGame (α-EigenGame). The paper provides rigorous theoretical analysis, including proofs of convergence and performance guarantees, and includes extensive experiments on both synthetic and real-world datasets.","['Can you provide more detailed pseudocode or a reference implementation to aid in reproducibility?', 'How does µ-EigenGame perform on other types of data beyond those presented in the paper?', 'Can you provide more intuitive explanations or visualizations to help readers understand the theoretical concepts?', 'Are there any limitations or scenarios where µ-EigenGame might not perform as well as expected?', 'Could the authors elaborate on the potential applications and impact of µ-EigenGame in practical settings?', 'Can you provide more details on the potential impact of the limitations discussed (e.g., issues with certain distributions)?', 'Have you considered any practical applications beyond those discussed in the paper?', 'How does µ-EigenGame compare to other recent advancements in the field of eigendecomposition and dimensionality reduction?']","['The paper addresses the limitations in constructing a suitable Lyapunov function for finite sample convergence.', 'Potential applications and extensions are discussed, such as in deep learning and graph spectral methods.', ""The algorithm's performance in scenarios with very noisy data or highly non-uniform distributions is not thoroughly explored."", 'Potential negative societal impacts are not discussed, although they may be minimal in this context.', 'Difficulty in obtaining finite sample convergence rates.', 'Potential issues with certain distributions (e.g., Cauchy).']",False,4,3,4,7,4,"['Novelty: The introduction of µ-EigenGame is novel, particularly in how it leverages unbiased updates to enhance scalability and performance.', 'Technical Depth: The paper provides rigorous theoretical analysis, including proofs of convergence and performance guarantees.', 'Empirical Validation: The paper includes extensive experiments on both synthetic and real-world datasets, demonstrating the efficacy of µ-EigenGame.', 'Practical Relevance: The proposed method is highly relevant for large-scale data processing tasks, such as dimensionality reduction and spectral clustering.']","['Complexity: The paper is dense and may be challenging for readers to follow without a strong background in game theory and linear algebra.', 'Reproducibility: While the authors provide pseudocode, the complexity of the algorithm might make it difficult to reproduce without further implementation details.', ""Evaluation Metrics: The metrics used to evaluate performance, such as the 'longest correct eigenvector streak,' might not fully capture the practical benefits of the proposed method."", 'Limited Scope: The experiments, though extensive, could benefit from more diverse datasets to further validate the generalizability of the results.', 'Potential Negative Societal Impacts: The paper lacks a thorough discussion of potential limitations and negative societal impacts.']",4,4,3,4,Accept
Zca3NK3X8G,"The paper presents WaveCorr, a new portfolio policy network architecture for deep reinforcement learning that addresses the problem of portfolio management by exploiting cross-asset dependency information more effectively than existing architectures. The key innovation is the introduction of a permutation invariant property for policy networks, which ensures that the network's performance is invariant to the order of assets. Through extensive experiments on Canadian and American stock market data, WaveCorr is shown to outperform state-of-the-art architectures, achieving significant improvements in average annual returns and Sharpe ratios.","['Can the authors provide more details on the hyperparameter tuning process and the choices made for the final model?', 'How does the WaveCorr architecture perform in terms of computational efficiency compared to state-of-the-art methods?', 'Can the authors clarify the mathematical formulation of the permutation invariant property and provide more intuitive explanations?', 'How generalizable is the WaveCorr architecture to other types of financial data and different market conditions?', 'Could the authors provide a theoretical comparison with other permutation invariant architectures?', 'What are the potential risks and negative societal impacts of the proposed method in real-world financial markets?', 'Can the authors provide more detailed proofs for the theoretical claims?', 'Can the authors clarify the mathematical notation and provide more detailed explanations?', 'Can the authors provide a more detailed description of the experimental setup to ensure reproducibility?', 'Can the authors contextualize the significance of the improvements within the existing literature?', 'How does WaveCorr perform compared to additional baselines beyond CS-PPN and EIIE?', 'Can you discuss the potential negative societal impacts of the proposed approach?', 'How does WaveCorr perform in diverse market conditions beyond the datasets used?', 'What are the potential limitations and negative societal impacts of using WaveCorr in real-world scenarios?']","['The potential negative societal impacts of the work are not thoroughly discussed. Automated trading systems can have significant effects on financial markets and society.', 'The scalability of the WaveCorr architecture to larger datasets or more assets is not addressed in detail.', 'There is a lack of discussion on the robustness of the model to different market conditions beyond the datasets used in the experiments.', 'Theoretical proofs provided are not detailed enough to allow for full verification of the claims.', 'The experimental setup is not described in sufficient detail, making reproducibility difficult.', 'Potential overfitting due to the complexity of the model is not addressed.']",False,3,3,3,6,4,"['The introduction of the permutation invariant property for policy networks is novel and well-motivated.', 'The proposed architecture, WaveCorr, shows significant performance improvements over existing methods in empirical evaluations.', 'The design of the network is clear and well-justified, particularly the use of WaveNet structure and the Corr layer.', 'Good experimental design with multiple datasets and extensive comparisons.']","['The paper lacks clarity in some sections, especially in the mathematical formulations and definitions.', 'There is a need for more detailed explanations of the experimental setup, including hyperparameter choices and training procedures.', 'Reproducibility could be an issue; while the authors provided a link to the code, the description of the implementation details is somewhat lacking.', 'The discussion on the potential negative societal impacts and ethical considerations is minimal.']",3,3,3,3,Reject
YfFWrndRGQx,The paper introduces the framework of Multi-Objective Online Convex Optimization (MO-OCO) and proposes the Online Mirror Multiple Descent (OMMD) algorithm with two variants. The paper derives regret bounds for both variants and validates them through extensive experiments. The OMMD-II variant is shown to have a lower bound and better performance in empirical evaluations.,"['Can the authors provide a more detailed explanation of how the theoretical bounds were derived?', 'Are there any specific limitations or assumptions in the experiments that might affect the generalizability of the results?', 'Can the authors elaborate more on the differences between OMMD-I and OMMD-II in practical applications?', 'How do the proposed methods compare to other state-of-the-art multi-objective optimization techniques in terms of computational efficiency?']","['The paper does not address the limitations of the proposed methods in detail.', 'The potential negative societal impacts of the work are not discussed.', 'The experiments assume certain conditions that may not hold in all real-world scenarios, which could affect the generalizability of the results.']",False,3,3,3,6,4,"['Introduction of a novel framework (MO-OCO) for multi-objective online learning.', 'Proposed a new algorithm (OMMD) with theoretical guarantees.', 'Extensive experiments demonstrating the effectiveness of the proposed algorithm.']","['The theoretical proofs require careful verification and may contain gaps or errors.', 'The paper is dense and may be difficult to follow for readers, affecting clarity.', 'Experimental details may need more explanation to ensure reproducibility.']",4,3,3,3,Accept
Oh1r2wApbPv,"The paper proposes an Imagine-and-Verbalize (I&V) method for generative commonsense reasoning (GCSR). It introduces a scene imagination step that constructs structured representations (scene knowledge graphs or SKGs) from input concepts and context. The method leverages SKGs from various sources and modalities, enhancing language models' ability to generate plausible scene descriptions. The paper demonstrates the method's effectiveness through experiments on concept-to-sentence and concept-to-story generation tasks.","['How does the method scale with larger datasets or more complex scenes?', 'What are the potential limitations when applying this method to real-world scenarios?', 'Can the approach be extended to other generative tasks beyond GCSR?', 'Can the authors provide more detailed theoretical analysis to support their method?', 'How does the method perform on a broader range of tasks beyond the specific GCSR tasks evaluated?', 'Can the authors provide more details on the implementation and hyperparameters used in the experiments?', 'Can the authors provide more detailed explanations of the methodology, particularly the training process of the imagination and verbalization modules?', 'How does the proposed method compare to other knowledge integration techniques not covered in the paper?', 'What are the limitations and potential failure cases of the proposed method?', 'How does the computational cost of the proposed method compare to existing baseline methods?', 'Can the approach be adapted to work with smaller and less resource-intensive models?', 'What are the potential negative societal impacts of deploying such models in real-world applications?', 'How does the method perform on tasks beyond text generation, such as dialogue generation or other interactive commonsense tasks?', 'Can the approach be scaled to smaller models for researchers with limited resources, and how would that affect performance?', 'Are there any specific failure cases where the SKG approach does not work well? If so, what are they and how can they be mitigated?']","['The scalability of the approach with larger datasets is not fully explored.', 'The potential negative societal impacts are not discussed in detail.', 'The paper lacks a detailed theoretical analysis.', 'The improvements over baseline methods are incremental.', 'There are concerns about the generalizability of the results.', 'The paper does not sufficiently address potential limitations and failure cases of the proposed method.', 'The complexity of the methodology may hinder reproducibility.', 'The reliance on the quality and diversity of SKG sources may limit the generalizability of the approach.', 'The computationally intensive nature of the method may pose challenges for practical deployment.', 'Limited human evaluation to substantiate claims about commonsense reasoning.', 'Insufficient exploration of potential negative societal impacts and ethical considerations.', 'The complexity of the multi-stage training process might limit its practical applicability.']",False,3,3,3,6,4,"['Novel integration of scene knowledge graphs (SKGs) for GCSR.', ""Comprehensive experiments and ablation studies support the method's effectiveness."", 'Clear improvements over state-of-the-art baselines in GCSR tasks.', 'Well-documented methodology and implementation details.', 'Innovative combination of knowledge graphs and language models.', 'Thorough experimental evaluation.', 'Clear writing and organization.', 'Addresses a significant challenge in generative commonsense reasoning.', 'Well-organized and clearly written, making the methodology and results easy to follow.', 'Inclusion of human evaluation to validate results.', 'Robustness in low-resource settings.']","['Some sections could be better organized for improved clarity, particularly the experimental setup.', 'Limited discussion on ethical considerations and potential negative societal impacts.', 'Scalability and applicability to real-world scenarios are not thoroughly addressed.', 'Incremental improvements over baseline methods.', 'Lack of detailed theoretical analysis.', 'Concerns about the generalizability of the results.', 'The methodology is complex and not clearly explained in certain sections.', 'Results, while promising, do not overwhelmingly demonstrate the superiority of the proposed method.', 'Claims about generalizability and robustness are not fully supported by the experimental evidence.', 'Relies heavily on the quality and diversity of the SKG sources, which may limit its generalizability.', 'Method might be computationally intensive due to the iterative generation process and the need for large pre-trained models.', 'Evaluation primarily focuses on automatic metrics, with limited human evaluation to substantiate the claims about commonsense reasoning.', 'Technical complexity may hinder replication.', 'Resource-intensive due to reliance on large pre-trained models.', 'Limited scope of evaluation, primarily focused on text generation tasks.', 'Performance dependency on the quality and diversity of SKGs.']",3,3,3,3,Accept
youe3QQepVB,"The paper proposes a Multi-task Oriented Generative Modeling (MGM) framework that integrates generative and discriminative networks to improve performance across multiple visual tasks such as semantic segmentation, depth estimation, and surface normal prediction. The framework is evaluated on benchmarks like NYUv2 and Taskonomy, showing significant improvements over state-of-the-art methods, particularly in low-data regimes.","['Can the authors provide more theoretical analysis to support the empirical findings?', 'How does the reliance on weak annotations (scene labels) affect the generalizability of the approach?', 'Can the authors clarify the explanation of the refinement network and the self-supervision network?', 'What are the potential limitations and real-world impacts of the proposed framework?', 'Can the authors provide more concise explanations of their method?', 'How does the performance of MGM compare with simpler baselines under the same conditions?', 'Can the authors provide more details on the computational requirements and training time for the proposed framework?', 'Can the authors provide more details on the training procedure for the refinement and self-supervision networks?', 'How does the performance of MGM compare to other state-of-the-art multi-task learning methods not included in the current experiments?', 'Can the authors include more ablation studies to isolate the contributions of each component in the framework?', ""How does the generative model's performance vary with different types of weak annotations?"", 'Can you provide more detailed comparisons with state-of-the-art methods in multi-task learning?', 'How does the MGM framework handle scalability with larger datasets or higher-resolution images?', 'Can you elaborate on the potential negative societal impacts of your work?', 'Can the authors provide more details on the training procedure, particularly the hyperparameters used for different components?', 'How does the performance of MGM vary with different types of generative models?', 'Can the authors discuss the potential limitations and negative societal impacts of their proposed method in more detail?']","['Reliance on weak annotations (scene labels) might limit generalizability.', 'Potential real-world impact and limitations need more discussion.', 'The scalability and generalizability of the method need further validation.', 'The generated images are not visually realistic, which might limit the understanding of their effectiveness.', 'Potential negative societal impacts are not adequately discussed.', 'The complexity of the framework might hinder its adoption and reproducibility.']",False,3,3,3,6,4,"['Innovative combination of generative models with multi-task learning.', 'Thorough experimental evaluation showing significant improvements.', 'Effective in low-data regimes.', 'Flexible framework applicable to various tasks and datasets.']","['Lacks sufficient theoretical analysis to support empirical findings.', 'Explanation of certain components could be clearer.', 'Complex and lengthy presentation, which may hinder clarity.', 'Insufficient explanation of certain components and training procedures.', 'Lack of additional baselines and ablation studies to fully validate the contributions of each component.', 'Potential impact and limitations are not adequately discussed.', 'Reproducibility concerns due to the lack of detailed implementation instructions and hyperparameter settings.']",3,3,3,3,Reject
8Py-W8lSUgy,"The paper introduces MetaLink, a relational multi-task learning framework that uses a knowledge graph to leverage auxiliary task labels for improved predictions on new tasks. The method is evaluated on multiple datasets in biochemical and vision domains, showing significant improvements over state-of-the-art methods.","['How does MetaLink perform compared to more diverse baselines?', 'Can the authors provide more intuitive explanations and better structure the methodology section?', 'What are the robustness and sensitivity analyses of the proposed method?', 'What steps have been taken to ensure fairness and mitigate potential biases introduced by auxiliary task labels?', 'Could you provide more theoretical justification for the proposed method?', 'Can you elaborate on how the knowledge graph is constructed in more detail?', 'What are the limitations of MetaLink in terms of computational resources and scalability?', 'Can you provide more detailed explanations of the knowledge graph construction process?', 'How does MetaLink perform compared to other state-of-the-art methods in more diverse settings?', 'What are the potential limitations of the proposed approach in real-world applications?', ""Can the authors provide more detailed explanations of the MetaLink framework's key components, particularly the knowledge graph construction and the GNN's role?"", 'Could you elaborate on how MetaLink handles the initialization of unseen task nodes during inference?', 'What specific steps are taken to ensure that the method generalizes well to unseen tasks?', 'What is the theoretical rationale for choosing specific configurations, such as the number of GNN layers?', 'Can you elaborate on the potential societal impacts of leveraging auxiliary task labels, especially in sensitive domains like biomedicine?']","[""The method's effectiveness is limited when tasks are not correlated."", 'Empirical study is limited to multi-label learning due to dataset availability.', 'Potential issues related to fairness when defining tasks have not been fully addressed.', 'Potential biases in the datasets used for training could impact the fairness of the model.', 'Potential negative societal impacts, particularly in terms of fairness and bias, should be addressed in more detail.']",False,3,3,3,5,4,"['Novel approach to leveraging auxiliary task labels using knowledge graphs.', 'Demonstrates significant improvements in ROC AUC on multiple datasets.', 'Addresses a relevant problem in multi-task learning with potential real-world applications.', 'Comprehensive empirical evaluation across various datasets and settings.']","['Incremental novelty compared to existing multi-task learning and graph neural network methods.', 'Limited comparison with a broader range of baselines.', 'Complex methodology that might be hard to follow for readers.', 'Lacks thorough ablation studies and sensitivity analyses.', 'Does not extensively discuss potential negative societal impacts or fairness considerations.']",4,3,3,4,Reject
fVu3o-YUGQK,The paper introduces Efficient Self-Supervised Vision Transformers (EsViT) for visual representation learning. The authors propose a multi-stage architecture with sparse self-attentions and a region matching pre-training task. The paper reports significant improvements in performance metrics such as top-1 accuracy on ImageNet and superior performance on downstream tasks.,"['Can the authors provide more theoretical analysis to support the empirical claims?', 'How do the computational costs compare across different hardware setups?', 'Can the authors clarify some of the dense figures and tables for better interpretation?', 'Can the authors provide more details on the implementation of the region matching pre-training task?', 'How do the proposed methods scale with larger and more diverse datasets beyond ImageNet?', 'Can the authors discuss potential limitations and negative societal impacts in more detail?', 'How does the region-matching task compare with other pre-training tasks in terms of computational overhead?', 'What are the potential limitations and negative societal impacts of this work that have not been discussed?', 'How does the proposed method perform on other tasks such as object detection and segmentation?', 'Could the authors provide more theoretical insights into why the proposed region matching task works so effectively?', 'Can the authors include more detailed ablation studies to isolate the effects of each component of the proposed method?', 'How well does the proposed method generalize to other datasets and tasks beyond those evaluated in the paper?']","['High computational requirements may limit practical impact.', 'Incremental contributions compared to existing approaches.', 'The paper does not sufficiently address the potential limitations of the proposed methods, such as scalability to larger and more diverse datasets.', 'There is a lack of discussion on the potential negative societal impacts of the proposed methods, such as environmental concerns related to computational efficiency.', 'The paper does not thoroughly address potential limitations and negative societal impacts.', 'More detailed comparative analysis with existing methods could strengthen the claims.', 'Limited evaluation on a broader set of tasks beyond ImageNet and a few others.', 'Lack of detailed ablation studies and comparisons with a wider range of baselines.']",False,3,3,3,6,4,"['Proposes a novel combination of multi-stage architecture and region matching pre-training task.', 'Reports impressive empirical results on ImageNet and downstream tasks.', 'Addresses the efficiency of Transformer-based self-supervised learning.', 'Comprehensive empirical evaluations are provided, showing that EsViT outperforms prior methods on several benchmarks.']","['The contributions are incremental rather than groundbreaking.', 'Limited theoretical analysis to support empirical claims.', 'High computational requirements and complexity.', 'Some areas lack clarity, especially in the methods section.', 'Insufficient discussion on potential limitations and societal impacts of the proposed methods.', 'Over-reliance on empirical results without sufficient theoretical justification for some claims.', 'Comparative analysis with existing methods could be deeper and more thorough.']",3,3,3,3,Reject
N0uJGWDw21d,"The paper proposes BINGO, a self-supervised distillation method that aggregates related instances into bags to transfer knowledge from a larger teacher model to a smaller student model. This method aims to improve the performance of small models in unsupervised learning tasks. The paper demonstrates significant improvements over existing methods, especially for small-scale models such as ResNet-18 and ResNet-34.","['Can the authors provide more details on how the computational complexity of BINGO compares to other methods?', 'How does the method perform with different bagging strategies beyond K-nearest neighbors and K-means clustering?', 'What are the potential limitations and negative societal impacts of the proposed method?', 'Can the authors provide more detailed explanations of the bagging process, specifically how the K-nearest neighbors and K-means clustering are implemented and compared?', 'Are there any specific computational trade-offs in terms of training time and resource usage when using BINGO compared to other methods?', 'How does the method perform on other architectures beyond ResNet-18 and ResNet-34?']","['Increased computational complexity, which might limit practical applications.', 'Potential challenges in implementing the bagging strategies effectively in different scenarios.', 'The paper does not fully address the potential negative societal impacts of the method.', 'The method relies on pretrained teacher models, which might not be available in all scenarios.']",False,3,3,3,7,4,"['The proposed BINGO method achieves state-of-the-art performance on small models.', 'Comprehensive experiments and ablation studies demonstrate the effectiveness of the method.', 'The paper is well-organized and provides detailed explanations of the methodology and experiments.', 'Publicly available code ensuring reproducibility.']","['Increased computational complexity compared to existing methods.', 'The reliance on specific bagging strategies might limit the general applicability.', 'The paper does not fully explore the potential negative societal impacts of the method.', 'Clarity of the methodology section could be improved.']",4,3,3,4,Accept
q79uMSC6ZBT,"The paper introduces GRAMMFORMER, a Transformer-based model for code completion that generates code with 'holes' where the model is uncertain. The model uses the programming language grammar to guide generation and introduces a new metric, REGEXACC, to evaluate the quality of predictions. Experiments show that GRAMMFORMER outperforms traditional sequence models in generating longer and more accurate code sketches.","['Can the authors provide more details on the computational cost and how it compares with traditional models?', 'Have any human studies been conducted to validate the REGEXACC metric?', 'Can the authors discuss potential negative societal impacts or ethical considerations related to their approach?', 'Can the authors provide more details on the pretraining process and how it impacts the final model performance?', 'What are the potential negative societal impacts of this work, and how do the authors plan to mitigate them?', 'Can the authors elaborate on the limitations of GRAMMFORMER and potential directions for future research?', 'Can the authors provide more details on the reinforcement learning setup and training procedure?', 'How does GRAMMFORMER handle ambiguous grammar rules in different programming languages?', 'Can qualitative user studies be included to complement the quantitative evaluation?', 'How does REGEXACC compare to existing metrics in practical user scenarios?', 'Have the authors considered evaluating the model on more diverse datasets or additional real-world scenarios?', 'Is there any plan to conduct a user study to validate the practical utility of GRAMMFORMER?']","['The complexity and computational cost of the approach.', 'Lack of human evaluation for the new metric.', 'Limited discussion on potential negative societal impacts or ethical considerations.', 'The model may struggle with ambiguous grammar rules.', 'Potential biases in the training data are not addressed.', ""The reliance on reinforcement learning and the lack of a large supervised dataset for training introduces additional complexity and potential instability in the model's performance.""]",False,3,3,3,5,4,"['Novel approach of using grammar-guided generation for code completion.', 'Introduction of a new evaluation metric, REGEXACC.', 'Thorough experiments and evaluation on Python and C# datasets.', 'Significant improvement over traditional sequence models in terms of sketch length and accuracy.', 'Potential significant application in IDEs and programming assistants.']","['Complexity of the approach may hinder practical application.', 'High computational cost due to repeated encoder-decoder runs.', 'Lack of direct human evaluation studies to validate the new metric.', 'Limited discussion on the potential negative societal impact or ethical considerations.', 'Certain methodological details, such as the pretraining process and reinforcement learning approach, could be explained more clearly.', 'The novelty is somewhat incremental given the reliance on existing Transformer architectures and reinforcement learning techniques.', 'Presentation is dense and may not be accessible to a broader audience.']",4,3,3,3,Reject
-9ffJ9NQmal,"The paper introduces VICE, a novel method for learning object concept embeddings from human behavior in an odd-one-out task using variational inference and a spike-and-slab prior. VICE addresses limitations of the previous model, SPoSE, and performs well on smaller datasets, making it valuable for cognitive science.","['Can the authors provide more intuitive explanations and visualizations for the key concepts and results?', 'How does VICE compare with other state-of-the-art methods beyond SPoSE?', 'Can the authors provide more empirical validation for the interpretability of the embeddings through user studies?', 'Can the authors provide more clarity on the spike-and-slab prior and how it specifically improves over the Laplace prior used in SPoSE?', 'Could the authors elaborate on the limitations and potential negative societal impacts of VICE in the main body of the paper?', 'What are the computational requirements (e.g., time, resources) for training VICE compared to SPoSE?', 'How do the authors ensure that the extensive hyperparameter tuning does not lead to overfitting?', 'Could the authors elaborate on the implications of their findings for practical applications in cognitive science?', 'Could you provide more details on the mathematical formulations and derivations?', 'How were the optimal hyperparameters selected, and could this process introduce any biases?', 'Can the authors provide more extensive human evaluation results to support the interpretability claims?', 'What are the potential societal impacts of this work, and how do the authors plan to mitigate any negative effects?']","['The technical complexity may limit the accessibility of the paper.', 'The comparison is limited to SPoSE, and broader baselines are not considered.', 'The interpretability claims are not rigorously validated through user studies.', 'The paper does not discuss the potential negative societal impacts or ethical considerations in detail.', 'There is a lack of clarity in some of the methodological explanations, which could hinder reproducibility.', 'The paper relies heavily on the comparability to SPoSE and may not generalize well to other tasks or datasets.', 'The extensive hyperparameter tuning could lead to overfitting, which is not extensively addressed in the paper.', 'The method may require significant computational resources, which could limit its practical applicability.']",False,3,3,3,6,4,"['Addresses significant limitations of SPoSE, particularly regarding sparsity and dimensionality selection.', 'Shows improved performance on smaller datasets, relevant for cognitive science.', 'Provides extensive empirical validation, comparing VICE with SPoSE on multiple datasets and metrics.', 'Indicates that VICE is more stable and reproducible across different random initializations.', 'Yields interpretable embeddings, crucial for cognitive science applications.']","['Highly technical and may be challenging for readers unfamiliar with variational inference and spike-and-slab priors.', 'Empirical results do not include comparisons with a broader range of baseline methods.', 'Interpretability claims are not empirically validated through user studies as rigorously as they could be.', 'Could benefit from more visualization and intuitive explanations.', 'The clarity of some sections, particularly the explanation of the spike-and-slab prior and the dimensionality reduction process, could be improved.', 'The paper lacks a detailed discussion on the potential negative societal impacts and ethical considerations of using VICE.', 'Some technical details, such as the exact hyperparameter tuning procedure, are relegated to the appendix, which can reduce readability.', 'Potential overfitting risks due to extensive hyperparameter tuning.', 'Incremental improvements over SPoSE, rather than groundbreaking innovations.']",3,3,3,4,Reject
UvNXZgJAOAP,"The paper introduces a novel attention mechanism called 'sharp attention' for sequence-to-sequence learning tasks, aiming to improve the alignment and interpretability of attention mechanisms by employing a sharpener module consisting of a localizer and an encoder. The module aims to refine the representation of the aligned region to be more target-specific. The approach is evaluated on synthetic handwritten digit and real-world scene text recognition datasets, showing performance improvements over soft and hard attention mechanisms.","['Can the authors provide more clarity on the specific contributions of the sharpener module compared to existing STN-based methods?', 'How does the proposed method compare with the latest state-of-the-art attention mechanisms in terms of statistical significance?', 'What are the potential limitations and negative societal impacts of this work?', 'Can the authors provide more theoretical insights into why the sharp attention mechanism outperforms soft and hard attention mechanisms?', 'How does the computational complexity of the proposed method compare to existing attention mechanisms?', 'Can the authors provide a more detailed breakdown of the hyperparameters and implementation details to aid reproducibility?']","['The paper does not discuss the potential limitations of the sharpener module, such as computational overhead or scenarios where it might fail.', 'There is no discussion on the potential negative societal impacts of this work, such as biases introduced by the attention mechanism.', 'The added complexity with the sharpener module and STNs could be a limitation in terms of scalability and computational efficiency.', 'The experiments are focused on specific tasks (handwritten digit recognition and scene text recognition). It would be helpful to see how the method performs on other Seq2Seq tasks.']",False,3,2,2,5,4,"['The idea of enhancing attention mechanisms with a sharpener module is interesting and addresses an ongoing issue in Seq2Seq learning.', 'The paper provides experimental results demonstrating the efficacy of the proposed method on both synthetic and real-world datasets.', 'The sharp attention mechanism is a novel extension to existing attention mechanisms.', 'The paper provides detailed implementation information, aiding reproducibility.']","['The novelty of the proposed method is questionable as it heavily relies on existing techniques like STNs and traditional attention mechanisms.', 'The clarity of the paper is compromised by dense mathematical notations and somewhat convoluted explanations.', 'Experimental results, while showing improvements, are not sufficiently rigorous and fail to convincingly establish the superiority of the method.', 'The paper lacks a comprehensive discussion of limitations and potential negative societal impacts.', 'Minor issues with reproducibility, as some hyperparameters and implementation details are not fully specified.', 'Theoretical justification for the superiority of sharp attention is lacking.', 'The added complexity of the model might not justify the incremental improvements in some cases.']",3,3,2,3,Reject
2yITmG7YIFT,"The paper proposes HD-cos networks, which are neural architectures designed for secure multi-party computation (MPC). The key innovations include using the cosine function as an activation function and employing Hadamard-Diagonal structured weight matrices. These are aimed to reduce computation and communication costs while maintaining model performance in MPC setups.","['Can the authors provide more details on the limitations and potential negative societal impacts of the proposed methods?', 'How does the performance of HD-cos networks compare with state-of-the-art MPC methods?', 'Can the authors provide more details on the experimental setup, including hyperparameter tuning and computational resources?', 'Can the authors provide more comprehensive comparisons with state-of-the-art methods in MPC settings?', 'How does the proposed method perform in larger and more diverse datasets beyond those tested?']","['The paper does not thoroughly discuss the potential limitations and negative societal impacts of the proposed methods.', 'The experimental evaluations, while promising, could be more comprehensive and include comparisons with state-of-the-art methods.', 'The paper does not adequately address the limitations related to scalability and generalizability of the proposed methods to other datasets and settings.', 'Potential negative societal impacts and ethical considerations are not discussed sufficiently.', 'The limitations of using cosine activation function and Hadamard-diagonal transformations in different contexts should be discussed.', 'Potential negative societal impacts, especially in terms of data privacy and security, should be addressed.']",False,3,3,3,5,4,"['The use of cosine as an activation function is novel and theoretically motivated.', 'The Hadamard-Diagonal transformation reduces computational complexity.', 'Theoretical motivations for the proposed methods are well-linked to existing literature.', 'Experimental results show competitive performance compared to traditional methods.']","['The paper lacks detailed discussion on the potential limitations and negative societal impacts of the proposed methods.', 'The experimental section could be more comprehensive, especially in terms of comparing with state-of-the-art methods.', 'The clarity of the presentation could be improved, particularly in the explanation of the theoretical aspects.', 'Organizational issues and dense mathematical formulations affect clarity.', 'Empirical results do not convincingly demonstrate a clear advantage over existing methods.']",3,3,3,3,Reject
kUGYDTJUcuc,"The paper proposes a unified model that combines top-down and bottom-up attention mechanisms for visual recognition. The model leverages image pyramids and Q-learning in a reinforcement learning framework to improve the exploration of regions of interest and guide policy search. The approach is evaluated on visual classification tasks using MNIST, CIFAR-10, and SVHN datasets.","['Could you provide more details on the specific implementation choices, such as the architecture of the networks used?', 'How does the performance of your method compare with more recent state-of-the-art models?', 'Can you provide more insight into the computational efficiency of your proposed model compared to the baselines?', 'Can you provide more details on the implementation of the entropy and context constraints?', 'How does your method handle cases where top-down and bottom-up mechanisms provide conflicting information?']","['The paper does not sufficiently address the computational cost associated with the proposed model.', 'Potential ethical implications of using reinforcement learning for visual recognition tasks are not discussed.', 'Scalability to larger and more complex datasets is not demonstrated.', 'The novelty of the approach may be seen as incremental.']",False,2,2,2,4,4,"['Combines top-down and bottom-up attention mechanisms in a novel way.', 'Utilizes reinforcement learning for effective region selection.', 'Shows promising results on several visual classification benchmarks.']","['The contributions are incremental given the extensive literature on attention mechanisms and reinforcement learning.', 'The paper is not clearly written and is often difficult to follow.', 'Experimental validation lacks comprehensive comparisons with state-of-the-art methods.', 'Key details about the implementation and experimental setup are missing or not sufficiently detailed.', 'The significance of the contributions in advancing the state of the art needs better justification.', 'Potential ethical concerns and computational costs are not adequately addressed.']",2,2,2,3,Reject
F2r3wYar3Py,"The paper introduces a 'distortable canvas' model inspired by human innate abstraction abilities to achieve one-shot learning in visual recognition tasks. It aims to classify and cluster images using minimal examples without pre-training, outperforming existing models in the tiny-data regime. The approach is evaluated on benchmarks such as MNIST, EMNIST-letters, and the Omniglot challenge.","['Can the authors provide more details on the experimental setup to ensure reproducibility?', 'How does the model scale with larger and more complex datasets beyond MNIST and Omniglot?', 'What are the specific limitations of the proposed approach, and how can they be mitigated?', 'Can the authors provide more empirical evidence to support their performance claims?', 'How does the model perform in comparison to other state-of-the-art few-shot learning methods on more varied datasets?', 'Could the authors clarify the steps necessary for reproducing their results?', 'Can you provide more details on how the optimization process handles local minima?', 'How does your method compare to other transformation-based models in terms of computational efficiency?', 'Have you tested your method on more complex and real-world datasets beyond MNIST, EMNIST-letters, and Omniglot?', 'Can the authors provide more theoretical analysis to support their claims?', 'How does the method perform on more complex, real-world tasks beyond abstract visual tasks?', 'Can the authors clarify the details of the experimental setup and comparisons to ensure fairness?', 'How does the model perform on more complex, photorealistic image datasets?', 'Can the authors provide more insights into the scalability of the approach?', 'What are the limitations of using a nearest-neighbor classifier, and how can these be addressed in future work?']","['The paper lacks a thorough discussion on potential limitations of the approach and its scalability.', 'There is no mention of any potential negative societal impacts.', ""The method's applicability to more complex and real-world datasets remains unclear."", 'The current implementation is highly sensitive to noisy and ambiguous training examples.', 'Potential sensitivity to noisy, erroneous, and ambiguous training examples due to reliance on 1-NN.', ""The model's performance diminishes with larger training sizes due to the limitations of the nearest-neighbor classifier.""]",False,2,2,2,4,4,"['Novel approach inspired by human cognitive processes.', 'Potential for significant impact in data-scarce scenarios.', 'Claims state-of-the-art performance on standard benchmarks in the tiny-data regime.']","['Presentation is convoluted and hard to follow.', 'Experimental results need more clarity and reproducibility details.', 'Practical significance and scalability of the approach are questionable.', 'Heavy reliance on theoretical constructs without sufficient empirical validation.', 'Limited evaluation on more complex and real-world datasets.', 'Unclear differentiation from existing transformation-based and few-shot learning models.', 'Lacks rigorous theoretical analysis and thorough experimental validation.', 'Comparisons with other methods are not always direct or fair.', 'Complexity and potential limitations in scaling to more complex, real-world tasks.']",3,2,2,3,Reject
36SHWj0Gp1,"The paper proposes GenTAL, a Transformer-based unsupervised model for binary code similarity detection. It leverages a denoising autoencoder and skip-gram design to capture the intrinsic representation of assembly code semantics. Experiments demonstrate its robustness and performance advantages over state-of-the-art methods in various tasks.","['Can the authors provide more detailed theoretical analysis and formal proofs for the claims made?', 'Could the authors elaborate on the limitations of their approach and potential negative societal impacts?', 'Can the authors provide more detailed descriptions of their methodology to enhance reproducibility?', 'Can the authors provide more detailed descriptions of the datasets and hyperparameter settings used in the experiments?', 'How does the OOV problem specifically impact the performance of GenTAL, and are there any potential solutions to mitigate this issue?', 'Can the authors discuss the computational complexity of GenTAL compared to other methods?', 'Can the authors provide more details on how the model handles out-of-vocabulary (OOV) issues, especially in heavily numeric libraries?', 'Are there any plans to evaluate the model on a more diverse set of datasets, beyond malware and benign software?', 'Could the authors elaborate on the potential negative societal impacts of their work and any measures to mitigate them?', 'Can the authors provide more details on the hyperparameters and training specifics?', 'How does the proposed method compare to other recent Transformer-based models in terms of computational complexity?', 'Can the authors clarify the process of generating the evaluation datasets and the ground truth for similarity detection?']","['The paper lacks detailed discussion on limitations and potential negative societal impacts, such as the impact of the model on privacy or potential misuse.', 'There is no mention of how the model performs on other obfuscation methods not evaluated in the paper.', 'The OOV problem is mentioned but not thoroughly discussed.', 'Potential high computational complexity of the model is not addressed.', ""The model's performance might be hindered by OOV issues in heavily numeric libraries."", 'Limited diversity in evaluation datasets, which might affect the generalizability of the results.', 'Potential overfitting to certain types of assembly code not discussed.', 'Lack of ablation study to understand the contribution of each model component.', 'The societal impact of the work is not discussed, which is particularly relevant given the application in cybersecurity.']",False,3,3,3,6,4,"['Addresses a significant problem in cybersecurity.', 'Innovative use of Transformer-based models with denoising autoencoder and skip-gram techniques.', 'Extensive experiments on multiple datasets and tasks, showing robust performance.']","['Insufficient theoretical analysis and formal proofs for some claims.', 'Limited discussion on limitations and negative societal impacts.', 'Some parts of the methodology are not clearly explained, impacting reproducibility.', 'Complexity and density of the paper may hinder clarity and reproducibility.', 'Evaluation datasets are limited to specific domains (malware and benign software).', 'No ablation study to understand the contribution of each component of the model.']",3,3,3,3,Reject
n6Bc3YElODq,"The paper introduces Model-Based Opponent Modeling (MBOM) for multi-agent reinforcement learning. MBOM uses recursive reasoning and Bayesian mixing to adapt to various types of opponents, including fixed, learning, and reasoning opponents. The methodology leverages an environment model to simulate interactions and generate opponent policies, which are then mixed according to their similarity with real opponent behaviors. Experimental results in competitive and cooperative tasks demonstrate the effectiveness of MBOM over existing methods.","['Can the authors provide more details on the computational overhead and scalability of MBOM?', 'How does MBOM perform in environments with more than two agents and more complex interactions?', 'Can the authors clarify if there are any assumptions made about the learning algorithms of the opponents?', 'How does the method perform when the environment model is inaccurate?', 'Can the authors discuss the potential negative societal impacts of their work?']","['The paper assumes access to certain opponent actions and rewards which might not be practical in all scenarios.', 'Scalability to larger number of agents and more complex environments is not thoroughly discussed.', 'Potential negative societal impacts are not explicitly addressed.']",False,3,3,3,5,4,"['Novel approach combining recursive reasoning and Bayesian mixing for opponent modeling.', 'Comprehensive evaluation in both competitive and cooperative environments.', 'Empirical results show clear improvements over strong baselines.', 'Addresses a relevant and challenging problem in multi-agent reinforcement learning.']","['The methodology section is complex and may be difficult to follow without further simplification.', 'Limited discussion on the computational overhead and scalability of the proposed approach.', 'Assumes the environment model is accurate, which might not hold in real-world applications.', 'Potential negative societal impacts are not explicitly addressed.']",3,3,3,3,Reject
Ti2i204vZON,"The paper investigates representation learning methods for pixel-based control in reinforcement learning, introducing a simple baseline and comparing it with existing methods in settings with and without background distractors. The authors propose new evaluation metrics based on task properties and advocate for a data-centric evaluation approach.","['Can the authors provide more details on the experimental setup, especially the hyperparameters and evaluation protocol?', 'How do the proposed evaluation metrics compare to existing metrics in terms of practicality and effectiveness?', 'What are the potential negative societal impacts of the proposed methods, if any?', 'Can you provide more theoretical justification for why the proposed baseline outperforms more complex methods in environments with distractors?', 'How do you ensure that the proposed categorization of benchmarks is exhaustive and covers all relevant data-centric properties?', 'Could you include more details on the hyperparameters used for each method in your experiments?', 'How would the proposed baseline perform on a wider range of benchmarks?', 'Are there specific scenarios where the baseline fails compared to existing methods?']","['The paper does not adequately address potential negative societal impacts or ethical concerns.', 'The baseline approach may not generalize well to more complex or diverse RL tasks.', 'The simplicity of the baseline may limit its applicability in more complex scenarios.', 'Minimal discussion on the potential negative societal impact of the work.', 'The evaluation is limited to specific benchmarks and may not reflect broader applicability.']",False,3,3,2,5,4,"['Addresses a relevant problem in RL with pixel-based inputs.', 'Provides a comprehensive comparison of various methods.', 'Proposes new evaluation metrics for RL algorithms.', 'Thorough empirical analysis across multiple benchmarks and settings.', 'Clear identification of challenges in current representation learning methods for RL.']","['Baseline approach lacks novelty, combining known techniques.', 'Experimental comparisons are not always convincing or well-justified.', 'Limited scope of experiments, focusing mainly on specific RL tasks.', 'Potential ethical concerns and societal impacts are not adequately discussed.', 'Lack of theoretical contributions or insights to support empirical findings.', 'Dense and difficult-to-follow writing in some sections.']",2,3,3,3,Reject
lvM693mon8q,The paper proposes Compressed Vertical Federated Learning (C-VFL) for communication-efficient training on vertically partitioned data. It introduces embedding compression techniques to reduce communication overhead and provides theoretical analysis on the impact of embedding compression on VFL convergence. The paper offers both theoretical proofs and empirical evaluations to demonstrate the effectiveness of the proposed method.,"['Can you provide more intuitive explanations for some of the notations and assumptions used in the theoretical analysis?', 'Have you considered the practical challenges that might arise in real-world implementations of C-VFL?', 'Could you extend the empirical evaluation to include more datasets and vary the number of participating parties?', 'Can the authors provide more detailed hyperparameter settings used in the experiments for better reproducibility?', 'How sensitive is the performance to the choice of compression parameters (e.g., number of bits in scalar quantization)?', 'Can the authors offer more intuitive explanations or visual aids for the mathematical derivations presented?', 'Could the authors provide more details on the practical implementation of the compression schemes?', 'How does the method handle different types of data distributions across parties?', 'Can the authors elaborate on the potential negative societal impacts of their method, particularly regarding data privacy?', 'Can you provide more details on the computational overhead introduced by the compression techniques?', 'How does C-VFL perform on more diverse datasets, especially those with different data distributions?', 'What are the implications if parties do not have access to labels?']","['The paper does not address potential challenges in real-world implementations.', 'The empirical evaluation is limited to two datasets and a small number of parties.', 'The method assumes access to labels by all parties, which may not be realistic in all scenarios.', 'The impact of data heterogeneity on the performance of C-VFL is not thoroughly explored.', 'Potential privacy issues related to embeddings and model inversion attacks should be more thoroughly discussed.']",False,3,2,3,6,4,"['Addresses an important problem in federated learning.', 'Provides theoretical analysis of convergence with compression.', 'Empirical results show significant communication savings.', 'Novel approach of applying embedding compression in Vertical Federated Learning (VFL).', 'Comprehensive theoretical analysis proving convergence rates for non-convex objectives.', 'Generalization of previous VFL methods by supporting arbitrary server models and multiple local iterations.']","['The paper is dense and difficult to follow, particularly the theoretical sections.', 'Some notations and assumptions are not well-explained.', 'Limited discussion on the practical implementation and potential challenges in real-world applications.', 'The empirical evaluation could be more comprehensive, e.g., testing on more datasets and varying the number of parties.', 'Reproducibility might be challenging due to the lack of detailed hyperparameter settings and experimental setup specifics.', 'Ethical considerations regarding data privacy are not deeply analyzed.']",3,3,2,3,Reject
f4c4JtbHJ7B,"The paper proposes Pixab-CAM, a novel method for generating explanation maps for CNNs using pixel-wise weights instead of channel-wise weights. The method aims to address limitations of previous CAM-based methods by removing dependency on the activation tensor and avoiding gradient-based issues. The paper also introduces new evaluation metrics using adversarial attacks to assess the quality of the explanation maps.","['Can the authors provide a clearer explanation of the proposed evaluation metrics using adversarial attacks?', 'How does Pixab-CAM handle cases where pixel-wise weights still lead to overestimation?', 'Can the authors discuss the computational complexity of Pixab-CAM compared to existing CAM methods?', 'Can the authors provide more theoretical grounding for their method?', 'How do the proposed metrics compare to traditional evaluation metrics in terms of reliability?', 'Can the authors clarify the experimental setup and provide more detailed results?', 'Can the authors provide more details on the implementation of Pixab-CAM to ensure reproducibility?', 'How does Pixab-CAM perform on different CNN architectures other than Inception V3?', 'What are the computational requirements and runtime performance of Pixab-CAM compared to other CAM methods?']","['The paper does not sufficiently address the potential computational overhead introduced by using pixel-wise weights.', 'The proposed evaluation metrics may not provide a comprehensive measure of the effectiveness of the explanation maps.', 'The impact of the proposed method on different types of CNN architectures is not explored.', 'Potential negative societal impacts are not adequately addressed. For example, how might Pixab-CAM be misused in applications involving sensitive or biased data?']",False,3,3,3,5,4,"['Introduces a novel approach using pixel-wise weights for CAM.', 'Attempts to remove dependency on the activation tensor.', 'Proposes new evaluation metrics using adversarial attacks.', 'Comprehensive qualitative and quantitative evaluations.']","['Methodology section lacks clarity and detailed explanation.', 'Insufficient theoretical grounding for new evaluation metrics.', 'Potential computational overhead due to pixel-wise weights.', 'Writing and organization need significant improvement.', 'Limited discussion on limitations and potential negative societal impact.']",3,3,3,3,Reject
rGg-Qcyplgq,The paper introduces a novel method for efficient exploration in Distributional Reinforcement Learning (DRL) by proposing a Perturbed Distributional Bellman Optimality Operator (PDBOO) and an algorithm called Perturbed Quantile Regression (PQR). It provides theoretical convergence guarantees and demonstrates empirical performance improvements over existing methods in various environments including Atari games.,"['Could you provide more details on the hyperparameters used for different environments?', 'How does PQR perform compared to other state-of-the-art DRL methods not included in the paper?', 'Can you elaborate on the practical implications and potential limitations of the proposed method in real-world applications?', 'Can the authors provide more detailed ablation studies to isolate the effects of different components of the proposed method?', 'Are there any practical limitations or computational overheads associated with the proposed PQR method?', 'Can the authors provide additional benchmarks to further validate the effectiveness of the proposed method?', 'Can you provide more details on the construction of the ambiguity set and its sampling method?', 'How does the proposed method perform in comparison to other state-of-the-art exploration methods not included in the empirical evaluation?', 'Can you discuss any potential negative societal impacts of your method in more detail?', 'Can the authors provide more intuitive explanations for their theoretical proofs?', 'Why was the empirical evaluation limited to the specific environments tested?', 'How does the method perform on a wider range of environments?', 'Can the authors discuss potential negative societal impacts of their work?', 'Can the authors provide more details on the computational complexity of the proposed method?', 'How does the method perform in more complex and diverse environments outside of Atari games?', 'Are there any specific implementation challenges or hyperparameter sensitivities that practitioners should be aware of?']","['Theoretical proofs rely on certain assumptions which may not hold in all practical scenarios.', 'The empirical evaluation is limited to specific environments and may not generalize to other types of tasks.', 'Potential negative societal impacts are not discussed in detail.', 'The complexity and potential computational overhead of the proposed method might limit its practical applicability.', 'The empirical validation is based on a limited set of environments. Additional benchmarks would strengthen the claims.', 'Some explanations are unclear and lack conciseness.', 'Theoretical analysis is presented in a dense and hard-to-follow manner.', 'Limited empirical evaluation in diverse environments might not fully demonstrate the robustness of the proposed method.']",False,2,2,3,5,4,"['The paper introduces a novel exploration method in DRL by perturbing the distributional Bellman operator.', 'Theoretical contributions include proofs of convergence and optimality.', 'Empirical results demonstrate the effectiveness of the proposed method in several benchmark environments.']","['The paper is densely written and challenging to follow, especially the theoretical sections.', 'Some experimental details and hyperparameters are not thoroughly explained.', 'Limited baseline comparisons—additional comparisons with a wider range of methods would strengthen the empirical claims.', 'Lack of detailed ablation studies to isolate effects of different components.', 'Limited discussion on potential negative societal impacts.']",4,2,2,3,Reject
bE239PSGIGZ,"The paper proposes a novel method for generating audio adversarial examples for ASR systems using a conditional variational auto-encoder (CVAE). The key contribution is the ability to create adversarial examples from scratch, without relying on existing benign audio. The approach, called Speech Synthesizing based Attack (SSA), uses an adaptive sign gradient descent algorithm and is evaluated on three datasets, showing superior performance compared to existing methods.","['Can the authors provide more details on the limitations and potential negative societal impacts of their work?', 'How does the proposed method perform in a black-box attack scenario?', 'Can the authors elaborate on the steps taken to ensure the reproducibility of their results?', 'What specific measures can be taken to improve the quality of the synthesized adversarial audio?', 'Can you provide more details on the experimental setup, specifically the training process of the CVAE and the parameters used?', 'How do you plan to address the quality issues of the synthesized adversarial audio as indicated by the MOS evaluations?', 'What are the potential negative societal impacts of this work, and how do you propose to mitigate them?', 'Can you clarify the specific contributions of your work compared to previous uses of CVAE in generating adversarial examples?', 'How do you address the lower quality of generated adversarial examples as indicated by the MOS score?', 'What measures have been taken to address potential negative societal impacts and ethical concerns of the proposed method?', 'How does the proposed method perform against different ASR models, and is it robust across various settings?']","['The paper does not adequately address the limitations and potential negative societal impacts of the proposed method.', 'The synthesized audio, while effective in fooling ASR models, still shows some distortion as indicated by the MOS scores.', 'The quality of the generated adversarial audio samples is not sufficiently high as indicated by MOS scores.', 'The practical significance of the approach is limited due to the quality issues.', 'The method relies on a white-box assumption, which may limit its applicability in real-world scenarios.', 'Limited analysis on the transferability of the adversarial examples to other ASR models.']",True,2,2,3,4,4,"['Introduces a novel threat model for ASR adversarial attacks.', 'Uses a CVAE to generate adversarial examples from scratch.', 'Proposes an adaptive sign gradient descent algorithm for optimization.', 'Extensive evaluation on three datasets with thorough comparisons to existing methods.']","['Clarity of the methodology section could be improved for better understanding.', 'Lack of detailed analysis on the limitations and potential negative impacts of the proposed method.', 'The quality of the synthesized audio could be further improved, as indicated by the MOS scores.', 'Limited discussion on the transferability of the adversarial examples to other ASR models.', 'Insufficient discussion of potential societal impacts and ethical considerations.', 'Lack of clarity and organization in mathematical formulations and experimental setup.', 'Reproducibility is challenging due to insufficient details provided in the methodology.']",3,2,2,3,Reject
SHbhHHfePhP,"The paper presents Graph Mechanics Networks (GMN) to model the dynamics of interacting objects with geometric constraints. GMN leverages generalized coordinates and equivariant message passing, providing theoretical guarantees of universality. Extensive experiments demonstrate its superiority in prediction accuracy, constraint satisfaction, and data efficiency over existing methods like EGNN.","['Can the proposed method be simplified to reduce its complexity without significantly sacrificing performance?', 'How sensitive is the method to errors in domain knowledge used for forward kinematics?', 'Can the authors provide more intuitive explanations or visualizations for the generalized coordinates and forward kinematics?', 'How robust is the proposed method to different types of constraints and noise in real-world applications?', 'Can the authors discuss potential limitations and negative societal impacts of their work?', 'Could the authors include more ablation studies to further validate the contributions and isolate the impact of different components?', 'Can the authors provide more details on the computational complexity and efficiency of GMN compared to other methods?', 'How robust is GMN to noisy or incomplete input data?', 'Can the authors clarify the steps taken to ensure the reproducibility of their experiments?', 'Can the authors provide more examples to clarify the formulation of the equivariant functions?', 'How does the method perform on datasets where domain knowledge for kinematics decomposition is not readily available?', 'Can the authors provide more comparisons with other state-of-the-art methods on real-world datasets?']","[""The method's complexity and reliance on domain knowledge could limit its practical adoption."", 'Further investigation is needed to understand the sensitivity to errors in the domain knowledge.', 'The paper does not discuss the potential limitations of the approach, such as computational complexity and scalability.', 'Potential negative societal impacts are not addressed.', 'The implementation relies on accurate knowledge of constraints, which may not always be available in real-world scenarios.', 'The paper does not explore the impact of noisy or uncertain constraint information on the performance of GMN.']",False,3,3,3,7,4,"['Addresses a significant challenge in modeling interacting systems with geometric constraints.', 'Combines generalized coordinates with equivariant message passing, offering theoretical guarantees.', 'Extensive experiments with simulated and real-world datasets showing superior performance.', 'Thorough and well-organized presentation.']","['Complexity of the proposed method might hinder practical adoption.', 'Heavy reliance on domain knowledge for forward kinematics.', 'Theoretical aspects are dense and difficult to follow.', 'Limited discussion on potential limitations and negative societal impacts.']",4,3,3,4,Accept
xaTensJtCP5,"The paper introduces 'Ab Initio' objective functions for optimizing neural MCMC proposal distributions. These functions are designed to be compatible with highly expressive neural architectures, which traditional MCMC methods struggle to optimize effectively. The paper provides theoretical foundations, constructs an example objective function, and validates its performance through various experiments.","['How does the proposed method significantly advance the state of the art compared to existing methods?', 'How does the proposed method perform in real-world applications beyond the presented experiments?', 'Can you provide a more detailed explanation or examples of how the Ab Initio objective function parameters were manually fit using approximate Newton-Raphson?', 'How do you plan to address the complexity and clarity issues to make the methodology more accessible to the broader community?', 'Can you provide more insights or initial results on the compatibility and performance of online adaptive procedures with Ab Initio objective functions?', 'How do the Ab Initio objective functions perform in more diverse and less controlled practical settings?', 'Can you provide more details on the potential negative societal impacts and limitations of your proposed method?', 'Can you provide more empirical evidence to substantiate the claims about the superiority of the new method?', 'How does the computational complexity of the proposed method compare to existing methods, especially in high-dimensional settings?', 'Can you simplify some of the technical explanations to make the paper more accessible to a broader audience?', 'Can you provide more details on the implementation and hyperparameter tuning?', 'How does the proposed method perform on real-world high-dimensional datasets?']","['The practical utility and significance of the proposed method in real-world scenarios are not fully demonstrated.', 'Ethical considerations and potential societal impacts are not adequately addressed.', 'The complexity of the proposed method might limit its accessibility and reproducibility.', 'The paper does not fully address the computational complexity and scalability of the proposed method.', 'The empirical validation is somewhat limited, and more evidence is needed to substantiate the claims.']",False,3,2,3,5,4,"['Innovative approach to optimizing neural MCMC proposal distributions.', 'Solid theoretical foundation and detailed construction of the objective functions.', 'Comprehensive experimental validation.', 'Addresses a significant gap in current MCMC optimization techniques.']","['Clarity issues in the explanation of technical details.', 'Potential reproducibility concerns due to lack of detailed implementation specifics.', 'Insufficient discussion on the limitations and potential negative societal impacts.', 'Some claims about the superiority of the new method are not fully substantiated with empirical evidence.', 'Limited discussion on computational complexity and scalability.']",3,3,2,3,Reject
TXqemS7XEH,The paper proposes a novel training strategy called 'Pseudo-to-Real' for efficiently training extremely large models that require high memory footprints. It also introduces Granular CPU offloading for better memory management and GPU utilization. The authors demonstrate the effectiveness of their approach by pretraining a 10-trillion-parameter model using 512 GPUs within 10 days.,"[""How does 'Pseudo-to-Real' compare with other existing techniques in terms of training efficiency?"", 'How generalizable is the proposed strategy to other types of models beyond the ones tested?', ""Can the authors provide more detailed explanations and clarifications on the 'Pseudo-to-Real' training strategy?"", 'Is there a plan to release the code and implementation details to ensure reproducibility?', 'Could the authors provide more theoretical analysis to support the claims of efficiency and performance improvements?', 'What are the potential negative societal impacts of creating and deploying such large-scale models, and how do you plan to mitigate them?', 'Can you provide more details and experimental validation on the Granular CPU offloading mechanism?']","['The paper acknowledges potential negative societal impacts but could provide more detailed mitigation strategies.', 'More clarity is needed on the limitations of the proposed methods in different settings.', 'Theoretical analysis supporting the efficiency claims is limited.', 'The paper does not address the potential negative societal impacts of creating and deploying large-scale models.']",False,3,3,3,6,4,"['Novel training strategy for large models', 'Comprehensive experimental validation', 'Potential for significant impact in AI research', 'Addresses a critical challenge in the field of efficient training of massive models']","['Feasibility and generalizability need further validation', 'Some technical aspects and results lack clarity', 'Limited theoretical analysis to support the claims', 'Lack of detailed explanations and reproducibility details in some experiments', 'Insufficient discussion on potential negative societal impacts']",3,3,3,4,Accept
iaxWbVx-CG_,"The paper proposes Hierarchical Cross Contrastive Learning (HCCL), a method designed to enhance self-supervised learning in computer vision by utilizing hierarchical projections and cross-level contrastive learning. The approach aims to improve the generalization ability of visual representations by leveraging features from multiple levels of a projection head. The authors validate their method through extensive experiments across various tasks, including classification, detection, and segmentation, showing improved performance over several baselines.","['Can you provide more intuitive explanations or visualizations to help understand the hierarchical projection head and the cross contrastive loss?', 'How sensitive is the method to hyperparameters such as the learning rate for predictors and the number of levels in the hierarchical projection head?', 'Can you elaborate on the theoretical foundations of why cross-level contrastive learning improves performance?', 'Can the authors provide more details on the implementation of the hierarchical projection head?', 'How does the computational complexity of HCCL compare to other SSL methods?']","['The method might be computationally expensive given the additional hierarchical projections and cross-level comparisons.', 'The applicability of HCCL to a broader range of SSL frameworks needs further experimentation.', 'The paper does not discuss the potential misuse or ethical concerns related to the deployment of enhanced visual representations.', 'The method is primarily validated on commonly used datasets and tasks. Its applicability to other domains remains to be seen.']",False,3,2,3,5,4,"['Novel approach leveraging hierarchical features and cross-level contrastive learning.', 'Extensive experimental validation across multiple tasks and datasets.', 'Improved performance metrics compared to several baseline models.']","['Complex and somewhat unclear methodology section.', 'Limited theoretical justification for the proposed method.', 'Insufficient details for reproducibility.', 'Claims of general applicability are not fully substantiated by experiments.', 'Lack of discussion on potential limitations and negative societal impacts.']",3,3,2,3,Reject
EMLJ_mTz_z,"The paper introduces a novel graph-based framework for predicting the performance of neural networks (NNs) by representing them as time-evolving graphs. It proposes a new, compact graph representation for convolutional layers and evaluates the method's effectiveness on various NN architectures and datasets. The framework aims to predict NN performance based on early training dynamics, potentially aiding in early stopping. The main contributions include a new graph representation for convolutional layers, a multi-step framework for performance prediction, and extensive empirical analysis on CIFAR-10 and ImageNet datasets.","['How does the computational overhead of the rolled graph representation compare to traditional early stopping techniques?', 'Can the proposed framework be extended or adapted to other types of neural networks beyond CNNs?', 'What are the specific limitations and potential negative societal impacts of this work?', 'How does the proposed graph representation specifically improve upon the existing unrolled representation in terms of predictive accuracy?', 'Can the authors provide more theoretical insights or justifications for the choice of graph-based features (e.g., weighted degree, eigenvector centrality)?', 'How does the method compare to other performance prediction techniques beyond early stopping?', 'Can the authors provide more details on how the proposed method advances the state-of-the-art?', ""Can the authors clarify how the proposed 'rolled' graph representation differs from existing representations?"", 'How does the proposed method perform on larger and more complex datasets beyond CIFAR-10 and ImageNet?', 'How does the proposed framework compare with state-of-the-art methods in terms of predictive accuracy and computational efficiency?', 'Can the proposed graph representation be extended to other types of layers beyond convolutional and fully-connected layers?', 'What are the potential limitations and negative societal impacts of the proposed approach?', 'Could the authors provide more details on how the graph representation for convolutional layers is constructed?', 'How does the proposed method compare with other NN performance prediction methods in terms of accuracy and computational efficiency?', 'Can the method be applied to other types of NNs (e.g., recurrent neural networks) and tasks (e.g., language modeling)?']","['The paper does not adequately address the computational overhead of the proposed methods.', 'The discussion on limitations and negative societal impacts is minimal.', 'The scalability of the proposed method to very large NNs or datasets is not thoroughly evaluated.', 'The proposed approach may not capture all relevant dynamics, such as those occurring in recurrent or attention-based networks.', 'The reliance on specific graph features (degree and eigenvector centrality) may limit the generalizability of the approach.', 'The computational complexity of generating graphs and extracting features for very large networks is a potential concern.', ""The method's applicability to other types of neural networks and tasks is not explored.""]",False,3,3,3,6,4,"['Novel graph-based representation of convolutional layers.', 'Multi-step framework for NN performance prediction.', 'Extensive empirical validation on multiple datasets and architectures.', 'Potential for efficient early stopping in NN training.']","['Lack of theoretical analysis to support the empirical findings.', 'Insufficient detail on the computational overhead of the proposed methods.', 'Limited discussion on the limitations and negative societal impacts.', 'Results may not generalize to all types of NNs or datasets.', 'The clarity and organization of the paper could be improved.', 'The novelty of the contributions is somewhat limited, as the idea of representing NNs as graphs is not entirely new.', 'The significance of the contributions is unclear, as it is not evident how this approach advances the state-of-the-art.', 'The paper does not adequately address the limitations and potential negative societal impacts of the work.']",3,3,3,3,Reject
kO-wQWwqnO,"The paper proposes L2BGAN, a GAN-based model for unsupervised low-light image enhancement. It introduces geometric and lighting consistency along with contextual loss and uses multiscale color, texture, and edge discriminators. Extensive experiments on multiple datasets are conducted to demonstrate the effectiveness of the approach.","['Can the authors provide more details on the geometric and lighting consistency constraints?', 'How do the proposed discriminators compare with traditional GAN discriminators in terms of performance?', 'What are the potential failure modes of the proposed approach?', 'Can the authors discuss any potential negative societal impacts of their work?']","['The individual components of the proposed method are not novel.', 'Some parts of the methodology are unclear, making reproduction difficult.', 'Limited evaluation on potential failure modes.', 'Limited discussion on limitations and potential negative societal impacts.']",False,3,3,3,5,4,"['Addresses an important problem in image enhancement without paired supervision.', 'Interesting combination of geometric and lighting consistency with contextual loss.', 'Utilizes multiscale color, texture, and edge discriminators.', 'Comprehensive evaluation on multiple datasets.']","['Lacks novelty in individual components; most methods are standard in the literature.', 'Some parts of the methodology are not clearly explained, making reproduction difficult.', 'Evaluation does not adequately address potential failure modes.', 'Limited discussion on limitations and potential negative societal impacts.', 'Inconsistencies in reported results and presentation could be improved.']",3,3,3,3,Reject
fJIrkNKGBNI,"The paper proposes a novel piece-wise polynomial filtering approach for Graph Neural Networks (GNNs) to improve performance on heterophilic graphs. The method involves learning multiple adaptive polynomial filters acting on different subsets of the graph's eigen-spectrum. The authors provide a theoretical analysis, comprehensive experiments, and comparisons with various state-of-the-art methods.","['How does the proposed method perform on extremely large graphs (millions of nodes)?', 'Can the authors provide more details on the computational overhead introduced by the piece-wise polynomial filters?', 'How does the method compare to other advanced filtering techniques not discussed in the paper?', 'Can the authors provide more detailed explanations of the mathematical concepts, especially the eigendecomposition and polynomial filter learning?', 'Are there any specific reasons for not including more diverse baselines in the empirical evaluation?', 'Can the authors provide more details on the implementation, such as parameter settings and computational resources used?', 'Is there a significant difference in performance when using different polynomial initialization schemes, and how does this impact the overall results?', 'Could the authors elaborate on the potential practical implications of their method in real-world applications, given the increased computational complexity?', 'How does the model handle very large graphs where full eigendecomposition is infeasible?', 'Can the authors provide more details on the computational trade-offs and possible optimizations for large-scale implementations?', 'Are there any specific datasets or scenarios where the proposed method does not perform well?']","[""The method's scalability to very large graphs remains to be thoroughly evaluated."", 'The societal implications of improved performance on heterophilic graphs could be better explored.', 'The computational cost of the proposed method is high due to the need for eigendecomposition.', 'The approach may not scale well to very large graphs with millions of nodes.', 'Potential negative societal impact if used for privacy-invasive applications.', 'The increased computational cost might limit the practical applicability of the method.']",False,3,3,3,6,4,"['Novel approach to filter design in GNNs using piece-wise polynomials.', 'Comprehensive theoretical analysis supporting the proposed method.', 'Extensive experimental evaluation across multiple datasets.', 'Clear identification of the limitations of existing methods and how the proposed method addresses them.']","['The contribution is somewhat incremental given the existing work on polynomial filters in GNNs.', 'The presentation is cluttered and could be more concise to improve readability.', 'Experimental comparisons, while comprehensive, could be more rigorously evaluated.', 'Potential societal implications of improved performance on heterophilic graphs need more thorough exploration.', 'Potential scalability issues due to the requirement of eigendecomposition.', 'Limited discussion on computational trade-offs for very large graphs.', 'Insufficient practical implementation details for scaling to large datasets.']",4,3,3,3,Accept

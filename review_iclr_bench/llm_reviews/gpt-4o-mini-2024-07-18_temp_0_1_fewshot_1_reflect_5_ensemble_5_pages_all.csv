paper_id,Summary,Questions,Limitations,Ethical Concerns,Soundness,Presentation,Contribution,Overall,Confidence,Strengths,Weaknesses,Originality,Quality,Clarity,Significance,Decision
tDirSp3pczB,"The paper establishes sharper learning bounds for contrastive unsupervised representation learning (CURL), demonstrating the impact of negative sample size on downstream classification performance. The authors derive both upper and lower bounds that highlight the importance of larger negative samples, supported by experiments on various datasets, thus providing a clearer theoretical framework for understanding CURL's effectiveness.","['Could the authors clarify some of the more complex mathematical notations and provide examples for better understanding?', 'What are the practical implications of the sharper bounds established in this study for real-world applications?']","['The theoretical implications are strong, but the practical significance of the findings needs to be more clearly articulated.', 'The clarity of the writing, particularly in the theoretical sections, requires improvement to enhance accessibility.']",False,3,2,3,6,4,"['Theoretical contributions provide sharper bounds on the performance of CURL that are tightly linked to negative sample size.', 'Extensive empirical validation across synthetic, vision, and language datasets strengthens the theoretical claims.', 'Addresses an important and timely topic in the field of representation learning with practical implications.']","['The mathematical formulations and proofs may be difficult for readers to follow due to the complex notation and structure.', 'Some experimental results could benefit from clearer explanations of their significance and implications.', 'The paper lacks a thorough discussion on the practical applications of the findings in real-world scenarios.']",3,3,3,4,Reject
YDud6vPh2V,"The paper introduces ξ-learning, a novel transfer learning mechanism in reinforcement learning that re-evaluates policies for general reward functions. It includes theoretical proofs of convergence and experimental comparisons with standard Q-learning and successor feature frameworks, demonstrating advantages for both linear and general reward tasks.","['Can the authors clarify the practical implications of the theoretical results presented?', 'What are the limitations of ξ-learning compared to traditional methods?', 'How does the performance of ξ-learning scale with increasing task complexity?']","['The clarity of mathematical arguments may hinder understanding for readers not deeply familiar with the area.', 'The paper does not address the potential impact of using ξ-learning in real-world applications.']",False,2,2,3,5,4,"['The introduction of ξ-learning provides a new perspective on handling general reward functions in transfer learning.', 'The theoretical proofs of convergence add credibility to the proposed method.', 'Experimental results show the potential advantages of ξ-learning over existing methods.']","['The clarity of the paper is lacking; key concepts and their implications are not sufficiently explained.', 'The paper does not adequately discuss the limitations or potential risks of the proposed method.', 'Comparative evaluations with existing algorithms are limited, and the paper could benefit from more comprehensive empirical validation.']",3,2,2,4,Reject
xZ6H7wydGl,"The paper proposes a new method for learning stochastic differential equations (SDEs) using an importance sampling estimator that avoids the computational expense of traditional SDE integrators. The proposed method allows for lower-variance gradient estimates and is parallelizable, leading to significant reductions in computation time.","['Can the authors clarify the steps involved in their algorithm to enhance understanding?', 'What measures are taken to validate the generalizability of their method beyond the Lorenz system?', 'Could additional comparisons with existing SDE learning methods be included to strengthen the evaluation?', 'Can the authors provide additional details on the implementation of the algorithms to enhance reproducibility?', 'What specific improvements were observed in various dimensions when compared to existing methods?']","['The paper may benefit from a more thorough exploration of the clarity of the proposed algorithms and methods.', 'The experiments could be expanded to include diverse datasets and scenarios to verify the effectiveness of the approach.', 'The paper does not fully address the limitations of the proposed method, such as potential biases introduced by the importance-sampling approach.']",False,2,2,2,4,4,"['The method introduces a novel importance-sampling estimator that does not rely on SDE integrators, improving computational efficiency.', 'It provides theoretical insights into the lower variance gradients achieved through the new approach.', 'The approach is scalable to high-dimensional processes, which is a significant advantage over existing methods.']","['The clarity of the proposed methods and algorithms is lacking, making it difficult to fully grasp the implementation details.', 'The experiments are mainly conducted on specific datasets (e.g., Lorenz system), which may limit generalizability.', 'The comparison with existing methods is insufficient, making it unclear how much of an improvement is offered by the proposed method.', 'The originality of the approach is questionable, as the use of importance sampling in this context has been previously explored in literature.']",3,2,2,3,Reject
CNY9h3uyfiO,"This paper investigates reward shifting in value-based deep reinforcement learning, demonstrating that it can positively affect learning by altering the initialization of the Q-function. The authors propose that positive shifts may lead to conservative exploitation while negative shifts encourage curiosity-driven exploration. They validate their claims through experiments across various tasks, including offline RL and both continuous and discrete controls.","['Can the authors clarify the implications of the reward shifting on policy learning, particularly in various RL scenarios?', 'What limitations does their approach have when applied to more complex tasks or environments?', 'Could the authors specify the contributions of their proposed method in the context of existing reward shaping techniques?', 'What specific ablation studies were conducted to support the claims about the effectiveness of positive and negative reward shifting?']","['The analysis and discussion around the results lack rigor, making it difficult to assess the practical implications of the proposed technique.', 'More comprehensive comparisons with existing methods in different settings would strengthen the paper.', 'The paper does not adequately address the limitations of the proposed method and its potential negative impacts on learning stability.']",False,3,3,3,5,4,"['The concept of reward shifting as a method to influence exploration and exploitation is novel and relevant.', 'The paper provides a comprehensive theoretical foundation linking reward shifts to Q-function initialization.', 'Experimental results show improvements in learning performance across different RL settings.']","['The theoretical explanations and implications of reward shifting lack clarity and depth.', 'The experimental validation appears to be limited in scope, and the generalizability of results to other tasks is uncertain.', 'The paper could benefit from more detailed ablation studies to better understand the impacts of the proposed methods.', 'The clarity of the paper is compromised by dense technical language and insufficient explanations of certain concepts.', 'Some results appear to be anecdotal or not robust across varying conditions, lacking comprehensive analysis.']",3,3,3,4,Reject
fXHl76nO2AZ,"The paper introduces Gradient Importance Learning (GIL), a method for training models to make predictions directly from incomplete datasets without requiring imputation. This approach leverages reinforcement learning to adjust gradient updates during training based on missingness patterns in the data. The authors claim improved performance on several datasets compared to traditional imputation-based methods.","['Can the authors clarify how GIL significantly improves upon existing methods in terms of both methodology and performance?', 'What specific measures have been taken to ensure the robustness of the experimental results?', 'Could the authors provide additional context on the choice of datasets and how they might represent the broader applicability of their method?']","['The clarity of the paper needs improvement to facilitate understanding of the proposed method.', 'The assumptions underlying the GIL framework may need to be explicitly stated and discussed.']",False,2,2,2,5,4,"['The problem of missing data is highly relevant, especially in fields such as healthcare.', 'The proposed GIL framework presents a novel way to handle missing data by integrating reinforcement learning with gradient updates.', 'The paper includes experiments on real-world datasets, demonstrating the potential effectiveness of the GIL approach.']","['The paper lacks clarity in its presentation, making it difficult to follow the methodology and results.', 'The novelty of the proposed method could be questioned, as similar ideas have been explored in the context of attention mechanisms in deep learning.', 'Experimental comparisons with existing state-of-the-art imputation methods are not thorough enough to convincingly demonstrate the superiority of the proposed approach.', 'The paper does not adequately address potential limitations or assumptions made by the GIL framework.']",3,2,2,3,Reject
bglU8l_Pq8Q,"The paper investigates the performance gap between dual-encoder (DE) and cross-attention (CA) models in information retrieval, proposing that the gap may stem from overfitting in DE models rather than capacity limitations. The authors introduce a distillation strategy to improve DE performance by mimicking CA models. Theoretical and empirical contributions are made, but clarity and methodological details could be enhanced.","['Could the authors clarify the methodology used in experiments, particularly the training and evaluation processes?', 'What considerations were made regarding potential biases in the training data, and how might they affect the results?', 'Can the authors provide more clarity on the experimental setup and results?']","['The paper does not sufficiently address potential biases in the training data, which could impact generalization.', 'The clarity of the results presentation may lead to misinterpretation of the empirical findings.']",False,3,3,3,6,4,"['Addresses a significant problem in information retrieval regarding the performance of DE versus CA models.', 'Provides theoretical insights into the expressivity of DE models and their potential to model complex scores.', 'Introduces a novel distillation strategy that effectively improves the performance of DE models based on empirical results.']","['The clarity of explanations can be improved; some sections are dense and may challenge readers.', 'While the experiments are comprehensive, additional methodological details would enhance reproducibility.', 'Discussion on limitations and potential biases in the datasets used could be more pronounced.']",3,3,3,4,Reject
cU8rknuhxc,"The paper introduces DISDAIN, an intrinsic reward mechanism for unsupervised skill learning in reinforcement learning that addresses pessimistic exploration by incentivizing exploration in states of high epistemic uncertainty. It employs an ensemble of discriminators to measure disagreement and provides empirical results demonstrating improved skill learning in both grid world and Atari environments.","['Can the authors clarify how DISDAIN performs in environments with less frequent state transitions compared to the Atari games?', 'What specific modifications or adaptations might be necessary for DISDAIN to be applied effectively in continuous action spaces?', 'Could the authors elaborate on the limitations of DISDAIN and potential failure modes in specific scenarios?']","['The reliance on an ensemble of discriminators may introduce additional complexity in terms of computational resources and training stability.', 'The paper does not sufficiently address potential failure cases or scenarios where DISDAIN might not provide a significant advantage.', 'The implications of using DISDAIN in continuous skill spaces or more complex environments are not discussed.']",False,3,3,3,6,4,"['The introduction of the DISDAIN exploration bonus is a novel approach to tackle the issue of pessimistic exploration in unsupervised skill learning.', 'The paper presents extensive empirical results showing the effectiveness of DISDAIN in enhancing the learning of skills across multiple environments.', 'The theoretical foundation for the method is well-articulated, leveraging concepts from Bayesian inference and information theory.']","['The clarity of the presentation could be improved, especially in explaining the motivation and implications of the proposed method.', 'The paper would benefit from a more thorough exploration of related work and how DISDAIN compares with other exploration bonuses in the literature.', 'While the results are promising, there is limited discussion on the robustness of the method and potential limitations or failure cases.']",3,3,3,4,Reject
HFPTzdwN39,"The paper proposes a method called reverse linear probing to measure the interpretability of self-supervised visual representations by estimating the mutual information between the representations and manually labeled concepts. It aims to provide insights into the semantic content captured by these representations, contrasting with traditional linear probing methods. However, the study lacks thorough comparative analysis and justification for its chosen metrics.","['Can the authors provide more examples that illustrate the effectiveness of reverse probing in distinguishing between different clusters?', 'How do the authors plan to address the limitations of interpretability metrics in practice?', 'What measures are in place to ensure the reliability of the automated expert classifiers used for labeling?']","['The dependence on manually labeled datasets may limit the generalizability of the findings.', ""The method's reliance on specific clustering algorithms may introduce biases that are not accounted for in the analysis.""]",False,2,2,3,5,4,"['The approach addresses an important gap in understanding self-supervised representations, which is critical for their deployment.', 'It introduces a novel methodology rooted in information theory, potentially leading to better evaluations of visual representations.', 'The extensive experiments on various self-supervised models provide a valuable benchmark for future research.']","['The clarity of the presentation could be improved; some sections are dense and may be hard to follow for readers unfamiliar with the underlying concepts.', 'The originality of the proposed method is somewhat limited, as it builds upon existing techniques without introducing significant innovations.', 'The experimental analysis, although extensive, lacks clarity regarding the robustness and reproducibility of the findings.', 'The paper does not adequately address the limitations of using automated expert classifiers for labeling data, which could introduce biases in the evaluation.']",3,2,2,3,Reject
EJKLVMB_9T,"The paper proposes SplitRegex, a framework for faster regex synthesis using a divide-and-conquer strategy via a neural network called NeuralSplitter. The framework aims to improve the speed and accuracy of regex generation from positive and negative string examples by splitting the strings into parts and synthesizing subregexes. Empirical results indicate that this approach outperforms existing methods on benchmark datasets.","['Can the authors elaborate on the scenarios where the proposed method might fail or produce suboptimal results?', 'How does the choice of hyperparameters affect the performance of the NeuralSplitter model?', 'What specific innovations does SplitRegex introduce compared to existing regex synthesis techniques?']","['The paper does not adequately address the limitations of the proposed framework, particularly in terms of robustness and potential edge cases.', 'The lack of clarity in methodology may raise concerns regarding reproducibility and understanding of how to apply the framework effectively.']",False,2,2,2,4,4,"['The introduction of a divide-and-conquer approach for regex synthesis is novel and relevant.', 'The use of a neural network to intelligently split example strings has potential to improve performance.', 'Empirical results demonstrate improvements over existing methods on benchmark datasets.']","['The paper lacks clarity in several sections, making it difficult to follow the methodology and understand the contributions fully.', 'The experimental results do not convincingly show substantial improvements over baselines; the performance increase seems marginal in many cases.', ""There is insufficient discussion on the limitations and potential failure cases of the proposed method, which is essential for establishing the framework's robustness."", 'The paper could benefit from more detailed examples and clearer explanations of how the NeuralSplitter model works.']",3,2,2,3,Reject
MWQCPYSJRN,"The paper introduces Generative Negative Replay (GNR), a method for continual learning that uses generated data as negative examples to mitigate catastrophic forgetting. The authors assert that GNR can be beneficial in class-incremental and data-incremental scenarios, especially when traditional generative replay approaches fail due to data degradation. The approach is evaluated on challenging datasets such as CORe50 and ImageNet-1000, showing improved performance compared to existing methods.","['Can the authors clarify the assumptions made about data quality in their experiments?', 'What specific changes would the authors propose for the ablation studies to enhance understanding of their approach?', 'Can the authors provide a more rigorous theoretical analysis of why generative negative replay is expected to perform better?']","['The clarity of the writing needs improvement to make the contributions more accessible.', 'More rigorous experimental validation is needed to substantiate the claims regarding the effectiveness of GNR.', 'The potential limitations of using generated data as negative examples should be more thoroughly discussed.']",False,2,3,3,5,4,"['Addresses a critical issue in continual learning: catastrophic forgetting.', 'Introduces a novel concept of using generated data as negative examples.', 'Demonstrates effectiveness on complex datasets, providing valuable insights.']","['Lacks clarity in the presentation of methodology and experimental setup.', 'Insufficient experimental validation and comparisons with state-of-the-art methods.', 'Theoretical foundations are not well-supported, leading to unclear claims.']",4,3,3,4,Reject
8CEJlHbKoP4,"The paper proposes METAGEN, an unsupervised model that integrates metacognition into object detection systems to enhance performance by addressing hallucinations and misses. The model learns a meta-representation of its perceptual system and applies cognitive principles to improve object detection accuracy.","['Can the authors provide more detailed information on the learning process of the metacognitive representation?', 'How do the authors ensure that the improvements observed are indeed due to the metacognitive layer and not merely a result of the chosen datasets or object detection models?', 'What additional metrics could be included to better assess the spatial accuracy of detections?']","['The paper lacks a robust discussion of limitations and potential negative impacts of the proposed method.', 'The experimental setup needs to clarify how representative the synthetic datasets are of real-world scenarios.']",False,3,3,3,6,4,"['The concept of integrating metacognition into object detection systems is innovative and could lead to advancements in model robustness.', 'The application of cognitive principles related to object perception to enhance detection models is an interesting approach.', 'The evaluation of METAGEN across multiple object detection architectures demonstrates its versatility.']","['The explanation of the METAGEN model lacks sufficient detail, particularly concerning the mechanics of how the metacognitive representation is learned and used.', 'Experimental results are not clearly presented, and the metrics used to evaluate performance do not convincingly demonstrate the benefits of METAGEN over traditional methods.', 'There is a lack of clarity regarding how the integration of cognitive principles translates into practical improvements in detection accuracy.', 'The paper does not adequately address potential limitations or the generalizability of the findings to real-world applications.']",3,3,3,4,Reject
WVX0NNVBBkV,The paper proposes a method for enhancing adversarial robustness in neural networks by leveraging proxy distributions generated from advanced generative models. It provides theoretical insights using conditional Wasserstein distance and empirical results showing improvements in robustness across various datasets.,"['Can the authors clarify how the proposed method addresses the limitations of existing approaches in adversarial robustness?', 'What measures have been taken to ensure that the improvements seen with synthetic data will generalize to real-world scenarios?', 'Could the authors elaborate on the potential limitations and risks associated with using synthetic data in adversarial training?']","['The reliance on synthetic data raises questions about the applicability of the findings in real-world settings.', 'The clarity of the theoretical contributions needs to be improved for better understanding.']",False,3,3,3,7,4,"['The theoretical foundation based on conditional Wasserstein distance offers an interesting perspective on the transfer of robustness from proxy to real distributions.', 'Empirical results demonstrate significant improvements in robust accuracy across different datasets and threat models, showcasing the effectiveness of the proposed method.', 'The paper addresses a relevant issue in the field of adversarial machine learning, which is the challenge of obtaining robust classifiers with limited access to real-world training data.']","['The clarity of the exposition is lacking in several sections, making it difficult to follow the arguments and understand the significance of the theoretical contributions.', ""The paper may over-rely on synthetic data from generative models, and it's unclear how well these results will generalize to real-world scenarios."", 'There is limited discussion on the limitations of the proposed approach and the potential negative implications of using synthetic data in adversarial training.', 'The experimental evaluation could be more comprehensive. For instance, additional datasets and a wider variety of generative models would strengthen the claims made.']",3,3,3,4,Accept
74x5BXs4bWD,"The paper presents EDO-CS, an Evolutionary Diversity Optimization algorithm that employs clustering-based selection to balance quality and diversity in reinforcement learning policies. While it addresses the need for diverse policies in complex environments, the paper lacks significant novelty and clarity.","['What specific innovations does EDO-CS introduce beyond existing quality-diversity optimization approaches?', 'Can you elaborate on the effectiveness of your clustering-based selection mechanism compared to other selection methods?', 'What additional experiments could strengthen the claims made about the performance and efficiency of EDO-CS?']","['The paper does not sufficiently address the limitations of the proposed algorithm or potential negative impacts of its application.', 'More comprehensive ablation studies are needed to validate the effectiveness of the proposed methods.']",False,2,2,2,4,4,"['Addresses the important issue of maintaining policy diversity in reinforcement learning.', 'Introduces a selection mechanism that emphasizes both quality and diversity.', 'Includes experiments across various environments.']","['Limited originality, closely resembling existing quality-diversity algorithms without substantial improvements.', 'Poor clarity in methodology, making it difficult to follow the contributions.', 'Insufficient empirical validation and comparisons with a broader range of existing methods.', 'Weak theoretical justification for the proposed method.']",2,2,2,3,Reject
4tOrvK-fFOR,"The paper proposes a novel method for sound source detection using multi-scale synperiodic filter banks to enhance time-frequency resolution from raw audio waveforms. It claims to outperform existing techniques in direction of arrival and physical location estimation tasks. However, the methodology lacks clarity, and the results do not convincingly demonstrate the proposed method's superiority over established approaches.","['Could the authors clarify the rationale behind the choice of periodicity in the synperiodic filter bank?', 'How do the authors ensure the reproducibility of their results, and can they provide more details on the training process?', 'What specific baseline methods were tested, and how do they compare in terms of architecture and performance?', 'Can the authors provide additional details regarding the implementation of the synperiodic filter bank?']","['The authors should provide more detailed explanations regarding the theoretical benefits of their approach compared to traditional methods.', 'The computational complexity of the method should be better discussed, especially in relation to its practical applications.', 'The paper does not fully address the implications of increased computational time, which could affect practical deployment.']",False,2,2,3,4,4,"['The proposed synperiodic filter bank presents an innovative approach to improving time-frequency resolution in sound processing.', 'The paper addresses a significant problem in sound source detection relevant to various applications, including robotics and audio analysis.', 'Experimental results indicate that the proposed method achieves better performance compared to existing methods.']","['The clarity of the writing is lacking, making it difficult to follow the proposed methodology and theoretical underpinning.', 'The paper does not provide sufficient detail in the experimental setup, including hyperparameter settings and training procedures.', 'Ablation studies are limited and do not fully explore the contributions of individual components of the proposed architecture.', 'The evaluation against existing methods lacks comprehensive analysis and comparison metrics.']",3,2,2,3,Reject
xFOyMwWPkz,"The paper proposes a method for quantitatively assessing the status of individual units in convolutional neural networks (CNNs) using a topological measure called feature entropy. This method aims to provide reliable indications of unit effectiveness across different network architectures and training conditions. However, the paper faces significant challenges in clarity, methodology, and experimental validation.","['Can the authors provide a clearer definition of feature entropy and how it is calculated?', 'What specific advantages does feature entropy provide compared to existing metrics?', 'Can the authors provide more detailed experimental results comparing feature entropy to other methods under various conditions?']","['The paper does not adequately discuss the limitations of feature entropy, particularly in regards to its applicability across different types of CNN architectures.', 'The clarity of the proposed method and its justification are lacking, which may hinder reproducibility.']",False,2,2,2,4,4,"['The introduction of feature entropy as a measure to assess individual CNN units is a novel approach.', 'The use of topological data analysis provides an interesting perspective on CNN interpretability.', 'The paper addresses an important issue in understanding CNN units and their effectiveness.']","['The methodology is overly complex and lacks clarity, making it difficult to understand how the proposed approach works in practice.', 'The experimental validation is limited, primarily focusing on a single architecture (VGG16) without sufficient exploration of other models.', 'The claims regarding the robustness and advantages of feature entropy are not convincingly supported by the experimental results.', 'There is insufficient discussion on the practical implications of using feature entropy in real-world applications.']",3,2,2,3,Reject
gPvB4pdu_Z,"The paper presents a compositional training framework for deep AUC maximization, integrating cross-entropy loss with AUC loss to enhance feature representation and classifier performance. It proposes a new stochastic optimization algorithm and provides empirical evaluations across various datasets, demonstrating improvements over traditional two-stage approaches.","['Could the authors clarify the theoretical foundations of the proposed compositional objective?', 'What specific ablation studies were conducted to verify the effectiveness of each component of the composite training method?', 'How do the authors justify the choice of hyperparameters in their experiments?']","['The paper does not sufficiently address the limitations of the proposed method, particularly in practical applications.', 'The clarity of the proposed algorithm and its theoretical analysis could be improved to support the claims more effectively.']",False,3,3,3,5,4,"['Addresses a significant problem in deep learning related to imbalanced data.', 'The compositional training framework has the potential to unify feature learning and classifier performance optimization.', 'Extensive empirical studies demonstrate improvements over baseline methods.']","['Lacks clarity in explaining the derivation and optimization of the compositional objective functions.', 'Experimental evaluations are not comprehensive; more ablation studies and baseline comparisons are needed.', 'The theoretical claims regarding convergence and performance improvements require more robust justification.']",3,3,3,4,Reject
Eot1M5o2Zy,"The paper introduces AestheticNet, a network designed to predict facial attractiveness while addressing bias in data sets used for training. The authors claim that their methodology can enhance fairness in AI applications, particularly in sensitive industries such as recruitment and security. The paper discusses human biases in facial aesthetic judgments and proposes techniques to mitigate these biases in the model's predictions.","[""Could the authors provide more detailed empirical results to support the claims made about AestheticNet's performance?"", 'How do the authors quantify and evaluate bias in their experiments? What specific metrics are used?', 'What are the broader societal implications of deploying such a system, and how do the authors plan to address potential negative consequences?']","['The empirical results are not robust enough to support the claims regarding the effectiveness of AestheticNet.', 'There is insufficient discussion about the ethical considerations and potential societal impacts of the proposed system.']",True,2,2,2,4,4,"['The topic of bias in facial attractiveness prediction is highly relevant and socially significant.', 'The authors address an important ethical issue regarding bias in AI systems, specifically in facial beauty prediction.', 'The methodology incorporates data augmentation and the use of GANs to address bias in training data.']","['The claims regarding the accuracy and effectiveness of AestheticNet are not sufficiently supported by rigorous empirical evidence.', 'The paper lacks clarity in presenting the methodology and the experimental results, making it difficult to assess the validity of the claims.', ""There is a significant lack of depth in the analysis of the proposed method's ethical implications and potential societal impacts."", 'The experimental design does not adequately describe how bias is quantified or the robustness of the results across different datasets.']",2,2,2,3,Reject
rxF4IN3R2ml,"The paper proposes MQTransformer, a novel architecture for multi-horizon time series forecasting that incorporates advanced attention mechanisms and context-dependent positional encodings to improve accuracy and reduce excess volatility. It claims significant performance improvements over existing models in empirical evaluations.","['Can the authors provide additional clarification on the experimental setup and the datasets used?', 'Could the authors elaborate on the design choices for their attention mechanisms and provide more justification for these choices?', 'What specific metrics were used to assess the reduction in volatility, and how were these computed?']","['The paper does not sufficiently address the limitations of the proposed architecture, especially in terms of its generalizability to other forecasting tasks. It would be beneficial to include a discussion on potential limitations and how they might be mitigated.', 'The authors should better address the limitations of their approach and discuss potential negative consequences of the proposed methods.']",False,3,3,3,6,4,"['The proposed architecture addresses key issues in multi-horizon forecasting, particularly the challenges of excess volatility and maintaining accuracy.', 'The integration of context-dependent positional encoding and horizon-specific attention is a novel contribution that can provide significant improvements.', 'Empirical results demonstrate notable improvements in forecasting accuracy on large-scale datasets.']","['The clarity of the paper is compromised by its organization, making it difficult to follow the methodologies and findings.', 'The paper lacks sufficient theoretical justification for several architectural choices, leaving questions about their effectiveness.', 'The experimental results are somewhat limited in scope, lacking robustness across diverse scenarios.']",3,3,3,4,Reject
jJOjjiZHy3h,"The paper proposes AdversarialAugment (AdA), a method aimed at improving the robustness of image classifiers against common corruptions and adversarial perturbations by leveraging image-to-image models to generate adversarially corrupted augmented images. It presents theoretical motivation for its approach, empirical results demonstrating state-of-the-art performance, and a discussion on computational complexity.","['Can the authors clarify the rationale behind the choice of specific image-to-image models used in AdA?', 'What steps are taken to ensure generalizability of the model across different datasets?', 'Could the authors expand upon the experimental setup to include more diverse methods for a clearer comparison?']","['The clarity of the theoretical motivations and the implementation details could be improved.', 'Generalization performance beyond the tested datasets is not well established.', ""The method's reliance on pre-trained models for corruption generation might limit applicability in scenarios where such models are unavailable.""]",False,3,2,3,7,4,"['Addresses a significant problem in machine learning related to robustness against image corruptions.', 'Integrates adversarial training with data augmentation in a novel way, potentially enhancing model performance.', 'Provides strong empirical results that demonstrate improved performance over existing methods.', 'The method reconciles existing techniques in adversarial training and data augmentation, providing a fresh perspective on improving model robustness.']","[""Lacks clarity in certain sections, particularly regarding the algorithm's implementation details and theoretical motivations."", 'The experimental setup could benefit from additional details regarding the choice of models and hyperparameters.', 'Some theoretical aspects could benefit from deeper exploration and explanation, particularly regarding the assumptions made.', 'The clarity in the experimental section can be improved; some results and comparisons are dense and may confuse the reader.']",3,3,2,4,Accept
Jjcv9MTqhcq,"The paper proposes a new supervised pre-training method called LOOK, which utilizes Leave-One-Out K-Nearest-Neighbor classification to enhance transferability to downstream tasks by preserving intra-class differences. It claims to outperform existing supervised and self-supervised pre-training methods across multiple datasets.","['Can the authors provide more substantial evidence on how LOOK outperforms self-supervised methods?', 'Can the authors clarify their choices for hyperparameters like k, queue size, and temperature?', 'Could the authors include more ablation studies on the individual components of the LOOK method?', 'How does the proposed method compare with existing literature that also attempts to address intra-class variation?']","['The paper does not adequately address the limitations of the proposed method or discuss potential negative societal impacts.', 'The evaluation lacks depth in exploring the effects of varying hyperparameters and components of the LOOK method.']",False,2,2,3,4,4,"['The proposed method addresses an important issue in supervised pre-training: the neglect of intra-class differences.', 'LOOK shows promising results in improving transferability on multiple downstream tasks compared to existing methods.', 'The experiments demonstrate the effectiveness of the proposed method with extensive empirical studies.']","['The paper lacks a clear explanation of how LOOK significantly differs from and improves upon existing methods, particularly in the context of self-supervised learning.', 'The presentation of the methodology is unclear and overly complex, which could hinder understanding.', 'The empirical results, while promising, lack depth in terms of comparisons against a wider range of methods.', 'The novelty of the approach could be questioned, as it builds on existing concepts in a somewhat traditional framework.']",3,2,2,4,Reject
9jsZiUgkCZP,"The paper proposes a unified compression framework for Vision Transformers (ViTs) that integrates pruning, layer skipping, and knowledge distillation under a single optimization framework. The authors claim that their approach can significantly reduce computational costs while maintaining accuracy, and they provide experimental results demonstrating its effectiveness on various ViT models.","['Can the authors clarify the integration process of the three compression techniques? How does the optimization algorithm handle conflicts between them?', 'What other ViT architectures have been tested with UVC? Are there plans for broader evaluations?', 'Could the authors provide more detailed comparisons with existing state-of-the-art compression methods?']",['The paper does not adequately address the potential limitations of the proposed method or discuss the scenarios where it might fail.'],False,2,2,3,5,4,"['Addresses the important and practical problem of compressing Vision Transformers, which are computationally intensive.', 'Presents a novel integration of multiple compression techniques into a single optimization framework, which is a valuable contribution to the field.', 'Conducts experiments on well-known ViT architectures and provides results that indicate competitive performance compared to existing methods.']","['The methodology lacks clarity, particularly in the explanation of how the three compression techniques are integrated and optimized simultaneously.', 'The experimental evaluation does not sufficiently cover a wide range of architectures or datasets, raising questions about the generalizability of the results.', 'While the results show improvements, they do not convincingly demonstrate that the proposed method significantly outperforms the best existing methods under a variety of conditions.']",3,2,2,3,Reject
Ve0Wth3ptT_,"The paper proposes DEGREE, a decomposition-based explanation method for Graph Neural Networks (GNNs) that aims to provide faithful explanations by decomposing the information flow within GNNs. It addresses limitations of existing approximation and perturbation techniques by tracking the contributions of graph components more accurately. Experimental results demonstrate the effectiveness of DEGREE compared to baseline methods.","['Can the authors clarify the rationale behind the specific decomposition strategies chosen for GNN layers?', 'Could additional ablation studies be conducted to evaluate the impact of different components in the proposed method?', 'Can the authors provide more detailed examples or visualizations to clarify the decomposition methodology?']","['The lack of clarity in the decomposition methods and the limited experimental validation are major concerns that need to be addressed.', 'The paper could benefit from more extensive discussion on the implications of the findings and how they compare to existing techniques.']",False,2,2,3,4,4,"['The proposed approach addresses a significant issue in GNN interpretability, contributing to the growing field of explainable AI.', 'The decomposition method allows for tracking contributions of specific graph components, enhancing understanding of model behavior.', ""The experimental validation includes both synthetic and real-world datasets, providing a comprehensive assessment of the method's effectiveness."", ""The method's ability to capture complex interactions between graph nodes is a notable advancement over existing techniques.""]","['The paper lacks clarity in its explanations, particularly in the technical details of the decomposition process; specific sections could benefit from more intuitive explanations.', 'The novelty of the approach may be limited, as it builds on existing techniques from other domains without sufficiently differentiating itself; a clearer articulation of its unique contributions would strengthen the paper.', 'The structure and organization of the paper could be improved for better readability; some important concepts are buried in technical jargon, making it challenging for readers to follow.', 'The experimental validation is somewhat narrow, focusing on a limited number of datasets and comparisons against a few baseline methods; broader validation could enhance the robustness of the findings.']",3,2,3,4,Reject
aYSlxlHKEA,"The paper presents Decentralized Model-based Policy Optimization (DMPO), a decentralized reinforcement learning algorithm for multi-agent systems that aims to enhance sample efficiency while achieving performance comparable to model-free methods. The authors provide theoretical analysis and experimental results primarily in traffic control environments.","['Could the authors clarify the novelty of their approach compared to existing decentralized reinforcement learning methods?', 'What other environments or scenarios were considered for validation, and how do they affect the generality of the findings?', ""Can the authors provide more detailed explanations of the algorithm's components and their significance?""]","['The paper does not adequately address the potential limitations of the proposed approach in non-cooperative or partially observable environments.', 'The results might not be generalizable beyond the specific traffic control scenarios tested.']",False,2,2,2,4,4,"['Addresses a significant challenge in multi-agent reinforcement learning with a decentralized approach.', 'Demonstrates promising results in sample efficiency and matches the performance of model-free methods.', 'Includes theoretical analysis that provides insights into the performance guarantees of the proposed method.']","['The clarity of the presentation is insufficient, making it difficult for readers to fully grasp the core contributions, particularly in the theoretical sections.', 'The originality of the approach is questionable, as similar decentralized methods exist, and the paper does not adequately differentiate itself.', ""Experimental validation is limited to traffic control environments, which may not fully showcase the algorithm's capabilities across diverse scenarios."", 'The theoretical contributions lack sufficient clarity and rigorous proof.']",2,2,2,3,Reject
buSCIu6izBY,The paper proposes the Maximal Credit Assignment Occupancy (MaCAO) objective for improving data efficiency in reinforcement learning. It interprets rewards as log-likelihoods on occupancy and aims to optimize the exploration-exploitation trade-off more effectively. The proposed method is implemented in an actor-critic framework and is shown to outperform baseline methods in some classical benchmarks.,"['Can the authors clarify the theoretical aspects of the MaCAO objective and how it relates to existing methods?', 'What specific improvements in data efficiency were observed, and how do these translate to real-world applications?', 'Can the authors provide additional comparisons with more state-of-the-art reinforcement learning methods?', 'Could the authors clarify the key concepts and provide simpler explanations for their mathematical formulations?']","['The clarity of the paper is a significant concern, and additional effort is needed to explain the methodology and results more succinctly.', 'The experimental validation needs to be strengthened with more comprehensive comparisons against state-of-the-art methods.', 'The lack of clarity may hinder the ability of others to replicate the results.', 'The experimental section does not sufficiently substantiate the theoretical claims made in the paper.']",False,2,2,2,4,4,"['The proposed MaCAO objective provides a novel perspective on the exploration-exploitation trade-off in reinforcement learning.', 'The paper attempts to unify various concepts in reinforcement learning under a probabilistic framework, which is an interesting approach.', 'The implementation shows some improvement in sampling efficacy and training efficiency in specific benchmarks.']","['The presentation is convoluted and lacks clarity, making it difficult for readers to grasp the main ideas and contributions.', 'The theoretical underpinnings of the MaCAO objective are not sufficiently detailed, leaving gaps in understanding its practical implications.', 'The experimental setup lacks rigor; the comparisons with baseline methods are not convincing, and the metrics used could be better justified.', 'The paper does not adequately discuss the implications of the proposed method in real-world applications or its limitations.']",3,2,2,3,Reject
CC-BbehJKTe,"The paper investigates program bloat in Genetic Programming (GP) and proposes a combination of deterministic and random simplifications to create winning trees, which can enhance the initialization of GP populations for better convergence and fitness. The study includes experimental validation on synthetic and real-world problems.","['Can the authors clarify the methodology used for simplification and how it compares to previous approaches?', 'Could additional context be provided on the significance of the experimental results, particularly regarding their implications for GP?', 'What specific insights can be drawn from the experimental results regarding the effectiveness of winning trees across various problem domains?']","['The clarity of the paper is a major concern; improvements are necessary to ensure that the methodologies and results are accessible to readers.', 'The potential redundancy in known concepts could affect the perceived impact of the contributions.', ""The lack of depth in the exploration of winning trees may hinder the reader's understanding.""]",False,2,2,2,4,4,"['Addresses the relevant issue of program bloat in Genetic Programming, which is a significant challenge in the field.', 'Introduces a novel concept of winning trees that could contribute to the understanding of GP solutions and their evolution.', 'Provides a comprehensive experimental analysis, including synthetic benchmarks and real-world regression problems.']","['The paper lacks clarity in many sections, with complex methodologies presented in a confusing manner, making it hard to follow.', 'The originality of contributions is limited, as simplification and building blocks in GP have been discussed in previous works.', 'The experimental results could be enhanced with more context and clearer explanations of their significance.', 'The theoretical foundations of winning trees are not well elaborated, and the empirical validation is insufficient.']",2,2,2,3,Reject
AUszBTiYBB6,"This paper introduces Tmean, a novel aggregation method for federated learning aimed at improving resilience against Byzantine attacks. By trimming certain values before averaging, the authors claim to enhance robustness compared to traditional methods like Krum and Mean. The paper includes theoretical analysis and experimental validation of the proposed approach.","['How does Tmean ensure robustness in more complex attack scenarios?', 'What metrics were used to evaluate the robustness of Tmean compared to Krum and Mean?', 'Can the experimental section be expanded to include more diverse attack strategies?']","['Clarity issues hinder understanding and reproducibility.', ""Theoretical analysis needs to be more robust to support claims about Tmean's effectiveness."", 'Experiments should cover a wider range of scenarios to demonstrate robustness.']",False,2,2,2,3,4,"['Addresses a significant issue of robustness in federated learning against Byzantine attacks.', 'Presents a novel approach with trimmed mean aggregation rules that could enhance resilience.', 'Includes theoretical analysis and experimental results that indicate the effectiveness of the proposed method.']","['The presentation lacks clarity and organization, making it challenging to follow key arguments.', 'The theoretical analysis does not sufficiently compare with existing methods or explore implications.', 'Experimental results are limited, lacking comprehensive evaluation against diverse attack scenarios.', 'Some claims are inadequately supported by empirical evidence, and potential limitations are not thoroughly discussed.']",2,2,2,3,Reject
7gWSJrP3opB,"The paper presents a comprehensive analysis of example-selection methods for Stochastic Gradient Descent (SGD), proposing a broad condition that ensures tight convergence rates in both strongly convex and non-convex settings. It introduces two new example-selection approaches and empirically validates their effectiveness across various benchmarks.","['Could the authors clarify the main theoretical contributions and the assumptions made?', 'Are there plans to conduct additional experiments to further validate the proposed methods?']","[""The clarity issues may hinder the understanding of the paper's contributions, particularly for readers unfamiliar with the topic."", 'The reliance on specific assumptions may limit the generalizability of the theoretical results, which should be addressed.']",False,3,2,3,6,4,"['The theoretical framework developed provides a significant contribution to understanding the impact of example order on SGD convergence, particularly through the introduction of average gradient error, which offers a novel perspective on convergence analysis.', 'The proposed QMC-based example-selection method demonstrates accelerated convergence rates, showing practical benefits for deep learning applications, especially in scenarios with limited data.', 'Empirical results on standard datasets, including MNIST and CIFAR, effectively showcase the practical utility and effectiveness of the proposed methods, with clear improvements in validation accuracy compared to traditional methods.']","[""The paper lacks clarity in some sections, particularly in explaining the theoretical arguments and their implications for the proposed methods, which may challenge readers' understanding."", 'While the proposed methods extend existing techniques, the originality of the contributions could be further emphasized to highlight their significance in advancing the field.', 'The experimental validation could be expanded to include a wider variety of datasets and comparisons with additional baseline methods to strengthen the findings and demonstrate robustness.']",3,3,2,4,Reject
04pGUg0-pdZ,"The paper proposes a decentralized actor-critic algorithm for multi-agent reinforcement learning (MARL) aimed at maximizing average reward without joint action knowledge. It claims to achieve finite-time convergence and competitive sample complexity. However, the contributions are not sufficiently validated through a clear and comprehensive experimental framework.","['Can the authors clarify how the proposed algorithm significantly improves upon existing methods in terms of practical applicability?', 'What specific experimental setups were used to validate the claims, and how do they compare with standard benchmarks in MARL?']","['The paper does not adequately discuss the limitations of the proposed approach and its assumptions, particularly in practical scenarios.']",False,3,2,3,5,4,"['Addresses a significant gap in the MARL literature by focusing on average reward settings without joint action knowledge.', 'Introduces a novel decentralized actor-critic algorithm that claims to have finite-time convergence.', 'The proposed sample complexity appears to match state-of-the-art results in single-agent reinforcement learning.']","['The presentation lacks clarity; the structure of the paper is convoluted, making it difficult to follow the main contributions.', ""Empirical results are limited and do not convincingly demonstrate the algorithm's advantages over existing methods."", 'Key concepts and results are not sufficiently contextualized within the broader MARL literature, which may mislead readers.', 'The assumptions and limitations of the proposed method are not clearly articulated, raising concerns about its practicality and applicability.']",3,2,2,3,Reject
B2pZkS2urk_,"The paper presents Evolutionary Plastic Recurrent Neural Networks (EPRNN), a framework that integrates evolutionary strategies, plasticity rules, and recursion-based learning to enhance task generalization, inspired by biological neural networks. However, it suffers from clarity issues and lacks compelling experimental results.","['Can the authors clarify how EPRNN improves upon traditional RNNs in more detail?', 'What specific advantages does EPRNN offer over existing gradient-based methods in practical applications?', 'Can the authors provide more details on the experimental setup and clarify the performance metrics used in the evaluation?']","['The paper does not adequately address the limitations of the proposed framework or the potential challenges in its implementation.', ""The clarity of the paper is a major concern along with the limited experimental results. These issues need to be addressed to enhance the paper's quality.""]",False,2,2,2,4,3,"['The integration of evolutionary strategies with plasticity and recursion offers an original approach to meta-learning.', 'The paper addresses a significant gap between artificial neural networks and biological neural networks, which is an important area of research.', 'The concept of evolving learning rules through natural evolution is intriguing and could lead to new research directions.']","['The paper lacks clarity in explaining the mechanics of EPRNN and how it differs from existing methods.', 'The experimental results do not convincingly demonstrate the advantages of EPRNN over established gradient-based approaches.', 'There is insufficient discussion of limitations and potential biases in the experimental setup, undermining the robustness of the claims.', 'The organization of the paper could be improved for better readability and understanding of the proposed methodology.']",3,2,2,3,Reject
iMqTLyfwnOO,"The paper introduces the Augmented Sliced Wasserstein Distance (ASWD), a novel metric designed to enhance the computational efficiency and accuracy of comparing probability distributions. By utilizing neural networks for nonlinear projections, the ASWD aims to capture complex data structures more effectively than traditional approaches. The authors provide theoretical guarantees for the validity of the ASWD and demonstrate its superior performance in various numerical experiments.","['Can the authors provide more details on the neural network architecture used for the injective mapping?', 'Could additional ablation studies be included to explore the impact of varying the regularization coefficient more thoroughly?', 'Can the authors clarify the practical implications of the ASWD in real-world applications?']","['The clarity of the methodology, especially concerning the injective neural networks, needs improvement.', 'Although the experimental results are promising, further investigations into the regularization impact are warranted.']",False,3,3,3,6,4,"['The ASWD offers a significant advancement in the computation of Wasserstein distances, leveraging neural networks for nonlinear projections.', 'The theoretical framework supporting the ASWD is robust, providing conditions for it to be a valid metric.', 'Extensive experimental results demonstrate the efficacy of the ASWD in comparison to existing metrics across multiple tasks.']","['The paper lacks clarity in certain sections, particularly regarding the details of the neural network architecture used for injective mapping, which could hinder reproducibility.', 'Some methodology details are insufficiently explained, making it difficult to assess the practicality of the ASWD.', 'The experimental results, while promising, do not consistently demonstrate that the ASWD outperforms existing methods across all datasets.']",4,3,3,4,Accept
yx_uIzoHJv,The paper presents a method to induce compositionality in emergent language systems by integrating a topological similarity metric into the loss function. This approach aims to improve generalization and convergence speed without requiring additional training phases. The experiments indicate that the effectiveness of this method varies with the adjustment of compositional pressure and environmental parameters.,"['Can the authors clarify how the topological similarity metric is calculated?', 'What implications arise from the varied results under different pressure conditions?', 'Could the authors elaborate on the architectural choices for the agents and their impact on the results?']","['The paper does not sufficiently address the limitations of the methodology and the implications of mixed results.', 'Clarity in the experimental setup and results could hinder reproducibility.']",False,2,2,3,4,4,"['The idea of using external pressure to promote compositionality is innovative.', 'The method is easy to implement in existing frameworks, avoiding the complexity of additional training phases.', 'The paper establishes a connection between compositionality and generalization through various experiments.']","['The experimental design lacks clarity, leading to potentially contradictory results that complicate definitive conclusions.', 'Key methodological details, particularly regarding the topological similarity metric, are not sufficiently explained.', 'A more thorough discussion of the limitations and potential pitfalls of the proposed approach is needed.']",3,2,2,3,Reject
4pijrj4H_B,"The paper investigates fairness in node representation learning through Graph Neural Networks (GNNs), identifying biases from nodal features and graph structure. It proposes adaptive data augmentation techniques to mitigate these biases and demonstrates their effectiveness through experiments on real networks.","['Could the authors provide more detailed explanations for their experimental setups and results?', 'How do the authors ensure that their methods do not inadvertently introduce new biases?', 'Can the authors clarify the limitations of their approach and how it might be generalized to other types of graphs?']","['Needs to clarify the potential for overfitting in the proposed methods.', 'Should address the limitations of the experiments conducted, particularly in terms of dataset diversity and size.']",False,3,2,3,5,4,"['Addresses an important and underexplored issue in machine learning: fairness in graph representation learning.', 'Presents a theoretical analysis of bias in GNNs, providing a solid foundation for the proposed methods.', 'Introduces novel adaptive data augmentation strategies that enhance fairness in node representations.', 'Demonstrates empirical results showing improvements in fairness metrics while maintaining competitive utility performance.']","['The paper lacks clarity in certain sections, particularly in the theoretical analysis and descriptions of experimental setups, which may hinder understanding.', 'The experimental evaluation could benefit from a more comprehensive set of baseline comparisons and ablation studies to isolate the effects of each proposed augmentation method.', 'Some claims regarding the effectiveness of the proposed methods could be seen as overstated without sufficient empirical evidence.', 'There is a potential for overfitting in the proposed methods which should be addressed.']",3,2,2,4,Reject
vh-0sUt8HlG,"The paper introduces MobileViT, a lightweight vision transformer that combines the strengths of convolutional neural networks (CNNs) and vision transformers (ViTs) for mobile vision tasks. It demonstrates that MobileViT outperforms both CNN and ViT-based networks on various benchmarks while being efficient in terms of parameters and latency, achieving top-1 accuracy of 78.4% on ImageNet with 5.6 million parameters.","['Could the authors provide more details on the MobileViT architecture and how it differs from previous hybrid models?', 'Can the authors clarify the efficiency metrics discussed in the paper, particularly in relation to real-world mobile applications?', 'What specific hyperparameters were critical in your training process, and how did you determine their values?', 'Can the authors clarify how MobileViT significantly improves on existing architectures beyond just parameter count and performance metrics?']","['The paper needs to improve clarity regarding the architecture and innovations of MobileViT.', ""More explicit details on efficiency metrics and comparisons to other models would enhance the paper's credibility."", ""The clarity of the paper could be improved, especially in explaining the architecture's components and their interactions."", 'The paper may benefit from clearer explanations of how the proposed architecture differs from existing models and a more rigorous experimental design.']",False,3,2,3,6,4,"['MobileViT effectively combines the strengths of CNNs and ViTs, addressing a significant gap in mobile vision applications.', 'The paper provides thorough experimental results demonstrating how MobileViT outperforms existing models while maintaining lower latency and fewer parameters.', 'The architecture is designed specifically for mobile applications, which is crucial for practical deployment.', 'The open-source release of the code enhances reproducibility and accessibility for further research.']","['The paper lacks clarity in the description of the MobileViT architecture, making it difficult to understand the innovations introduced.', 'While performance metrics are provided, comparisons to other architectures could be clearer, particularly in the context of real-world application constraints.', 'The discussion around the training efficiency and inference time could benefit from more explicit detail on the methods used.', 'The novelty of the model architecture is questionable as it heavily relies on existing CNN and transformer principles.', 'The experimental comparisons with existing models lack depth and could be more comprehensive.']",4,3,2,4,Reject
0rjx6jy25R4,The paper proposes a Classifier-Noise-Invariant Conditional GAN (CNI-CGAN) framework that combines Positive-Unlabeled (PU) learning with conditional generation to improve performance in scenarios with limited labeled data and abundant unlabeled data. It aims to leverage out-of-distribution data for better classification and generation outcomes.,"['What specific contributions does the CNI-CGAN make over existing GANs trained with noisy labels?', 'Can the authors provide more clarity around the training process and architecture of the CNI-CGAN?', 'How does this work compare quantitatively with other recent methods in PU learning and generation?']","['The paper does not adequately address the limitations of relying on noisy labels from the PU classifier.', 'The potential societal impacts of using generative models in sensitive applications are not discussed.']",False,2,2,3,4,4,"['Addresses a significant challenge in machine learning related to the scarcity of labeled data.', 'Introduces an innovative framework that combines PU learning with conditional GANs.', 'The concept of exploiting out-of-distribution data is novel and relevant to many real-world applications.']","['The originality of the approach is somewhat limited as it builds on existing techniques without introducing sufficiently novel concepts.', 'The theoretical analysis lacks depth and clarity, making it difficult to assess the validity of the claims.', ""Experimental results appear insufficient to convincingly demonstrate the proposed method's superiority over existing approaches."", ""The writing lacks clarity and coherence in several sections, making it challenging to follow the authors' arguments.""]",3,2,2,4,Reject
7B3IJMM1k_M,"The paper proposes a novel quantization clip-floor-shift activation function aimed at improving the conversion from artificial neural networks (ANNs) to spiking neural networks (SNNs). It addresses performance degradation issues associated with short time-steps and claims to achieve high accuracy and ultra-low latency. The authors provide a theoretical analysis of conversion errors and validate their approach on CIFAR-10, CIFAR-100, and ImageNet datasets, demonstrating improvements over existing methods.","['Can the authors provide more detailed explanations or visualizations for the conversion error analysis?', 'What are the specific performance impacts of the proposed activation function compared to using ReLU in detail?', 'Could the authors discuss potential limitations or scenarios where their approach might fail to outperform existing methods?']","['The clarity of the theoretical sections could be improved to enhance understanding.', 'More extensive ablation studies are needed to validate the claims regarding the proposed activation function.', 'The paper does not sufficiently address potential limitations or scenarios where the proposed approach may fail.']",False,3,3,3,7,4,"['The proposed quantization clip-floor-shift activation function is innovative and addresses a significant issue in SNN performance.', 'The theoretical analysis of conversion errors is well-founded and provides a solid foundation for the proposed method.', 'Experimental results indicate that the proposed method outperforms existing state-of-the-art techniques in terms of accuracy and latency across multiple datasets.']","['The paper lacks clarity in several sections, particularly in the theoretical justifications and empirical results, making it difficult to follow the arguments presented.', 'There is a need for more extensive empirical validation, including comparisons with a broader range of existing methods and additional ablation studies.', 'The strong claims regarding zero expected conversion error require more robust experimental validation.']",3,3,3,4,Reject
k7efTb0un9z,"The paper proposes a Graph Network-based Scheduler (GNS) for learning rate scheduling in deep neural networks, utilizing graph neural networks and reinforcement learning to dynamically adjust learning rates based on intermediate layer information. The authors claim improved performance across various datasets and architectures compared to traditional methods.","['Can the authors clarify how the graph representation directly improves performance over existing heuristic methods?', 'What specific metrics were used to evaluate the performance of GNS, and how do they compare to those used in previous work?', 'Could the authors provide more detailed comparisons with existing state-of-the-art schedulers?']","['The paper lacks thorough evaluation against established benchmarks, which raises concerns about its claims.', 'Potential scalability issues for larger models are not addressed.']",False,2,2,3,5,4,"['Addresses an important aspect of neural network training – learning rate scheduling.', 'Proposes a novel approach leveraging graph neural networks and reinforcement learning.', 'Demonstrates improvements over baseline methods in experiments.']","['The clarity of the methodology is lacking, making it difficult to fully grasp how GNS functions and the specific advantages it offers over other methods.', 'The experimental validation is insufficient; lacks thorough comparisons with state-of-the-art methods.', 'Insufficient detail regarding the experimental setups and hyperparameter tuning, which may hinder reproducibility.', 'The originality of the approach is limited, primarily building on existing techniques without introducing fundamentally new concepts.']",2,2,2,3,Reject
hcoswsDHNAW,"The paper introduces Fast AdvProp, a method aimed at enhancing the efficiency of adversarial training by reducing computational costs while maintaining or improving model performance. It proposes modifications to the existing AdvProp framework, focusing on decoupling clean and adversarial training samples and implementing gradient recycling techniques.","['Can the authors provide additional experimental results to confirm the scalability and effectiveness of Fast AdvProp across various models?', 'What specific theoretical insights guided the design changes in Fast AdvProp?', 'Could the authors provide more detailed experimental results to strengthen their claims?']","['The paper lacks sufficient clarity in its methodology, which may hinder reproducibility.', 'The empirical results are not contextualized well against a broad range of baselines, which weakens the evidence for its claims.']",False,2,2,3,4,4,"['Addresses a significant issue in adversarial training: the high computational cost.', 'Empirical results demonstrate improvements in model performance across various datasets, indicating practical applicability.', 'The approach may stimulate further exploration of adversarial training techniques in the deep learning community.']","['The clarity of the methodology is lacking, making it difficult for readers to fully grasp the innovations.', 'Experimental validation is insufficient; comparisons to other methods are superficial and lack depth.', 'Claims about performance improvements are made without adequate statistical significance or robustness checks.', 'The paper does not sufficiently address potential limitations or scenarios where Fast AdvProp may underperform.']",3,2,2,3,Reject
QKEkEFpKBBv,"The paper presents Differentiable Nonparametric Belief Propagation (DNBP), a method that integrates neural networks with nonparametric belief propagation to learn probabilistic factors for inference in articulated pose tracking tasks. The approach aims to reduce reliance on hand-crafted functions while maintaining uncertainty estimation capabilities. The effectiveness of DNBP is evaluated through experiments on simulated and real-world datasets.","['Could the authors clarify the differentiability of the message passing algorithm and how the non-differentiable resampling impacts the overall performance?', 'What specific advantages does DNBP demonstrate over traditional NBP methods in terms of practical applications?']","['The paper does not sufficiently address the potential limitations of the proposed method, including scenarios where the learned factors may not generalize well.', 'The ethical implications of using neural networks for probabilistic inference in real-world applications are not discussed.']",True,3,3,3,5,4,"['The proposed DNBP framework is innovative, combining neural networks with nonparametric belief propagation to learn probabilistic factors end-to-end.', 'The experiments demonstrate the effectiveness of DNBP on challenging articulated tracking tasks, including both simulated and real-world scenarios.', 'The ability to maintain uncertainty estimates in predictions is a significant advantage for applications in robotic perception.']","['The paper lacks clarity in explaining the methodology, particularly in sections detailing the differentiable message passing and the role of neural networks in learning.', 'While the experiments are comprehensive, the comparison with existing state-of-the-art methods is limited. More baselines should be included for a clearer evaluation of performance.', 'The limitations of the proposed method, particularly regarding the non-differentiable resampling step, are inadequately addressed.']",3,3,3,4,Reject
AsyICRrQ7Lp,"The paper presents Bootstrapped Hindsight Experience Replay (BHER), which combines Hindsight Experience Replay (HER) with a bootstrapping technique using multiple Q-value heads to improve data efficiency in sparse reward environments. It introduces a counterintuitive prioritization method that favors lower uncertainty data samples over higher uncertainty ones in the context of hindsight experiences, claiming this improves performance. The authors support their claims with a series of experiments demonstrating state-of-the-art results in multiple goal-conditioned tasks.","['Can the authors elaborate on how BHER significantly differs from existing HER approaches beyond incorporating bootstrapping?', 'What is the theoretical justification for counterintuitive prioritization, and how does it relate to existing exploration strategies?', 'How do the results hold up in more varied environments than those tested?', 'What specific experimental conditions were used to affirm the effectiveness of the prioritization technique?']","['The paper does not sufficiently address the limitations of the method and its applicability to different types of environments.', 'The clarity of key concepts, particularly around the counterintuitive aspects of the prioritization method, needs to be improved.']",False,3,3,3,5,4,"['The approach addresses a significant problem in reinforcement learning regarding sparse rewards, making it relevant and practical.', 'The experimental results show that the proposed method achieves state-of-the-art performance across various tasks, indicating its potential effectiveness.', 'The paper provides a detailed methodology and comprehensive analysis of results, including ablation studies.']","['The novelty of the contributions is unclear; the paper could benefit from a more detailed differentiation of BHER from existing methods.', 'Clarity of presentation is lacking in some sections, which may hinder understanding for readers not deeply familiar with the context.', 'The counterintuitive prioritization claim may require more empirical support and clearer explanation of its theoretical underpinnings.', 'The experimental validation does not convincingly address the robustness of the proposed method across different tasks and scenarios.']",3,3,3,4,Reject
lQI_mZjvBxj,"The paper proposes a theoretical framework for model-agnostic federated learning using knowledge distillation, addressing the challenges of heterogeneous models and datasets. It introduces several algorithms, including alternating knowledge distillation and averaged knowledge distillation, while analyzing their performance in federated learning settings. However, the empirical results do not convincingly demonstrate significant advancements over existing methods.","['Can the authors provide additional experiments to validate the proposed methods against standard federated learning approaches?', 'Could the authors clarify the relationship between the theoretical insights and the empirical results presented?']","['The paper does not adequately address the gap between theoretical predictions and empirical results.', 'There is a need for more extensive evaluations to support the claims made regarding the performance of the proposed methods.']",False,2,2,2,4,4,"['Addresses a significant challenge in federated learning regarding model and data heterogeneity.', 'Introduces a theoretical framework that enhances understanding of knowledge distillation in federated settings.', 'Explores multiple algorithms and their comparative performance, providing a foundation for future work.']","['Empirical results are not compelling enough to demonstrate the practical effectiveness of the proposed methods.', 'Theoretical contributions lack clarity and rigor, making it difficult for readers to grasp their implications.', 'The writing is convoluted, leading to confusion about key points and limiting accessibility.']",3,2,2,3,Reject
OWZVD-l-ZrC,"The paper proposes RUNE, an exploration method for preference-based reinforcement learning that utilizes uncertainty in learned reward functions to improve sample and feedback efficiency. The method is evaluated through experiments on robotic manipulation tasks, demonstrating improvements over existing exploration techniques.","['Can the authors clarify how RUNE significantly differs from existing exploration methods in its approach?', 'Could the authors provide additional experimental results with a broader range of comparison methods to better support their claims?', 'What are the limitations of using uncertainty in reward models when applied to various environments?']","['The exploration method may be vulnerable to the quality of human feedback, which can vary significantly.', 'The impact of ensemble size on performance and computational efficiency needs to be addressed more thoroughly.']",False,3,3,3,6,4,"['Addresses a significant problem in preference-based RL concerning feedback efficiency.', 'Proposes a novel exploration method that incorporates uncertainty from learned reward functions.', 'Includes comprehensive experimental results on complex robotic manipulation tasks, showing improved efficiency.']","['The novelty of the method could be better articulated, as it builds upon existing ideas without a strong theoretical foundation.', 'Some sections of the paper are dense and could benefit from clearer explanations.', 'The experimental evaluation could include a broader range of comparison methods to better support claims.', 'The paper does not adequately address potential limitations or the scalability of the proposed method in real-world scenarios.']",3,3,3,4,Reject
ghTlLwlBS-,"The paper proposes a Feudal Reinforcement Learning (FRL) framework that consists of a manager agent and a worker agent to address the semantic mismatch between high-level language instructions and low-level actions in RL tasks. The manager generates sub-goals from textual information, while the worker agent performs actions in the environment. The authors claim competitive performance on RTFM and Messenger tasks without human-designed curriculum learning.","['How does the proposed approach specifically differentiate from previous work on feudal reinforcement learning?', 'What are the contributions of the multi-hop plan generator, and how does it outperform simpler models?', 'Can the authors provide more details on the interaction between the manager and worker agents?', 'What are the limitations of the benchmarks used for evaluation?', 'What measures have the authors taken to address potential ethical concerns related to deploying RL agents in real-world contexts?']","['The lack of novel contributions limits the impact of the work.', 'The methodology and results need clearer presentation to enhance understanding and reproducibility.', 'The paper does not sufficiently address the limitations or potential ethical considerations of deploying such an RL framework in real-world applications.']",True,2,2,2,4,4,"['The paper tackles a relevant problem of semantic mismatch in reinforcement learning with language instructions.', 'The proposed FRL framework introduces a hierarchical approach, which may effectively address some challenges in reading to act tasks.', 'The experiments show some promising results on challenging benchmarks.']","['The originality of the approach is questionable as it heavily relies on existing methods without clear differentiation or novelty.', 'The clarity of the methodology is lacking, making it difficult to follow the proposed framework and its components.', 'The explanation of how the manager and worker agents interact and learn could be elaborated further.', 'Limited ablation studies are provided to back up claims, particularly regarding the impact of the multi-hop plan generator.', 'The results, while competitive, are not sufficiently contrasted with well-established baselines beyond a few comparisons.']",3,2,2,3,Reject
aq6mqSkwApo,"The paper introduces Meta-OLE, a geometry-regularized method for few-shot image classification that learns to adapt feature spaces with inter-class orthogonality and intra-class low-rankness. The proposed method aims to enhance classification performance through meta-learned transformations and is validated through experiments showing superior performance over state-of-the-art methods.","['Can the authors clarify how their method is fundamentally different from existing methods?', 'Can more details be provided regarding the integration of the components within the framework?', 'What specific experiments were conducted to ensure the robustness of the method under varying conditions?']","['The paper does not adequately explore potential shortcomings of the proposed method or the implications of its use in practical scenarios.', 'There is a lack of robustness checks or ablation studies to validate the contributions of various components of the proposed model.']",False,2,2,3,5,4,"['The method addresses the important issue of few-shot learning with a focus on geometric properties, which can lead to improved generalization.', 'The incorporation of orthogonal low-rank structures is an innovative approach that adds theoretical depth to the methodology.', ""Extensive experiments on multiple benchmarks provide strong evidence of the method's effectiveness compared to existing state-of-the-art techniques.""]","['The clarity of the presentation is lacking, making it difficult to understand the advantages of the proposed method over existing techniques.', 'The novelty of the proposed method is questioned, as the idea of low-rank embeddings and orthogonality has been explored previously in other contexts.', 'The experimental setup does not sufficiently address the limitations of the method or provide a comprehensive comparison with the latest methods in the field.']",3,2,2,3,Reject
eMudnJsb1T5,"The paper introduces a new family of particle evolution samplers based on mirrored Stein operators, aimed at constrained domains and non-Euclidean geometries. It presents methods like Mirrored SVGD and Stein Variational Mirror Descent, demonstrating their effectiveness through experiments on benchmark problems, including confidence intervals in post-selection inference. The paper also establishes convergence properties for these methods under specific conditions.","['Can the authors clarify the theoretical derivations presented?', 'Will additional experiments be included to validate the performance of the methods across various datasets?', 'How do the proposed methods compare to existing state-of-the-art methods in terms of computational efficiency?']","['The clarity of presentation is a concern, with complex derivations that may not be easily understood.', 'More empirical evidence is needed to assess the robustness and generality of the proposed algorithms.']",False,3,2,3,5,4,"['The proposed methods are innovative and address significant challenges in constrained and non-Euclidean sampling.', 'The theoretical contributions, particularly regarding convergence, are substantial and provide a solid foundation for the proposed algorithms.']","['Certain theoretical concepts and derivations lack clarity, which may confuse readers not well-versed in advanced probability and statistics.', 'The experimental section would benefit from more thorough validation and analysis to support the performance claims of the proposed methods.', 'Key details about the implementation and computational complexity of the algorithms are not adequately discussed.']",3,3,2,4,Reject
VNdFPD5wqjh,"This paper proposes Unit DRO, a method for Generalizable Person Re-Identification (DG ReID) that operates without relying on demographic information. The authors argue that this approach addresses privacy concerns associated with demographic data while still achieving robust performance across various datasets. They leverage distributionally robust optimization techniques to develop a methodology that reweights samples based on their importance in the learning process.","['Could the authors provide more details on the implementation of Unit DRO?', 'How do the authors ensure the robustness of their results across different datasets?', 'What are the inherent limitations of Unit DRO in practical applications?']","['The authors do not discuss the potential biases that might arise from the absence of demographic information.', 'The reliance on hyperparameter tuning without demographic data could lead to models that are overly sensitive to specific training conditions.']",False,2,2,3,4,4,"['The problem of generalizable person re-identification without demographics is timely and relevant given current privacy concerns.', 'The proposed method, Unit DRO, offers a new perspective on distributionally robust optimization in the context of person re-identification.', 'The empirical results suggest that Unit DRO can outperform existing methods that rely on demographic data.']","['The paper lacks clarity in the explanation of the proposed methodology, particularly in terms of the implementation details of Unit DRO.', 'The experimental validation does not provide a comprehensive analysis of results across a variety of tasks and datasets, which may limit the generalizability of the findings.', 'The paper does not adequately address potential limitations or provide a thorough discussion on the implications of the results.']",3,2,2,3,Reject
_j4hwbj6Opj,"The paper proposes a meta-learning approach to 3D point cloud registration, introducing a novel 3D registration meta-learner that aids in quickly adapting to new point clouds with limited training data. The proposed method aims to generalize across different registration tasks, leveraging a variational auto-encoder for task distribution estimation and a region-aware flow regression for point transformations.","['Can the authors provide more details on how the meta-learner improves the adaptability of the registration learner?', 'What specific metrics were used to evaluate the effectiveness of the proposed model, and how do these compare to existing methods?', 'Can the authors offer more insight into the experimental setup to ensure reproducibility?']","['The clarity of the methodology and results could hinder understanding and evaluation of the proposed approach.', 'Limited experimental validation raises questions about the generalization of findings.']",False,2,2,2,4,4,"['Addresses a significant challenge in the field of 3D point cloud registration.', 'Introduces a novel meta-learning framework that enhances adaptability to new tasks.', 'The use of variational auto-encoders for learning priors is an innovative approach that could lead to improved performance.']","['The explanation of the methods lacks sufficient detail, particularly regarding the interaction between the meta-learner and the learner.', 'The experimental setup is not clearly articulated, making it difficult to assess the robustness of the results.', 'Limited ablation studies are presented, which could demonstrate the necessity and effectiveness of different components of the proposed method.']",3,2,2,4,Reject
iEvAf8i6JjO,"The paper presents Trust Region Gradient Projection (TRGP), a method aimed at addressing catastrophic forgetting in continual learning by enabling effective knowledge transfer from strongly correlated old tasks. The method introduces a trust region mechanism for task selection and employs scaled weight projection for knowledge reuse, demonstrating significant improvements over state-of-the-art methods through extensive experimental results.","['Could the authors clarify how the trust region is defined and its implications for knowledge transfer?', 'Can additional comparisons with existing methods be included to better contextualize the results?']","['The clarity in explaining key concepts and the overall methodology needs improvement.', 'More thorough theoretical backing for the proposed approach is necessary.']",False,3,3,4,5,4,"['Addresses a significant issue in continual learning: catastrophic forgetting.', 'Introduces a novel trust region concept for selecting correlated old tasks.', 'Experimental results show substantial performance improvements over existing methods.']","['Lacks clarity in the presentation, making it difficult to follow the methodology and theoretical rationale.', 'Theoretical justification for the trust region concept is insufficiently detailed.', 'Insufficient experimental comparisons with a broader range of existing methods limit the context of the results.']",4,3,3,4,Reject
ptZfV8tJbpe,"This paper proposes a novel approach to multi-label text classification (MLTC) that utilizes latent label encodings to implicitly model label correlations. This method aims to address the limitations of existing approaches that model correlations explicitly, which can introduce inductive biases. The authors claim significant improvements over state-of-the-art methods on benchmark datasets, suggesting the potential of their approach.","['Can the authors clarify how latent label encodings are trained and their specific advantages over actual labels?', 'What plans do the authors have for validating the model across a wider range of datasets?']","[""The paper's clarity issues may hinder understanding and application of the proposed method."", 'Further validation across diverse datasets is necessary to establish the robustness of the approach.']",False,3,2,3,5,4,"['Addresses a critical challenge in MLTC by modeling label correlations implicitly, enhancing flexibility.', 'Introduces a novel method using latent label encodings, which reportedly improves performance on benchmark datasets.', 'Demonstrates substantial improvements over existing state-of-the-art methods.']","['The methodology lacks clarity, making it difficult for readers to fully understand the proposed approach.', 'The rationale for using latent label encodings over actual label encodings is not sufficiently justified.', 'The evaluation is limited to two datasets, raising questions about the generalizability of the results.']",3,3,2,4,Reject
wQStfB93RZZ,The paper presents a novel approach for asynchronous multi-agent decision-making using macro-actions within the framework of decentralized partially observable Markov decision processes (POMDPs). It proposes several actor-critic methods that allow agents to optimize their policies asynchronously. Experimental results demonstrate the effectiveness of these methods across various multi-agent environments.,"['Can the authors clarify the theoretical contributions and provide additional insights into how the methods compare with existing work?', 'What additional baselines could be included to strengthen the evaluation of the proposed methods?', 'Could the authors elaborate on the limitations of their approach in real-world applications?']","['The complexity of the methods and the lack of clear explanations could limit accessibility to readers.', 'Insufficient baseline comparisons raise questions about the robustness of the findings.']",False,3,2,3,6,4,"['Addresses a significant problem in multi-agent reinforcement learning: the need for agents to act asynchronously without waiting for others.', 'Introduces a novel framework for macro-action-based learning that allows agents to operate independently.', 'Empirical results demonstrate the effectiveness of the proposed methods across diverse environments, showing improvements over baseline approaches.']","['The clarity of the paper is lacking; many concepts are not sufficiently explained, making it hard to follow the methodology.', 'The experimental evaluation is somewhat limited. It would benefit from more varied environments and deeper analysis.', 'The comparison with existing methods could be more rigorous; additional ablation studies are needed to justify the performance claims.']",3,3,2,4,Reject
W9G_ImpHlQd,"The paper introduces ZO-AE-DS, a method for enhancing the robustness of black-box machine learning models against adversarial attacks using zeroth-order optimization and denoised smoothing. This approach is significant for scenarios where model details cannot be shared due to privacy concerns.","['Can the authors clarify the rationale behind the choice of denoiser variations and their impact on performance?', 'What limitations were considered in the development of ZO-AE-DS, and how might they affect its applicability in real-world scenarios?']","['The complexity of the methodology could benefit from clearer explanations.', 'The lack of comprehensive comparisons with robust baselines raises questions about the generalizability of the results.']",False,3,2,3,5,4,"['Addresses a critical issue of adversarial robustness in machine learning.', 'Proposes a novel integration of zeroth-order optimization with autoencoders for black-box defenses.', 'Empirical results show improvements in certified robustness and accuracy on benchmark datasets.']","['The methodology lacks clarity, making it challenging to understand the implementation of ZO-AE-DS.', 'Experimental results do not adequately compare against a wide range of existing robustification techniques, limiting the claims of effectiveness.', 'The paper does not sufficiently discuss the limitations or potential drawbacks of the proposed method.']",3,3,2,4,Reject
l431c_2eGO2,"The paper introduces Mix-MaxEnt, a method that regularizes deterministic neural networks by adding an entropy maximization term to enhance accuracy and uncertainty estimates. It aims to create high-entropy regions between class clusters to better manage out-of-distribution samples. The approach is evaluated on CIFAR datasets, demonstrating improved performance over standard models and other baselines.","['Could the authors clarify how Mix-MaxEnt differs from existing methods like mixup?', 'Can the authors provide more details on the entropy maximization process and its theoretical underpinnings?']","['The paper does not fully explore the limitations of the proposed method or potential scenarios where it may underperform.', 'There is limited discussion on the implications of using synthetic samples and their impact on generalization.']",False,3,3,3,5,4,"['The method is straightforward and easy to implement, requiring minimal changes to existing code.', 'Experiments show significant improvements in both classification accuracy and uncertainty estimates compared to baseline methods.', 'The paper addresses a crucial issue in deep learning regarding uncertainty estimation and overconfidence.']","['The novelty of the approach is somewhat limited, as it builds on existing concepts without introducing substantial new ideas.', 'Certain sections, particularly the methodology and experimental setup, could benefit from clearer explanations.', 'The evaluation could be strengthened by including a wider variety of datasets and comparisons with more recent state-of-the-art methods.']",3,3,3,4,Reject
z3Tf4kdOE5D,"The paper presents FEDDISCRETE, a federated learning framework that employs a probabilistic discretization mechanism to enhance robustness against weight poisoning attacks. The authors provide theoretical analyses on utility, robustness, and convergence, and evaluate their approach using several datasets.","['Can the authors clarify the theoretical implications of the discretization mechanism more thoroughly?', 'What specific experiments were conducted to evaluate the effectiveness of FEDDISCRETE against varying attack strengths?', 'How does the discretization mechanism impact model performance in real-world applications with diverse client settings?']","['The method may not be effective in scenarios with a high proportion of adversarial clients, which should be discussed in detail.', 'The connection between theoretical results and empirical performance metrics could be strengthened.']",True,2,2,3,4,4,"['Addresses a critical issue in federated learning concerning vulnerability to weight poisoning attacks.', 'Introduces a novel probabilistic discretization mechanism that appears to enhance robustness against several types of attacks.', ""Includes theoretical analysis of the framework's utility, robustness, and convergence.""]","['The clarity of the presentation is poor; several sections are dense and may be difficult for readers to follow.', 'The theoretical analysis lacks depth and rigor, making it difficult to assess the true robustness of the proposed mechanism.', 'Experimental validation is limited; the paper does not provide comprehensive evaluations across a broader range of attack scenarios or existing defenses.', 'The limitations of the proposed approach are not adequately discussed, particularly in scenarios with a high fraction of adversarial clients.']",3,2,2,3,Reject
a34GrNaYEcS,"The paper proposes RP-DRO, a novel approach to Distributionally Robust Optimization that utilizes parametric likelihood ratios to improve robustness against distribution shifts. The authors claim that their method simplifies the optimization process compared to existing approaches while achieving better performance. They provide experimental results across various datasets, demonstrating that RP-DRO consistently outperforms existing methods.","['Could the authors clarify the theoretical motivations behind the parametric approach and its advantages over existing methods?', 'Can the authors include additional ablation studies to validate the effectiveness of each component of their method?']","['The paper could improve in clarity, especially in complex sections that may hinder understanding.', 'The complexity of the proposed method may limit its accessibility to practitioners, and potential computational overhead should be addressed.']",False,3,2,3,6,4,"['The proposed RP-DRO method effectively addresses the limitations of existing DRO approaches by simplifying the modeling process and improving computational efficiency.', 'Extensive experiments on diverse datasets (text and image) demonstrate the robustness and effectiveness of the proposed method, consistently showing superior performance compared to other DRO techniques.', 'The paper introduces practical solutions for normalization and optimization that could be beneficial for real-world applications.']","['The clarity of the paper is lacking; certain sections, particularly those involving mathematical formulations (e.g., the min-max problem in Eq. 2) and the normalization strategy, are dense and may confuse readers unfamiliar with the topic.', 'Key concepts related to the optimization strategies, such as the rationale behind the KL penalty, are not adequately explained, which may hinder understanding.', 'The paper lacks depth in its experimental validation, particularly in terms of ablation studies and detailed comparisons with existing methods.']",3,3,2,4,Reject
izvwgBic9q,"The paper proposes an unsupervised learning framework for Full-Waveform Inversion (FWI) that integrates convolutional neural networks (CNNs) and partial differential equations (PDEs). It introduces a new dataset (OpenFWI) and demonstrates that the proposed UPFWI method can achieve performance comparable to supervised methods, relying solely on seismic data. The approach circumvents the high costs of obtaining velocity maps, making it a significant contribution to the field.","['Can the authors provide more detailed explanations on how the perceptual loss contributes to the overall performance?', 'What specific challenges were encountered when applying UPFWI to more complex geological structures, and how were they addressed?']","['The paper does not address potential limitations of the unsupervised learning approach in real-world applications, such as noise in seismic data.', 'There is a need for more comprehensive ablation studies to understand the contributions of each component in the proposed method.']",False,3,3,4,8,4,"['The integration of CNNs and PDEs in an unsupervised learning framework is innovative and addresses a significant gap in the FWI methodology.', 'The introduction of the OpenFWI dataset provides a valuable benchmark for future research in the area.', 'Experimental results show that UPFWI can achieve comparable performance to supervised methods with only unlabeled seismic data, highlighting the potential of unsupervised learning in complex geophysical problems.']","['The clarity of the paper could be improved, particularly in explaining the methodology and the implications of the results.', 'Some experimental results may be overstated, especially when comparing to established supervised baselines without detailed justification.', 'The paper lacks a thorough discussion on the limitations and potential challenges of the proposed approach, particularly regarding the generalization to various geological structures.']",4,4,3,4,Reject
7pZiaojaVGU,"The paper investigates the equivalence between gradient attacks and data poisoning in personalized federated learning, establishing theoretical foundations and introducing a practical attack method. It provides both theoretical and empirical evidence of the effectiveness of the proposed counter-gradient attack.","['Could the authors elaborate on the experimental setup used to validate the counter-gradient attack, including more details on the datasets and evaluation metrics?', 'What specific measures can be taken to mitigate the vulnerabilities identified in this paper?']","['The paper could improve its accessibility to a wider audience by simplifying complex concepts.', 'A more detailed discussion on the potential limitations of the counter-gradient attack would be beneficial.']",False,3,3,4,7,4,"['The theoretical contribution of demonstrating the equivalence between gradient attacks and data poisoning is significant.', 'The introduction of the counter-gradient attack as a practical method adds value to the theoretical results.', 'Empirical validation strengthens the claims regarding the effectiveness of the proposed attack.']","['The clarity of the paper could be improved; some sections are densely packed and difficult to follow.', 'Experimental details are insufficient, hindering reproducibility; specific hyperparameters and configurations need clearer documentation.', 'The theoretical proofs could benefit from additional intuition or explanatory context.']",3,3,3,4,Accept
30SXt3-vvnM,"The paper introduces a kernelized classification layer for deep learning networks, enabling nonlinear classifications on embeddings produced by lightweight networks. It presents theoretical foundations and empirical evaluations across various tasks, claiming significant improvements over traditional softmax classifiers.","['Can the authors clarify the kernel selection process?', 'How do the authors prevent overfitting in the kernelized layer, especially with higher-dimensional embeddings?', 'Could the authors include additional datasets in their experiments to strengthen their claims?', 'Can the authors provide more empirical comparisons against a wider range of baseline classifiers?', 'Could the theoretical discussions be simplified for better accessibility?']","['The paper lacks sufficient details on the practical implications of implementing kernelized classifiers in real-world scenarios.', 'Ambiguities in theoretical derivations and potential issues with overfitting diminish the overall clarity and impact of the paper.', 'The lack of comprehensive evaluation across diverse datasets raises questions about the generalizability of the proposed method.']",False,2,2,3,5,4,"['The kernelized classification layer effectively addresses the limitations of linear classifiers on embeddings.', 'The theoretical framework provided supports the proposed method and connects classic kernel methods with modern deep learning.', ""Empirical results indicate improvements in several benchmarks, suggesting the method's potential applicability.""]","['The theoretical sections could benefit from clearer explanations; the derivations and implications of kernel choices are not fully articulated.', 'Empirical evaluations, while promising, lack comprehensive analysis across diverse datasets to validate robustness.', 'Concerns regarding potential overfitting with the increased number of parameters in kernelized models are not adequately addressed.', 'The writing quality needs improvement; instances of unclear phrasing and complex sentences detract from overall readability.']",3,3,2,3,Reject
WxuE_JWxjkW,"The paper investigates the expressivity of emergent languages in deep learning models through language games, positing that expressivity is a trade-off between contextual complexity and unpredictability. It introduces a novel measure of expressivity based on generalization performance and identifies the phenomenon of message type collapse, suggesting the use of contrastive loss to mitigate this issue.","['Can the authors clarify how they define and measure complexity and unpredictability in the context of their experiments?', 'What specific parameters influenced the emergence of languages during the experiments, and how were they determined?', 'Could the authors provide more intuitive explanations for their experimental findings?']","['The paper could benefit from a more rigorous discussion of the implications of its findings for future research in emergent communication.', ""Insufficient detail in explanations and definitions may hinder the reader's understanding.""]",False,3,3,3,5,4,"['The topic is timely and relevant, addressing the interplay between emergent language and deep learning.', 'The introduction of message type collapse is interesting and adds depth to the discussion on emergent communication.', 'The experimental design is comprehensive, utilizing multiple games to validate the hypothesis, which strengthens the findings.']","[""The definitions of key concepts such as expressivity, complexity, and unpredictability need clearer exposition, as they are crucial for understanding the paper's contributions."", 'The writing lacks clarity in several sections, particularly in the explanation of the experimental setup and results, making it difficult to follow the logical progression of ideas.', 'The results, while showing trends, need to be presented more rigorously, especially in terms of statistical significance and robustness across different settings.']",3,3,3,4,Reject
MvO2t0vbs4-,"The paper analyzes the efficiency of committee-based models (ensembles and cascades) in deep learning, demonstrating that even simple committee methods can match or exceed the accuracy of state-of-the-art models while being more efficient. The findings suggest that these methods outperform sophisticated neural architecture search methods and provide significant speedups across various tasks including image classification, video classification, and semantic segmentation.","['Could the authors clarify how the proposed committee-based models compare with newer architectures beyond the ones mentioned?', 'What are the specific limitations of cascades in certain scenarios, and how might they be addressed in future work?']","[""The lack of a novel contribution may limit the paper's long-term impact on the field."", 'Some methodologies may not generalize well across all tasks or architectures.']",False,3,3,2,6,4,"['The paper addresses an important aspect of model efficiency in deep learning, providing practical insights for both researchers and practitioners.', 'The empirical analysis is thorough, covering various tasks and architecture families, and the results are well-presented.', 'The findings support the notion that simple committee-based models can outperform more complex architectures, which has implications for future research in model design.']","['The paper does not introduce a novel method or architecture, which limits its originality and impact in advancing the field.', 'Some sections are overly dense with technical details, which may hinder clarity for readers not deeply familiar with the topic.', 'While the experiments are extensive, additional quantitative comparisons with more recent models or more diverse datasets could strengthen the claims.']",2,3,4,3,Reject
IptBMO1AR5g,"The paper proposes a novel regularization method for deep neural networks by penalizing the trace of the Hessian matrix using a stochastic estimator. This method, referred to as Stochastic Estimators of Hessian Trace (SEHT), aims to improve generalization and stability in neural networks. The authors provide experimental results suggesting performance gains over existing regularizers, but the clarity and depth of the methodology and experiments are lacking.","['Can the authors provide clearer explanations for the mathematical formulations and algorithms used?', 'What is the statistical significance of the performance improvements observed in the experiments?', 'Could the authors include more comparative experiments with a broader range of regularization methods?']","['The clarity of the paper is a major concern, as the complex mathematical formulations may deter readers from understanding the contributions.', 'More detailed comparisons with existing methods are necessary to validate the claims of superiority.']",False,2,2,2,4,4,"['The paper addresses the important challenge of overfitting in deep neural networks.', 'The proposed regularization method is theoretically motivated and innovative.', 'The connection to dynamical systems provides an interesting theoretical perspective.']","['The presentation lacks clarity, particularly in explaining the algorithms and their implementation.', 'The experimental validation is limited, with insufficient comparisons to a wider range of regularization techniques.', 'The paper does not adequately discuss the computational complexity associated with Hessian estimation.', 'The statistical significance of the performance improvements is not sufficiently addressed.']",3,2,2,3,Reject
NuzF7PHTKRw,"The paper proposes EAT-C, a framework that enhances reinforcement learning (RL) efficiency on long-horizon tasks by generating a curriculum of sub-tasks and adversarially modifying environments. It introduces a cooperative planning policy for generating sub-task sequences and an adversarial environment generator to ensure tasks are sufficiently challenging, aiming to improve the agent's learning and robustness.","['Can the authors clarify the novelty of their approach compared to existing hierarchical RL methods?', 'What specific measures were taken to ensure that the generated sub-tasks are indeed diverse and appropriately challenging?', 'How do the authors justify the choice of specific baselines in their experiments?']","['Insufficient clarity regarding the implementation details of the planning and environment policies.', 'Potential over-reliance on specific baselines without rigorous justification for their selection.']",False,3,3,3,4,4,"['Addresses critical challenges in RL, specifically sparse rewards and sensitivity to environmental changes.', 'The dual approach of sub-task generation and environment modification is a novel contribution, which could lead to improved learning efficiency.', 'Comprehensive experiments were conducted across various benchmark tasks, demonstrating the effectiveness of the proposed method.']","['The originality of the approach may be limited as it builds upon existing methods for hierarchical RL and environment generation without sufficient differentiation.', 'Some key components of the approach, such as the planning policy and environment generator, lack detailed explanation in terms of their design and training mechanisms.', 'The clarity of the paper is compromised by complex terminology and insufficient explanations of critical concepts, hindering reader understanding.', 'Comparative evaluations with all relevant baseline methods are not comprehensive, which raises concerns about the robustness of the results.']",4,3,3,4,Reject
zuDmDfeoB_1,"The paper investigates the performance of Model-Agnostic Meta-Learning (MAML) compared to standard non-adaptive learning (NAL) in terms of task hardness and optimal solution geography. It provides theoretical proofs regarding when MAML achieves significant gains over NAL, supported by empirical experiments in few-shot learning scenarios.","['Can the authors clarify the reasoning behind the choice of tasks and settings used in the experiments?', 'What specific additional experiments do the authors consider to validate their theoretical findings?']","['The paper does not sufficiently address potential limitations and future work that could further validate the findings.', 'The clarity and presentation of the theoretical proofs could be improved to enhance accessibility.']",False,3,2,3,6,4,"['Theoretical insights provided on the conditions necessary for MAML to outperform NAL are valuable and advance understanding in the meta-learning field.', ""The analytical results are well-structured and logically derived, contributing to a deeper understanding of MAML's optimization behavior."", 'The paper successfully connects theoretical findings with practical implications, suggesting when to prefer MAML over NAL.']","['The presentation is somewhat dense and could benefit from clearer exposition and more intuitive explanations of the results.', 'The experimental section is relatively weak, with limited real-world datasets and scenarios. More diverse and comprehensive experiments are needed to substantiate the claims.', 'The clarity of the theoretical exposition could be improved to enhance understanding.']",3,3,2,4,Reject
4Muj-t_4o4,"The paper proposes a method for online adaptation in reinforcement learning by learning a subspace of policies within the parameter space. This approach aims to improve the adaptability of RL agents to variations in environments without relying on meta-learning techniques or extensive tuning. Experiments are conducted across multiple benchmarks, demonstrating the effectiveness of the proposed method.","['Can the authors provide more clarity on the theoretical underpinnings of their approach?', 'What specific metrics and benchmarks did the authors use to evaluate the significance of their improvements over existing methods?', 'Could the authors elaborate on the potential limitations and how they plan to address them in future work?']","[""The clarity of the paper's contributions and the experimental setup needs significant improvement."", 'The evaluation lacks depth and fails to fully explore the theoretical implications of the proposed approach.']",False,3,2,3,5,4,"['The idea of learning a subspace of policies is novel and relevant to the challenges of online adaptation in RL.', 'The paper addresses an important issue in RL concerning the generalization of policies to unseen environments.', 'Experiments across various benchmarks suggest that the proposed method performs competitively.']","['The paper lacks clarity in articulating its main contributions and the significance of the proposed method.', 'The experimental setup details are insufficient, particularly regarding the hyperparameter tuning process and the criteria for selecting policies in the subspace.', 'The comparison with existing methods is mostly qualitative, lacking rigorous quantitative evaluations and deeper analysis of results.', 'The paper does not adequately discuss potential limitations or the implications of the method in practical applications.']",3,2,2,4,Reject
m5EBN92vjN,"The paper presents the Attention Aware Network (AASeg) for real-time semantic segmentation, integrating spatial and channel attention with a multi-scale context module. The network achieves competitive performance on Cityscapes, ADE20K, and Camvid datasets, with a mean IoU of 74.4% on Cityscapes while running at 202.7 FPS.","['Can the authors provide more detailed explanations of the spatial attention and channel attention modules?', 'What specific contributions does AASeg make over existing methods that incorporate attention mechanisms?', 'Can the authors clarify the unique contributions of their method compared to existing approaches?']","['The clarity of the paper is a significant limitation, affecting understanding of the proposed method.', 'The originality of the contributions is low, as the approach does not sufficiently differentiate itself from existing works.']",False,2,2,2,4,4,"['AASeg demonstrates competitive performance metrics, particularly in speed and mean IoU.', 'The combination of multiple attention mechanisms and a multi-scale context module is a relevant approach for real-time segmentation tasks.', ""The evaluation on established datasets like Cityscapes, ADE20K, and Camvid provides a solid basis for assessing the method's effectiveness.""]","['The methodology lacks clarity; descriptions of the spatial attention and channel attention modules need elaboration.', 'The novelty of the approach is questionable as it builds on existing architectures without significant innovation.', 'The paper does not sufficiently discuss the implications of the findings or how they advance the state of the art.', 'Comparative analysis with existing architectures lacks depth, which could strengthen the case for the proposed network.']",2,2,2,3,Reject
mqIeP6qPvta,"The paper introduces FoveaTer, a foveated Transformer model designed to mimic biological foveated vision for image classification tasks. It utilizes pooling regions and eye movements to enhance computational efficiency while maintaining competitive accuracy. The model also demonstrates robustness against adversarial attacks, suggesting its potential for practical applications.","['Could the authors clarify the pooling mechanism and provide more details on the architecture?', 'Can the authors conduct more comprehensive ablation studies to elucidate the contributions of each component of the model?', 'What specific contributions to adversarial robustness does the foveated architecture provide compared to standard models?']","['The paper does not sufficiently address the limitations of the foveated architecture in scenarios requiring high-resolution detail.', 'The effects of different initial fixation points on model performance and robustness could be explored further.']",False,3,2,3,5,4,"['The integration of foveated vision concepts into a Transformer architecture is a novel contribution.', 'The model achieves significant computational savings while maintaining performance, which is crucial for resource-constrained applications.', 'The focus on adversarial robustness is timely and relevant, addressing a critical challenge in deploying machine learning models.']","['The clarity of the paper is lacking, particularly in explaining the architecture and the pooling mechanism.', 'The experimental validation is limited, with insufficient comparisons to a broader range of state-of-the-art models.', 'The theoretical basis for the advantages of the foveated approach over traditional methods is not well articulated.']",3,3,3,4,Reject
JXSZuWSPH85,"The paper presents SOLO-IRL, a novel method for inverse reinforcement learning that employs adversarial one-class classification to estimate rewards from expert trajectories without the need for baseline trajectories. While the method shows potential, clarity issues and insufficient experimental validation limit its effectiveness.","['Can the authors clarify how SOLO-IRL compares to baseline methods in terms of performance metrics?', 'What specific limitations does the proposed method have, and how do the authors plan to address these in future work?']","['The clarity issues in the paper could lead to misunderstandings of the proposed methods.', 'The experimental validation does not convincingly demonstrate the advantages of SOLO-IRL over existing methods.']",False,2,2,2,4,4,"['The integration of adversarial one-class classification into IRL is innovative and offers a fresh perspective.', 'Eliminating the need for baseline trajectories is a significant advancement over traditional IRL methods.']","['The writing lacks clarity, making it challenging to fully understand the methodology and results.', 'Experimental results are inadequately presented, with limited comparisons to existing methods.', 'There is insufficient analysis of the limitations and potential negative impacts of the proposed method.']",3,2,2,3,Reject
D78Go4hVcxO,"The paper investigates the properties of multi-head self-attention (MSA) mechanisms in Vision Transformers (ViTs) compared to convolutional neural networks (CNNs), proposing that MSAs improve generalization and flatten loss landscapes. It introduces AlterNet, a model that combines CNN and MSA architectures to enhance performance across different data regimes.","['Can the authors provide more empirical evidence to support the claim that MSAs function as spatial smoothings?', ""What specific aspects of AlterNet's architecture contribute most significantly to its performance improvements over traditional CNNs?"", 'Could the authors clarify the method for evaluating the robustness of their models against perturbations or corruptions?', 'How do the authors justify the claims regarding MSAs acting as low-pass filters with concrete empirical evidence?', 'What specific experiments were conducted to support the performance improvements claimed for AlterNet?']","['The experimental validation of the theoretical claims is limited; more comprehensive testing across different datasets and tasks would strengthen the paper.', 'The clarity and organization of the paper could be improved to make the findings more accessible to a broader audience.', 'The paper does not sufficiently address potential limitations or alternative explanations for the observed performance differences between MSAs and Convs.']",False,2,2,3,4,4,"['The paper tackles a relevant and current topic regarding the understanding of MSAs in ViTs, which is important as Transformers gain traction in computer vision.', 'The introduction of AlterNet presents a practical application of the insights derived from the study of MSAs and Convs, providing a novel architectural approach.', 'The paper includes a variety of experiments and analyses, such as loss landscape visualizations and Hessian eigenvalue spectra, which support its claims.']","['The conclusions about MSAs behaving as generalized spatial smoothings are not sufficiently supported by rigorous experimental evidence, leaving the reader wanting more detailed validation.', ""The paper's presentation is dense and at times convoluted, making it challenging to follow for readers who may not have a deep background in the topic."", 'While the introduction of AlterNet is interesting, it may not represent a significant enough advancement over existing models to warrant publication in a top-tier venue.', 'Many assertions, such as the nature of MSAs as low-pass filters, lack thorough theoretical explanation.', 'The experimental evaluation lacks depth and rigor, which limits the conclusions that can be drawn.']",3,2,2,3,Reject
8QE3pwEVc8P,"The paper introduces a novel operation scoring method, Zero-Cost-PT, for differentiable neural architecture search (NAS) aimed at improving search efficiency and accuracy. It critiques existing operation scoring proxies and presents its zero-cost approach through empirical evaluation across multiple search spaces.","['Could the authors clarify the methodology for scoring and the differences between existing methods and Zero-Cost-PT more distinctly?', 'What specific limitations does the authors foresee for the Zero-Cost-PT approach?']","['The paper does not adequately address the potential limitations of the proposed method, particularly in specific search contexts.', 'The empirical results should be reproducible in various scenarios to substantiate the claims made.']",False,3,3,3,6,4,"['The proposed method addresses a significant challenge in differentiable NAS regarding operation scoring, which could improve both search speed and accuracy.', 'The experimental results demonstrate improvements over existing methods like DARTS and DARTS-PT in multiple settings, which is promising.', 'The paper is well-structured and covers relevant related work in the context of NAS.']","['The clarity of the methodology and the presentation of results can be improved. Some critical details about the implementation of Zero-Cost-PT are lacking.', 'While the paper claims significant improvements, the empirical support for these claims is not robust enough; further validation across more diverse tasks would be beneficial.', 'The limitations of the proposed method are not sufficiently discussed, particularly in contexts where it may fail or underperform.']",3,3,3,4,Reject
reFFte7mA0F,"The paper proposes a Conditional Expectation based Value Decomposition (CEVD) method to enhance the efficiency of on-demand ride pooling by considering the interactions among multiple vehicles and their actions. The authors claim to outperform the current state-of-the-art, NeurADP, by significant margins on a city-wide taxi dataset.","['Can the authors clarify the assumptions made in their model regarding agent interactions?', 'Could the authors provide more details on the evaluation metrics used in their experiments?', 'What specific limitations of the NeurADP method does CEVD address, and how are these reflected in the results?', ""Could the authors elaborate on the algorithm's limitations and potential ethical concerns related to its implementation?""]","[""The clarity of the paper could hinder understanding of the proposed method, particularly in sections discussing the algorithm's implementation."", 'The lack of detailed comparison with existing methods leaves uncertainty about the generalizability of the results.', 'The ethical implications of deploying such algorithms in urban environments (e.g., data privacy, algorithmic bias) are not discussed.']",True,3,2,3,5,4,"['Addresses a relevant and practical problem in on-demand ride pooling.', ""Introduces a novel approach that considers the impact of other agents' actions, which is crucial for real-world applications."", 'Demonstrates significant improvements in performance metrics, showing practical relevance and applicability to real-world ride pooling scenarios.']","['The paper lacks clarity in explaining the methodology, particularly in describing how CEVD operates compared to NeurADP.', 'The experimental results are not adequately detailed or discussed, making it difficult to understand the full implications of the improvements claimed.', 'There is insufficient motivation and explanation for the choice of parameters and settings used in the experiments.', 'The discussion on the limitations of the proposed method is limited, and potential negative societal impacts, such as data privacy and algorithmic bias, are not adequately addressed.']",3,3,2,4,Reject
IsHQmuOqRAG,"The paper proposes a framework for learning object-centric representations from single images using predictive learning, inspired by developmental psychology. It introduces a new synthetic dataset with complex textures and aims to segment objects and infer their 3D locations without supervision. However, the methodology lacks clarity, and the experimental evaluation is insufficient.","['Could you clarify how your method fundamentally differs from existing unsupervised object-centric representation methods?', 'What statistical methods were used to ensure the robustness of the experimental results?', 'Can you provide additional visual examples or qualitative comparisons to better illustrate the performance of your model?']","['The paper does not adequately address the limitations of the proposed approach, such as potential biases introduced by the dataset.', 'Clarity issues may hinder reproducibility and understanding of the method.']",False,2,2,2,4,4,"['The integration of insights from developmental psychology into the framework is a novel perspective.', 'The new dataset with complex textures can help in evaluating object-centric models under more realistic conditions.', 'The proposed method demonstrates potential for learning object representations without supervision.']","['The paper lacks clarity in describing how the proposed method differs from existing models, making it difficult to assess originality.', 'The experimental results lack detailed comparative analysis and statistical significance tests.', 'The methodology section is dense and difficult to follow, hindering reproducibility.', ""Insufficient evaluation of the proposed method's performance relative to existing state-of-the-art methods.""]",3,2,2,4,Reject
fCSq8yrDkc,"The paper develops a fast and reliable method for solving large-scale optimal transport problems using the Douglas-Rachford splitting technique. It claims to provide improvements in speed and accuracy compared to existing methods like the Sinkhorn method, supported by theoretical analysis and GPU implementations. However, the originality and clarity of the work are questioned, and the experimental evaluation is limited.","['Can the authors provide more extensive comparisons with a wider range of existing optimal transport methods?', 'What specific novel insights does this paper provide beyond existing literature, particularly regarding the Douglas-Rachford method?']","['The paper does not sufficiently address its limitations, particularly regarding potential numerical instability and scenarios where performance may deteriorate.', 'There is a lack of discussion surrounding the implications of using this method in practical applications beyond computational efficiency.']",False,3,2,3,5,4,"['The proposed method addresses a significant challenge in optimal transport, relevant to many machine learning applications.', ""The algorithm's claimed improvements in speed and accuracy are promising, particularly with the GPU implementation."", 'The paper includes theoretical guarantees, such as linear convergence rates, which enhance its credibility.']","['The originality of the work is limited, as it heavily relies on established techniques without offering fundamentally new insights.', 'The clarity of the paper is poor, with dense mathematical formulations and organization issues that hinder understanding.', 'The experimental evaluation is primarily focused on comparisons with the Sinkhorn method, lacking a broader context against other state-of-the-art methods.']",2,3,2,3,Reject
vfsRB5MImo9,"The paper introduces the Continual Knowledge Learning (CKL) problem for Large Language Models (LMs), focusing on the challenge of updating their knowledge without losing previously acquired information. It proposes a benchmark to evaluate this problem and compares various methods from the literature as baselines. While the topic is relevant and timely, the execution and clarity of the study raise several concerns.","['Can the authors clarify their methodology to enhance reproducibility?', 'What specific aspects make their approach to CKL different from existing continual learning methods?', 'Could the authors provide more theoretical insight into the implications of their findings?']","['The clarity of the paper is inadequate, which could lead to misunderstandings regarding the contributions.', 'The practical implications of the findings are not sufficiently explored, limiting the significance of the results.']",False,3,2,3,6,4,"['Addresses a significant challenge in updating knowledge in language models while mitigating catastrophic forgetting.', 'The introduction of a new benchmark for evaluating knowledge retention, updating, and acquisition is a timely and relevant contribution.', 'The experiments cover a range of methods and provide a thorough evaluation of their performance under CKL.']","['Lacks clarity in the methodology section, making it difficult to reproduce the work based on the descriptions provided.', 'The novelty of the proposed CKL methods is not sufficiently differentiated from existing continual learning strategies, which could lead to confusion about the contributions of the paper.', 'The theoretical framework and analysis of the findings are weak, failing to clearly articulate the practical implications of the observed performance differences.']",3,3,2,4,Reject
kSwqMH0zn1F,"The paper proposes PipeGCN, a method for efficient full-graph training of Graph Convolutional Networks (GCNs) that pipelined communication of node features with computation to reduce training time. It provides theoretical convergence analysis, showing that PipeGCN's convergence rate is close to vanilla distributed GCN training without staleness. The method includes a smoothing technique to further enhance convergence and boosts training throughput significantly.","['How do the authors plan to further validate the theoretical claims with empirical evidence?', 'Can the authors elaborate on the potential pitfalls of relying on stale features and gradients in real-world applications?']","['The paper could benefit from clearer explanations of the implications of using stale features and gradients.', 'It would be helpful to see more extensive experiments to support the claims made regarding efficiency and accuracy.']",False,3,4,3,7,4,"['Addresses a significant bottleneck in the training of GCNs related to communication overhead in distributed settings.', 'Provides a theoretical convergence analysis which is a valuable contribution to the understanding of GCN training with stale features.', 'Demonstrates substantial improvements in training throughput through extensive empirical evaluations across multiple datasets.']","['The theoretical results need deeper empirical validation; the convergence analysis might be too optimistic given the practical challenges of staleness.', 'The paper lacks clarity in some sections, particularly regarding the implications of staleness in the training process.', 'Experimental results could benefit from more diverse settings and additional comparisons with more baseline methods.']",3,3,4,4,Reject
gFDFKC4gHL4,"The paper introduces MASA, an algorithmic framework for assessing shifts in machine learning API performance over time by estimating differences in confusion matrices. It addresses the practical concern of silent performance changes in APIs used by various applications. The framework employs adaptive sampling based on uncertainty scores to efficiently query the API with minimal costs, showing significant improvements in estimation accuracy compared to standard sampling methods.","['Could the authors provide more detailed explanations of how MASA operates, particularly regarding the adaptive sampling process?', 'What measures were taken to ensure the robustness of the experimental results?', 'Can the authors clarify the reasoning behind some methodological choices in MASA?', 'What are the potential societal implications of relying on shifting ML APIs, and how does MASA address these concerns?']","['Lack of clarity in explaining the algorithm may limit accessibility for practitioners and researchers.', 'The focus on classification tasks limits the applicability of the framework to other types of APIs.', 'Relying solely on confusion matrix differences may overlook nuances in API performance changes.']",True,3,3,3,6,4,"['Addresses a critical issue in ML API usage, highlighting the impact of silent updates on application performance.', 'Proposes a theoretically sound framework (MASA) that utilizes adaptive sampling for efficient API shift assessment.', 'Empirical results demonstrate significant improvements in estimation accuracy and sample efficiency with MASA compared to standard approaches.']","['The explanation of the MASA algorithm lacks sufficient detail, which may hinder reproducibility.', 'The manuscript would benefit from clearer descriptions of the experiments and their implications.', 'Some sections are verbose, potentially obscuring key findings.']",3,3,3,4,Reject
d2TT6gK9qZn,"The paper proposes a Pade approximation based exponential neural operator scheme for efficiently solving Initial Value Problems (IVPs) associated with non-linear partial differential equations. It aims to enhance data efficiency and performance in modeling complex dynamical processes, including applications in epidemic forecasting.","['Can the authors clarify how their method fundamentally differs from existing neural operators?', 'What specific experiments were conducted to validate the theoretical claims, and how were they selected?', 'Could the authors provide more intuitive explanations of their proposed methods and the rationale behind their choices?']","['The clarity of theoretical aspects and methodology needs improvement for better understanding and reproducibility.', 'The evaluation of the model is limited and does not cover enough diverse datasets or applications.']",False,2,2,3,4,4,"['Addresses a critical challenge in solving IVPs with non-linear operators, which is highly relevant across various scientific domains.', 'The theoretical foundation regarding bounded gradients is a notable contribution that enhances the robustness of the approach.', 'Demonstrates practical applicability through experiments on synthetic datasets and real-world applications, particularly in epidemic forecasting.']","['Lacks clarity in theoretical explanations and methodology, which may hinder reproducibility and understanding.', 'The novelty of the method compared to existing neural operators is not sufficiently articulated, making it challenging to assess its contributions.', 'Experimental validation is limited and does not encompass a diverse range of datasets or applications, raising concerns about generalizability.']",3,2,2,4,Reject
_PHymLIxuI,"The paper presents CrossFormer, a novel vision transformer architecture that enhances feature interactions across different scales using a Cross-scale Embedding Layer (CEL) and Long Short Distance Attention (LSDA). The proposed design aims to maintain small-scale features while enabling long-distance interactions, addressing limitations in current vision transformers. The experiments conducted show that CrossFormer achieves state-of-the-art performance across various vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation.","['Can the authors elaborate on the differences between the proposed dynamic position bias and existing position bias mechanisms?', 'Could the authors clarify the expected impact of the proposed methods on computational efficiency in practical applications?', 'Can the authors provide clearer explanations of the CEL and LSDA implementations?', 'What specific rationale led to the choice of kernel sizes in the Cross-scale Embedding Layer?']","['The paper could better address potential limitations of the architecture in handling very high-resolution images or complex scenes.', 'More discussion on the trade-offs between model complexity and performance would be beneficial.', 'Clarity issues in technical descriptions and justifications for design choices.']",False,2,3,3,5,4,"['The proposed CrossFormer effectively addresses the issue of cross-scale feature interaction, which is critical for many vision tasks.', ""The architecture introduces innovative components like CEL and LSDA, enhancing the model's capabilities in a computationally efficient manner."", ""Extensive experiments demonstrate the model's superiority over state-of-the-art vision transformers on multiple tasks."", 'The paper includes comprehensive ablation studies that validate the effectiveness of the proposed methods.']","['Some sections of the paper, particularly those explaining the architecture, could benefit from clearer explanations and illustrations.', 'The paper does not sufficiently discuss the novelty of the dynamic position bias compared to existing methods, which may lead to questions about its distinctiveness.', 'While the experiments are thorough, the paper could provide more insight into the failure cases or limitations of the proposed approach.', 'The experimental evaluation lacks detailed statistical analyses to validate performance claims.']",3,2,3,4,Reject
Xg47v73CDaj,"The paper presents ParNet, a novel neural network architecture that utilizes parallel subnetworks to achieve competitive performance with reduced depth. The authors claim that ParNet can achieve over 80% accuracy on ImageNet with a depth of only 12 layers, challenging the conventional wisdom that deeper networks are essential for high performance. However, the originality of the approach is questioned, and the paper lacks clarity in presenting its contributions and experimental results.","['Can the authors clarify the architectural design choices and their implications on performance?', 'How does ParNet improve upon existing shallow networks and non-deep architectures in a way that is not already covered in the literature?', 'Can the authors provide more detailed comparisons against a wider array of existing network architectures?']","['The lack of detailed information about the architecture and experimental setup raises concerns about reproducibility.', 'The assumptions made regarding the advantages of parallel processing over depth need further exploration and validation.']",False,3,3,3,5,4,"['The exploration of non-deep networks addresses a significant question in neural network design and has practical implications for low-latency applications.', 'Empirical results show that ParNet can achieve competitive performance on standard benchmarks, demonstrating the potential of non-deep networks.', 'The concept of using parallel subnetworks is innovative and relevant for future hardware designs.']","['The originality of the approach is questionable, as similar concepts of parallel architectures and shallow networks have been explored in the literature.', 'The presentation lacks clarity in some areas, particularly in the explanation of architectural choices and their implications on performance, such as the specific advantages of the parallel structure.', 'The experimental validation lacks depth; comparisons are primarily made against a narrow subset of existing architectures without comprehensive evaluation.']",3,3,3,4,Reject
oxC2IBx8OuZ,The paper proposes a framework for Continual Federated Learning (CFL) that addresses the challenges posed by time-varying heterogeneous data in Federated Learning (FL). It presents theoretical analysis showing faster convergence rates than traditional methods like FedAvg and supports these claims with empirical evaluations across various datasets.,"['Can the authors provide a more detailed explanation of the approximation techniques used in the CFL framework?', 'Could the authors clarify how their framework handles extreme cases of client drift or data unavailability?', 'What steps will the authors take to improve the clarity of their exposition in future versions?']","['The lack of clarity in some sections could prevent full comprehension of the proposed methods and their implications.', 'The experimental design, while extensive, may benefit from more rigorous comparisons demonstrating practical advantages of CFL methods.']",False,3,4,3,7,4,"['The proposed CFL framework addresses a significant gap in the current Federated Learning literature regarding time-varying heterogeneous data.', 'Theoretical convergence results are provided, demonstrating that CFL methods converge faster than FedAvg under certain conditions.', 'Extensive experiments validate the proposed methods against state-of-the-art FL baselines.']","['The paper lacks clarity in the presentation, particularly in explaining the methodology and theoretical assumptions, which may confuse readers.', 'The originality of the contributions is somewhat limited, as the concept of continual learning has been previously explored, with novelty primarily in its application to federated settings.', 'Empirical results need clearer presentation and analysis, particularly in highlighting practical advantages of CFL over existing methods.']",4,3,4,4,Reject
ULfq0qR25dY,"This paper introduces the maximum n-times coverage problem, a novel combinatorial optimization challenge framed within the context of peptide vaccine design for COVID-19. The authors propose two algorithms to solve this problem and claim superior population coverage compared to existing designs. However, the presentation lacks clarity, and the theoretical and experimental validations are insufficient.","['Could the authors clarify the definitions and implications of the maximum n-times coverage problem?', 'Can the authors provide more in-depth theoretical analysis supporting the NP-completeness of the problem?', 'How do the proposed methods compare against a broader set of existing methods in terms of coverage and computational efficiency?']","['The paper does not sufficiently address potential limitations or assumptions made in the proposed algorithms.', 'The experimental results require better explanation and context to truly demonstrate the advantages of the proposed methods.']",False,2,2,3,4,4,"['The maximum n-times coverage problem is a relevant and timely contribution, particularly in the context of vaccine design.', 'The introduction of weighted elements and n-times coverage constraints provides a novel approach to optimizing vaccine composition.', 'The application of the proposed methods to COVID-19 vaccine design addresses a critical area in public health.']","['The clarity of the problem definition and the algorithms could be improved; certain sections are overly complex and difficult to follow, particularly in the mathematical formulations.', 'The theoretical justification for the proposed problem and its complexity is not thoroughly explored, leaving gaps in understanding its implications.', 'The experimental validation is shallow, lacking comprehensive comparisons with a wider range of existing vaccine design methods, which diminishes the robustness of the claims.']",3,2,2,4,Reject
KTPuIsx4pmo,"The paper introduces a novel approach to meta-imitation learning that enables robots to learn tasks from human video demonstrations without requiring robot demonstrations. It presents A-CycleGAN, a generative model that translates human actions into robot actions, facilitating data collection and aligning with human imitation behavior. Empirical results indicate that the proposed method achieves comparable performance to existing meta-imitation learning techniques.","['Can the authors provide more details on the architecture and training process of A-CycleGAN?', 'What measures are in place to ensure the quality of the translated robot actions, and how might this impact learning?', 'Could the authors elaborate on the limitations of their approach and potential future work?']","['The lack of clarity in the methodology and insufficient experimental validation limit the impact of the findings.', 'The reliance on simulated environments may not fully capture the complexities of real-world applications, affecting the generalizability of the results.']",True,2,2,3,4,4,"['Addresses a significant challenge in robotics by allowing learning from human video demonstrations without the need for robot demonstrations.', 'The A-CycleGAN model for translating human actions into robot actions is innovative and relevant to the field of imitation learning.', 'Empirical results demonstrate that the proposed method performs comparably to existing techniques, suggesting its potential effectiveness.']","['The methodology lacks clarity, particularly in detailing the architecture and training process of A-CycleGAN.', 'Experimental validation is limited, with insufficient comparisons to a broader range of baselines and a lack of robustness in real-world scenarios.', 'The paper does not adequately discuss the limitations of the approach or potential ethical considerations related to using human video data.']",3,2,2,3,Reject
jJWK09skiNl,"The paper proposes a method for zero-shot detection of daily objects using a modified YOLOv5 architecture on the YCB Video dataset. It aims to address the challenges of recognizing and localizing unseen objects in dynamic manufacturing environments. However, the execution lacks clarity, and the results do not sufficiently support the claims made.","['Can the authors clarify the specific modifications made to YOLOv5 and their expected impact?', 'What metrics were used to evaluate the zero-shot detection performance, and how do they compare to state-of-the-art methods?', 'Can the authors provide a more detailed explanation of the attribute labeling method and how it specifically benefits the detection task?', 'What are the baseline methods against which the proposed approach is being evaluated?']","['The methodology lacks clarity, which could hinder reproducibility.', 'The results do not provide a comprehensive evaluation against existing methods in the literature.', 'The paper does not adequately address the limitations of the proposed method, particularly regarding its performance on unseen objects.']",False,2,2,2,4,4,"['The problem of zero-shot detection in manufacturing robotics is relevant and timely.', 'The use of YOLOv5 for this task is an interesting choice, potentially allowing for faster object detection.', 'The approach addresses a significant gap in the literature regarding indoor object detection in manufacturing settings.']","['The description of the modified YOLOv5 architecture is unclear and lacks detail, making it difficult to understand the technical contributions.', 'The results presented do not convincingly demonstrate the effectiveness of the proposed method compared to existing approaches.', 'There is insufficient analysis of the results, particularly regarding the impact of the proposed changes on detection performance.', 'The clarity of the writing is poor, making it challenging to follow the proposed methodology and contributions.', 'The experimental results lack depth and sufficient analysis, particularly in how the proposed method compares against existing state-of-the-art techniques.']",2,2,2,3,Reject
bUAdXW8wN6,"The paper proposes Domain Invariant Adversarial Learning (DIAL), an adversarial training method that aims to improve the robustness of deep neural networks by enforcing a domain-invariant feature representation. DIAL utilizes a variant of Domain Adversarial Neural Network (DANN) and shows promising results in terms of robustness and standard accuracy across various datasets.","['Can the authors clarify how DIAL significantly differs from existing adversarial training techniques?', 'What statistical tests have been performed to validate the improvements reported in the experiments?', 'Could the authors provide more detailed explanations on the choice of hyperparameters and their impact on performance?']","['The paper does not adequately address potential limitations of the proposed approach, such as the computational overhead of adversarial training.', 'The generalizability of the method to real-world scenarios where different types of attacks are employed remains untested.']",False,3,3,4,6,4,"['The idea of incorporating domain-invariant feature representation into adversarial training is novel and addresses a significant problem.', 'The paper includes extensive experiments on multiple benchmark datasets (MNIST, SVHN, CIFAR-10, CIFAR-100), showing improvements in both robustness and natural accuracy.', 'The proposed method demonstrates competitive performance against state-of-the-art adversarial training methods.']","['The originality of the approach is somewhat questionable as it primarily builds upon existing adversarial training frameworks and domain adaptation techniques without demonstrating a significant departure from them.', ""The explanations of the model architecture and the loss functions are not clear enough, making it difficult to fully grasp the proposed method's implementation."", 'The clarity of the presentation could be improved; some sections are convoluted, making it challenging to follow the proposed method and its implementation.', 'The experimental results lack sufficient detail, such as statistical significance tests, which raises concerns about the robustness of the reported improvements.']",4,3,3,4,Reject
j-63FSNcO5a,"The paper introduces a novel framework called Disentanglement via Contrast (DisCo) that aims to learn disentangled representations by leveraging pretrained generative models. The authors validate their approach through experiments showing state-of-the-art performance across various datasets. However, the clarity of the presentation and the novelty of the contributions are questioned by multiple reviewers.","['Could the authors provide more detailed comparisons with existing methods to better illustrate the novelty of DisCo?', 'Can the authors clarify the role and functioning of the Navigator and the ∆-Contrastor in more detail?', 'What specific improvements do the entropy-based domination loss and hard negatives flipping bring to the overall performance?']","['The paper does not sufficiently address potential limitations or drawbacks of the proposed method, particularly in terms of its generalizability to other generative models not tested.', 'The clarity and depth of explanation around key components of the method could be improved.']",False,3,2,3,4,4,"['The proposed framework DisCo addresses an important problem in representation learning by focusing on disentanglement.', 'The methodology introduces novel techniques such as the entropy-based domination loss and hard negatives flipping strategy.', 'The empirical results demonstrate that DisCo achieves state-of-the-art performance on several disentanglement metrics.']","['The clarity of the paper is lacking, with complex concepts not sufficiently explained for a broader audience.', 'The novelty of the approach is not adequately discussed in relation to existing methods, making it hard to evaluate its contribution.', 'The experimental results may not be robust enough; reliance on pretrained models could influence the outcomes significantly.']",3,3,2,4,Reject
L1L2G43k14n,"This paper investigates the correlation between flatness of loss landscapes and generalization in deep neural networks, critiquing existing flatness measures and proposing the log of Bayesian prior as a more robust predictor of generalization. The authors conduct experiments on standard datasets like MNIST and CIFAR-10 to support their claims.","['Can the authors clarify how the experiments were designed to ensure fair comparisons between flatness measures and the Bayesian prior?', 'Could the authors provide more theoretical justification for the claims about the robustness of the Bayesian prior?', 'How do the authors envision future work extending their findings, particularly regarding the theoretical backing for the Bayesian prior?']","['The clarity of the paper is a significant concern, potentially hindering its impact.', 'The empirical results could benefit from clearer presentation and analysis.', 'The theoretical arguments need to be articulated more robustly.']",False,2,2,3,5,4,"['Addresses a significant question in deep learning regarding flatness and generalization.', 'Introduces a novel approach using Bayesian priors, which is theoretically interesting.', 'Includes thorough experimental analysis across multiple datasets.']","['The writing is dense and may be difficult for a broader audience to follow.', ""The empirical results do not convincingly demonstrate the proposed method's superiority over existing flatness measures."", 'The theoretical foundations could be more robust to support the claims made.', 'The experimental setup lacks clarity in comparing different measures.']",3,2,2,3,Reject
yV4_fWe4nM,"The paper proposes a deep fair clustering framework that integrates group-level fairness constraints into a discriminative clustering model, formulating the fairness criteria as an integer linear programming problem. The experimental results indicate that the proposed approach achieves better clustering performance while ensuring fairness compared to existing methods.","['How does the proposed method compare to existing fair clustering approaches in terms of scalability and real-world applicability?', 'Can the authors clarify the practical implications of their method for practitioners working in sensitive applications?', 'What specific datasets and scenarios were used to evaluate the performance of the proposed method?', 'Will the authors provide additional ablation studies to dissect the contributions of different components of their framework?']","['The paper could benefit from a clearer delineation of the novelty of its contributions compared to existing literature.', ""More detailed explanations of the algorithm's implementation and practical applications would enhance clarity."", 'The potential for the framework to be misused or for fairness constraints to be manipulated should be discussed in more detail.']",True,3,2,3,5,4,"['Addresses a significant issue in AI and machine learning related to fairness in clustering.', 'The formulation of fairness as an integer linear programming problem is interesting and allows for efficient computation.', 'Experimental results indicate that the proposed method outperforms existing fair clustering algorithms.']","['The novelty of the approach is somewhat undermined by existing literature on fair clustering, making it unclear what is entirely new in this work.', 'Certain sections of the paper lack clarity, particularly in the explanation of the algorithm and its practical implications.', 'The connections between fairness and clustering performance need to be better articulated; the paper does not fully explain how fairness constraints impact clustering outcomes.', 'The experimental results are limited in scope and do not cover a wide enough range of datasets or scenarios to demonstrate robustness.']",2,3,2,4,Reject
9rKTy4oZAQt,"The paper presents Cumulative Prospect Proximal Policy Optimization (C3PO), a risk-sensitive policy gradient method for reinforcement learning that optimizes distributional outcomes based on cumulative distribution functions. It aims to enhance agent decision-making in uncertain environments and is validated through experiments in OpenAI Safety Gym, showing promise compared to traditional methods.","['Can the authors clarify the specific contributions of C3PO compared to existing methods?', 'What steps can be taken to improve the clarity of the proposed algorithm and its implementation?', 'Could the authors provide more detailed statistical analysis of the experimental results to support their claims?']","['The clarity of the paper may hinder reproducibility and understanding of the proposed method.', 'Potential biases introduced by the chosen utility and weight functions are not addressed.', 'The empirical results may not be generalizable due to the limited scope of environments tested.']",False,2,2,3,4,4,"['Addresses a significant gap in reinforcement learning by incorporating risk sensitivity.', 'The proposed method allows for flexible risk profiles, enhancing robustness in uncertain environments.', 'Empirical validation across multiple OpenAI Safety Gym environments demonstrates potential practical applications.']","['The methodology lacks clarity; key components and theoretical foundations are not well articulated, making it difficult to reproduce the results.', 'Experimental results could be more robust, with a need for additional statistical analysis and comparisons to existing methods.', 'The paper does not sufficiently address potential limitations or drawbacks of the proposed method.']",3,2,2,4,Reject
lY0-7bj0Vfz,"The paper proposes a Memory Concept Attention (MoCA) mechanism for few-shot image generation, inspired by neurophysiological findings about 'grandmother cells' in the visual cortex. The authors claim that MoCA enhances image synthesis by utilizing prototype memory, leading to improved image quality and robustness. They validate their approach through experiments with existing GAN architectures.","['Can the authors clarify the connection between the biological findings and the proposed MoCA framework?', 'What specific contributions does MoCA offer that are distinct from existing memory and attention mechanisms?', 'Can the authors provide additional comparisons with other recent methods in few-shot image generation?']","['The paper does not adequately address the limitations of the proposed method or its potential ethical implications.', 'The clarity and organization significantly hinder understanding and may obscure the significance of the contributions.']",False,2,2,2,4,4,"['The integration of cognitive neuroscience principles into machine learning is a novel and refreshing approach.', 'The proposed MoCA mechanism shows promise in improving image synthesis quality in few-shot scenarios.', 'The paper includes extensive experimental results across various datasets, demonstrating the potential applicability of the proposed method.']","['The paper lacks clarity in presenting the underlying mechanisms of MoCA and how it directly relates to existing attention mechanisms.', 'The novelty of the approach is questionable; it relies heavily on existing concepts without offering significant new insights.', 'The experimental evaluation is not comprehensive; ablation studies are insufficiently detailed, which raises concerns about the robustness of the results.', 'Some claims regarding robustness and interpretability need stronger empirical backing.']",3,2,2,3,Reject
R8sQPpGCv0,"The paper introduces Attention with Linear Biases (ALiBi), a novel method for enhancing the extrapolation capabilities of transformer models for longer input sequences than those seen during training. ALiBi modifies the attention mechanism to eliminate the need for traditional positional embeddings while maintaining or improving performance. Experimental results demonstrate that ALiBi outperforms existing methods in terms of perplexity and resource efficiency.","['Could the authors clarify the choice of slope values for the biases in ALiBi? How does this choice impact performance across different datasets?', 'Can additional experiments be provided that explore the extrapolation capabilities of ALiBi in comparison to other methods more thoroughly?']","['The paper does not adequately address the limitations of the proposed method, particularly regarding its scalability to longer sequences or its performance in varying contexts.', 'The clarity of descriptions and the presentation of results could lead to misinterpretations; clearer visuals and explanations are recommended.']",False,3,3,3,7,4,"['ALiBi presents a novel approach to positional encoding that simplifies the positional embedding process and enhances extrapolation capabilities.', 'The experimental results are compelling, showing that models trained with ALiBi achieve better or comparable performance to sinusoidal and rotary models, even when trained on shorter sequences.', 'The paper is well-structured and clearly presents performance metrics and comparisons with existing methods.']","['The paper lacks clarity in explaining how the biases are calculated and the rationale behind the choice of specific slope values for the biases.', 'Comparative analyses with other methods, particularly regarding extrapolation, could be more detailed to clarify the advantages of ALiBi.', 'Some experimental results lack sufficient context or explanation, making it challenging to understand the significance of certain findings.']",3,3,3,4,Accept
EHaUTlm2eHg,"The paper introduces Policy Gradients Incorporating the Future (PGIF), a reinforcement learning method that allows agents to utilize future trajectory information during training while imposing an information bottleneck to prevent over-reliance on this information. The method aims to enhance credit assignment in RL, particularly in complex environments with sparse rewards and partial observability. Despite the interesting premise, the execution raises concerns regarding clarity, thoroughness of evaluation, and potential biases introduced by leveraging future information.","['Can the authors clarify the implementation details of the information bottleneck in PGIF?', 'How do the authors address the potential biases introduced by conditioning on future trajectory information, especially in offline settings?', 'Can additional experimental comparisons be provided to strengthen the claims of improved performance?']","['The paper does not sufficiently evaluate the impact of biases introduced by access to future information in the training datasets.', 'Potential issues with the scalability of the proposed method in complex environments are not discussed.']",True,3,2,3,5,4,"['Addresses significant challenges in reinforcement learning, particularly credit assignment and learning in sparse reward settings.', 'Introduces an innovative approach to utilize future trajectory information without explicit modeling.', 'Demonstrates potential effectiveness through experiments on various RL algorithms.']","['Clarity issues regarding the implementation details of PGIF, particularly around the information bottleneck and the role of latent variables.', 'Limited exploration of potential biases and ethical implications of using future information, especially in offline datasets.', 'Experimental results lack thoroughness and sufficient comparisons to validate claims of superior performance.', 'The paper does not adequately address the generalizability of results across different RL settings.']",3,3,2,4,Reject
Fj1Tpym9KxH,This paper investigates the impact of smoothness in domain adversarial training and introduces a method called Smooth Domain Adversarial Training (SDAT). The authors claim that focusing on smoothness in task loss enhances generalization performance in domain adaptation tasks. The paper includes theoretical insights and empirical validation across various datasets.,"['Can the authors clarify the theoretical implications of their findings on smoothness?', 'What specific steps will be taken to ensure the robustness and replicability of the experimental results?']","['The paper does not adequately address the limitations of the proposed method or potential negative impacts of the findings.', 'The reliance on specific hyperparameter settings without a discussion on their tuning process may limit reproducibility.']",False,3,3,3,6,4,"['Addresses an important issue in domain adaptation by analyzing smoothness in domain adversarial training.', 'Introduces a novel method (SDAT) that shows potential improvements in generalization performance.', 'Provides theoretical contributions and empirical results across multiple datasets.']","['The clarity of the theoretical analysis could be improved to enhance understanding of the implications of the findings.', 'Some experimental results raise concerns about robustness and reproducibility, particularly regarding hyperparameter choices.', 'The originality of the approach may be limited, as it builds on existing concepts without introducing significantly novel mechanisms.']",3,3,3,4,Reject
k7-s5HSSPE5,"The paper presents a method for unsupervised cross-lingual transfer learning named Importance-Weighted Domain Alignment (IWDA), which addresses the issue of class prior shifts negatively impacting performance. The authors provide empirical analyses demonstrating the correlation between representation invariance and transfer performance, and propose IWDA as a solution to align representations while correcting for prior shifts using unlabeled target data.","['Can the authors provide a clearer explanation of the methodology and experimental setup?', 'How does IWDA directly compare to similar methods, and what specific advantages does it offer?']","['The paper does not adequately address potential limitations of the proposed approach, including scenarios where prior shifts are less significant.', 'The clarity of the presentation is a significant limitation, hindering understanding and reproducibility.']",False,3,2,3,6,4,"['The paper tackles an important and relevant problem in cross-lingual transfer learning, specifically addressing class prior shifts that are often overlooked.', 'The proposed method, IWDA, appears to be a novel approach that combines representation alignment with prior shift correction.', 'The experiments show promising results, indicating that IWDA can outperform existing methods under conditions of prior shift, particularly in the sentiment analysis and named-entity recognition tasks.']","['Methodological concerns: The experimental setup is not thoroughly explained, raising concerns about reproducibility and the completeness of the evaluation.', 'Clarity issues: The presentation of the paper could be clearer; some sections, particularly the methodology and experimental setup, are dense and may confuse readers not already familiar with the topic.', 'Comparative analysis: There is a lack of clarity on how IWDA compares to existing methods and what specific advantages it offers, which raises questions about its originality.']",3,3,2,4,Reject
SVwbKmEg7M,"The paper presents a novel approach to unsupervised neural machine translation leveraging generative pre-trained language models like GPT-3. The method includes few-shot amplification, distillation, and iterative backtranslation, achieving state-of-the-art performance on the WMT14 English-French benchmark with a BLEU score of 42.1. The study shows how generative pre-trained models can be effectively utilized to generate synthetic translations without the need for traditional encoder-decoder architectures.","[""Can the authors provide more details on the distillation process and how it impacts the final model's performance?"", 'What steps can be taken to improve the accessibility of the proposed methodology for researchers with limited resources?', 'Could the authors elaborate on the potential limitations of their method in terms of overfitting and its generalizability to other language pairs?']","['The paper does not sufficiently address the limitations and potential biases of using large generative models in translation tasks.', 'The methodology may not be easily reproducible due to the dependence on large-scale models.']",False,3,3,3,7,4,"[""The approach effectively leverages GPT-3's zero-shot translation capabilities to produce high-quality translations."", 'The methodology of few-shot amplification, distillation, and backtranslation is innovative and aligns with recent trends in leveraging large language models.', 'The results demonstrate a new state-of-the-art performance on the WMT14 English-French benchmark, showcasing the effectiveness of the proposed approach.']","['The reliance on large models like GPT-3 raises concerns about the accessibility and applicability of the method in resource-constrained environments.', 'The paper could benefit from a more detailed exploration of the limitations of the proposed method, particularly in terms of overfitting and generalizability to other languages or domains.', 'Some sections could be clearer, particularly regarding the specifics of the distillation and backtranslation processes, which could make it difficult for others to replicate the results.']",3,3,3,4,Reject
nK7eZEURiJ4,"This paper investigates distributional reinforcement learning (RL) from theoretical and algorithmic perspectives, proposing a Sinkhorn distributional RL algorithm. It connects distributional RL to maximum likelihood estimation and presents experimental results on Atari games. However, the theoretical contributions are often unclear, and the experimental validation lacks depth.","['Could the authors clarify the main contributions and how they differ from existing work?', 'What limitations do the authors foresee in applying Sinkhorn loss in distributional RL?', 'Can the authors clarify the connections between different sections, particularly the implications of theoretical results?', 'What specific experimental protocols were followed to ensure reproducibility?']","['The paper does not adequately address the clarity of its theoretical contributions.', 'Experimental results need to provide more insight into the performance of the proposed method compared to existing techniques.', ""Lack of clarity in theoretical exposition may hinder the paper's impact."", 'Insufficient detail in experiments raises questions about reproducibility.']",False,3,2,3,5,4,"['Addresses an important topic in reinforcement learning, discussing the theoretical aspects of distributional RL.', 'Introduces a novel connection between Wasserstein distance and maximum mean discrepancy (MMD) through the proposed Sinkhorn distributional RL algorithm.', 'Experimental results demonstrate competitive performance on several Atari games, indicating practical applicability.']","['Theoretical arguments are convoluted and lack clarity, making it difficult to follow the contributions.', ""Insufficient demonstration of the proposed algorithm's superiority over existing state-of-the-art methods."", 'Limited discussion on the implications of using Sinkhorn loss in distributional RL.', 'The organization of the paper could be improved for better flow and cohesion.', 'Experimental details are insufficiently described, raising concerns about reproducibility.']",3,3,2,3,Reject
SvFQBlffMB,"The paper proposes Pseudo-Knowledge Distillation (Pseudo-KD), a method that enhances instance-specific label smoothing by introducing a two-stage optimization process. It aims to bridge the gap between knowledge distillation and label smoothing, demonstrating competitive performance on image classification and natural language understanding tasks.","['Can the authors clarify the theoretical advantages of their method over existing techniques?', 'Could the authors provide more detailed results from ablation studies to justify the effectiveness of their method?', 'How does the choice of hyperparameters affect the performance in practice?']","['The clarity of the mathematical background and derivations needs improvement for better understanding.', 'The comparisons with previous methods could be expanded to include more contextual reasoning for their choices.', 'The theoretical justifications require more depth to strengthen the foundation of the proposed approach.']",False,3,3,3,5,4,"['The proposed method fills a gap between knowledge distillation and label smoothing, offering a new perspective on instance-specific label regularization.', 'The experiments are extensive, showcasing results on multiple datasets and neural architectures, demonstrating the robustness of the method.', 'The method promises computational efficiency by not requiring a pre-trained teacher model.']","['The presentation lacks clarity, particularly in the mathematical formulations and the two-stage optimization process.', 'The originality of the method is questionable, as it does not clearly differentiate itself from existing techniques.', 'The experimental evaluation could benefit from deeper analyses and broader comparisons with state-of-the-art methods.']",3,3,4,4,Reject
uVXEKeqJbNa,"The paper proposes a stiffness-aware neural network (SANN) for learning Hamiltonian dynamical systems from data, introducing a stiffness-aware index (SAI) to classify training data into stiff and nonstiff portions. This classification enhances stability and energy preservation in simulations. Evaluations on complex physical systems like the three-body problem and billiard model demonstrate significant improvements over existing methods.","['Can the authors provide a more thorough theoretical analysis of the stiffness-aware index (SAI) and its advantages over traditional metrics?', ""What are the implications of choosing different stiffness ratios on the model's performance, and how might this affect practical applications?"", 'Could the authors clarify the process of classifying intervals as stiff or nonstiff and the criteria used for this classification?']","['The theoretical aspects of SAI need to be better articulated to understand its effectiveness fully.', 'The paper could benefit from more diverse experimental comparisons to validate the robustness of SANN.']",False,3,3,3,5,4,"['The introduction of the stiffness-aware index (SAI) is a novel contribution that addresses a critical challenge in learning Hamiltonian systems.', 'The experimental results indicate that SANN outperforms state-of-the-art methods in terms of stability and energy conservation.', 'The paper is well-structured, providing a solid foundation for understanding the proposed approach.']","['The paper lacks a thorough theoretical foundation for the stiffness-aware index (SAI) and its implications on model performance.', 'Clarity issues arise in sections discussing the SAI calculation and its implications, making it difficult for readers unfamiliar with the topic to fully grasp the contributions.', 'Some experimental evaluations could be more extensive, particularly in comparison with a broader range of existing techniques.']",3,3,3,4,Reject
sTNHCrIKDQc,"The paper proposes graphon-based methods for clustering and testing network-valued data without vertex correspondence. It introduces a novel graph distance and presents two clustering algorithms, providing theoretical guarantees for their consistency and demonstrating their effectiveness through empirical evaluations.","['How do the authors justify the choice of graphon-based methods over existing techniques in practical applications?', 'Can the authors provide more comprehensive experimental results demonstrating the advantages of their approach in diverse scenarios?']","['The paper does not sufficiently address the limitations of the proposed methods, particularly regarding the assumptions made about graphon smoothness.', 'The clarity of the theoretical analysis could be improved to facilitate understanding and reproducibility.']",False,3,3,3,5,4,"['Addresses a significant problem in clustering network-valued data without vertex correspondence.', 'Introduces a novel graph distance based on graphons, which is theoretically justified.', 'Includes empirical evaluations that demonstrate the effectiveness of the proposed algorithms.']","['The originality of the work is questionable, as it builds on existing graph distance approaches without sufficiently distinguishing itself.', 'The empirical results are limited and do not demonstrate the advantages of the proposed methods across a broader range of datasets.', 'The clarity of the presentation could be improved, particularly in explaining the theoretical developments and experimental setups.']",3,3,3,4,Reject
yztpblfGkZ-,"The paper proposes BankGCN, a novel graph convolution operator that utilizes an adaptive filter bank to capture diverse spectral characteristics of graph data. It addresses limitations in existing message passing graph convolutional networks (MPGCNs) and spectral methods by allowing for a more flexible representation of heterogeneous signals. Extensive experiments show that BankGCN performs well on benchmark datasets.","['Can the authors clarify the reasoning behind the choice of specific filters in the filter bank?', 'How do the performance metrics compare with a broader range of existing methods besides the chosen few?', 'Can the authors provide additional details on the regularization strategy and its impact on performance?']","[""The paper's clarity issues hinder understanding and may limit its impact on the community. More straightforward explanations are needed."", 'The experimental results, while promising, lack comprehensive statistical validation and could benefit from additional datasets and baseline comparisons.']",False,3,2,3,4,4,"['The introduction of the adaptive filter bank is a novel contribution that attempts to improve existing GCNs by capturing a wider range of spectral characteristics.', 'The paper reports results across several benchmark datasets, demonstrating the potential effectiveness of the proposed method.', 'The approach addresses the limitations of low-pass filtering in existing MPGCNs and offers a more compact architecture.']","['The paper lacks clarity in several sections, making it difficult for readers to follow the proposed methodology and its significance.', 'While experiments are conducted, the comparisons with baseline methods could be more thorough, and more statistical analysis could enhance the robustness of the results.', 'Some explanations, particularly regarding the mathematical formulations and the implications of the results, are convoluted and could benefit from simplification.']",3,3,2,3,Reject
FqKolXKrQGA,The paper proposes a novel transformer-like architecture for inferring the structure of network games from observed equilibrium actions without explicit knowledge of utility functions. It aims to address significant limitations in existing methods and demonstrates effectiveness through experiments on synthetic and real-world datasets.,"['Can the authors clarify the theoretical implications of their model?', ""What steps are taken to ensure the robustness of the model's predictions across varying game types and structures?"", 'Could more details be provided on the training process and hyperparameter tuning?']","['The paper does not sufficiently address the limitations of the proposed method and its assumptions about network structures.', ""Clarity issues may hinder the reader's understanding of the architecture and methodology.""]",False,3,2,4,6,4,"['Addresses an important problem in inferring network structures from game outcomes without prior knowledge of utility functions.', 'The transformer-like architecture is innovative and suitable for the problem at hand.', 'Empirical results indicate potential applicability and effectiveness on various datasets.']","['The presentation lacks clarity, particularly in explaining the proposed methodology and its theoretical underpinnings.', 'Insufficient comparisons with existing methods to validate claims of superiority.', ""Some experimental results lack relevance or do not clearly demonstrate the model's advantages.""]",4,3,3,4,Reject
34mWBCWMxh9,"The paper proposes a method called spatial smoothing to enhance the performance of Bayesian Neural Networks (BNNs) by adding blur layers to ensemble neighboring feature maps. The authors claim improvements in accuracy, uncertainty estimation, and robustness while reducing computational costs. However, the experimental validation is limited, and the presentation lacks clarity in some parts.","['How does spatial smoothing compare to existing smoothing techniques in terms of unique advantages?', 'Can the authors provide a more detailed theoretical justification for the improvements claimed?', 'What limitations or potential negative implications could arise from using spatial smoothing in practice?']","['The contributions may not be as novel given existing literature on smoothing techniques.', 'Clarity in theoretical explanations and empirical validations needs improvement.']",False,2,2,2,4,4,"['The concept of spatial smoothing is innovative and addresses significant challenges in improving BNN performance.', 'Empirical results demonstrate improvements in accuracy and uncertainty estimation for both BNNs and deterministic neural networks.', 'The method is straightforward to implement and does not require additional training parameters.']","['The originality of the approach is questionable, as similar smoothing techniques have been discussed in existing literature.', ""The paper's clarity is hindered by technical jargon and a lack of clear examples."", 'The theoretical justification for the claimed improvements is underdeveloped and lacks rigorous support.', 'Experimental validation is limited, with insufficient comparisons to other existing methods or baselines.']",3,2,2,3,Reject
ZaVVVlcdaN,"The paper proposes FedChain, a novel framework for federated learning that combines local and global update methods to optimize communication costs and improve convergence rates. The authors provide theoretical guarantees for their approach, demonstrating near-optimal convergence rates for convex and nonconvex objectives, supported by empirical results. However, the presentation of algorithms and assumptions could be clearer.","['Can the authors clarify the practical implications of their theoretical findings?', 'What measures have been taken to ensure that the empirical results are robust across varying levels of client heterogeneity?']","['The paper does not sufficiently elaborate on the experimental setup, making it hard to evaluate the results.', 'Lacks sufficient discussion on the limitations of the proposed approach and its applicability in real-world federated learning scenarios.']",False,3,2,3,6,4,"['Addresses important challenges in federated learning, specifically communication efficiency and data heterogeneity.', 'Proposes a theoretically sound framework with clear mathematical formulations.', 'Demonstrates promising theoretical improvements over existing methods for certain convergence rates.']","['Clarity is compromised by dense mathematical notation and jargon, making it difficult for readers to grasp the key ideas.', 'Experimental validation is limited, lacking comprehensive comparisons with state-of-the-art methods across diverse datasets.', 'The originality is moderate as the concept of combining local and global updates has been explored in prior works.']",3,3,2,4,Reject
YJ1WzgMVsMt,"The paper introduces the LOGO algorithm, which addresses the challenge of sparse rewards in reinforcement learning by utilizing offline demonstration data from a sub-optimal behavior policy. The method combines policy improvement with guidance from offline data, aiming for faster and more efficient learning. The authors provide theoretical guarantees and demonstrate the algorithm's effectiveness on benchmark environments and a mobile robot application.","['Can the authors provide more details on the experimental setups, especially regarding comparisons with other state-of-the-art methods?', 'Could the authors clarify the assumptions made about the behavior policy and their implications for the generalization of LOGO?', 'Can the authors provide further empirical results in diverse environments to validate the robustness of LOGO?']","[""The clarity of the algorithm's description could be improved for better understanding."", 'The experimental validation lacks depth and breadth in comparison to existing methods, making it challenging to evaluate the significance of the results.', 'The paper does not adequately address potential limitations and scenarios where the method might fail, particularly concerning reliance on offline data.']",False,3,2,3,6,4,"['The approach addresses a significant issue in reinforcement learning, making it timely and relevant.', 'The theoretical analysis provides valuable insights into the performance guarantees of the LOGO algorithm.', ""Experimental results demonstrate the algorithm's effectiveness across various benchmark environments and in a real-world application.""]","['Some algorithmic descriptions lack clarity, particularly regarding the integration of trust region policy optimization (TRPO) with offline data guidance.', 'The experiments do not sufficiently compare LOGO against a wide range of existing methods, limiting the impact of the findings.', ""Assumptions about the behavior policy may not hold universally, potentially affecting the algorithm's applicability.""]",3,3,2,4,Reject
kG0AtPi6JI1,"This paper introduces latent domain learning, a novel approach for visual representation learning that operates without domain labels, contrasting with traditional multi-domain learning. The authors propose a sparse latent adaptation strategy to enhance performance when dealing with latent domains. While the concept is relevant and timely, the paper suffers from clarity issues and lacks depth in experimental validation.","['Can the authors clarify how latent domain learning fundamentally differs from existing domain adaptation methods?', 'What specific experiments can be conducted to better demonstrate the effectiveness of the proposed sparse adaptation technique?', 'Could the authors provide more details on how fairness and long-tailed recognition are integrated into their framework?']","['The lack of extensive experimental validation raises concerns about the robustness of the findings.', 'The paper could benefit from a clearer explanation of the proposed methods and their implications.']",False,2,2,3,5,4,"['The concept of latent domain learning addresses practical challenges in dataset curation and model generalization.', 'The proposed sparse latent adaptation method is an interesting contribution that aims to improve learning without domain labels.', 'The paper provides a relevant discussion of related work, establishing context for the proposed approach.']","['The paper lacks clarity in explaining the proposed method and how it fundamentally differs from existing approaches in domain adaptation.', 'Experimental results are limited, and more extensive testing against a wider array of baseline methods is needed to validate claims of superiority.', 'The connection between the proposed method and applications in fairness or long-tailed recognition is mentioned but not thoroughly explored.']",3,2,2,4,Reject
o9DnX55PEAo,"The paper proposes a method for cross-architecture distillation of large pretrained language models into a more efficient architecture called CMOW, which incorporates bidirectional representations and a two-sequence encoding scheme. The authors claim that their model achieves comparable performance to DistilBERT while using fewer parameters and providing faster inference speeds.","['Can the authors elaborate on the development of the two-sequence encoding scheme and its advantages over previous methods?', 'What specific metrics were used to evaluate the improvements provided by the bidirectional component?', 'How does the proposed model compare to other recent distillation methods beyond GLUE?']","['Insufficiently addresses the limitations and robustness of findings across diverse tasks.', 'Needs a more thorough examination of the trade-offs between model size and performance on various tasks.']",False,3,2,3,5,4,"['Addresses the critical issue of model efficiency in NLP, relevant given the trend towards larger pretrained models.', 'Introduces a novel hybrid architecture with bidirectional capabilities and a two-sequence encoding scheme.', 'Demonstrates competitive performance on various GLUE tasks compared to existing models.']","['Lacks clarity in explaining the novel contributions of the CMOW architecture and its comparison to existing architectures.', 'Experimental evaluation is narrow, focusing predominantly on GLUE tasks without broader dataset exploration.', 'Insufficient analysis of potential limitations and failure cases of the proposed approach.', 'Methodology section could benefit from clearer explanations, particularly regarding the two-sequence encoding and distillation process.']",3,3,2,3,Reject
68n2s9ZJWF8,"The paper introduces Implicit Q-Learning (IQL), a novel offline reinforcement learning method that avoids querying unseen actions during training to improve policy performance. It leverages expectile regression for policy evaluation without requiring explicit constraints, demonstrating state-of-the-art results on D4RL benchmarks, particularly in complex tasks like Ant Maze.","['What theoretical guarantees can the authors provide to support the effectiveness of their method?', 'Can the authors elaborate on the implications of using expectile regression compared to traditional methods?']","['The theoretical foundations of the proposed method may not be sufficiently robust, and more empirical comparisons are needed to validate its effectiveness against a wider array of baselines.', 'The paper could benefit from clearer explanations of key concepts and the proposed method, as the current presentation may alienate readers unfamiliar with the topic.']",False,3,2,3,5,4,"['Effectively addresses a significant challenge in offline reinforcement learning by eliminating the need to evaluate unseen actions.', 'Demonstrates strong performance on D4RL benchmarks, especially on challenging tasks, indicating the effectiveness of the proposed approach.', 'The method is computationally efficient and straightforward to implement, requiring only minor modifications to standard SARSA-style updates.']","['The originality of the approach is somewhat limited as it builds on established concepts like expectile regression without introducing substantial new ideas.', 'Lacks rigorous theoretical analysis to support claims of optimality and performance under various conditions.', 'The presentation is dense and may hinder understanding, making it difficult for readers to grasp the key contributions.']",3,2,3,4,Reject
z7DAilcTx7,"The paper introduces a novel framework for adversarial training framed within distributional robustness optimization using the ∞-Wasserstein distance. It connects adversarial training to optimal transport theory and proposes the use of Langevin Monte Carlo sampling to derive optimal distributions of adversarial examples, claiming a significant speed-up and improved robustness over baseline methods.","['Could you clarify the advantages of the Langevin sampling method over previous sampling techniques in terms of both speed and effectiveness?', 'Can you provide a more detailed explanation of the choice of parameters used during training and their impact on performance?']",['The paper does not extensively evaluate how the proposed method performs against diverse adversarial attacks beyond those benchmarked.'],False,3,2,3,5,4,"['Theoretical framework connects adversarial training with optimal transport and distributional robustness, providing a fresh perspective.', 'Significant claims of speed-up in training time and robustness against adversarial attacks, particularly on standard datasets like MNIST and CIFAR-10.', 'Comprehensive references to existing works and a clear lineage of thought leading to the proposed method.']","['The paper is densely written and may be difficult to follow for readers not well-versed in optimal transport or distributional robustness.', 'The experimental results, while promising, lack sufficient comparison against a wider range of existing approaches beyond just PGD.', 'Clarity regarding the implementation details of the Langevin Monte Carlo method and its integration with adversarial training could be improved.']",3,3,2,4,Reject
EcGGFkNTxdJ,"The paper proposes Heterogeneous-Agent Trust Region Policy Optimisation (HATPRO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO) as novel algorithms for multi-agent reinforcement learning (MARL). These methods extend trust region approaches to accommodate heterogeneous agents without requiring parameter sharing, ensuring monotonic improvement in policy performance. The authors provide theoretical guarantees and demonstrate the effectiveness of their methods through empirical evaluations on various benchmarks, achieving state-of-the-art results compared to existing algorithms.","['Can the authors clarify how their algorithms compare to non-parameter sharing variants of existing methods in terms of convergence speed?', 'What specific hyperparameter settings were tuned, and how sensitive are the algorithms to these settings?', 'Could the authors discuss the implications of their work in terms of potential ethical concerns in multi-agent systems?']","['The paper could do a better job addressing the practical limitations and assumptions inherent in their approach, particularly regarding the scalability of the algorithms in larger environments.']",False,3,3,4,7,4,"['Theoretical foundations are well-articulated, providing clear guarantees for policy improvement.', 'The algorithms allow for heterogeneity in agent parameters, which is crucial for real-world applications.', 'Extensive empirical validation demonstrates the effectiveness of the proposed methods across multiple environments.']","['Clarity of the presentation could be improved; some theoretical concepts are complex and may confuse readers.', 'The experimental results could benefit from more detailed breakdowns, especially regarding hyperparameter sensitivity and robustness across varied settings.', 'The paper could provide a deeper analysis of the limitations and potential ethical implications of deploying these algorithms in practical multi-agent systems.']",4,3,3,4,Accept
3pZTPQjeQDR,"The paper investigates how the size of the subword vocabulary learned by Byte-Pair Encoding (BPE) affects the memorization behavior of Transformer models, demonstrating that larger vocabularies facilitate memorization and increase vulnerability to membership inference attacks. The study includes various experiments to explore these effects, with implications for both practical applications and ethical considerations.","['Can the authors clarify certain sections that are difficult to understand?', 'What are the practical implications of the findings in terms of model training and deployment?', 'Can the authors provide a more diverse set of datasets for their experiments to validate their claims?']","[""The paper could benefit from clearer writing and better organization to enhance the reader's understanding."", ""The study's limited focus on a single dataset raises concerns about the generalizability of the findings."", 'The authors should address the potential overfitting of their models to the training data, which may skew results.']",True,3,2,3,5,4,"['Addresses a relevant and timely issue of memorization in NLP models.', 'Provides a comprehensive set of experiments across different tasks to investigate the effects of BPE vocabulary size.', 'Offers insights into the relationship between memorization and generalization, which is an important aspect in NLP.']","['The writing lacks clarity in some sections, making it difficult to follow the argumentation.', 'The novelty of the findings could be questioned, as they build on existing literature without introducing substantially new concepts.', 'The implications of the findings could be discussed more thoroughly, particularly in relation to practical applications.', 'The paper does not adequately address potential confounding factors in the experimental design that could influence the results.']",2,3,2,3,Reject
AJO2mBSTOHl,"The paper presents TAGI, a method for Bayesian deep reinforcement learning that allows for tractable analytical inference in deep Q-learning without relying on gradient descent. The authors argue that it can achieve comparable performance to traditional DQNs while using fewer hyperparameters, particularly in complex environments like Atari games.","['Can the authors clarify the computational efficiency of TAGI in practical terms compared to gradient-based methods?', 'How does TAGI perform in more complex reinforcement learning architectures beyond the Atari benchmarks?']",['The paper does not sufficiently discuss the limitations and potential drawbacks of using TAGI in comparison to traditional methods.'],False,2,2,3,4,3,"['Interesting approach that combines Bayesian inference with deep reinforcement learning.', 'Provides a new perspective on uncertainty estimation in Q-learning.', 'Demonstrates potential for less hyperparameter tuning, which is a significant challenge in deep RL.']","['Lacks clarity in the presentation of the TAGI method, making it difficult to understand its full implications, especially in relation to existing methods.', 'Experimental results do not provide a comprehensive comparison with existing state-of-the-art methods, particularly in terms of performance metrics and benchmarks across multiple Atari games.', 'Does not adequately address the computational efficiency and scalability of the proposed method in practical applications, which is crucial for real-world deployment.']",3,2,2,3,Reject
YevsQ05DEN7,The paper investigates dimensional collapse in contrastive self-supervised learning and proposes a new method called DirectCLR that directly optimizes the representation space without a trainable projector. The authors claim that DirectCLR outperforms existing contrastive methods like SimCLR on ImageNet.,"['Can the authors provide more detailed ablation studies to substantiate their claims regarding DirectCLR?', 'What specific changes in dimensionality or representation are observed in DirectCLR compared to traditional methods?']","['The clarity of theoretical explanations could be improved.', 'Limited empirical validation raises questions about the robustness of the claims.']",False,3,2,3,5,4,"['Addresses the important issue of dimensional collapse in self-supervised learning.', 'Proposes DirectCLR, a method designed to optimize representation space directly.', 'Presents empirical results suggesting improvements over existing contrastive learning methods.']","['Theoretical explanations are dense and may be difficult for readers to follow.', 'Empirical evaluations lack thorough ablation studies to support claims about the efficacy of DirectCLR.', 'Originality is somewhat limited, as the method builds on existing contrastive learning frameworks without introducing fundamentally new ideas.', 'Presentation quality is compromised due to excessive mathematical notation and lack of clear visualizations.']",2,3,2,3,Reject
6Q52pZ-Th7N,"The paper introduces Pseudo-Labeled Auto-Curriculum Learning (PLACL), a method for semi-supervised keypoint localization that dynamically selects reliable pseudo-labels using reinforcement learning. The authors claim that this method improves performance across various benchmark datasets, addressing issues like confirmation bias in pseudo-labeling.","['Could the authors provide clearer explanations of the key components of PLACL?', 'How does PLACL compare with existing curriculum learning methods in more detail?', 'What specific challenges did you face during the application of the cross-training strategy, and how did you address them?']","['The clarity of the paper needs improvement, particularly in explaining the algorithm and its components.', 'More comprehensive comparisons with other state-of-the-art methods in curriculum learning would strengthen the paper.', 'A more thorough discussion on the limitations of the PLACL approach, particularly in terms of its scalability and computational demands, is needed.']",False,3,2,3,6,4,"['The approach addresses the key problem of confirmation bias in pseudo-labeling, which is significant in semi-supervised learning.', 'The use of reinforcement learning to automate curriculum design is a novel contribution that could be valuable for the community.', 'Extensive experiments across multiple datasets demonstrate the robustness and applicability of the method.']","['The paper lacks clarity in explaining the proposed method; some sections are overly technical and may confuse readers.', 'The novelty of the approach is diminished by insufficient comparison with existing curriculum learning methods, leaving questions about its relative effectiveness.', 'The ablation studies could be more detailed to better elucidate the impact of each component of the proposed method.']",3,3,2,4,Reject
XJFGyJEBLuz,"The paper introduces Born Again Neural Rankers (BAR) for improving performance in Learning to Rank (LTR) tasks by applying knowledge distillation techniques. It proposes a novel teacher score transformation and a listwise distillation framework, claiming significant performance improvements over existing models without increasing model capacity. The authors provide theoretical explanations and empirical results to support their claims.","['Can you provide more details about the impact of the teacher score transformation on model performance?', 'What are the theoretical implications of using listwise vs. pointwise distillation in your experiments?', 'Could you elaborate on the robustness of your findings across different datasets in terms of generalizability?']","['The lack of clarity in explaining the design decisions and their implications undermines the overall contribution of the paper.', 'The empirical results need to be contextualized better within the existing literature on knowledge distillation for ranking.', 'The paper does not adequately address the limitations of their proposed approach or consider potential negative impacts.']",False,3,3,3,6,4,"['The introduction of BAR specifically tailored for ranking problems is a novel contribution to the knowledge distillation literature.', 'The paper demonstrates significant empirical results, showing improvements in ranking performance on multiple datasets compared to state-of-the-art methods.', 'The theoretical insights provided for the effectiveness of listwise distillation are valuable and contribute to understanding the design choices.']","['The paper lacks clarity in certain sections, particularly regarding the reasoning behind the teacher score transformation and its implications.', 'The empirical evaluation, while showing improvements, raises questions about the reproducibility and generalizability of the results across different LTR datasets.', 'There is insufficient exploration of ablation studies and comparisons with a wider range of existing methods.']",3,3,3,4,Reject
u7UxOTefG2,"The paper critically examines the use of Bayesian Neural Networks (BNNs) for out-of-distribution (OOD) detection, challenging the assumption that their epistemic uncertainty is inherently suited for this task. It discusses how function space priors induced by neural networks can lead to poor predictive uncertainties in OOD contexts, and emphasizes the importance of architectural choices. The authors argue that a trade-off exists between generalization and OOD detection capabilities in BNNs.","['Can the authors clarify the practical implications of their theoretical findings?', 'What specific architectural choices do the authors recommend for enhancing OOD detection in practice?']",['The paper would benefit from a clearer presentation of its arguments and findings to make the complex concepts more accessible to a broader audience.'],False,3,2,3,5,4,"['The paper addresses an important issue in the machine learning community regarding OOD detection and the assumptions about Bayesian methods.', 'It provides a clear theoretical framework by connecting BNNs with Gaussian processes, highlighting the implications of architectural choices on OOD behavior.', 'The exploration of trade-offs between generalization and OOD capabilities is a significant contribution to the understanding of BNNs.']","['Certain sections lack clarity, making it challenging for readers to fully grasp the key arguments without additional effort.', 'The practical implications of the findings are not sufficiently explored, leaving questions about how to implement these insights in real-world applications.', 'The organization of the paper could be improved to better guide the reader through the complex arguments presented.']",3,3,2,4,Reject
30nbp1eV0dJ,"The paper investigates tight lower bounds for differentially private empirical risk minimization (ERM) for general convex functions, introducing a novel biased mean property for fingerprinting codes. It aims to close existing gaps in the literature regarding differential privacy limits, providing theoretical insights applicable to both constrained and unconstrained cases.","['Can the authors clarify the novelty of their techniques compared to existing works?', 'What empirical evidence supports the claims made regarding the effectiveness of the bounds?', 'Can the authors provide more intuitive explanations or examples to clarify the implications of their findings?']","['The clarity of the paper needs improvement.', 'Results require more rigorous proofs to ensure the claimed tightness of bounds.', 'The paper could benefit from a discussion on practical implications of the theoretical findings.']",False,3,3,3,6,4,"['Addresses significant gaps in the understanding of lower bounds for differentially private ERM.', 'Introduces innovative techniques, including biased mean properties, to derive tight lower bounds.', 'The topic is highly relevant and significant in the context of privacy-preserving machine learning.']","['The clarity of the presentation could be improved, as some arguments and techniques may be difficult to follow.', 'The results, while theoretically interesting, lack sufficient empirical validation to assess their practical significance.', 'The paper primarily focuses on theoretical bounds without sufficiently addressing how these findings could influence practical implementations.']",3,3,3,4,Reject
AJAR-JgNw__,"The paper introduces DEPTS, a deep learning framework for periodic time series forecasting, focusing on modeling complex dependencies and diverse periodicities. It features an expansion module and a periodicity module, claiming significant improvements over existing methods. The experiments on synthetic and real-world datasets show promising results, but the clarity of the writing and the originality of the framework raise concerns.","['What are the specific novel contributions of DEPTS compared to existing methods?', 'Can the authors simplify their explanations, particularly regarding the model architecture and the loss functions used?', 'How do the periodicity coefficients derived from the model relate to practical periodic characteristics in the time series?']","['The paper does not adequately address the limitations of the proposed approach or discuss potential negative societal impacts.', 'The experiments could be strengthened by including a broader range of baseline methods for comparison.']",False,3,2,2,4,4,"['Addresses the important problem of periodic time series forecasting, which is relevant in many industries.', 'Introduces a structured approach to model complicated periodic dependencies.', 'Extensive experiments on synthetic and real-world datasets demonstrate improvements over existing methods.']","['The originality of the work is questionable; it appears to follow existing concepts without significant innovation.', 'The clarity of the writing is poor in many sections, hindering understanding of the proposed methods.', 'The comparative analysis with a wide range of baselines is lacking, making it hard to assess the actual improvements.']",3,3,2,3,Reject
Uxppuphg5ZL,"The paper introduces a constraint-based framework for learned physical simulation using Graph Neural Networks (GNNs) to model constraints and solve for future states. This method demonstrates competitive performance against existing learned simulators across various physical scenarios, including simulated ropes and bouncing balls, and showcases unique capabilities for generalization and the incorporation of hand-designed constraints at test time.","['Can the authors clarify the implementation of the GNN as a constraint function?', 'What specific hyperparameters were used for the various models, and how were they selected?', 'How do the authors envision extending this work for more complex physical simulations?']","['The clarity of the paper could be improved, particularly in explaining the methodology and experimental setup.', 'The discussion on limitations and future work is lacking, which is important for guiding future research.']",False,3,2,3,6,4,"['The approach presents a novel method for learning physical simulations through constraints, marking a significant contribution to the field.', 'Utilizing GNNs allows for flexibility in modeling complex physical systems with rich compositional structures.', 'Experimental results indicate that the proposed framework achieves competitive or superior performance compared to state-of-the-art methods.', ""The ability to incorporate hand-designed constraints at test time enhances the model's applicability.""]","['The paper lacks clarity in explaining the constraint satisfaction process and the implementation of the GNN as a constraint function.', 'Some experimental details and hyperparameter choices are insufficiently explained, making reproduction of results challenging.', 'While results are promising, the paper does not adequately discuss the limitations of the approach or potential future work.', 'Figures and tables could be clearer in presenting key results and comparisons.']",3,3,3,4,Reject
3PN4iyXBeF,"The paper proposes Amortized Implicit Gradient Optimization (AmIGO), a novel algorithm for bilevel optimization problems that utilizes amortized implicit differentiation and a warm-start strategy. It presents a theoretical framework for analyzing convergence and claims to match the complexity of oracle methods. Empirical results are provided on synthetic tasks and hyper-parameter optimization.","['Can the authors clarify the assumptions made regarding the convexity of the functions involved?', ""Could additional experiments be provided to demonstrate the algorithm's performance across a wider range of tasks?""]","['The assumptions about the smoothness and convexity of the functions may limit the applicability of the results.', 'The clarity of the presentation could lead to misunderstandings about the contributions and the validity of the claims.']",False,3,2,3,5,4,"['Introduces a novel approach to bilevel optimization using amortized implicit differentiation.', 'The theoretical framework for analyzing convergence is a significant contribution.', 'Empirical results demonstrate the potential effectiveness of the AmIGO algorithm.']","['The clarity of the presentation is lacking, particularly in the theoretical analysis and proofs, making it difficult to follow the arguments.', 'Experimental validation is limited, focusing primarily on synthetic tasks without exploring a wider range of applications.', 'Some assumptions in the theoretical analysis may not hold universally, raising concerns about the robustness of the claims.']",3,3,2,4,Reject
Ih7LAeOYIb0,"The paper proposes an Iterative Memory Network (IMN) for long sequential user behavior modeling in recommender systems. It aims to overcome the limitations of RNNs and attention mechanisms by efficiently capturing both intra-sequence and target-sequence dependencies, claiming significant improvements in Click-Through Rate (CTR) in both public and industrial datasets.","['Could the authors provide more detailed justification for the iterative memory update mechanism?', 'What specific theoretical backing supports the O(L) claim in contrast to traditional attention mechanisms?', 'Can the authors clarify how the various components of the IMN interact and the advantages of the proposed architecture over existing methods?']","[""The clarity of the model's workings and implications of the iterative memory update process need to be better articulated."", ""The potential for overfitting due to multiple iterations and the model's complexity hasn't been adequately discussed."", 'The paper does not sufficiently address potential biases in the datasets used for evaluation, impacting generalizability.']",False,2,2,3,4,4,"['The IMN architecture effectively addresses significant challenges in sequential modeling, particularly for long sequences, by combining target-sequence and intra-sequence dependency modeling.', 'Empirical results demonstrate substantial improvements in CTR in a real-world industrial application, indicating practical relevance and applicability.', 'The framework claims to reduce computational complexity while effectively modeling dependencies, which is a notable advancement in the field.']","['The paper lacks clarity in explaining the iterative memory update process, which may confuse readers unfamiliar with the methodology.', ""Details regarding the memory update mechanism and its integration into the model are insufficiently explained, making it difficult to fully grasp the model's operation."", 'Experimental results focus primarily on AUC metrics; more diverse evaluations and comparisons with additional baseline models would strengthen the findings.']",3,2,2,4,Reject
7Bc2U-dLJ6N,"The paper proposes SGEM, a novel optimization algorithm that integrates energy and momentum to solve non-convex stochastic optimization problems. It claims to improve performance over existing methods like AEGD and SGDM in terms of convergence speed and generalization. The method is theoretically analyzed and experimentally validated on deep learning benchmarks.","['How does SGEM perform in scenarios where existing methods excel? What specific advantages does it offer in those cases?', 'Can the authors simplify the theoretical exposition to make it more accessible?']","['The clarity of the paper and the depth of experimental analysis are significant concerns that need to be addressed.', 'The paper does not sufficiently differentiate SGEM from existing methods in terms of innovation.']",False,3,3,3,6,4,"['The integration of energy and momentum is a novel approach in optimization, potentially enhancing convergence properties.', 'The paper provides a comprehensive theoretical analysis, including unconditional energy stability and convergence rates.', 'Experimental results demonstrate that SGEM performs well on standard benchmarks, indicating practical applicability.']","['The exposition is complex and may hinder understanding of the core contributions.', 'The originality is somewhat questionable as SGEM builds on existing methods without significant differentiation.', 'The experimental results could benefit from deeper analysis; the paper does not clearly explain under what conditions SGEM outperforms its peers.']",3,3,3,4,Reject
rTAclwH46Tb,"The paper introduces Eigencurve, a novel learning rate schedule for SGD that achieves minimax optimal convergence rates for quadratic objectives with skewed Hessian spectra. The authors provide theoretical analysis and empirical results demonstrating that Eigencurve outperforms existing methods, especially in cases with fewer epochs. They also derive two practical schedulers inspired by their theoretical findings.","['Can the authors clarify how the learning rate schedules can be computed in practice without heavy computational burden?', 'Could the authors provide more detail on the experimental setups to ensure reproducibility?', 'Can the authors provide additional experiments comparing Eigencurve with a wider variety of learning rate schedules?', ""How do the authors address potential limitations of their assumptions regarding the Hessian's eigenvalue distribution in practical applications?""]","['The reliance on specific assumptions about eigenvalue distributions may limit the applicability of the proposed method in real-world scenarios.', 'The clarity of the theoretical analysis could be improved to enhance understanding and reproducibility.', ""The paper does not fully address the potential computational burden of estimating the Hessian's eigenvalue distribution in large models.""]",False,3,2,3,6,4,"['Theoretical contributions are robust, providing a clear advancement over previous learning rate schedules.', 'Empirical results support the theoretical claims, showing significant improvements in performance on CIFAR-10.', 'The paper addresses a relevant and practical problem in machine learning, relating to the optimization of learning rates.']","['The clarity of the theoretical exposition could be improved; some sections are dense and may be difficult for readers to follow.', 'The paper could benefit from better organization, particularly in how theoretical results are presented and connected to empirical findings.', 'Some experimental settings lack sufficient detail, making reproduction challenging.', 'The reliance on the eigenvalue distribution of the Hessian matrix may limit the applicability of Eigencurve in practice, especially for larger models.']",4,3,2,4,Reject
ZumkmSpY9G4,"The paper proposes a novel generative framework for online class-incremental learning that aims to bypass the logits bias problem associated with softmax classifiers. By replacing the softmax classifier with a nearest-class-mean classifier and employing a pair-based metric learning loss, the authors claim to reduce catastrophic forgetting and improve performance over existing methods. The framework is tested on various benchmarks, demonstrating significant improvement compared to state-of-the-art replay-based methods.","['Can the authors provide a more rigorous theoretical justification for the advantages of the proposed method over traditional approaches?', 'How do the authors ensure that the generative classifier remains effective with the limited data typical in online learning?', 'What specific modifications were made to existing methods to adapt them for online settings in the experiments?']","['The paper does not sufficiently explore the limitations of the proposed method, especially in scenarios with larger class distributions.', 'Potential weaknesses in the reliance on generative models over discriminative ones need to be acknowledged.']",False,3,3,3,5,4,"['Addresses a significant problem in online continual learning: the logits bias in softmax classifiers.', 'Introduces a generative approach that is theoretically backed and empirically validated across multiple datasets.', 'Extensive experimentation with a comprehensive set of baseline comparisons, showing clear advantages in performance.']","['The clarity of the theoretical contributions, particularly in the proofs, is insufficient, making it hard to follow the reasoning behind certain claims.', 'Lacks detailed explanations of the experiments and the rationale for specific design choices.', 'The connection between the proposed method and theoretical claims could be better defined and more rigorously justified.']",3,3,3,4,Reject
MkTPtnjeYTV,"The paper investigates the memorization power of feedforward ReLU neural networks, demonstrating that such networks can memorize N points under certain conditions using O(√N) parameters. The authors present both upper and lower bounds for the number of parameters needed and claim their construction is optimal up to logarithmic factors, extending results to networks with bounded depth and bit complexity.","['Could the authors provide more intuitive explanations of their results and constructions?', 'What are the practical implications of these theoretical results for the design and training of neural networks?']","['The clarity of the paper is a major concern; clearer explanations and motivations for the technical details are needed.', 'The practical application of these theoretical results is not adequately addressed.']",False,3,2,3,4,4,"['Addresses an important theoretical question regarding the memorization capacity of neural networks.', 'Provides optimal parameter bounds for memorization that contribute to the theoretical understanding of neural networks.', 'Theoretical insights into the depth and bit complexity of networks are valuable for future research.']","['The paper lacks clarity in several sections, making it difficult for readers to follow the arguments and results.', 'The explanations of the methods and results are convoluted, with insufficient intuitive insights.', 'The practical implications of the theoretical findings are not well articulated, limiting their impact.']",3,2,2,3,Reject
hOaYDFpQk3g,"The paper presents LightWaveS, a distributed solution for multivariate time series classification (MTSC) that utilizes wavelet scattering transformation and distributed feature selection to achieve efficient and accurate classification. The framework aims to reduce the number of features significantly compared to ROCKET while maintaining competitive accuracy across various datasets. The authors claim substantial speedups during inference on edge devices compared to existing methods.","['Can the authors clarify how LightWaveS fundamentally differs from ROCKET and MINIROCKET?', 'Could the authors provide more details on the feature selection process used in the distributed framework?', 'Are there additional benchmarks that could be included to demonstrate the effectiveness of LightWaveS across different datasets?']","['The paper could benefit from clearer definitions and explanations of key concepts, particularly around wavelet scattering.', 'While speedup is demonstrated, the trade-off in accuracy should be better quantified with statistical significance.', 'The experimental results, while promising, do not encompass enough diversity in comparison methods.']",False,3,3,3,5,4,"['Addresses a relevant and practical problem in multivariate time series classification.', 'Proposes a novel approach using wavelet scattering and distributed feature selection that shows potential for efficiency improvements.', 'Demonstrates impressive speedups in inference time compared to existing methods, which is crucial for real-world applications.']","['The novelty of the method is not clearly articulated, particularly in how it fundamentally differs from existing methods like ROCKET and MINIROCKET.', 'Some sections of the paper lack clarity, especially the details on the wavelet scattering process and the feature selection mechanism.', 'The experimental setup could be more comprehensive, with comparisons to a wider range of state-of-the-art methods in the MTSC domain.', 'Some claims about performance improvements need more rigorous statistical validation.']",4,3,3,4,Reject
7MV6uLzOChW,"The paper introduces a conditional variational autoencoder (VAE) that utilizes a pretrained unconditional VAE to improve training efficiency and performance in conditional image generation tasks, particularly image inpainting. The authors demonstrate that their method outperforms state-of-the-art GAN-based approaches while effectively capturing the posterior distribution.","['Can the authors clarify the limitations of using pretrained models and how this might affect the generalizability of their approach?', 'What additional ablation studies might the authors consider to strengthen their claims regarding the performance of their method?']","['The paper does not adequately address the potential limitations of relying on pretrained models, especially concerning datasets that differ from those used for pretraining.', 'The clarity of the exposition could be improved, particularly in explaining the architecture and the specific contributions of each component.']",True,3,2,3,5,4,"['The approach effectively reduces training time by leveraging pretrained models.', 'The paper presents comprehensive experimental results demonstrating superior performance in image inpainting tasks compared to existing methods.', 'The discussion on potential applications, particularly in Bayesian experimental design, adds practical relevance to the research.']","['The paper lacks clarity in some sections, particularly regarding the architecture and how the pretrained model is integrated. Specific examples of unclear sections would strengthen the review.', ""The reliance on a pretrained unconditional VAE raises concerns about the method's applicability across different datasets and tasks, which should be discussed in more detail."", 'The experimental results, while promising, could benefit from additional comparisons and ablation studies to further validate the claims made.']",3,3,2,3,Reject
vcUmUvQCloe,"The paper introduces joint Shapley values as an extension of traditional Shapley values to evaluate the importance of sets of features in machine learning models. While it aims to provide insights into feature interactions, the execution is flawed, with unclear definitions and insufficient experimental validation.","['Can the authors clarify the computational complexity of calculating joint Shapley values in practice?', 'What specific advantages do joint Shapley values provide in practical applications compared to existing measures?']","['The clarity of the theoretical framework may hinder readers from fully grasping its practical importance.', 'The experimental section does not convincingly demonstrate the claimed advantages of joint Shapley values over existing methods.']",False,2,2,2,4,4,"['Introduces a novel extension of Shapley values to account for joint contributions of sets of features, representing a significant theoretical advancement.', 'Attempts to provide a comprehensive axiomatic foundation for joint Shapley values, addressing limitations of existing measures.', 'Includes initial experiments that demonstrate application to both game-theoretical models and ML feature attribution problems.']","['The paper lacks clarity in explaining complex concepts and results, making it challenging for readers to follow the theoretical developments.', 'Experimental validation is limited and does not sufficiently compare joint Shapley values against a wide range of existing feature importance measures, failing to demonstrate their advantages in practical scenarios.', 'The implications of the findings could be articulated more clearly, particularly regarding how joint Shapley values can be applied in real-world machine learning contexts.']",3,2,2,3,Reject
fHeK814NOMO,"The paper proposes a method for automatically adjusting the learning rate during training of deep neural networks by treating it as a trainable parameter. The authors claim that this approach offers robustness and minimal computational overhead compared to existing methods. However, the paper suffers from clarity issues and lacks rigorous comparisons with state-of-the-art optimizers.","['Can the authors clarify the theoretical foundation behind their method and how it compares to existing techniques?', ""What specific metrics were used to evaluate 'robustness' across different scenarios?""]","['Insufficient comparison with state-of-the-art approaches may undermine the claims of improvement.', 'The theoretical underpinning lacks depth, which could mislead practical implementations.']",False,2,2,3,4,4,"['The idea of treating the learning rate as a trainable parameter is innovative and relevant to optimization in deep learning.', 'The proposed method potentially reduces the need for extensive hyperparameter tuning.', ""Extensive experiments demonstrate the method's applicability across different datasets and architectures.""]","['The clarity of the presentation is poor, making it hard to follow the theoretical motivations and methodology.', 'The originality is moderate as similar concepts have been explored previously, but the approach still presents a novel angle.', 'Results do not sufficiently compare against existing state-of-the-art optimizers under varying conditions.', 'The paper lacks a thorough discussion of potential limitations and negative impacts of the proposed method.']",4,2,2,3,Reject
rqolQhuq6Hs,The paper develops a theoretical model for understanding the dynamics of stochastic gradient descent (SGD) by deriving a stochastic differential equation (SDE) with logarithmized loss. It proposes a new escape rate formula from local minima that emphasizes the ratio of loss values. The authors argue that their insights explain why SGD prefers flat minima with low effective dimensions.,"['Can the authors clarify the relationship between the theoretical results and their practical implications for SGD in real-world applications?', 'What steps could be taken to improve the clarity of the presentation and make the work more accessible to a broader audience?']","['The lack of comprehensive experimental validation raises concerns about the applicability of the theoretical results.', 'The dense mathematical treatment may alienate readers who are not specialists in the theoretical aspects of SGD.']",False,2,2,3,4,4,"['The theoretical framework addresses a critical aspect of SGD dynamics and contributes to understanding its convergence behavior.', 'The introduction of logarithmized loss provides a novel perspective on escape rates from local minima.', 'The paper connects concepts from statistical mechanics to machine learning, potentially opening new research avenues.']","['The presentation is convoluted and difficult to follow, with sections dense in mathematical notation lacking clear explanations.', 'While the theoretical contributions are significant, the experimental validation is limited and does not convincingly demonstrate practical implications.', 'Key terms and concepts are not clearly defined, making it challenging for readers unfamiliar with the topic to grasp the significance of the results.']",3,2,2,4,Reject
sBT5nxwt18Q,"The paper introduces Critical Classification Regions (CCRs) to enhance explanation-by-example methods in explainable AI (XAI). CCRs highlight important parts of test images and connect them to their nearest neighbors in training data, potentially improving interpretability. The authors conduct experiments across multiple domains and a user study to assess the effectiveness of CCRs.","['Can the authors clarify the methodology behind computing CCRs and their integration into existing frameworks?', 'What steps can enhance the user study, such as increasing the number of test images?', 'Could the authors clarify the statistical methods used in the user study?', 'What challenges did you face in isolating CCRs, and how did you address them?']","['The paper does not adequately address the limitations of CCRs and potential user misinterpretation.', 'The user study design could be improved for a more robust evaluation.', 'The clarity of the methodologies described could be enhanced for easier replication.', 'The paper may benefit from additional comparative studies against established XAI techniques.']",False,2,2,3,3,4,"['The introduction of Critical Classification Regions (CCRs) is a novel enhancement to explanation-by-example methods in XAI.', 'The paper addresses a significant issue in interpretability, relevant for high-stakes applications.', 'A user study assesses the impact of CCRs on user perception, providing empirical evidence for the proposed method.']","['The methodology for computing and integrating CCRs lacks clarity, making it difficult to understand their enhancement of explanations.', 'User study results are limited in scope, with a small number of test images that may not be representative.', 'There is insufficient discussion on the implications of the findings for real-world applications.', 'The clarity of the paper is lacking; some sections are convoluted and hard to follow.', 'The experimental design, particularly in the user study, lacks sufficient details about participant demographics and statistical methods.']",3,2,2,3,Reject
49A1Y6tRhaq,"The paper proposes a method to connect emergent communication with natural languages through corpus transfer. It demonstrates that pre-training on emergent language corpora can enhance performance on NLP tasks such as language modeling and image captioning, particularly in low-resource settings. The authors also introduce a new metric for evaluating emergent languages based on their translatability to natural language, which shows a strong correlation with downstream task performance.","['Can the authors elaborate on the potential implications of their findings for future research in emergent communication and NLP?', 'What are the limitations of their corpus transfer approach, and how might they impact the usefulness of emergent languages in practical applications?']","['The paper does not sufficiently address the limitations of the proposed corpus transfer technique or its potential negative implications for NLP tasks.', 'The clarity and presentation of the methodology could be improved to enhance understanding of the experiments and their implications.']",False,3,3,4,7,4,"['The approach of using corpus transfer to bridge emergent and natural languages is innovative and timely.', 'The experiments provide clear quantitative evidence of the benefits of using emergent language corpora.', 'The introduction of a novel metric for evaluating emergent languages is a valuable contribution to the field.']","['The paper lacks clarity in certain sections, making it difficult to fully grasp the methodology and implications of the findings.', 'The originality of the approach is somewhat limited, as it builds on existing concepts without providing a strong justification for its novelty.', 'The generalizability of the findings is questionable, and the authors should consider validating their approach on a wider range of tasks.']",4,3,3,4,Reject
9W2KnHqm_xN,"The paper proposes a Spatiotemporal aware Embedding framework (STE) for successive point-of-interest (POI) recommendation, inspired by the entorhinal-hippocampal system in neuroscience. It aims to improve POI representations by integrating spatial and temporal contexts through a spatiotemporal context graph. The framework reportedly achieves state-of-the-art performance on two benchmark datasets and is also applicable to traffic flow prediction.","['Can the authors clarify how the spatiotemporal context graphs are constructed and utilized?', 'What are the specific advantages of the STE framework compared to existing methods beyond the presented benchmarks?', 'Could the authors provide additional details on the ablation studies to enhance the credibility of their claims?', 'What specific limitations were encountered during the experiments, and how were they addressed?']","['The clarity of the paper can be improved significantly, especially regarding the methodology.', 'The depth of the experimental validation is insufficient; more diverse datasets or tasks could strengthen the results.', 'The discussion on the limitations and potential improvements of the proposed approach is lacking.', 'Insufficient attention is given to potential ethical considerations, despite claims of enhanced user privacy.']",True,2,2,2,4,4,"['The integration of neuroscience concepts into machine learning provides a novel perspective for developing spatiotemporal representations.', 'The proposed framework demonstrates improvements over existing methods in POI recommendations, which is a relevant application in location-based services.', 'The paper outlines a clear methodology for constructing context graphs and applying a spatiotemporal model.']","['The clarity of the writing is inconsistent; many sections are convoluted and difficult to understand.', 'The methodology lacks sufficient detail regarding the construction and utilization of the spatiotemporal context graphs.', 'The experimental validation is limited in robustness and depth, particularly in the ablation studies.', 'The paper does not adequately address the limitations of the proposed methods or provide a thorough discussion on the generalizability of the STE framework across different datasets.']",3,2,2,3,Reject
p98WJxUC3Ca,"The paper proposes a discrepancy-based active learning method for domain adaptation, leveraging theoretical results on Lipschitz functions and discrepancy distances. It derives generalization error bounds and presents a K-medoids algorithm designed for efficiency in large datasets, claiming competitive performance with state-of-the-art methods in domain adaptation applications.","['Can the authors clarify the assumptions made in the theoretical sections?', 'What measures could be taken to enhance the empirical validation of the proposed algorithm?', 'Could the authors provide more examples or case studies to illustrate the practical application of their method?', 'Can the authors clarify the motivation behind choosing the localized discrepancy?']","['The paper can be difficult to follow due to dense theoretical exposition.', 'Experimental validation seems limited, with a need for broader dataset comparisons.', 'Insufficient clarity in method description and results could hinder reproducibility.']",False,3,2,3,3,4,"['Addresses a significant problem in machine learning regarding domain adaptation and active learning.', 'Theoretical contributions are well-founded, providing generalization bounds and a localized discrepancy framework.', 'Proposes an efficient K-medoids algorithm that can handle large datasets effectively.']","['The theoretical derivations, while solid, could benefit from clearer exposition and more intuitive explanations.', 'Experimental results lack depth; further validation with diverse datasets and additional metrics would strengthen the claims.', ""Clarity issues in the presentation make it difficult to follow the algorithm's practical implementation."", 'The originality of the contributions seems limited and incremental over existing works.']",3,3,2,3,Reject
Gx6Tvlm-hWW,"The paper proposes a new method for conformal prediction that aims to output precise prediction sets while controlling the number of false positives. This approach is particularly relevant in high-stakes applications like drug discovery, where reducing the cost of false positives is crucial. The authors demonstrate the effectiveness of their method across various classification tasks.","['Could the authors clarify how their approach compares to existing methods more explicitly in the related work section?', 'What additional ablation studies do the authors plan to conduct to support their claims?']","['The paper lacks sufficient clarity and organization in some sections, which may hinder understanding.', 'The authors should address the need for more extensive evaluations and comparisons with existing methods.']",False,3,4,4,7,4,"['The approach addresses a significant issue in conformal prediction by trading coverage for precision, which is particularly relevant for applications with high costs for false positives.', 'The method is theoretically sound, providing rigorous control over false positive rates while maintaining a reasonable true positive rate.', 'The paper provides empirical validation across multiple tasks, showcasing the applicability of the proposed method in different domains.']","['The clarity of the presentation could be improved; some sections are dense and may confuse readers unfamiliar with the topic.', 'The related work section could benefit from a more thorough discussion of existing methods and how this approach directly compares or improves upon them.', 'Additional ablation studies are needed to substantiate the claims regarding the performance and effectiveness of the proposed method.']",3,3,4,4,Reject
lu_DAxnWsh,"The paper proposes a method to enhance the ability of neural networks to perform 'System 2' tasks, which require multi-step reasoning, by incorporating intermediate steps during training. The authors demonstrate that a Transformer can effectively learn to perform binary addition when trained with these intermediate results, suggesting that traditional training methods may be insufficient for algorithmic tasks.","['How might the proposed approach generalize to other algorithmic tasks beyond binary addition?', 'What criteria were used to select the intermediate steps, and could alternative configurations yield better results?']","['The paper does not adequately address the limitations of requiring structured supervision in training, which may not be feasible in all scenarios.', 'The necessity of intermediate steps needs more rigorous validation through a broader set of experiments to confirm its effectiveness.']",False,3,2,3,4,4,"['Addresses a significant gap in the training of neural networks for algorithmic tasks, particularly in bridging the gap between System 1 and System 2 capabilities.', 'Empirical results indicate improved performance on binary addition when intermediate steps are included, showcasing the potential of the proposed method.', 'The approach aligns with human cognitive processes, providing a plausible framework for training that could inspire future research in algorithmic reasoning.']","['The presentation lacks clarity and could benefit from more detailed explanations of methods and concepts, making it difficult for readers to fully grasp the approach.', 'Experiments are limited to binary addition, raising questions about the generalizability of the findings to other algorithmic tasks and contexts.', 'Insufficient evaluation of the proposed method against existing approaches for similar tasks, which could provide a clearer picture of its effectiveness.']",3,3,2,3,Reject
HfUyCRBeQc,"The paper introduces selective ensembles as a method to mitigate inconsistencies in predictions and feature attributions from deep learning models. It employs hypothesis testing to ensure consistent predictions while allowing models to abstain when confidence is low. The authors provide theoretical proofs and empirical results demonstrating the effectiveness of selective ensembles across multiple datasets, achieving zero inconsistent predictions with low abstention rates.","['Can the authors provide more clarity on the implications of the results and the methodology used?', 'What are the practical implications of high abstention rates in sensitive applications?', 'Can additional ablation studies be included to explore the influence of different parameters in selective ensembles?']","['The paper does not adequately discuss the potential drawbacks of using selective ensembles, particularly in scenarios where abstention may lead to negative outcomes.', 'The implications of selective ensembles on interpretability need to be better elucidated.']",True,3,3,3,7,4,"['Addresses a significant issue of prediction inconsistency in high-stakes applications.', 'Introduces a novel method (selective ensembles) grounded in solid theoretical foundations.', 'Empirical results convincingly demonstrate the effectiveness of the proposed method.']","['Clarity of the paper is inconsistent; some sections are dense and difficult to follow.', 'Limited discussion on the practical implications of high abstention rates in real-world applications.', 'The paper lacks extensive real-world validation and detailed ablation studies.']",3,3,3,4,Reject
8e2vrVvvaeQ,"The paper investigates indiscriminate data poisoning attacks, revealing that the perturbations used in these attacks are often linearly separable. This property is linked to shortcut learning in deep models, suggesting that models can rely on imperceptible perturbations as shortcuts. The authors propose using pre-trained feature extractors as a defense against these attacks.","['Could you clarify the specific methods used to evaluate the effectiveness of the proposed defense?', 'What additional experiments could be done to strengthen the findings regarding linear separability and its implications for poisoning attacks?']","['The paper does not adequately address the limitations of the proposed defense, especially in relation to potential white-box attacks.', 'The clarity issues in the methodology may hinder reproducibility of the results.']",False,2,2,3,5,4,"['The paper addresses a relevant and timely issue in machine learning, exploring the vulnerabilities posed by data poisoning attacks.', 'The finding that perturbations exhibit linear separability is a novel contribution, providing insight into how these attacks function.', 'The connection drawn between poisoning attacks and shortcut learning is an interesting perspective that could influence future research.']","['The methodology lacks clarity in some sections, making it difficult to follow the proposed processes and experiments.', 'The experimental evaluation does not comprehensively assess the proposed defense mechanism against various attack types, limiting the robustness of the conclusions.', 'Some claims about the effectiveness of the proposed defense are not thoroughly supported by experimental evidence.']",3,2,2,4,Reject
O476oWmiNNp,"This paper investigates the scalability issues of Vision Transformers (ViTs) and provides a rigorous theoretical framework analyzing the low-pass filtering effects of self-attention mechanisms. It proposes two techniques, AttnScale and FeatScale, to mitigate these effects and enhance performance with deeper architectures. The authors provide extensive experiments showcasing the effectiveness of their approaches across various ViT models, yielding notable performance improvements.","['Can the authors provide more details about the ablation studies for AttnScale and FeatScale to clarify their individual contributions?', 'Would it be possible to include more visualizations or examples that illustrate the impact of the proposed techniques on attention maps and feature maps?', 'Can the authors clarify how the proposed techniques are expected to interact with different ViT architectures?']","['The paper would benefit from clearer explanations in sections dealing with theoretical proofs and implications.', 'Additional ablation studies would strengthen the validation of the proposed techniques.', 'The implications of the proposed methods on model complexity and training time are not thoroughly discussed.']",False,3,3,4,7,4,"['The paper establishes a solid theoretical foundation for understanding the limitations of ViTs, particularly regarding attention collapse and patch uniformity.', 'The proposed techniques, AttnScale and FeatScale, are innovative and practical, showing clear improvements in performance without significant overhead.', 'The empirical results are comprehensive, demonstrating the effectiveness of the proposed methods across multiple ViT architectures and configurations.']","['The clarity of some sections could be improved, particularly in explaining the theoretical aspects and the implications of the proposed techniques.', 'While the empirical results are strong, there is a lack of detailed ablation studies that could further substantiate the individual contributions of AttnScale and FeatScale.', 'The originality of the proposed solutions may not be sufficiently high, as they build on existing empirical findings without presenting radically new concepts.']",4,3,3,4,Reject
JLbXkHkLCG6,"The paper presents methods for imitation learning from pixel observations, focusing on continuous control tasks. It introduces Pixel Sinkhorn Imitation Learning (P-SIL) and Pixel Discriminator Actor Critic (P-DAC), applying optimal transport and adversarial learning techniques. The authors claim to achieve expert-level performance on the DeepMind control suite tasks without needing action information, supporting their findings with extensive evaluations and ablation studies.","['How do the proposed methods significantly advance the field beyond existing optimal transport and adversarial learning techniques?', 'Could the authors clarify the sections on reward calculations for both P-SIL and P-DAC to enhance reader understanding?', 'Can the authors provide more insight into the ablation studies and their findings?']","['The paper does not clearly present the originality of its contributions, which may lead to confusion regarding its significance in the literature.', 'The clarity of the technical details may hinder understanding and reproducibility.', 'The methods may not generalize well beyond the tested environments, and their robustness in real-world applications is unclear.']",False,3,3,3,6,4,"['The paper addresses an important problem in reinforcement learning by focusing on imitation learning from visual observations.', 'The proposed methods leverage established techniques from optimal transport and adversarial learning, providing a novel approach to the challenge of high-dimensional visual data.', ""A comprehensive experimental evaluation demonstrates the methods' effectiveness, including comparisons with baseline approaches.""]","['The novelty of the proposed methods is questionable, as they largely build upon existing techniques without significant theoretical contributions.', 'The presentation lacks clarity in some sections, making it challenging for readers to follow the core ideas and understand the methods fully.', 'Some parts of the paper are overly complex and could benefit from simplification or more intuitive explanations.', 'The paper does not sufficiently address the potential limitations of the proposed methods and their applicability to real-world scenarios.']",3,3,3,4,Reject
UTTrevGchy,The paper proposes the InfoMax Termination Critic (IMTC) algorithm for learning diverse options in reinforcement learning by maximizing mutual information between options and their terminating states. The approach aims to enhance the reusability of options in various tasks and presents a scalable approximation of MI maximization. Experiments demonstrate improved diversity of learned options without extrinsic rewards and effective task adaptation.,"['Can the authors provide more details on how the classification model is trained and the parameters used?', 'What specific improvements does IMTC show over other option-learning methods in terms of diversity and reusability based on quantitative metrics?', 'Could the authors clarify their exploration strategy to mitigate the risk of uninteresting options?']","['The paper lacks detailed experimental evaluations against a broader range of existing methods.', ""The clarity of the algorithm's implementation and certain experimental results needs improvement for better reproducibility."", 'The potential for learned options to be diverse but not meaningful is a critical limitation that should be addressed.']",False,3,3,3,6,4,"['Addresses a significant challenge in reinforcement learning regarding the learning of reusable options.', 'Introduces a novel approach leveraging mutual information maximization, which is theoretically sound.', 'Demonstrates promising experimental results indicating improved performance in task adaptation.']","[""Lacks comprehensive comparisons with state-of-the-art methods, limiting the assessment of IMTC's effectiveness."", 'Insufficient ablation studies to clarify the contributions of individual components of the algorithm.', 'Clarity is compromised by dense mathematical formulations and insufficient explanations of key concepts.']",3,3,3,4,Reject
CgV7NVOgDJZ,"The paper presents Guided-TTS, a novel text-to-speech model that utilizes untranscribed speech data for training by combining an unconditional diffusion probabilistic model with a phoneme classifier. This approach aims to generate high-quality speech without requiring transcribed data, thereby facilitating the use of available audio resources like audiobooks and podcasts.","['Can the authors clarify the limitations of using only specific datasets for evaluation and how they plan to address this in future work?', 'What measures are taken to ensure the robustness of the phoneme classifier across different accents or speaking styles?']","['The proposed method heavily relies on the quality of the phoneme classifier, which may not generalize well across diverse speakers.', 'The performance metrics reported are based on a limited number of datasets, which might not represent broader applications.']",False,3,4,4,7,4,"['Addresses a significant limitation in existing TTS models, which require transcribed data for training.', 'Introduces a novel application of unconditional diffusion models to TTS, which is an innovative approach in the field.', 'Demonstrates the potential to achieve competitive performance with existing TTS models using untranscribed data.']","['The experimental evaluation lacks thoroughness; results should be validated across a wider variety of datasets and conditions.', 'Some sections of the methodology are unclear and could benefit from more detailed explanations, particularly regarding the phoneme classifier and its integration.', ""The results, while promising, are based on limited datasets, and the generalizability of the model's performance is uncertain.""]",4,4,4,4,Reject
o_HsiMPYh_x,"The paper investigates methods for predicting target domain accuracy using labeled source data and unlabeled target data. It proposes a method called Average Thresholded Confidence (ATC), which learns a threshold on model confidence to predict accuracy. The authors claim that ATC outperforms existing methods across various datasets and distribution shifts, while also exploring theoretical foundations regarding the challenges of estimating accuracy under distribution shifts.","['What specific assumptions about distribution shifts are necessary for ATC to work effectively?', 'Can the authors provide more clarity on the assumptions made and their implications for different types of distribution shifts?', 'Could the authors provide more detailed analysis or examples of when ATC may fail?']","['The dependence on specific assumptions regarding the nature of distribution shifts may limit the applicability of the method.', 'The paper could benefit from additional empirical validation on more diverse datasets to strengthen claims.', 'The lack of ablation studies raises questions about the contributions of different components of ATC.']",False,3,2,3,5,4,"['Addresses a significant problem of estimating accuracy under distribution shifts, which is very relevant in real-world applications.', 'The proposed method ATC is simple to implement and demonstrates promising empirical performance across multiple datasets and distribution shifts.', 'The paper includes a theoretical exploration of the conditions under which accuracy estimation is possible, providing valuable insights.']","['The theoretical foundations are somewhat lacking; particularly, the implications of the assumptions required for accuracy estimation are not thoroughly explored.', 'The experiments, while comprehensive, could include more cases demonstrating the limitations of ATC, especially in scenarios with complex distribution shifts.', 'The paper does not sufficiently address potential failure modes of the proposed method or provide guidance on when it may not perform well.', 'Clarity and organization of the paper could be improved, especially in describing the methodology and experimental setup.']",3,3,2,4,Reject
LhObGCkxj4,"The paper proposes a theoretical framework for understanding global convergence in optimization algorithms for deep neural networks, introducing a recursive algorithm and bounded assumptions. While the theoretical contributions are significant, the paper lacks empirical validation and clarity in presentation.","['What empirical results can validate the proposed theoretical claims?', 'How do the bounded style assumptions impact the practical applicability of the algorithms?', 'Can the authors clarify the motivation behind the new representation and its potential advantages over existing methods?']","['Theoretical contributions are not supported by practical experiments.', 'The complexity of the theoretical exposition may alienate readers who are less familiar with advanced optimization techniques.']",False,2,2,2,4,4,"['Addresses a fundamental issue in deep learning optimization: convergence to global minima.', 'Introduces a novel theoretical framework with interesting convergence guarantees.', 'The topic is highly relevant and timely in the context of deep learning.']","['Lacks empirical validation; no experiments or practical implementations to support theoretical claims.', 'The bounded style assumptions may limit the applicability of the results.', 'The clarity of the writing could be improved to help readers better understand the methodology and results.']",3,2,3,4,Reject
0SiVrAfIxOe,"The paper presents a closed-loop control policy for additive manufacturing using reinforcement learning, addressing the challenge of adjusting process parameters in real-time. It introduces a numerical model that approximates the deposition process and claims to outperform existing controllers with a minimal sim-to-real gap. However, the methodology lacks clarity, and the experimental validation of its claims is insufficient.","['Can the authors clarify the methodology in detail to facilitate reproducibility?', 'What specific improvements were observed compared to existing methods, and how were they measured?', 'Can the authors provide additional experimental results to support their claims?']","['The methods section lacks detail, which could lead to misunderstandings regarding the proposed approach.', 'The paper does not adequately address potential limitations of the proposed model or its practical implications.']",False,2,2,3,4,4,"['Addresses a critical issue in additive manufacturing: the need for adaptive control of process parameters.', 'Introduces a novel numerical model that aims to improve the simulation-to-reality transfer.', 'Utilizes reinforcement learning, which is a relevant approach for adaptive manufacturing.']","['The methodology is vague, making it difficult to reproduce the results.', 'Experimental validation is lacking; the performance claims are not convincingly supported by the data.', 'The connection to existing literature is not adequately established, limiting the assessment of originality.']",3,3,3,4,Reject
Fza94Y8VS4a,"The paper proposes a framework for analyzing the evolution of uncertainty in multi-agent learning systems using differential entropy. It formalizes the relationship between differential entropy and volume analysis, demonstrating that uncertainty increases linearly over time in various game settings. The findings are applied to different learning algorithms, particularly focusing on Multiplicative Weights Update (MWU).","['Can the authors clarify the practical implications of their findings?', 'What specific experiments have been conducted to validate the theoretical claims?', 'Can the authors simplify the presentation of their mathematical analysis to improve clarity?']","['The paper does not adequately discuss the limitations of the proposed framework and its applicability across various scenarios.', 'There is insufficient empirical evidence to support the theoretical results presented.']",False,2,2,2,2,4,"['The topic is relevant and addresses an important aspect of learning algorithms in game-theoretic contexts.', 'The use of differential entropy provides a novel perspective on understanding uncertainty in these systems.', 'The theoretical analysis contributes to the understanding of how uncertainty evolves in multi-agent learning, which is crucial for developing robust algorithms.']","['The mathematical presentation is dense and difficult to follow, which may alienate readers unfamiliar with the technical details.', 'The paper lacks sufficient experimental validation to support the theoretical claims, limiting its practical significance.', 'Key concepts and their implications are not adequately explained, leading to clarity issues throughout the paper.']",3,2,2,3,Reject
aYAA-XHKyk,"The paper proposes Regrouping CPE (ReCPE) for class-prior estimation in positive-unlabeled learning, addressing the limitations of existing CPE methods that rely on the irreducibility assumption. ReCPE constructs an auxiliary distribution to ensure that the positive data distribution is not contained in the negative data distribution, leading to improved performance in various datasets. The paper includes theoretical analyses and experimental validations to support its claims.","['What specific contributions differentiate ReCPE from existing methods that utilize the irreducibility assumption?', 'Can the authors provide more detailed explanations about the selection of hyperparameters and their impact on the results?', 'Could the authors include more baseline comparisons to illustrate the advantages of ReCPE?']","['The paper needs to provide clearer explanations in certain sections and more thorough justifications for its experimental design.', 'The significance of the proposed method is not convincingly demonstrated against a wider array of state-of-the-art methods.']",False,3,2,3,6,4,"['Addresses a significant limitation in PU learning by tackling the irreducibility assumption that many CPE methods rely on.', 'The proposed ReCPE method is theoretically sound and offers a new direction for improving class-prior estimation.', 'Empirical results show that ReCPE can improve on existing state-of-the-art methods across various datasets.']","['The clarity of the paper could be improved, especially regarding the theoretical implications and the practical implementation of the ReCPE method.', 'The novelty of the approach may be questioned since it builds on existing methods without sufficiently differentiating its contributions.', 'Some experimental settings and hyperparameter choices lack detailed justification, which may hinder reproducibility.']",3,3,3,4,Reject
2sDQwC_hmnM,"The paper introduces ZeroFL, a framework designed to enhance on-device training efficiency for federated learning through local sparsity techniques. It aims to reduce communication costs while maintaining model performance in resource-constrained environments. However, the contributions and novelty of the proposed methods are questioned, and the experimental validation is limited.","['What specific adaptations have been made to the existing sparsification methods to suit the FL context?', 'How do the proposed methods compare to other recent approaches in terms of efficiency and accuracy?', 'Can the authors provide additional experiments on more diverse datasets and configurations to strengthen their claims?']","['The paper does not adequately address the potential negative impacts of implementing sparsity in FL, such as accuracy loss in varying environments.', ""Lacks a comprehensive analysis of the proposed methods' performance across different scenarios, which could limit the applicability of the findings.""]",False,2,2,2,4,4,"['Addresses a relevant problem in Federated Learning by focusing on on-device training efficiency.', 'Presents empirical results indicating potential improvements in accuracy and communication costs with local sparsity.', 'The approach could significantly benefit practical applications of Federated Learning on constrained devices.']","['The novelty of the approach is not clearly established; it heavily relies on existing sparsity methods without substantial modifications.', 'Experimental validation is limited, with insufficient comparisons to a wider range of baselines and scenarios, raising concerns about the robustness of the findings.', 'Descriptions of the proposed methods and results lack clarity; figures and tables could be more informative.', 'The organization of the paper is unclear, and certain sections lack sufficient detail, making it difficult to follow the methodology.']",2,2,2,4,Reject
mF122BuAnnW,"The paper proposes a novel method for collective robustness certification of multi-output classifiers using localized randomized smoothing. This method addresses the limitation of existing certificates that only apply to strictly local models by providing stronger guarantees for softly local models, where different outputs depend on varying portions of the input. The authors validate their approach through experiments in image segmentation and node classification, showing that their method maintains high prediction quality while certifying robustness against adversarial perturbations.","['Can the authors provide additional clarification on the implementation of localized randomized smoothing?', 'What specific ablation studies can be conducted to further validate the contributions of various components of the proposed method?', 'Could the authors provide additional context or examples to better illustrate the experimental results presented?', 'Could the authors clarify the assumptions made regarding the locality of the models?', 'What specific comparisons were made against state-of-the-art methods?']","['The clarity of the presentation, especially regarding the theoretical foundations and practical implementations, needs improvement.', 'The experimental validation may not cover all edge cases and scenarios pertinent to the broader application of the proposed method.', 'The lack of extensive experimental validation against a variety of methods raises questions about the robustness of the claims.']",False,3,2,3,5,4,"['The paper tackles a relevant and practical problem in the robustness of multi-output classifiers.', 'The introduction of localized randomized smoothing offers a novel perspective that improves upon previous methods limited to strictly local models.', 'The experimental evaluation includes a variety of tasks and demonstrates the effectiveness of the proposed method in real-world scenarios.']","['The paper lacks clarity in certain sections, particularly in the explanation of localized randomized smoothing and its implementation details.', 'The methodology could benefit from more thorough ablation studies to understand the impact of various components on performance.', 'Some experimental results and discussions are difficult to interpret due to a lack of context or explanation, particularly in the comparison with baselines.', 'The paper does not sufficiently compare against a wider array of existing methods, limiting the demonstration of its advantages.']",3,2,2,4,Reject
fRnRsdc_nR7,"The paper introduces Noise-FGSM (N-FGSM), a method for single-step adversarial training that aims to prevent catastrophic overfitting (CO) and improve robustness by avoiding clipping of perturbations and using increased noise. The authors provide extensive empirical analyses showing that N-FGSM performs competitively against state-of-the-art methods while achieving a threefold speed-up.","['Can the authors provide more theoretical justification for the effectiveness of increased noise?', 'Could the authors clarify how N-FGSM prevents catastrophic overfitting?']","['The paper does not fully address the implications of removing clipping on clean accuracy and potential trade-offs.', 'Further explanation is needed on how noise magnitude affects robustness, particularly in relation to catastrophic overfitting.']",False,3,3,4,6,4,"['The experimental analysis is thorough, covering multiple datasets (CIFAR-10, CIFAR-100, SVHN) and architectures (PreActResNet18, WideResNet28-10).', 'The paper addresses a significant issue in adversarial training, specifically catastrophic overfitting, and presents empirical evidence that N-FGSM effectively mitigates this problem.', 'The proposed method shows promising results, matching or exceeding the performance of more computationally intensive methods like GradAlign.']","['The paper lacks clarity in some sections, particularly in explaining the theoretical foundations of the proposed method and its advantages over existing techniques.', ""Certain claims regarding the effectiveness of N-FGSM lack rigorous theoretical backing, which would enhance the paper's credibility."", 'The novelty of the method seems more empirical than theoretical, as it builds on prior methods without introducing fundamentally new concepts.']",4,3,3,4,Reject
mZsZy481_F,"The paper proposes the Few-shot ROBust (FROB) model aimed at enhancing classification and Out-of-Distribution (OoD) detection in few-shot settings. It combines self-supervised learning with few-shot outlier exposure to improve robustness and reliable confidence predictions. However, the methodology lacks clarity, and the experimental evaluation raises concerns about reproducibility.","['Can the authors clarify the methodology used in FROB, particularly the self-supervised learning aspect?', 'What specific experiments were conducted to validate the claims of robustness, and how do these compare to existing methods?', 'Could the authors provide more context and justification for their experimental design choices?']","['The clarity of the methodology and results is a major concern, which would need to be addressed in the rebuttal phase.', 'The reliance on specific datasets and the performance metrics used may limit the generalizability of the findings.']",False,2,2,3,4,3,"['Addresses a significant problem in few-shot learning and OoD detection.', 'Introduces a novel approach combining generated boundaries with few-shot outlier exposure.', 'Claims competitive performance on various datasets.']","['The methodology is poorly described, making it challenging to understand how FROB operates.', 'Insufficient clarity in the experimental setup and evaluation metrics.', 'Lacks comprehensive experimental validation and ablation studies.']",4,2,2,4,Reject
K47zHehHcRc,"This paper introduces the concept of interventional consistency in autoencoders, proposing a training scheme that incorporates this concept to enhance the quality of representations. The authors provide empirical evidence across various autoencoder architectures, but the clarity and rigor of the evaluations are lacking.","['Can the authors clarify the specific advantages of interventional consistency over existing metrics for evaluating representations?', 'How do the results of this work compare quantitatively with those from other state-of-the-art representation learning methods?', 'Could the authors provide more detailed explanations of the explicit causal latent block and its advantages?']","['The paper needs to better address the clarity and comprehensibility of the proposed concepts.', 'More detailed comparisons with existing methods are necessary to validate the claims made in the paper.']",False,2,2,3,4,4,"['The introduction of interventional consistency is a relevant and timely topic in representation learning.', 'The paper provides empirical evidence across multiple autoencoder architectures, indicating thorough experimentation.', 'The proposed explicit causal latent block offers a new approach to improve the separability of information and structure in latent representations.']","['The paper lacks clarity in explaining the methodology and implications of interventional consistency, making it difficult for readers to follow.', 'The empirical validation lacks depth, particularly in terms of ablation studies and comparisons to a wider range of existing methods.', 'Some claims about the benefits of the proposed methods are not sufficiently supported by the experimental results presented.']",3,2,2,3,Reject
F0v5uBM-q5K,"The paper presents a power-aware neural network (PANN) aimed at reducing power consumption in deep neural networks (DNNs) through the introduction of unsigned arithmetic and quantization methods. While it addresses a critical issue in deploying DNNs on resource-constrained devices, the originality of the contributions is limited, and the experimental validation lacks depth and clarity.","['Can the authors provide more detailed explanations of their power modeling?', 'What specific experiments were conducted to validate the effectiveness of PANN compared to state-of-the-art methods?', 'How do the authors address potential limitations or drawbacks of their approach?']","['The paper does not adequately address the limitations of the proposed method, particularly in terms of scalability and generalization.', 'More thorough evaluation against existing power reduction techniques is necessary to establish the effectiveness of PANN.']",False,3,2,3,5,4,"['Addresses a critical problem of power consumption in DNNs relevant for deployment in resource-constrained environments.', 'Introduces unsigned arithmetic as a method to reduce power consumption, which is an interesting idea.', 'The paper discusses power consumption in detail and proposes a framework for navigating power-accuracy trade-offs.']","['The originality of the contributions is moderate, as many ideas are adaptations of existing concepts without significant innovation.', 'The experimental results are not comprehensive, lacking sufficient comparisons to existing methods, particularly in terms of accuracy and power efficiency.', 'Several claims are made without adequate theoretical backing or empirical evidence, making it difficult to assess their validity.', 'The paper lacks clarity in explaining methodologies, particularly in how power consumption is modeled and evaluated, which could confuse readers.']",3,3,2,4,Reject
ChKNCDB0oYj,"The paper proposes a mistake-driven training approach for image classification that employs FastGAN for augmenting underperforming classes to improve overall model performance. It introduces a method that focuses on classes with low accuracy after initial training, using GANs to generate data specifically for these classes. The methodology is experimentally validated on five datasets.","['Can the authors clarify how their method compares to existing methods in terms of performance and computational efficiency?', 'What specific improvements does the proposed method offer over existing GAN-based augmentation techniques?', 'Can the authors provide more context on how the choice of GANs impacts the augmentation process beyond simply being lightweight?', 'What measures were taken to prevent overfitting during GAN training?', 'What are the potential risks or drawbacks of using GANs in this context, particularly related to ethical considerations?']","['The lack of clarity in the proposed methodology and its practical implications may hinder reproducibility and understanding.', 'The evaluation metrics and comparisons with state-of-the-art methods need to be more comprehensive.', 'The paper does not address the potential for GANs to produce misleading or biased data, which can exacerbate class imbalances rather than mitigate them.']",True,3,3,3,5,4,"['The approach addresses a relevant problem in image classification regarding class imbalance and performance disparity.', 'The use of FastGAN for efficient data augmentation is innovative and potentially beneficial for scenarios with limited data.', 'The paper includes extensive experiments and ablation studies demonstrating the applicability of the proposed method.']","['The clarity of the proposed methodology is lacking, making it difficult to understand how it compares to existing methods.', 'The originality of the work is somewhat unclear; similar concepts of class-wise augmentation have been explored previously, and the novelty of the approach could be better articulated.', 'The results, while competitive, do not consistently outperform state-of-the-art methods across all datasets, raising questions about the significance of the contributions.', 'The paper does not sufficiently articulate the practical implications or advantages of the proposed mistake-driven training approach over more traditional methods.', 'There is insufficient discussion on the limitations of the proposed methods or potential negative impacts of using GANs.']",3,3,3,4,Reject
nhN-fqxmNGx,The paper compares Lasso with five other variable selection methods based on expected Hamming error in high-dimensional linear regression settings. The authors derive theoretical convergence rates and present phase diagrams to illustrate the performance of each method under specific assumptions about the regression coefficients and design matrix.,"['Can the authors clarify the practical implications of their findings?', 'What specific contributions does this paper make over existing literature on variable selection methods?', 'Can the authors elaborate on the assumptions made in the theoretical framework and their implications for the results?']","['The theoretical analysis may not hold in practical scenarios where the assumptions are violated.', 'Insufficient clarity and depth in discussions may hinder readers from fully grasping the results and their implications.']",False,2,2,2,4,4,"['Addresses a critical issue in high-dimensional statistics: variable selection, which is particularly relevant in fields such as genomics and finance.', 'Provides a theoretical analysis of Hamming errors, enhancing the understanding of the performance of various variable selection methods.', 'Effectively utilizes phase diagrams to visualize and compare the performance of different methods, aiding in the interpretation of results.']","['The clarity and organization of the paper are lacking; the presentation of results is convoluted and may confuse readers.', 'The novelty of the contributions is limited, as the paper primarily compares established methods without introducing significant new insights.', 'Practical implications of the theoretical results are not well articulated, leaving readers uncertain about how to apply the findings in real-world scenarios.', 'The theoretical framework relies on specific assumptions that are not adequately justified, which may limit the applicability of the results.']",2,2,2,3,Reject
mRc_t2b3l1-,"This paper investigates the limiting dynamics of deep neural networks trained with stochastic gradient descent (SGD), focusing on anomalous diffusion in parameter space. The authors derive a continuous-time model represented as an underdamped Langevin equation and explore its implications through the lens of statistical physics. The paper aims to explain the interactions between optimization hyperparameters, gradient noise structure, and the Hessian matrix, proposing a modified loss function that governs the limiting dynamics of trained networks.","['Can the authors provide more empirical evidence to support the theoretical claims?', 'Could certain sections be simplified or clarified for better comprehension?', 'How do the proposed dynamics directly influence practical training strategies?', 'Can the authors clarify how their theoretical contributions differ significantly from existing works in the field?']","['The paper lacks robust empirical validation, which may undermine the theoretical claims presented.', 'Dense mathematical presentation may hinder understanding for a broader audience.', 'The reliance on theoretical assumptions that may not universally apply across different model architectures or training scenarios needs to be addressed more thoroughly.']",False,3,2,3,5,4,"['Addresses a significant and complex issue in the dynamics of neural network training, focusing on anomalous diffusion.', 'Utilizes theoretical concepts from statistical physics to derive insights into the dynamics of SGD, potentially advancing the understanding of training processes.', 'Theoretically rigorous approach with well-defined assumptions and derived equations.']","[""The paper's presentation is dense and may be difficult for readers not well-versed in the mathematical background."", 'The empirical validation of the theoretical predictions is limited, and the experiments could be more comprehensive to establish practical applicability.', 'Some sections lack clarity and could benefit from more intuitive explanations.', 'The originality of the contributions is not sufficiently highlighted, as the paper heavily references existing literature without clear differentiation.']",3,3,2,3,Reject
-3Qj7Jl6UP5,"The paper investigates the application of magnitude vectors, a concept from metric spaces, to image processing tasks such as edge detection and adversarial robustness. It proposes a novel computational algorithm for efficiently calculating magnitude vectors, aiming to reduce computational costs. However, the theoretical foundations are not rigorously established, and empirical results are limited.","['Can the authors provide more rigorous theoretical foundations for the claims made in the paper?', 'What specific experiments were conducted to validate the edge detection and adversarial robustness claims, and what were the parameters used?', 'Could the authors clarify the differences between their approach and existing methods in the related work?']","['The lack of rigorous theoretical backing and comprehensive experiments significantly limits the impact of the findings.', 'The paper does not adequately address the limitations of the proposed methods, particularly regarding their applicability to various image types.']",False,2,2,3,4,4,"['The introduction of magnitude vectors is a novel theoretical approach that connects mathematical concepts with practical image processing tasks.', 'The proposed algorithm for efficient computation of magnitude vectors addresses a significant computational bottleneck.', 'The potential applications in edge detection and adversarial robustness are relevant and timely in the machine learning landscape.']","['The theoretical framework lacks rigorous proofs for many claims, raising concerns about the validity of the results.', 'Empirical evaluations are insufficiently rigorous, lacking comprehensive testing against baseline methods.', 'The clarity of the writing is inconsistent, making it difficult for readers to understand the significance of the findings.', 'The related work section is underdeveloped and does not adequately contextualize the proposed work within existing literature.']",3,2,2,4,Reject
alaQzRbCY9w,The paper proposes a new optimization algorithm called Stochastic Model Building (SMB) to enhance Stochastic Gradient Descent (SGD) by using a model building strategy that incorporates second-order information. It presents convergence rate analysis and experimental results demonstrating improved performance over existing methods.,"['Can the authors clarify the innovations that distinguish SMB from existing stochastic optimization methods?', 'What measures will be taken to improve the clarity of the paper in its current form?']","['The clarity of the paper needs significant improvement to facilitate understanding of the proposed method.', ""Lack of robust experimental comparisons with a broader set of optimization algorithms limits the paper's impact.""]",False,2,2,2,4,4,"['The proposed SMB algorithm introduces a novel approach to adjusting both the stepsize and search direction in SGD, which could lead to improvements in convergence rates.', 'The paper provides a convergence analysis for the SMB algorithm, which is a valuable contribution to the understanding of its behavior.', 'Experimental results show that SMB performs better than traditional SGD and Adam on certain datasets, indicating potential practical applications.']","['The paper lacks clarity in various sections, making it difficult to follow the proposed methodology and the reasoning behind certain decisions.', 'The originality of the contributions is questionable, as several existing methods already address similar problems using adaptive learning rates and model building.', 'The experiments do not provide enough comparative analysis against a wider range of state-of-the-art optimization methods, limiting the robustness of the claims.', 'The convergence analysis is not sufficiently rigorous and does not convincingly demonstrate that SMB significantly outperforms existing methods in a clear and practical manner.']",2,2,2,3,Reject
TKrlyiqKWB,"The paper introduces the Concept Subspace Network (CSN), a neural network architecture aimed at unifying classification tasks, specifically targeting fair and hierarchical classification. The authors claim that CSNs generalize existing specialized classifiers, enabling a model to learn multiple concept relationships simultaneously. However, the experimental results and theoretical foundations are not sufficiently convincing.","['Can the authors clarify the theoretical advantages of CSNs over existing models?', 'What specific improvements in performance can be attributed to the unique aspects of the CSN architecture?']","['The lack of clarity in the paper makes it difficult to assess the actual contributions and practical implications of the proposed method.', 'The potential ethical implications of deploying CSNs in sensitive classification scenarios, such as bias reinforcement, are not adequately addressed.']",True,2,2,3,4,4,"['The concept of combining fairness and hierarchical classification in a single architecture is novel and addresses a relevant issue in machine learning.', 'The use of prototype-based representations aligns with current trends in interpretable machine learning, potentially enhancing model transparency and usability.']","['The paper lacks clarity in explaining the architecture and how it significantly improves upon existing models. Many aspects appear to be under-explained.', 'The experimental results do not convincingly demonstrate that CSNs outperform state-of-the-art methods in meaningful ways. Comparisons are often vague or lack sufficient detail.', ""The paper fails to provide a strong theoretical foundation for the claims made about the CSN's capabilities and advantages.""]",3,2,2,4,Reject
w8HXzn2FyKm,"The paper introduces a distributed linear stochastic approximation algorithm that operates under uni-directional communication constraints among agents, moving away from the traditional assumption of bi-directional communication. The authors derive finite-time bounds on the mean-square error for their proposed method, representing a significant contribution to the field of distributed reinforcement learning.","['Can the authors provide a clearer explanation of the implications of their results?', 'What are the practical limitations or challenges in implementing the proposed algorithm in real-world scenarios?']","['The paper does not adequately discuss how the uni-directional communication impacts the robustness of the algorithm in practical situations.', 'The assumptions made regarding the stochastic matrices may limit the applicability of the results.']",False,3,2,3,6,4,"['Addresses a relevant and practical issue in distributed reinforcement learning by considering uni-directional communication, which is a common scenario in real-world applications.', 'Provides finite-time error bounds, which enhance the understanding of the algorithm’s performance.', 'Theoretical contributions build on and extend existing work, potentially benefiting future research in distributed algorithms.']","['The presentation is dense and lacks clarity, making it challenging to follow the key contributions and implications of the results.', 'Important definitions and assumptions are not sufficiently highlighted, which may confuse readers unfamiliar with the background.', 'The paper does not adequately discuss the limitations of the proposed approach, particularly in relation to practical implementations.']",3,3,2,4,Reject
e-JV6H8lwpl,"The paper proposes a novel nonlinear system identification method that utilizes a neural network with a bottleneck layer to create a state estimator and predictor for model predictive control (MPC). The authors claim that their method extends the subspace identification techniques used in linear systems to nonlinear systems, providing a theoretical foundation and interpretability based on linear control theory.","['Can the authors provide more details on the training process of the neural network and the selection criteria for the hyperparameters?', 'How do the authors plan to scale their approach to more complex, high-dimensional systems in practical applications?', 'Could you clarify how the bottleneck layer specifically enhances the interpretability of the model?', 'What additional experiments could be conducted to validate the robustness of the proposed method across different types of nonlinear systems?']","['The paper does not sufficiently address the limitations of using neural networks in this context, particularly regarding overfitting and generalization.', 'The clarity of the paper significantly hampers its impact, and the lack of comprehensive experimental validation raises concerns about the practical applicability of the proposed method.']",False,2,2,2,4,3,"['The integration of deep learning with traditional system identification methods offers a fresh perspective.', 'The theoretical foundation based on observability and the analogy with subspace methods provides potential avenues for interpretability.', ""The illustrative example of a cascaded tanks system effectively demonstrates the proposed method's functionality and its application in MPC.""]","['The methodology lacks clarity, particularly in detailing the neural network architecture and training process.', 'The experimental evaluation appears limited; more extensive tests could strengthen the conclusions drawn from the results.', 'The connection to existing literature could be better articulated, and the novelty of the approach is not convincingly justified.', 'The writing is dense, making it challenging to discern the main contributions and results.']",3,2,2,4,Reject
ZWykq5n4zx,"The paper investigates high probability generalization bounds for uniformly stable randomized algorithms, particularly focusing on stochastic gradient descent (SGD) with time-decaying learning rates. It introduces a confidence-boosting technique that establishes near-tight bounds by leveraging a subbagging process, aiming to improve the understanding and performance of such algorithms in terms of generalization.","['Could the authors clarify the implications of their assumptions on the generalization bounds? How do these assumptions affect their conclusions?', 'What additional empirical results could be included to demonstrate the practical effectiveness of the proposed method?']","['The clarity and organization of the paper could be improved to make it more accessible.', 'The empirical evidence provided is limited; more extensive experiments would enhance the reliability of the results.']",False,3,3,3,6,4,"['Addresses a crucial gap regarding high probability generalization bounds for randomized algorithms, specifically SGD.', 'Introduces a novel confidence-boosting technique that enhances the understanding and application of generalization in machine learning.', 'Theoretical results are well-founded and substantially improve upon existing works.']","['The presentation is dense, with some sections lacking clarity that could hinder understanding for readers less familiar with the concepts.', 'Empirical validation is limited; more experiments would strengthen the claims and demonstrate the practical effectiveness of the proposed method.', 'Some theoretical claims may benefit from further clarification, particularly regarding assumptions and implications.']",3,3,3,4,Reject
3mgYqlH60Uj,The paper proposes a reinforcement learning model for generating locomotion in simulated characters by incorporating a Normalized Cumulative Fatigue (NCF) model. This approach aims to improve the naturalness and symmetry of the generated movements without relying on motion capture data or additional hyperparameter tuning.,"['Can the authors provide more details on how the NCF model is validated against existing methods?', 'What specific improvements in performance metrics can be attributed directly to the NCF model versus other components?', 'Could the authors clarify the choice of evaluation metrics and their relevance to the claims made?']","['The implications of the NCF model in diverse environments are not fully explored, which may limit its applicability.', 'Potential biases in the experimental setup could affect the generalizability of the results.', 'Improving the clarity of the methodology and results would facilitate better comprehension and replication of the study.']",False,2,2,3,4,4,"['Addresses a significant problem in biomechanical modeling related to reinforcement learning and locomotion.', 'Introduces a novel fatigue-based reward mechanism that enhances the naturalness of locomotion patterns.', 'Demonstrates improved symmetry and robustness in locomotion tasks compared to existing methods.']","['The explanation of the NCF model and its implementation lacks clarity, which may hinder reproducibility.', 'Experimental comparisons against state-of-the-art methods are limited; broader benchmarks would strengthen the findings.', 'Ablation studies are insufficient, making it challenging to evaluate the effectiveness of individual components.']",3,2,2,3,Reject
z7p2V6KROOV,"The paper presents WILDS 2.0, an extension of the WILDS benchmark that includes curated unlabeled data for eight datasets. It aims to evaluate the effectiveness of various unsupervised adaptation methods in mitigating distribution shifts. While the motivation is strong, the evaluation reveals limited success across methods, suggesting challenges in leveraging unlabeled data effectively.","['What specific recommendations can be made for improving method performance in the context of WILDS 2.0?', 'Could you elaborate on any strategies that may enhance the use of unlabeled data in future studies?', 'Can the authors clarify why many methods underperformed despite the extensive hyperparameter tuning?']","['The limited success of many methods on the new benchmark necessitates a deeper exploration of why these methods struggled, which is not sufficiently discussed.', 'The paper does not explore the potential biases or limitations in the unlabeled data that could affect model training.']",False,3,3,3,6,4,"['The paper addresses a critical issue in machine learning regarding distribution shifts and the availability of unlabeled data.', 'The extension of the WILDS benchmark to include unlabeled data is a significant contribution, offering a new avenue for research in unsupervised adaptation.', 'The comprehensive dataset spans various tasks and modalities, enhancing the relevance and applicability of the benchmark.']","['Despite the introduction of unlabeled data, the evaluation results show that many methods, such as Pseudo-Label and FixMatch, fail to outperform standard supervised training, raising questions about the effectiveness of leveraging unlabeled data.', 'There is limited discussion on the potential reasons for the poor performance of the evaluated methods, which could provide valuable insights for future research.', 'The paper could benefit from a more detailed analysis of the conditions under which unlabeled data might be useful, guiding practitioners in deploying these methods.']",3,3,4,4,Reject
3Li0OPkhQU,"The paper investigates a semi-supervised learning algorithm for Convolutional Neural Networks (CNNs) that utilizes data-dependent features from unlabeled data. It provides theoretical guarantees under specific distributional assumptions about image patches, aiming to demonstrate the algorithm's efficiency in learning CNNs. The authors complement their theoretical analysis with empirical results on standard datasets such as MNIST and FMNIST.","['Can the authors clarify the implications of their theoretical findings for practical applications?', 'What strategies could be employed to relax the distributional assumptions without significantly impacting performance?']","[""The clarity of the paper is a major concern, which may hinder readers' understanding and the overall impact of the work."", 'The empirical evaluation lacks sufficient depth and variety in the datasets used, which may not adequately demonstrate the effectiveness of the proposed method.']",False,2,2,3,4,4,"['The theoretical framework presents a novel perspective on the learnability of CNNs under specific distributional assumptions.', 'The paper contributes to the understanding of the relationship between low-dimensional structures in data and the learnability of neural networks.', ""The inclusion of theoretical guarantees and lower bounds provides valuable insights into the algorithm's limitations.""]","['The empirical validation is limited and does not convincingly demonstrate an advantage over existing methods.', 'The reliance on restrictive distributional assumptions may limit the applicability of the proposed algorithm to real-world scenarios.', 'The clarity of the writing is inconsistent, making it challenging for readers to follow the theoretical developments.']",3,3,3,4,Reject
D1TYemnoRN,"The paper proposes a framework that connects optimization path lengths after convergence with generalization performance in machine learning. It argues that shorter paths indicate better generalization and provides theoretical results across various models, establishing bounds based on the length of the optimization trajectory.","['Can the authors clarify the implications of their findings with more intuitive examples or visualizations?', 'What specific improvements to clarity can be made in the presentation of the theoretical proofs?']","['The paper does not adequately address the limitations of the proposed framework in practical settings, which could affect its applicability.', 'The lack of clarity may lead to misunderstanding the significance of the results, especially for non-expert readers.']",False,2,2,3,4,4,"['The paper addresses a relevant and important issue in machine learning by correlating optimization and generalization.', 'The introduction of a length-based generalization bound is a novel approach that could have significant implications for understanding model behavior.', ""The theoretical results are well-supported and applicable to multiple machine learning models, enhancing the paper's relevance.""]","['The paper lacks clarity, making it challenging to follow the theoretical developments and their implications.', 'Some sections are overly dense with information, which could benefit from clearer explanations and more intuitive presentations.', 'The experimental section, while present, does not provide enough detail on the methodologies used to validate the theoretical claims, limiting reproducibility.']",3,2,2,3,Reject
CVfLvQq9gLo,"The paper presents ARTEMIS, a novel image retrieval method that utilizes both image and text queries through a dual-module framework, focusing on Explicit Matching (EM) and Implicit Similarity (IS). The authors claim to achieve state-of-the-art performance while maintaining computational efficiency across multiple datasets.","['Could the authors clarify the design choices for the attention mechanisms in both modules?', 'What specific steps were taken to ensure the effectiveness of the proposed model compared to existing methods?', 'Can you provide more details on the ablation studies conducted to validate the contributions of each module?']","['The clarity of the paper is a concern, particularly regarding the novel contributions and design choices.', 'The impact of the proposed method in practical applications, such as real-time image retrieval, is not addressed.']",False,3,3,3,6,4,"['The paper addresses a relevant and practical problem in image retrieval by combining visual and textual queries.', 'The proposed dual-module approach is innovative and could lead to more nuanced retrieval results.', 'The experimental validation demonstrates competitive performance on several datasets.']","['The originality of the proposed method is questionable as it builds on existing techniques without significant novelty.', 'The attention mechanisms and their implementation are not sufficiently detailed, raising concerns about their effectiveness.', 'The paper lacks comprehensive ablation studies and qualitative analyses to support the claims made.']",3,3,3,4,Reject
xRK8xgFuiu,"The paper proposes a novel algorithm for causal discovery based on Cholesky factorization of covariance matrices, claiming improvements in time and sample complexity over existing methods. The algorithm is said to recover the directed acyclic graph (DAG) structure efficiently and achieves state-of-the-art performance on synthetic and real-world datasets.","[""Could the authors clarify the specific assumptions made about the noise and their implications for the algorithm's applicability?"", 'What additional experiments could be conducted to further validate the robustness of the algorithm under different conditions?', ""Could the authors provide more detailed explanations of the algorithm's components and their significance in the overall process?""]","['The paper does not adequately address the limitations of the proposed algorithm, particularly regarding the assumptions made.', ""The clarity and completeness of the algorithm's description could hinder reproducibility.""]",False,2,2,2,4,4,"['The use of Cholesky factorization for causal discovery is innovative and offers significant computational advantages, potentially making it applicable to larger datasets.', 'The theoretical guarantees for exact DAG recovery under specific assumptions are well-articulated, providing a solid foundation for the proposed method.', 'Experimental results demonstrate that the algorithm is significantly faster than previous methods while achieving competitive performance on various datasets.']","[""The clarity of the algorithm's description and implementation details is insufficient, making it challenging for readers to fully understand the proposed method and its application."", ""The assumptions made regarding noise and their implications for the algorithm's applicability need to be discussed in greater detail to assess the method's robustness."", 'There is a lack of comprehensive ablation studies to validate the contributions of various components of the algorithm, which would strengthen the claims made.', 'The originality of the contribution is somewhat diminished by its reliance on established methods from existing literature, which should be acknowledged more explicitly.']",2,2,2,3,Reject
T_uSMSAlgoy,"The paper investigates latent holes in Variational Autoencoders (VAEs) and proposes a Tree-based Decoder-Centric (TDC) algorithm for identifying these holes, particularly in the context of text generation. It includes empirical analysis of the impact of latent holes on VAE performance.","['What specific improvements does TDC offer compared to existing methods?', 'Can the authors clarify the empirical results and provide stronger comparisons to existing literature?']","['Insufficient empirical validation of the TDC algorithm compared to existing latent hole detection methods.', ""Clarity issues in writing that hinder the reader's understanding of the methodology and results.""]",False,2,2,2,4,4,"['Addresses an important issue in VAEs related to latent holes, which can significantly affect model performance.', 'Proposes a novel algorithm (TDC) that focuses on the decoder, which is crucial for text generation tasks.', 'Provides empirical analysis and experiments on multiple datasets, demonstrating the relevance of the findings.']","['The empirical analysis lacks depth and does not provide sufficient comparison against existing methods, limiting the impact of the findings.', 'The clarity of the writing is poor; the methodology and results are not clearly articulated, making it difficult for readers to follow.', 'The contributions of the paper could be more clearly distinguished from existing literature, as some findings reiterate known issues without offering new insights.']",3,2,2,4,Reject
SN2bkl9f69,"The paper proposes MSMT-GAN, a novel architecture for text-to-image synthesis that introduces a Multi-Tailed Word-level Initial Generation stage and a Spatial Dynamic Memory module to improve image generation quality. It aims to address limitations in existing methods and demonstrates competitive performance on benchmark datasets CUB and COCO.","['Can the authors clarify how their method significantly differs from existing text-to-image synthesis techniques?', 'Could the authors provide more detailed ablation studies to substantiate the performance improvements claimed?']","['The paper lacks thorough discussions on the limitations of the proposed method, particularly in terms of computational efficiency and scalability.', 'Potential negative societal impacts of generating realistic images from text descriptions are not addressed.']",False,3,3,4,6,4,"['The proposed architecture addresses significant limitations in existing text-to-image synthesis methods, particularly in separating image attributes.', 'The introduction of a Multi-Tailed Word-level Initial Generation stage allows for better contextualization of image features based on text input.', 'Demonstrated competitive performance against state-of-the-art methods on benchmark datasets, indicating the effectiveness of the proposed approach.']","['The clarity of the methodology and results needs improvement; specific technical details, such as the workings of the Spatial Dynamic Memory module, are not clearly explained.', 'Insufficient ablation studies to validate the effectiveness of individual components; more in-depth analysis is needed to support the claims.', 'The originality of the contributions could be better articulated, as they build upon existing techniques without sufficient distinction.']",4,3,3,4,Reject
6ya8C6sCiD,"The paper explores emergent communication in multi-agent systems through a proposed method called symbolic mapping, which helps agents learn a compositional and symmetric language by starting with simple tasks and progressing to more complex ones. The authors argue that this gradual approach aids language learning, and they provide experimental results demonstrating the effectiveness of symbolic mapping.","['Can the authors clarify the implementation details of the symbolic mapping architecture?', 'How do the authors ensure that the improvements observed are not due to other factors already established in the literature?', 'What specific prior works inspired the concept of symbolic mapping, and how does this work differentiate itself?']","['The paper lacks a thorough discussion on potential limitations and future work, particularly regarding the scalability of the proposed approach.', 'The effectiveness of symbolic mapping in facilitating language learning should be more thoroughly evaluated against established methods.']",False,2,2,2,5,4,"['Addresses a relevant and interesting problem in emergent communication in multi-agent systems.', 'Introduces the novel concept of symbolic mapping, which provides a new approach to understanding language learning in agents.', 'Experimental results suggest that the proposed method has potential benefits for language learning in complex tasks.']","['Lacks clarity in the presentation of methodology and experimental setup, making it difficult to reproduce results.', 'The novelty of the proposed approach is questionable as similar concepts have been explored in the literature.', 'The experimental results do not convincingly demonstrate a significant advantage over existing methods.', 'The paper does not adequately address potential limitations in the generalizability of the findings, particularly in more complex environments.']",3,2,2,3,Reject
1gEb_H1DEqZ,"The paper introduces PROPHET, a pre-trained language model aimed at enhancing logical reasoning in natural language understanding through fact-based representations and three novel pre-training tasks. This approach seeks to improve the model's ability to capture logical relationships compared to traditional methods.","['Can the authors clarify the process of constructing the logical graphs and provide examples?', 'How do the introduced pre-training tasks compare to existing tasks in terms of effectiveness and novelty?', 'Could the authors provide additional experimental results or comparisons to strengthen their claims?']","[""The paper's clarity and rigor need improvement, particularly in methodology and experimental evaluations."", 'The potential impact of the proposed model is not fully substantiated due to the lack of comprehensive comparisons and analyses.']",False,3,2,3,5,4,"['Addresses a significant challenge in NLP by integrating logical reasoning capabilities into pre-trained language models.', 'The introduction of fact-based representations is an innovative approach that may enhance contextual understanding.', 'Experimental results demonstrate improvements across various benchmark tasks, indicating the effectiveness of the proposed methods.']","['The methodology lacks clarity, particularly regarding the construction of logical graphs and the implementation of pre-training tasks, necessitating more detailed explanations.', 'The novelty of the proposed tasks is questionable, as similar techniques have been explored in prior work without a specific focus on logical reasoning.', 'The experimental evaluation is limited and could benefit from more thorough comparisons with existing models and methods.']",3,3,2,3,Reject
qyTBxTztIpQ,"The paper presents CrowdPlay, a framework for crowdsourcing human demonstrations for offline learning in reinforcement learning, specifically in Atari 2600 games. It aims to support the collection of diverse human gameplay data to advance imitation learning and offline RL research. The authors provide a substantial dataset and benchmarks but lack depth in methodology and evaluation compared to existing datasets and techniques.","['Can the authors provide more details about the data collection process, specifically how the incentive structures were designed?', 'What measures were taken to ensure the quality of the collected data, and how did participant motivation affect the results?', 'Could the authors clarify how the benchmarks were chosen and how they specifically relate to the effectiveness of the proposed framework?']","['The paper does not adequately address potential biases in the data collection process or the implications of using crowdsourced data for RL research.', 'There is a lack of quantitative analysis comparing the performance of offline learning algorithms on the new dataset versus existing datasets.']",False,2,2,2,4,4,"['The concept of using crowdsourcing to generate human demonstration data for offline learning is novel and relevant.', 'The dataset created is substantial, with over 250 hours of gameplay and diverse participant recruitment strategies.', 'The integration of real-time feedback and incentive structures is a noteworthy feature that could improve data quality.']","['The methodology lacks clarity in certain areas, particularly in how the data collection process was structured and the specific roles of different recruitment channels.', 'The evaluation of the effectiveness of the proposed framework and its benchmarks is insufficiently rigorous, with limited analysis of the results and comparisons to existing datasets.', 'Concerns about the quality and diversity of the data collected, especially regarding the incentive structures and their impact on participant behavior, are not adequately addressed.']",3,2,2,3,Reject
hxitw01k_Ql,"The paper investigates how different memory architectures affect learning in partially observable Markov decision processes (POMDPs), specifically comparing random access memory (RAM) and a constrained memory design. It presents theoretical and empirical results suggesting that constrained memory can lead to better learning outcomes, particularly in a two-hypothesis testing problem.","['Could the authors clarify the specific contributions that distinguish this work from previous studies on memory in reinforcement learning?', 'Can the authors provide more insight into how these findings could impact applications in real-world settings?']","['The paper does not adequately address the limitations of the proposed methods or their applicability to more complex scenarios.', 'There is a need for clearer explanations of the theoretical results and their relevance to practical implementations.']",False,2,2,2,4,4,"['Addresses a significant issue in reinforcement learning related to memory architectures in POMDPs.', 'Provides relevant comparisons between different memory architectures, offering insights into their impact on learning.', 'Empirical results indicate potential advantages of constrained memory architectures.']","['The presentation lacks clarity, making it difficult to follow the rationale and key arguments.', 'The contributions, while relevant, do not significantly advance the state of the art in the field.', ""The theoretical claims require stronger support, and empirical results do not convincingly demonstrate the proposed methods' superiority.""]",2,2,2,3,Reject
RftryyYyjiG,"The paper proposes a method for extreme parameter compression of pre-trained language models (PLMs) using tensor decomposition. The authors introduce a framework that applies various decomposition techniques to reduce model size while maintaining performance on the GLUE benchmark, showing that their compressed models achieve competitive results with significantly fewer parameters.","['Could the authors clarify the specific tensor decomposition methods used and their advantages?', 'How does the proposed method compare in terms of efficiency and performance with other established compression techniques?', 'Can the authors provide more details on the experimental setup and results to strengthen the claims made in the paper?', 'What limitations do the authors foresee in applying their approach to other architectures or tasks beyond BERT?']","['The paper does not adequately address the limitations of the proposed method, particularly regarding the trade-offs between compression and model interpretability.', 'The authors do not sufficiently discuss the limitations of their proposed methods, particularly in terms of how well they generalize to other architectures or tasks beyond BERT.']",False,2,2,2,4,3,"['The proposed approach demonstrates a high compression ratio while maintaining competitive performance on the GLUE benchmark.', 'The use of tensor decomposition to exploit parameter redundancy in PLMs is a novel contribution that adds value to the compression literature.', 'The experiments indicate that the proposed method can lead to faster inference times.']","['The paper lacks clarity in explaining certain concepts, particularly around the mathematical formulations and the rationale behind some choices.', 'There is insufficient comparison with existing compression techniques, which makes it difficult to fully assess the benefits of the proposed method.', 'Some experimental details are vague, such as the training process and specific configurations of the models tested.', 'The originality of the contributions is questionable as the paper does not sufficiently differentiate its approach from existing compression techniques.']",2,2,2,3,Reject
jNB6vfl_680,"The paper proposes a simple yet effective pruning technique using global magnitude pruning (GP) combined with a minimum threshold (MT) to avoid over-pruning in neural networks. The authors claim that this approach achieves state-of-the-art performance across various architectures and datasets, notably ResNet-50 and MobileNet-V1 on ImageNet.","['Can the authors elaborate on the novelty of their pruning method compared to existing techniques?', 'What specific advantages does the proposed method have over more complex pruning techniques?', 'Could the authors provide more details on the implementation of the minimum threshold (MT) and its effects across different architectures?']","[""The reliance on a previously established method (GP) may undermine the paper's contributions."", 'Lack of thorough comparative analysis with state-of-the-art methods diminishes the impact of the findings.']",False,3,3,3,5,4,"['The paper addresses an important topic in neural network optimization, specifically pruning methods.', 'The introduction of a minimum threshold (MT) alongside global magnitude pruning (GP) provides a practical solution to the issue of over-pruning.', 'The experimental results show improvements in performance and accuracy on popular benchmark datasets.']","['The approach heavily relies on global magnitude pruning, which has been previously established as a baseline technique, raising questions about the originality of the contribution.', 'The paper does not sufficiently explore or compare its approach with more complex and established pruning methods.', 'Descriptions of the methodology, particularly regarding the implementation and evaluation of the minimum threshold, are vague.', 'The experimental setup lacks diversity in datasets and architectures.']",3,3,3,3,Reject
Ih0iJBSy4eq,"The paper investigates the use of reinforcement learning to find Stackelberg-Nash equilibria in general-sum Markov games, focusing on leader-follower dynamics. It proposes algorithms for both online and offline settings, claiming provable sample efficiency. While the theoretical contributions are significant, the paper suffers from clarity issues and limited empirical validation.","['How do the proposed algorithms compare with existing methods in terms of practical performance?', 'Can the authors provide additional empirical evaluations to validate their effectiveness?']","['The theoretical contributions may not translate into practical improvements without further empirical validation.', 'The clarity of the paper may hinder its accessibility to a broader audience.']",False,3,2,3,5,4,"['Addresses a relevant and important problem in multi-agent systems and reinforcement learning.', 'Proposes novel algorithms with theoretical guarantees, contributing to the literature on Stackelberg-Nash equilibria.', 'The distinction between online and offline settings is commendable.']","[""The clarity of the exposition is lacking; key concepts such as the leader-follower dynamics and the algorithms' mechanisms are not well-defined, making it difficult for readers to grasp the methodology."", 'The experimental validation is limited, with insufficient comparisons to existing methods, which undermines the claims of efficiency. More diverse scenarios and baselines would strengthen the results.', 'The theoretical analysis, while promising, requires more rigorous substantiation to ensure practical applicability.']",3,2,2,4,Reject
N0n_QyQ5lBF,"The paper introduces unsupervised vision-language (VL) grammar induction as a new task, proposing a model called CLIORA that constructs a shared hierarchical structure for images and language. The model employs context-dependent semantics and fine-grained alignment to address challenges in multimodal information processing. CLIORA demonstrates improvements on the Flickr30k Entities dataset and introduces a new evaluation metric, Critical Concept Recall Rate (CCRR), for assessing performance.","['Could you provide a clearer breakdown of how the different components of CLIORA interact?', 'How does the proposed task of VL grammar induction differ significantly from existing grammar induction tasks?', 'Can the authors clarify how CCRR is validated against existing metrics?']","[""The paper could benefit from clearer explanations of the model's components and their roles in the overall framework."", 'The novelty of the task may be limited as it builds on existing concepts in grammar induction without substantial innovations.']",False,2,2,3,4,4,"['The introduction of the unsupervised VL grammar induction task is a timely and relevant contribution to the field.', 'The proposed CLIORA model showcases a novel approach to integrating visual and textual information through a shared hierarchical structure.', ""The introduction of a new evaluation metric (CCRR) allows for a better assessment of the proposed method's performance.""]","['The clarity of the methodology is lacking; the interactions between different components of the model are not sufficiently explained, which may hinder reproducibility.', 'The task of VL grammar induction, while interesting, does not significantly depart from existing works in grammar induction, potentially limiting its originality.', 'The experimental results, while showing improvements, may need more rigorous statistical validation and ablation studies to support the claims.']",3,2,2,4,Reject
HiHWMiLP035,"The paper proposes E[2]CM, a novel early exit mechanism based on class means for improving computational efficiency in neural networks, particularly for deployment on low-power devices. It claims to achieve higher accuracy and lower computational cost compared to existing methods, without requiring gradient-based training of internal classifiers.","['Can the authors provide more detailed comparisons with existing early exit techniques? How does E[2]CM differ from previous approaches?', 'What specific empirical results support the claims of improved performance?', 'Could the authors clarify the training process and how class means are computed without introducing additional computational overhead?']","['The paper does not clearly articulate the limitations of E[2]CM, particularly in scenarios where class distributions are imbalanced or where data is noisy.', 'The lack of robust experimental evidence raises concerns about the validity of the claims made in the paper.']",False,2,2,2,4,4,"['Addresses the relevant problem of computational efficiency in deep learning, especially for edge devices.', 'Introduces a novel approach that does not require gradient-based training, potentially making it easier to deploy.', 'Claims to outperform existing early exit mechanisms in terms of accuracy and efficiency.']","['Lacks clarity in the description of the methodology, making it difficult to understand how E[2]CM operates.', 'Experimental validation appears limited; more diverse datasets and comparisons with existing methods are needed.', 'Claims of superiority over existing methods are not well-supported by rigorous comparative analysis.', 'The originality of the contribution is questionable, as similar concepts may exist in the literature without sufficient differentiation.']",3,2,2,3,Reject
GQd7mXSPua,"The paper proposes a meta-learning framework for uncertainty estimation and out-of-distribution detection by learning class-specific covariance matrices through an attentive set encoder. It aims to improve predictive distributions under dataset shifts using an energy-based inference process. While the topic is relevant, the execution and clarity of the paper have significant room for improvement.","['Can the authors clarify the methodology, particularly around the formulation of the covariance matrices?', 'What specific contributions does this work provide compared to existing methods?', 'Could the authors elaborate more on the experimental setup and the rationale behind the chosen metrics?']","['The paper does not adequately address its limitations or potential negative impacts, particularly in the context of deployment in real-world applications.', 'The clarity of the paper is a significant limitation, making it challenging for readers to understand the proposed framework and its contributions.']",False,2,2,3,4,4,"['Addresses a significant problem in deep learning regarding uncertainty calibration and OOD detection.', 'Introduces the concept of meta-learning class-specific covariance matrices, which is a novel approach.', 'Includes experimental validation on benchmark datasets, showcasing the potential benefits of the proposed method.']","['The paper lacks clarity in explaining the methodology, making it difficult for readers to follow the proposed approach.', 'The experimental section is underdeveloped, with results presented but lacking sufficient analysis and interpretation.', 'The claims regarding the novelty and effectiveness of the method are not adequately backed by thorough comparisons against existing methods.', 'There are inconsistencies in terminology, and some equations are not well defined, which affects comprehension.']",3,2,2,4,Reject
vr39r4Rjt3z,"The paper proposes two architectural modifications, Masked Highway Connection (MHC) and Layer-Wise Normalisation (LWN), aimed at reducing catastrophic forgetting in continual learning. The authors claim that these modifications allow neural networks to retain knowledge from previous tasks when learning new ones, without requiring external memory or additional parameters. The results show that these modifications can achieve competitive performance with existing methods.","['Could you clarify how the proposed methods are different from standard highway connections and layer normalisation?', 'Can you provide more detail on the exact implementation of MHC and LWN, particularly how they interact with existing continual learning methods?', 'Could you include additional results or scenarios in the experiments to strengthen the claims?', 'What are the potential drawbacks of using MHC and LWN in practical applications, particularly in terms of computational complexity or memory usage?']","['The potential limitations of the proposed methods in complex scenarios or with varying task distributions are not adequately addressed.', 'The paper does not sufficiently explore the trade-offs between the proposed internal methods and traditional external continual learning strategies.']",False,3,2,3,5,4,"['The approach introduces novel architectural modifications that address a significant problem in continual learning: catastrophic forgetting.', 'The experimental results demonstrate that the proposed methods can achieve competitive results compared to existing techniques and can be integrated with them to further enhance performance.', 'The paper presents a clear motivation for the proposed modifications based on the stability-plasticity dilemma.']","['The clarity of the paper could be improved; some sections are dense and contain jargon that may not be accessible to all readers.', 'The description of the MHC and LWN methods lacks sufficient detail on their implementation and their differences compared to existing techniques.', 'Experimental results, while promising, do not provide enough diverse scenarios to fully validate the robustness of the methods across different contexts.', 'The theoretical justification for MHC and LWN could be strengthened; the paper assumes their effectiveness without a deep investigation into the underlying mechanics.']",3,3,2,4,Reject
EhYjZy6e1gJ,"The paper presents PiCO, a novel framework for partial label learning that integrates contrastive learning with prototype-based label disambiguation. It effectively addresses the challenges of representation learning and label ambiguity, demonstrating significant performance improvements over existing methods and achieving results comparable to fully supervised learning.","['Could the authors clarify the integration process of contrastive learning and label disambiguation in PiCO?', 'Can the authors provide more details on the ablation studies to substantiate claims about the contributions of each component?']","['The paper lacks clarity in some parts of the methodology, which may hinder reproducibility.', 'While the empirical results are promising, the paper does not sufficiently discuss the limitations of the proposed approach.']",False,3,3,3,6,4,"['Innovative integration of contrastive learning with partial label learning, addressing a relevant problem.', 'Strong empirical results showing state-of-the-art performance on multiple benchmark datasets.', 'Theoretical insights linking the method to the Expectation-Maximization algorithm.']","['Lack of clarity in the methodology, particularly regarding the integration of contrastive learning and label disambiguation.', 'Insufficient depth in the theoretical justification and experimental setup, making replication challenging.', 'Limited discussion on the robustness of the method and its generalizability to other tasks.']",3,3,3,4,Reject
OCgCYv7KGZe,"The paper proposes Auto-Encoding Inverse Reinforcement Learning (AEIRL), a framework that utilizes auto-encoders to derive reward functions from expert demonstrations. The authors claim that AEIRL enhances robustness and performance in the presence of noisy expert data, demonstrating superior results in various MuJoCo environments compared to state-of-the-art methods.","['Can the authors clarify how AEIRL significantly differs from existing IRL methods, particularly regarding its novelty?', 'What specific hyperparameter settings and baseline configurations were used in the experiments?', 'How does the proposed method perform under varying types and levels of noise in expert demonstrations?']","['The paper should address the lack of clarity in experimental methodologies and the implications this has on reproducibility.', 'There is insufficient exploration of the robustness of the proposed method in light of its claimed advantages.']",False,2,2,2,4,4,"['The proposed method is innovative in applying auto-encoders to obtain reward signals in IRL.', 'Experiments are conducted on multiple MuJoCo tasks and show promising results, indicating potential for real-world application.', 'The paper highlights the importance of robustness in learning from noisy expert demonstrations, which is a pertinent issue in practical scenarios.']","['The originality of the approach is unclear as it builds on existing frameworks without a clear differentiation.', 'Experimental details are insufficient, lacking clarity on hyperparameter settings and baseline configurations, which affects reproducibility.', 'The paper does not adequately discuss the limitations of the proposed method or how different levels of noise affect its performance compared to baselines.', 'Writing is convoluted and lacks organization, making it challenging for readers to follow the argumentation.']",3,2,2,3,Reject
LtKcMgGOeLt,"This paper investigates the performance of Vision Transformers (ViTs) and MLP-Mixers, demonstrating that they can outperform ResNets without large-scale pre-training or strong data augmentations by employing a sharpness-aware optimizer. The authors analyze loss landscapes, revealing that ViTs and MLP-Mixers converge at sharp local minima and introduce a sharpness-aware minimizer (SAM) to promote smoother loss geometries, leading to improved accuracy and robustness across various tasks.","['Can the authors elaborate on why SAM is necessary compared to existing optimization techniques?', 'Will the authors consider conducting additional ablation studies to clarify the contributions of SAM?']","['While the results are impressive, the reliance on SAM may lead to increased computational costs. Future work should explore methods to mitigate this.']",False,4,3,4,7,4,"['The study provides a novel perspective on the training dynamics of ViTs and MLP-Mixers, emphasizing the importance of loss landscape smoothness.', 'The introduction of the sharpness-aware minimizer (SAM) is an innovative approach that shows clear benefits in both accuracy and robustness for models trained from scratch.', ""The experimental validation across multiple tasks and datasets, including adversarial and transfer learning scenarios, strongly supports the paper's claims.""]","['The motivation for using SAM and its advantages over conventional optimizers could be articulated more clearly.', 'More detailed ablation studies could help isolate the effects of SAM from other influencing factors in the experiments.', 'Some complex concepts, such as loss landscape geometry, could benefit from further clarification to enhance reader understanding.']",4,4,3,4,Accept
zz9hXVhf40,"This paper investigates design choices in offline model-based reinforcement learning (MBRL), focusing on uncertainty penalties and hyperparameter tuning. It provides a comparative analysis of various uncertainty metrics and their interactions with hyperparameters, proposing a Bayesian Optimization approach for hyperparameter selection that leads to significant performance improvements over existing methods.","['Could the authors elaborate on the rationale behind selecting specific uncertainty penalties and their practical implications?', 'What specific steps can be taken to ensure that the improvements observed in the benchmarks are generalizable to other environments?']","['The paper does not fully address potential limitations of the proposed methods, especially in terms of scalability and applicability to real-world scenarios.', 'More detailed comparisons between different heuristics used for uncertainty penalties and their trade-offs would enhance the discussion.']",False,3,3,4,7,4,"['The paper addresses a critical area in offline MBRL, bridging the gap between theoretical concepts and practical implementations.', 'The comparative analysis of different uncertainty penalties is thorough and provides valuable insights for both researchers and practitioners.', 'The use of Bayesian Optimization for hyperparameter tuning is innovative and demonstrates substantial performance gains.']","['Several sections lack clarity, making it difficult for readers to grasp the methodologies and results.', 'The paper could benefit from additional examples or case studies to illustrate the effectiveness of the proposed methods more vividly.', 'There is insufficient discussion regarding the limitations of the proposed methods, particularly concerning their scalability and applicability to diverse environments.']",3,3,3,4,Accept
bsycpMi00R1,"The paper investigates the dynamics of generalized Gradient Descent-Ascent (GDA) in Hidden Convex-Concave (HCC) games, particularly focusing on Generative Adversarial Networks (GANs). It introduces Natural Hidden Gradient (NHG) dynamics and provides global convergence guarantees under mild assumptions. The authors analyze two geometries: hidden mapping geometry and Fisher information geometry, presenting both theoretical results and experimental validation.","['Can the authors provide more intuitive explanations for the theoretical results?', 'What additional comparisons could be made in the experimental section to strengthen the claims?']","['The clarity of the mathematical exposition requires improvement to ensure that readers can follow the extensive derivations and results.', 'The experimental section could benefit from a broader range of comparisons and real-world applications to substantiate the claims made in the theoretical sections.']",False,3,3,4,6,4,"['The introduction of Natural Hidden Gradient dynamics (NHG) provides a novel approach to understanding convergence in GANs and related applications.', 'The theoretical results are strong, offering global convergence guarantees which are crucial for practical implementations.', 'The paper addresses a significant gap in the understanding of non-convex non-concave game dynamics, which is highly relevant for modern ML applications.']","['The presentation is dense in places, particularly in the mathematical derivations, which may hinder reader understanding.', 'The experimental results, while promising, lack depth in terms of comparison against a wider range of existing methods.', 'The clarity of the presentation and the complexity of the mathematical formulations may deter readers from fully grasping the contributions of the paper.']",4,3,3,4,Reject
WN2Sup7qLdw,"The paper presents Multi-Resolution Continuous Normalizing Flows (MRCNF), a new approach to generative modeling that leverages multi-resolution representations to improve the performance of Continuous Normalizing Flows (CNFs). The authors claim that MRCNF achieves competitive performance with fewer parameters and reduced training time compared to existing models. However, the clarity of the presentation and the depth of the experimental evaluation raise concerns.","['Can the authors clarify the unique contributions of MRCNF compared to existing normalizing flow models?', 'Could a wider range of comparative experiments be included to strengthen claims about model efficiency and performance?', 'What specific challenges did the authors encounter during experiments, and how were they addressed?']","['The paper should provide a more detailed analysis of its limitations, particularly regarding the scalability of the proposed model to larger datasets.', 'The clarity of the transformation details may hinder reproducibility.']",False,2,2,2,4,4,"['The integration of multi-resolution techniques into CNFs is an innovative approach that addresses efficiency in generative modeling.', 'The paper provides a solid background on normalizing flows and related work, establishing a clear context for the proposed method.', 'Experimental results indicate promising performance metrics in terms of Bits-per-dimension (BPD) and training time compared to existing models.']","['The novelty of the MRCNF approach is not clearly articulated. The authors should provide explicit comparisons to existing models to highlight unique contributions.', 'The experimental evaluation could be enhanced by including comparisons with a broader range of state-of-the-art generative models, particularly GANs and VAEs.', 'Certain sections, especially the method description, are dense and could benefit from clearer explanations and simpler language.']",2,2,2,3,Reject
ExJ4lMbZcqa,"The paper introduces VIDA, a novel approach for dereverberating speech using both audio and visual cues, demonstrating significant improvements over traditional audio-only methods. The authors develop a large-scale dataset for training and evaluate their approach across multiple tasks, achieving state-of-the-art results.","['Could the authors elaborate on the specific contributions of the visual features to the dereverberation process?', 'What potential limitations does the authors foresee in environments where visual information is unavailable?', 'Can the authors provide more clarity on the architecture used for dereverberation and how visual features are utilized?']","['The paper does not thoroughly address what happens in scenarios lacking visual input or in very noisy environments.', ""The clarity issues in the paper may affect the audience's understanding and ability to replicate the results.""]",False,3,2,3,4,4,"['The proposed task of audio-visual dereverberation is novel and addresses a significant issue in speech enhancement.', 'The methodology combines audio and visual data effectively, leveraging visual information to inform acoustic properties, which is a unique contribution.', 'The authors provide a comprehensive dataset that includes realistic acoustic renderings and a variety of room environments.']","['The paper lacks clarity in certain sections, particularly regarding the implementation details and dataset preparation, which may hinder reproducibility.', 'Evaluation metrics and the rationale behind them are not thoroughly discussed, leaving some questions about how results relate to practical applications.', 'Some claims about performance improvements lack sufficient detail or context to fully understand the contributions made by the authors.']",3,3,2,4,Reject
xtZXWpXVbiK,"The paper introduces the FlOw-based Recurrent BElief State model (FORBES) for learning belief states in POMDPs using normalizing flows. The approach aims to improve multi-modal predictions and sample efficiency in reinforcement learning tasks, claiming to capture complex belief states better than traditional Gaussian approximations. Empirical results demonstrate improved performance in visual-motor control tasks.","['Can the authors clarify the rationale behind the choice of specific normalizing flow architectures used in their model?', 'What specific metrics were used to evaluate the performance of FORBES, and how do they compare quantitatively with other state-of-the-art methods?', 'Could the authors provide additional insights into the scalability of FORBES in other high-dimensional continuous spaces?']","['The paper does not thoroughly address potential limitations of the proposed method in real-world scenarios, such as computational efficiency and scalability.', 'There is insufficient exploration of the implications of using normalizing flows for belief state inference in terms of computational complexity and scalability.']",False,3,3,4,6,4,"['The integration of normalizing flows allows for a more flexible modeling of belief states, overcoming limitations of Gaussian approximations.', 'The paper provides a thorough experimental evaluation across various challenging tasks, demonstrating the effectiveness of the proposed method.', 'The theoretical foundation is solid, providing insights into the advantages of the FORBES model over traditional methods.']","['The clarity of presentation is lacking in several sections, making it difficult to understand the contributions and methodology.', 'The claims of performance improvements are not sufficiently substantiated against a comprehensive set of baselines.', 'The depth of theoretical justification for the choice of specific flow architectures could be further elaborated.']",3,3,3,4,Reject
-29uFS4FiDZ,The paper proposes a two-stage method for knowledge distillation from BERT to multi-sense embeddings aimed at improving resource-constrained systems. It seeks to address polysemy issues in word embeddings by leveraging BERT's contextual information. The authors claim competitive performances in word sense induction and contextual word similarity tasks.,"['Could the authors clarify the novelty of their contributions compared to existing work in multi-sense embeddings and knowledge distillation?', 'What specific modifications or enhancements in the methodology could improve clarity for readers?', 'How does the proposed method compare to recent advancements in multi-sense embeddings beyond the mentioned models?']","['The clarity of the paper is a significant concern, which could limit its accessibility and impact.', 'The originality of contributions seems limited when compared to existing literature, which may affect its significance.', 'The authors do not adequately discuss the limitations of their approach, particularly in terms of scalability and its performance in real-world applications.']",False,3,2,3,5,4,"['Addresses the significant problem of polysemy in word embeddings, which is relevant for practical applications.', 'Employs a knowledge distillation approach from BERT, which is a clever way to leverage pre-trained models for improving multi-sense embeddings.', 'Experimentation with multiple benchmarks to validate the proposed method, showing practical utility.']","['Lacks substantial originality; the approach resembles existing multi-sense embedding methods and knowledge distillation techniques.', 'Clarity issues throughout the paper may hinder understanding of the proposed methods and results.', 'While the results are competitive, they do not present a significant breakthrough compared to existing models.']",3,3,2,3,Reject
TNxKD3z_tPZ,"The paper proposes a method to estimate the generalization of neural networks using persistent homology (PH) from algebraic topology. The authors claim that the evolution of PH diagram distances correlates with validation accuracy, potentially allowing generalization estimation without a validation set. They conduct experiments on various datasets and neural network architectures.","['Can the authors clarify the computational steps involved in calculating persistent homology for neural networks?', 'What measures were taken to ensure that the results are not dataset-specific and can generalize across different architectures?', 'How do the authors justify the claim that their method can reliably replace validation sets without adequate empirical evidence backing it?', 'What specific limitations of your approach should the reader be aware of when interpreting the results?']","['The lack of clarity in methodology may hinder understanding and reproducibility.', 'The experiments need to demonstrate more robustness and a thorough evaluation of different architectures and datasets.', 'The correlation found does not necessarily imply causation or effectiveness in practical scenarios.', 'The dependence on a specialized mathematical background may limit the accessibility of the proposed method for practitioners.']",True,2,2,3,4,3,"['The paper addresses an important problem in machine learning: estimating generalization without a validation set.', 'The use of persistent homology is novel and provides a fresh perspective on monitoring neural network training.', 'The authors present empirical results showing a correlation between PH diagram distances and validation accuracy across different datasets.']","['The methodology lacks clarity. The explanation of how persistent homology is applied and computed in the context of neural networks is convoluted and could benefit from more straightforward exposition.', 'The experimental validation is somewhat limited. While the authors test across various datasets, the robustness of their findings is not thoroughly examined, including potential overfitting to specific datasets.', 'The presentation of results is not sufficiently clear, particularly in visualizing and interpreting the correlation results between PH distances and validation accuracy.', 'The theoretical background lacks depth, making it difficult for readers unfamiliar with algebraic topology to fully grasp the methods used.', 'The paper does not adequately discuss the practical implications and potential limitations of applying this method in real-world scenarios.']",3,2,2,3,Reject
AS0dhAKIYA0,"The paper proposes a method to enhance the interpretability of Machine Reading Comprehension (MRC) models by utilizing semantic role labeling (SRL) and creating semantic role relation tables. The authors claim that this approach can improve the recognition of supporting facts in multi-hop questions using the HotpotQA dataset, achieving better performance even with limited training data.","['Can the authors clarify the construction process of the semantic role relation tables?', 'How does the proposed model perform compared to current state-of-the-art models in a more comprehensive evaluation?']",['The paper lacks a detailed discussion of the limitations of the proposed approach and how it may perform in different contexts or datasets.'],False,2,2,2,3,4,"['The focus on improving interpretability in MRC is relevant and important for real-world applications.', 'The integration of semantic role labeling offers a structured approach to understanding semantic relations in sentences.', 'The proposed method has the potential to enhance user trust and acceptance in MRC systems, which is crucial for deployment in practical scenarios.', 'The use of semantic role relation tables is a novel approach that could inspire further research in the area of explainable AI.']","['The methodology is not clearly defined, making it difficult to understand how the semantic role relation tables are constructed and utilized in the model.', ""The experimental results lack depth; only limited evaluation metrics are presented, and it's unclear how the proposed method compares to state-of-the-art approaches in a meaningful way."", 'The significance of the contributions is questionable, as the paper does not convincingly demonstrate practical improvements over existing methods.', 'There is insufficient discussion on the limitations of the proposed approach and its applicability to different contexts or datasets.']",2,2,2,2,Reject
qTHBE7E9iej,"The paper presents HeLMS, a hierarchical mixture latent variable model for learning transferable motor skills in robots. It effectively captures both discrete and continuous behavioral variations, demonstrating improved sample efficiency and performance in manipulation tasks, facilitating skill transfer across various tasks and objects.","['Can the authors elaborate on how the discrete and continuous components interact during skill execution?', 'What mechanisms are proposed to encourage exploration in sparse-reward settings?', 'Could the authors clarify the rationale behind the choice of hyperparameters for KL-regularization?']","[""The paper does not fully address the model's performance in highly variable task definitions or environments with significant dynamics, which could impact generalization."", 'Further elaboration on the limitations of using offline data for skill learning would strengthen the paper, particularly regarding potential biases in the dataset.']",False,3,2,3,6,4,"['The hierarchical mixture model integrates discrete and continuous behaviors, enhancing the transferability of learned skills, as evidenced by performance metrics in manipulation tasks.', 'Empirical evaluation shows strong performance and sample efficiency, particularly in challenging sparse-reward scenarios.', ""The analysis of learned skills and their impact on exploration in sparse-reward settings provides valuable insights into the model's effectiveness.""]","['The clarity of the presentation could be improved; some concepts, such as the interaction between discrete and continuous components, may be challenging for readers unfamiliar with the domain.', 'Ablation studies could be more thorough to better understand the contributions of each component within the HeLMS framework.', 'The organization of the paper could be enhanced for better flow, especially in the methods section where complex interactions are described.']",3,3,2,4,Reject
vEIVxSN8Xhx,"The paper presents a novel Log-Polar Space Convolution (LPSC) layer designed to enhance the receptive field of convolutional neural networks (CNNs) without significantly increasing the number of parameters. By employing elliptical kernels in log-polar coordinates, the method aims to improve feature extraction capabilities in CNNs. While the authors provide experimental results across various datasets, the effectiveness of LPSC compared to traditional convolution methods remains inadequately demonstrated.","['Can the authors provide additional experimental results that compare LPSC with a broader range of existing methods?', 'What theoretical insights can the authors offer to support the claims regarding the benefits of using log-polar space?', 'Could the authors clarify how the LPSC layer can be effectively implemented in various architectures?']","['The paper lacks comprehensive empirical evaluation across diverse tasks and datasets to substantiate the effectiveness of the proposed method.', ""Clarity issues in the presentation hinder the reader's understanding of LPSC and its advantages compared to traditional methods.""]",False,2,2,2,4,4,"['The innovative use of log-polar coordinates for convolution addresses the limitations of fixed kernel shapes in traditional convolutions.', 'LPSC can be integrated into existing CNN architectures, potentially broadening its applicability across various tasks.', 'The method effectively targets the important challenge of increasing the local receptive field while keeping the parameter count manageable.']","['The experimental results do not convincingly demonstrate a significant advantage of LPSC over existing convolution methods, raising questions about its practical benefits.', 'The paper lacks clarity in explaining the implementation details and the rationale behind hyper-parameter choices for LPSC.', 'There is insufficient comparison with state-of-the-art methods that also aim to enhance the receptive field.']",3,2,2,3,Reject
BduNVoPyXBK,"The paper proposes Feature Attending Recurrent Modules (FARM), a deep reinforcement learning architecture that aims to enhance generalization by discovering perceptual schemas for recurring task structures. It investigates generalization across three diverse task settings and compares FARM against existing recurrent architectures with spatial attention, providing experimental results that suggest FARM's advantage in capturing diverse structures for generalization.","[""Can the authors clarify the modular interactions and how FARM's modules coordinate attention?"", ""What steps are taken to ensure that FARM's performance improvements are not due to existing techniques being implemented in a different form?"", 'Can further details be provided on the hyperparameter choices and their impact on the results?']","['The paper does not adequately discuss the limitations of FARM, particularly in the context of potential inefficiencies or pitfalls in learning perceptual schemas.', 'There should be a more detailed investigation into the trade-offs between the proposed dynamic feature attention and spatial attention mechanisms.']",False,3,3,4,5,4,"['The introduction of perceptual schemas as a mechanism for generalization in reinforcement learning is innovative and draws inspiration from cognitive science.', 'The proposed FARM architecture effectively utilizes dynamic feature attention and modular recurrent structures, which could enable better generalization across various tasks.', 'The experimental results indicate that FARM outperforms traditional methods and provides insights into how different components contribute to its effectiveness.']","['The clarity of the methodology could be improved, particularly in detailing how the FARM architecture operates and its components interact. A clearer explanation of the dynamic feature attention mechanism would be beneficial.', 'The paper does not sufficiently address potential overlaps with existing attention mechanisms and recurrent architectures, which may diminish the novelty of the approach. A discussion on how FARM differentiates itself from these methods would strengthen the paper.', 'Some experimental results lack sufficient detail on their reproducibility and the choices of hyperparameters, which are critical for validation. Providing more information on the experimental setup would enhance the review process.']",3,3,3,4,Reject
AypVMhFfuc5,"The paper presents FrugalMCT, a framework designed to optimize the selection and combination of ML APIs for multi-label classification tasks while respecting user-defined budgets. The framework adapts to different data and leverages an accuracy estimator to make informed decisions about which APIs to use. The authors conduct experiments with various ML APIs and showcase significant cost reductions while maintaining or improving accuracy compared to individual APIs.","['Can the authors provide clearer explanations of the theoretical aspects of their method?', 'What specific improvements in accuracy were observed with the different combinations of APIs, and how were these evaluated?', 'Could the authors include more detailed comparisons with baseline methods to substantiate their claims?', 'What are the specific limitations of the accuracy predictor? Could you provide more insights into the scenarios where it may fail?', 'Could you elaborate on the computational complexity of the online algorithm compared to the previous FrugalML approach?']","['The clarity of the methodology and experimental results requires improvement.', 'The current evaluation does not sufficiently demonstrate the robustness of the proposed framework across diverse datasets.', 'The reliance on external APIs could introduce variability in the results and impacts reproducibility.', 'The broader implications of using such a framework in sensitive applications need to be discussed.']",True,3,2,3,6,4,"['Addresses a relevant and practical problem in the growing field of MLaaS.', 'Introduces a novel framework that combines the strengths of multiple APIs to improve classification outcomes.', 'Empirical results indicate substantial cost savings and accuracy improvements.']","['The presentation lacks clarity in several sections, particularly in the methodology and theoretical foundations.', 'The experimental evaluation could be more thorough; comparisons with baseline methods are limited.', 'The paper could benefit from additional ablation studies to better understand the contributions of different components.', 'Lacks thorough theoretical analysis, particularly around the accuracy predictor and its training methodology.', 'The paper does not sufficiently explore the potential negative societal impacts of MLaaS and API selection.']",3,3,2,4,Reject
XWODe7ZLn8f,"The paper introduces C3-GAN, a method for unsupervised fine-grained class clustering that combines InfoGAN with contrastive learning to enhance feature representation and clustering performance. It aims to create distinct cluster boundaries in the embedding space while maximizing mutual information between latent codes and image observations. Experimental results indicate that C3-GAN achieves state-of-the-art performance on multiple fine-grained datasets.","['Can the authors clarify the training process and how the contrastive loss directly influences the clustering performance?', 'Could more detailed ablation studies be included to validate the contributions of various components?', 'How do the authors plan to improve the clarity and presentation of their results?']","['The paper does not sufficiently address potential limitations of the proposed method, particularly regarding the computation and scalability of the approach in larger datasets.', 'There is a lack of discussion on the ethical implications of using generative models for this task.']",False,3,3,3,6,4,"['Addresses a significant problem in fine-grained class clustering, which is challenging due to subtle differences among classes.', 'The integration of contrastive learning with GANs is an innovative approach that enhances the mutual information between latent codes and image observations.', 'Experimental results demonstrate competitive performance compared to existing methods, achieving state-of-the-art results on four fine-grained datasets, including CUB and Stanford Cars.']","['The methodology lacks clarity in the description of the training process and the relationship between the contrastive loss and clustering performance.', 'The paper does not provide sufficient detail on the experimental setup, including hyperparameter tuning and baseline methods, which makes it difficult to reproduce the results.', 'The originality of the approach is somewhat diminished by the lack of novelty in the underlying concepts, as similar integrations have been explored in other contexts.']",3,3,3,4,Reject
Yr_1QZaRqmv,"The paper proposes a decision tree-based algorithm for solving Markov Decision Processes (MDPs) with large state-action spaces, aiming to improve computational tractability and provide interpretable policies. However, the execution lacks clarity and thorough empirical validation.","['Could you clarify the theoretical foundations of your approach and how they compare to existing methods?', 'What specific performance metrics were used to evaluate the algorithm, and how do they compare with existing methods?', 'Can you provide more clarity on the algorithmic steps and decision tree construction?']","[""The lack of clarity in the methodology makes it hard for readers to grasp the algorithm's implementation."", ""The reliance on numerical examples without strong experimental validation weakens the paper's claims."", 'The paper does not sufficiently explore the limitations of using decision tree policies in RL.']",False,2,2,2,4,4,"['The approach of using decision trees for MDPs is innovative and addresses the interpretability issue common in reinforcement learning.', 'The proposed method addresses a significant issue in reinforcement learning: the curse of dimensionality in MDPs.', 'The combination of decision trees with MDPs is a novel approach that has potential for interpretability and transparency in the decision-making process.']","['The methodology lacks clarity; key concepts and steps in the algorithm are not sufficiently explained.', 'Empirical validation is weak; the paper provides limited experimental results to demonstrate the effectiveness of its approach.', 'The paper does not adequately compare its performance against existing methods or benchmarks, making it difficult to assess its significance.', 'The novelty of the approach is not clearly articulated, and it lacks a thorough comparison with existing deep RL methods.']",2,2,2,3,Reject
XVPqLyNxSyh,"The paper proposes a methodology for discovering spurious and core visual features in deep learning models using minimal human supervision. It introduces the Salient ImageNet dataset to identify how models rely on these features for predictions, highlighting the importance of understanding spurious features in model reliability.","['How do the authors envision their methodology improving model training or performance in practical applications?', 'What steps could be taken to rigorously validate the methodology beyond the current evaluation?', 'Can the authors clarify the specific methodologies used in the Mechanical Turk studies?', 'How does the proposed framework generalize to other datasets beyond ImageNet?']","['The authors do not adequately discuss the limitations of their findings or the potential negative impacts of their methodology.', ""The clarity and organization of the paper hinder understanding, which might affect the readers' ability to replicate the results.""]",True,2,2,3,5,4,"['Addresses a significant issue in deep learning models regarding spurious features and their impact on model reliability.', 'The introduction of the Salient ImageNet dataset is a notable contribution that could facilitate further research in this area.', 'The methodology leverages neural features from pre-trained models, which is innovative and reduces the need for extensive human labeling.']","['The validation of the proposed methodology lacks rigor; the authors do not provide sufficient evidence that the discovered features lead to improved model understanding or performance.', 'The evaluation results are somewhat superficial and do not deeply analyze the impact of spurious features on model predictions, limiting the conclusions that can be drawn.', 'Certain sections of the writing lack clarity, making it difficult to fully grasp the proposed framework and its implications for model reliability.', 'The reliance on Mechanical Turk for human annotations may introduce biases or inconsistencies in the labeling of spurious and core features, potentially affecting the validity of the findings.']",3,2,2,3,Reject
8la28hZOwug,"The paper introduces Prototypical Contrastive Predictive Coding (ProtoCPC), a novel method that combines knowledge distillation and contrastive learning to improve representation transfer between teacher and student models. It proposes a new objective that utilizes prototypes to define probabilistic outputs and applies this to three distillation tasks.","['Can the authors clarify the rationale behind the choice of prototypes?', 'What specific advantages does ProtoCPC provide over traditional KD methods in terms of implementation and performance?', 'Could the authors provide additional ablation studies to evaluate the impact of prior momentum rate and other hyperparameters?']","['The paper could improve clarity and depth of explanation, particularly around implementation.', 'More detailed comparisons with state-of-the-art methods would strengthen the evaluation.']",False,3,2,3,5,4,"['Innovative integration of knowledge distillation and contrastive learning.', 'Extensive experiments demonstrating effectiveness across various benchmarks.', 'Theoretical grounding in mutual information maximization.']","[""The method's explanation lacks clarity, making implementation details difficult to grasp."", 'Justification for the choice of prototypes and optimization processes is insufficient.', 'Evaluation against existing methods could be more comprehensive, particularly with ablation studies.']",3,3,3,4,Reject
okmZ6-zU6Lz,"The paper investigates the controllability of large-scale networked dynamical systems using coarse summaries of network structures. It proposes a learning-based framework to infer controllability from coarse measurements and compares this with traditional model order reduction methods, providing theoretical bounds on the approximations.","['Can the authors clarify the distinction of their approach from existing methods in controllability analysis?', 'What are the specific limitations of the proposed method in practical scenarios, and how might they be addressed?', 'Could additional simulations be provided to illustrate the robustness of the framework across different network structures?']","['The paper does not sufficiently explore the implications of its findings in practical applications, particularly in sensitive areas like healthcare.', 'Potential ethical implications of manipulating network structures based on the proposed methodology are not discussed.']",True,2,3,2,4,4,"['Addresses a significant problem in control theory and network dynamics, with real-world applications in fields like neuroscience.', 'Introduces the use of community-based representations, which could provide valuable insights for practitioners.', 'Offers theoretical analysis and bounds regarding controllability metrics based on coarse network summaries.']","['The theoretical contributions could be more clearly distinguished from existing literature, making it challenging to assess the originality of the work.', 'Some areas of the presentation, particularly in the methodology and derivation of key results, could benefit from clearer explanations.', 'Experimental validation is limited; more diverse simulations and comparisons with existing methods would strengthen the claims.']",3,3,4,4,Reject
DrZXuTGg2A-,"The paper introduces interactive shuffle protocols for stochastic convex optimization, focusing on achieving differential privacy through a noninteractive protocol for summing vectors. It aims to improve existing privacy guarantees while optimizing convex loss functions, but lacks sufficient experimental validation and clarity.","['Can the authors provide more detailed comparisons with existing methods to clarify the advantages of their approach?', 'What specific scenarios or applications do the authors envision for their proposed methods beyond theoretical guarantees?', 'Will the authors consider including more extensive experiments to support their claims?']","['The paper does not adequately discuss the computational complexity involved in their proposed protocols.', 'There is a lack of exploration regarding the trade-offs between privacy and utility in practical applications.']",False,2,2,3,4,4,"['Addresses a significant gap in the literature regarding shuffle privacy in stochastic convex optimization.', 'Introduces a novel method for summing vectors with bounded ℓ2 sensitivity.', 'Provides theoretical guarantees for various convex loss functions.']","['The theoretical analysis lacks depth compared to existing works, making it difficult to assess the real impact of the contributions.', 'The experimental evaluation is insufficient and does not convincingly demonstrate the practical advantages of the proposed methods.', 'The clarity of writing is inconsistent, with dense notation and convoluted explanations that may confuse readers.']",3,2,2,4,Reject
EMxu-dzvJk,"The paper introduces GRAND++, a graph neural network framework that integrates a source term into the diffusion process to mitigate over-smoothing and enhance performance with limited labeled data. The theoretical advantages include a non-convergence to constant node representations, which is crucial for deep architectures, and improved classification accuracy under low-labeling conditions.","['Can the authors clarify the theoretical implications of the source term in greater detail?', 'What specific aspects of GRAND++ set it apart from existing methods in a more concrete sense?', 'Could the authors provide clearer explanations of the theoretical results?', 'Would the authors consider additional comparisons with more GNN models to further validate the effectiveness of GRAND++?']","['The paper could benefit from a more detailed discussion of the limitations of the proposed method in practical scenarios.', 'The complexity of the theoretical framework and the presentation may limit understanding and reproducibility.', 'The paper should explicitly mention any computational limitations or challenges encountered when implementing the GRAND++ framework, especially regarding scalability.']",False,3,3,3,6,4,"['Addresses significant issues in GNNs related to over-smoothing and low labeling rates, which are critical for practical applications.', 'Theoretical contributions provide a solid mathematical foundation for the claims made, particularly regarding the dynamics of node representations.', 'Comprehensive experimental validation across multiple datasets demonstrates the practical advantages of GRAND++ over existing GNNs.']","['The clarity of the theoretical explanations and mathematical formulations could be improved, as some sections may be difficult for readers to fully grasp.', 'The novelty of the contributions compared to existing GNN architectures could be articulated more clearly to highlight its uniqueness.', 'Some experimental results could benefit from additional context, such as the rationale behind specific hyperparameter choices.']",3,3,3,4,Reject
DIjCrlsu6Z,"The paper presents a method for identifying and constructing directions invariant to a given classifier, termed orthogonal classifiers, aimed at enhancing tasks like style transfer, domain adaptation, and fairness. The authors provide a theoretical framework for defining orthogonality in non-linear classifiers and demonstrate the effectiveness of their approach through empirical evaluations in various applications.","['Could the authors clarify the assumptions made in defining orthogonality in the non-linear case?', 'What are the practical limitations or challenges of applying the proposed orthogonal classifiers in real-world scenarios?']","['The paper does not sufficiently address potential limitations of the orthogonal classifier in diverse applications.', 'Technical explanations could be improved for accessibility to a broader audience.']",False,2,2,2,4,4,"['Addresses important challenges in controlling directions orthogonal to classifiers, with implications for fairness and adaptation tasks.', 'The theoretical foundation for orthogonality in non-linear classifiers is a novel contribution.', 'Empirical results across multiple use cases lend credibility to the approach.']","['Lacks clarity and organization, particularly in technical definitions and theoretical underpinnings.', 'Insufficient comparisons to state-of-the-art methods limit the impact of the findings.', 'The evaluation is focused on specific scenarios, lacking broader applicability or scalability discussions.']",3,2,2,3,Reject
89W18gW0-6o,"The paper proposes FOCAL++, an enhanced method for context-based offline meta-reinforcement learning (COMRL) that integrates intra-task attention mechanisms and inter-task contrastive learning objectives. The authors claim that this combination improves task representation robustness against sparse rewards and distribution shifts, supported by theoretical analysis and experimental results.","['Can the authors clarify the assumptions made in the theoretical section and provide more rigorous justification for the proposed model?', 'What specific ablation studies have been conducted to assess the importance of the attention and contrastive components?', 'Could additional details regarding the experimental setups and comparison with other state-of-the-art methods be provided?']","['The paper does not adequately discuss the limitations of the proposed method or scenarios where it might fail.', 'The clarity and organization of the paper could be improved to enhance reader comprehension.']",False,3,2,3,5,4,"['Addresses significant challenges in offline meta-reinforcement learning.', 'Innovative integration of attention mechanisms with contrastive learning.', 'Theoretical analysis provides a solid foundation for the proposed approach.']","['Clarity issues in the presentation, particularly in methodology and theoretical claims, such as the assumptions made in the theoretical analysis and the lack of detail in the experimental setup.', 'Insufficient detail in experimental setups and lack of comprehensive comparative analysis.', 'The novelty of the contributions is questionable as similar integrations have been explored in other domains.']",3,3,2,4,Reject
Z0XiFAb_WDr,"The paper presents the Language-complete Abstraction and Reasoning Corpus (LARC), a dataset of natural language instructions for procedural tasks, aimed at improving understanding and execution by AI systems. It emphasizes the differences between human communication through natural language and traditional programming languages, proposing the concept of 'natural programs' that capture human cognitive processes in problem-solving.","['Can the authors clarify the empirical evaluation and provide more concrete results demonstrating the advantages of using LARC?', 'What specific limitations does the LARC dataset have that might affect its usage in AI development?', 'Can you provide more details on the methodology used for data collection and validation of the LARC dataset?', 'What specific challenges do you foresee in transitioning insights from LARC to practical AI applications, and how do you propose to address them?']","['The paper does not adequately demonstrate the practical applications of the LARC dataset.', 'Insufficient handling of the potential negative implications of AI systems leveraging natural language communication.', 'The clarity of the paper is a significant concern; enhancing the presentation could improve reader comprehension.']",True,2,2,3,4,4,"['The introduction of LARC as a dataset for understanding natural language instructions is a valuable contribution to the field.', 'The study addresses an important gap in AI, focusing on how humans communicate tasks effectively using natural language.', 'The concept of natural programs provides a fresh perspective on how humans communicate instructions for complex tasks.']","['The paper lacks clarity and coherence in organization, making it difficult to follow the main arguments and findings.', 'The methodology for collecting and validating LARC is not sufficiently detailed, raising concerns about reproducibility.', 'The experimental evaluation is not comprehensive enough; more quantitative results demonstrating the effectiveness of LARC in improving program synthesis are needed.', 'The analysis of natural programs lacks depth; it could benefit from more rigorous evaluation metrics and comparisons with existing program synthesis techniques.']",3,3,2,4,Reject
PilZY3omXV2,"The paper introduces CoST, a contrastive learning framework for time series forecasting that learns disentangled seasonal-trend representations. It argues for the advantages of this paradigm over traditional end-to-end training methods and demonstrates improved forecasting performance on several benchmarks.","['Could you provide more details about how the Trend Feature Disentangler and Seasonal Feature Disentangler are structured and trained?', 'Can you clarify the significance of the different components in the ablation studies and their correlation with performance metrics?', 'Can the authors elaborate on how CoST compares to other recent approaches in terms of computational efficiency?']","['The clarity of the model architecture and some experimental results could be improved for better understanding.', 'The paper does not sufficiently discuss the trade-offs involved in using the proposed method compared to traditional end-to-end approaches.']",False,3,3,3,7,4,"['The framework addresses a significant challenge in time series forecasting by focusing on disentangled seasonal and trend representations, which may enhance generalization in non-stationary environments.', 'The proposed framework demonstrates substantial improvement over state-of-the-art methods in multiple datasets, showcasing its robustness.', 'The empirical results indicate that CoST consistently outperforms state-of-the-art methods by a considerable margin, particularly in multivariate forecasting contexts.']","['The explanation of the model architecture, particularly the details surrounding the Trend Feature Disentangler and Seasonal Feature Disentangler, could be clearer.', 'Some of the results from the ablation studies are not adequately discussed, leaving questions about the necessity and impact of specific components.', 'The clarity of the presentation could be improved, especially for complex sections. Some readers may find it challenging to follow the causal arguments made in the paper.']",3,3,3,4,Accept
lkQ7meEa-qv,"The paper introduces Neural Acoustic Fields (NAFs), an implicit representation designed to model sound propagation in physical spaces. By treating acoustic properties as a linear time-invariant system, NAFs map emitter-listener pairs to impulse response functions, allowing high-fidelity predictions of sound propagation. The work aims to enhance cross-modal generation of visual scenes from sparse acoustic inputs and demonstrates potential applications in sound source localization.","['Could the authors provide additional details on the training process and architecture to improve clarity?', 'What specific ablation studies could be performed to better illustrate the importance of local geometric conditioning?', 'Can the authors clarify the architectural decisions made in the NAF model and their contributions to overall performance?']","['Clarity regarding methodology and experimental setup is a major concern.', ""Experimental evaluations need to be more robust to support claims about NAFs' performance."", 'The paper does not adequately address limitations of the proposed method, particularly regarding its applicability to various acoustic environments.']",False,2,2,2,4,4,"['NAFs present a novel approach to modeling acoustics with an implicit representation, contributing original insights to the field.', 'The integration of local geometric features enhances generalization across emitter-listener pairs, improving model robustness.', 'The potential applications of NAFs in cross-modal learning and sound source localization are significant and could inspire further research.']","['The paper lacks clarity in the technical implementation, particularly regarding model architecture and training processes, which may hinder reproducibility.', 'Experimental evaluations are limited; while some results are presented, comprehensive ablation studies are needed to validate the impact of various model components.', ""Certain sections are overly technical, potentially alienating a broader audience and limiting the paper's impact.""]",3,2,2,4,Reject
kj0_45Y4r9i,"The paper proposes Clustering by Discriminative Similarity (CDS), a method that learns a discriminative similarity metric for clustering by minimizing the generalization error of unsupervised classifiers. It introduces a new clustering algorithm termed CDSK, validated through experiments. While the theoretical foundations are promising, the paper suffers from clarity issues and limited experimental validation.","['Can the authors clarify the theoretical contributions, particularly the generalization bounds?', 'What specific datasets were used for comparison, and how do the results hold against a wider range of clustering methods?', 'Can the authors provide a more intuitive explanation of how the proposed method improves upon existing clustering methods?']","['The paper does not sufficiently address the limitations of the proposed method, especially concerning its application to high-dimensional or complex datasets.', ""Clarity issues in the presentation may lead to misunderstandings about the algorithm's implementation and results.""]",False,2,2,2,4,4,"['The concept of using discriminative similarity for clustering is innovative and theoretically grounded.', 'The theoretical foundation using generalization bounds provides a solid basis for the proposed method.', 'The paper addresses an important problem in clustering by focusing on the discriminative aspect of similarity.']","['The presentation is convoluted and poorly structured, making it difficult to follow the proposed methodology.', 'The originality of the approach is diminished by insufficient differentiation from existing methods.', 'The experimental validation is limited, lacking comparisons to a broader range of clustering algorithms.']",2,2,2,3,Reject
-3yxxvDis3L,"The paper investigates the performance of stochastic gradient descent (SGD) when applied to highly dependent data samples, presenting a study on how different stochastic update schemes, specifically periodic data subsampling and mini-batch SGD, can improve the sample complexity of SGD. The authors provide theoretical results demonstrating these improvements and validate their findings with numerical experiments.","['Can the authors clarify some of the theoretical results, especially those relating to the implications of periodic subsampling and mini-batch updates?', 'What additional experimental scenarios could be considered to strengthen the empirical validation of the proposed methods?']","['The theoretical analysis could benefit from clearer explanations and a more rigorous presentation.', 'The experimental validation is somewhat limited and does not sufficiently demonstrate the practical applicability of the proposed methods.']",False,2,2,2,4,4,"['The topic is highly relevant as many practical applications involve dependent data, which challenges conventional machine learning assumptions.', 'The theoretical contributions regarding the impact of stochastic update schemes on sample complexity enhance the understanding of SGD in dependent settings.']","['The paper lacks clarity in several sections, making it difficult to follow the theoretical derivations and conclusions.', 'The experiments validate some theoretical results but are limited in scope, lacking a wide range of scenarios to robustly support the claims.', 'The presentation could be improved by providing more detailed explanations and examples to clarify the significance of the results.']",3,2,2,3,Reject
BkIV7EOXkSs,The paper investigates the Bregman Proximal Point Algorithm (BPPA) and its relationship with classification tasks using separable data. It provides theoretical insights into the regularization effects and the importance of the distance generating function in determining the quality of solutions achieved by BPPA. The authors also extend their findings to mirror descent (MD).,"['How do the authors plan to address the clarity issues in their explanations, particularly in the theoretical sections?', 'Can the authors provide additional empirical validation using more complex datasets to strengthen their claims?']","['The paper lacks comprehensive empirical studies on complex real-world datasets, which is critical for validating the theoretical claims made.', 'Sections of the paper are overly dense and could confuse readers, requiring more careful consideration of clarity and structure.']",False,3,2,3,4,4,"['The theoretical contributions are significant, providing important insights into the properties of BPPA and how the choice of divergence affects the quality of solutions.', 'The paper addresses relevant questions in the optimization community about implicit regularization and the effectiveness of BPPA in practical applications.', 'The results for the constant and varying stepsizes present a novel angle on how to improve convergence properties in BPPA.']","['The clarity of writing is lacking in some sections, making it difficult for readers to follow the proposed theories and results.', 'Empirical validation is predominantly based on synthetic data, limiting the demonstration of practical effectiveness. More extensive experiments on real-world datasets would strengthen the paper.', 'Some of the theoretical results are complex and could benefit from clearer exposition or examples to make them more accessible to the reader.']",3,3,3,4,Reject
yhCp5RcZD7,"The paper presents implicit displacement fields (IDFs) as a novel representation for 3D geometry, proposing to disentangle a complex surface into a low-frequency base surface and a high-frequency displacement field. The approach claims to improve training stability and geometric detail representation over existing neural implicit methods.","['Can the authors clarify how the performance metrics were derived?', 'What specific improvements does the proposed method offer over existing techniques?', 'Can the authors provide more detailed comparisons with state-of-the-art methods to substantiate the claims of superior performance?']","[""Lack of detailed experimental results and performance metrics limits the paper's impact."", 'Insufficient clarity in methodology makes it difficult to assess the validity of claims.', 'The necessity for aligned shapes in the detail transfer task may limit the applicability of the method in practical scenarios.']",False,3,2,3,5,4,"['Introduces a novel parameterization for neural implicit functions that aims to enhance geometric detail representation.', 'Theoretically grounded approach, extending classic displacement mapping to continuous implicit representations.', 'Promise of better performance in detail transfer tasks and geometric modeling.']","['The experimental evaluation lacks comprehensiveness; results are not sufficiently detailed.', 'Methodological clarity is insufficient; certain explanations are convoluted and could confuse readers.', 'The significance of contributions compared to existing methods is not clearly articulated.']",3,3,2,3,Reject
AkJyAE46GA,"This paper investigates the capability of pretrained models to act as effective active learners by selecting informative examples that help resolve task ambiguity. Through various experiments across different datasets, the authors demonstrate that fine-tuning pretrained models using active learning can achieve higher accuracy with fewer labeled examples. The paper contributes to the understanding of how pretraining can enhance active learning mechanisms, particularly in dealing with ambiguity in real-world datasets.","['Can the authors clarify the specific metrics and evaluation criteria used to assess the effectiveness of the active learning approach?', 'How do the authors account for potential biases in the datasets used for their experiments?']","['The paper does not adequately address potential biases present in the datasets, which could affect generalizability.', 'The active learning process could be better defined, including details on how examples are selected and how this impacts overall learning.']",False,3,2,3,4,4,"['The paper addresses a relevant and significant problem in machine learning: task ambiguity during few-shot learning scenarios.', 'The empirical results suggest that pretrained models can effectively reduce labeling costs while maintaining accuracy through active learning.', 'The diversity of datasets used for evaluation highlights the generalizability of the findings.']","['The methodology lacks clarity in certain aspects, such as the exact procedures for how active learning is applied and evaluated across the different datasets.', 'There is insufficient discussion regarding the limitations of the datasets used, particularly any biases that may affect the outcomes.', 'The paper could benefit from a more thorough exploration of the hyperparameter choices for active learning, including how these impact results.']",3,3,2,4,Reject
mfwdY3U_9ea,"The paper introduces IGEOOD, a method for detecting out-of-distribution (OOD) samples using the Fisher-Rao distance within the framework of information geometry. It claims to enhance OOD detection performance without requiring OOD training samples and is applicable across various neural network architectures.","[""Can the authors clarify the impact of different settings (BLACK-BOX, GREY-BOX, WHITE-BOX) on the method's performance?"", 'What specific ablation studies were conducted to validate the significance of different components in IGEOOD?', 'Could the authors provide more insight into the tuning process for hyperparameters and the assumptions regarding Gaussianity?']","['The paper does not adequately address the limitations of the proposed approach, especially concerning the assumptions made about the data distributions.', 'There is a lack of depth in experimental validation, particularly concerning how components of the approach contribute to performance.']",False,3,4,3,7,4,"['The use of Fisher-Rao distance provides a novel perspective on OOD detection.', 'The method is flexible and can be applied in various scenarios based on the level of access to the neural network model.', 'Empirical results suggest that IGEOOD outperforms several state-of-the-art methods across different datasets and architectures.']","['The clarity of the exposition is lacking, particularly in explaining the Fisher-Rao distance and its application.', 'Insufficient ablation studies to convincingly demonstrate the importance of each component of the proposed method.', 'The paper does not provide thorough comparisons with existing methods, and the theoretical justification for using the Fisher-Rao distance is underdeveloped.', 'The limitations and assumptions regarding the methodology are not adequately addressed.']",3,3,4,4,Reject
6hTObFz_nB,"The paper presents a novel approach to safety-aware reinforcement learning called latent shielding, which enables agents to learn their own latent world models to avoid unsafe states during training. The authors claim that their method addresses the limitations of traditional shielding approaches that require handcrafted models, and they provide experimental evidence of improved safety performance.","['Can the authors clarify the rationale behind the choice of environments used for the experiments?', 'Could the authors provide more details on the impact of the shield introduction schedule on the training dynamics?', 'What are the limitations of the proposed latent shielding approach compared to traditional symbolic shielding?']","['The paper does not adequately address potential limitations of the latent shielding method, particularly concerning its safety guarantees compared to traditional approaches.', 'The experimental results, while promising, need more robust evaluation across a wider range of environments and conditions to validate the generalizability of the findings.']",False,3,3,3,6,4,"['The proposed latent shielding method is innovative and addresses a significant gap in safety-aware reinforcement learning by removing the need for handcrafted models.', 'The experimental results demonstrate that the latent shielding approach can effectively reduce unsafe behaviors during training and achieve competitive performance compared to existing methods.', 'The paper contributes to the important topic of safety in reinforcement learning, which is increasingly relevant as RL systems are deployed in real-world applications.']","['The clarity of the presentation is inconsistent. Some sections contain dense technical jargon and could benefit from clearer explanations, particularly in the introduction and method sections.', 'The paper does not provide enough detail on the experimental setup, including the specific environments used and the exact parameters for training, which makes it difficult to fully assess the reproducibility of the results.', 'While the experiments show promising results, they lack a comprehensive ablation study to explore the impact of individual components of the proposed method.']",4,3,3,4,Reject
0d1mLPC2q2,"The paper investigates the interplay between knowledge distillation (KD) and data augmentation (DA), proposing new methods for enhancing KD through stronger augmentation schemes (TLmixup and TLCutMix) and an active learning inspired approach (TLCutMix+pick). The authors assert that KD benefits more from DA than cross-entropy loss, suggesting that different views of data during training provide richer information for the student model. Extensive experiments demonstrate improved performance on CIFAR-100, Tiny ImageNet, and ImageNet datasets, achieving new state-of-the-art accuracy with the original KD loss.","['Can the authors provide a deeper theoretical analysis of the proposed framework and its implications for future KD research?', 'What specific metrics or criteria were used to evaluate the performance of the new data augmentation methods compared to existing techniques?']","['The paper could benefit from clearer explanations of the proposed methods and their advantages over existing approaches.', 'The impact of the proposed methods in terms of computational efficiency and resource requirements should be discussed.']",False,3,3,3,6,4,"['The paper addresses an important and timely topic in the field of deep learning, specifically the combination of knowledge distillation and data augmentation.', 'The proposed methods (TLmixup, TLCutMix, and TLCutMix+pick) are innovative and show potential for improving KD performance.', 'The experiments are well conducted across multiple datasets, providing comprehensive validation of the proposed methods.', 'The paper has the potential to inspire further research at the intersection of KD and DA.']","['The clarity of the paper could be improved; some sections are dense and could benefit from better organization and explicit explanations.', 'While the results are competitive, they do not represent a significant leap over existing state-of-the-art methods, which raises questions about the novelty of the contributions.', 'The theoretical framework presented lacks depth in terms of rigorous analysis; it would benefit from a more comprehensive exploration of the implications of the findings.', 'Some claims made in the paper could use more direct evidence from the experiments to strengthen their validity.']",3,3,3,4,Reject
e-IkMkna5uJ,"The paper investigates spectral bias in deep learning models, particularly in image classification networks, presenting methodologies for measuring this bias and reporting empirical findings. It identifies how model size and regularization methods affect spectral bias and discusses implications for generalization in neural networks.","['Can the authors clarify the methodology for measuring spectral bias, particularly regarding the Fourier transform complexity?', 'What are the implications of the findings on model architecture and training strategies?']","['The clarity of the paper and the depth of the discussion around methodologies are significant concerns that need to be addressed.', 'The study focuses only on CIFAR-10, limiting the generalizability of the findings to other datasets or tasks.']",False,3,2,3,6,4,"['The topic of spectral bias is timely and relevant, contributing to the understanding of generalization in deep learning.', 'The methodologies for measuring spectral bias are innovative and extend previous work, allowing for a comprehensive investigation.', 'The empirical findings provide insights into how different factors affect the spectral bias of models.']","['The paper lacks clarity in some sections, particularly in the methodologies presented, which could confuse readers unfamiliar with the concepts.', 'Some claims could benefit from further elaboration or supporting references to strengthen the arguments.', 'The organization of the content could be improved to enhance the flow of ideas and findings.']",3,3,2,4,Reject
Zk3TwMJNj7,"The paper investigates the directional bias of Stochastic Gradient Descent (SGD) in kernel regression, asserting that SGD converges towards the largest eigenvector of the Gram matrix, which purportedly aids in generalization. The authors provide theoretical results supported by experiments on the FashionMNIST dataset, but the originality and empirical validation of the findings are questioned.","['Can the authors clarify how their findings significantly advance the current understanding of SGD in the context of kernel regression?', 'What specific new insights do the authors believe they provide beyond existing literature?', 'Can the authors provide additional experiments on diverse datasets to support their claims?']","['The paper does not sufficiently demonstrate the practical implications of the theoretical results in real-world applications.', 'There is a lack of comprehensive evaluation against current state-of-the-art methods.']",False,2,2,2,4,4,"[""Addresses a relevant and important topic in understanding SGD's behavior in kernel regression."", 'The theoretical analysis provides insights into the convergence properties of SGD versus Gradient Descent (GD).', 'The connection drawn between SGD and generalization performance is noteworthy.']","['The originality of the work is low, heavily relying on prior studies without offering substantial new contributions.', 'Experimental validation is limited to a single dataset, lacking diversity and robustness.', 'The clarity of the exposition could be improved, as some complex theoretical concepts are inadequately explained.']",2,2,4,4,Reject
rrWeE9ZDw_,"The paper proposes a method for autonomously learning object-centric representations suitable for planning in reinforcement learning. It aims to improve sample efficiency by allowing agents to transfer knowledge of learned objects across tasks. The proposed framework is demonstrated in a 2D crafting domain and Minecraft tasks, where the authors claim that their agents can quickly learn new tasks with fewer samples by leveraging object-centric abstractions.","['Can the authors provide more detail on the theoretical basis for their method?', 'How do the learned representations compare to existing methods in terms of efficiency and effectiveness?', 'What specific metrics were used to evaluate the performance of the learned models?', ""Can the authors clarify the role of the agent's ability to individuate objects in their approach?""]","['The paper does not adequately address the limitations of the proposed method, particularly concerning the assumptions about object individuation.', 'The lack of clear experimental comparisons and metrics may undermine the claims of the paper.']",False,2,3,3,5,4,"['Addresses the important issue of sample efficiency in reinforcement learning by learning object-centric representations.', 'The integration of learned abstractions with task-level planners is a relevant contribution to the field.', 'Experimental validation across multiple domains, including Minecraft, showcases potential real-world applicability.']","['The theoretical foundation of the method is not adequately detailed, making it difficult to evaluate its novelty and robustness.', 'Experimental results lack thorough comparisons with baseline methods, and the metrics used for evaluation are not clearly defined.', 'The paper suffers from clarity issues in explaining the process of learning object-centric representations and their application in different tasks.', ""The approach relies on assumptions about the agent's ability to individuate objects, which may not hold in all environments.""]",3,2,3,4,Reject
DIsWHvtU7lF,"The paper introduces FINN, a compositional physics-aware neural network designed for learning spatiotemporal advection-diffusion processes. It combines neural networks with physical knowledge to model partial differential equations (PDEs) in a modular way, demonstrating superior accuracy and generalization over state-of-the-art models in various scenarios, including real-world applications.","['Can the authors clarify the specific functions of each module in the FINN architecture?', 'Will the authors consider adding more ablation studies to better illustrate the contributions of different components of FINN?', ""What additional experiments could be performed to validate the model's performance across a wider range of PDEs and boundary conditions?""]","[""The paper does not adequately address limitations regarding the model's assumptions and the potential challenges in applying it to other types of PDEs."", 'The clarity of the presentation is a major concern; the paper needs to better explain its methodology and findings.']",False,3,3,3,6,4,"['FINN effectively integrates physical knowledge into neural networks, enhancing generalization over initial and boundary conditions.', ""The experimental results indicate significant performance improvements across multiple PDEs, showcasing the model's practical relevance."", 'The modular architecture allows for interpretability and adaptability, which is valuable for real-world applications.']","['The paper lacks clarity in explaining the architecture and the specific roles of its different modules, which could confuse readers.', 'Limited ablation studies are provided, making it difficult to fully understand the contributions of each component in the model.', 'The theoretical foundation supporting the claims made about generalization capabilities and model behavior needs to be strengthened.']",4,3,3,4,Reject
Ivku4TZgEly,"The paper investigates the limitations of Integrated Gradients (IG) as an attribution method in machine learning, particularly focusing on fairness and the influence of baseline choices. It compares IG to Shapley values and introduces Integrated Certainty Gradients (ICG) as a solution to identified issues. While the exploration is important, the clarity and generalizability of results could be improved.","['Can the authors clarify how the findings on fairness and attribution transfer can be applied in practical scenarios?', 'What specific methodologies were used for the experimental comparisons, and how can these be generalized to more diverse datasets?']","['The paper does not sufficiently articulate the broader implications of its findings on the practical use of attribution methods in machine learning.', 'Clarity of presentation is a major concern, as complex ideas could be simplified without losing rigor.']",False,3,2,3,4,4,"['Addresses an important topic in machine learning interpretability by analyzing the fairness of attribution methods.', 'Introduces Integrated Certainty Gradients (ICG) as a novel contribution to resolve issues inherent in existing methods.', 'Comprehensive review of baseline choices and their implications for attribution quality.']","['Lacks depth and clarity in explaining fairness concepts and their implications, which may confuse readers.', 'Experiments do not sufficiently demonstrate the robustness of ICG across diverse scenarios, raising questions about generalizability.', 'Some sections are overly technical without adequate context, potentially alienating readers unfamiliar with the subject.']",3,3,2,3,Reject
rdBuE6EigGl,"The paper introduces a dual connection architecture in recurrent neural networks (RNNs) that adds a direct connection between the input and output, bypassing the recurrent module. This modification aims to enhance performance in sequence modeling tasks, particularly in natural language processing. Experimental results demonstrate consistent improvements in perplexity scores on datasets like Penn Treebank and WikiText-2, with dual architectures outperforming their non-dual counterparts across various configurations.","['Can the authors elaborate on the theoretical justification for the dual connection and its expected benefits?', 'What specific limitations were encountered when applying this dual architecture to larger or more complex datasets?']","['The paper does not adequately discuss the limitations of the proposed approach or the conditions under which it might fail.', 'There is a lack of exploration into the robustness of the results across different types of sequence modeling tasks beyond language.']",False,3,3,3,5,4,"['The dual connection in RNNs is a straightforward enhancement that offers new insights into improving sequence modeling.', 'The experimental results show significant performance improvements across multiple datasets, establishing new state-of-the-art perplexity scores.', 'The paper addresses a relevant area in deep learning, contributing to the exploration of recurrent architectures.']","['The novelty of the proposed approach is somewhat limited, as adding direct connections in neural networks has been explored in other contexts.', 'The paper lacks a detailed theoretical foundation for the proposed method, making it challenging to understand the underlying mechanisms behind the observed improvements.', 'The clarity of the presentation could be improved, particularly regarding the experimental setup and hyperparameter tuning.']",3,3,3,4,Reject
q2ZaVU6bEsT,The paper proposes a novel approach to tiny object detection by integrating a feature pyramid network with context augmentation and feature refinement. It also introduces a data enhancement method called 'copy-reduce-paste' aimed at improving training balance for tiny objects. Experimental results indicate that the proposed method yields improved performance metrics compared to existing models.,"['Can the authors provide more detailed explanations of the context augmentation and feature refinement modules?', 'What specific configurations were used for the baseline models in the experiments?', 'How does the proposed copy-reduce-paste method differ from existing data augmentation techniques?', 'Can the authors clarify how the copy-reduce-paste method differentiates itself from existing augmentation techniques?', 'Can the authors provide more detailed analyses in their ablation studies to highlight the contributions of each module?']","['The clarity of the paper needs significant improvement, particularly in explaining the proposed methods and their components.', 'The contribution of the new data augmentation method compared to existing techniques is not adequately substantiated.', 'The depth of experimental validation and comparison with existing methods is insufficient, limiting the impact of the proposed work.']",False,2,2,2,4,4,"['Addresses a significant challenge in object detection, specifically for tiny objects.', 'Proposes a combination of context augmentation and feature refinement to improve detection performance.', 'Presents experimental results that show a notable improvement over existing methods on the VOC dataset.']","['The clarity of the paper suffers; some sections are verbose and could be more concise.', 'The originality of the proposed methods, particularly the copy-reduce-paste technique, lacks sufficient comparison against existing methods that tackle similar issues.', 'Experimental comparisons with state-of-the-art methods are limited, making it hard to assess the true impact of the proposed approach.', 'The methodology lacks clarity; it is difficult to grasp how the proposed components work together effectively.']",2,2,2,3,Reject
V7eSbSAz-O8,The paper proposes a framework for benchmarking the robustness of machine learning methods in classifying SARS-CoV-2 spike sequences by introducing perturbations that simulate sequencing errors. It claims that deep learning methods are more robust than traditional machine learning approaches in this context.,"['Can the authors clarify the unique contributions of their method compared to existing works?', 'What specific methodologies did you consider for simulating sequencing errors, and why were these chosen?', 'Could the authors provide more details on the experimental setup and how they validated their results?']","['The clarity of the paper is a major concern, as several sections are difficult to understand.', 'The experimental comparisons lack depth and do not provide a comprehensive view of the landscape of existing solutions.']",False,2,2,2,4,4,"['Addresses a highly relevant and timely topic related to COVID-19 and viral genomic data.', 'Proposes a framework for testing the robustness of classification methods against simulated sequencing errors.', 'Experimental results indicate that deep learning approaches generally perform better against errors.']","['The novelty of the proposed framework is questionable, as similar robustness assessments have been conducted in other domains.', 'The methodology lacks clarity and detail, particularly regarding how perturbations are introduced and assessed.', 'Results are not well contextualized against prior work, making it difficult to assess their significance.', 'The presentation is poor, with grammatical errors and awkward phrasing that hinder understanding.']",2,2,2,3,Reject
GlN8MUkciwi,"The paper proposes a Context Adapter Module (CAM) for video-text retrieval that incorporates user comments to enhance representation learning. It argues that comments, often unstructured and irrelevant, can be filtered and adapted to improve retrieval performance. The method uses an attention mechanism to evaluate the relevance of comments, aiming to create meaningful video-text representations.","['How does the model handle potentially harmful or misleading comments?', 'Can the authors provide more details on the choice of datasets and the implications of using user-generated comments?', 'What measures are taken to address ethical concerns regarding the use of user comments from platforms like Reddit?']","['The clarity of the paper is lacking, particularly in describing the Context Adapter Module and its functionality.', 'The ethical implications of using user-generated comments are not sufficiently discussed.']",True,2,2,3,5,4,"['The approach of incorporating user comments into video-text retrieval is innovative and addresses a gap in existing literature.', 'The use of attention mechanisms to filter irrelevant information is a promising direction for improving multi-modal representation learning.', 'The experiments conducted show some improvement in retrieval performance when comments are included.']","[""The methodology lacks clarity in its descriptions and could benefit from more detailed explanations of the Context Adapter Module's design and implementation."", 'The experimental validation is not robust, and the results do not convincingly demonstrate the superiority of the proposed method over existing baselines.', 'The paper does not adequately address potential biases and ethical implications of using user-generated content for training.']",3,2,2,3,Reject
1-YP2squpa7,"This paper introduces a family of message-passing algorithms based on belief propagation (BP) for training multi-layer neural networks, specifically a variant called focusing BP (fBP) that incorporates a reinforcement term. The authors claim that their approach achieves performance comparable to stochastic gradient descent (SGD) across various tasks, particularly in sparse networks and continual learning scenarios.","['Can the authors clarify the specific advantages of the proposed algorithms over SGD, particularly regarding theoretical contributions?', 'What experiments were conducted to ensure statistical significance of the results?', 'Could the authors improve the clarity of algorithm descriptions to facilitate reproducibility?']","['The paper does not sufficiently address limitations of the proposed methods, especially regarding convergence properties and computational efficiency compared to SGD.', 'Lack of clarity in algorithmic descriptions may hinder understanding and implementation.']",False,2,2,2,4,4,"['Innovative integration of message-passing algorithms into neural network training.', 'Relevant exploration of continual learning and sparse networks.', 'Comprehensive experiments on standard datasets demonstrate the applicability of the proposed algorithms.']","['The paper lacks clarity and organization, making it challenging to follow key contributions and methodology.', 'Statistical validation of results is insufficient; comparisons with existing methods like SGD are not comprehensive.', 'The theoretical foundations of the proposed methods are inadequately discussed, raising concerns about robustness and generalizability.', 'While the work builds on existing methods, it does not sufficiently differentiate itself, impacting its originality.']",3,2,2,3,Reject
hfU7Ka5cfrC,"The paper proposes a novel method for optimizing hyperparameters in machine learning models using implicit differentiation, claiming to do so more efficiently without requiring multiple training restarts. It includes theoretical justifications for convergence to true hypergradients and empirical results demonstrating competitive performance across several datasets.","['Can the authors clarify how their method improves upon existing hypergradient methods, specifically in terms of computational efficiency?', ""Could additional details on the experimental setup and results be provided to offer a clearer picture of the method's effectiveness?"", 'What additional experiments could be conducted to explore the limits of hyperparameter settings for the proposed method?']","[""The complexity of the theoretical framework may obscure understanding for some readers, which could hinder the paper's accessibility."", 'While the method shows promise, there is a lack of extensive testing across diverse datasets and hyperparameter settings that could provide a more comprehensive assessment.', 'The paper does not fully address the potential for overfitting, especially when hyperparameters are tuned too aggressively based on validation performance.']",False,3,3,3,5,4,"['Addresses a significant and practical problem in machine learning: hyperparameter optimization.', 'Introduces an innovative method for optimizing hyperparameters that claims to reduce computational costs.', 'Provides a theoretical framework for convergence to the true hypergradient.', 'Demonstrates competitive performance on several benchmark datasets, showcasing the potential of the method.']","['The method lacks a thorough empirical evaluation across a wide range of datasets, which is crucial for verifying its effectiveness.', 'Sections of the paper are complex and could benefit from clearer explanations, which may hinder understanding for a broader audience.', 'There is a lack of detailed ablation studies to demonstrate the contributions of various components of the proposed method.', 'The novelty of the approach appears incremental, relying heavily on previous works without significant advances.']",3,3,3,4,Reject
dLTXoSIcrik,"The paper proposes the POELA algorithm to mitigate overfitting in offline policy optimization due to importance sampling. It provides theoretical justification and empirical validation through experiments in healthcare-related scenarios, claiming improved performance over existing methods.","['Can the authors clarify the theoretical contributions and their implications?', 'What additional experiments could strengthen the evaluation of POELA?', 'Could the authors provide clearer explanations of the metrics used in their evaluations?']","['The paper does not adequately address the limitations of the proposed method.', 'Clarity issues may hinder understanding and reproducibility.']",False,3,2,3,4,4,"['Addresses a significant problem of overfitting in offline policy optimization.', 'The proposed algorithm is theoretically justified and empirically validated.', 'Demonstrates improved performance in relevant applications.']","['Lacks clarity in the presentation, particularly in the theoretical sections, making it difficult to follow the arguments and understand the implications of the proposed method. For instance, the explanation of the overfitting phenomenon could be clearer.', 'Insufficient evaluation against a broader range of existing algorithms, limiting the comparison of effectiveness.', 'Limited ablation studies to assess the impact of different components of the method.']",3,3,2,4,Reject
-dzXGe2FyW6,The paper proposes a new fairness goal termed Equalized Robustness (ER) to ensure fair model robustness against unseen distribution shifts across majority and minority groups. It introduces a new fairness learning algorithm called Curvature Matching (CUMA) to achieve both traditional in-distribution fairness and the new robust fairness goal. Experimental results indicate that CUMA outperforms traditional methods under distribution shifts while maintaining similar overall accuracies.,"['Can the authors provide more details on the implementation of the curvature matching and its computational efficiency?', 'What specific limitations or trade-offs were observed in the experiments, especially regarding the balance between fairness and accuracy?']","['The clarity of the paper is lacking in several areas, particularly in the explanation of new concepts and metrics introduced.', 'The experimental design may not fully capture the robustness of the proposed methods, especially under varying distribution shifts.']",False,2,2,3,5,4,"['The introduction of a new fairness goal (Equalized Robustness) is timely and addresses a critical gap in current fairness metrics.', 'CUMA shows potential in achieving robustness against distribution shifts without sacrificing in-distribution fairness.', 'The experiments conducted on multiple datasets provide a comprehensive evaluation of the proposed methodology.']","['The methodology lacks clarity in terms of how the curvature matching is implemented and its computational feasibility.', 'There is insufficient detail regarding the experimental setup and how the results were obtained, particularly regarding the distribution shifts.', 'The paper does not adequately address potential drawbacks or limitations of the proposed approach, which could mislead readers about its applicability in real-world scenarios.']",3,3,3,4,Reject
m8uJvVgwRci,"The paper proposes Weak Indirect Supervision (WIS), a framework for synthesizing training labels from indirect supervision sources with different output spaces. It introduces the Probabilistic Label Relation Model (PLRM) to address challenges related to mismatched label spaces, supported by theoretical analysis and empirical results showing improvements over existing methods.","[""Can the authors provide more detailed explanations of PLRM's construction and how it effectively utilizes label relations?"", 'What additional experiments could be conducted to better demonstrate the robustness and effectiveness of the proposed method?']","['The clarity of the paper needs improvement, particularly in the description of the model and experimental setup.', 'The experimental comparisons with existing methods are not exhaustive enough to convincingly demonstrate the advantages of PLRM.']",False,3,3,3,5,4,"['Addresses a relevant and practical problem in machine learning related to label synthesis.', 'Introduces a novel framework (WIS) and a probabilistic model (PLRM) that extends existing weak supervision methods.', 'Provides theoretical foundations and demonstrates advantages through quantitative experiments.']","['The methodology lacks clarity in some aspects, making it challenging to fully grasp the implementation details of PLRM.', 'The experimental evaluations are somewhat limited and do not sufficiently validate the proposed framework against a broad range of benchmarks.', 'The significance of the contributions could be articulated more clearly relative to existing literature, making it difficult to assess the advancements provided by the authors.']",3,4,4,3,Reject
ckZY7DGa7FQ,"The paper proposes belief fine-tuning (BFT), a framework for improving belief state modeling in partially observable Markov systems. BFT enhances the accuracy of belief models by dynamically fine-tuning them during inference, addressing previous limitations in multi-agent settings. The authors validate their approach through experiments on the Hanabi game, showing competitive performance against traditional methods.","['Can the authors clarify the implementation details of BFT, especially how fine-tuning is performed on the belief model?', 'What measures are taken to ensure that the improvements shown in Hanabi can be replicated in other multi-agent systems?', 'How does BFT compare with existing models beyond the benchmark provided in Hanabi?']",['The paper could benefit from a more thorough discussion of its limitations and potential negative implications of applying BFT in practice.'],False,3,2,3,5,4,"['Addresses a critical challenge in belief state modeling, particularly in the context of multi-agent systems.', 'Introduces a novel framework (BFT) that leverages dynamic programming to improve belief state accuracy at inference time.', 'Comprehensive experiments demonstrate the effectiveness of BFT, especially in the Hanabi game, showcasing its practical applicability.']","['The clarity of exposition could be improved, particularly in explaining technical details and the implications of the findings.', 'Some sections, particularly those detailing the methodology, could benefit from more structured organization and clearer definitions.', 'While the results are promising, more ablation studies could strengthen the claims about the advantages of BFT over traditional methods.']",3,3,3,4,Reject
e6MWIbNeW1,"The paper proposes an inductive graph partitioning (IGP) framework that aims to balance quality and efficiency in graph partitioning across multiple associated graphs. It employs a dual graph neural network trained on historical graphs to generalize to new graphs efficiently. The authors claim that IGP achieves competitive results compared to state-of-the-art methods, demonstrating improved runtime without sacrificing quality.","['Can the authors clarify how IGP significantly improves upon existing methods in terms of both runtime and partitioning quality?', 'Could additional ablation studies be included to better demonstrate the contribution of each component of the IGP framework?']","['The paper does not adequately discuss the limitations of the proposed method or potential negative societal impacts.', 'Clarity issues in the paper may lead to misunderstandings about the proposed methodology and results.']",False,2,2,3,3,4,"['The IGP framework effectively addresses the NP-hard challenge of graph partitioning through an inductive approach.', 'The methodology is comprehensive, and the experimental results across multiple datasets support the claims of improved efficiency.', 'The dual GNN structure is a novel contribution that leverages historical graph data.']","['The clarity of the presentation is insufficient; certain sections, particularly in the methodology and results, are convoluted and may confuse readers.', 'The paper does not clearly articulate how IGP significantly improves upon existing transductive and inductive graph partitioning methods, which diminishes its perceived novelty.', 'Experimental results lack sufficient benchmarks and comparisons to existing state-of-the-art methods, making it difficult to validate the claims of quality and efficiency.', 'Additional ablation studies would strengthen the understanding of the contributions of various components of the model.']",3,2,2,3,Reject
QNW1OrjynpT,"The paper investigates the short-term memory capabilities of neural language models, comparing transformers and LSTMs. It tests their ability to retrieve prior context tokens based on various factors such as the number of items retrieved, semantic coherence, and intervening text length. The results show that transformers can retrieve verbatim token information while LSTMs primarily capture a semantic gist, with implications for understanding memory systems in language processing.","['Can the authors clarify the rationale behind the choice of noun lists and their potential limitations?', ""What measures were taken to ensure that the models' performance wasn't biased by the specific choice of training data?"", 'How do the authors envision applying these findings in real-world language processing tasks?', 'Can the authors clarify the choice of specific model architectures and training datasets used in the experiments?']","['The evaluation of the models lacks thorough statistical analysis, which could strengthen the claims made regarding their memory retrieval capabilities.', 'There is insufficient discussion on the implications of the findings for future model design and cognitive science.', 'The study does not explore potential negative implications of improved memory retrieval in language models, such as overfitting to specific contexts.']",False,3,3,3,5,4,"['Addresses a crucial aspect of language models: memory retrieval mechanisms.', 'Comprehensive experimental evaluation comparing transformers and LSTMs.', 'Findings highlight significant differences in memory capabilities between architectures.']","['The methodology lacks clarity in experimental setup and analysis, making it difficult to fully understand the implications of the results.', 'The presentation is verbose and could benefit from more concise writing.', 'The reliance on user-defined lists introduces potential biases that are not adequately addressed.', 'The novelty of the approach is limited, as it primarily builds on established models without proposing fundamentally new architectures or mechanisms.']",3,3,3,4,Reject
R332S76RjxS,"The paper presents a global convergence theory for implicit neural networks activated by ReLU, demonstrating that gradient descent can converge to a global minimum at a linear rate under over-parameterization. It addresses a theoretical gap in understanding implicit neural networks, which have been empirically successful but not well-studied theoretically.","['Can the authors clarify certain assumptions and key definitions to enhance understanding?', 'Could the authors provide more experimental results to validate the theoretical claims?', 'How do the findings specifically advance the existing literature on implicit neural networks?']","['The paper does not adequately address potential limitations of the proposed theory or its assumptions.', 'The clarity of the paper is a significant concern, as the dense mathematical content may deter readers.']",False,3,2,3,5,4,"['Addresses an important theoretical gap in implicit neural networks, providing a significant contribution to the field.', 'Demonstrates a novel result that gradient descent can converge linearly for over-parameterized implicit networks.', 'Highlights the importance of over-parameterization in achieving convergence in implicit neural networks.']","['The clarity and organization of the paper are poor, making it difficult to follow the mathematical derivations and overall argumentation.', 'The theoretical exposition is dense and may be difficult for readers not familiar with advanced mathematical concepts.', 'Limited experimental validation to support the theoretical claims, which weakens the impact and applicability of the results.']",3,3,2,4,Reject
V3C8p78sDa,"The paper investigates the relationship between upstream pre-training accuracy and downstream task performance, revealing a saturation phenomenon where downstream performance does not continue to improve with upstream accuracy. It includes extensive experimentation with over 4800 trials involving different architectures (Vision Transformers, MLP-Mixers, ResNets) across various datasets.","['Can the authors elaborate on the novel contributions of their findings in comparison to existing literature?', 'What specific insights can be drawn from the observed saturation behavior that have not been previously reported?', 'Could the authors clarify their methodologies to improve reproducibility?']","['The lack of novel theoretical insights or frameworks to explain the observed phenomena.', 'Insufficient clarity and detail in the experimental setup, which may affect reproducibility.']",False,3,2,3,5,4,"['Extensive empirical analysis with over 4800 experiments provides strong evidence for the claims made.', 'The investigation into the saturation phenomenon challenges existing narratives about linear transfer of performance improvements.', 'The paper offers valuable insights into the dynamics of transfer learning, contributing to a deeper understanding of model performance across various tasks.']","['The saturation phenomenon discussed is not novel and has been previously explored in related works.', 'The paper lacks clarity in its presentation, making it difficult to follow key findings; clearer organization and explicit definitions would enhance understanding.', 'Some methodologies are insufficiently explained, which could hinder reproducibility; detailed descriptions of experimental setups are needed.', 'The theoretical foundation supporting the empirical findings is weak, limiting the overall contribution; a more robust theoretical framework would strengthen the paper.']",3,3,2,4,Reject
EVqFdCB5PfV,"The paper introduces DOCHOPPER, a model designed for answering complex questions over long, hierarchically structured documents. It employs an iterative attention mechanism that allows the model to navigate through sections of a document, improving efficiency and performance in multi-hop question answering tasks. The authors demonstrate state-of-the-art results on several datasets while also highlighting the model's computational efficiency compared to previous approaches.","['Can the authors provide more clarity on the iterative attention mechanism and how it improves information retrieval?', 'What specific contributions does DOCHOPPER make over existing hierarchical attention models?', ""Could the authors elaborate on the results of the ablation studies and how they validate the model's design choices?"", 'How does DOCHOPPER handle the trade-off between retrieval efficiency and the accuracy of the answers across different datasets?']","['The paper could be strengthened by providing more detailed analysis and discussion regarding the importance of each component in DOCHOPPER.', 'Additional experiments or analysis on the scalability of the model for extremely long documents would be beneficial.']",False,3,2,3,6,4,"['DOCHOPPER effectively tackles the challenge of multi-hop question answering over extensive documents, which is a significant and practical problem in NLP.', 'The iterative attention mechanism allows for dynamic information retrieval, showing innovation in how the model processes and navigates through document structures.', 'The experimental results indicate strong performance, with DOCHOPPER achieving state-of-the-art results on multiple datasets while also demonstrating improved efficiency.']","['The clarity of the paper is lacking in certain sections, particularly in the explanation of the iterative attention process and the rationale behind the architectural choices.', 'While the model shows improvement in performance, more detailed comparisons with baseline models and a thorough ablation study are necessary to validate claims of efficiency and effectiveness fully.', ""The impact of the hierarchical structure on the model's performance could be elaborated further with specific examples or visualizations to enhance understanding.""]",3,3,2,4,Reject
3ILxkQ7yElm,"The paper proposes a novel scene representation called the environment field, which encodes reaching distances to facilitate agent navigation in both 2D mazes and 3D indoor environments. It leverages implicit functions for continuous representation and demonstrates applications in agent navigation and human trajectory prediction, showing promising results compared to existing methods.","['Could the authors provide more clarity on the architecture of the implicit neural networks used for training?', 'How do the authors plan to address the limitations related to the assumptions made during human trajectory predictions?', 'Can the authors elaborate on how the implicit function could be generalized for more complex environments or tasks?']","['The paper does not adequately address the limitations of the implicit function representation, particularly in complex environments with dynamic obstacles.', 'Clarity issues may hinder reproducibility and understanding of the proposed method.']",False,2,2,3,5,4,"['The concept of using an implicit function to create a continuous representation of reaching distances is innovative and addresses a significant problem in dynamic navigation.', 'Demonstrated applicability in both 2D and 3D environments, enhancing the versatility of the method.', 'The paper presents extensive experiments demonstrating the effectiveness of the proposed method in 2D maze navigation and 3D human trajectory modeling.']","['The clarity of the paper could be improved, particularly regarding the details of the methodology and the implementation of implicit functions.', 'The experimental results could benefit from more detailed analysis, especially when comparing against baseline methods.', 'There is insufficient discussion on the limitations of the approach, particularly regarding the assumptions made in the human navigation model and potential challenges in real-world applications.']",3,2,2,3,Reject
ccWaPGl9Hq,"The paper proposes a theoretical framework for Deployment-Efficient Reinforcement Learning (DE-RL), establishing lower bounds for deployment complexity and introducing algorithms aimed at achieving optimal deployment efficiency, particularly in finite-horizon linear MDPs. While the theoretical contributions are significant, the paper lacks empirical validation.","['What empirical evidence can the authors provide to support the effectiveness of the proposed algorithms in real-world scenarios?', 'Can the authors clarify the sections that are difficult to follow, particularly in terms of the exposition of the theoretical results?']","['The lack of experimental validation is a significant limitation, hindering the practical applicability of the theoretical results.', 'The clarity of the writing needs improvement to ensure that the findings are accessible to a broader audience.']",False,3,3,3,6,4,"['The formal definition of Deployment-Efficient Reinforcement Learning (DE-RL) fills a critical gap in the literature.', 'Establishing information-theoretic lower bounds for deployment complexity provides valuable insights.', 'The proposed algorithms demonstrate a practical approach to achieving optimal deployment efficiency.']","['The paper lacks experimental validation, which is crucial for demonstrating the practical applicability of the proposed algorithms.', 'The exposition is dense and lacks clarity, making it difficult for readers to follow the arguments and results.', 'The practical implications of the theoretical results are not adequately discussed or demonstrated.']",4,3,3,4,Reject
BlyXYc4wF2-,"The paper addresses the challenge of safety constraints in multi-agent reinforcement learning (MARL) by proposing two algorithms, MACPO and MAPPO-Lagrangian, and introducing a new benchmark suite, Safe Multi-Agent MuJoCo, for testing these methods against existing MARL baselines. The authors provide theoretical guarantees for their approaches, aiming to ensure both reward maximization and safety.","['How do the authors plan to address the clarity issues? Are there plans to include more detailed experimental comparisons in a possible future revision?', 'Could the authors clarify the key differences between MACPO, MAPPO-Lagrangian, and other existing methods? What specific advances do these algorithms represent?', 'Can additional ablation studies be provided to better understand the contributions of various components of the proposed algorithms?']","['The experimental section lacks depth, with limited comparative analysis against a broader range of existing methods.', 'The clarity of some of the theoretical explanations needs improvement to ensure the audience can follow the proposed methods effectively.']",False,3,3,3,4,4,"['Addresses a critical and timely issue in AI safety, specifically in the context of multi-agent systems.', 'Theoretical guarantees of monotonic improvement and constraint satisfaction for the proposed algorithms are well-articulated.', 'The introduction of a new benchmark suite for safe MARL research is a valuable contribution that could aid future studies.']","[""The clarity of the presentation could be improved, particularly in explaining the algorithms' steps and their implications."", 'The empirical validation lacks comprehensive comparisons with existing methods in various scenarios.', 'The paper does not sufficiently address potential limitations or edge cases regarding safety constraint satisfaction.']",3,3,4,4,Reject
Dup_dDqkZC5,"The paper introduces Latent Variable Sequential Set Transformers (AutoBots) for multi-agent motion prediction, utilizing a transformer-based architecture to capture social, contextual, and temporal information. It claims to provide robust predictions across various datasets, including nuScenes and Argoverse.","['Can the authors clarify the training process and provide more details on the architecture?', 'What additional ablation studies can be included to strengthen the evaluation?', 'How does the model handle potential limitations in real-world scenarios?']","['Insufficient discussion on the limitations of the model and its performance in edge cases.', 'Lack of consideration of societal impacts, safety concerns, and ethical implications of deploying such models.']",True,3,3,4,6,4,"['The proposed architecture shows innovative use of transformers for multi-agent trajectory predictions.', ""Strong performance on competitive datasets like nuScenes and Argoverse, demonstrating the model's potential."", 'The paper provides a comprehensive comparison with existing models, highlighting the benefits of the proposed approach.']","['The paper lacks clarity in explaining the underlying mechanisms and training processes of the proposed model.', 'Limited ablation studies to analyze the impact of different components on performance.', 'The evaluation mainly focuses on motion prediction without adequately addressing broader implications or limitations of the approach.', 'Potential negative societal impacts are not discussed, which is crucial for work related to autonomous systems.']",4,3,3,4,Reject
x4tkHYGpTdq,"The paper presents Dually Sparsity-Embedded Efficient Tuning (DSEE), a framework aimed at improving the efficiency of fine-tuning large pre-trained language models by leveraging sparsity in both weight updates and final model weights. It claims to achieve significant parameter and resource efficiency while maintaining competitive performance across various NLP tasks, supported by experimental results.","['Could the authors clarify the rationale behind certain design choices in the DSEE framework?', 'Can the authors provide more details on the convergence behavior of DSEE compared to traditional fine-tuning methods?', 'What specific metrics were used to measure resource efficiency, and how do they compare with other methods?', 'Can the authors provide clearer explanations of the algorithms, particularly the decomposition and sparsity mechanisms?']","['The lack of clarity in certain sections may hinder understanding and reproducibility of the proposed method.', 'The paper could provide a deeper analysis of the efficiency gains and performance trade-offs when using the DSEE framework.', 'Potential ethical implications of deploying large language models and the associated societal impacts are not addressed.']",False,2,2,3,4,4,"['Addresses important issues of efficiency in fine-tuning large pre-trained models, which is highly relevant in the current landscape of NLP.', 'The proposed method combines both unstructured and structured sparsity, providing a comprehensive approach to achieving resource efficiency.', 'Extensive experimental results demonstrate the effectiveness of the proposed method across various language models and tasks.']","['The organization and clarity of the paper could be improved, as many sections are dense and difficult to follow.', 'The novelty of the approach is questionable, as sparsity in model training is a well-explored area.', 'The experimental evaluation lacks rigorous analysis and validation, making it hard to assess the true impact of the proposed method.', 'Insufficient comparison with a robust set of baseline methods weakens the claims of improvement.']",3,2,2,3,Reject
Rupm2vTg1pe,"The paper introduces the Infinite Contextual Graph Markov Model (ICGMM), an extension of the Contextual Graph Markov Model (CGMM) that incorporates Hierarchical Dirichlet Processes to automate hyperparameter selection and improve scalability. The model is evaluated on eight graph classification tasks, claiming competitive performance against supervised methods.","['Can the authors clarify the methodology behind the integration of Hierarchical Dirichlet Processes into CGMM?', 'Could the authors provide more details on the experimental setup and how hyperparameters were chosen?', 'What specific advantages does ICGMM offer over CGMM and other models in practical applications?']","['The paper does not adequately address the limitations of the proposed ICGMM, particularly regarding dataset size and edge feature utilization.', 'The reliance on Gibbs sampling for inference may not scale well for very large graphs.']",False,3,3,3,5,4,"['Addresses the important issue of hyperparameter selection in deep graph networks.', 'Integrates Bayesian nonparametric methods, which is a valuable contribution to graph representation learning.', 'Demonstrates competitive performance on multiple graph classification tasks.']","['The methodology lacks clarity, making it difficult to follow the main contributions and implementation details.', 'Experimental results are presented without sufficient detail on the experimental setup, hindering reproducibility.', 'Comparative analysis with existing models is limited and does not convincingly demonstrate the advantages of ICGMM.']",3,3,3,4,Reject
RB_2cor6d-w,"The paper proposes APSyn, a synthesizer for adversarial multi-patch attacks, aiming to create imperceptible perturbations to fool deep neural networks while minimizing pixel distortion. The approach combines program synthesis with numerical optimization to explore patch configurations and evaluates the method against standard datasets. The results show promising success rates and lower distortion compared to existing attacks.","['Can the authors provide more details on the optimization process, particularly regarding gradient estimation for discrete variables?', 'How does APSyn perform against a broader range of existing methods beyond C&W? Are there comparisons to other recent adversarial attacks?', 'Could the authors clarify how the program synthesis framework specifically contributes to the efficiency and effectiveness of the attack?']","['The explanation of the optimization process could be expanded to provide more clarity.', ""The experimental setup does not benchmark against a comprehensive set of adversarial attacks, which could limit the claims made about the method's effectiveness.""]",True,3,3,3,6,4,"['The approach addresses a significant problem in adversarial machine learning, particularly the challenge of generating imperceptible adversarial attacks in physical settings.', 'The combination of program synthesis and numerical optimization is innovative and provides a structured way to explore patch configurations.', 'The experimental results demonstrate competitive performance with existing methods, particularly in terms of success rates and lower L0 distortion.']","['The explanation of the optimization techniques used could be more detailed to enhance reproducibility and understanding of the method.', 'The paper would benefit from a broader comparison with existing adversarial attack methods to validate its effectiveness.', 'Some sections could be more concise and clearer, particularly in the related work and technical explanations.']",3,3,3,4,Reject
0uZu36la_y4,"The paper introduces Class Focused Online Learning (CFOL), a method aimed at improving adversarial training by minimizing the worst class error instead of the average error. The authors argue that focusing solely on average accuracy can leave the weakest classes vulnerable to adversarial attacks. CFOL provides theoretical convergence guarantees and shows empirical improvements across multiple datasets, including CIFAR10, CIFAR100, and STL10.","['Can the authors provide a more detailed comparison of CFOL against other state-of-the-art methods?', 'How might the theoretical guarantees hold up in more complex, real-world scenarios?', 'What are the implications of the convergence guarantees in practical scenarios?']","['The potential limitations of CFOL in more complex datasets or adversarial settings are not thoroughly discussed.', 'The paper could benefit from additional clarity in explaining technical details and methodology.']",False,3,3,3,5,4,"['Addresses a critical issue in adversarial training by focusing on the worst class accuracy.', 'Provides theoretical guarantees for the proposed method, enhancing its credibility.', 'Demonstrates empirical improvements across various datasets, indicating practical applicability.']","['The theoretical guarantees presented may not be fully validated across diverse real-world scenarios.', 'Lacks comprehensive comparisons with existing methods, limiting the understanding of its relative performance.', 'Clarity in explaining the relationship between CFOL and previous work could be improved.']",4,3,3,4,Reject
AAeMQz0x4nA,"The paper proposes Explicit Credit Assignment joint Q-learning (ECAQ) to address the multi-agent credit assignment problem in cooperative environments. It formulates an explicit framework for agents to weight their individual Q-values, aiming to improve interpretability and performance. Theoretical foundations and empirical results are provided, but clarity and depth of evaluation are lacking.","['Can the authors clarify how their method differs significantly from existing implicit credit assignment methods?', 'What measures would ensure that the findings are generalizable beyond the tested scenarios?', 'Could additional experiments be provided to cover various multi-agent tasks to strengthen the claims?']","['The paper does not adequately address the limitations of the proposed approach and its applicability across different multi-agent environments.', 'Potential ethical implications of the credit assignment process are not discussed.']",True,3,2,3,5,4,"['The explicit formulation of credit assignment is a novel contribution to the multi-agent reinforcement learning field.', 'The paper provides a solid theoretical foundation for the proposed method.', 'Extensive empirical evaluations demonstrate the potential benefits of the approach.']","['The clarity of the paper is lacking in several areas, particularly regarding implementation details and theoretical explanations.', 'The originality of the contributions is questionable, as the proposed method does not significantly deviate from existing approaches.', 'The empirical evaluation lacks depth and breadth, raising questions about the generalizability of the findings.']",3,3,2,4,Reject
PGGjnBiQ84G,"The paper proposes a novel approach for learning surface parameterization for document image unwarping by creating a continuous bijective mapping between 3D surface positions and 2D texture coordinates. It integrates differentiable rendering techniques to achieve state-of-the-art results in document unwarping and texture editing. However, concerns regarding clarity, experimental validation, and ethical implications are raised.","['Can the authors provide more details about the implementation of the MLPs?', 'What specific datasets were used for training and how do they compare to existing datasets?', 'How does the method generalize to different types of documents beyond those used in experiments?']","['The clarity of the methodology needs improvement to ensure reproducibility.', 'The lack of extensive experimental validation raises concerns about the generalizability of the results.']",True,2,1,2,4,4,"['The proposed method effectively integrates recent advancements in differentiable rendering techniques.', 'The approach shows state-of-the-art performance in document unwarping and texture editing.', 'The work addresses an important problem in document processing, which has practical applications.']","['The paper lacks clarity in explaining the architecture of the proposed MLPs and their training process.', 'Details on the datasets used for training and evaluation are insufficient.', 'The experimental validation appears limited, with a need for more comprehensive testing across diverse real-world scenarios.', 'The paper does not sufficiently address potential limitations and assumptions made in the proposed method.']",3,2,1,4,Reject
xDIvIqQ3DXD,"The paper investigates the approximation properties of recurrent encoder-decoder architectures, focusing on their differences from traditional RNNs. It provides a universal approximation theorem and introduces the concept of a 'temporal product structure' that characterizes the input-output relationships that can be approximated efficiently.","['Can the authors provide more detailed explanations of the implications of their findings?', 'Are there practical applications or numerical experiments that can validate their theoretical results?', 'How do the results relate to existing work on RNNs and other sequence modeling architectures?']","['The paper does not adequately address the clarity of the presentation, which hampers understanding.', 'Lacks sufficient experimental validation to support theoretical claims.']",False,3,2,2,4,4,"['Addresses a relevant and significant topic in the field of sequence modeling, particularly in understanding encoder-decoder architectures.', 'Presents new theoretical results that extend the understanding of the approximation capabilities of these architectures.', 'Provides a universal approximation theorem, which is a notable contribution to the theoretical foundations of deep learning models.']","['The clarity of the writing is poor, making it difficult to follow the contributions and implications of the results. Specific sections, such as the introduction and conclusion, could be rewritten for better coherence.', 'The experimental validation is limited; more extensive experiments or practical examples would strengthen the claims and demonstrate the applicability of the theoretical results.', 'Lacks a discussion on potential limitations or negative impacts of the theoretical findings, which is important for grounded research.']",3,2,2,3,Reject
NrB52z3eOTY,"The paper introduces KLoS, a Kullback-Leibler divergence measure designed for uncertainty estimation in classifiers, particularly in open-world recognition contexts. It leverages evidential models to quantify both in-distribution and out-of-distribution uncertainties without requiring out-of-distribution training data. The proposed KLoSNet neural network refines these uncertainty estimates, and extensive experiments demonstrate its effectiveness compared to existing measures.","['Could the authors clarify the methodology used for KLoS and how it differs from existing measures?', 'What specific improvements or changes to the experimental setup would enhance the clarity of the results?', 'Can the authors provide more discussion on the limitations of KLoS compared to traditional measures?']","['The paper does not adequately address the limitations regarding the variability of out-of-distribution datasets and their impact on model performance.', 'Further ablation studies could help clarify the impact of various components of the proposed method.']",False,3,2,3,6,4,"['Addresses a critical issue in machine learning related to uncertainty estimation in classifiers.', 'Introduces KLoS as a novel measure that captures both class confusion and lack of evidence.', 'Comprehensive experimental validation across various datasets shows promising results.']","['The clarity of the paper is lacking; complex concepts and methodologies are not well articulated.', 'Some experimental setups lack robustness and detail, particularly regarding hyperparameter choices and the impact of out-of-distribution datasets.', 'The novelty of KLoS and its advantages over existing methods are not sufficiently justified.']",3,3,3,4,Reject
rMbLORc8oS,"The paper proposes SemiRetro, a framework for retrosynthesis prediction that combines template-based and template-free methods using semi-templates and a directed relational graph attention (DRGAT) layer. It claims to improve accuracy and scalability, demonstrating significant improvements over existing methods on the USPTO-50k dataset.","['Can the authors provide more detailed explanations about the DRGAT layer and its advantages?', 'What measures were taken to ensure that the semi-templates do not lead to overfitting?', 'Will the authors consider conducting additional experiments with a broader range of baselines?', 'Could the authors provide further insights into the interpretability aspect of the proposed method?']","['The clarity of the methodology, especially concerning the DRGAT layer, needs improvement.', 'Limited comparison with other state-of-the-art methods may undermine claims of superiority.', 'The potential for overfitting due to template selection and the specificity of the training data is not adequately addressed.']",False,3,3,3,6,4,"['The integration of template-based and template-free methods addresses significant challenges in retrosynthesis prediction.', 'The introduction of semi-templates reduces redundancy and enhances scalability.', 'The DRGAT layer shows promise in improving center identification accuracy.', 'Experimental results indicate clear improvements over existing state-of-the-art methods.']","['The paper lacks clarity in the description of the DRGAT layer and the semi-template concept.', 'More comprehensive ablation studies are needed to validate the contributions of the DRGAT layer and semi-templates.', 'The reliance on a single dataset raises concerns about the generalizability of the results.', 'Limited comparisons with a broader range of existing methods may undermine claims of superiority.']",3,3,3,4,Reject
U-_89RnR8F,"The paper proposes a systematic method called Conceptual Counterfactual Explanations (CCE) for explaining model mistakes using human-understandable concepts. It claims to identify spurious correlations and biases in trained models without requiring access to training data. The validation of CCE is conducted on various datasets, including medical applications, and the authors provide public code for their method.","['Can the authors clarify how CCE significantly differs from existing methods based on counterfactual explanations?', 'What specific metrics were used to validate the effectiveness of CCE, and how do these metrics relate to the real-world applicability of the findings?', 'Could the authors provide additional examples or case studies to illustrate the practical benefits of using CCE in model evaluation?']","['The paper does not adequately address the limitations of the proposed method, particularly in terms of its generalizability to various model architectures or tasks.', 'The reliance on a fixed concept bank might limit the applicability of CCE in diverse domains where concepts need to be dynamically defined.']",False,2,2,2,4,4,"['The approach of using CCE to explain model mistakes in terms of human-understandable concepts is novel and could enhance model interpretability.', 'The validation of the method on challenging datasets, including real-world medical data, showcases the practical applicability of the proposed approach.', 'The authors provide all necessary code and data publicly, which facilitates reproducibility.']","['The novelty of the approach is questionable, as it seems to heavily rely on existing methods such as counterfactual explanations and concept activation vectors without sufficient differentiation.', 'The paper lacks clarity in its exposition, making it difficult to follow the methodology and the significance of findings.', 'While the authors claim to have identified biases and spurious correlations, the evidence presented is anecdotal and does not thoroughly explore these implications.', 'The evaluation metrics used to assess the effectiveness of CCE could be better defined and contextualized.']",3,2,2,3,Reject
Qu_XudmGajz,"The paper proposes a novel approach to improve the observational distribution in Variational Autoencoders (VAEs) by introducing a low-rank multivariate normal distribution to capture spatial dependencies among pixels. This approach aims to resolve issues with pixel-wise independent distributions that lead to spatial incoherence in generated samples, thereby enhancing the quality of the outputs.","['Can the authors elaborate on potential challenges when integrating the proposed observational distribution into existing VAE frameworks?', 'What measures can be taken to ensure that the method does not overfit to the training data?', 'Can the authors provide more details on the experimental setup and parameters used for the comparison with standard VAEs?']","['The paper does not sufficiently address the practical challenges of applying the proposed method in real-world scenarios, such as computational efficiency and scalability.', 'Clarity issues may hinder reproducibility and understanding of the proposed method, which is critical for future research.']",True,3,3,3,6,4,"['Addresses an important limitation in VAEs related to the observational distribution, which is often overlooked.', 'The introduction of a low-rank parameterization for the covariance matrix is innovative and relevant for image synthesis tasks.', 'Experimental results show that the proposed method produces more spatially coherent samples compared to standard VAEs.']","['The paper lacks clarity in some sections, particularly regarding the training process and the implications of the entropy constraint, which could confuse readers.', 'While the experiments show improvements, the evaluation could benefit from more rigorous quantitative analysis beyond FID scores, such as perceptual metrics or user studies.', 'Training instability with non-diagonal covariance matrices is mentioned but not explored in depth, leaving uncertainty about the robustness of the proposed method.']",3,3,3,4,Accept
GrFix2vWsh4,"The paper investigates the relationship between Cross-Entropy (CE) and Dice losses in segmentation tasks, focusing on their theoretical underpinnings and practical implications. It claims to reveal hidden label-marginal biases in these losses and proposes new loss functions that integrate CE with regularization to improve performance, especially in imbalanced scenarios.","['Can the authors provide additional experiments on more diverse datasets to strengthen the claims about the proposed loss functions?', 'Could the authors clarify the implications of their theoretical findings in practical terms for practitioners working with segmentation tasks?']","['The analysis and results are somewhat limited in scope; further validation across various segmentation tasks would enhance robustness.', 'The complexity of the theoretical analysis might make it less accessible to practitioners in the field.']",False,3,4,3,6,4,"['Theoretical insights into the relationship between CE and Dice losses are valuable and can guide future research on loss function design.', 'The paper provides a clear explanation of how label-marginal biases affect segmentation performance across different datasets.', 'The proposed solution for controlling label-marginal bias is novel and has potential implications for improving segmentation results, especially in imbalanced scenarios.']","['The experiments are primarily conducted on two datasets, which may limit the generalizability of the findings.', 'The paper could benefit from more clarity in the theoretical derivations, as some of the mathematical concepts may be hard to follow for readers not deeply familiar with optimization and information theory.', 'There is a lack of extensive comparison with other state-of-the-art loss functions beyond just CE and Dice, which may overlook potentially competitive approaches.']",3,3,4,4,Reject
pzgENfIRBil,"The paper proposes a method named Self-consistent Gradient-like Eigen Decomposition (SCGLED) for solving the Schrödinger equation, aiming to eliminate reliance on heuristic initial guesses. While it claims to improve efficiency and robustness compared to traditional methods, the clarity of the exposition and the originality of the contributions are questioned.","['Can the authors clarify how SCGLED significantly differs from traditional methods?', 'What evidence can the authors provide to show the robustness of SCGLED across varied scenarios?', 'Could the authors simplify their explanations for better accessibility?']","['Significant concerns regarding clarity and the novelty of the contributions.', 'The experimental validation is not comprehensive enough to support the claims made.']",False,2,2,2,5,4,"['Addresses a significant problem in computational physics.', 'Proposes a novel approach that integrates concepts from online learning and eigen-decomposition.', 'Reports performance advantages over traditional initial guess methods.']","['Lacks clarity in the presentation, particularly in the explanation of the algorithm and its implementation.', 'The method appears to build upon existing techniques without clear differentiation or substantial improvements.', 'Experimental results do not convincingly demonstrate robustness or generalizability across different scenarios.', 'The writing is verbose and could be more concise for better understanding.']",3,2,2,3,Reject
Mlwe37htstv,"The paper proposes Wasserstein Policy Optimization (WPO) and Sinkhorn Policy Optimization (SPO) as new methods for policy optimization in reinforcement learning, utilizing Wasserstein and Sinkhorn distances. The authors derive closed-form updates and provide theoretical guarantees, along with experimental results demonstrating their effectiveness compared to traditional methods.","['Can the authors clarify the assumptions made in their theoretical derivations?', 'What additional experiments could be conducted to demonstrate the robustness of WPO and SPO in a wider variety of scenarios?', 'Can the authors provide a clearer explanation of their experimental setup and results presentation?']","[""The lack of comprehensive experimental results makes it difficult to fully assess the proposed methods' efficacy against a diverse set of benchmarks."", 'The potential computational complexity and sensitivity to hyperparameters are not adequately discussed.']",False,3,3,3,5,4,"['The introduction of Wasserstein and Sinkhorn distances for policy optimization is a novel approach.', 'The theoretical guarantees for WPO and SPO provide valuable insights into their performance.', 'Empirical results show some promise in terms of robustness and sample efficiency.']","['The theoretical contributions lack clarity and depth, particularly regarding assumptions and implications.', 'The experimental evaluation is limited, lacking a diverse range of environments and benchmarks.', 'The overall clarity and organization of the paper could be improved.']",3,3,3,3,Reject
nKWjE4QF1hB,The paper introduces a Proof Cost Network (PCN) that modifies the AlphaZero algorithm's training target to prioritize solving games quickly rather than just winning. It presents a new heuristic for estimating the effort required to solve problems and compares the effectiveness of PCN against traditional AlphaZero networks in the contexts of 15x15 Gomoku and 9x9 Killall-Go. The results indicate that PCN can solve more problems effectively.,"['Can the authors clarify how PCN fundamentally differs from existing methods like PNS or standard AlphaZero, beyond the training targets?', 'What implications does using PCN have for other game-solving contexts beyond those explored in this paper?']","['The clarity regarding the implementation and advantages of the proposed methods needs improvement.', 'Consideration of additional game types or scenarios would strengthen the validation of findings.']",False,2,2,2,3,4,"['Addresses a significant challenge in game solving by distinguishing between playing and solving.', 'Introduces a novel heuristic, proof cost, which offers a fresh perspective on optimizing game-solving strategies.', 'Experimental results demonstrate that PCN can outperform AlphaZero heuristics in specific contexts, suggesting practical applications.']","['The methods and their improvements over existing frameworks are not clearly explained, making it difficult for readers to fully grasp the contributions.', 'Experimental validation is limited to two game types, raising questions about the generalizability of the findings.', 'More detailed comparisons with existing state-of-the-art techniques are needed to highlight the advantages of PCN.']",3,2,2,3,Reject
H4EXaI6HR2,"The paper presents a novel architecture for modeling cost-to-go functions in dynamic programming for electrical power systems, specifically focusing on optimizing energy dispatch. It introduces a series of neural networks with parameters as functions of time to capture seasonal patterns, claiming improved performance over traditional methods in terms of operational cost and computational efficiency.","['Can the authors provide more detailed descriptions of the implementation of the parametric network series?', 'What specific benchmarks were used for comparison aside from the classic Bellman method?', 'Could the authors clarify the implications of using a sliding window strategy in terms of computational efficiency?']","[""The method's performance may vary under different operational scenarios which are not extensively tested in the current paper."", 'Lack of clarity regarding the methodology makes it difficult to assess the validity of the proposed approach.']",False,3,3,3,5,4,"['Addresses a significant issue in energy systems optimization, particularly relevant with increasing renewable energy sources.', 'The proposed architecture of using parametric network series is innovative and well-suited for capturing seasonal patterns.', 'Demonstrates improvements in both operational cost and computational efficiency compared to existing methods.']","['Lacks comprehensive experimental validation against a wider array of baseline methods.', 'The clarity of the proposed method could be improved, especially in explaining the parameterization and the impact of the sliding window strategy.', 'Insufficient justification for architectural choices and limited discussion on the limitations of the proposed method.']",3,3,3,4,Reject
WQVouCWioh,"The paper presents DARK, a deep generative model for de novo protein design that generates novel protein sequences with predicted ordered structures. The authors claim their approach improves the efficiency and diversity of generated sequences compared to existing methods reliant on natural sequences.","['Could the authors elaborate on how DARK improves upon existing generative models beyond sampling speed?', 'Can the authors provide additional comparative studies against a wider array of contemporary protein design methods?', 'What metrics were used to evaluate the quality of generated sequences, and how do these compare to those from traditional design methods?']","['The paper does not adequately address the limitations of the proposed method or potential negative implications in a broader context.', 'The generalizability of the results is uncertain due to a lack of diverse experimental validation.']",False,3,2,3,5,4,"['The paper tackles a significant challenge in protein design, specifically the generation of sequences that do not exist in nature.', 'DARK demonstrates the ability to produce diverse and structurally ordered protein sequences, utilizing AlphaFold for structural predictions.', 'The results indicate substantial improvements in sampling speed and efficiency over traditional methods.']","['While the approach is innovative, it builds on existing generative techniques and lacks substantial novel theoretical contributions.', 'Comparative analyses with a broader range of state-of-the-art protein design methods are limited, which may affect the significance of the findings.', 'Some sections of the paper are dense and could benefit from clearer explanations and more straightforward language.']",3,3,2,4,Reject
SgEhFeRyzEZ,"The paper provides a theoretical analysis of the Feedback Alignment (FA) algorithm for training deep linear networks, presenting convergence guarantees and exploring phenomena related to implicit regularization. While the theoretical contributions are substantial, the paper lacks empirical validation and suffers from clarity issues.","['Can the authors clarify the contributions of their work compared to existing literature on Feedback Alignment?', 'What specific experiments could be conducted to validate the theoretical claims presented in the paper?']","[""The clarity of the paper significantly hinders the reader's ability to understand the theoretical contributions."", 'The lack of empirical evidence weakens the claims made about the effectiveness of FA.']",False,3,3,2,5,4,"['Addresses a relevant problem in the training of neural networks, specifically the weight transport problem.', 'Presents rigorous theoretical results, including convergence guarantees and insights into the dynamics of learning.', 'Introduces concepts like implicit regularization and anti-regularization, which could stimulate further research.']","['The presentation is unclear and overly technical, making it difficult for readers to grasp the main ideas.', 'The paper lacks sufficient empirical validation to support the theoretical claims made about the FA algorithm.', 'The originality of the results is questionable; many concepts discussed are extensions of previous work without substantial new insights.']",3,2,3,3,Reject
WcZUevpX3H3,"The paper proposes FEDPNAS, a personalized neural architecture search method for federated learning, which allows for structural personalization of models based on local tasks. It introduces a two-component architecture that separates task-agnostic and task-specific components and employs a context-aware sampling method. The authors claim significant performance improvements over existing NAS and FL benchmarks on several datasets.","['Can the authors provide more details on the context-aware sampling method and how it improves upon traditional methods?', 'What additional experiments could strengthen the evaluation of FEDPNAS compared to more baselines?', 'Could the authors clarify the primary contributions of this work in light of existing literature on NAS and FL?']","['The clarity of the algorithm and its components could be improved to enhance understanding.', 'The theoretical claims would benefit from more empirical support to verify their applicability in practice.']",False,3,3,4,5,4,"['Addresses a critical limitation in federated learning by allowing for personalized model architectures.', 'The proposed algorithm effectively combines insights from NAS and FL, offering a novel approach to model personalization.', 'Empirical results demonstrate significant performance gains across multiple datasets, validating the effectiveness of the proposed method.']","['The methodology lacks clarity, particularly in explaining the context-aware sampling distribution and its advantages over traditional methods.', 'The novelty of the contributions could be better articulated, especially in distinguishing them from existing approaches.', 'The experimental validation is somewhat limited, lacking a comprehensive comparison with a broader range of baselines.']",4,3,3,4,Reject
eSHBmLnD1s8,"The paper proposes a two-stage stochastic subsampling method (SSS) designed to efficiently select features and instances from high-dimensional data, aiming to minimize performance degradation in downstream tasks. It combines Bernoulli and Categorical distributions for candidate and subset selection, claiming to outperform existing methods across various tasks.","['Can the authors clarify how their approach compares to existing methods in terms of computational efficiency and performance under extreme conditions?', 'What specific limitations do the authors foresee in their proposed method, and how might these affect real-world applications?', 'Could the authors provide additional visualizations of results to support the claims made in the paper?']","['The paper does not sufficiently address potential biases introduced by the subsampling process and their impact on model performance.', 'There is little discussion about how the model performs under different input distributions or real-world datasets that may not conform to the assumptions made in the experiments.']",False,2,2,2,4,4,"['The method addresses a relevant issue in deep learning related to the efficiency of handling high-dimensional data.', 'The two-stage approach is innovative and allows for flexible operation on both features and instances.', 'Experimental results indicate that SSS outperforms several existing baselines in various tasks.']","['The originality of the work is questionable as it builds on existing techniques without sufficiently highlighting unique contributions.', 'Clarity is a significant issue; many sections are difficult to follow, particularly the descriptions of the methods and results.', 'The experimental validation is not comprehensive; the paper does not adequately compare the proposed method against a wide array of relevant baselines.', 'Insufficient discussion regarding the limitations of the proposed method and potential implications for practical applications.']",2,2,3,3,Reject
1JN7MepVDFv,"This paper investigates the relationship between disentangled representations and multi-task learning, focusing on hard parameter sharing. It presents an empirical study indicating that disentanglement emerges during multi-task training. However, the authors find inconclusive evidence regarding the positive impact of disentangled representations on model performance.","['Can the authors clarify the methodology used to generate the datasets and the tasks?', 'What specific evidence supports the claim that disentanglement improves performance in multi-task settings?', 'How do the authors plan to address the inconsistency in performance improvement for different datasets?']","['The inconclusive nature of the findings raises questions about the overall contribution of the paper.', 'The lack of clarity in the methods and results may mislead readers about the significance of the findings.', 'The paper does not sufficiently discuss the limitations of synthetic datasets in generalizing to real-world scenarios.']",False,3,3,3,5,4,"['The topic of disentangled representations and multi-task learning is timely and relevant.', 'The empirical analysis across multiple datasets provides a thorough examination of the proposed hypotheses.', 'The construction of synthetic datasets to facilitate the study is a notable approach.']","['The paper lacks clarity in its methodologies, making it difficult to follow the experimental setups and results.', 'The results presented are inconclusive, particularly regarding the benefits of disentangled representations for multi-task learning.', ""The writing style is sometimes convoluted, which may hinder the reader's understanding of the core contributions and findings.""]",3,3,3,4,Reject
8rR8bIZnzMA,"The paper proposes a Transformer-based method for dynamic graph representation learning called Dynamic Graph Transformer (DGT), which aims to address the challenges posed by noisy graph information by leveraging spatial-temporal encoding and self-supervised pre-training. The authors claim improvements over state-of-the-art methods through extensive experiments on real-world datasets.","['Can the authors clarify the rationale behind the specific choices of hyperparameters in the experiments?', 'How does DGT perform on other dynamic graph tasks beyond link prediction, and can the authors provide results on those tasks?', 'Can the authors provide more detailed explanations of the ablation studies and their implications?']","['The complexity of the model and the explanations may hinder the reproducibility of the results.', 'There should be a clearer distinction from existing methods to better highlight the novel contributions of DGT.', 'The paper does not adequately address limitations or potential biases in the experimental setup which could affect the results.']",False,3,4,3,6,4,"[""The integration of self-supervised pre-training tasks is a pertinent approach to enhance the model's generalization capabilities."", 'The proposed temporal-union graph and target-context node sampling strategy present interesting methods for efficient training on dynamic graphs.', 'The experimental results show competitive performance against various baselines across multiple datasets, indicating the potential of the proposed method.']","[""The paper's clarity suffers from the complex explanations of the model architecture and the encoding mechanisms, making it challenging to understand the overall workflow."", 'The originality of the contributions is somewhat diluted as the foundational concepts are not thoroughly differentiated from existing literature.', 'The experiments, while promising, lack a comprehensive analysis of various hyperparameters and alternative configurations that could further validate the robustness of the proposed method.']",3,3,4,4,Reject
sOK-zS6WHB,"The paper proposes a fingerprinting mechanism for generative models that enables responsible disclosure and attribution of generated samples, particularly in the context of deepfakes. The authors claim their method achieves efficient fingerprinting, allowing for the generation of numerous unique models without significant performance loss. Extensive experiments validate its effectiveness and scalability.","['Can the authors clarify how their fingerprinting method differs fundamentally from traditional watermarking techniques?', 'What specific challenges do they foresee in the deployment of this mechanism in practice, particularly regarding scalability and user compliance?', 'Could you provide more detailed explanations of the fingerprinting mechanism and its integration into the GAN framework?']","['The paper does not sufficiently address the potential for adversarial attacks against the fingerprinting mechanism.', 'There is a lack of discussion regarding the robustness of the method against various adversarial conditions.']",True,3,3,3,6,4,"['Addresses a critical issue in the responsible use of generative models, particularly in the context of deepfakes.', 'The fingerprinting mechanism is innovative and scalable, allowing for the generation of numerous unique models.', 'Experimental results demonstrate high accuracy in fingerprint detection and preservation of generation quality.']","['The methodology lacks clarity in detailing how the fingerprinting mechanism is integrated into the GAN framework, which may hinder reproducibility.', 'The originality of the approach is questionable as it parallels existing watermarking techniques without a clear distinction on improvements.', 'The paper does not adequately address potential adversarial attacks against the fingerprinting mechanism or the ethical implications of its use.']",3,3,3,4,Reject
7YDLgf9_zgm,"The paper presents a novel approach for continual learning called Recursive Gradient Optimization (RGO), which aims to mitigate forgetting in neural networks without relying on data replay or increasing model capacity. It incorporates a virtual Feature Encoding Layer to represent task variations while maintaining fixed network parameters. RGO demonstrates improved performance on continual learning benchmarks, achieving state-of-the-art results on specific datasets.","['Can the authors clarify the theoretical assumptions made regarding the neighborhood assumption in the optimization process?', 'What specific ablation studies can be conducted to further validate the effectiveness of the proposed virtual Feature Encoding Layer?', 'Why does the paper not provide a more extensive comparison with a wider range of continual learning methods?']","['The paper does not clearly define the limitations of the proposed method, particularly regarding its dependency on certain theoretical assumptions.']",False,2,2,2,4,4,"['The method introduces a unique approach to continual learning by focusing on gradient optimization without data replay.', ""The virtual Feature Encoding Layer allows for flexible representations of different tasks, enhancing the model's adaptability."", 'Empirical results indicate that RGO achieves strong performance on several benchmarks, setting new records and demonstrating its effectiveness.']","['The originality of the method is somewhat limited, as it builds on existing regularization techniques without significantly advancing the state of the art.', 'The paper lacks clarity in its presentation, making it challenging to follow the proposed method and its theoretical foundations.', 'The experimental evaluation is insufficient; while claiming state-of-the-art performance, it does not provide a comprehensive comparison with a wider range of methods or thorough ablation studies to support the results.', 'The paper does not adequately address potential limitations or concerns regarding the assumptions made in the theoretical framework.']",3,2,2,3,Reject
WqoBaaPHS-,"The paper proposes a new notion of multiclass calibration called top-label calibration, focusing on conditioning probabilities based on the predicted top label. It introduces a multiclass-to-binary (M2B) reduction framework that unifies various calibration methods. The authors provide theoretical guarantees for their framework and demonstrate empirical results on CIFAR-10 and CIFAR-100, showing that their methods outperform existing calibration techniques.","['Could the authors clarify the implementation details of the algorithms, particularly in terms of their practical application?', 'What are the implications if the calibration data distribution shifts significantly, and how might the proposed methods adapt to such scenarios?', 'Can the authors provide more clarity on the implementation details of the proposed algorithms?', 'What are the potential limitations of top-label calibration, and how do they compare with confidence calibration in practical applications?', 'Are there any additional datasets or scenarios where the M2B framework has been tested?']","['The paper does not sufficiently address potential limitations related to the applicability of the proposed methods across different types of datasets or applications.', 'The lack of extensive empirical validation raises concerns about the robustness of the proposed techniques.']",False,3,3,3,6,4,"['Introduces the novel concept of top-label calibration, which is practically relevant and addresses a real issue in classification tasks.', 'The M2B reduction framework provides a unified approach to various calibration methods, simplifying the calibration process.', 'Empirical results on benchmark datasets support the theoretical claims and show the effectiveness of the proposed methods.']","['The overall clarity of the presentation could be improved; some sections are difficult to follow and may confuse readers.', 'While theoretical claims are robust, the experimental validation is limited; further testing on diverse datasets could strengthen the findings.', 'The algorithms and their implementations could be explained more clearly, as some details are currently vague.']",3,3,3,4,Reject
v-v1cpNNK_v,"The paper presents NASI, a novel neural architecture search algorithm that leverages the Neural Tangent Kernel (NTK) to estimate architecture performance at initialization, avoiding the need for model training during the search process. This approach aims to enhance both the efficiency and effectiveness of NAS across various datasets, demonstrating label and data agnosticism.","['Can the authors clarify the reasoning behind their approximations and provide more intuitive explanations?', 'What specific comparisons were made against existing NAS methods, and how do these compare in terms of performance metrics?', 'Can the authors provide additional visualizations or examples to support their empirical claims?']","['The theoretical foundations and assumptions regarding NTK and its implications for NAS need clearer articulation.', 'The paper could benefit from more rigorous evaluation against a wider range of state-of-the-art NAS algorithms.']",False,3,3,3,6,4,"['The proposed method significantly improves search efficiency by eliminating the need for model training, which is a notable advancement in the NAS field.', 'The use of NTK for performance estimation at initialization is both innovative and theoretically grounded.', 'Empirical results show that NASI achieves competitive performance while being significantly more efficient than traditional NAS methods.']","['The clarity of the paper could be improved, as some explanations of methods and theoretical justifications may be challenging for readers to follow.', 'There is a lack of comprehensive comparisons with existing NAS methods, which would help contextualize the contributions of NASI.', 'Some experimental results could benefit from more detailed explanations or visualizations to better assess their validity and implications.']",3,3,3,4,Reject
rq1-7_lwisw,"The paper introduces Object Concept Learning (OCL), a task aimed at enhancing machine understanding of objects by inferring their attributes and affordances through a causal reasoning framework. It presents a new annotated dataset and a baseline model, the Object Concept Reasoning Network (OCRN), to support this task.","['Can the authors clarify how the OCRN model was validated against existing methods and what specific experiments were conducted?', 'How do the authors ensure that the dataset annotations are free from bias, especially given the subjective nature of attributes and affordances?', 'Could the authors provide additional details on how the causal annotations were validated and the metrics used for evaluation?']","['The paper does not adequately address the limitations of the OCL dataset and the OCRN model regarding generalization to unseen categories or affordances.', 'The reliance on existing datasets raises concerns about the novelty and independence of the work.']",False,2,2,3,5,4,"['The introduction of the OCL task addresses a significant gap in AI by pushing beyond simple object recognition to a deeper understanding of attributes and affordances.', 'The dataset constructed for OCL is extensive and provides a valuable resource for future research.', 'The incorporation of causal reasoning into the framework is an innovative aspect that could lead to advancements in reasoning within AI systems.']","['The methodology is overly complex and lacks clarity, particularly in explaining how the OCRN operates and how causal relationships are implemented.', 'The experimental evaluation is insufficient, lacking thorough comparisons with existing state-of-the-art methods and detailed metrics.', 'There is inadequate discussion of the limitations and potential biases in the dataset and the implications of using causal reasoning.']",3,2,2,3,Reject
HMJdXzbWKH,"The paper proposes two novel algorithms, Q-Rex and Q-RexDaRe, that enhance Q-learning for linear MDPs by incorporating online target learning (OTL) and reverse experience replay (RER). It aims to bridge the gap between practical success and theoretical limitations of Q-learning, providing non-asymptotic bounds on sample complexity.","['Can the authors clarify the specific advantages of Q-Rex and Q-RexDaRe over existing Q-learning methods in terms of practical applications?', 'Could additional experiments be provided to demonstrate the robustness of the proposed algorithms across different types of MDPs?']","['The paper does not adequately address potential limitations in the theoretical assumptions made, which could affect the practical applicability of the methods.', 'The clarity of the theoretical explanations and experimental results needs improvement to better communicate the findings.']",False,3,2,3,5,4,"['Addresses a significant gap in the theoretical understanding of popular Q-learning methods.', 'Provides non-asymptotic bounds on sample complexity, which is a valuable contribution to the field.', 'Experiments demonstrate improvements over traditional Q-learning methods, indicating practical relevance.']","['The paper lacks clarity in presenting the theoretical results and their implications, making it difficult for readers to fully grasp the contributions.', 'Experimental results are somewhat limited in scope and could be more comprehensive, particularly in comparison to a wider range of existing approaches.', 'The presentation of results could be improved; the figures and tables should be clearer and better explained.']",3,3,2,4,Reject
aPOpXlnV1T,"The paper critiques the use of negative log-likelihood (NLL) for estimating uncertainty in neural networks, identifying its limitations and proposing a new loss function, β-NLL, which weights contributions based on predicted variance. The authors validate their approach through experiments across various datasets, showing improvements in predictive performance.","['Can the authors clarify the theoretical motivations for the choice of β and its impact on the loss function?', 'What specific related works do the authors plan to compare with in future iterations?']","['The paper could benefit from clearer explanations of the proposed methods and their implications for practitioners.', 'A more comprehensive discussion on potential limitations or failure cases of the β-NLL loss function is needed.']",False,3,3,3,6,4,"['Addresses a significant issue in uncertainty estimation relevant to practitioners.', 'The proposed β-NLL loss function offers a practical solution to improve mean predictions while maintaining uncertainty calibration.', 'Empirical results demonstrate improvements in predictive accuracy and robustness across multiple datasets.']","['The novelty of the contribution is somewhat limited, as it builds on existing loss functions rather than introducing a fundamentally new approach.', 'Some sections of the paper lack clarity and could be more straightforward.', 'The paper could benefit from more detailed comparisons with state-of-the-art methods to better highlight its contributions.']",3,3,3,4,Reject
9Hrka5PA7LW,"The paper proposes a framework for unsupervised continual learning (UCL) and introduces Lifelong Unsupervised Mixup (LUMP) to address catastrophic forgetting. The authors demonstrate that UCL representations are more robust and generalize better compared to supervised continual learning (SCL) methods. A thorough experimental evaluation is provided across several datasets, showing improved performance and reduced forgetting.","['Can the authors provide more details on the implementation and effectiveness of LUMP compared to other unsupervised methods?', 'Could additional examples be provided in the qualitative analysis to support the findings?', 'How does the proposed method fundamentally differ from existing UCL methods?']","['Implementation details of LUMP need to be clearer and more comprehensive.', 'The paper could benefit from a broader comparison with existing unsupervised continual learning methods.', 'Clarity regarding experimental design and hyperparameter settings needs improvement to ensure reproducibility.']",False,3,3,3,6,4,"['Addresses a critical issue in continual learning by focusing on unsupervised scenarios.', 'Extensive experimental validation shows UCL outperforms SCL across multiple tasks.', 'Introduces a novel method (LUMP) that is easy to implement and effectively mitigates forgetting.']","[""Certain sections, particularly regarding LUMP's implementation, lack clarity and detail."", 'While experiments are extensive, comparisons with a broader range of unsupervised methods could strengthen results.', 'The qualitative analysis would benefit from additional examples to illustrate the effectiveness of learned representations.', 'The novelty of the proposed UCL method is questionable, as similar approaches exist in the literature.']",3,3,3,4,Reject
b30Yre8MzuN,"The paper introduces NEUROSED, a siamese graph neural network model designed to learn subgraph edit distance (SED) and graph edit distance (GED). The authors propose a novel embedding space that captures the structure of SED while ensuring that predicted distances satisfy theoretical properties such as the triangle inequality. NEUROSED demonstrates significant improvements in both accuracy and computational efficiency compared to existing methods, achieving approximately 2 times lower RMSE and up to 3 orders of magnitude faster retrieval times.","['Could the authors clarify the theoretical guarantees provided by their approach in simpler terms?', ""What specific steps could be taken in future work to improve the model's performance on larger query sizes?"", 'Can the authors provide more details on the assumptions made regarding the embeddings and their implications?']","['The paper could benefit from a more detailed discussion of the limitations of NEUROSED, particularly in terms of scalability and generalization to unseen query sizes.', ""The reliance on specific distance functions, while justified, may limit the model's applicability in more diverse settings.""]",False,3,3,3,6,4,"['Addresses a significant problem in graph analysis, specifically the challenge of efficiently computing subgraph edit distances.', ""NEUROSED's architecture appropriately leverages a siamese structure, enhancing generalization capabilities from low-volume training data."", 'Experimental results are robust, demonstrating clear improvements over existing state-of-the-art methods in both SED and GED tasks.', 'The authors provide a thorough theoretical foundation for their method, ensuring that key properties of SED and GED are preserved.']","['The paper lacks clarity in certain sections, particularly in the exposition of the underlying theory and the detailed workings of the model.', 'Some experimental comparisons could be more exhaustive, particularly in terms of baseline methods and the variety of datasets used.', 'The ablation studies, while present, could be expanded to provide a clearer understanding of the impact of different architectural choices on performance.', 'The presentation is dense and may be difficult for some readers to grasp fully, especially those less familiar with graph theory.']",3,3,3,4,Reject
NH29920YEmj,"The paper proposes a novel Positive and Unlabeled (PU) learning method called P[3]Mix, which utilizes a heuristic mixup technique to improve classification performance by addressing decision boundary deviations. The method aims to augment unlabeled instances with partially positive instances to refine the decision boundary. Experimental results indicate that P[3]Mix outperforms existing PU learning methods across several benchmark datasets.","['Can the authors clarify the differences between their method and existing mixup techniques?', 'What specific mechanisms are in place to ensure that the use of heuristic mixup does not introduce additional noise or bias?', 'Could the authors provide more detailed explanations for the experimental setup and parameter choices?', 'What measures were taken to ensure the robustness of the proposed method across different datasets and conditions?']","['The paper does not sufficiently characterize the limitations of the proposed method or discuss potential biases in the results.', 'A clearer discussion on the implications of the decision boundary deviation phenomenon is needed.']",False,2,2,2,4,4,"['Addresses a significant problem in PU learning by focusing on decision boundary deviation.', 'Introduces a heuristic mixup technique that combines data augmentation with supervision correction.', 'Experimental results demonstrate that the proposed method generally outperforms existing PU learning methods.']","['The originality of the work is questionable as it builds heavily on existing methods without a clear novel contribution.', 'The clarity of the presentation is poor; several technical details are vague or insufficiently explained, making it difficult to follow the methodology.', 'The experimental setup lacks rigor, with limited comparisons to a broader range of baselines and insufficient ablation studies.', 'The rationale behind some design choices, particularly the mixup partner selection, lacks sufficient theoretical backing.']",2,3,2,3,Reject
MqEcDNQwOSA,"The paper introduces a novel k-sub-embedding structure for language models that aims to significantly reduce the number of parameters in embeddings while preserving performance. By leveraging Cartesian products of sub-embeddings and contextual information from pretrained models, the approach effectively addresses the out-of-vocabulary (OOV) problem. Initial experimental results suggest that this method performs comparably to traditional embeddings, although the clarity of the methodology and presentation raises concerns.","['Can the authors clarify the experimental setup and provide more details about how the k-sub-embedding is integrated into existing models?', 'What specific metrics were used for evaluation, and how do they compare to standard benchmarks?', 'Could the authors provide a more in-depth analysis of the results and discuss potential weaknesses of their approach?']","['The paper does not adequately address its limitations or potential negative impacts of the new embeddings on downstream tasks.', 'The evaluation of the proposed method lacks depth, with insufficient ablation studies and comparisons to existing methods.']",False,2,2,3,4,4,"['Addresses the critical issue of parameter size in modern language models, which is highly relevant in the field.', 'The k-sub-embedding concept presents an innovative approach to mitigate the OOV problem, potentially enhancing model efficiency.', 'Experimental results demonstrate that the proposed method can achieve over 99% compression in embedding size while maintaining competitive performance on benchmarks.']","['The paper lacks clarity in explaining the methodology and mathematical formulations, making it difficult for readers to follow.', 'Experiments should include more robust baselines for a comprehensive comparison to validate the effectiveness of the proposed approach.', 'Insufficient details on the implementation and training process hinder reproducibility of the results.', 'The originality of the work is somewhat diminished as it appears to combine existing techniques without introducing sufficiently novel insights.']",3,2,2,3,Reject
A05I5IvrdL-,"The paper investigates memoryless stochastic policy optimization in infinite-horizon POMDPs, presenting a polynomial programming framework and a geometric perspective on the optimization landscape. It establishes that state-action frequencies and expected cumulative rewards can be expressed as rational functions, but lacks clarity and empirical validation.","['Can the authors provide more intuitive explanations or visual aids to clarify complex concepts?', 'What practical applications have the authors considered to validate their theoretical results?', 'Could the authors discuss the limitations of their approach and potential areas for future work?']","['The theoretical nature of the study may limit its applicability to real-world problems without further empirical validation.', 'The complexity of the paper may alienate readers unfamiliar with advanced mathematical concepts.']",False,3,2,3,4,4,"['Theoretical contributions to understanding memoryless policies in POMDPs.', 'Introduction of polynomial programming as a novel optimization approach.', 'Establishes a mathematical framework linking observability to optimization complexity.']","['Dense mathematical notation may hinder understanding for a broader audience.', 'Lack of empirical validation or practical examples to support theoretical claims.', 'Insufficient clarity in explaining the implications of findings.']",3,2,2,3,Reject
h-z_zqT2yJU,"The paper proposes Adaptive Temperature Knowledge Distillation (ATKD) to address performance degradation in knowledge distillation caused by sharpness gaps between teacher and student models. The authors introduce a metric to quantify sharpness and adaptively adjust temperatures during training to mitigate these gaps, supported by extensive experiments on CIFAR-100 and ImageNet.","['Can the authors clarify the theoretical foundation behind the sharpness metric and its implications for knowledge distillation?', 'What specific hyperparameter values were chosen for the experiments, and how do they influence the results?', 'Could more ablation studies be included to assess the robustness of ATKD?']","['The clarity of the theoretical analysis and the presentation of the sharpness metric needs improvement.', 'Insufficient experimental validation and analysis could lead to misleading conclusions about the effectiveness of ATKD.']",False,2,3,3,5,4,"['Addresses a significant problem in knowledge distillation related to performance degradation when using larger teacher models.', 'Introduces a novel sharpness metric that provides a fresh perspective on the issue.', 'Empirical results demonstrate the effectiveness of ATKD across multiple datasets.']","['The theoretical foundation of the sharpness metric is not clearly defined or rigorously justified, raising questions about its validity and applicability in various contexts.', 'The paper lacks comprehensive experimental validation against a wider range of state-of-the-art methods, which limits the generalizability of the findings and their practical implications.', 'Clarity in the presentation of the methodology and results is insufficient, making it challenging for readers to fully grasp the contributions and implications of the work.']",3,2,2,3,Reject
Ctjb37IOldV,"The paper proposes that dropout enables neural networks to find flatter minima, thereby improving generalization. It introduces a 'Variance Principle' that suggests noise variance is larger in sharper directions of the loss landscape, explaining why dropout leads to flatter minima. Empirical studies across various datasets are conducted to support this claim.","['Could the authors clarify the methodology used in the experiments to ensure the robustness of their results?', 'Can the authors provide additional data or comparisons with existing noise structures to better support their claims?']","['Insufficient experimental details and a lack of rigorous comparison with existing literature make the results less convincing.', 'The theoretical contributions are not adequately substantiated by the empirical findings.']",False,2,2,2,3,4,"['Addresses an important question in machine learning regarding dropout and its effects on generalization.', 'Introduces a novel theoretical perspective (Variance Principle) to explain the role of dropout, which could have significant implications for future research.', 'Includes experiments across different datasets and network architectures, demonstrating the general applicability of the findings.']","['The experimental validation lacks depth and detail, particularly in the methodology and results interpretation, making it hard to assess the reliability of the claims.', 'The connection between the proposed theory and the experimental results is not clearly established, leading to potential gaps in understanding.', 'More thorough comparisons with existing methods or noise structures are needed to contextualize the findings and strengthen the argument.', 'Some parts of the paper are poorly organized, leading to confusion about the methodology and implications.']",3,2,2,3,Reject
dEwfxt14bca,"The paper investigates mode-switching exploration strategies in reinforcement learning (RL), proposing a flexible approach to balance exploration and exploitation over varying time scales. The authors conduct experiments on Atari games to evaluate the effectiveness of their proposed strategies.","['How do the proposed switching mechanisms compare to existing exploration strategies in terms of performance?', 'Could the authors clarify the rationale behind their choice of parameters and their impact on learning?']","['The clarity of presentation needs improvement to facilitate understanding of the proposed methods.', 'The evaluation is not comprehensive, limiting the generalizability of the findings.']",False,2,2,2,5,4,"['Addresses a key challenge in RL - the exploration-exploitation trade-off.', 'Explores diverse strategies for switching between exploration and exploitation modes.', 'Presents experimental results on Atari games, demonstrating potential improvements over traditional methods.']","['Originality is moderate; while the approach is interesting, it does not significantly diverge from existing exploration strategies.', 'Clarity could be improved; the presentation of methods and results lacks sufficient structure.', 'Experimental evaluation is somewhat limited and could benefit from a broader range of tests and comparisons.']",3,2,2,4,Reject
XHUxf5aRB3s,This paper addresses the non-stationarity problem in cooperative multi-agent reinforcement learning (MARL) by introducing a new measurement called δ-stationarity and proposing the MAMT algorithm that applies trust-region constraints to local policies. The authors argue that this approach can effectively mitigate non-stationarity and improve agent collaboration in various tasks.,"['Can the authors clarify the computational overhead associated with their proposed method compared to existing approaches?', 'What specific metrics were used to evaluate the performance of MAMT, and how do they compare with established benchmarks?']","['The paper does not adequately discuss the limitations and potential negative consequences of the proposed approach, particularly in terms of computational complexity and applicability in real-world scenarios.']",False,3,2,3,5,4,"['The introduction of δ-stationarity as a measurement for non-stationarity is a novel contribution that may help in understanding policy dynamics in MARL.', 'The proposed MAMT algorithm shows potential for improving performance in cooperative tasks, particularly in environments with complex interactions.', 'The paper provides a theoretical framework and justifications for its claims, which is beneficial for understanding the underlying mechanisms.']","[""The algorithm's complexity may hinder its applicability, and the benefits of δ-stationarity are not convincingly demonstrated compared to simpler existing methods."", 'The experimental validation lacks depth; more comparisons with state-of-the-art methods are needed to substantiate the claims of superior performance.', 'Some sections of the paper are difficult to follow, especially the mathematical formulations and their implications for the proposed algorithm.']",3,3,2,3,Reject
pgkwZxLW8b,"The paper introduces a method called Federated Sampled Softmax (FedSS) for efficient learning of image representations in a federated learning setting. The method aims to reduce computational and communication costs associated with using a large number of classes in softmax cross-entropy loss by sampling classes on client devices, while maintaining comparable performance to full softmax methods.","['Can the authors clarify the sampling mechanism and its impact on the learning process?', 'What specific hyperparameter choices were made, and how do they affect the performance of FedSS?', 'Could the authors provide more details on the experimental setup, including hyperparameter choices and how they impact performance?']","['The clarity of the paper could be significantly improved to facilitate understanding of the proposed method and its implications.', 'More comprehensive experimental validation is needed to convincingly demonstrate the effectiveness of the method compared to other state-of-the-art techniques.']",False,3,2,3,5,4,"['Addresses a significant problem in federated learning regarding computational and communication efficiency.', 'The proposed FedSS method offers a novel approach to sampled softmax for large-scale classification in a federated setting.', 'Empirical results indicate that FedSS performs comparably to full softmax while requiring fewer resources.']","['Lack of clarity in the presentation; complex concepts could be articulated more clearly.', 'The methodology section lacks sufficient detail, particularly regarding the sampling mechanism and its integration with local optimization.', 'The experimental setup is not sufficiently robust; there is limited discussion on hyperparameter choices and their impacts, and the paper does not provide enough comparative analysis against existing methods.']",3,3,2,3,Reject
s51gCxF70pq,"The paper introduces k-Step Latent (KSL), a representation learning method for reinforcement learning that enhances sample efficiency by enforcing temporal consistency in the learned representations. By utilizing a self-supervised auxiliary task, KSL allows agents to predict action-conditioned representations of the state space over multiple future steps. The results show that KSL achieves state-of-the-art performance on the PlaNet benchmark suite and demonstrates improved generalization and robustness in learned representations.","['Could the authors clarify the implications of the increased computational cost associated with KSL, particularly in practical deployments?', 'What are the main reasons for the observed limitations in the KSL performance when compared to non-augmented image methods, especially in terms of exploration strategies?']","['The increased wall clock time for KSL compared to previous methods raises concerns about its practicality in real-world scenarios.', 'The focus on specific benchmark tasks may not fully capture the potential weaknesses of KSL when applied to more diverse or unstructured environments.']",False,3,2,3,5,4,"['KSL effectively addresses the representation learning bottleneck in deep RL, which is a significant challenge in the field.', ""The paper provides extensive experimental results, showing KSL's superiority over various baseline methods in both data efficiency and overall performance."", 'Clear improvements in generalization to unseen tasks and robustness against state perturbations are reported, which are vital for real-world applications of RL.']","['The clarity of the presentation could be greatly improved; some sections are dense and could benefit from clearer explanations of the methodology and results.', 'The paper lacks sufficient discussion on the potential limitations and negative societal impacts of utilizing advanced RL techniques, especially in safety-critical applications.', 'While the experiments are comprehensive, it could be valuable to see a broader range of environments and tasks to fully assess the generalizability of KSL.']",3,3,2,4,Reject
Rx9luEzcSoy,"The paper introduces the concept of 'lottery image prior' (LIP), proposing that sparse subnetworks within deep neural networks can achieve performance comparable to full models in various image inverse problems. It validates this through experiments with untrained DNNs and pre-trained GANs, highlighting the potential for computational efficiency in image restoration tasks.","['Can the authors clarify how LIP subnetworks maintain transferability across different tasks?', 'What steps are taken to ensure that results are not overly optimistic due to the specific datasets used?', 'Could the authors provide further details on the limitations of their findings and potential future work?']","[""The clarity of the writing could hinder the understanding of key concepts and findings, which may impact the paper's overall effectiveness."", 'The experiments could be strengthened by comparing LIP subnetworks with more existing state-of-the-art image priors to validate the results more robustly.']",False,3,3,4,5,4,"['The introduction of the lottery image prior (LIP) is a novel conceptual contribution to the field of image processing and deep learning.', 'Extensive experiments across various image inverse problems provide substantial support for the claims made regarding the effectiveness of LIP.', 'The findings on the high transferability of LIP subnetworks are interesting and could have practical implications for computational efficiency.']","['The clarity of the paper is suboptimal; the presentation is convoluted and may confuse readers, making it difficult to follow the central arguments.', 'The experimental section, while extensive, lacks deep analysis and comparison with existing methods. It could be improved by including more comprehensive evaluations against state-of-the-art techniques.', 'The justification for certain claims, particularly regarding transferability across tasks and domains, lacks sufficient detail and empirical backing.']",4,3,3,4,Reject
ab7lBP7Fb60,The paper proposes an algorithm (FPFL) to enforce group fairness in private federated learning (PFL) by extending the modified method of differential multipliers to account for fairness constraints. The algorithm is tested on federated versions of the Adult dataset and a modified FEMNIST dataset to demonstrate its effectiveness in mitigating unfairness while adhering to differential privacy.,"['Could you clarify how FPFL compares computationally to existing methods in practical applications?', 'Can you provide more details on the efficiency and scalability of your algorithm in real-world federated learning scenarios?']","[""The paper's clarity issues may prevent readers from fully understanding the proposed algorithm."", 'The empirical evaluations could be more comprehensive to cover various scenarios and datasets.']",False,3,3,3,5,4,"['Addresses an important issue of fairness in private federated learning, which is timely and relevant.', 'The proposed algorithm FPFL is a novel extension of existing methods, integrating fairness with privacy concerns.', 'Empirical results indicate that FPFL can effectively reduce unfairness across groups while maintaining reasonable model accuracy.']","['The writing is dense and lacks clarity, making it challenging for readers to grasp the core contributions.', 'Insufficient context on how FPFL compares to existing fairness techniques, particularly regarding computational efficiency.', 'The experimental section lacks diversity in datasets and could benefit from additional experiments.']",3,3,3,4,Reject
KeBPcg5E3X,"The paper proposes ContraLORD, a method that incorporates contrastive learning into latent optimization for learning disentangled representations in generative models. It claims to improve both linear classification performance and representation disentanglement across multiple benchmarks. The authors evaluate their approach on ten datasets, presenting promising results.","['Can the authors clarify the specific contributions of their method compared to existing approaches?', 'What are the hyperparameters used in the experiments, and how do they impact the results?', 'Could the authors provide more detail on the experimental setup to improve reproducibility?', 'Can the authors elaborate on how ContraLORD differs significantly from previous methods in more detail?', 'What limitations or potential biases might arise from the use of contrastive learning in this context?']","['The clarity and organization of the paper need improvement to effectively communicate the proposed methodology.', 'There is a lack of engagement with related work, which undermines the perceived novelty of the contributions.', 'The paper does not sufficiently address limitations related to the scalability of the proposed method or potential biases introduced in the learning process.']",False,2,2,3,4,4,"['The proposed approach addresses an important problem in representation learning, particularly in the context of disentanglement.', 'The integration of contrastive learning with latent optimization is a timely and relevant topic, showcasing innovation in the field.', 'The extensive experimental evaluations across multiple datasets and tasks demonstrate the potential effectiveness of the proposed method.']","['The originality of the contributions could be better articulated, as the methodology builds upon existing works without sufficiently highlighting its unique aspects.', 'The clarity of the paper could be improved; some sections lack detailed explanations, making it challenging for readers to follow the methodology.', 'The experimental evaluations are limited in scope and do not include comparisons with a broader set of state-of-the-art methods.', 'The paper lacks a clear delineation of how it differs from existing work, raising questions about the originality and contributions.']",3,2,2,4,Reject
neqU3HWDgE,"The paper proposes a novel method for unsupervised disentanglement using tensor product representations on a toroidal structure, arguing it leads to disentangled latent representations that capture generative factors effectively. It presents experiments demonstrating advantages in disentanglement, completeness, and informativeness over traditional methods.","['Can the authors clarify the rationale behind the choice of a toroidal structure for all datasets?', 'What are the specific limitations of the method when dealing with datasets that exhibit more complex generative relationships?', 'Can the authors provide more details on the construction of the tensor product representation and its integration into the VAE framework?']","['The clarity of the paper could hinder understanding and reproducibility.', 'The method may not scale well to datasets with many generative factors, which needs to be addressed.']",False,2,2,3,5,4,"['The innovative approach of using tensor product representations for disentanglement is compelling and offers a fresh perspective.', 'The paper introduces a new metric, DC-score, combining disentanglement and completeness, contributing to the evaluation of generative models.', ""The experiments are extensive, covering multiple datasets and demonstrating the proposed method's advantages.""]","['The paper suffers from clarity issues; the mathematical formulations are dense and not always well-explained, potentially hindering comprehension.', 'The significance of the results could be questioned due to a lack of comparative analysis with a broader range of existing methods.', 'The dependence on a specific toroidal structure may limit the applicability of the method to datasets with more complex generative factors.']",3,2,2,3,Reject
DYaFB19z1ig,"The paper introduces Self-Distribution Distillation (S2D), a novel method for uncertainty estimation in deep learning that integrates ensemble training and distribution distillation into a single framework. It demonstrates that S2D can achieve improved uncertainty estimates and performance compared to traditional methods like deep ensembles and Monte Carlo dropout.","['Could the authors clarify how S2D handles the trade-offs between computational efficiency and the accuracy of uncertainty estimates?', 'Can the authors provide more details on the experimental settings and any potential limitations of their approach?', 'What steps will the authors take to establish the originality of their contributions in the context of existing literature?']","['Clarity issues may hinder the ability of readers to fully grasp the proposed approach and its implications.', 'The paper does not thoroughly address potential limitations or drawbacks of the S2D approach, which could affect its adoption in practical applications.']",True,3,2,3,5,4,"['The proposed method addresses an important issue in deep learning related to uncertainty estimation in safety-critical applications.', ""S2D's integration of ensemble training with distribution distillation is a novel approach that could advance the field."", 'The experiments show promising results, indicating that S2D can outperform standard methods in various tasks and datasets.']","['The clarity of the paper is lacking; some concepts and methodologies are not sufficiently detailed, making it difficult to follow.', 'The paper could benefit from better organization and clearer definitions of key terms to aid understanding.', 'While the experimental results are generally positive, the significance of the improvements is not always well contextualized against existing methods.', 'The originality of the work is questionable as it builds upon existing concepts without providing sufficient novel insights.', 'The experimental validation is limited to specific datasets, raising concerns about generalizability.']",3,3,2,3,Reject
8in_5gN9I0,The paper proposes data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles in graphs using a heavy edge oracle. It presents theoretical improvements over previous algorithms and empirical results demonstrating the effectiveness of the approach with various datasets.,"['Can the authors clarify how the heavy edge oracle is trained and the impact of its inaccuracies on the overall algorithm performance?', 'Could more examples be provided to illustrate the practical applications and benefits of the proposed algorithms?', 'What additional baseline algorithms were considered in the experiments?']","['The clarity of the paper is a significant limitation; the algorithms and theoretical results could be better communicated.', ""Potential practical limitations of the oracle's accuracy in real-world applications have not been addressed sufficiently."", 'The experimental results do not convincingly demonstrate the claimed advantages of the proposed methods.']",False,3,2,3,5,4,"['The integration of machine learning into streaming algorithms is innovative and relevant.', 'The paper provides both theoretical and empirical results that support the effectiveness of the proposed methods.', 'The algorithms demonstrate improved space complexities in triangle and four-cycle counting tasks.']","['The presentation is dense and may be challenging for readers unfamiliar with the specific field of graph stream algorithms.', 'Some experimental details, such as the exact workings of the oracle and how it is trained, are lacking which could affect reproducibility.', 'The paper could benefit from clearer explanations of the methodology and more intuitive insights into the results.']",3,3,2,4,Reject
u6sUACr7feW,"The paper proposes DPP-TTS, a novel text-to-speech model that utilizes Determinantal Point Processes (DPPs) to diversify prosodic features in synthesized speech. The authors claim that their method increases expressiveness while maintaining naturalness, using a prosody diversifying module (PDM) and conditional maximum induced cardinality (MIC) objective to learn the kernel matrix of the DPPs.","['Can the authors clarify the specific changes made to the TTS framework to incorporate DPPs?', 'What metrics were used to evaluate naturalness and diversity, and how were they measured?', 'Could the authors provide more details on the experimental design and validation?']","['The methodology is not clearly explained, which may hinder reproducibility.', 'Results may not be generalizable due to limited evaluation compared to a broader set of models.']",False,2,2,3,5,4,"['Innovative application of DPPs to enhance prosodic diversity in TTS.', 'Allows controlled variation in prosody, which is beneficial for various applications.', 'Experiments indicate that DPP-TTS achieves better prosodic diversity compared to baseline models.']","['The methodology lacks clarity, particularly in how DPPs are integrated into the TTS framework.', 'Insufficient detail in the experimental setup and evaluation metrics makes it difficult to assess the robustness of the results.', 'Limited comparative analysis with a broader range of baseline models.', 'While some improvements are noted, they do not convincingly demonstrate significant advancements over existing methods.']",3,2,2,4,Reject
e8JI3SBZKa4,"The paper proposes a method for kernel similarity matching using Hebbian learning rules to directly optimize nonlinear features, contrasting with existing methods that rely on random Fourier features. The approach is based on correlation-based learning and aims to create biologically plausible learning mechanisms.","['Can the authors clarify how the proposed upper bound leads to effective learning rules?', 'What specific advantages does the proposed method offer over traditional approaches in terms of performance and interpretability?', 'Can the authors provide clearer justifications for the complexity of the methodology?', 'How does the proposed method specifically improve upon existing techniques, and can this be quantified?']","['The paper does not adequately address how the proposed method compares to established techniques in terms of performance and practical utility.', 'The practical applicability of the proposed method in real-world scenarios remains questionable.']",False,2,2,2,3,4,"['Innovative integration of biological principles with kernel-based learning.', 'Focus on Hebbian learning rules may inspire future research in biologically plausible neural networks.']","['The theoretical foundation lacks clarity, particularly in how the upper bound leads to effective learning rules.', 'Empirical results do not convincingly demonstrate significant advantages over existing methods, raising questions about effectiveness.', 'The presentation is unclear, making it difficult to follow the theoretical and experimental sections.', 'Originality is limited, as the work does not significantly advance beyond existing kernel similarity matching methods.', 'Writing is poorly organized, complicating the understanding of contributions and methodology.']",2,2,2,3,Reject
inSTvgLk2YP,"The paper introduces MeshInversion, a method for single-view 3D reconstruction that utilizes a pre-trained GAN to exploit generative priors for reconstructing textured meshes. The authors claim their approach provides robust and realistic 3D reconstructions, especially when viewed from novel perspectives and under occlusion. Experimental results suggest that their method outperforms existing techniques in certain metrics.","['Can the authors clarify the specific advantages of Chamfer Texture Loss over traditional losses in more detail?', 'How do the results of this method compare to existing state-of-the-art methods in varying conditions?', 'Could the authors clarify how their method significantly differs from existing GAN-based 3D reconstruction techniques?', 'What specific improvements do the proposed losses bring compared to traditional methods?']","['The clarity of the writing needs improvement to enhance understanding of the proposed methods.', 'The experimental evaluation could benefit from more robust comparisons with existing techniques.', ""The method's reliance on pre-trained GANs may limit its generalization to unseen categories."", 'The paper does not adequately discuss the implications of using silhouette masks for reconstruction.']",False,3,2,3,4,4,"['The approach of using GANs for 3D reconstruction is innovative and leverages the generative power of pre-trained models.', 'The paper presents methods to address common issues in 3D reconstruction, such as occlusion and unobserved regions, through Chamfer-based losses.', ""The empirical results appear promising, showcasing the method's ability to generalize to less common shapes.""]","['The paper is lacking in clarity, particularly in explaining the methodology and how the losses contribute to the learning process.', 'The evaluation metrics need to be more comprehensive, including a wider range of comparisons with baseline methods under various conditions.', 'There is insufficient discussion on the limitations of the proposed method and areas for improvement.', 'The originality of the proposed method is questionable as it relies heavily on existing GAN techniques and prior research.', 'The experimental validation lacks thoroughness, with insufficient comparison to state-of-the-art methods.']",3,3,2,3,Reject
0lSoIruExF,"The paper proposes methods to enhance hybrid neighborhood-based recommendation systems by integrating user-item similarities derived from user interactions and item content. It claims to improve accuracy while addressing user privacy concerns related to data sharing. However, the experimental validation is limited, and the novelty of the contributions is questionable.","['Can the authors elaborate on how their methods differ from existing techniques in greater detail?', 'What specific improvements in user engagement or satisfaction can be expected from these methods?', 'Could the authors clarify the calculations of user feature vectors and their impact on recommendations?']","['The clarity of the methodologies and their descriptions is lacking, which may confuse readers.', 'The improvements in accuracy presented in the results are modest and may not justify the complexity introduced.']",True,2,2,2,4,4,"['Addresses significant challenges in recommendation systems, particularly concerning user privacy and data sparsity.', 'Demonstrates measurable improvements in prediction accuracy through the integration of user-item similarity.', 'Utilizes well-known datasets like MovieLens, enhancing the credibility of the experimental setup.']","['The proposed methods lack significant novelty compared to existing techniques.', 'Clarity issues in the methodology descriptions hinder full comprehension of the proposed solutions.', 'Experimental results, while showing improvements, do not sufficiently establish practical implications or scalability in real-world scenarios.', 'The evaluation lacks a comprehensive comparison against a broader range of baseline models to better contextualize the results.']",2,2,2,3,Reject
4lLyoISm9M,"The paper presents Range-Net, a low-memory approach for computing rank-r Singular Value Decomposition (SVD) aimed at big data applications. It claims to provide a deterministic alternative to current randomized SVD methods, with theoretical guarantees based on established mathematical results. However, the originality is undermined by its reliance on existing frameworks, and the execution of experiments lacks rigor and clarity.","['Could you clarify how Range-Net compares to a wider range of SVD methods?', 'Can you provide more details on the implementation and training process?', 'What specific datasets were used for comparison, and how were they selected?']","['The paper does not adequately address the limitations of the proposed method.', 'The experimental setup does not convincingly demonstrate the advantages over existing techniques.']",False,2,2,2,4,4,"['Addresses a significant problem in big data applications regarding memory requirements for SVD.', 'Proposes a deterministic two-stage method for low-rank approximation.', 'Claims theoretical guarantees aligned with established mathematical results.']","['The originality is questionable as the method heavily relies on known theoretical results.', 'The experimental validation is inadequate; comparisons with a broader set of state-of-the-art methods are necessary.', 'The presentation lacks clarity, with dense technical jargon that may confuse readers.']",2,2,2,3,Reject
g4nVdxU9RK,"The paper presents Rewardless Open-Ended Learning (ROEL), an unsupervised reinforcement learning algorithm that integrates open-ended learning with the POET framework to generate diverse skills without predefined rewards. This approach aims to enable agents to learn complex skills across various environments.","['What specific innovations does ROEL introduce compared to previous works, particularly POET?', 'Can the authors provide more detailed experimental results comparing ROEL to other contemporary reinforcement learning methods?', 'How do the authors ensure the interpretability of the skills learned by ROEL?']","['The paper does not adequately address the limitations of using a co-evolutionary framework, particularly regarding scalability and convergence issues.', 'The lack of a clear experimental protocol makes it difficult to assess the validity of the claims made in the results.']",False,2,2,2,4,4,"['The integration of open-ended learning with unsupervised reinforcement learning is a novel approach that could lead to significant advancements in the field.', 'Empirical results indicate that ROEL effectively enables agents to generalize skills across different environments, showcasing its potential utility.', 'The paper addresses a critical challenge in reinforcement learning regarding the difficulties of designing effective reward functions.']","['The paper lacks clarity and organization, making it challenging to fully grasp the contributions and methodologies employed.', 'The novelty of the ROEL algorithm is somewhat diminished by its reliance on existing frameworks like POET, which may limit its perceived originality.', ""Comparative experiments are limited, and the analysis of ROEL's performance against other leading methods in the field is insufficient."", 'The writing contains grammatical and structural issues that detract from the overall quality and readability of the paper.']",3,2,2,3,Reject
6PlIkYUK9As,"The paper proposes a method for selecting informative and diverse subsets of data using balancing constraints on class labels and decision boundaries, leveraging matroids and a greedy algorithm with constant approximation guarantees. It aims to reduce data and annotation efforts while maintaining performance similar to models trained on full datasets.","['Can the authors clarify how the matroid constraints specifically enhance performance?', 'What specific experimental results substantiate the claims of improved performance over existing methods?', 'Could the authors provide more details on the choice of parameters and their influence on the results?']","[""The clarity issues significantly hinder the paper's accessibility, which could affect its impact."", 'The evaluation lacks depth; further analysis of the results is necessary to validate the claims.']",False,2,2,3,5,4,"['Addresses a significant problem in deep learning related to data efficiency and reducing resource consumption.', 'Introduces a novel approach using matroids for subset selection, enhancing the flexibility and effectiveness of the method.', 'Empirical results show competitive performance across standard and long-tailed datasets, indicating practical applicability.']","['The presentation lacks clarity, making it challenging to fully grasp the proposed methods and their implications.', 'The evaluation of competing methods is insufficient; a more thorough comparison would strengthen the claims made.', 'Some experimental results are not adequately supported, limiting the overall impact of the findings.']",3,2,2,4,Reject
EFSctTwY4xn,The paper proposes a framework called Adaptive Federated Meta-Learning (AFML) aimed at improving personalized federated learning (PFL) under non-IID data scenarios. The authors introduce an 'adaptive trade-off theorem' that balances information flows from the initial model and local datasets to enhance performance and adaptability.,"['Can the authors clarify the limitations of their proposed framework in varying degrees of non-IID data beyond what is presented?', 'What specific methods were used for hyperparameter tuning in the experiments, and how might they influence the reported results?', 'Could additional experiments be included to demonstrate the robustness of the AFML framework under more diverse non-IID scenarios?']","[""Lack of clarity in technical implementation details and overall writing style may hinder the reader's understanding and appreciation of the contributions."", 'Limited comparison against a broader set of recent benchmarks reduces the perceived significance of the findings.']",False,4,3,3,6,4,"['Addresses the important issue of generalization in personalized federated learning under varying non-IID data distributions.', 'Introduces a theoretical foundation with the adaptive trade-off theorem that provides insights into managing information flow during model training.', 'Experimental results show potential for AFML to outperform existing leading frameworks in terms of personalization accuracy and communication efficiency.']","['The paper lacks clarity in certain sections, making it difficult for readers to follow the theoretical development and application.', 'The technical details regarding the implementation of the AFML framework, particularly the algorithm and regularizers, could be explained more clearly.', 'The paper could benefit from a more comprehensive comparison against a wider range of recent benchmarks in personalized federated learning.']",3,4,3,4,Reject
5o7lEUYRvM,"The paper proposes a function-space variational inference (fVI) method for Bayesian deep learning classification, using Dirichlet predictive priors to enhance uncertainty quantification and model robustness. It claims improvements in adversarial settings and presents results on various datasets.","['Could the authors clarify certain sections of the methodology to improve understanding?', 'What steps can be taken to further validate the robustness of the results, especially regarding the impact of varying the Dirichlet prior parameters?', 'How does the proposed method compare in practicality to existing methods in real-world applications?']","['The authors need to address the clarity issues in the presentation and methodology to ensure the proposed approach is accessible to readers.', 'More comprehensive experiments and ablation studies could be conducted to better understand the effectiveness and limitations of the proposed method.']",False,3,3,3,6,4,"['The approach addresses significant issues in traditional Bayesian methods, specifically the challenges of weight-space priors.', 'The use of Dirichlet predictive priors in function space is a novel contribution that offers a potentially more interpretable method for uncertainty quantification.', ""Experiments demonstrate the method's scalability and effectiveness across different datasets and tasks.""]","['The clarity of the presentation is lacking in several sections, making it difficult to fully grasp the implications of the proposed method.', 'The experimental results, while promising, need more thorough analysis and comparison with state-of-the-art methods to validate the claims.', 'The paper does not adequately discuss potential limitations or the trade-offs involved with the proposed method.']",3,3,3,4,Reject
i2baoZMYZ3,"The paper introduces Action Quantization from Demonstrations (AQuaDem), a method for discretizing continuous action spaces in reinforcement learning by leveraging human demonstrations. This approach aims to simplify exploration and improve performance in continuous control tasks. The authors evaluate AQuaDem across three setups, reporting improvements in performance and sample efficiency compared to state-of-the-art methods.","['Could the authors clarify how AQuaDem compares to existing discretization techniques beyond what is presented?', 'What specific ablation studies were conducted to isolate the impact of the quantization process on performance?', 'What measures were taken to ensure the quality and representativeness of the human demonstrations used in the experiments?', 'Could the authors provide more clarity on the implementation details of the AQuaDem framework?', 'What specific limitations do the authors recognize in their proposed framework, especially concerning the quality of demonstration data?']","['The reliance on human demonstrations may limit the generalizability of the method to situations where such data is not available.', 'The complexity of the method and its implementation may pose challenges for practitioners looking to apply it in real-world scenarios.', 'The paper does not adequately address the limitations or potential drawbacks of using human demonstrations, especially regarding variability in actions across different demonstrators.']",False,3,2,3,5,4,"['Addresses a significant problem in reinforcement learning by proposing a method to discretize continuous action spaces effectively.', ""Demonstrates extensive experimental validation across multiple challenging tasks, showcasing the method's advantages in terms of performance and sample efficiency."", 'The concept of leveraging demonstrations to inform action discretization is a promising direction that could benefit various applications.']","['The novelty of the approach could be questioned, as discretization techniques have been explored in the past.', 'The presentation is somewhat dense and convoluted, which may hinder understanding for readers who are not deeply familiar with the topic.', 'The experimental comparisons are limited primarily to human demonstration data; a broader evaluation against additional baseline methods could strengthen the paper.', 'The methodology lacks clarity in describing how the action quantization is implemented and how it effectively captures multimodal behavior from demonstrations.', 'The evaluation metrics and experimental setups are not sufficiently detailed, making it difficult to assess the robustness of the findings.']",3,3,2,4,Reject
hjlXybdILM3,"The paper proposes SimpleBits, a method for simplifying input data to enhance neural network understanding by reducing information content while retaining task-relevant information. This is achieved by minimizing the encoding bit size of inputs using a pretrained generative model, and the effects of simplification are explored in various contexts, including training, dataset condensation, and post-hoc analysis.","['Can the authors clarify how the generative model is trained and its influence on the simplification process?', 'What are the criteria for determining whether the simplified input retains sufficient task-relevant information?']","['The paper does not adequately address the limitations of the simplification approach, particularly in terms of potential impacts on model performance or interpretability.', 'More discussion is needed regarding the implications of the findings for practical applications in real-world scenarios.']",False,3,2,3,5,4,"['The concept of simplifying inputs to aid in understanding neural network behavior is novel and relevant.', 'The approach utilizes a generative model to measure and minimize input complexity, providing a quantitative basis for simplification.', 'The experiments demonstrate that SimpleBits can effectively reduce input complexity without significantly degrading task performance.']","['The paper lacks clarity in the presentation, making it difficult to follow the methodology and results.', 'Some methodological details are not well explained, particularly regarding the training process and the role of the generative model.', 'The evaluation may not fully address potential biases or limitations in the simplification approach, affecting reproducibility and generalizability.']",3,2,2,4,Reject
pWBNOgdeURp,"The paper proposes a class of pruning algorithms for deep neural networks based on Koopman operator theory, aiming to unify magnitude and gradient pruning methods. It analyzes the dynamics of pruning during training and provides empirical evidence of the effectiveness of its methods, especially in the early training phase.","['Can the authors clarify the theoretical foundations behind their methods?', 'What specific advantages do the proposed methods have over traditional pruning techniques, and how do they perform in a wider range of tasks?', 'Could the authors provide more details on how the experimental results could be replicated or extended in future work?']","['The clarity and comprehensibility of the theoretical explanations could be improved.', 'More extensive experimental validation would strengthen the claims made in the paper.', 'The paper does not adequately address potential limitations or contexts where the proposed methods may not apply effectively.']",False,2,2,3,4,4,"['The integration of Koopman operator theory into the pruning of neural networks is a novel and interesting approach.', 'The paper provides empirical results that demonstrate the equivalence of Koopman-based pruning methods with traditional pruning techniques, which could lead to new insights in the field.', 'The work is theoretically motivated and attempts to unify disparate pruning methods, addressing an important challenge in the field.']","['The paper lacks clarity in certain sections, particularly in explaining the theoretical aspects of Koopman operator theory and its application to pruning.', 'The experimental results, while promising, could benefit from more extensive analysis and discussion to provide better context and rigor.', 'Some claims regarding the equivalence of pruning methods need more detailed justification and explanation of their implications.', 'The originality of the contribution is not sufficiently established; many ideas are rooted in existing literature without substantial novelty.', 'The presentation is often convoluted, making it difficult to grasp the key concepts and results.']",3,2,2,3,Reject
iLHOIDsPv1P,"The paper proposes a PAC-Bayes Information Bottleneck (PIB) framework aimed at understanding and measuring the generalization ability of neural networks through the information stored in weights (IIW). It introduces an algorithm for approximating IIW and demonstrates how PIB can empirically capture the fitting-compressing phase transition in neural network training. The authors argue that this new approach can better explain neural networks' behavior in various scenarios, including varying batch sizes and label noise.","['Could the authors clarify the assumptions made regarding the relationship between IIW and generalization?', 'What are the implications of the findings for existing deep learning practices, and how can PIB be integrated with current training methodologies?']","['The clarity of key concepts could be improved, as some readers may struggle to grasp the theoretical foundations and implications of the proposed PIB framework.', 'A lack of comprehensive testing across multiple datasets and scenarios raises concerns about the general applicability of the results.']",False,2,2,3,3,4,"['The paper addresses the critical issue of understanding neural network generalization, which is fundamental in machine learning.', 'It introduces a theoretically grounded approach to existing theories on information bottlenecks and generalization, providing a new perspective with potential practical implications for neural network training.', 'The experimental results illustrate that the proposed IIW measure effectively captures the fitting-compressing phase transition during training, offering insights into network behavior under various conditions.']","['The paper suffers from clarity issues, particularly in presenting complex concepts and the motivation behind certain assumptions.', 'Some theoretical claims need more rigorous justification, and the relationship between IIW and generalization could be explained more clearly.', 'The experimental validation, while promising, requires more diverse datasets and settings to demonstrate the robustness of the proposed approach.']",3,3,2,4,Reject
0q0REJNgtg,"The paper introduces a novel retrieval-augmented reinforcement learning paradigm (R2A) that enhances traditional RL agents by integrating a retrieval process, allowing agents to access past experiences and expert demonstrations. The authors demonstrate the effectiveness of R2A across multiple environments, including Atari games and multi-task settings, showing faster learning and higher scores compared to baseline agents.","['Can the authors provide more detail on the computational complexity and efficiency of the retrieval mechanism compared to traditional methods?', 'What specific insights were gained from the ablation studies, and how do they inform the design choices made in R2A?', 'Could the authors clarify the theoretical motivation behind the retrieval mechanism?', 'How do the authors envision addressing potential ethical implications of using past experiences from other agents?']","['The paper does not sufficiently address the potential computational overhead incurred by the retrieval process, which may limit its applicability in resource-constrained environments.', 'The reliance on a dataset of past experiences may limit the applicability of the approach in environments with sparse data.', 'There is insufficient discussion on the ethical implications of using experiences from other agents or experts.']",True,3,3,3,5,4,"['The integration of a retrieval mechanism into reinforcement learning is innovative and addresses key limitations of traditional parametric models.', 'Extensive experiments across various environments demonstrate the effectiveness of the proposed method, providing strong empirical evidence.', ""The paper presents a clear architectural overview of the retrieval-augmented agent, making it easier to understand the interaction between the retrieval process and the agent's learning mechanism.""]","['The clarity of some sections could be improved; for instance, the descriptions of the retrieval process and the integration with the agent are somewhat convoluted.', 'While ablation studies are performed, they could be more comprehensive. A deeper analysis of the impact of different hyperparameters related to the retrieval process would strengthen the findings.', 'The paper lacks a discussion on the computational overhead introduced by the retrieval mechanism, which is critical for understanding its practical implications.', 'The originality of the approach is questionable, as similar retrieval-based mechanisms have been explored in other domains.']",3,3,3,4,Reject
kQ2SOflIOVC,"The paper investigates few-shot learning (FSL) techniques in histology images using a combination of contrastive learning (CL) and latent augmentation (LA). It proposes a novel approach to enhance generalization by leveraging unlabeled data, claiming improved performance over supervised methods in histological image classification tasks.","['Could the authors clarify the latent augmentation process and provide more detail on how it interacts with the contrastive learning framework?', 'How does the proposed method compare quantitatively with existing few-shot learning methods in histology?', 'What specific limitations do the authors see in their approach?']","['Lack of clarity in the presentation of the method.', 'Insufficient comparison to existing work, especially in the context of histological images.', 'The reliance on specific datasets may limit the generalization of findings to other contexts.']",False,2,2,3,5,4,"['Addresses an important and clinically relevant problem in histology image analysis.', 'The combination of contrastive learning and latent augmentation is a novel approach that has the potential to enhance few-shot learning in this domain.', 'Empirical results suggest significant improvements in generalization performance for CL models compared to traditional methods.']","['The paper lacks clarity in explaining the details of the proposed methods, particularly regarding the implementation of latent augmentation and its integration with contrastive learning.', 'Results are presented with limited statistical analysis and insufficient comparisons to state-of-the-art methods, which undermines the validity of the claims.', 'The writing style is inconsistent, making it difficult to follow the key arguments and understand the methodology.']",3,2,2,4,Reject
gCmCiclZV6Q,"The paper discusses the ethical issues associated with large-scale image datasets, particularly the risks posed by offensive content. It proposes a method utilizing pre-trained models, specifically CLIP, to assist in the automated curation of these datasets by identifying offensive images. The authors argue that this approach can help avoid the propagation of harmful stereotypes and associations present in existing datasets.","['How does the model account for the subjective nature of offensiveness? Is there a mechanism to adapt to different cultural contexts?', 'Can the authors provide more details on the performance metrics used to evaluate the effectiveness of their approach?']","['The study could benefit from a more robust evaluation across multiple datasets and contexts, examining how well the model generalizes.', 'The ethical implications of automating content curation need to be explored in greater depth, particularly potential biases in the training data.']",True,3,3,3,4,4,"['The paper tackles a crucial and timely issue in machine learning regarding dataset ethics and offensive content.', 'The proposed methodology using CLIP for automated curation is innovative and has clear implications for improving dataset quality.', 'The paper provides thorough background and context on the challenges of dataset curation in relation to ethical considerations.']","['The clarity of the proposed methodology could be improved; some technical aspects may be difficult for readers to grasp.', ""The evaluation of the model's effectiveness is somewhat limited. More comprehensive experiments and validations across different datasets would strengthen the claims."", 'While the paper highlights the importance of tackling offensive content, it lacks a discussion on how to handle the subjectivity of offensiveness across different cultures.']",3,3,3,4,Reject
xS8AMYiEav3,"The paper proposes REASSURE, a novel methodology for repairing neural networks with ReLU activations, focusing on localized changes that rectify buggy outputs while maintaining the properties of the original network. The approach claims soundness and completeness, allowing for guaranteed fixes and minimal changes. However, the experimental validation is limited, and clarity issues hinder understanding.","['Can the authors provide more extensive experimental results across a wider range of neural network architectures?', 'How does the method scale with larger and more complex networks?', 'Could the authors clarify the construction and validation process of the patch networks in detail?']","['Experimental results are limited to specific benchmarks and do not address the scalability or generality of the method.', 'The paper does not adequately discuss the limitations of the proposed approach or its potential negative impacts on other parts of the neural network.']",False,3,3,3,7,4,"['Addresses an important problem in neural network deployment, particularly in safety-critical applications.', 'Proposes a theoretically sound and complete approach to neural network repair with guarantees on locality and minimality.', 'The experimental results demonstrate better performance in terms of locality and accuracy retention compared to existing methods.']","['Lacks comprehensive experimental validation across a variety of complex network architectures beyond the benchmarks provided.', 'The scalability of the approach to larger models or more complex problems is not adequately discussed.', 'Some sections of the methodology lack clarity, particularly in how the patch networks are constructed and validated.']",3,3,3,4,Reject
OqHtVOo-zy,"The paper proposes a method for estimating the Bayes label transition matrix in the context of instance-dependent label noise using deep neural networks. The authors argue that this approach is advantageous over traditional methods that estimate clean label transition matrices, as Bayes optimal labels are less uncertain. However, the paper is technically convoluted and lacks clear exposition, making it difficult to assess the contributions and implications of the method.","['Can the authors clarify the definitions and methodologies used for the transition matrix estimation?', 'What specific experimental protocols were followed to ensure the validity of the results presented?', 'Could the authors provide a more detailed explanation of the advantages of using Bayes optimal labels compared to clean labels?']","['The overall lack of clarity in both the exposition of the methodology and the presentation of the results hinders reproducibility.', 'The assumptions made regarding the transition matrix estimation need to be better justified.']",False,2,2,3,4,4,"['Addresses an important problem in learning with noisy labels.', 'Proposes a novel approach focusing on Bayes optimal labels, which theoretically provides advantages over traditional clean label transition estimations.', 'Includes a variety of experiments on synthetic and real-world datasets.']","['Lacks clarity and organization, making it challenging to understand the methodology and contributions.', 'Technical details regarding the estimation of the transition matrix and definitions used are ambiguous.', 'Experimental results are presented without sufficient context or analysis, making it hard to evaluate the significance of the improvements claimed.', 'Claims of superiority over existing methods are not well-supported with robust evidence.']",3,2,2,4,Reject
oTQNAU_g_AZ,"The paper proposes DAIR, a method for improving bimanual robot manipulation tasks by addressing the challenges of domination and conflict between two cooperating robots through disentangled attention intrinsic regularization. The method is evaluated on five manipulation tasks and demonstrates improved success rates and efficiency compared to several baselines.","['Can the authors clarify how the performance improvements compare to other state-of-the-art methods in more detail?', 'What specific measures were taken to ensure the validity of the results, particularly in avoiding overfitting?', 'Could the authors provide more detailed explanations of the attention mechanism and its implementation?']","['The paper does not adequately address the potential limitations of the disentangled attention mechanism, particularly in more complex tasks.', 'There are concerns about the reproducibility of results and the clarity of the experimental setup.']",False,3,3,3,6,4,"['Addresses a practical and relevant problem in robotics, namely safe and efficient bimanual manipulation.', 'Introduces a novel approach using disentangled attention to mitigate domination and conflict issues.', 'Experimental results demonstrate improvements in performance and safety compared to baseline methods.']","['The presentation lacks clarity in some sections, making it difficult to follow the methodology and results.', 'The significance of the improvements is not adequately contextualized or compared against a broader range of benchmarks.', 'The reliance on existing RL frameworks may reduce the perceived novelty of the approach.', 'Insufficient ablation studies and comparisons with state-of-the-art methods raise questions about the robustness and originality of the contributions.']",4,3,3,4,Reject
KSSfF5lMIAg,"This paper presents model-agnostic interpretability methods for Multiple Instance Learning (MIL), focusing on identifying key instances within bags and their contributions to model decisions. It establishes interpretability requirements for MIL and claims improvements in interpretability accuracy over existing methods.","['Can the authors clarify the methodology behind the proposed interpretability methods?', 'What specific limitations do the authors identify for their methods, and how might these affect the applicability of their results?', 'Could the authors provide a more detailed comparison of their methods against existing ones in terms of specific metrics?']","['The paper does not adequately address the limitations of the proposed methods, particularly in the context of varying datasets.', 'Clarity issues may hinder understanding and application of the methods by other researchers in the field.']",False,2,3,3,5,4,"['Addresses a significant gap in interpretability methods for Multiple Instance Learning.', 'Proposed methods show potential for broader applicability and demonstrate notable improvements in interpretability accuracy.', 'Comprehensive evaluation across multiple datasets provides valuable insights.']","['The methodology lacks clarity, making it difficult to fully grasp the proposed methods and their implications.', 'Experimental validation is limited, with insufficient analysis of how different datasets affect performance.', 'Claims regarding performance improvements lack robust statistical backing and detailed exploration of limitations.']",3,2,3,4,Reject
on54StZqGQ_,"The paper investigates degradation attacks on certifiably robust neural networks, demonstrating that these defenses can lead to unnecessary input rejections, thereby reducing model utility. It introduces new attack algorithms that exploit this flaw and empirically validates their efficacy against state-of-the-art certifiable defenses.","['Could the authors clarify their choice of models and datasets for the empirical evaluation?', 'How do the authors justify the sufficiency of their experiments to generalize the findings to other certifiable defenses?']",['The paper does not adequately address potential countermeasures against degradation attacks or explore the implications of such attacks in real-world applications.'],False,3,3,3,6,4,"['Addresses a critical issue in adversarial machine learning by highlighting the shortcomings of certifiably robust neural networks.', 'Introduces the novel concept of degradation attacks, which is relevant and timely.', 'Provides empirical evidence demonstrating the practical impact of these attacks on existing models.']","['The paper could benefit from clearer definitions and explanations, as some sections are convoluted and hard to follow.', 'The methodology section lacks sufficient detail regarding the implementation of the attack algorithms.', 'The empirical evaluation, while insightful, may not cover a wide enough range of scenarios or models to fully support the conclusions.']",3,3,3,4,Reject
R3zqNwzAVsC,The paper proposes an Ethical Module for mitigating gender bias in face recognition systems through a post-processing method that adjusts the embeddings of a pre-trained model. The method employs a shallow MLP trained with the von Mises-Fisher loss to enhance representation for discriminated subgroups and introduces new fairness metrics.,"['Can the authors provide more detailed explanations of the experimental setup and results?', 'What specific improvements does the Ethical Module provide over existing bias mitigation techniques?', 'Could you clarify how the new fairness metrics are computed and their implications for the results?']",['The paper does not sufficiently address the limitations of the proposed method or discuss potential negative societal impacts of biased models.'],True,2,2,2,5,4,"[""Addresses a critical issue of bias in face recognition, which is highly relevant in today's AI applications."", 'The proposed method is conceptually sound, leveraging existing pre-trained models to reduce computational costs and improve efficiency.', 'Introduces two new fairness metrics which could provide valuable insights into the performance of face recognition algorithms.']","['The clarity of the exposition is poor; some concepts and methodologies are not sufficiently explained, making it hard to follow.', 'The originality of the approach is questionable as it mainly builds upon existing methods without significant novel contributions.', 'The experimental section lacks depth and adequate evaluation metrics; more comprehensive results and comparisons with existing methods would strengthen the claims.', 'The choice of datasets and the specifics of the grid search for hyperparameter tuning are not adequately detailed.']",2,2,2,3,Reject
BGvt0ghNgA,"The paper proposes Lipschitz-constrained Skill Discovery (LSD), an unsupervised skill discovery method that addresses the limitations of existing mutual information-based approaches by encouraging the discovery of dynamic skills through a Lipschitz continuity constraint. The authors demonstrate the effectiveness of LSD across various MuJoCo environments, showing improved skill diversity and performance in downstream tasks.","['Can the authors clarify the implementation details and hyperparameter choices for better reproducibility?', 'Could the authors provide more comprehensive ablation studies to support the significance of the individual components of LSD?', 'Can the authors elaborate on how the Lipschitz constraint empirically aids in producing dynamic skills over time compared to MI objectives?']","[""The paper's clarity may hinder understanding, and additional effort to elaborate on complex components could enhance its accessibility."", 'The paper does not sufficiently address potential limitations of the proposed method, such as scenarios where the Lipschitz constraint might not be meaningful.']",False,3,3,4,7,4,"['The proposed LSD method addresses a notable limitation in current skill discovery methods by promoting dynamic skills.', 'The experiments conducted on multiple MuJoCo environments are comprehensive, showcasing the effectiveness of LSD in both skill discovery and downstream task performance.', 'The zero-shot goal-following capability of LSD is a significant contribution, indicating practical applications in reinforcement learning.']","['The clarity of the writing can be improved in several sections, making it challenging for some readers to grasp complex ideas.', ""Certain claims regarding the superiority of LSD could benefit from more extensive ablation studies to validate the individual components' significance."", 'The paper lacks detailed explanations of implementation choices and hyperparameter settings, which are crucial for reproducibility.', 'The novelty of the approach is somewhat undermined by the lack of clarity in explaining how LSD fundamentally differs from existing methods.']",3,3,4,4,Reject
1XdUvpaTNlM,"The paper presents a probabilistic channel pruning method called Batch Whitening Channel Pruning (BWCP) aimed at improving the efficiency of Convolutional Neural Networks (CNNs). BWCP utilizes a probabilistic framework to stochastically discard unimportant channels while preserving the learning capacity of the network. The authors claim that their method achieves competitive accuracy with reduced computational costs, supported by experiments on CIFAR-10, CIFAR-100, and ImageNet.","['Could the authors provide more detailed explanations of the batch whitening mechanism and its relationship with the learned activation probabilities?', 'How does the computational overhead of BWCP compare quantitatively to other pruning methods during training?', 'What specific scenarios or architectures would BWCP not be applicable or effective?', 'Can the authors clarify the limitations of their approach, particularly concerning potential trade-offs in accuracy?']","['The paper lacks clarity in several key areas, which may hinder reproducibility of the results.', 'There is insufficient exploration of potential increased computational costs during training with BWCP compared to traditional methods.']",False,3,3,3,5,4,"['The method addresses a significant issue in CNN efficiency by introducing a probabilistic approach to channel pruning.', 'Empirical results demonstrate that BWCP achieves competitive accuracy with substantial reductions in FLOPs, suggesting practical applicability.', 'The introduction of the batch whitening technique provides a theoretical basis for enhancing activation probabilities of important channels.']","['The clarity of the proposed methodology is lacking; specific details about the implementation of batch whitening and the soft sampling process require elaboration.', 'Comparisons with state-of-the-art methods are limited, and the paper does not address potential drawbacks associated with the increased computational overhead during training.', 'Some claims about the effectiveness of the method seem overstated without sufficient supporting evidence.']",3,3,3,4,Reject
cpstx0xuvRY,"The paper investigates the generalization error of iterative semi-supervised learning algorithms using information-theoretic principles, focusing on a binary Gaussian mixture model. It provides theoretical bounds that suggest the generalization error decreases with iterations but saturates eventually. The theoretical findings are supported by experiments on datasets like MNIST and CIFAR.","['Can the authors clarify the connection between the theoretical results and practical implications for practitioners in SSL?', 'What additional datasets or experiments could be included to strengthen the empirical findings?']","['The clarity of the presentation and theoretical derivations can hinder understanding.', 'A broader range of experiments is necessary to substantiate the claims made in the paper.']",False,3,3,3,5,4,"['The theoretical contribution provides valuable insights into the behavior of generalization error in semi-supervised learning.', 'The use of information-theoretic measures to derive bounds on generalization error is a novel approach that could help future research.', 'The empirical results corroborate the theoretical findings, showing the practical relevance of the study.']","[""The paper's presentation is dense and at times unclear, making it challenging for the reader to follow the theoretical derivations."", 'Limited experimental validation on only a few datasets, suggesting a need for broader validation to support claims.', 'The discussion of results lacks a deeper analysis of the implications of the findings.']",3,3,3,3,Reject
Wm3EA5OlHsG,"The paper presents Scene Transformer, a unified architecture for predicting multiple agent trajectories in dynamic environments, specifically focusing on autonomous driving. It employs attention mechanisms to account for interactions between agents, achieving state-of-the-art performance on both marginal and joint prediction tasks across two datasets.","['Could the authors clarify the architectural details and the reasoning behind specific design choices?', 'What are the potential limitations of the model in real-world applications?']","['The paper lacks a thorough discussion of limitations and potential real-world implications of using the proposed model.', 'The clarity issues may hinder understanding and reproducibility.']",False,3,3,3,5,4,"['Addresses a significant problem in autonomous driving by modeling interactions between multiple agents.', 'Proposes a novel Transformer-based architecture that utilizes attention across agents, time, and road graph elements.', 'Demonstrates competitive results on standard benchmarks, providing strong evidence for the effectiveness of the approach.']","['The clarity of the presentation could be improved, particularly regarding the architecture and its components, which makes it difficult to follow.', 'Insufficient detail is provided on the masking strategies and the reasoning behind design choices, impacting reproducibility.', 'The paper does not critically discuss the limitations of the proposed approach or its applicability in real-world scenarios.']",3,3,3,4,Reject
-uZp67PZ7p,The paper proposes a multi-agent reinforcement learning approach to inventory management using a shared-resource stochastic game framework. It introduces an algorithm aimed at optimizing replenishment decisions while addressing the complexities of cooperation and competition among agents. The authors conduct experiments to demonstrate the effectiveness of their approach compared to existing methods.,"[""Can the authors clarify the algorithm's steps and provide more detailed pseudocode?"", 'What measures are in place to ensure the robustness of the experimental results given the approximations used?', 'How do the authors plan to address the scalability of their approach in more complex scenarios?']","['The paper does not adequately address the limitations of the shared-resource assumption and its implications.', 'The clarity of the paper is a concern, as the explanation of the algorithm is not detailed enough for replication.']",False,3,3,3,5,4,"['The application of multi-agent reinforcement learning to inventory management is timely and relevant.', 'The shared-resource stochastic game framework is a novel approach that effectively captures agent interactions.', 'The paper includes extensive experimental results demonstrating potential efficiency gains.']","['The clarity of the methodology could be improved, making it challenging to fully grasp the proposed approach.', 'The experimental validation lacks comparisons against a broader range of baselines.', 'Key assumptions and limitations of the proposed method are not sufficiently discussed.']",3,3,3,4,Reject
vgqS1vkkCbE,"The paper proposes Value Function Spaces (VFS), a state representation derived from the value functions of low-level skills in hierarchical reinforcement learning. It claims that VFS improves long-horizon performance and enables better zero-shot generalization. Empirical evaluations are conducted in maze-solving and robotic manipulation tasks.","['Can the authors clarify how their proposed method differs significantly from existing state abstraction techniques in hierarchical RL?', 'What specific experimental results support the claim that VFS outperforms all baselines, especially in long-horizon tasks?', 'Could the authors provide a more detailed explanation of the implementation of VFS and its integration with existing reinforcement learning algorithms?']","['The methodology lacks sufficient detail, limiting reproducibility.', 'Experiments should include more diverse baselines to ensure performance improvements are significant.', 'Potential overfitting to specific environments or tasks is not adequately addressed.']",False,2,2,3,5,4,"['Addresses the important issue of long-horizon reasoning in reinforcement learning.', 'Introduces a novel representation that captures the affordances of skills, potentially streamlining decision-making.', 'Empirical results demonstrate improved performance in specific tasks and zero-shot generalization.']","['Clarity is lacking in several sections, making it difficult to follow the arguments.', 'Comparisons with existing methods could be more comprehensive, particularly regarding state abstraction techniques explored in prior work.', 'Experiments do not thoroughly evaluate alternative representations beyond a few baselines, raising questions about robustness.', 'The originality of using value functions for state representation has been previously explored, and the paper does not clearly delineate its novelty.']",2,2,2,4,Reject
2DJn3E7lXu,"The paper evaluates 18 different hardware metric predictors for Neural Architecture Search (NAS), analyzing their performance across various metrics, devices, and network architectures. It finds that MLP models are the most promising and suggests that verifying predictions can significantly improve architecture selection outcomes.","['Could the authors clarify the methodology for selecting predictors and datasets?', 'What recommendations do the authors have for future work based on their findings?', 'How could these findings be extended to other architectures or tasks not covered in this study?']","['Findings may not generalize well across all NAS applications.', 'Does not explore the impact of different hardware settings on predictor performance.', 'Does not address potential limitations of predictors in real-world applications.']",False,3,2,3,5,4,"['Addresses a critical issue in Neural Architecture Search (NAS).', 'Comprehensive evaluation of 18 predictors provides valuable insights into hardware metric prediction.', 'Offers practical recommendations for improving architecture selection outcomes based on predictor performance.']","['Lacks clarity in certain sections, making it difficult to follow some arguments.', 'Limited discussion on implications for future NAS work and potential improvements to predictors.', 'Reproducibility of results is questionable due to insufficient detail in some comparisons.', 'Verbose writing could be more concise; some sections lack coherence.', 'Analysis of predictor inaccuracies could benefit from more concrete examples.']",3,3,2,4,Reject
aBAgwom5pTn,"The paper introduces DYHPO, a method for hyperparameter optimization in deep learning that improves efficiency by dynamically determining which configurations to evaluate at varying budgets. It utilizes a novel Gaussian Process surrogate model that captures learning dynamics and modifies the acquisition function for multi-budget scenarios. The approach is tested on diverse datasets and neural networks, showing promising results over state-of-the-art methods.","['Can you clarify the specific hyperparameter configurations used during experiments?', 'What measures were taken to ensure the robustness of the results across different datasets?']","['The complexity of the proposed method may hinder practical implementation without further simplification.', 'The paper does not sufficiently address potential limitations or trade-offs of the approach compared to existing methods.']",False,3,2,3,6,4,"['Addresses a critical issue in hyperparameter optimization, particularly in gray-box settings.', 'Introduces an innovative surrogate model and acquisition function designed for multi-budget optimization.', 'Demonstrates broad applicability through evaluation across various datasets and neural network architectures.']","['The methodology is complex and may be difficult for readers to fully grasp without prior knowledge.', 'Lacks detailed descriptions of the experimental setup, particularly regarding datasets and hyperparameter configurations.', 'While results are promising, they do not consistently compare against a wide range of existing methods to validate improvements.']",3,3,2,4,Reject
SsPCtEY6yCl,"The paper discusses the uncomputability of partition functions in energy-based sequence models, arguing that expressive parametric families can lead to undecidable model selection and learning difficulties. It presents theoretical results demonstrating the challenges of estimating partition functions and model selection in these contexts.","['Can the authors provide intuitive explanations of the implications of their findings for practitioners?', 'What recommendations can be made for practitioners given the uncomputability issues discussed?', 'Can the authors provide examples or case studies illustrating challenges in model selection due to these theoretical results?']","['The paper may not adequately address how theoretical results translate into practical model design and selection.', 'Complexity of the theoretical framework may hinder broader understanding and application.']",False,3,2,3,4,4,"['Addresses a significant theoretical issue in energy-based sequence models.', 'Explores uncomputability and its implications for model learning, which is highly relevant.', 'Presents a structured approach to complex theoretical concepts.']","['Dense and difficult to follow, potentially alienating readers not well-versed in theoretical computer science.', 'Practical implications of the theoretical results are not clearly articulated, limiting relevance for practitioners.', 'Clarity in presenting complex arguments could be improved to avoid misunderstandings.', 'Lack of empirical validation raises concerns about the applicability of the theoretical insights.']",4,2,2,3,Reject
RxplU3vmBx,"The paper proposes a Cost-Free Incremental Learning (CF-IL) paradigm to mitigate catastrophic forgetting in deep learning models during incremental learning. The approach leverages a memory recovery paradigm that synthesizes past exemplars without the need for external memory or parallel networks, addressing the memory constraints associated with existing methods. The results demonstrate improved performance over state-of-the-art techniques on CIFAR-10 and Tiny-ImageNet datasets.","['Can the authors provide more detailed explanations and justifications for the memory recovery paradigm?', 'How does the proposed method compare with other recent works that also focus on memory recovery or synthesis of past experiences?', 'What specific hyperparameters were used during training, and how were they selected?']","['The paper does not adequately address the limitations of the proposed method, such as potential issues with overfitting when generating synthetic samples.', 'The clarity of the methodology and experimental setup could be improved.']",False,2,2,3,4,4,"['The proposed CF-IL paradigm effectively tackles the catastrophic forgetting problem in a cost-efficient manner, which is relevant for real-world applications.', 'The results on CIFAR-10 and Tiny-ImageNet datasets show promising improvements over existing methods, indicating the potential of the approach.', 'The method does not require additional memory or parallel architectures, simplifying the implementation.']","['The methodology lacks clarity in certain aspects, particularly in how the memory recovery paradigm synthesizes past exemplars and the specifics of the Dirichlet distribution used.', 'The experimental validation, while indicating improvements, could benefit from more comprehensive comparisons with a wider array of benchmarks and configurations.', 'The originality of the approach is somewhat limited as it does not sufficiently distinguish itself from existing methods in the literature, particularly those employing similar memory recovery techniques.']",2,2,2,3,Reject
PgNEYaIc81Q,"The paper introduces the Compositional Physical Reasoning (ComPhy) dataset and the Compositional Physics Learner (CPL) framework, aimed at enhancing AI's ability to infer hidden physical properties from videos. The work addresses the challenge of understanding non-visible properties and proposes a modular approach that integrates various reasoning techniques.","['Can the authors provide more clarity regarding the implementation details of the CPL model?', 'How do the authors plan to address the limitations observed in the evaluation of baseline models?', 'What specific metrics were used to evaluate the performance of the proposed models, and how were the baselines selected?']","[""The paper does not sufficiently address the limitations of the dataset or the CPL model's capacity to generalize beyond the provided examples."", 'The reliance on a limited number of training examples raises concerns regarding the robustness of the proposed approaches.']",False,3,3,3,5,4,"['The introduction of the ComPhy dataset fills a significant gap in existing benchmarks by focusing on hidden physical properties.', 'The CPL framework represents a comprehensive approach to physical reasoning, combining multiple components effectively.', 'The dataset includes various question types, enhancing its utility for rigorous evaluation of reasoning capabilities.']","['The paper lacks clarity in explaining the methodologies and the relationships between different components of the proposed model.', 'Evaluation is primarily based on a limited set of baseline models, and the performance results could benefit from a broader comparison.', 'The potential for overfitting on the specific datasets due to the few-shot learning setup is not adequately addressed.']",3,3,3,4,Reject
qI4542Y2s1D,"The paper presents FILM, a modular approach to embodied instruction following that utilizes structured representations to enhance navigation based on natural language instructions. It achieves state-of-the-art performance on the ALFRED benchmark without relying on expert trajectories or low-level instructions, indicating that structured spatial memory and a semantic search policy can significantly improve agent capabilities.","['Can the authors clarify how the modular components interact and contribute to performance improvements?', 'What specific aspects of the semantic search policy lead to the observed performance gains?', 'Could the authors provide a more detailed error analysis to better understand the limitations of the current approach?']","['The clarity of the paper could be improved, particularly regarding the methodologies and interactions of the component modules.', 'Further ablation studies are needed to establish the significance of each component in the context of overall performance.']",False,3,2,3,6,4,"['Achieves state-of-the-art performance on the ALFRED benchmark with a notable absolute improvement over previous methods.', 'Innovative use of modular components for language processing, semantic mapping, and semantic search, which enhances generalizability in diverse settings.', 'Demonstrates the potential of structured representations in embodied tasks, paving the way for future research.']","['Lacks clarity in describing the interactions between modular components, making it challenging to fully grasp the methodologies employed.', 'Insufficient comprehensive ablation studies to clarify the contributions of each component to overall performance.', 'While empirical results are promising, clearer definitions of success metrics and a deeper analysis of error modes would strengthen the findings.']",3,3,4,4,Reject
uy602F8cTrh,"The paper proposes CausalDyna, a Dyna-style model-based reinforcement learning algorithm that enhances generalization and sample efficiency through counterfactual reasoning using structural causal models. The approach is evaluated in the CausalWorld robotic-manipulation environment, showing improvements over state-of-the-art algorithms like MBPO and SAC.","['Can the authors clarify the methodology and how counterfactual reasoning is implemented in practice?', 'Will the authors consider expanding their experiments to include a wider variety of object properties and scenarios?', 'What additional experiments could be conducted to further validate the effectiveness of CausalDyna in different environments?']","['The clarity of the paper is a major concern; the methodology could be explained in a more straightforward manner.', 'The experimental evaluations are somewhat limited, which may not fully support the claims of improved generalization; more diverse testing is needed.', 'The reliance on structural causal models may limit the applicability of the proposed method to environments that do not conform to the assumptions of SCMs.']",False,3,2,3,5,4,"['Addresses a significant issue in reinforcement learning: the generalization to unseen object properties.', 'Introduces the innovative use of counterfactual reasoning within a Dyna-style framework, potentially improving sample efficiency.', 'Empirical results demonstrate improvements in performance metrics such as sample efficiency and generalization.']","['The presentation lacks clarity in explaining the methodology and the novel contributions of the proposed approach; clearer definitions and explanations are needed.', 'The experimental section lacks depth, with limited scenarios; expanding the range of experiments would strengthen the validation of generalization claims.', 'The connection between the proposed method and the results is not sufficiently articulated, making it difficult to assess the true impact of the contributions; more detailed analysis is required.']",3,3,2,4,Reject
iaqgio-pOv,"The paper proposes model-agnostic local explanations for similarity learners, introducing feature attributions and analogy-based explanations to enhance interpretability. It validates its approach through empirical evaluations and user studies across various datasets, particularly in healthcare and natural language processing applications.","['How do the authors plan to improve the clarity of their explanations?', 'Can the authors provide more elaboration on the experimental design and participant feedback?', 'What specific insights can be drawn from the analogy-based explanations in practice?']","['Key concepts and methods are not adequately explained, potentially leading to confusion among readers.', 'Limited exploration of the implications of applying these explanation methods in real-world scenarios.']",False,3,2,3,5,4,"['Addresses a significant gap in explainability for similarity models, which is crucial for trust in AI systems.', 'Introduces innovative methods that provide complementary insights into model predictions, enhancing interpretability.', 'Empirical evaluations and user studies demonstrate the effectiveness of the proposed methods, providing strong evidence of their utility.']","['The presentation lacks clarity; some sections are dense and convoluted, making it challenging to follow the arguments.', ""Insufficient comparison with existing explainability methods in the literature, which could strengthen the paper's contributions."", 'The experimental design and user study methodology require more detail to ensure robustness and reproducibility.']",3,3,2,4,Reject
JmU7lyDxTpc,"The paper investigates the epoch-wise double descent phenomenon in deep learning using a linear teacher-student model and statistical physics tools to derive analytical expressions for generalization dynamics. The authors validate their findings through numerical experiments, suggesting that double descent arises from the learning of features at different scales.","['Can the authors clarify how their findings can be translated to real-world deep learning architectures?', 'What additional experiments could be conducted to strengthen the claims made about epoch-wise double descent?']","['The theoretical model may oversimplify the complexities of real neural networks, leading to potentially misleading conclusions.', 'The paper does not sufficiently address the implications of the findings for practical applications in deep learning.']",False,3,3,3,6,4,"['Addresses an important theoretical issue in deep learning regarding epoch-wise double descent.', 'Utilizes statistical physics tools to derive closed-form analytical expressions, providing a novel perspective.', 'Presents relevant numerical experiments that validate theoretical predictions and align with empirical observations.']","['The clarity and organization of the paper could be improved, as some theoretical derivations may be difficult to follow.', ""The experimental validation is somewhat limited and could benefit from additional experiments to demonstrate the findings' applicability to complex models."", 'The practical implications of the findings could be articulated more clearly, enhancing their relevance to real-world applications.']",3,3,3,4,Reject
ZC1s7bdR9bD,"The paper proposes a novel algorithm for uncertainty attribution in Bayesian machine learning using path integrals. It aims to improve interpretability compared to existing methods and validates the approach on benchmark datasets, claiming to yield more meaningful attributions.","['Can the authors clarify the methodology and provide more details on the implementation?', 'What steps will the authors take to ensure comprehensive evaluations in future work?', 'Can the authors clarify the theoretical guarantees for their method, especially concerning completeness and implementation invariance?']","['The paper may not clearly convey how the proposed method outperforms existing alternatives beyond the presented experiments.', 'Potential confusion in understanding the relationship between path integrals and uncertainty attribution may limit accessibility.', 'The work lacks a thorough exploration of limitations and may not adequately address potential edge cases in uncertainty attribution.']",False,3,3,3,5,4,"['Addresses a significant problem of uncertainty attribution in Bayesian machine learning.', 'Introduces a novel methodology leveraging path integrals, providing a fresh perspective in this area.', 'Comprehensive experiments on benchmark datasets demonstrate the effectiveness of the proposed method.']","['The methodology lacks clarity, making it challenging for readers to fully grasp the proposed approach.', 'Some experimental results may not be comprehensive enough; additional evaluations could strengthen the findings.', 'Comparisons with existing methods could be more in-depth, particularly regarding their limitations.']",3,3,3,4,Reject
qnQN4yr6FJz,"The paper proposes a hybrid method for predicting outcomes with incomplete features, combining generative and discriminative approaches using variational inference. It aims to leverage the strengths of both approaches to improve predictive performance when features are missing. However, the contributions appear incremental and lack sufficient empirical validation.","['Can the authors clarify the differences between their approach and existing methods in the literature?', 'What specific empirical results suggest that their method outperforms established techniques?', 'Could the authors expand on the limitations of their method and discuss potential areas for improvement?']","['Insufficient clarity in methodology and presentation.', 'Lack of comprehensive empirical results across various datasets, raising concerns about generalizability.', 'Potential redundancy with existing literature on similar methods.']",False,2,2,2,4,4,"['Addresses a relevant problem in machine learning concerning incomplete data.', 'Attempts to combine generative and discriminative methods, which is a novel angle.', 'The use of variational inference provides a flexible framework applicable to modern machine learning models.']","['The presentation is unclear, making it difficult to follow the methodology.', 'Lacks sufficient empirical validation across a broad range of datasets, particularly in demonstrating the effectiveness of the proposed method.', 'The results do not convincingly demonstrate the superiority of the proposed method over existing approaches.', 'The originality of the method is questionable as it closely resembles existing work in the literature.']",2,2,2,3,Reject
HuaYQfggn5u,"The paper proposes FedBABU, a federated learning algorithm that improves personalization by decoupling the model into a body (extractor) and a head (classifier), updating only the body during training. The authors present empirical results demonstrating improved personalization performance compared to existing methods.","['Could the authors clarify the benefits of the fixed head compared to a learned classifier?', 'What specific improvements does the proposed method offer over existing personalized federated learning methods?', 'Can the authors provide a clearer explanation of their methodology?', 'Could additional ablation studies be included to validate the proposed approach?']","['Does not adequately discuss the limitations of the proposed method.', 'Needs clearer articulation of the novelty and contributions compared to existing approaches.', 'Experiments could include more diverse datasets.']",False,3,2,3,5,4,"['Addresses the important problem of personalization in federated learning.', 'Empirical results indicate that the proposed method can outperform existing federated learning algorithms.', 'Decoupling the model into an extractor and a classifier is a sound conceptual approach.']","['Lacks clarity in presenting the methodology and results.', 'Limited discussion on the implications of the fixed head during training.', 'Novelty is reduced as it builds upon existing concepts without sufficient distinction.', 'Experimental evaluation lacks depth against the latest state-of-the-art personalization methods.']",2,3,2,4,Reject
YmONQIWli--,"The paper proposes an efficient SDE solver designed for accelerating score-based generative models. It introduces adaptive step sizes to improve speed and reduce the number of score function evaluations while maintaining or improving sample quality. The authors compare their method to existing solvers, showing significant improvements in generation speed and image quality.","['Could the authors provide more detailed ablation studies to clarify the impact of individual components of their SDE solver?', 'What specific limitations have been observed in the applicability of the proposed method to other generative tasks outside image generation?', 'Can the authors clarify how the proposed method compares in terms of theoretical guarantees with existing SDE solvers?', 'Could the authors provide more detailed comparisons with other SDE solvers to contextualize the performance gains?']","['The paper primarily focuses on continuous-time image generation models, limiting its applicability to other domains.', 'The need for a relative tolerance parameter introduces a hyperparameter that can affect performance.', 'While the proposed method shows improvements, it has not been extensively validated across a wide variety of models and datasets, limiting generalizability.']",False,3,2,3,6,4,"['Addresses a prominent challenge in score-based generative models: slow data generation times.', 'Innovative approach using adaptive step sizes tailored to score-based models.', 'Demonstrates significant speed improvements (2 to 10 times faster) while maintaining image quality.', 'Extensive experiments with quantitative metrics (FID, IS) and qualitative samples showcase the effectiveness of the proposed method.']","['Lack of thorough ablation studies to isolate the effects of specific components of the proposed method.', 'Some comparisons with existing methods lack depth and could benefit from more systematic evaluation.', 'The clarity of the presentation can be improved, especially in explaining some of the technical details and results.', 'Experimental validation is limited; more comprehensive comparisons with existing state-of-the-art methods across multiple datasets would strengthen the claims.']",3,3,2,4,Reject
4jUmjIoTz2,"The paper proposes a collaboration framework (CDA[2]) for enhancing adversarial robustness in deep learning models by allowing multiple sub-models to collaborate rather than vote in an ensemble. The framework aims to minimize vulnerability overlaps and improve model capacity utilization, supported by empirical experiments showing competitive performance against established methods.","['Can the authors clarify how CDA[2] distinctly improves over existing ensemble methods?', 'Could the authors provide additional experimental comparisons with more diverse datasets and attack methodologies?', 'What specific measures did the authors take to ensure the collaboration does not lead to trivial optimization?']","['The paper does not sufficiently address the potential computational overhead of using multiple sub-models compared to a single robust model.', 'The lack of diverse datasets may limit the robustness of the proposed approach.']",False,2,2,3,4,4,"['The concept of collaboration among sub-models for adversarial robustness is novel and relevant.', 'Empirical results demonstrate that CDA[2] outperforms various ensemble methods under both black-box and white-box attacks.', 'The framework is theoretically motivated, addressing critical issues in model capacity.']","['The clarity of the writing is significantly lacking; many sections are convoluted and hard to follow.', ""The theoretical foundations lack rigorous proof to support claims about collaboration's superiority over ensembles."", 'The empirical evaluation is limited to a single dataset (CIFAR10), raising questions about the broader applicability of the findings.', 'Insufficient discussion on limitations and potential drawbacks of the CDA[2] framework.']",3,2,2,3,Reject
q9zIvzRaU94,"The paper introduces a method called State-Dependent Causal Inference (SDCI) for causal discovery in conditionally stationary time-series data. It aims to recover causal dependencies in scenarios where the underlying causal graph changes based on state variables. The method is evaluated in synthetic scenarios, showing some ability to recover causal dependencies.","['What specific contributions does the SDCI method make compared to existing approaches?', 'How can the authors ensure the reproducibility of their experiments?', 'What practical limitations does the proposed method face in real-world applications?']","['The paper does not sufficiently address the limitations of the proposed method, particularly regarding its applicability to real-world scenarios with noise and incomplete data.', 'The overall clarity and organization of the paper could be improved.']",False,2,2,2,4,4,"['Addresses a significant problem in causal discovery by focusing on non-stationary time-series data.', 'Proposes a novel approach (SDCI) that dynamically models causal relationships based on hidden states.', 'The problem of causal discovery in non-stationary time-series is highly relevant and significant.']","['The writing lacks clarity, making it challenging to follow the methodology, especially the SDCI framework.', ""Experimental results are limited to synthetic scenarios, which may not demonstrate the method's robustness in real-world applications."", 'The paper does not provide sufficient comparisons with a broader range of baseline methods, limiting the assessment of its significance.', 'The generalizability of the method to more complex scenarios is not adequately discussed.']",3,2,2,3,Reject
JV4tkMi4xg,"The paper presents NN+MILP, a framework for discrete black-box optimization that integrates piecewise-linear neural networks as surrogates with mixed-integer linear programming (MILP) for optimizing acquisition functions. The authors claim that their approach provides optimality guarantees and competitive performance on various benchmarks, including neural architecture search and DNA binding problems.","['Could the authors clarify the assumptions made regarding the types of neural network architectures used in the experiments?', 'What steps do the authors plan to take to improve the scalability of their approach for larger problem instances?', 'Can the authors provide more detailed comparisons with other state-of-the-art methods and discuss the limitations of their approach?']","['The authors should address the clarity of the proposed algorithms and the steps involved in the MILP approach as it is not very intuitive.', 'There is a lack of exploration of how the NN+MILP framework might adapt to broader classes of optimization problems, particularly in continuous or mixed-integer settings.']",False,3,2,3,5,4,"['The integration of MILP with neural networks offers a novel approach to discrete black-box optimization, leveraging the strengths of both methods.', 'The paper includes comprehensive experiments demonstrating that NN+MILP performs competitively against established algorithms across multiple problem domains.', 'The framework provides optimality guarantees, which is a significant advantage over heuristic methods typically used in this domain.']","['The methodology section lacks clarity, particularly in explaining the MILP formulation and its integration with neural network surrogates.', 'The experimental setup does not sufficiently explore the scalability of the method or provide a broader comparison with state-of-the-art methods.', 'There is insufficient discussion on the limitations of the proposed method, particularly regarding computational complexity and generalizability.']",3,3,3,4,Reject
pC00NfsvnSK,"The paper proposes Generalized Similarity Functions (GSF) to improve zero-shot generalization in offline reinforcement learning. It leverages contrastive learning to aggregate observations based on similarity in expected future behavior, employing generalized value functions to quantify this similarity. The framework is validated on an offline Procgen benchmark, demonstrating improved performance over existing methods.","['Could the authors clarify the key differences between GSF and existing methods in terms of theoretical contributions?', 'What specific empirical results support the claims of improved performance in zero-shot generalization?']","['The paper lacks sufficient clarity and detail in the methodology, making it hard to follow.', ""The experimental results need to be more comprehensive to substantiate the claims made about GSF's effectiveness.""]",False,3,2,3,4,4,"['Addresses a relevant and important problem in reinforcement learning regarding generalization from offline datasets.', 'Proposes a theoretically motivated framework for measuring similarities between observations using generalized value functions.', 'Introduces a new benchmark (offline Procgen) for testing zero-shot generalization performance in offline RL.']","['The clarity of presentation is lacking, making it difficult to fully grasp the proposed method and its implementation.', 'The originality is somewhat limited as the proposed method relies on existing ideas in representation learning and does not sufficiently distinguish itself from prior works.', 'The experimental validation is limited, and the paper would benefit from more comprehensive results to convincingly demonstrate the performance improvements over existing methods.']",3,2,2,3,Reject
LOz0xDpw4Y,"The paper introduces a dynamic programming method for optimizing inference schedules in Denoising Diffusion Probabilistic Models (DDPMs), aiming to reduce the number of refinement steps while maintaining sample quality. The authors claim significant improvements in generation speed with minimal loss in log-likelihood across various pre-trained DDPMs.","['Can the authors clarify the specific implementation details of the dynamic programming algorithm and how it compares to previous approaches?', 'What additional benchmarks could the authors consider to further validate their approach?', 'Could the authors provide more detailed ablation studies to support the claims made in the paper?']","['The paper does not sufficiently address potential limitations regarding the generalizability of the proposed inference paths to different datasets or tasks.', 'The clarity of the presentation could be improved, especially in explaining the dynamic programming algorithm and its application.']",False,3,3,3,5,4,"['The proposed method addresses a critical bottleneck in DDPMs, potentially leading to faster generation times.', 'The use of dynamic programming to optimize inference paths is a novel approach that could have implications for other generative models.', 'Empirical results indicate that the method can significantly reduce the number of refinement steps while maintaining competitive performance.']","['The clarity of the paper is subpar, particularly in explaining the dynamic programming algorithm and its integration with existing models.', 'The experimental validation lacks thorough ablation studies and comparisons with a wider range of benchmarks, limiting the robustness of the findings.', 'Some claims regarding improvements in log-likelihood and their correlation with FID scores require more rigorous analysis.']",3,3,3,4,Reject
DBOibe1ISzB,"The paper proposes the Simulation Transformer (SiT), a novel method for particle-based physics simulation that leverages interaction and abstract tokens to improve the modeling of particle interactions and material characteristics. SiT demonstrates superior performance and generalization capabilities compared to existing GNN-based approaches.","['Can the authors clarify the specific advantages of the interaction tokens over traditional scalar representations of interactions?', 'What specific adjustments to the hyperparameters led to the best performance, and how sensitive is the model to these parameters?', 'Can the authors provide additional details on the architecture of the sub-network used for interaction token generation?']","['The paper needs to improve clarity in the methodology and provide more information in the ablation studies to enhance reader understanding.', 'The lack of extensive qualitative comparisons with existing methods may limit the perceived effectiveness of the proposed approach.']",False,3,2,4,6,4,"['The introduction of interaction tokens and abstract tokens represents a significant advancement in how particle interactions and material properties are modeled.', ""The paper shows strong empirical results, demonstrating SiT's effectiveness across multiple environments and its ability to generalize well to unseen scenarios."", 'The comprehensive experiments and comparisons with state-of-the-art methods highlight the advantages of SiT in terms of performance and parameter efficiency.']","['The methodology is complex and lacks clarity, making it difficult to discern how the proposed architecture significantly differs from existing approaches.', 'The ablation studies are insufficiently detailed, particularly regarding the impact of interaction tokens and hyperparameter choices.', 'Some figures and descriptions are overly complicated, which may hinder comprehension for readers unfamiliar with the topic.']",4,3,2,4,Reject
Tubzedlc4P,"This paper introduces a Riemannian geometric framework for analyzing point cloud data, employing the Fisher information metric to establish a statistical manifold. It presents two case studies that illustrate applications in autoencoders for shape interpolation and latent space optimization. However, the paper lacks a thorough comparison with existing methods and suffers from clarity issues.","['How does the proposed method quantitatively compare with existing state-of-the-art techniques?', 'Can the authors provide clearer explanations of the mathematical constructs involved?', 'What specific advantages does the proposed method offer in practical applications compared to current methods?']","['The clarity of the presentation needs improvement to ensure accessibility to a broader audience.', 'The paper should provide a more thorough evaluation against existing methodologies to substantiate its claims.']",False,2,2,2,4,4,"['The application of Riemannian geometry to point cloud data is innovative and has the potential for significant impact.', 'The framework provides a new perspective on understanding and manipulating point cloud data through statistical manifolds.', 'The inclusion of case studies demonstrates practical applications of the proposed method.']","[""The paper does not adequately compare its approach with existing methodologies, such as the Hausdorff distance or Earth Mover's Distance, undermining the originality and significance of its contributions."", 'Clarity is a major concern; the mathematical details are dense and may not be easily understood by all readers.', 'The experimental validation is insufficiently rigorous, and the advantages of the method over established approaches are not convincingly demonstrated.']",3,2,2,3,Reject
bTteFbU99ye,"This paper investigates how neural language models (NLMs) estimate probabilities of sequences in natural language, focusing on the challenges posed by rare events. The authors develop a controlled evaluation methodology using generative models to create artificial languages, allowing for precise comparisons of estimated and true probabilities. The findings reveal that LSTM and Transformer models consistently underestimate the probability of sequences, especially rare ones, and tend to overestimate perturbed sequences.","['Could the authors clarify the specific experimental design and steps taken during evaluation?', 'What are the limitations of the artificial languages used for comparison, and how might they affect the findings?', 'Can the authors provide more detailed ablation studies to support their claims regarding model estimation error?']","['The methodology may not fully capture the complexity of natural language distributions as it relies on artificial languages.', 'Potential limitations in the experimental design may affect the generalizability of the findings.']",False,2,2,2,3,4,"['Addresses a critical issue in neural language modeling regarding the estimation of probabilities for rare sequences.', 'Introduces a novel controlled evaluation methodology that leverages generative models to create artificial languages.', 'Comprehensive experimental results provide clear insights into the performance of LSTM and Transformer models.', 'Discusses implications of the findings for understanding the limitations of current neural language models.']","['The methodology lacks clarity in the experimental design and specific evaluation steps.', 'Insufficient details in the ablation studies hinder robust validation of results, particularly regarding training data size and model architecture.', 'Some results, especially those regarding softmax temperature, could be presented more clearly.', 'The discussion on implications could be more thorough, particularly in relation to existing literature.']",2,2,2,4,Reject
dIVrWHP9_1i,"The paper presents G-Mixup, a novel data augmentation method for graph classification that leverages graphons to mix graph data from different classes. It addresses the challenges of applying mixup to graphs by focusing on class-level augmentation rather than individual graphs. Theoretical analysis supports the method's effectiveness, and experimental results show improvements in the generalization and robustness of GNNs.","['Can you provide additional experimental results to validate G-Mixup across different datasets and GNN architectures?', 'Could you clarify the specific metrics used to evaluate the robustness of GNNs in your experiments?']","['The experimental setup lacks diversity, limiting the generalizability of the results.', ""Clarity issues in writing may hinder readers' understanding of the proposed method and its implications.""]",False,3,2,3,5,4,"['The application of mixup to graph data using graphons is innovative and addresses a significant gap in current data augmentation techniques for GNNs.', 'The theoretical foundation for preserving discriminative motifs in generated graphs is a valuable contribution.', 'Experimental results demonstrate that G-Mixup enhances the performance and robustness of GNNs across various datasets.']","['The experimental evaluation is limited; more diverse datasets and GNN architectures should be tested to validate the approach comprehensively.', 'The clarity and organization of the writing need improvement, as some sections are difficult to follow.', 'The theoretical claims require stronger empirical support to validate the robustness of the proposed method.']",3,3,2,3,Reject
FFGDKzLasUa,"The paper proposes a stochastic deep network architecture using linear competing units for meta-learning, specifically called Stochastic LWTA. The authors claim that this approach enhances generalization while significantly reducing model size. The experimental results suggest improvements in predictive accuracy on standard few-shot classification benchmarks such as Omniglot, Mini-Imagenet, and CIFAR-100.","['Could the authors clarify how Stochastic LWTA distinctly improves upon traditional LWTA in practical applications?', 'What are the specific limitations of the proposed method, and how do the authors plan to address them in future work?']","['The paper lacks a comprehensive discussion on the limitations of the proposed approach, particularly regarding scalability and implementation complexity.', 'The potential computational overhead introduced by stochastic sampling at prediction time is not sufficiently discussed.']",False,2,2,3,4,4,"['The proposed method introduces a unique mechanism of stochastic competition among network units, which could lead to advancements in meta-learning.', 'The experimental results demonstrate promising performance improvements on few-shot learning tasks, indicating the potential applicability of the proposed approach.', 'The paper is well-structured, with clearly defined sections covering the proposed approach, experiments, and results.']","['The novelty of the approach is questionable as it heavily builds on existing concepts such as LWTA and Bayesian inference without providing substantial differentiation.', 'The clarity of explanation in several sections, particularly in the theoretical aspects and algorithm formulation, is lacking and may confuse readers.', 'The paper does not adequately address limitations or potential negative implications of the proposed methodology.', 'The ablation studies presented are limited and do not thoroughly explore the effects of different parameters or configurations.']",3,2,2,4,Reject
ahi2XSHpAUZ,"The paper proposes WeakM3D, a method for weakly supervised monocular 3D object detection that eliminates the reliance on labor-intensive 3D box annotations. By leveraging 2D detections and RoI LiDAR points, the method employs several novel losses to align predicted 3D boxes with these weak supervision signals. The proposed method addresses challenges such as alignment ambiguity and uneven point cloud distribution. Extensive experiments demonstrate its effectiveness, achieving performance comparable to some fully supervised methods.","['Can the authors provide more detailed insights into how each proposed loss function contributes to the overall performance?', 'What are the specific limitations observed during experiments, particularly in scenarios with occlusion or low point cloud density?', 'How does the proposed method compare to other weakly supervised methods beyond the discussed comparisons?']","['The paper lacks a thorough discussion of limitations and potential failure cases, which is crucial for understanding the scope of the proposed method.']",False,3,3,3,5,4,"['The approach addresses a real and significant problem in 3D object detection by reducing reliance on expensive 3D annotations.', 'The introduction of multiple innovative loss functions is a notable contribution to addressing challenges like alignment ambiguity and point density imbalance.', 'The paper includes extensive experiments on the KITTI dataset and demonstrates performance improvements over several baselines.']","['The explanations of the proposed loss functions and their interactions lack sufficient depth, making it difficult to fully grasp their individual contributions. More detailed descriptions or examples would enhance understanding.', 'The experimental results could be more comprehensive with clearer comparisons to a wider range of state-of-the-art methods, particularly in the weakly supervised context. Including additional baselines would strengthen the evaluation.', 'The paper does not sufficiently discuss the limitations of the proposed approach, particularly in challenging scenarios such as occlusion or extreme viewpoint differences. A discussion on potential failure cases would be beneficial.']",3,3,3,4,Reject
EZNOb_uNpJk,"The paper presents ClimateGAN, a generative model designed to simulate photorealistic flooding on street-level images to raise awareness about climate change. It combines simulated and real data through a dual architecture comprising a Masker model for flood prediction and a Painter model for rendering realistic water textures.","['Could the authors clarify how the model performance compares quantitatively to existing state-of-the-art methods?', 'What specific metrics were used during the human evaluation, and how were participants selected?', 'Can the authors provide more detailed explanations of how the Masker and Painter models interact during training?', 'How can the authors ensure that the generated images are not misinterpreted or misused by the public?']","['The reliance on simulated data may limit its applicability to real-world scenarios that were not represented in the training data.', 'The evaluation methodology lacks robustness, particularly in the absence of ground truth for real images.']",True,3,3,3,5,4,"['Addresses a critical issue of climate change by providing visual representations of potential flooding.', 'Innovative use of generative modeling to raise awareness about climate change.', 'The creation of a dataset from a virtual environment is a notable contribution that could aid future research.']","['The novelty of the method is somewhat overshadowed by existing techniques in image-to-image translation and GANs, making the contributions less clear.', 'The methodology lacks clarity, particularly regarding the training procedure and the interaction between the Masker and Painter.', ""Evaluation metrics are not clearly justified, and the reliance on a limited number of human evaluators may not adequately capture the model's performance."", 'The paper does not sufficiently discuss the potential limitations of the dataset and how it may affect generalization to real-world scenarios.']",3,3,3,4,Reject
FKp8-pIRo3y,"The paper introduces HinDRL, a framework that enhances goal-conditioned reinforcement learning by utilizing task-specific goal distributions derived from demonstrations. It effectively addresses the challenges of long-horizon dexterous manipulation tasks and demonstrates significant improvements in performance over existing methods, requiring fewer demonstrations.","['Can the authors elaborate on the decision-making process for selecting task-specific goals in the HinDRL framework?', 'What limitations do the authors foresee in scaling this approach to more complex environments or tasks?', 'Are there any ethical considerations associated with the deployment of this technology in real-world scenarios?']","['The paper does not adequately address the limitations or potential negative societal impacts of deploying robotic systems trained using this technology.', 'Further exploration of the robustness of the learned representations in varying conditions is needed.']",False,3,4,3,6,4,"['The proposed HinDRL framework effectively combines demonstration-driven learning with hindsight relabelling, leading to improved performance in complex tasks.', 'The experimental results show that HinDRL can significantly reduce the number of required demonstrations while achieving high accuracy in long-horizon tasks.', 'The paper provides a comprehensive evaluation across multiple complex robotic tasks, showcasing the robustness of the proposed method.']","['Certain parts of the methodology and results sections lack clarity, particularly in explaining how task-specific goals are selected and utilized.', 'The paper does not sufficiently discuss the limitations of the approach or the potential ethical implications of using AI in robotics.', 'Some figures and diagrams could be better annotated to enhance understanding.']",3,3,4,5,Reject
GugZ5DzzAu,The paper extends the MARINA method for distributed non-convex optimization by introducing correlated compressors and a new metric called Hessian variance. It claims that these extensions improve communication complexity in specific scenarios and validates these claims through experiments on synthetic datasets and the MNIST dataset.,"['Can the authors clarify the practical implications of using PermK compared to existing methods in more detail?', 'What are the potential drawbacks or limitations of the proposed permutation-based compressors in real applications?', 'Could the authors discuss the trade-offs between communication efficiency and computational overhead introduced by the new methods?']","['The clarity of the paper is a major concern, particularly regarding the assumptions and the implications of the results.', 'The experiments require more detailed descriptions to ensure reproducibility and to understand the contexts in which the findings hold.']",False,3,2,3,5,4,"['The introduction of correlated compressors is a novel contribution that may enhance the state-of-the-art in distributed optimization methods.', 'The concept of Hessian variance is innovative and could lead to deeper insights in optimization analysis.', 'The theoretical framework provides a fresh perspective on communication efficiency in distributed systems.']","['The paper lacks clarity in its presentation, especially in defining key concepts and the implications of various assumptions. For instance, the definitions of Hessian variance and its relevance could be elaborated further.', 'The empirical validation is limited, with insufficient comparisons to existing methods, which raises questions about the practical applicability of the proposed techniques.', 'The theoretical exposition is dense and may be challenging for readers without a strong background in optimization theory.']",3,3,2,4,Reject
RQ428ZptQfU,"The paper introduces Variational Deep Survival Clustering (VaDeSC), a novel probabilistic approach to clustering survival data that leverages a deep generative model. The authors claim that their method outperforms existing techniques in clustering and predicting survival times across various datasets, including medical imaging data.","['Can the authors clarify the novelty of their contributions compared to existing survival clustering methods?', 'What specific improvements do they expect from their novel generative assumptions compared to existing models?', 'Can the authors provide more detailed ablation studies to substantiate their claims regarding the contributions of different components of their model?']","['The clarity of the paper could be significantly improved, particularly in articulating the contributions and methodology.', 'The completeness of the experimental evaluation is questionable; the authors should consider more comparisons with relevant state-of-the-art approaches.', 'The paper does not adequately address the potential ethical implications of using AI in survival analysis, particularly in clinical settings.']",True,3,2,3,5,4,"['Addresses an important and under-explored problem in survival analysis.', 'Innovative use of a deep generative model to jointly model explanatory variables and survival outcomes.', ""Comprehensive experiments on synthetic, semi-synthetic, and real-world datasets demonstrate the method's effectiveness.""]","['The novelty and contributions of the proposed method compared to existing techniques are not clearly articulated.', 'Mathematical foundations and the generative process of the proposed model lack clarity, making it difficult to assess its validity.', 'The significance of the results could be better contextualized against previous work in the field.', 'The originality of the approach is limited as it closely resembles existing mixture models and clustering methods.', 'Insufficient comparisons to existing state-of-the-art methods and lack of ablation studies to validate claims.']",3,3,2,3,Reject
5Qkd7-bZfI,"The paper explores the role of population heterogeneity in emergent communication, particularly in the context of the Lewis Game. It investigates how varying agent population size and learning speeds affect the structure of emergent languages, finding that larger populations do not necessarily lead to better language structures in homogeneous settings, but introducing heterogeneity improves stability and structure.","['Could the authors clarify the methodology used to introduce population heterogeneity? What specific measures were taken?', 'How do the authors ensure that the observed effects are not confounded by other factors?']","[""The clarity of the paper is a major limitation, which could hinder the reader's understanding and the paper's impact."", 'Further validation of the proposed hypotheses in different contexts is necessary to strengthen the claims.']",False,3,3,3,7,4,"['Addresses a significant gap in the literature regarding the effect of population heterogeneity on emergent communication.', 'The study is well-grounded in sociolinguistic theory, providing a theoretical basis for the experiments.', 'Empirical results provide evidence that introducing heterogeneity in agent training speeds can enhance language properties in larger populations.']","['The paper lacks clarity in several sections, particularly the methodology and experimental design.', 'The experimental results may not be sufficiently robust or comprehensive to support the claims made.', 'Some sections could benefit from clearer definitions and explanations of key concepts, especially regarding the established correlations and metrics.']",3,3,3,4,Reject
0JzqUlIVVDd,The paper proposes a KL divergence-based approach for domain adaptation that derives a generalization bound to align representations between source and target domains. It claims to outperform existing marginal-alignment techniques without additional computational overhead or adversarial training.,"['Could the authors provide additional clarity on the experimental setup and results?', ""What are the authors' thoughts on the limitations of their approach, particularly in cases where the conditional distributions vary significantly?"", 'Can the authors clarify the implications of the KL divergence in practice?', 'Could the authors provide more details on the experimental setup and results on other datasets?']","['The clarity of the paper is a major issue that needs to be addressed to enhance understanding.', 'The experiments may not fully capture the performance of the proposed method in various realistic scenarios.', 'The paper lacks comprehensive ablation studies to support the claims about the efficiency and stability of the proposed method.', 'There may be concerns regarding the generalizability of the method to real-world applications beyond the tested datasets.']",False,3,3,3,6,4,"['The theoretical foundation provided by the generalization bound is a significant contribution to the domain adaptation literature, offering a new perspective on representation alignment.', 'The approach to using KL divergence for representation alignment is novel and offers potential benefits in practical applications, particularly in scenarios where computational resources are limited.', 'The experimental results suggest that the proposed method achieves competitive performance against established baselines, indicating its effectiveness.']","['The paper lacks clarity in presentation, particularly in explaining the methodology and the implications of the results, which could confuse readers.', 'Some experimental results are not sufficiently detailed, and comparisons to existing methods could be more comprehensive to better contextualize the findings.', 'The implications of the proposed method and its limitations are not thoroughly discussed, raising concerns about its robustness in practical scenarios.']",3,3,3,4,Reject
-6me0AsJVdu,"The paper introduces Mutation Validation (MV), a novel model validation method that utilizes mutated training labels to assess model performance. MV aims to provide a more reliable alternative to traditional validation sets by focusing on how well a model can handle noise in training labels. The authors explore various learning algorithms and datasets, claiming that MV significantly outperforms traditional methods in model selection and stability.","['Can the authors clarify the process of generating mutated labels and how different types of mutations affect results?', ""What specific theoretical frameworks support the claims made about MV's effectiveness compared to traditional methods?"", 'Could the authors provide more details on the experimental setup and data characteristics used in their analysis?']","['The paper fails to adequately justify the theoretical foundations of MV, leading to concerns about its robustness and applicability.', ""Clarity issues in methodology and results hinder the reader's ability to fully grasp the significance and implications of the findings.""]",False,2,2,2,4,4,"['The approach of using mutated labels for model validation is innovative and could provide valuable insights into model robustness.', 'The study covers a diverse range of algorithms and datasets, enhancing the general applicability of MV.', 'Results indicate that MV outperforms traditional validation methods in certain scenarios, suggesting practical relevance and potential for real-world applications.']","['The methodology lacks clarity regarding the generation of mutated labels and the systematic interpretation of results.', ""Insufficient theoretical justification for MV's effectiveness compared to established validation methods."", 'Results are presented without detailed descriptions of the experimental setup, making it difficult to assess the rigor of the claims.', 'There is a reliance on software testing techniques without adequately addressing their translation to the machine learning context.']",2,2,2,3,Reject
eIvzaLx6nKW,The paper proposes a Multi-Domain Self-Supervised Learning (MDSSL) approach that aims to improve feature representations across diverse datasets using a hierarchical loss function designed to measure agreement within and across datasets. The authors claim significant performance improvements over existing methods and provide a framework that can operate with or without domain labels.,"['Can the authors elaborate more on the robustness of MDSSL across diverse datasets?', 'How do the efficiency gains impact the representation quality?', 'Could you provide more details on the clustering methodology, particularly on how outlier detection is implemented?', 'What specific metrics were used to evaluate the robustness of the clustering approach?']","['Lack of clarity and detail in experimental results may hinder understanding and reproducibility.', 'Efficiency claims need more in-depth analysis with respect to potential trade-offs.', 'The paper does not sufficiently explore the limitations of the proposed method when domain labels are not available.']",False,3,3,3,5,4,"['Addresses an important problem of self-supervised learning in multi-domain settings.', 'Proposes a novel hierarchical loss function that enhances feature representation learning across multiple datasets.', 'Demonstrates up to 25% improvement in accuracy on downstream tasks compared to baseline methods.']","['The presentation lacks clarity in explaining the experimental setup and results, which may hinder reproducibility.', 'There is insufficient discussion on the robustness of the model across various datasets and their characteristics.', 'Efficiency claims require more nuanced discussion and evidence regarding potential trade-offs.', 'The reliance on domain labels during training may limit the applicability of MDSSL in real-world scenarios where such labels are unavailable.', 'The clustering approach lacks detail, particularly regarding the robustness of the clustering technique and its integration with the MDSSL framework.']",3,3,3,4,Reject
xnYACQquaGV,"The paper presents Neural-LinUCB, a new algorithm for neural contextual bandits that combines deep representation learning with shallow exploration. It claims to achieve a regret bound of O(√T) and demonstrates computational efficiency through empirical evaluations on real-world datasets.","['Could the authors clarify how their method fundamentally differs from existing approaches in neural contextual bandits?', 'Can the authors provide a more detailed interpretation of their theoretical results?', 'What specific limitations do the authors foresee for their method in practical applications?']","['The paper does not adequately differentiate itself from prior work in neural contextual bandits, raising concerns about its contribution.', 'The theoretical implications of the results could be presented more clearly.', 'The experimental results, while promising, are not comprehensive enough to validate the claims made.']",False,3,2,3,5,4,"['The proposed algorithm effectively combines deep representation learning with shallow exploration, addressing the exploration-exploitation dilemma in contextual bandits.', 'The theoretical results provide a solid foundation for the proposed method, establishing a sublinear regret bound.', 'Empirical results show that Neural-LinUCB outperforms several existing algorithms on various datasets, demonstrating practical viability.']","['The originality of the work is overstated; it does not provide enough novel contributions compared to existing literature.', 'The clarity of the presentation could be improved; some sections are dense and may be difficult for readers to follow.', ""The experimental section lacks sufficient breadth and clarity in presenting results, limiting the ability to evaluate the proposed algorithm's effectiveness.""]",3,3,2,4,Reject
qQuzhbU3Gto,"The paper proposes a novel edge-independent graph generative model that captures both heterophilous and homophilous structures, providing nonnegative embeddings for enhanced interpretability. Theoretical results support the model's expressiveness, and experiments demonstrate its effectiveness in tasks such as multi-label clustering and link prediction.","['Can you provide additional comparisons with existing models, particularly those that also claim to handle heterophily?', 'How does the model perform on larger, more complex networks beyond the datasets presented?']","['The paper should clarify its contributions relative to existing models and provide more robust evaluations of its performance across diverse datasets.', 'The clarity of the theoretical contributions and their implications for practice could be enhanced.']",False,3,4,4,6,4,"['The model addresses a significant gap in current graph generative models by effectively capturing heterophilous structures.', 'The use of nonnegative embeddings enhances interpretability, allowing for clearer understanding of community relationships.', ""The theoretical framework is well-developed and supports the claims made about the model's expressiveness.""]","['The originality may be considered moderate, as the model builds on existing techniques like NMF and logistic PCA without introducing substantial novelty.', 'The experimental section could benefit from more comprehensive comparisons with a broader range of existing models, limiting the assessment of its effectiveness.', 'The presentation is dense with theoretical details that may confuse readers, making it challenging to follow the core contributions.']",4,3,4,5,Reject
SYuJXrXq8tw,"The paper introduces a novel approach to adversarial training by incorporating static and dynamic sparsity to enhance robust generalization. It presents two methods: Robust Bird (RB) for static sparsity and Flying Bird (FB) for dynamic sparsity, demonstrating significant reductions in robust generalization gaps and training costs through experiments on CIFAR-10/100 and Tiny-ImageNet. However, the clarity of the methodology and the thoroughness of the evaluation are questioned.","['Can the authors elaborate on the limitations of their approach, particularly regarding the trade-offs of sparsity in practical applications?', 'Could the authors provide more details on the experimental setup to enhance reproducibility?']","['The clarity of the methodology, especially regarding dynamic sparsity, could be improved.', 'The reliance on specific datasets may limit the generalizability of the findings.']",False,3,3,3,5,4,"['The introduction of sparsity into adversarial training is a novel contribution that could advance the field.', 'Empirical results demonstrate significant improvements in robust generalization and efficiency.', 'The paper addresses a critical issue in adversarial training—robust generalization gaps.']","['The methodology and rationale behind the static and dynamic sparsity concepts lack sufficient detail.', 'Clarity in explanations and structure could be improved to enhance understanding.', 'Additional comparisons and ablation studies would strengthen the experimental validation.']",3,3,3,4,Reject
O-r8LOR-CCA,"The paper introduces ORCA, a novel framework for open-world semi-supervised learning that allows for the discovery of new classes in unlabeled data. It proposes an uncertainty adaptive margin mechanism to address class distribution mismatches between labeled and unlabeled datasets. While the experiments show that ORCA outperforms existing methods on benchmark datasets, the paper suffers from clarity and originality issues.","['Can the authors provide more details on how the uncertainty adaptive margin is calculated?', 'What specific metrics were used to benchmark the performance of ORCA against the baselines, and how were they determined?', 'Could the authors clarify the reasoning behind choosing the datasets used for evaluation?']","['The paper does not sufficiently address the potential limitations of using an uncertainty adaptive margin, particularly in varied data distribution scenarios.', 'There is a lack of thorough analysis regarding the generalizability of the results across different domains and datasets.']",False,2,4,3,5,4,"['Addresses a significant gap in semi-supervised learning by considering open-world scenarios where novel classes may appear.', 'Introduces a novel uncertainty adaptive margin mechanism that could contribute to more robust learning under class distribution mismatches.', 'Demonstrates strong performance improvements on benchmark datasets, suggesting practical applicability.']","['Lacks clarity in the description of the ORCA framework and its components, making it difficult to fully understand the methodology.', 'The experimental setup and comparison with existing methods are not rigorous enough to convincingly demonstrate the advantages of ORCA.', 'The paper does not adequately explore the impact of different hyperparameters and settings on the performance of ORCA, which raises concerns about its robustness.']",4,3,4,4,Reject
9u5E8AFudRx,"The paper proposes a novel approach to enhancing the learning capabilities of autonomous agents by integrating social learning with autotelic learning through the Help Me Explore (HME) interaction protocol. The authors present GANGSTR, a graph-based autotelic agent capable of mastering complex configurations with minimal social interventions.","['Can the authors provide a more detailed explanation of how the internalization mechanism works?', 'What statistical methods were used to validate the experimental results? Can the authors provide more extensive comparisons with other state-of-the-art methods?']","['The paper does not sufficiently address the clarity of its presentation, making it hard for readers to grasp the proposed methods.', 'The experimental results lack depth and context, which limits the ability to assess the significance of the findings.']",False,3,3,4,6,4,"['The integration of social and autotelic learning is an interesting and innovative approach that could enhance the adaptability and skill acquisition of autonomous agents.', 'The proposed HME protocol facilitates guided exploration for the agents, leveraging social interactions to help them reach beyond their current capabilities.', 'The use of a graph-based representation for managing goals and configurations is a reasonable and promising direction for improving learning efficiency.']","['The presentation of the paper lacks clarity in some sections, making it challenging to follow the proposed methods and results. Key concepts and experimental setups need to be explained more thoroughly.', 'Experimental validation could be strengthened with more comparisons to existing methods and a clearer reporting of results. The experimental design would benefit from a more structured approach and robust statistical analysis.', 'Some components, like the internalization mechanism and the construction of the semantic graph, require more detail to ensure reproducibility and understanding.']",3,3,3,4,Reject
EYCm0AFjaSS,"The paper introduces ZerO, a deterministic weight initialization scheme for residual networks using only zeros and ones. It claims to improve reproducibility and achieve state-of-the-art performance on image classification tasks without batch normalization. The method involves augmenting ResNet architectures with additional skip connections and Hadamard transforms.","['What specific advantages does ZerO offer over other deterministic initialization methods?', 'Can you provide more detailed analyses on the implications of training without batch normalization?', 'How does ZerO perform against other contemporary initialization methods that do not rely on randomness?']","['The paper does not sufficiently address potential limitations and drawbacks of the ZerO initialization method.', 'It remains unclear how ZerO performs in more complex scenarios beyond image classification.']",False,2,2,3,5,4,"['The concept of deterministic initialization in deep learning is novel and could lead to improvements in reproducibility.', ""ZerO's potential to eliminate the reliance on batch normalization is an interesting angle that could impact future network training practices."", 'The experiments conducted demonstrate competitive performance, suggesting that the proposed method is promising.']","['The paper lacks sufficient theoretical justification for why deterministic initialization is effective compared to established random methods.', 'Results are primarily shown against random initialization methods; comparisons with other recent deterministic methods are limited.', 'The methodology and the impact of the Hadamard transform need clearer explanations for better understanding.', 'The significance of the results is not adequately discussed, particularly regarding the implications of achieving lower variance in repeated runs.']",3,3,3,3,Reject
MTsBazXmX00,"The paper presents a target propagation (TP) approach based on regularized inversions for training recurrent neural networks (RNNs). It aims to provide an alternative to gradient backpropagation, particularly for long sequences. While the contributions are relevant, they are incremental, and the clarity and depth of experimental validation are insufficient.","['What specific novel insights does this work provide that are not already established in the literature?', 'Can the authors clarify how their method significantly improves performance over traditional back-propagation methods in a broader set of tasks?', 'What are the practical implications of the proposed regularization in their approach?']","['The paper does not adequately address the limitations of target propagation compared to back-propagation.', 'The experimental results lack diversity in tasks and datasets, potentially limiting the generalizability of the findings.', 'The clarity of the presentation needs improvement to better convey the proposed method.']",False,2,2,2,4,4,"['The exploration of target propagation as an alternative to gradient backpropagation is timely and relevant.', 'The theoretical insights regarding regularized inversions provide a fresh perspective.', 'Some empirical results indicate potential advantages of TP over BP in specific scenarios.']","['The originality of the contributions is limited, as the work does not significantly advance existing literature on target propagation.', 'The experimental validation is narrow and does not comprehensively support the claims made about the advantages of TP.', 'The clarity of the writing is subpar, making it difficult to fully grasp the contributions and proposed methods.']",2,2,2,3,Reject
gjNcH0hj0LM,"The paper introduces Temporal Coherence-based Label Propagation (TCLP) for active learning in time-series data, claiming significant improvements in classification accuracy while querying fewer data points. It demonstrates the effectiveness of the method through experiments, suggesting a novel approach to label propagation based on temporal coherence.","['Can the authors clarify how the plateau model fitting works in practice? Are there any specific parameter settings that influence its performance?', 'Could more rigorous comparisons with existing active learning methods be provided to validate the claims of superiority?', 'What specific limitations might the proposed method face in real-world applications?']","['The clarity of the methodology could be improved, as some concepts might confuse the reader.', 'The experimental results may not be sufficient to make strong claims about the effectiveness of TCLP over all existing methods.']",False,2,2,3,5,4,"['Addresses an important problem in time-series active learning, specifically the sparsity of labeled data.', 'Introduces the novel concept of using temporal coherence for label propagation, which has potential practical applications.', 'Demonstrates substantial performance improvements in classification accuracy compared to baseline methods.']","['The explanations of the methods, especially regarding the plateau model and its fitting, are not sufficiently clear.', 'The experimental validation lacks depth; comparisons with existing methods are limited, and specific details on implementation are absent.', 'The writing is occasionally convoluted, making it difficult to follow the logical flow of the proposed methods and results.']",3,2,2,3,Reject
wu5yYUutDGW,The paper proposes a Boundary-aware Self-Supervised Learning (BaSSL) framework for video scene segmentation that leverages pseudo-boundaries derived from shot sequences. It introduces three novel pretext tasks focusing on maximizing intra-scene similarity and inter-scene discrimination. The authors claim to achieve state-of-the-art performance on the MovieNet-SSeg benchmark and emphasize the importance of contextual representation learning.,"['Could the authors provide more clarity on how the pseudo-boundary is determined and its implications on the performance?', 'What specific advantages do the proposed pretext tasks have over standard contrastive or supervised learning methods?', 'Can the authors clarify the role of each of the proposed pretext tasks in the overall performance improvement?']","['The paper does not sufficiently address the potential limitations of using pseudo-boundaries, such as how noise in the data could affect performance.', 'The lack of clarity in the presentation may lead to misunderstandings about the contributions and underlying mechanisms of the proposed approach.']",False,2,2,3,5,4,"['Addresses an important task in video understanding.', 'Introduces the concept of leveraging pseudo-boundaries for self-supervised learning.', 'Achieves promising results on a relevant benchmark dataset.', 'The proposed framework has potential applications in various video analysis tasks, enhancing its significance.']","['The novelty of the proposed boundary-aware pretext tasks is unclear and lacks sufficient theoretical justification.', 'The methodology section is overly convoluted and difficult to follow, which may hinder understanding.', 'The comparison with existing methods is insufficient, making it hard to assess the true impact of the proposed approach.', 'The reported results may not convincingly demonstrate a significant advantage over existing methods, particularly in practical applications.']",3,2,2,4,Reject
qyzTEWWM0Pp,"The paper proposes Multiresolution Equivariant Graph Variational Autoencoders (MGVAE), a framework for learning and generating graphs in a multiresolution manner using higher order message passing. It claims to achieve competitive results in various graph generative tasks, including molecular generation and link prediction.","['Can the authors clarify the technical details of the higher-order message passing and its integration with MGVAE?', 'Could the authors provide more qualitative results and comparisons to existing methods?', 'What is the rationale behind the choice of hyperparameters in the experiments?']","['The clarity of explanations requires significant improvement.', 'The paper lacks thorough experimental validation against state-of-the-art methods.']",False,2,2,2,4,4,"['Addresses the important problem of graph generation through a novel multiresolution framework.', 'Introduces higher-order message passing, which enhances the ability to capture complex graph structures.', 'Demonstrates competitive performance on several benchmarks, indicating the potential of MGVAE.']","['Presentation is convoluted, with many sections lacking clarity, particularly in the technical details.', 'Methodology lacks sufficient detail, making it difficult for readers to fully grasp the implementation of higher-order message passing.', 'Limited comparisons with existing state-of-the-art methods, which diminishes the demonstrated impact of the contributions.', 'Minimal qualitative results; additional visual examples would strengthen the evaluation.']",3,2,2,4,Reject
ks_uMcTPyW4,"The paper proposes a model-based reinforcement learning framework that incorporates active feature acquisition to address the exploration-exploitation dilemma in partially observable environments. It presents a sequential variational autoencoder for learning representations from partially observed states, aiming to enhance cost efficiency in information acquisition, particularly in healthcare. The method is evaluated in a control domain and a medical simulator, showing improvements over conventional baselines.","['Can the authors clarify the integration of the sequential VAE with the reinforcement learning policies?', 'What are the potential limitations of applying the proposed method in real-world applications, especially in high-risk domains?', 'Can the authors provide more detail on the experimental setup, including how the data was collected and the specific metrics used for evaluation?']","['The clarity of the overall methodology could hinder reproducibility and understanding.', 'The paper does not sufficiently explore the ethical implications of applying this framework in sensitive fields like healthcare.', ""The experimental results are limited to specific scenarios, which may not provide a comprehensive view of the method's effectiveness.""]",True,3,4,3,4,4,"['Addresses a significant challenge in reinforcement learning: active feature acquisition in partially observable environments.', 'Introduces a sequential variational autoencoder to learn high-quality representations, which is a novel contribution.', 'Demonstrates empirical results that show the proposed method outperforms conventional baselines in both control and medical domains.']","['The methodology is not clearly articulated, particularly in how the sequential VAE integrates with the reinforcement learning components.', 'Lacks in-depth exploration of the implications and limitations of the proposed approach in real-world scenarios, especially in high-risk domains like healthcare.', 'The paper does not sufficiently address how the chosen model dynamics affect the performance of the policy training.']",3,3,4,3,Reject
qEGBB9YB31,"The paper introduces a novel approach to explainable AI by developing parameter-space saliency maps that analyze neural network parameters responsible for misclassifications, contrasting conventional input saliency maps. The authors validate their method through experiments demonstrating improved predictions when salient parameters are turned off, as well as the semantic similarity of misclassified samples.","['Can the authors provide additional clarifications on the methodology used for generating parameter saliency maps?', ""What specific ablation studies could enhance the validation of the parameters' importance in misclassifications?"", 'Can the authors elaborate on why they believe parameter saliency is a more effective measure than traditional input-space saliency methods?']","[""The clarity of the methodology and overall presentation of results need improvement to enhance the paper's impact."", 'More robust experiments would help validate the findings and improve confidence in the proposed method.', 'The implications of the findings could be explored further, especially how they can be applied in real-world scenarios.']",False,3,2,3,5,4,"['The paper tackles an important issue in explainable AI by shifting focus from input saliency to parameter saliency.', 'Experiments provide validation of the proposed method, showing improvements in prediction accuracy when salient parameters are manipulated.', 'The introduction of an input-space saliency counterpart is an interesting addition, linking input features to specific network components.']","['The presentation lacks clarity in describing the methodology, making it difficult for readers to fully understand the approach.', 'Some experiments could be more robust; for instance, additional ablation studies could provide deeper insights.', 'The relationship between parameter saliency and misclassification could be explored in greater detail to strengthen the argument.']",3,2,2,4,Reject
eqaxDZg4MHw,"The paper investigates the generalization gap in deep reinforcement learning (RL) through a large-scale empirical study using procedurally generated video games. It identifies limitations in current methods and proposes that simple auxiliary tasks can enhance generalization. The findings suggest that adapting to new levels does not necessitate fine-tuning all layers of the policy network, indicating potential improvements in transfer learning within RL.","['Can the authors clarify the methodology used for the auxiliary tasks and the selection process for data augmentation?', 'Could the authors provide more detailed descriptions of the experimental setups and how they ensure reproducibility?']","['The paper does not sufficiently address potential negative impacts of the proposed methods.', 'A more thorough explanation of the implications of the findings for future research in the field is needed.']",False,3,3,3,5,4,"['Addresses a critical issue in deep reinforcement learning regarding the generalization gap.', 'Provides empirical findings based on a comprehensive analysis of various RL approaches across multiple procedurally generated games.', 'Suggests practical improvements, such as the use of auxiliary tasks and refined data augmentation strategies, to enhance policy generalization.']","[""The paper's structure can be unclear at times, making it challenging to follow the progression of ideas and findings."", 'Some sections lack depth and could benefit from additional detail, particularly regarding methodology and experimental setup.', 'Experimental results could be presented more accessibly; clearer visual aids and explanations would enhance understanding.']",3,3,3,4,Reject
hyuacPZQFb0,"The paper proposes ADATIME, a systematic evaluation framework for domain adaptation algorithms focused on time series data. It addresses inconsistencies in evaluation schemes, datasets, and model selection practices, and conducts extensive experiments comparing various state-of-the-art methods. The findings suggest that visual domain adaptation methods can perform competitively with methods specifically designed for time series data.","['Can the authors elaborate on the unique contributions of this work compared to existing evaluations in the field?', 'How do the findings generalize to other domain adaptation scenarios outside of time series data?', 'Could the authors provide more clarity on the experimental setup, particularly how hyper-parameters were tuned?']","['The reliance on existing visual domain adaptation methods may limit the perceived originality of the contribution.', 'The clarity of the presented results and methodology could be improved for better understanding.']",False,3,2,3,5,4,"['Addresses a significant gap in the evaluation of domain adaptation for time series data, which is crucial for practical applications.', 'Proposes a structured approach to evaluate domain adaptation methods, ensuring fair and consistent evaluation across different algorithms.', 'Includes extensive experiments across multiple datasets, providing valuable insights into the performance of various adaptation methods.']","['The novelty of the proposed framework is somewhat limited as benchmarking suites are common in machine learning, and the paper does not present significant new methodologies.', 'The analysis of results lacks depth; some findings are presented without thorough discussion or context, which could mislead readers.', 'Clarity issues exist in the presentation of results; the metrics and their interpretations are not adequately explained, making it difficult for readers to grasp the implications.']",3,3,2,4,Reject
RjMtFbmETG,"The paper introduces 'resmax', a new soft-greedy operator for reinforcement learning that aims to improve exploration by focusing on the suboptimality gap of actions. It claims to overcome limitations of ε-greedy and softmax while maintaining state-space coverage. Experiments suggest that resmax performs comparably or better than these traditional methods in various environments.","['Can the authors provide more detailed comparisons against other exploration strategies?', 'What are the theoretical guarantees for resmax in more complex environments?']","['The paper does not sufficiently address the potential limitations or edge cases of the resmax operator.', 'The clarity issues in the writing could hinder reader comprehension and reproduction of results.']",False,3,3,3,6,4,"['The concept of resmax is an interesting approach to improve exploration in reinforcement learning.', 'The paper addresses known limitations of ε-greedy and softmax operators.', 'Empirical results show that resmax performs well in certain environments, demonstrating its potential.']","['The paper lacks clarity in the presentation; the explanations of the resmax operator and its advantages over existing methods could be more detailed.', 'Empirical results are not robust, with limited environments tested and insufficient comparative analysis against a wider range of baselines.', 'The novelty of the proposed operator is questionable, as it is based on existing ideas and only offers a slight modification.']",3,3,3,4,Reject
UgNQM-LcVpN,"The paper proposes a novel modulating fully connected layer (MFCL) for neural networks, aimed at improving robustness against data quality issues such as missing data. Inspired by biological neuromodulation, the MFCL adjusts its weights based on the reliability of inputs, allowing for better handling of missing or noisy data. The authors present experiments across classification, regression, and imputation tasks, showing that their approach can improve performance in challenging real-world scenarios.","['Could you clarify the modulation mechanism and provide more detailed explanations of the architecture?', 'How do your results compare with the state-of-the-art methods in a more rigorous manner?', 'Can the authors provide a more detailed analysis of the experimental results and how MFCL compares to existing methods in various scenarios?']","['The paper does not fully address the computational complexity introduced by the modulation layers, which could be a limitation in resource-constrained environments.', 'The clarity of the presentation could be improved, particularly in explaining the architecture and experimental setup.']",False,2,2,3,4,4,"['Addresses a significant problem in machine learning related to data quality, particularly in critical domains like healthcare.', 'The modulation mechanism is inspired by biological systems, offering a novel perspective on weight adjustment in neural networks.', 'Demonstrates promising results across multiple tasks, suggesting practical applicability.']","['The methodology lacks clarity and detail, making it difficult to fully understand the proposed mechanisms and their implementation.', 'Experimental results need more consistency and robustness across various conditions to substantiate the claims of improvement over existing methods.', 'The paper could benefit from clearer explanations of the architectures used and how they integrate with the modulation mechanism.', 'Insufficient analysis of the performance differences between MFCL and existing imputation methods, leaving questions about the advantages of the proposed approach.']",3,3,2,4,Reject
kcrIligNnl,"The paper proposes a novel method for molecular conformation generation that directly outputs atomic coordinates, utilizing a variational auto-encoder framework and a roto-translation invariant loss function. The method demonstrates strong performance on benchmark datasets, outperforming several baselines.","['Can the authors clarify the implementation details of the model architecture, particularly for the encoder and decoder modules?', 'Could the authors provide more insights into the failure cases observed in the results?', 'Will the authors consider conducting more comprehensive ablation studies to better illustrate the contributions of various model components?']","['Clarity issues in methodology could hinder reproducibility.', 'The limited scope of the ablation studies raises concerns about the robustness of the proposed method.']",False,3,3,3,5,4,"['The direct generation of atomic coordinates is a novel approach that addresses limitations of distance-based methods.', 'The use of a variational auto-encoder framework allows for diverse conformation generation.', 'The proposed loss function being invariant to roto-translation is a significant improvement for the problem.', 'Empirical results demonstrate state-of-the-art performance on various datasets, indicating the effectiveness of the proposed method.']","['The paper lacks clarity in explaining the model architecture and the workflow, making it difficult to follow.', ""Insufficient details about the loss functions and how they are implemented could lead to confusion regarding their impact on the model's performance."", 'The experimental evaluation does not sufficiently compare the proposed method against all relevant baselines, especially regarding the implications of the results.', 'The paper does not adequately discuss potential limitations or edge cases where the model might fail.']",3,3,3,4,Reject
Ub1BQTKiwqg,"This paper proposes a new method for training sparse neural networks using a soft-thresholding approach for weight management. The authors claim that this method allows for better performance with fewer training cycles compared to existing methods. They provide experimental results to support their claims, particularly in terms of accuracy and sparsity.","['Can the authors provide a detailed theoretical justification for the use of soft-thresholding in their method?', 'What specific baseline methods were compared in the experiments, and how do the results compare in a broader context?', ""Could the presentation be enhanced to offer clearer explanations of the proposed method's mechanics?""]","['The theoretical justification and comparisons to existing methods are not sufficiently developed.', 'The experiments may not cover all relevant aspects needed to validate the proposed approach.']",False,2,2,2,4,4,"['The concept of using soft-thresholding for weight management is novel and could improve training efficiency for sparse neural networks.', 'The paper addresses an important problem in the field of deep learning related to model sparsity and training efficiency.', 'Experimental results show competitive accuracy levels at high sparsity rates, which is promising.']","['The paper lacks a rigorous theoretical foundation for the proposed method, which would help in understanding why it works.', 'The experimental evaluation is not comprehensive enough to fully support the claims made; additional comparisons to baseline methods are needed.', 'The clarity of the writing could be improved, especially in explaining how the proposed method functions and how it differs from existing approaches.']",3,2,2,3,Reject
BRFWxcZfAdC,"This paper explores lossy compression under distribution shifts, proposing a framework that generalizes optimal transport with an entropy constraint. The authors derive trade-offs between compression rate and distortion, particularly emphasizing the role of shared randomness. Through theoretical analysis and experimental validation on image denoising and super-resolution tasks, they demonstrate how their framework leads to improved performance compared to traditional approaches.","['Can the authors elaborate on how the theoretical results directly translate to improvements in practical applications?', 'What are the specific advantages of using common randomness in this context compared to existing methods?', 'Could the authors clarify the organization of the theoretical results and improve the exposition?']","['The paper could include more extensive experimental comparisons with existing lossy compression methods to provide a clearer context of its contributions.', 'The clarity of the presented theoretical results could be improved, which may hinder understanding and further application by the community.']",False,3,2,3,5,4,"['The theoretical formulation is well-developed and provides a comprehensive overview of the trade-off between compression rates and distortion.', 'The incorporation of common randomness into the compression process is a novel contribution that enhances the performance of the proposed methods.', 'Experimental results indicate that the proposed approach is effective in practical scenarios, particularly in image restoration tasks.']","['The presentation lacks clarity, making it difficult for readers to follow the theoretical development and its implications for practice.', 'The experimental validation is somewhat limited; more extensive comparisons with state-of-the-art methods would strengthen the claims made.', 'Some theoretical results are not sufficiently connected to the practical outcomes, leading to potential confusion about their significance.']",3,3,2,4,Reject
_ixHFNR-FZ,"The paper investigates the relationship between adversarial robustness and domain transferability in machine learning, proposing a theoretical framework that defines sufficient conditions for transferability. It argues that robustness is not the cause of transferability but a by-product of regularization, supported by empirical experiments on various datasets.","['Can the authors clarify the assumptions made in their theoretical framework?', 'What is the justification for the choice of datasets and methods used in the empirical experiments?', 'How do the authors plan to enhance the clarity of the theoretical explanations?']","['The theoretical framework needs a more rigorous formulation and clearer exposition.', 'Empirical experiments lack depth and may not fully validate the theoretical claims.', 'The implications of the findings on practical applications or future research directions are not clearly articulated.']",False,3,2,3,5,4,"['Addresses a significant issue in machine learning regarding the correlation between robustness and transferability.', 'Proposes a theoretical framework to understand sufficient conditions for domain transferability.', 'Includes a variety of experiments and examples to illustrate the findings.']","['The theoretical contributions lack rigor and may not be sufficiently novel compared to existing literature.', 'The presentation of the theoretical framework is convoluted and may confuse readers.', 'Empirical results do not convincingly demonstrate the claims regarding the negative correlation between robustness and transferability.', 'The paper would benefit from clearer explanations and more detailed discussions of the results.']",3,3,2,4,Reject
C4o-EEUx-6,"The paper presents Flashlight, an open-source library aimed at enhancing innovation in machine learning tools and systems. It focuses on a modular and customizable architecture to facilitate rapid prototyping and experimentation, particularly for systems researchers. Flashlight seeks to compete with established frameworks like PyTorch and TensorFlow, offering lower binary size and faster compile times.","['Can the authors provide more extensive empirical evaluations to support their claims?', 'How does Flashlight compare with specific features of leading frameworks like TensorFlow and PyTorch?', 'What specific use cases do the authors envision for Flashlight in machine learning research?']","['The paper does not fully address how Flashlight handles unconventional approaches or integrates with existing frameworks.', 'Lacks clarity in explaining practical use cases and advantages of Flashlight.']",False,2,3,2,5,3,"['Addresses the important issue of framework innovation in machine learning.', 'Provides a modular and customizable architecture that can benefit systems researchers.', 'Offers a strategy to reduce the engineering burden for researchers.']","['Lacks comprehensive empirical validation; the experiments are limited in scope.', 'The significance of contributions is not sufficiently demonstrated through results.', 'Clarity issues arise from technical jargon and convoluted explanations.', 'Comparison with existing frameworks lacks depth.']",3,2,3,3,Reject
TBWA6PLJZQm,"The paper introduces two benchmark datasets, CIFAR-10N and CIFAR-100N, which contain human-annotated noisy labels for CIFAR-10 and CIFAR-100, addressing the limitations of existing noisy label datasets. It analyzes the characteristics of real-world label noise and compares various methods on these datasets, highlighting the challenges posed by human annotations compared to synthetic noise.","['Can the authors provide more detailed comparisons of existing noisy label methods on the introduced datasets to better contextualize their findings?', 'What steps can be taken to improve the clarity of the paper, particularly in the presentation of experimental results?']","['The paper does not adequately address potential limitations of the datasets, including the challenge of generalizing findings from a potentially biased sample of human annotators.']",False,3,3,3,6,4,"['The introduction of CIFAR-10N and CIFAR-100N provides a valuable resource for the research community, facilitating studies on learning with noisy labels.', 'The paper identifies and discusses the differences between human-annotated and synthetic label noise, which is crucial for advancing the understanding of label noise in practical scenarios.', 'The detailed collection procedure of the datasets is well-documented, providing transparency on how the noisy labels were generated.']","['The paper lacks clarity in several sections, making it difficult to follow the reasoning and conclusions drawn from the experiments.', 'The experimental evaluation seems limited, as it does not thoroughly explore the performance of existing methods on the new datasets, potentially missing out on valuable comparative insights.', 'The novelty of the contributions is questionable, as the paper does not sufficiently differentiate its findings from prior work in the field.']",3,3,3,4,Reject
6u6N8WWwYSM,"The paper introduces ReCo, a contrastive learning framework designed to improve semantic segmentation by focusing on hard negative pixels and leveraging unlabelled data. It demonstrates strong results, particularly in semi-supervised settings, achieving high-quality segmentation with minimal labelled examples.","['Can the authors provide a more detailed explanation of the memory footprint and computational efficiency of ReCo compared to other methods?', 'Will the authors conduct more comprehensive ablation studies to clarify the impact of different components of the ReCo framework?', 'Can the authors clarify how ReCo differentiates itself from existing methods in terms of novelty?', 'Could additional ablation studies be included to further validate specific claims?']","[""The clarity of the paper is a major concern, particularly in explaining the framework's integration with existing segmentation models."", ""The lack of thorough hyperparameter analysis limits the understanding of ReCo's robustness and generalizability."", 'The paper does not sufficiently address potential limitations of the approach, particularly in cases where the assumptions about class relationships may not hold.']",False,3,2,3,5,4,"['ReCo effectively addresses the challenge of semantic segmentation, especially with limited labelled data.', 'The focus on hard negative pixels and adaptive sampling strategies is innovative and aligns well with semi-supervised learning goals.', ""Experimental results show consistent performance improvements across various settings and datasets, highlighting the framework's potential.""]","['The paper lacks clarity in its presentation, making it difficult to follow the methodology and understand how ReCo integrates with existing frameworks.', 'Insufficient detail is provided on the computational efficiency and memory requirements of the proposed method compared to existing techniques.', 'Limited ablation studies are presented to explore the impact of different components and hyperparameters of ReCo, which is crucial for validating its effectiveness.', 'The novelty of the ReCo approach compared to existing contrastive learning methods is not clearly articulated.']",3,3,2,4,Reject
t5s-hd1bqLk,The paper introduces a novel approach for conditioning sequence-to-sequence models by learning activation functions based on a conditioning vector. This method aims to reduce model size while maintaining or improving performance in personalized sound enhancement and automatic speech recognition tasks.,"['Can the authors provide more insight into the theoretical implications of using learned activation functions for conditioning?', 'How does the proposed architecture compare with existing methods beyond just performance metrics?', 'Could the authors clarify their explanations of the experimental results, particularly the variations observed across tasks?']","['The paper does not adequately address the limitations of the proposed method, particularly regarding generalizability and potential negative impacts.']",False,3,3,4,6,4,"['The approach effectively addresses the challenge of model size in neural networks by learning activation functions, which can lead to more efficient implementations.', 'Experimental results show that the proposed method achieves competitive performance compared to traditional concatenation and modulation techniques.', 'The focus on personalized sound enhancement and automatic speech recognition is relevant and timely.']","['The theoretical basis for learning activation functions in this context is not well-explained, leaving some foundational questions unanswered.', 'The presentation of results could be clearer, making it challenging to fully assess the significance of the findings.', 'The related work section lacks depth, which raises concerns about the originality and context of the contributions.', 'The paper does not sufficiently discuss the limitations of the proposed method or potential negative societal impacts.']",4,3,3,4,Reject
1L0C5ROtFp,"The paper proposes a method for unsupervised learning of counterfactual reasoning in pixel space, focusing on predicting the outcomes of interventions in physical processes using a hybrid latent representation. It introduces a new benchmark dataset for this task and claims improvements over existing baselines.","['Can the authors clarify the methodology used to evaluate the counterfactual predictions?', 'Could more details on the experimental setup and hyperparameters be provided to enhance reproducibility?', 'What specific ablation studies were conducted to validate the claims of improvement?']","['The paper could benefit from clearer explanations and organization to enhance reader understanding.', 'More rigorous evaluations and comparisons with recent literature would strengthen the claims made regarding performance.', 'The paper does not adequately address the limitations of the proposed model and its performance on varied datasets.']",False,2,2,3,4,4,"['Addresses a relevant and challenging problem in causal reasoning and long-term video prediction.', 'The introduction of a new benchmark dataset for counterfactual reasoning is a valuable contribution.', 'The proposed hybrid latent representation is an interesting approach that could potentially improve model performance.']","['The paper lacks clarity in the presentation of the methodology, making it difficult to follow the proposed approach.', 'The organization of the paper could be improved, as some sections feel disconnected and lack coherence.', 'Details in experimental setups, such as hyperparameters and evaluation metrics, are not sufficiently elaborated.', 'The claim of outperforming strong baselines is not supported by comprehensive comparisons, and it is unclear how novel the contributions are relative to existing work.']",3,2,2,4,Reject
ZFIT_sGjPJ,"The paper proposes a novel data-dependent approach to Gaussian randomized smoothing aimed at enhancing the certified robustness of deep neural networks. By optimizing the variance of the Gaussian distribution based on input data, the authors claim to improve the certification radius and certified accuracy on datasets like CIFAR10 and ImageNet. The method integrates with existing frameworks and shows significant empirical improvements.","['Can the authors clarify the theoretical guarantees for the memory-enhanced certification process?', 'What specific challenges did the authors face when integrating the data-dependent variance into existing models?']","['The paper does not adequately address the potential computational overhead introduced by the data-dependent smoothing.', 'The clarity of the proposed methodology and its theoretical underpinnings need to be strengthened.']",False,2,3,3,6,4,"['The data-dependent variance approach is innovative and addresses limitations in existing smoothing techniques.', 'The empirical results demonstrate substantial improvements in certified accuracy, indicating practical relevance.', 'The framework is adaptable and can be integrated into various existing randomized smoothing methods.']","['The paper lacks clarity in explaining the memory-enhanced certification process and its implications for soundness.', 'There is insufficient theoretical justification for the proposed method and its certification guarantees.', 'The experimental section could benefit from more comprehensive comparisons and detailed ablation studies to validate the proposed approach.']",3,3,3,4,Reject
uEBrNNEfceE,"This paper addresses the linear-quadratic dual control problem and proposes a safe learning scheme that guarantees almost sure convergence of parameter inference error and control performance. The authors introduce a switching strategy that combines a switched controller with parameter inference based on cross-correlation, ensuring safety during the learning process. The theoretical results are well-founded and align with optimal rates known in the literature, but the clarity and practical implications of the proposed approach remain ambiguous.","['Can the authors provide more clarity on the practical implications of their method and how it can be applied in real-world scenarios?', 'Could the authors simplify the presentation of their arguments and proofs to enhance reader understanding?']","['The clarity of the paper is a major concern, and simplifying complex arguments would help in comprehending the proposed methods.', 'More extensive experimental results, particularly in real-world applications, would strengthen the claims made.']",False,3,2,3,6,4,"['Addresses a significant problem in optimal control with a focus on safety and stability.', 'The proposed safe switched control strategy is innovative and offers a clear framework for ensuring bounded-cost safety.', 'The theoretical results regarding convergence rates are strong and provide a valuable contribution to the field.']","['The presentation of the algorithm and proofs is overly complex, making it challenging for readers to follow.', 'Experimental validation is limited to simulations, lacking extensive evaluation in real-world scenarios.', 'The clarity of some sections could be improved, particularly regarding the practical implications of the proposed method.']",3,3,2,4,Reject
JGO8CvG5S9,"The paper proposes a constrained universal approximation theorem for transformer networks, demonstrating that these networks can achieve universal approximation while satisfying convex and non-convex constraints. The main contributions include a probabilistic attention mechanism that manages constraint satisfaction and a deep neural version of Berge's Maximum Theorem.","['What empirical studies are planned to validate the theoretical results presented in the paper?', 'Could the authors elaborate on the probabilistic attention mechanism and its implementation in practical scenarios?']","['The lack of experimental results is a major limitation, as theoretical findings need to be supported by practical applications to be fully validated.', 'The paper does not sufficiently address the practical implementation of the proposed methods in typical machine learning tasks.']",False,3,3,4,6,4,"['The theoretical contributions are significant and address an important problem in deep learning related to constraint satisfaction.', 'The introduction of a probabilistic attention mechanism is novel and offers a fresh perspective on managing constraints within transformer networks.', 'The paper rigorously establishes conditions under which universal approximation is possible in the presence of constraints.']","['The paper lacks empirical validation of the theoretical claims, which is crucial for understanding the practical applicability of the proposed methods.', 'The mathematical formalism is dense and may not be accessible to all readers, potentially limiting the impact of the work.', ""More clarity in presentation and explanation of key concepts could enhance the paper's readability.""]",4,3,3,4,Reject
IEsx-jwFk3g,"The paper presents ReBraiD, a graph neural network model designed to analyze dynamic brain activities by integrating fMRI and DWI data. It introduces novel techniques such as adaptive adjacency matrix learning and multi-resolution smoothing to capture latent brain dynamics. While the approach is relevant and timely, the paper suffers from clarity issues and lacks robust evaluations to substantiate its claims.","['Can the authors clarify how the adaptive adjacency matrix is generated and its implications on model performance?', 'What specific contributions does ReBraiD make compared to existing GNN models beyond performance metrics?', 'Could the authors provide additional examples or case studies to illustrate the interpretability of the results?']","['The potential for overfitting given the relatively small dataset size could limit generalizability.', 'The clarity of the model architecture and its components needs improvement for better understanding.']",False,2,2,2,4,4,"['The integration of fMRI and DWI data represents a significant advancement in neuroscience research.', 'The model introduces innovative concepts like adaptive adjacency matrix learning and multi-resolution smoothing, enhancing the understanding of brain dynamics.', ""Extensive experiments and ablation studies demonstrate the model's effectiveness across various tasks.""]","['The methodology lacks clarity, making it difficult to follow the model design and implementation details.', 'The originality of the approach is questionable, as it does not sufficiently differentiate itself from existing graph neural network techniques.', 'Evaluation metrics and comparisons with existing methods are inadequate, raising concerns about the robustness and generalizability of the results.', 'The paper does not adequately address its limitations or potential biases in the data used.']",2,2,2,3,Reject
WLEx3Jo4QaB,The paper proposes a framework for graph condensation aimed at reducing the size of large graphs while maintaining performance in Graph Neural Networks (GNNs). It utilizes a gradient matching loss to optimize the condensation process and presents experimental results across various datasets.,"['Can the authors clarify the optimization process used in graph condensation and provide more intuitive explanations for the key steps?', 'What limitations does the proposed method have regarding different types of graphs or tasks, and how might these be addressed in future work?']","['The paper does not adequately explain the implications of graph condensation on various GNN architectures.', 'A broader evaluation against more state-of-the-art methods is needed to validate the effectiveness of the proposed approach.']",False,3,2,3,5,4,"['Addresses a significant challenge in GNNs related to large-scale graph training.', 'Introduces a novel method for graph condensation that effectively combines node feature and graph structure optimization.', 'Demonstrates strong experimental results across multiple datasets, achieving substantial reductions in graph sizes while maintaining performance.']","['The methodology lacks clarity, making it difficult for readers to fully grasp the proposed graph condensation approach.', 'The organization of the presentation could be improved; key concepts are not clearly defined, which may lead to confusion.', 'The discussion on limitations and potential drawbacks of the proposed method is insufficient.']",3,3,2,4,Reject
8Wdj6IJsSyJ,"The paper proposes a fully differentiable model discovery approach by integrating Sparse Bayesian Learning (SBL) with Physics Informed Neural Networks (PINNs). It aims to automate the discovery of differential equations from datasets while maintaining differentiability in the variable selection process. The authors showcase their method through various experiments, including a proof-of-concept with Physics Informed Normalizing Flows (PINF).","['Can the authors clarify how their approach significantly improves upon existing methods like DeepMoD in practical applications?', 'What specific metrics were used to evaluate the performance of the proposed method against state-of-the-art techniques?']","['The complexity of the paper and presentation style may hinder understanding of the proposed methods.', 'The significance of the results compared to existing methods needs more thorough discussion.']",False,3,2,3,5,4,"['The integration of SBL with PINNs is a novel approach that enhances model discovery by enabling differentiable variable selection.', 'The authors provide a thorough overview of the background and existing methods, effectively situating their contributions within the broader context of model discovery.', ""The experimental results demonstrate the proposed method's capability to discover governing equations from noisy data, showcasing its practical applicability.""]","[""The paper's complexity and verbosity may hinder reader comprehension of the main contributions and methodologies."", 'The clarity regarding how the proposed method outperforms existing techniques is insufficient; specific performance improvements relative to state-of-the-art methods need clearer articulation, particularly in the results section.', 'The experimental validation could be more robust, with additional datasets or comparisons to a wider range of baseline methods to strengthen the claims.']",3,3,2,3,Reject
UJ9_wmscwk,"The paper presents GLIE, a Graph Neural Network designed for influence estimation and maximization in large graphs. It claims to outperform existing methods in terms of accuracy and efficiency, particularly in handling larger graphs than those used for training. The methodology involves integrating GLIE with traditional optimization methods and presents experimental results comparing GLIE to state-of-the-art methods.","['How does the proposed GLIE fundamentally differ from existing GNN approaches in the context of influence maximization?', 'Can the authors clarify the training procedure for GLIE and how they ensure the generalization of their model to larger graphs?', 'What limitations or potential negative impacts could arise from the proposed methods?']","['The paper does not sufficiently address the limitations or potential societal impacts of using influence maximization methods in real-world scenarios.', 'The lack of clarity in the methodology makes it difficult to assess the reproducibility of results.']",True,2,2,2,4,4,"['Addresses a significant problem in network science: influence maximization in large networks.', 'The proposed method shows promising results in influence estimation and maximization, outperforming existing benchmarks.', 'The experiments include a variety of real-world datasets and demonstrate the effectiveness of the proposed approach.']","['The originality of the work is questionable as it builds heavily on existing methodologies without introducing substantial new concepts.', 'The clarity of the presentation is lacking; some sections are overly complex and difficult to follow.', 'The experimental evaluation, while comprehensive, lacks clarity in the results presentation and a detailed analysis of the results.', 'The methodology section lacks sufficient detail regarding the implementation of GLIE and its training process, making it challenging to reproduce the results.', 'There is insufficient exploration of the impact of different model configurations and hyperparameters on the overall performance.']",3,2,2,4,Reject
d2XZsOT-_U_,"This paper proposes a Transformer-based model for predicting outcomes of pairwise competitions by representing players through their historical match data instead of traditional scalar skill ratings. The model claims to improve predictions for new players and incorporates contextual information such as home-field advantage, showing better performance than traditional methods like Elo and Glicko across datasets from Chess, Baseball, and Ice Hockey.","['Can the authors clarify the methodology in more detail?', 'What specific aspects of the performance metrics support the claims of significant improvements?', 'Could the authors provide more robust comparative analysis with existing methods?', 'Can you clarify how the proposed model can be extended to multi-player settings?']","['The paper lacks a thorough examination of the limitations of the proposed model, particularly in practical applications.', 'Potential biases in the datasets used for evaluation are not discussed.', 'The significance of the results may be diminished by the lack of evaluations in varied contexts and with different types of data.']",False,2,2,3,5,4,"['Addresses important limitations of traditional ranking systems by using historical data for player representation.', 'Demonstrates the ability to predict outcomes for players with limited historical data.', 'Utilizes a modern architecture (Transformers) which is relevant in the current research landscape.', 'Experimental results indicate significant performance improvements over traditional methods.']","['The methodology is not clearly articulated, making it difficult to understand how the model operates.', 'Insufficient comparative analysis with existing methods, particularly in terms of explaining why the proposed method outperforms traditional systems.', 'The experiments lack robustness; more datasets or variations in the experimental setup could strengthen the findings.', 'The claims regarding performance improvements over traditional methods are not adequately supported by detailed statistical analysis.', 'The paper lacks clarity in the explanation of the model architecture and the transformation process of player histories.']",3,2,2,4,Reject
HHpWuWayMo,"The paper proposes a model-based approach (cMBA) for adversarial attacks in cooperative multi-agent reinforcement learning (c-MARL) systems, focusing on generating perturbations to misguide agents in continuous action spaces. The method is validated through experiments in multi-agent Mujoco tasks, showing effectiveness against baseline methods.","['How does the proposed method compare with more recent developments in adversarial attacks in MARL?', 'Can the authors provide more insights into the limitations of their approach and scenarios where it may fail?', 'Could the authors clarify the training procedure for the dynamics model and its impact on the attack performance?']","['The paper does not adequately address the broader implications of the proposed attacks in real-world multi-agent systems.', 'Lack of clarity in the description of algorithms and the mathematics involved may lead to misunderstandings.']",False,2,2,3,5,4,"['Addresses a relevant and timely challenge in multi-agent reinforcement learning: robustness against adversarial attacks.', 'Introduces a novel model-based framework that extends existing work on adversarial attacks to multi-agent contexts.', 'Demonstrates effectiveness through extensive numerical experiments, outperforming baseline methods.']","['Lacks clarity in writing, particularly in complex formulations and algorithm descriptions, hindering understanding.', 'Insufficient discussion of related work and how the proposed method compares to other adversarial strategies.', 'Experimental evaluation is limited to specific environments, lacking generality and diversity in scenarios.']",3,2,2,4,Reject
WPI2vbkAl3Q,The paper investigates the influence of data structure on the performance of stochastic gradient descent (SGD) through a theoretical framework that predicts test loss dynamics based on feature covariance structures. It validates its findings with experiments on datasets like MNIST and CIFAR-10.,"['Can the authors clarify how their work differs from prior studies on SGD dynamics?', 'What additional experiments can be conducted to strengthen the empirical validation of the theoretical claims?']","['The complexity of the theoretical framework may deter some readers.', 'Further validation on a broader set of tasks and architectures would strengthen the claims made.']",False,3,3,4,6,4,"['Addresses the significant issue of how data structure affects SGD performance.', 'Provides a theoretical framework that offers exact predictions for test loss dynamics.', 'Includes empirical validation on real datasets, which adds credibility to the theoretical claims.']","['The theoretical exposition is dense and may be challenging for some readers to follow.', 'Empirical results are somewhat limited in scope and could benefit from additional validation.', 'The practical implications of the findings could be explored in more depth.']",4,3,3,4,Reject
YZHES8wIdE,The paper proposes the Generative Planning Method (GPM) to improve exploration in reinforcement learning by generating multi-step action sequences. It aims to combine the strengths of model-free RL and planning methods to enhance exploration efficiency and interpretability.,"['Could you clarify the sections of the methodology that may be difficult to reproduce?', 'What specific metrics will you apply to further substantiate the performance of GPM in more complex environments?', 'Can the authors clarify how GPM distinguishes itself from similar methods in the existing literature?', 'What specific experiments or ablation studies can the authors conduct to strengthen their claims?']","['The paper does not sufficiently explore the implications of the proposed method beyond the benchmark tasks tested.', 'Potential issues with reproducibility due to lack of clarity in the methodology.', 'The complexity of the proposed method may hinder its adoption in practical RL applications.', 'The lack of a comprehensive evaluation against a wider range of baselines limits the claimed contributions.']",False,3,2,3,5,4,"['The idea of generating multi-step action sequences for exploration is a novel contribution to the field.', 'The potential for increased interpretability of the learned policies could benefit the application of RL methods in real-world scenarios.', 'The paper includes experiments on several benchmark environments which demonstrate the effectiveness of the proposed method.']","['The methodology lacks clarity in several sections, making it difficult to reproduce the results.', 'The experimental results are somewhat limited, focusing primarily on standard benchmarks without exploring more complex or realistic environments.', 'Connections to existing literature on planning and exploration in RL could be better articulated to highlight the novelty of the approach.', 'The performance improvements over baseline methods could be further substantiated with more comprehensive evaluations.']",4,3,2,3,Reject
o6dG7nVYDS,"The paper presents a novel learning-theoretic generalization bound for domain generalization (DG) that relates performance to model complexity through Rademacher complexity. It argues that the erratic performance of existing DG methods can be explained by this complexity-performance trade-off. The authors suggest that domain generalization can be effectively achieved through regularized empirical risk minimization (ERM) with a leave-one-domain-out cross-validation objective, and they provide empirical results to support their claims.","['Could the authors clarify how the proposed complexity metrics can be directly applied to current domain generalization methods?', 'What steps do the authors suggest for practitioners in implementing the findings of this study in their work?']","['The theoretical nature of the work may limit its practical appeal and application.', 'The reliance on linear models may not generalize to more complex architectures commonly used in practice.']",False,3,3,4,7,4,"['Theoretical contributions provide a solid foundation for understanding the performance variability in domain generalization methods.', 'Empirical results corroborate the theoretical claims, demonstrating a clear relationship between model complexity and performance.', 'The analysis encourages a shift towards more principled model selection strategies in the context of domain generalization.']","['The theoretical analysis may be too abstract for practitioners seeking immediate applications and concrete guidelines.', 'More extensive empirical validation across a wider range of datasets and model architectures could enhance the robustness of the findings.', 'The paper could benefit from clearer explanations of complex theoretical concepts and their implications for practical model development.']",4,3,3,4,Accept
dtYnHcmQKeM,"The paper proposes the Physics-Informed Neural Operator (PINO), a novel framework that integrates operator learning with physics-informed optimization techniques to solve partial differential equations (PDEs). The authors claim that PINO improves convergence rates and accuracy compared to existing methods like Physics-Informed Neural Networks (PINNs) and Fourier Neural Operators (FNOs). Experiments are presented to demonstrate the advantages of PINO across various PDE families.","['Can the authors provide more detailed descriptions of the training methodology and hyperparameter tuning for reproducibility?', 'How does PINO compare quantitatively against other methods on a wider range of PDE problems?', 'What steps can be taken to enhance the reproducibility of the experiments reported?']","['The clarity of the paper is a major concern, as several sections could benefit from more detailed explanations.', 'More transparency is needed in the experimental setup and comparison to existing methods.']",False,2,2,3,5,4,"['The integration of operator learning with physics-informed methods is innovative and addresses limitations of existing PDE solvers.', 'The proposed method shows promising results in solving complex PDEs, particularly in long temporal domains and chaotic scenarios.', 'The paper tackles an important problem in scientific computing, potentially advancing the state of the art.']","['The methodology lacks clarity and detail, making it difficult to fully understand how PINO operates and its specific advantages.', 'The experimental evaluation is insufficiently rigorous, with selective results and inadequate comparisons to other state-of-the-art methods.', 'There is a lack of transparency regarding hyperparameter tuning and the training process, impacting reproducibility.']",3,2,2,4,Reject
z8xVlqWwRrK,"The paper introduces EVaDE, a framework that enhances model-based reinforcement learning by using event-based variational distributions for exploration. The framework employs three types of layers that leverage Gaussian dropout to facilitate variational Thompson sampling, particularly in object-based domains. The authors demonstrate the effectiveness of EVaDE-SimPLe in a suite of Atari games, achieving higher performance than several baseline methods under restricted interaction conditions.","['Can the authors provide more details on the theoretical justification for the effectiveness of the EVaDE layers?', 'Would the authors consider additional ablation studies to clarify the individual contributions of the different layers?', 'Can the authors elaborate on the design choices behind the event-based convolutional layers?']","['The paper could improve clarity in presenting the methods, which may hinder understanding for readers not already familiar with the topic.', 'The theoretical contributions could be explored in greater depth to enhance the perceived significance of the findings.']",False,3,3,3,7,4,"['Addresses a significant challenge in model-based reinforcement learning related to exploration in object-based domains.', 'Presents a novel approach using event-based variational distributions that is both theoretically grounded and empirically validated.', 'Empirical results indicate substantial improvements over baseline methods in multiple Atari games, suggesting practical applicability.']","['The clarity of the presentation could be improved; some explanations of the proposed methods and their theoretical foundations need more detail.', 'Certain claims regarding the effectiveness of the event-based layers would benefit from additional analyses or ablation studies.', 'The introduction of concepts and terminology could be made more accessible to readers unfamiliar with variational inference or reinforcement learning.']",3,3,3,4,Reject
ODnCiZujily,"The paper proposes a novel operator splitting method for verifying deep neural networks against adversarial attacks. By solving convex relaxations through a splitting approach, it aims to improve the scalability of verification methods and demonstrates its effectiveness on large neural networks like ResNet and DQNs.","['Could the authors clarify the practical implications of their method in real-world scenarios?', 'What specific improvements in verification times do their results indicate over previous methods?', 'Can the authors clarify how their method significantly differs from existing operator splitting methods?', 'Could a more user-friendly explanation of the algorithm be provided to enhance understanding?']","['The lack of clarity and dense technical details may hinder understanding.', 'Need for more comprehensive experimental evaluations and comparisons.', 'The clarity of the algorithmic description and mathematical background may pose challenges for readers unfamiliar with operator splitting and ADMM.']",False,3,2,3,5,4,"['Addresses a critical issue in neural network robustness and verification.', 'Introduces a novel operator splitting approach, which has potential for scalability in large networks.', 'Demonstrates effectiveness through extensive experiments on realistic neural network architectures.']","['The clarity of presentation is poor, with dense technical material that may confuse readers.', 'Experimental results lack detailed explanations and comparisons to relevant baselines.', 'The practical impact of the method remains unclear; more real-world applicability examples would improve the paper.']",3,3,2,3,Reject
morSrUyWG26,"The paper presents AutoOED, an automated platform for optimizing multi-objective experimental designs using Bayesian optimization techniques. It introduces modular features, including a graphical user interface (GUI) for ease of use, asynchronous optimization strategies, and a novel method called Believer-Penalizer (BP) for efficiently conducting experiments. The authors validate the platform through various benchmark tests and real-world applications, claiming improvements in efficiency and usability for experimental design.","['Can the authors elaborate on the performance comparison of BP with existing asynchronous optimization strategies?', 'How do the authors plan to enhance the clarity and depth of the explanations regarding the interactions of various components in AutoOED?']","['The paper does not provide enough detail on the limitations of the proposed methods and potential pitfalls in practical applications.', 'There is insufficient discussion of the boundary conditions under which the platform operates effectively.']",False,2,2,3,5,4,"['The modular approach of AutoOED allows for easy integration of various optimization algorithms and provides flexibility for users.', 'The inclusion of a user-friendly GUI makes the platform accessible to non-experts in machine learning and optimization.', 'The platform is tested across multiple benchmark problems and includes real-world applications, demonstrating its practical utility.']","['The originality of the proposed Believer-Penalizer (BP) strategy is not thoroughly justified, as it does not provide enough comparisons with existing strategies, leading to potential claims of novelty being overstated.', 'The clarity of the paper could be improved, particularly in explaining how the components interact within the platform and the specific contributions of each module.', 'The experimental validation lacks depth; more comprehensive comparisons with existing platforms and algorithms are needed to substantiate claims of superiority.']",3,2,2,4,Reject
-TSe5o7STVR,"The paper proposes LaMer, a novel framework for text style transfer that leverages large-scale language models and scene graphs to mine roughly parallel expressions from non-parallel datasets. The method aims to enhance transfer accuracy, content preservation, and fluency across various tasks, including sentiment, formality, and a new political stance transfer task.","['Can the authors provide more details on the scene graph integration process and its impact on the mining of parallel sentences?', 'What measures are taken to address potential biases in the generated outputs, and how might these affect the usability of LaMer?']","['The paper does not adequately address the ethical considerations related to potential biases in language models and generated outputs.', 'Lack of clarity in the methodology may hinder reproducibility and understanding.']",True,3,3,3,6,4,"['Addresses a significant limitation in current text style transfer methods by effectively utilizing non-parallel datasets.', 'Introduces an innovative method for mining roughly parallel sentences using scene graphs.', 'Demonstrates empirical improvements across multiple benchmark tasks, indicating the effectiveness of the approach.']","['The methodology lacks clarity, particularly regarding the mining process and the integration of scene graphs.', 'Insufficient exploration of ethical implications and potential biases in the generated outputs.', 'The evaluation metrics could benefit from more comparative analysis with other state-of-the-art methods.']",3,3,3,4,Reject
i--G7mhB19P,"The paper investigates the inductive biases of natural gradient descent (NGD) compared to Euclidean gradient descent (EGD) in deep linear networks. It argues that while NGD is invariant to parameterization, this invariance may lead to poor generalization in certain cases, particularly in over-parameterized settings. The authors present theoretical findings and experimental results that illustrate situations where NGD fails to generalize effectively, unlike EGD with appropriate architecture.","['Can the authors provide additional experimental results on a wider range of architectures to demonstrate the generalizability of their findings?', 'What are the implications of this work for the design of practical optimization algorithms in deep learning?']","['The paper primarily focuses on linear models, which may limit the applicability of its findings to more complex neural network architectures.', 'The clarity issues throughout the paper detract from its overall impact.']",False,3,2,3,5,4,"['The paper addresses an important and relevant question regarding the role of parameterization in gradient-based learning and its implications for generalization.', 'It presents a solid theoretical foundation, supported by clear theorems and proofs, which enhance the understanding of NGD versus EGD.', 'The experiments are well-structured, demonstrating the claims made in the theoretical sections effectively.']","['The experimental validation is somewhat limited to specific scenarios (e.g., linear models, matrix factorization); broader testing across various architectures and datasets would strengthen the findings.', 'While the theoretical contributions are strong, the paper could benefit from a more explicit discussion on practical implications and potential applications of the findings.', 'The clarity in presenting some complex proofs could be improved for better accessibility to readers less familiar with the mathematical background.']",3,3,2,4,Reject
zyrhwrd9EYs,The paper addresses the significant issue of missing data in treatment effect estimation by introducing a new missingness mechanism termed Mixed Confounded Missingness (MCM) and proposing a selective imputation strategy. It argues that traditional imputation methods can lead to biased estimates and provides empirical evidence suggesting that selective imputation improves treatment effect estimation compared to naive methods.,"['Could the authors clarify how selective imputation is determined in practice?', 'What are the implications of MCM in real-world scenarios, and how does it compare to traditional methods across various fields?', 'Can the authors provide more empirical evidence or real-world examples to support the effectiveness of selective imputation?']","['The paper needs to address its clarity and organization issues to effectively communicate its contributions.', 'There may be limitations in the empirical studies that should be discussed, particularly regarding the generalizability of results.']",False,3,2,3,5,4,"['Addresses a critical problem in treatment effect estimation related to missing data, which is highly relevant in practical applications.', 'Introduces the novel concept of Mixed Confounded Missingness (MCM), providing a deeper understanding of how missing data can influence treatment selection and outcomes.', 'Empirical results demonstrate the effectiveness of selective imputation over naive methods, offering valuable insights for practitioners in causal inference.']","['The explanation of the MCM mechanism could benefit from more depth and clarity, making it challenging for readers to fully grasp its implications.', ""The paper's presentation is somewhat dense and complex, which may hinder the understanding of key concepts for a broader audience."", 'Empirical results are primarily based on synthetic datasets, which raises concerns about the generalizability of findings to real-world scenarios.']",3,3,2,4,Reject
NZQ8aTScT1-,"The paper proposes a theoretical framework to understand the learnability of neural networks based on their architecture, particularly focusing on how convolutional networks restructure eigenspaces compared to multilayer perceptrons. It introduces concepts of spatial and frequency indices as they relate to the architecture's ability to model various interactions.","['How do the authors plan to empirically validate the theoretical claims presented in the paper?', 'Can the authors clarify the practical implications of the proposed spatial and frequency indices?', 'Can the authors provide clearer examples or illustrations to demonstrate the key concepts?', 'What specific empirical results can support the claims made regarding the benefits of the proposed framework?']","['The theoretical contributions are not adequately supported by empirical data.', 'The organization of the paper complicates understanding, which may lead to misinterpretation of key points.', 'The paper does not adequately address the limitations of its theoretical claims or the potential for misinterpretation.', 'The lack of practical validation raises questions about the real-world applicability of its findings.']",False,2,2,2,4,4,"['Addresses a fundamental question in deep learning regarding the principles behind neural network success.', 'Introduces new theoretical concepts like spatial and frequency indices which could be valuable for future research.', 'The paper uses a variety of references to support its theoretical claims.']","['The clarity and organization of the paper are poor, making it difficult to follow the main arguments and contributions.', 'Lacks comprehensive empirical validation of the theoretical claims made, particularly in relation to different architectures.', 'The relationship to existing work and how this paper uniquely contributes to the field is not sufficiently articulated.', 'The theoretical concepts introduced need clearer definitions and examples to enhance understanding.']",3,2,2,3,Reject
IEKL-OihqX0,"This paper introduces RMwGGIS, a method for learning discrete energy-based models (EBMs) using ratio matching with gradient-guided importance sampling. The authors claim that their approach reduces computational complexity and memory usage compared to traditional methods while improving performance. The method is evaluated on synthetic datasets, graph generation, and Ising models, showing promising results.","['Can the authors clarify the rationale behind the choice of datasets used for experiments?', 'What measures were taken to ensure the robustness of the proposed method across different types of discrete data?', ""Could the authors provide additional experiments or analysis to further validate the claims regarding RMwGGIS's effectiveness?""]","['The lack of clarity in the presentation could hinder understanding and reproducibility.', 'The experimental section does not sufficiently demonstrate the robustness of RMwGGIS across various datasets and scenarios.']",False,3,2,3,5,4,"['The RMwGGIS method addresses significant computational challenges in learning EBMs on discrete data.', 'The theoretical foundation is well-articulated, providing a clear motivation for the proposed changes.', 'Experimental results indicate improvements in efficiency and performance over existing methods.']","['The clarity of the writing is poor, making it difficult to follow the methodology and results.', 'The experimental validation lacks diversity, primarily focusing on synthetic datasets without adequate real-world applications.', 'The paper does not sufficiently discuss the limitations of the proposed method or potential negative impacts.']",3,3,2,3,Reject
ZOcX-eybqoL,"The paper proposes a framework for lifelong reinforcement learning that leverages logical composition to enhance task generalization and skill transfer. It provides theoretical bounds on the performance of transferred policies and demonstrates its effectiveness through empirical experiments. However, clarity in presentation and depth of experimental validation are significant concerns.","['Can the authors provide more extensive experimental results, particularly in terms of the environment and task scenarios?', 'How does the proposed method compare quantitatively with existing state-of-the-art transfer learning methods?', 'Could the authors clarify the practical implications of their theoretical results in real-world applications?']","['The clarity of the presentation is a significant limitation that could hinder understanding and adoption of the proposed method.', 'The experimental design does not convincingly demonstrate the advantages of the proposed framework over existing techniques.']",False,2,2,3,5,4,"['Theoretical contributions provide solid bounds on the performance of transferred policies.', 'The integration of logical composition into lifelong reinforcement learning is a novel and relevant approach.', 'Empirical results show promising improvements in task performance and learning efficiency.']","['The paper lacks clarity in several sections, particularly in explaining the logical composition framework and its implications, which may confuse readers.', 'Experimental validation is limited in scope and does not sufficiently compare the proposed method with existing techniques, making it hard to assess its effectiveness.', ""The discussion of related work is insufficient, making it difficult to assess the paper's positioning within the current literature.""]",3,2,2,3,Reject
hUr6K4D9f7P,"The paper introduces Weighted Truncated Adversarial Weight Perturbation (WT-AWP) as a method to enhance generalization in Graph Neural Networks (GNNs). It identifies a vanishing gradient issue in existing Adversarial Weight Perturbation (AWP) methods and proposes WT-AWP to mitigate this problem. The paper includes theoretical analysis and empirical validation across various graph learning tasks, demonstrating improvements in both natural and robust generalization.","['Can the authors clarify the theoretical implications of their new generalization bound in comparison to existing ones?', 'What specific steps can be taken in future work to enhance the clarity and depth of the theoretical contributions presented in the paper?', 'Could the authors provide additional experiments or analyses to strengthen their claims about performance improvements across diverse datasets?', 'Can the authors clarify the reasoning behind the choice of perturbation strength and its impact on performance?']","['The paper lacks clarity in presenting its findings and theoretical contributions.', ""More ablation studies would strengthen the understanding of the proposed method's impact."", 'The clarity of the paper could be significantly improved, especially regarding the theoretical contributions.']",True,3,3,3,6,4,"['Addresses a critical problem in machine learning regarding generalization and robustness in GNNs.', 'Introduces WT-AWP, providing a novel approach to improving GNN performance, supported by empirical results.', 'Theoretical analysis of the vanishing gradient issue is a valuable contribution.', 'Empirical results show consistent improvements in both natural accuracy and robustness against adversarial attacks across various tasks and models.']","['The presentation of theoretical contributions lacks clarity, and some claims require further elaboration.', 'The clarity of the paper is insufficient, particularly regarding algorithm explanations and result interpretations.', 'The experimental section could benefit from better organization and clearer descriptions of methodologies and results.', 'More detailed ablation studies are needed to thoroughly understand the effects of the proposed modifications.', 'The paper does not adequately discuss the potential negative societal impacts of adversarial training methods.']",3,3,3,4,Reject
1xXvPrAshao,"The paper presents the Mutually supErvised Multimodal VAE (MEME), a novel approach to multimodal variational autoencoders that leverages mutual supervision to effectively handle missing modalities in the data. This method allows for learning from partially observed data and demonstrates superior performance over existing models on standard datasets (MNIST-SVHN and CUB). The approach captures relatedness between modalities and learns effective representations.","['Could the authors provide additional details on the ablation studies to clarify the contributions of various components?', 'Can the authors elaborate on the implications of mutual supervision in comparison to traditional multimodal VAE approaches?', 'What specific hyperparameters were used in training, and how sensitive is the model to these choices?']","['The paper could be improved by clarifying the methodology and reasoning behind certain design choices, particularly concerning mutual supervision.', 'The experimental results are promising but could benefit from a broader array of metrics and comparisons to reinforce the robustness of the findings.', 'The clarity and organization of the paper could be improved significantly to aid reader comprehension.']",False,3,3,3,6,4,"['The proposed model effectively addresses the challenge of learning from partially observed multimodal data, which is a significant concern in the field.', 'The experimental results show that MEME outperforms existing baselines on both image-image and image-text datasets, demonstrating its versatility.', 'The paper provides a comprehensive discussion on the theoretical foundations of the approach, particularly around mutual supervision and semi-supervised VAE frameworks.']","['Certain sections of the paper lack clarity, particularly in explaining the implications of mutual supervision and its differences from existing methods.', 'The experimental section could benefit from additional ablation studies to elucidate the contributions of different components of the model.', 'Some figures and results could be presented more clearly to enhance understanding and comparison with baselines.', 'The paper lacks sufficient detail on implementation specifics, particularly in the experimental section, which could hinder reproducibility.']",3,3,4,4,Reject
IhkSFe9YqMy,"The paper proposes an experience replay mechanism in Deep Reinforcement Learning based on the Add Noise to Noise (AN2N) algorithm, termed Experience Replay More (ERM). This method emphasizes replaying experiences that contain key states to improve agent performance and reduce catastrophic forgetting. The authors claim state-of-the-art performance in experiments conducted on OpenAI Gym tasks when combined with existing algorithms like DDPG, TD3, and SAC.","['Could the authors clarify how key states are defined and identified in practice?', 'What specific comparisons were made to other experience replay methods, and how do the results differ?', 'Can the authors provide more clarity on the implementation specifics of the ERM algorithm and the rationale behind design choices?']","['The paper does not adequately address the limitations of the proposed method, particularly regarding its effectiveness in diverse environments and potential biases introduced by focusing on key states.', 'The lack of clarity in methodology may impede reproducibility.']",False,2,2,2,4,4,"['The concept of focusing on key states for experience replay is relevant and could improve sample efficiency in deep reinforcement learning.', 'Experimental results indicate performance improvements across multiple RL algorithms, suggesting practical applicability.']","[""The paper lacks clarity in defining and identifying 'key states', making it difficult to assess the methodology."", 'Implementation details of the AN2N algorithm are insufficiently explained, hindering reproducibility.', 'There is a lack of strong comparative baselines, and the performance improvements appear marginal rather than transformative.', 'The writing quality is poor, with numerous grammatical errors and convoluted phrasing that impede comprehension.']",2,2,2,3,Reject
FpKgG31Z_i9,"The paper introduces a technique called optimizer grafting, which facilitates the transfer of implicit learning rate schedules between optimizers, aiming to simplify hyperparameter tuning in deep learning. The authors assert that grafting can enable non-adaptive optimizers like SGD to achieve state-of-the-art performance by leveraging the properties of tuned adaptive optimizers like Adam. However, the paper suffers from clarity issues and presents limited experimental evaluation.","['Could the authors clarify the implications of grafting for both practical applications and theoretical understanding?', 'What specific metrics were used for comparison, and how were they defined across different experiments?', 'Can the authors provide a more thorough theoretical justification for why optimizer grafting works?', 'What are the limitations of grafting in terms of optimizer performance and learning rate dynamics?']","[""Clarity issues may hinder the reader's understanding of the contributions and implications of the work."", 'Some experimental results lack comprehensive discussion and context, especially regarding their significance.', 'The paper does not fully address the potential negative impacts of relying on grafted optimizers in certain settings.']",False,3,2,3,4,4,"['Addresses a significant challenge in deep learning related to optimizer tuning and learning rate scheduling.', 'The concept of optimizer grafting is novel and has the potential to simplify the hyperparameter tuning process.', 'Empirical results demonstrate the effectiveness of grafting across various models and settings.']","['The writing lacks clarity in certain sections, making it difficult to follow the main arguments.', 'The experimental design could be improved; for instance, clearer definitions of metrics and more rigorous comparisons are needed.', 'The implications of the findings for practitioners and theoreticians are not sufficiently explored.', ""The theoretical foundation of the grafting method is weak, and the paper doesn't provide enough insight into why it works.""]",3,3,2,4,Reject
eo1barn2Xmd,"The paper introduces SLIM-QN, a stochastic quasi-Newton optimizer designed to efficiently train large-scale deep neural networks by addressing the computational and convergence challenges of second-order methods. It proposes using momentum and damping in Hessian updates to improve convergence stability and reduce memory usage. The performance claims are supported by theoretical analysis and empirical results, demonstrating faster convergence compared to SGD and KFAC on various tasks.","['Could you provide more extensive comparisons with other second-order optimizers beyond KFAC?', 'What are the implications of SLIM-QN on non-convolutional architectures, and how does it perform in those scenarios?', 'How do the introduced components (momentum and damping) specifically affect convergence in different training scenarios?']","['The evaluation is limited to certain architectures and datasets, which may not reflect the broader applicability of the proposed method.', 'The potential drawbacks of using momentum and damping in stochastic environments are not sufficiently discussed.']",False,3,3,3,6,4,"['The proposed SLIM-QN optimizer effectively addresses significant challenges in the application of second-order methods for large-scale deep learning.', 'The introduction of momentum and adaptive damping mechanisms is a novel approach that enhances stability and efficiency.', 'The paper provides a comprehensive theoretical foundation for the proposed method along with empirical results supporting its effectiveness.']","['The evaluation is primarily focused on specific architectures (ResNet and Vision Transformer) and may not generalize well across different model types or datasets.', 'There is a lack of comparative analysis against a broader range of baseline optimizers, particularly other state-of-the-art second-order methods.', 'The presentation could benefit from clearer structuring and summarization of key findings and implications.']",3,3,4,4,Reject
dg79moSRqIo,"The paper presents a framework for unsupervised skill discovery in reinforcement learning, termed Discovery of Incremental Skills (DISk). This approach focuses on learning skills incrementally to mitigate catastrophic forgetting and enhance adaptability in dynamic environments. Experimental results suggest that DISk outperforms existing methods in both evolving and static environments. However, the paper suffers from some clarity issues and lacks rigorous comparisons with state-of-the-art methods.","['Can the authors clarify how DISk significantly differs from existing skill discovery methods?', 'What specific design choices contribute most to the performance improvements observed in the experiments?', 'Could the authors provide more details on the hyperparameter selection process and its influence on the results?']","['The paper does not adequately address the limitations of the proposed method in scenarios with highly dynamic environments.', 'There is a lack of detailed analysis regarding the performance of DISk in more complex tasks.']",False,3,3,3,6,4,"['The proposed DISk framework addresses the significant challenge of catastrophic forgetting in reinforcement learning.', 'The authors conduct experiments demonstrating the effectiveness of DISk in both evolving and static environments.', 'The incremental learning approach is a novel contribution that is theoretically sound.']","['The clarity of the presentation could be improved, making it easier to follow the methodology and results.', 'The experimental evaluation lacks depth and rigorous comparisons with existing methods.', 'The paper does not sufficiently address the limitations of the proposed method in complex or highly variable environments.']",3,3,4,4,Reject
DrCsriMQ1o,"The paper proposes a novel method for generating counterfactual explanations using tractable probabilistic models, specifically sum-product networks (SPNs). The authors aim to improve upon existing methods by providing faster computations and more realistic counterfactuals through a two-step process involving gradient-based perturbations followed by density maximization.","['Could the authors clarify the specific advantages of using SPNs over other generative models, particularly in the context of counterfactual explanations?', 'Can the authors elaborate on the implementation details of the SPNs and how they specifically enhance the performance of counterfactual generation?', 'What specific limitations do the authors see in their approach compared to traditional optimization-based methods for counterfactual explanations?']","['The explanations for the proposed methodology could be clearer, and the technical details could use more elaboration.', 'The performance of the proposed method relative to a wider range of baselines should be explored further.', 'The authors should address any potential biases or limitations in their approach.']",False,2,2,3,4,4,"['The proposed approach leverages tractable probabilistic models, which could lead to significant improvements in computational efficiency.', 'The method addresses important shortcomings in existing counterfactual explanation approaches, particularly in terms of generating realistic examples.', ""The empirical evaluation includes multiple datasets, demonstrating the approach's effectiveness across different contexts.""]","['The paper lacks clarity in explaining the methodology, especially the mechanics of the proposed approach.', 'Comparative evaluation with existing methods is somewhat limited; more comprehensive comparisons are needed to fully substantiate claims of superiority.', 'The novelty of using SPNs for this purpose is not sufficiently justified against existing literature on generative models.', 'The significance of the results is not thoroughly discussed, and the authors do not adequately address potential limitations or shortcomings of their approach.']",3,2,2,3,Reject
UseMOjWENv,"The paper presents MIDI-DDSP, a hierarchical model designed to synthesize music with realistic audio and detailed control over performance attributes. It proposes a three-level hierarchy (notes, performance, synthesis) that allows users to intervene at each level, aiming to enhance the musical experience through both automated and manual controls. The paper includes experiments demonstrating the model's capabilities in audio reconstruction and attribute manipulation.","['Can the authors provide more qualitative examples to illustrate the effectiveness of MIDI-DDSP in real-world applications?', 'What are the limitations of the current model regarding polyphonic audio synthesis, and how do the authors plan to address them in future work?', 'Can the authors clarify how the user control mechanisms work in practice?', 'Could they provide more explicit comparisons of MIDI-DDSP with existing models in terms of user experience?']","[""The clarity of the paper could be improved, particularly in the description of the model's architecture and how different components interact."", 'The current focus on monophonic instruments limits the applicability of the model; the authors should discuss how they plan to extend this work.', 'The complexity of the model may lead to implementation challenges and difficulty in reproducibility.']",False,3,2,3,6,4,"['The hierarchical structure provides a clear pathway for user control, enhancing the usability of generative models in music.', 'The proposed model integrates both high-level note control and low-level synthesis manipulation, which is a significant step forward in music generation.', ""The paper includes quantitative experiments and listening tests that demonstrate MIDI-DDSP's effectiveness in generating realistic audio.""]","['The explanations of the methodologies and the architecture could be clearer, especially for readers unfamiliar with the underlying concepts of audio synthesis.', ""While the paper presents quantitative results, there is insufficient qualitative analysis and examples provided to fully understand the model's capabilities in practice."", 'The paper could benefit from exploring more ablation studies to detail the contributions of each part of the architecture.', 'The novelty of the contributions seems limited, as many aspects overlap with existing literature in music synthesis and control.']",3,3,2,4,Reject
kiNEOCSEzt,The paper addresses the influence of recommender systems (RS) on user preferences and proposes a framework for estimating and evaluating such shifts. It introduces the concept of 'safe shifts' to help RS designers avoid undesirable preference manipulations.,"['What specific novel contributions does this work make compared to existing literature on RS and user preference dynamics?', 'How do the proposed methods improve upon or differ from previous approaches in quantifying and controlling preference shifts?', 'Can the authors clarify how the proposed model performs against existing methods in more detail?', 'What specific improvements can the authors provide in the next version to enhance the clarity of the methodologies presented?']","['The lack of experimental validation raises questions about the reliability of the claims made.', 'The ethical implications of controlling user preferences are touched upon but not deeply explored.', 'The reliance on simulated data may limit the applicability of the findings.', ""Presentation issues may hinder the reader's ability to fully understand the contributions and implications of the work.""]",True,2,2,2,4,4,"['The topic is highly relevant given the increasing deployment of RS in daily life.', ""The introduction of the concept of 'safe shifts' provides a framework for ethical considerations in RS design."", 'The paper draws on a solid foundation of existing literature, grounding its contributions in established research.']","['The contributions appear to lack significant novelty compared to existing works, as many concepts are adaptations of prior research without clear innovation.', 'The clarity of the writing is poor, with complex ideas presented in a convoluted manner that may confuse readers.', 'The methodology lacks rigor in terms of experimental validation and thorough analysis, making it difficult to assess the effectiveness of the proposed framework.', 'The paper does not adequately address limitations and potential negative societal impacts of the proposed solutions.']",2,2,2,3,Reject
gLqnSGXVJ6l,"The paper proposes a framework for solving the Vehicle Routing Problem with Time Windows (VRPTW) using neural networks and reinforcement learning, specifically an attention model that predicts near-optimal routes. The model is trained in a reinforcement learning environment to optimize routes based on various constraints. While the approach shows promise and outperforms some baselines on synthetic data, there are concerns regarding clarity and experimental depth.","['Can the authors clarify the model architecture and provide more details on the training process?', 'How do the results compare with other well-established methods besides those mentioned?', 'Could the authors provide additional experimental results on real-world datasets?']","['The clarity of the paper needs improvement, especially regarding model details and experimental setups.', 'The generalizability of results is uncertain due to the reliance on synthetic data.']",False,2,2,2,4,4,"['Addresses a relevant and complex combinatorial optimization problem, VRPTW.', 'The use of reinforcement learning and attention mechanisms is a novel approach to dynamically optimize routes.', 'The proposed method shows superior performance in terms of solution quality on synthetic datasets.']","['The paper lacks clarity in the presentation of the model architecture and training process, making it hard to follow.', 'The experiments are limited to synthetic data, which raises concerns about the practical applicability of the results.', 'There is insufficient comparison with established state-of-the-art methods and baselines, limiting the significance of the claimed improvements.', 'The description of the data generation process and the specific setup for experiments is vague.']",2,2,2,3,Reject
5XmLzdslFNN,"The paper proposes a method for lifelong reinforcement learning based on neural composition, allowing agents to decompose complex tasks into subproblems and reuse solutions. It aims to enable faster learning of new tasks by leveraging previously learned modules. However, the clarity and novelty of the approach are questioned, as it does not sufficiently differentiate itself from existing work.","['How does this approach fundamentally differ from previous works in modular RL or hierarchical RL?', 'Can the authors clarify their evaluation process and provide more comprehensive results to support their claims?']",['The paper does not adequately address the limitations of its approach or potential challenges in scalability and generalization to more complex tasks.'],False,3,2,3,5,4,"['Addresses a relevant problem in reinforcement learning: the challenge of lifelong learning and knowledge reuse.', 'The concept of using neural composition to handle complex tasks is interesting and could lead to more efficient learning processes.']","['Lacks clarity in presentation, making it difficult to follow the proposed methods and results.', 'The novelty of the approach is questionable as it heavily draws from existing works without providing a clear distinction or contribution.', ""Experimental evaluation appears limited and does not convincingly demonstrate the proposed method's advantages over established techniques.""]",3,3,2,3,Reject
fEcbkaHqlur,"The paper proposes a novel approach to stabilizing Deep Q-Learning by introducing functional regularization to the squared Bellman error, aiming to address the instability caused by target networks. The authors claim that their approach leads to faster training and improved performance across various Atari environments compared to traditional methods.","['Can the authors clarify how their method compares with existing regularization techniques in terms of performance and stability?', 'What specific experiments demonstrate the robustness of the proposed method under various hyperparameter settings?', 'Could the authors provide a simpler explanation of functional regularization and its advantages over target networks?', 'What are the limitations or potential downsides of this approach that the authors foresee?']","['The paper does not adequately address potential limitations or scenarios where the proposed method may fail or underperform compared to traditional target networks.', 'There is insufficient discussion on the implications of using functional regularization in other reinforcement learning contexts.']",False,3,3,3,7,4,"['The introduction of functional regularization is a novel approach that addresses known issues with target networks in Deep Q-Learning.', 'Empirical results show improvements in sample efficiency and training stability across multiple Atari environments.', 'The theoretical backing for the approach is solid, drawing from established concepts in reinforcement learning.']","['The paper lacks clarity in several sections, particularly in explaining the functional regularization method and how it differs from existing approaches.', 'The experimental evaluation does not sufficiently compare the proposed method with a wider range of state-of-the-art algorithms, limiting the understanding of its practical significance.', 'The presentation of results could be improved; some figures are difficult to interpret due to lack of context or explanation.', 'The paper does not adequately discuss the potential risks associated with moving away from target networks, such as increased instability in certain environments.']",3,3,3,4,Reject
RMv-5wMMrE3,"The paper presents Cell2State, a method for learning low-dimensional representations of cell states based on barcoded single-cell gene expression transitions. It aims to improve the understanding of cell dynamics by providing a predictive mapping of gene-expression profiles. The method is evaluated on a barcoded stem cell dataset and shows promise in downstream tasks such as cell state prediction and clustering.","['Can the authors clarify the specific improvements over existing methods and provide more context for the chosen benchmarks?', 'What are the limitations of the Cell2State method, and how do they plan to address them in future work?', 'Could you provide more detailed explanations about the algorithm implementation?', 'How do the authors plan to validate the robustness of their method against more diverse baseline methods?']","['The paper does not adequately address potential limitations or weaknesses of the proposed method.', 'The dependence on specific datasets may limit the generalizability of the findings.', 'The clarity of the paper is a significant concern; more explanation is needed for the proposed methods and results.', 'The experiments lack depth; additional datasets and comparisons would strengthen the validation of the method.']",False,2,2,3,4,4,"['Addresses a significant challenge in single-cell genomics by focusing on individual cell transitions rather than ensemble analysis.', 'Introduces a novel cell-to-state learning method that combines ideas from dynamical systems and kernel methods.', 'Demonstrates the effectiveness of the approach through comprehensive experiments on real and synthetic datasets.']","['The paper lacks clarity in its methodology, particularly in the description of the Cell2State algorithm and its implementation details.', 'The experimental section does not provide enough detail on the benchmarks used for comparison, making it difficult to assess the validity of the claims regarding performance improvements.', 'The writing quality is inconsistent, leading to confusion about the key contributions and findings of the work.']",3,2,2,4,Reject
DfMqlB0PXjM,"The paper introduces HIERARCHICAL DIVNOISING (HDN), a hierarchical variational autoencoder designed for unsupervised image denoising and artifact removal. The method aims to provide diverse outputs while maintaining state-of-the-art performance on various benchmarks, particularly in microscopy imaging. The authors claim that HDN outperforms existing unsupervised methods and provides interpretable results, addressing the limitations of prior works.","['Can the authors provide more clarity on the architecture of HDN and how it differs from existing methods?', 'What specific improvements were made in the hierarchical VAE design compared to existing architectures?', 'Could the authors provide additional ablation studies to demonstrate the importance of each architectural component?']","['The paper lacks clarity in its presentation, which could hinder understanding and reproducibility.', 'The validation of the method on a wider range of datasets is necessary to establish its robustness and applicability.']",False,3,3,3,6,4,"['Addresses a significant issue in image processing by focusing on unsupervised denoising and artifact removal, which is highly relevant for microscopy.', 'The proposed HDN architecture is innovative and claims to generate diverse restorations, improving the interpretability of the model.', 'The experimental validation is extensive, covering multiple datasets and comparisons with several baseline methods, demonstrating the effectiveness of the proposed approach.']","['The clarity of the paper could be improved, as some technical details may be difficult for readers to follow.', 'The paper would benefit from additional ablation studies to justify the design choices made in HDN, especially regarding the number of latent layers and the impact of each architectural component.', 'While the results are strong, they may be overfitted to specific datasets, and the generalizability of the approach to other types of images is not sufficiently demonstrated.']",3,3,3,4,Reject
R612wi_C-7w,"The paper introduces the Resetting Path Integrator (RPI) model for path integration, which fuses visual and proprioceptive signals to create a cognitive map in a controlled 2D environment. The model claims to outperform traditional LSTM architectures in performance and interpretability, but lacks a strong theoretical basis and comprehensive experimental evaluation.","['Can the authors clarify the theoretical underpinnings of their approach and how it compares to existing models?', 'What measures are in place to ensure that the results are generalizable beyond the specific environment used in the experiments?', 'Could you provide more detailed explanations of the model architecture and training procedures?']","['The simplicity of the environment may not adequately reflect the challenges faced in real-world navigation tasks.', 'The paper does not adequately discuss the potential limitations of the proposed model and its performance in more complex environments.']",False,2,2,2,4,4,"['Novel approach combining visual and proprioceptive signals for path integration.', 'The proposed RPI model shows promise in improving path integration performance, particularly in managing noisy inputs.', 'The experiments provide clear comparisons between RPI and traditional LSTM models.']","['Lacks a strong theoretical framework to justify the design choices of the RPI model.', 'The clarity of the paper is poor; explanations of methods and results are convoluted.', 'Insufficient comparative analysis against existing state-of-the-art models.', 'The experimental setup is simplistic and may not translate well to more complex real-world scenarios.']",2,2,2,3,Reject
Zq2G_VTV53T,"The paper introduces FastSHAP, a method for efficiently estimating Shapley values using a learned explainer model that allows for a single forward pass. The authors claim that this method significantly speeds up the explanation process while maintaining accuracy compared to traditional approaches.","['Can the authors provide more clarity on the training process for the explainer model?', 'What specific hyperparameter settings were found to be most effective, and how do they impact the results?', 'Could the authors include additional results comparing FastSHAP with more state-of-the-art methods?']","['The paper does not address potential limitations in the application of FastSHAP, particularly regarding its generalizability across different model types and datasets.']",False,3,3,3,7,4,"['FastSHAP addresses a crucial aspect of model interpretability by providing a method to compute Shapley values efficiently.', 'The use of a learned explainer model is an innovative approach that holds potential for both speed and accuracy.', 'The experiments demonstrate that FastSHAP outperforms traditional methods in terms of speed, which is a significant contribution to the field.']","['The paper lacks a comprehensive comparison with a broader range of existing methods, particularly in complex scenarios where Shapley value calculations are typically used.', 'Several sections of the paper are unclear, particularly around the training process of the explainer model and how certain hyperparameters affect performance.', 'The claims regarding real-time performance improvements need to be substantiated with detailed experimental results, including variance analysis and robustness testing.']",3,3,3,4,Reject
VyZRObZ19kt,"The paper proposes a dynamic adjustment framework for the parameter ε in learned index structures, addressing the limitations of fixed ε in existing methods. It provides a theoretical analysis linking ε to data characteristics and presents empirical results indicating improved performance with dynamic ε adjustments compared to traditional methods.","['Can the authors clarify how the dynamic adjustment of ε is implemented in practice, particularly in terms of computational overhead?', 'Could the authors provide more detailed explanations for the experimental design and how the effectiveness of their framework is measured?']","['The clarity of the mathematical derivations and the overall presentation of the results could be improved.', 'There is a need for clearer explanations of the experimental setups, which could assist in understanding the significance of the results.']",False,3,2,3,6,4,"['Addresses a relevant problem in learned index structures by proposing a dynamic adjustment for the parameter ε.', 'The paper provides a strong theoretical foundation for the proposed method and demonstrates its effectiveness through empirical results.', 'The proposed method is pluggable into existing learned index methods, enhancing their performance without major structural changes.']","['The organization of the paper could be improved for better flow and clarity.', 'Some mathematical derivations are complex and may not be easily understood by all readers, impacting overall clarity.', 'The experimental setup and results could benefit from clearer explanations and contextualization regarding the datasets used.']",3,3,3,4,Reject
ZDYhm_o8MX,"The paper proposes Neural Manifold Clustering and Embedding (NMCE), which integrates data augmentation with a Maximum Coding Rate Reduction (MCR2) objective for clustering data points from non-linear manifolds. The authors claim that NMCE achieves state-of-the-art performance on benchmark datasets, but the clarity and originality of the contributions are questioned.","['Can the authors clarify how NMCE significantly differs from existing manifold clustering methods?', 'Could the authors provide more details on the implementation of the MCR2 objective and its effectiveness?', 'What additional experiments or ablation studies could strengthen the claims made regarding the advantages of NMCE?']","['The paper does not adequately discuss the limitations of the proposed approach.', 'Lack of clarity in methodology and results could hinder understanding and application.']",False,2,2,3,5,4,"['Addresses a relevant problem in manifold clustering.', 'Innovative integration of data augmentation with MCR objective.', 'Empirical results show competitive performance on standard datasets.']","['Lacks clarity and coherence in presentation, making it difficult to follow. Specific sections that could benefit from clearer explanations include the methodology and results.', 'Insufficient detail in methodology and experimental setup hinders reproducibility. More explicit descriptions of the experimental conditions and parameters would be beneficial.', 'Originality could be better articulated, as similar techniques have been explored previously. A more thorough discussion of how NMCE builds upon or differs from existing methods would strengthen the paper.']",4,2,2,4,Reject
ziRLU3Y2PN_,"The paper proposes a wavelet-based model for texture synthesis that utilizes generalized rectifier wavelet covariance statistics. It aims to bridge the gap between classical wavelet-based models and state-of-the-art CNN-based methods, claiming improvements in visual quality. However, the originality and clarity of the approach are questioned, and the experimental validation is deemed insufficient.","['Can the authors clarify what makes this method significantly better than previous approaches?', ""Could the authors provide more detailed explanations of the model's mechanics, especially in the context of the results presented?"", 'What specific metrics were used to evaluate the quality of the synthesized textures?']","['The paper does not sufficiently address the limitations of the proposed model, particularly in terms of generalizability.', 'The reliance on visual inspection without comprehensive quantitative metrics raises concerns about reproducibility.']",False,2,2,2,4,4,"['The motivation for using wavelet-based representations is well-founded, as wavelets capture structures at multiple scales.', 'The proposed model shows promising visual quality in texture synthesis.', 'The paper provides a thorough experimental comparison with existing models.']","['The originality of the work is somewhat incremental; while it builds on existing methods, it does not introduce a fundamentally new concept.', ""Technical clarity is lacking in certain sections, particularly in the explanation of the model's mechanics and the results, making it difficult to fully grasp the proposed methods."", 'The experimental results do not convincingly demonstrate a significant advantage over existing models.']",3,2,2,3,Reject
Czsdv-S4-w9,"The paper introduces DIGAN, a dynamics-aware implicit generative adversarial network for video generation that utilizes implicit neural representations to improve motion dynamics and video coherence. It claims significant improvements in video generation quality and efficiency over existing methods, showcasing various properties such as long video synthesis and non-autoregressive generation.","['Could the authors provide more detailed explanations for the generator and discriminator components?', 'What specific ablation studies do the authors plan to include to address the contributions of different parts of the model?', 'Can the authors clarify the reasoning behind the choice of datasets used for evaluation?']","[""The paper's clarity could be improved, particularly in the implementation details and the evaluation of results across different datasets."", 'The robustness of the results across various scenarios and datasets needs further validation to ensure the generalizability of the approach.']",True,3,3,3,6,4,"['Innovative use of implicit neural representations for video generation, addressing significant challenges in generating long, high-quality videos.', 'Demonstrates substantial improvements in state-of-the-art metrics for video generation, particularly in Fréchet video distance scores.', 'The model exhibits intriguing properties such as time interpolation and extrapolation, and diverse motion sampling.']","['The clarity of the technical components, including the generator and discriminator architecture, could be improved.', 'The experimental validation lacks robustness, with limited diversity in datasets and insufficient ablation studies to fully assess the contributions of different components.', 'The paper does not adequately address potential ethical concerns related to the misuse of generated videos.']",3,3,3,4,Reject
18Ys0-PzyPI,"The paper introduces ODITS, a reinforcement learning framework for ad hoc teamwork that enables agents to adapt to unknown teammates in partially observable environments. ODITS learns latent representations of teammates' behaviors to facilitate cooperation without predefined types, addressing significant limitations in previous approaches.","['Could the authors provide more detailed explanations of the components of ODITS, particularly the information-based regularizer?', 'What specific metrics were used to evaluate the performance improvements over baselines, and how do they compare qualitatively?', 'Can the authors clarify the theoretical basis for the latent variable learning?']","['The paper does not thoroughly address the scalability of the proposed method in larger teams or more complex environments.', ""The impact of the diversity of teammates' policies on performance is not explored in depth."", 'The explanation of the ODITS framework lacks depth, which may hinder reproducibility.']",False,3,2,3,5,4,"['Addresses a significant challenge in multi-agent systems: adapting to unknown teammates with varying behaviors.', 'Proposes a novel approach that goes beyond fixed teammate types, allowing for more flexible and dynamic teamwork.', 'Extensive experimental results demonstrate superior performance compared to baseline methods.']","['The paper lacks clarity in the presentation of the methodology, making it difficult for readers to fully grasp the framework.', 'Insufficient theoretical analysis of the components, particularly regarding the information-based regularizer and its implications.', 'Some experimental comparisons and ablations are limited, which could strengthen the validation of the proposed approach.']",3,3,2,4,Reject
0DcZxeWfOPt,"The paper presents MEND, a framework for model editing in large pre-trained models, focusing on efficient localized edits using gradient decomposition. It addresses the need for post-hoc corrections in model behavior without complete retraining. The framework is shown to be effective in editing models like T5, GPT, BERT, and BART, demonstrating scalability and adaptability.","['Can you provide more insights into how the low-rank decomposition directly affects the efficiency of model edits?', 'What are the specific limitations you foresee in using MEND for different types of models or datasets?', 'How do the authors plan to address the issue of overgeneralization in edits?', 'What considerations were taken regarding the ethical implications of using model editing techniques like MEND?']","['Clarity issues regarding the methodology and its implications for practical implementations.', 'Potential overfitting in the editing process if not enough diversity is present in the edit training data.', 'The paper does not sufficiently address the limitations of MEND, particularly in terms of its applicability to different types of models or tasks.', 'There is a lack of discussion on potential negative societal impacts of easy model editing.']",True,3,2,3,5,4,"['Innovative approach to model editing using gradient decomposition, allowing efficient edits without complete retraining.', 'Demonstrates effectiveness on large scale models with comprehensive experiments, showing significant improvements over existing methods.', 'Addresses a critical challenge in NLP with practical implications for model maintenance and adaptation.']","['The explanation of the low-rank decomposition and its application in gradient mapping could be clearer.', 'Some experimental details, such as the choice of datasets and specific evaluation metrics, need more elaboration for reproducibility.', 'The paper could benefit from discussing potential limitations or failure modes of the approach more thoroughly.', 'The clarity of the writing could be improved; certain technical details are not presented in an easily digestible format.', 'The paper lacks a detailed exploration of potential negative societal impacts or ethical considerations related to model editing.']",3,3,3,4,Reject
mF5tmqUfdsw,"The paper proposes the Zeroth-Order Actor-Critic (ZOAC) algorithm, which integrates zeroth-order optimization methods with first-order reinforcement learning techniques in an actor-critic framework. ZOAC aims to enhance sample efficiency and robustness through a modified rollouts collection strategy and a critic network. The method is evaluated on various continuous control tasks, showing improved performance compared to baseline algorithms.","['Can the authors clarify how ZOAC improves upon existing methods in a way that is not merely the result of combining techniques?', 'What specific additional experiments can be conducted to validate the robustness claims beyond the provided benchmarks?', 'Could the authors provide more details on how the critic network was trained and the implications of this on the performance of ZOAC?']","['The paper does not sufficiently address the potential limitations of the proposed method, particularly in terms of scalability to more complex environments.', ""The analysis of the algorithm's performance could be enhanced by providing a wider range of benchmarks or comparing against more baseline methods.""]",False,3,4,3,5,4,"['The integration of zeroth-order and first-order methods is an interesting approach that could enhance sample efficiency and robustness in reinforcement learning.', 'The experimental results demonstrate competitive performance on challenging continuous control benchmarks.', 'The theoretical foundation regarding the variance of gradient estimators is well derived and adds depth to the paper.']","['The clarity of presentation could be improved; some complex ideas are not communicated effectively, making it challenging to follow the proposed methodology.', 'While the work builds on existing techniques, the originality could be seen as limited due to the lack of fundamentally new concepts introduced.', 'The experimental evaluation, while showing positive results, could benefit from more comprehensive testing across a wider array of environments and conditions to validate claims of robustness and efficiency.']",4,3,4,3,Reject
4l5iO9eoh3f,"This paper proposes a supervised deep learning framework for solving the Capacitated Vehicle Routing Problem (CVRP) with a fixed fleet size. The method constructs complete tour plans while adhering to a specified number of vehicles, claiming to outperform existing reinforcement learning methods in terms of speed and feasibility. The authors provide empirical comparisons to various models, emphasizing the practical implications of vehicle costs.","['Can the authors clarify the reasoning behind the specific choices made for the loss function and the impact of the auxiliary losses?', 'Could additional results or comparisons against more recent state-of-the-art methods be provided for a more robust validation?', 'What specific innovations does this method introduce compared to existing approaches? How does it improve upon them?']","['The paper does not adequately address potential biases in the training data or the limitations of the proposed model in real-world scenarios.', 'There is a lack of detailed information regarding the training and inference efficiency compared to existing methods.']",False,2,2,3,5,4,"['Addresses a significant real-world problem in logistics and combinatorial optimization.', 'Proposes a supervised learning framework that is faster to train than traditional reinforcement learning approaches.', 'Demonstrates competitive performance in experiments against various state-of-the-art methods.']","['Lacks clarity in the description of the model architecture and training process, making it difficult for readers to grasp implementation details.', 'The novelty of the approach is questionable, as it builds significantly on existing work without introducing substantial new concepts.', 'Experimental validation is limited; it would benefit from a broader comparison with more established and diverse baselines.', 'Results are presented in a cluttered manner, making it hard to interpret the significance and implications of the findings.']",3,2,2,3,Reject
dEOeQgQTyvt,"The paper proposes SEAL, a framework utilizing structured energy networks as dynamic loss functions for multi-label classification tasks. It claims improvements in computational efficiency and model performance over traditional methods by adjusting energy functions dynamically during training. The approach is validated through experiments on several datasets, showcasing improvements over traditional loss functions.","['Can the authors provide clearer details on how the energy functions are dynamically adjusted during training?', 'What specific steps were taken to ensure the reproducibility of the experiments, and how were hyperparameters chosen?', 'Could the authors expand on the underlying theory that justifies using SEAL over existing methods?', 'What measures are in place to prevent overfitting, especially in datasets with high variance?']","['The explanation of the dynamic loss learning process is vague and needs more elaboration to clarify its advantages.', 'The paper does not adequately address potential limitations or negative implications of using structured energy networks in this way.', 'The performance metrics on some datasets show significant discrepancies that require further investigation.']",False,3,3,3,5,4,"['The concept of using structured energy networks as a dynamic loss function is innovative and could significantly enhance multi-label classification tasks.', 'The paper includes a variety of experiments across multiple datasets, demonstrating the applicability of SEAL in different contexts and its potential to outperform traditional methods.', 'Results indicate that SEAL shows significant performance improvements, particularly with the NCE ranking method, which adds value to the existing literature.']","['The paper lacks clarity in explaining how the dynamic aspect of SEAL works, particularly in terms of the mechanisms by which the energy function adapts during training.', 'There are insufficient details on the architectural choices and hyperparameter settings, which could affect reproducibility and understanding of the method.', 'The originality of the contribution is questionable as it appears to heavily leverage existing frameworks without providing a significant new theoretical insight or framework.', 'The comparison between SEAL and other methods lacks depth; a more thorough analysis of why specific losses perform differently would strengthen the paper.']",2,3,3,4,Reject
4Ycr8oeCoIh,"The paper investigates the process of finetuning pretrained GANs, focusing on how pretraining affects model coverage and performance. It highlights that pretrained checkpoints primarily influence model coverage rather than individual sample fidelity and proposes a method for selecting suitable GAN checkpoints for finetuning.","['Can the authors clarify the rationale behind their experimental setup and the choice of metrics used for evaluation?', 'What specific improvements do the authors believe their findings will bring to the field of GAN research compared to existing literature?', 'Could the authors provide more rigorous experimental results that validate their claims across different models and datasets?']","['The paper does not adequately address the potential limitations of the proposed method or the implications of using pretrained GANs.', 'The lack of diversity in experimental conditions may limit the generalizability of the findings.']",False,3,2,3,5,4,"['Addresses a significant gap in understanding the effects of pretraining on GAN performance.', 'Provides empirical evidence indicating the benefits of pretrained generators and discriminators.', 'Offers practical guidelines for selecting GAN checkpoints, which could be beneficial for practitioners.']","[""The writing lacks clarity and organization, making it difficult to follow the authors' arguments and conclusions."", 'The experimental setups lack rigor and depth, with insufficient validation across various datasets and models.', 'Some claims are repetitive and do not provide significant advancements to existing knowledge in the field.']",2,3,2,3,Reject
O5Wr-xX0U2y,"The paper proposes a novel deep reinforcement learning algorithm for risk-averse dynamic decision-making, specifically in equal-risk pricing and hedging of financial derivatives using dynamic expectile risk measures. It extends the deep deterministic policy gradient algorithm to create a new actor-critic reinforcement learning algorithm. While the problem addressed is significant, the paper suffers from clarity issues and insufficient experimental validation.","['Can the authors clarify the differences between their approach and existing methods in more detail?', 'What specific baselines were used for comparison, and how do they perform relative to the proposed method?', 'Can the authors provide more details on the implementation of the algorithm and experimental setup?']","['The paper does not adequately address the limitations of the proposed method.', 'The lack of clarity in explaining the algorithm and its components could hinder understanding and reproducibility.']",False,2,2,2,4,4,"['Addresses a significant problem in financial risk management.', 'Proposes a novel extension of existing reinforcement learning algorithms to dynamic risk measures.', 'Demonstrates potential improvements in hedging strategies through numerical experiments.']","['The clarity of the writing is poor, making it difficult to follow the methodology and results.', 'The experimental validation is insufficient; more detailed comparisons with existing methods are needed.', 'The originality of the contributions is somewhat limited, as the application of DRL in risk-averse settings has been explored previously.', 'Key details regarding the implementation of the algorithm are lacking, raising concerns about reproducibility.']",3,2,2,3,Reject
tFgdrQbbaa,"The paper provides a theoretical analysis of generalization performance in continual learning using the neural tangent kernel (NTK) regime. It investigates knowledge transfer and forgetting, establishing conditions for positive and negative transfer, and includes empirical validation on MLP and ResNet architectures.","['Can the authors clarify the theoretical concepts and their implications?', 'How do the findings translate into practical strategies for improving continual learning?', ""Could additional experiments be conducted to evaluate the model's performance across varying scenarios or datasets?""]","['The complexity of the theoretical analysis may hinder broader understanding and application.', 'The experimental section lacks detail and rigor regarding how experiments were conducted and results validated.']",False,3,3,3,6,4,"['The theoretical insights into knowledge transfer and forgetting are valuable contributions to the field of continual learning.', 'The use of the neural tangent kernel regime provides a solid foundation for the analysis.', 'Empirical validation on standard architectures supports the theoretical claims.']","['The presentation is complex and may hinder understanding for readers less familiar with NTK and statistical mechanics.', 'The experimental validation is somewhat limited; more diverse scenarios and datasets could strengthen the arguments.', 'The practical implications of the theoretical findings are not sufficiently explored.']",3,3,3,4,Reject
JYQYysrNT3M,"The paper proposes a reinforcement learning framework focused on maximizing the expected minimum total reward across multiple reward types, introducing a novel algorithm called Online-ReOpt aimed at achieving near-optimality under this framework. While it presents theoretical guarantees and some experimental results, the clarity of the presentation and the depth of the evaluation are lacking.","['Can the authors clarify the differences between ex-ante and ex-post max-min fairness more thoroughly in the paper?', 'What measures were taken to ensure the robustness of the experiments and the generalizability of the findings?', 'Could the authors provide more comprehensive empirical results or comparisons with other RL methods?']","['The lack of clarity and dense writing style detracts from the overall comprehension of the proposed methods.', 'Insufficient experimental evaluation raises concerns about the reliability and applicability of the proposed algorithm.', ""The focus on simulations may not adequately demonstrate the algorithm's effectiveness in practical scenarios.""]",False,2,2,3,4,4,"['The paper addresses a relevant and important problem in reinforcement learning related to multiple objectives and fairness.', 'The introduction of ex-post max-min fairness adds a new perspective to existing frameworks in reinforcement learning.', 'The proposed algorithm, Online-ReOpt, shows potential for achieving near-optimality in the defined objective.']","['The paper lacks clarity in its presentation, with dense sections that make it difficult to follow the proposed methods and motivations, particularly in the algorithm description and theoretical guarantees.', 'The experimental evaluation is limited, showcasing only a few algorithms without comprehensive analysis across various scenarios, raising questions about the robustness of the findings.', 'The distinction between ex-ante and ex-post objectives is not clearly articulated, making it challenging to understand the implications of the proposed method.']",3,2,2,3,Reject
2s4sNT11IcH,The paper provides a convergence analysis of deep learning with differential privacy (DP) using the neural tangent kernel (NTK). It introduces a global clipping method aimed at improving convergence while retaining privacy guarantees. The work demonstrates that global clipping leads to better-calibrated classifiers and provides empirical results showcasing its benefits over traditional clipping methods.,"['Could you provide more detailed explanations of the theoretical implications of your findings?', 'What strategies do you plan to adopt to improve the clarity of the theoretical discussions?', 'Can you provide more extensive comparisons of calibration metrics with existing methods in your experiments?']","['The clarity of the presentation, especially regarding the theoretical aspects, could hinder understanding.', 'More empirical evidence is needed to firmly establish the benefits of global clipping compared to existing methods.']",False,3,4,3,7,4,"['Addresses a significant gap in understanding the convergence behavior of deep learning with differential privacy.', 'The introduction of global clipping is a novel contribution that potentially improves both performance and calibration in DP models.', 'Empirical results are provided, demonstrating the advantages of global clipping over local clipping in various tasks.']","['The theoretical analysis could be clearer, particularly in how the implications of the findings are communicated.', 'The paper could benefit from a more extensive empirical evaluation, particularly in comparing calibration metrics with state-of-the-art methods.', 'The reproducibility aspect is not fully addressed; while a small code addition is mentioned, detailed implementation specifics are needed.']",3,3,4,4,Reject
6-lLt2zxbZR,"This paper investigates the use of pseudo-log-likelihoods (PLL) for natural language scoring with a zero-shot approach using the ALBERT model. The authors claim that this smaller model outperforms the larger T5 model on common sense reasoning tasks, attributing this success to compositionality. While they present state-of-the-art results on several benchmarks, the clarity of their methodology and justification of their claims require improvement.","['Can the authors elaborate on how the pseudo-log-likelihood scoring compares to existing methods in more detail?', 'What limitations or biases might arise from their methodology?']","['The clarity of methodology and results is a significant limitation, which may hinder reproducibility and understanding.', 'A more thorough analysis of the results and their implications is needed to substantiate the claims of state-of-the-art performance.']",False,2,2,2,4,4,"['The application of pseudo-log-likelihoods for evaluating language models is innovative and could significantly impact natural language processing tasks.', 'The results challenge the assumption that larger models always perform better, demonstrating that a smaller model can achieve competitive results.']","['The paper lacks clarity in its methodology, making it difficult for readers to fully grasp the experimental setup and results.', 'Claims of state-of-the-art performance are made without sufficient comparison to existing methods, raising questions about the validity of these results.', 'There is inadequate discussion of limitations or potential biases in the proposed method.']",3,2,2,3,Reject
cD0O_Sc-wNy,The paper proposes a method for optimizing task replay scheduling in continual learning environments using Monte Carlo Tree Search (MCTS). The approach aims to improve performance by efficiently utilizing limited memory resources and is inspired by human learning principles. Experimental results indicate that the proposed method can outperform baseline strategies that do not consider scheduling.,"['Can the authors provide more detailed explanations of the MCTS implementation and how it can be replicated?', 'What specific metrics were used to evaluate the performance of the proposed method against the baselines?', 'Could the authors elaborate on the tuning process for any hyperparameters in their method?']","['The paper does not address potential limitations or challenges in applying the proposed method in real-world scenarios.', 'Further clarity is needed on how the method can be generalized across various types of continual learning tasks.']",False,2,2,3,5,4,"['The concept of learning the timing of task replays is innovative and draws from human learning principles.', 'The use of Monte Carlo Tree Search (MCTS) to optimize replay scheduling is a valuable contribution.', 'The paper shows promising experimental results across several benchmark datasets.']","['The clarity of the presentation is lacking in some areas, making it difficult to follow the methodology.', 'The experimental evaluations are not comprehensive enough, lacking a broader range of baselines and conditions to fully validate the claims made.', 'Insufficient detail in the experimental setup and evaluation metrics limits the reproducibility of the results.']",3,2,2,4,Reject
dtt435G80Ng,"The paper proposes Centered Symmetric Quantization (CSQ) for low-bit quantized neural networks, aiming to improve performance by equalizing positive and negative quantization levels. The authors present experimental results indicating that CSQ outperforms conventional quantization methods at very low precision (2-3 bits).","['Can the authors clarify how CSQ fundamentally differs from existing quantization techniques beyond just the symmetric aspect?', 'What specific improvements in training or inference times can be expected from the proposed method compared to state-of-the-art techniques?', 'Can the authors provide more details on the theoretical foundations of CSQ?', 'Will the authors include additional ablation studies to strengthen their claims?', 'How do the proposed quantization levels compare with other recent methods that address low-bit quantization?']","['The paper does not adequately discuss the limitations of the proposed method or its implications for broader applications in neural network quantization.', 'The clarity of the paper is a significant concern that could impact comprehension and the overall impact of the work.', 'The experimental results, while promising, may not be repeatable or applicable across various architectures without further validation.']",False,2,2,3,4,4,"['The proposal addresses a critical issue in neural network quantization, particularly at low bit precision, which is essential for efficient model deployment.', 'The experimental results demonstrate that CSQ can provide significant performance benefits over conventional methods, making it valuable for practitioners working with resource-constrained devices.']","['The originality of the contributions is moderate, as the proposed method builds on existing concepts but introduces a new quantization approach.', 'The clarity of the presentation is lacking, with complex ideas insufficiently explained, making it challenging to follow the rationale behind the proposed quantization method.', 'The experimental setup lacks depth, with limited analysis of results and insufficient comparisons to a broader range of quantization methods.', 'The discussion on hardware implementation is superficial and does not provide enough detail on how the proposed method compares to existing techniques in practical applications.']",3,2,2,3,Reject
LtI14EpWKH,"The paper proposes a Tessellated 2D Convolution Network (TCNN) aimed at improving robustness against adversarial attacks by partitioning images into non-overlapping regions and learning independent representations for each. The authors suggest that a well-structured tessellation, specifically Mondrian partitioning, minimizes vulnerability to adversarial perturbations.","['Can the authors clarify the rationale for choosing specific tessellation methods?', 'How do the proposed TCNN architectures compare quantitatively with other recent adversarial defenses?', 'Could the authors provide clearer explanations for the Mondrian scores and their implications for the results?', 'What measures are in place to ensure that the proposed approach generalizes to other datasets and attack types?']","['The clarity of the paper is inadequate, particularly regarding the explanation of the TCNN architecture and the experiments.', 'The experimental validation is limited and could benefit from more rigorous testing across different datasets and adversarial attacks.', 'The practical implications of using tessellated networks, particularly in terms of performance and efficiency, are not discussed.']",False,2,2,2,4,4,"['The proposed method of tessellated networks is novel and presents a unique architectural approach to enhancing adversarial robustness.', 'The consideration of diverse tessellation strategies, including Mondrian, adds an interesting dimension to the design of robust networks.', 'The idea of dividing the image into non-overlapping regions for feature extraction is innovative and could lead to interesting future avenues of research.']","['The paper lacks clarity in explaining the architectural details and the rationale behind the chosen tessellation methods.', ""There is insufficient comparison with existing state-of-the-art methods, limiting the understanding of the proposed method's advantages and disadvantages."", 'The experimental results are not thoroughly discussed, and some of the key metrics are unclear, particularly the implications of the Mondrian score.', 'The evaluation is limited as it does not include a broader range of comparison with existing methods to substantiate the claims.']",3,2,2,3,Reject
xspalMXAB0M,The paper proposes a boosting approach for reinforcement learning that aims to efficiently solve MDPs with large state spaces by leveraging weak learners. The authors develop an algorithm that iteratively improves the policy using a non-convex variant of the Frank-Wolfe method coupled with boosting techniques from supervised learning.,"['Can the authors clarify the assumptions made regarding the weak learners?', 'What specific empirical results can the authors provide to support the efficacy of their algorithm?', 'Can the authors provide more empirical results to demonstrate the effectiveness of their proposed method compared to state-of-the-art approaches?']","['The paper does not adequately address the limitations of the proposed approach or potential challenges in real-world applications.', 'The lack of empirical validation raises questions about the practical utility of the proposed algorithms.']",False,2,2,2,4,4,"['The application of boosting techniques from supervised learning to reinforcement learning is novel and interesting.', 'The paper addresses the significant problem of computational hardness in RL for large state spaces.', 'The theoretical framework for the boosting method is well-grounded in existing literature.']","[""The algorithm's exposition is unclear, making it difficult to follow the main contributions."", 'The theoretical guarantees lack rigor, and the connection to practical RL scenarios is weak.', 'Empirical validation is insufficient; the paper does not provide enough experimental results to support its claims.', 'Assumptions about the weak learners and their applicability to real-world scenarios are not well justified.']",3,2,2,3,Reject
p7LSrQ3AADp,"The paper proposes a framework to characterize and compare saliency methods in machine learning, introducing nine dimensions of comparison that include methodology, sensitivity, and perceptibility. It suggests the creation of 'saliency cards' to document these methods, aiming to enhance understanding and selection of saliency techniques.","['Can the authors provide more empirical examples or case studies to validate the framework?', 'How do the proposed dimensions translate into practical guidance for users of saliency methods?', 'What specific metrics or methods could be used to evaluate the various dimensions of saliency methods proposed in the framework?']","[""The lack of empirical results and practical examples significantly limits the framework's applicability and impact."", 'The writing could be improved for better clarity and coherence, as several concepts are introduced without adequate explanation.']",False,2,2,3,5,4,"['The framework provides a comprehensive way to characterize and compare various saliency methods.', ""The introduction of 'saliency cards' is a practical tool for users to understand and choose appropriate saliency methods."", 'The paper identifies gaps in current research and suggests new directions for future work.']","['The paper lacks empirical validation of the proposed framework; it does not provide sufficient experimental results or case studies to demonstrate its effectiveness.', ""The clarity of the writing is subpar, making it difficult to follow the authors' arguments and the implications of their framework."", 'The definitions of dimensions in the framework could be clearer, and there is insufficient detail on how these dimensions can be practically applied or measured.']",3,2,2,4,Reject
VFBjuF8HEp,"The paper introduces Differentiable Diffusion Sampler Search (DDSS), a method that optimizes fast samplers for diffusion models by differentiating through sample quality scores. It presents Generalized Gaussian Diffusion Models (GGDM), a family of flexible samplers, and demonstrates significant improvements in sample quality with fewer inference steps across various datasets compared to existing methods.","['Can the authors clarify how the perceptual loss is integrated into the optimization process?', 'What implications do the findings have for future research on diffusion models?', 'Could the authors provide more detailed explanations of the optimization process and the perceptual loss used?', 'How do the authors ensure that the improvements in sample quality are not dataset-specific?']","['The clarity of the implementation details could hinder reproducibility.', ""The paper does not thoroughly address potential limitations in the proposed method's applicability across different types of data or tasks."", 'The impact of the optimization on diverse datasets remains unaddressed.']",False,3,3,3,6,4,"['The proposed method effectively addresses the challenge of sampling efficiency in diffusion models.', 'DDSS achieves strong empirical results, demonstrating state-of-the-art sample quality with significantly fewer inference steps.', 'The optimization framework is innovative, utilizing the reparametrization trick and gradient rematerialization.']","['Some sections lack clarity, particularly regarding the implementation details of DDSS and the GGDM family.', 'The significance of the results could be better contextualized within the broader landscape of sampling methods for diffusion models.', 'A more thorough discussion of potential limitations and future work would strengthen the paper.', 'Comparative analysis with a wider range of existing methods is limited, raising questions about the generalizability of the results.']",3,3,3,4,Reject
jE_ipyh20rb,"The paper introduces FEDPROF, a selective federated learning algorithm that utilizes representation profiling to adjust client participation based on data quality. This approach aims to enhance model convergence speed while maintaining client privacy. The results indicate that FEDPROF effectively reduces communication rounds and improves accuracy compared to traditional methods.","['Can the authors clarify the theoretical justification for the Gaussian distribution of representations?', 'Could the experimental details be expanded to improve reproducibility?', 'What specific methods were used to ensure that the Gaussian distribution property holds for the representations in various scenarios?', 'Could additional experiments be provided to compare FEDPROF against a broader range of existing federated learning methods?']","['The paper does not sufficiently address potential limitations in its theoretical claims, particularly regarding the Gaussian assumption.', 'The effectiveness of the method on real-world datasets should be evaluated, as the experiments are primarily conducted on benchmark datasets.', 'The potential risk of excluding clients with useful data early in the training process is not adequately addressed.']",False,3,2,3,5,4,"['Addresses a critical issue in federated learning: the influence of low-quality data from clients.', 'Innovative representation profiling scheme that could lead to more efficient client selection.', 'Experimental results show that FEDPROF achieves faster convergence and improved accuracy over established federated learning algorithms.']","['The theoretical justification for the Gaussian distribution assumption of data representations needs clearer explanation and may require more rigorous proofs.', 'Some experimental setups lack sufficient detail, hindering reproducibility.', 'Clarity of writing could be improved; certain sections are dense and may confuse readers unfamiliar with the topic.', 'Methodology lacks clarity in aspects such as the representation profiling process and client scoring.', 'Experimental validation is not comprehensive enough to establish the significance of the results.']",3,3,2,4,Reject
YLglAn-USkf,"The paper investigates the zero-shot learning capabilities of BERT family models by applying a Multi-Null Prompting strategy, which shows promising results across various datasets. However, it fails to adequately address the limitations of the proposed methods and lacks clarity in its presentation.","['Can the authors clarify how their findings apply to other types of tasks beyond text classification?', 'What specific limitations do they see in their proposed strategies, and how can these be addressed in future work?', 'How do the authors select the datasets for their study, and are there any biases in the selection that could affect the results?']","['The paper does not adequately address the limitations of the Multi-Null Prompt strategy and its performance across different tasks.', ""Clarity of the writing significantly impacts the reader's ability to grasp the details of the approach.""]",False,2,2,2,4,4,"['Addresses a relevant and timely topic in NLP regarding zero-shot capabilities of PLMs.', 'Empirical results indicate a potentially effective prompting strategy that improves zero-shot performance.', 'The study covers multiple datasets, providing a broad evaluation of results.']","['Clarity issues in writing; some sections are convoluted and hard to follow.', 'Limited exploration of the implications of findings across different tasks.', 'Insufficient depth in discussing limitations of the proposed methods and their applicability.', 'Lack of detailed analysis on how the proposed strategies can be generalized to other settings or models.']",3,2,2,3,Reject
mFpP0THYeaX,"The paper proposes GIFT (Gradual Interpolation of Features toward Target), a method for domain adaptation that creates virtual samples by interpolating representations from source and target domains when intermediate distributions are absent. The authors claim that GIFT improves performance over traditional iterative self-training methods, supported by experiments on synthetic and real-world data shifts.","['Can the authors provide more detailed explanations of the GIFT methodology and its comparison to existing techniques?', 'What are the implications of the results on more diverse and complex datasets beyond those used in the experiments?', 'What specific limitations or challenges do you anticipate in applying GIFT to real-world datasets?']","['The clarity of the methodology and overall presentation could be improved.', 'The results may not generalize well beyond the datasets used in the experiments.', 'The paper does not adequately explore the potential limitations or challenges of the proposed GIFT method.']",False,3,2,3,4,4,"['Addresses a significant challenge in domain adaptation, particularly in scenarios lacking intermediate distributions.', 'Introduces an innovative approach by generating virtual samples through interpolation, which is a novel contribution.', 'Empirical results indicate potential improvements over standard iterative self-training methods, demonstrating the effectiveness of GIFT.']","['The methodology and interpolation process lack sufficient clarity, making it difficult to fully understand the proposed approach.', 'The empirical validation is limited, primarily relying on synthetic datasets, which may not generalize well to real-world applications.', 'There is insufficient discussion regarding the limitations and potential societal impacts of the proposed method.']",3,3,2,4,Reject
q4HaTeMO--y,"The paper proposes a theoretical framework connecting deep equilibrium models (DEQs) and deep declarative networks (DDNs) using kernelized generalized linear models (kGLMs). It claims to improve training stability and performance of DEQs through an innovative initialization scheme derived from DDNs. However, the empirical validation is limited, and the presentation lacks clarity in several sections.","['Can the authors provide additional empirical results to support the practical significance of their theoretical claims?', 'Could the authors clarify the more complex sections of the paper, particularly around the proofs and derivations?', 'What additional experiments can be conducted to further validate the effectiveness of the proposed model across different tasks?']","['The paper does not sufficiently address the limitations of the proposed approach or discuss potential negative impacts.', 'The lack of diverse datasets in the experimental evaluation limits the generalizability of the findings.']",False,3,2,3,5,4,"['Theoretical contributions establish a clear connection between DEQs and DDNs, providing a novel perspective in the field.', 'The introduction of an initialization scheme that enhances DEQ performance is valuable and could lead to practical improvements in model training.', 'The paper addresses an important topic in deep learning, specifically the use of implicit layers in neural network architectures.']","['The empirical validation is limited, with only a few experiments conducted to demonstrate the effectiveness of the proposed initialization scheme.', 'The presentation is overly complex with dense mathematical notation that may hinder comprehension for readers not deeply familiar with the subject.', 'Certain assumptions and conditions in the theoretical framework are not clearly justified or discussed, which may affect the applicability of results.']",3,2,2,3,Reject
FPCMqjI0jXN,"The paper presents Domino, a slice discovery method that utilizes cross-modal embeddings to identify coherent slices where machine learning models perform poorly. It introduces a quantitative evaluation framework to assess slice discovery methods across various settings. Domino claims to improve the identification of slices by 12 percentage points over existing methods and can generate natural language descriptions of the identified slices.","['Could the authors clarify the rationale behind the chosen evaluation metrics?', 'Can the authors provide more details on the natural language description generation process?', 'What limitations do you foresee in the application of Domino to datasets with very low slice strength?']","['Clarity issues that could hinder understanding of the evaluation framework and methodology.', 'Lack of detailed explanations in certain sections may lead to confusion regarding the implementation of Domino.', 'The paper does not sufficiently address potential limitations of the proposed methods.']",True,3,3,4,7,4,"['The introduction of a systematic evaluation framework for slice discovery methods addresses a significant gap in the literature.', 'Domino effectively utilizes cross-modal embeddings to enhance slice discovery, providing natural language descriptions of the identified slices.', 'The comprehensive experimental evaluation across multiple domains demonstrates the robustness of the proposed method.']","['The clarity of the paper could be improved, particularly in explaining the evaluation framework and the methods used for generating natural language descriptions.', 'Some parts of the methodology could benefit from further elaboration to ensure that readers fully understand the approach and its implications.', 'While the results are promising, the paper could do more to contextualize the findings within the broader landscape of slice discovery methods.']",4,3,3,4,Reject
5hLP5JY9S2d,"The paper investigates the relationship between closed-set classification accuracy and open-set recognition (OSR) performance, demonstrating that improvements in closed-set accuracy can enhance OSR performance. It introduces the Semantic Shift Benchmark (SSB) for better evaluation of OSR tasks focused on semantic novelty. The findings indicate that a well-trained closed-set classifier can be competitive with or outperform existing state-of-the-art OSR methods.","['Can the authors clarify how the proposed SSB differs from existing benchmarks in terms of evaluation methodology?', 'What specific implications do the findings have for the design of open-set classifiers in practical applications?', 'Could the authors provide additional qualitative analyses to complement their quantitative results?']","['The paper could benefit from clearer explanations of the experimental designs and the significance of the results.', 'Further discussion on the assumptions made regarding the relationship between closed-set performance and open-set recognition is warranted.']",False,3,3,3,7,4,"['Addresses an important and practical problem in machine learning related to open-set recognition.', 'Establishes a significant correlation between closed-set accuracy and open-set performance, providing valuable insights.', 'Introduces the Semantic Shift Benchmark (SSB) as a new evaluation method for OSR, which can guide future research.', 'Extensive experiments are conducted across various datasets and architectures, yielding compelling results.']","['Certain sections lack clarity, particularly regarding the methodology and the implications of the findings.', 'The presentation of results could be improved, as some figures and tables are not intuitively clear.', 'The paper could benefit from a more thorough analysis of how the findings can be applied in real-world scenarios, particularly in terms of practical deployment.']",3,3,3,4,Accept
JHXjK94yH-y,"The paper proposes the Adversarial Surprise algorithm for unsupervised reinforcement learning, which introduces a competition between two policies—Explore and Control—aimed at balancing exploration and control in high-dimensional stochastic environments. The paper provides theoretical backing and empirical results showing that this approach can effectively explore state spaces and achieve zero-shot transfer to downstream tasks.","['Can the authors clarify the key theoretical results and their implications more explicitly?', 'Could additional experiments in varied environments be included to strengthen the validation of AS?', 'Can the authors provide clearer explanations or a more structured presentation of the theoretical results?', 'What measures were taken to ensure the scalability of the method to more complex environments?']","['The complexity of the method may limit its applicability or implementation by others in the field.', 'The paper does not sufficiently address potential limitations or drawbacks of the proposed approach.', 'Clarity issues in the description of the algorithm and its components might hinder reproducibility.']",False,3,2,3,4,4,"['The introduction of a two-policy adversarial game is novel and addresses the challenges in unsupervised reinforcement learning.', 'Theoretical results provide a strong foundation for the claims made regarding the effectiveness of the proposed method.', 'Experiments show that Adversarial Surprise outperforms several state-of-the-art baselines in terms of exploration and transfer learning.']","['The clarity of the presentation is lacking; the paper could benefit from a more structured and straightforward exposition of the method, particularly in the theoretical sections.', 'The notation used in the theoretical sections is complex and may be difficult for readers to follow, potentially obscuring the main contributions.', 'Some results are presented without sufficient context or explanation, making it hard to evaluate their significance fully.', 'The empirical evaluation may not cover a broad enough range of scenarios and conditions to fully validate the proposed approach.']",3,3,2,4,Reject
js62_xuLDDv,"The paper evaluates fairness in deep metric learning (DML) methods, introducing finDML as a benchmark for fairness and proposing PARADE to mitigate biases from imbalanced data. It presents empirical results demonstrating the effectiveness of the proposed methods.","['Can the authors clarify how PARADE specifically improves fairness over traditional methods? What are the key differentiators?', 'Could the authors provide more quantitative results comparing PARADE with additional state-of-the-art methods?', 'What are the potential limitations of PARADE in practical applications, and how might they be addressed?']","['The experimental validation, while strong, could benefit from more extensive comparisons and configurations.', 'The clarity of certain sections, especially regarding the definitions and metrics, could hinder understanding.', 'The paper does not provide sufficient detail on the implementation of PARADE and its performance across various subgroup scenarios.']",True,3,3,3,6,4,"['The topic of fairness in deep metric learning is highly relevant and addresses a notable gap in the literature.', 'The introduction of finDML as a benchmark for evaluating fairness in DML is a significant contribution.', 'The empirical evidence showing bias propagation from upstream embeddings to downstream tasks is compelling.']","['The clarity of the paper could be improved, particularly in explaining the PARADE method and its advantages over existing methods.', 'The experimental section lacks a comprehensive exploration of different configurations for PARADE and comparative analyses with more DML methods.', 'Some definitions and metrics used in finDML require clearer explanations for readers unfamiliar with the topic.']",3,3,3,4,Reject
rS9t6WH34p,"The paper presents ObSuRF, a method for unsupervised segmentation of 3D scenes into objects using Neural Radiance Fields (NeRF). It claims to efficiently learn object representations from RGB-D images without explicit ray marching, achieving competitive performance on various benchmarks.","['Can the authors clarify how the components of their model interact?', 'What specific improvements does ObSuRF offer over existing methods, particularly in practical applications?', 'How is depth information integrated into the learning process?', ""What metrics were used to compare ObSuRF's performance against existing methods, and how do these metrics validate the claims made?""]","['The paper should address potential limitations regarding dataset diversity and the generalizability of the model to real-world scenarios.', 'Further exploration of how different hyperparameters affect performance could provide valuable insights.', 'The clarity of the methodology and results needs improvement to fully understand the contributions of the paper.']",False,3,2,3,5,4,"['Addresses a significant challenge in 3D scene understanding by focusing on unsupervised object segmentation.', 'Introduces a novel training approach that enhances computational efficiency, particularly with RGB-D inputs.', 'Provides a thorough evaluation on both 2D and 3D datasets, demonstrating the effectiveness of the proposed method.']","['Lacks clarity in the description of the overall architecture and methodology, which may hinder reproducibility.', 'Comparative analyses against existing state-of-the-art methods in 3D segmentation are limited, making it difficult to assess the true impact of the results.', 'The novelty of the approach relative to current techniques is not clearly articulated, especially in the context of existing literature.']",3,3,2,3,Reject
VqzXzA9hjaX,"The paper introduces the concept of Optimizer Amalgamation, aiming to combine various existing optimizers into a single optimized algorithm. It proposes several amalgamation mechanisms and stability techniques to improve performance and reduce variance. The experimental results show some promising performance improvements compared to existing optimizers.","['Can the authors provide clearer explanations for the proposed amalgamation methods?', 'What specific contributions does this work make beyond existing knowledge distillation and optimizer training methods?']","['The paper does not adequately address the limitations of the proposed approach or acknowledge potential downsides.', 'There is insufficient discussion on the implications of the results and potential applications in real-world scenarios.']",False,3,2,3,5,4,"['Addresses a relevant and practical problem in the optimization domain.', 'The proposed amalgamation strategies are innovative and provide a way to leverage multiple optimizers.', 'The experimental results demonstrate some improvement over baseline optimizers.']","['The clarity of the presentation is lacking; some concepts and methods are not well explained, particularly the amalgamation mechanisms.', 'The experimental evaluation lacks depth, with limited analysis of results across different settings.', 'The originality of the work is questionable as it builds heavily on existing concepts without clearly stating the new contributions.']",3,3,2,4,Reject
vdbidlOkeF0,"The paper introduces the Scaled Density Ratio Estimator (SDRE) for estimating density ratios, claiming it addresses issues with existing methods in situations where distributions are well-separated. The authors provide a theoretical foundation based on scaled Bregman divergence and empirical evaluations to support their claims, but the clarity and depth of these evaluations are lacking.","['Could the authors clarify the theoretical guarantees for the proposed SDRE method?', 'How does SDRE compare to other methods beyond the examples provided? Are there any limitations in specific distributions or scenarios?', 'Can the authors provide more detailed explanations of the scaling measures used in the experiments?']","['The clarity of the presentation is a major concern, which may hinder understanding and reproducibility.', 'The paper does not sufficiently address the limitations of the proposed method or the scenarios where it may not perform well.']",True,2,2,3,5,4,"['The proposed SDRE method offers a novel approach to density ratio estimation, potentially addressing limitations of existing methods.', 'The theoretical foundation based on scaled Bregman divergence is a significant contribution.', 'Empirical evaluations demonstrate the performance of SDRE across various datasets, indicating its practical applicability.']","['The presentation lacks clarity in describing the methodology, making it difficult to fully grasp the proposed approach.', 'The empirical results do not convincingly demonstrate significant improvements over existing methods, and the experimental setups lack sufficient detail.', 'The theoretical guarantees for SDRE need to be more explicitly stated and discussed; the paper should address potential limitations and assumptions.']",3,2,2,3,Reject
7AzOUBeajwl,"The paper proposes a novel approach to text style transfer that accounts for confounding factors by using invariant classifiers to separate style from other characteristics. It aims to achieve sentiment transfer while preserving the underlying content. The empirical evaluations suggest improvements over existing methods, but the execution and clarity of the methodology are lacking.","['Can the authors provide a more detailed explanation of the invariant classifiers and their training process?', 'What specific advantages does the proposed method offer over previous methods in practical applications?', 'Could the authors include more qualitative examples to illustrate the benefits of their method?']","['Lack of clarity in methodology raises concerns about reproducibility.', 'Limited experimental validation on diverse datasets.']",False,2,2,2,4,4,"['Innovative approach to style transfer that addresses confounding factors.', 'The use of invariant classifiers is a novel contribution.', 'Empirical evaluations show promise in sentiment transfer tasks.']","['The methodology lacks clarity, making it difficult to follow the training and evaluation of invariant classifiers.', 'Experimental results are not well justified, raising concerns about their validity.', 'The writing style is convoluted, affecting overall readability.']",3,2,2,3,Reject
nsjkNB2oKsQ,"The paper introduces a framework for deep reinforcement learning that addresses the challenge of delayed rewards in non-Markovian environments. It proposes a new Q-function formulation and an HC-decomposition rule aimed at improving training efficiency and stability, supported by theoretical guarantees and extensive experimental results demonstrating superior performance over existing methods.","['Can the authors clarify how the HC-decomposition framework can be universally applied to other reinforcement learning tasks?', 'Could the authors provide more extensive comparisons with a wider range of existing RL algorithms in their experimental evaluation?', 'What specific choices were made for hyperparameters during experiments, and how did they impact results?']","['The paper does not sufficiently address the limitations of the proposed algorithms, especially in terms of scalability to very high-dimensional problems.', 'There is minimal discussion on potential negative societal impacts arising from the applications of delayed reward RL.', 'The clarity of the HC-decomposition framework needs to be improved to ensure that readers can replicate the proposed methods.']",False,3,2,3,6,4,"['Addresses a significant challenge in reinforcement learning related to delayed rewards.', 'Introduces a theoretically grounded framework with a novel Q-function formulation that improves convergence guarantees.', 'Extensive experiments showing superior performance compared to existing methods, enhancing the credibility of the proposed approach.']","['The clarity of presentation is lacking; key concepts are densely packed, making it hard to follow, particularly in the sections discussing the HC-decomposition framework.', 'Some terms and methodologies are not sufficiently explained, which could lead to misunderstandings, especially for readers unfamiliar with delayed reward scenarios.', 'While the experiments are comprehensive, additional comparisons with a wider range of existing methods would strengthen the paper.']",3,3,2,4,Reject
2hMEdc35xZ6,"The paper presents Defect Transfer GAN (DT-GAN), which aims to enhance data availability for defect detection in industrial production lines by generating synthetic defective samples. The approach focuses on disentangling defect-specific content from the background, allowing for diverse defect generation across different product types. Experiments demonstrate the effectiveness of DT-GAN in producing realistic samples and improving classification performance.","['Could the authors clarify the methodology, particularly the interaction between different components of the DT-GAN?', 'Will the authors consider conducting more thorough ablation studies to better understand the contribution of each component?', 'How does the proposed method compare to other state-of-the-art methods in practical applications beyond the datasets used?']","['The paper does not fully address the limitations of the proposed method, particularly in terms of its scalability and applicability to other types of defects or industries.']",False,3,3,3,5,4,"['Addresses a significant problem in industrial defect detection by generating synthetic data to mitigate the scarcity of defective samples.', 'Introduces a novel framework (DT-GAN) that effectively combines existing GAN architectures with style-content separation and foreground-background disentanglement.', 'Provides extensive quantitative and qualitative evaluations on real industrial datasets, demonstrating the effectiveness and practical applicability of the proposed method.']","['The originality of the approach is somewhat limited, as it heavily relies on existing GAN frameworks without introducing substantial theoretical innovations.', 'Clarity issues in the description of the methodology, particularly regarding the interaction between different components of the GAN.', 'Lacks comprehensive ablation studies that would help to clearly establish the contribution of each component of the method.', 'Some experimental results lack statistical significance and robustness, raising concerns about the generalizability of the findings.']",3,3,3,4,Reject
uHv20yi8saL,"The paper presents a new monotonic improvement guarantee for optimizing decentralized policies in cooperative Multi-Agent Reinforcement Learning (MARL), applicable under non-stationary conditions. It provides a theoretical foundation for the strong performance of Independent Proximal Policy Optimization (IPPO) and Multi-Agent PPO (MAPPO), demonstrating how bounding independent ratios enforces a trust region constraint. Empirical results support the hypothesis that this approach effectively enhances performance in MARL tasks.","['Could you clarify how the new guarantees directly impact the performance of IPPO and MAPPO in practice?', 'What are the implications of your findings for the choice of hyperparameters, especially as the number of agents changes?', 'Can you provide more detailed explanations in the proofs to enhance understanding?']","['The paper lacks clarity in presenting complex theoretical concepts and proofs.', 'Empirical results need a deeper exploration of how varying agent counts affect performance and trust region enforcement.']",False,3,3,3,6,4,"['Addresses a significant theoretical gap in the understanding of decentralized policies in MARL.', 'Introduces a novel monotonic improvement guarantee applicable under non-stationarity.', 'Empirical results support the theoretical claims, demonstrating the effectiveness of the proposed methods.']","['The presentation could be clearer, as some sections are difficult to follow, particularly the theoretical analysis.', 'There are clarity issues in the presentation of theoretical constructs and empirical results that could be improved.', 'The paper would benefit from additional ablation studies or comparisons with alternative methods to validate the proposed approach comprehensively.']",3,3,4,4,Reject
5FUq05QRc5b,"The paper presents a theoretical framework for understanding latent correlation maximization in multiview learning, proposing a generative model to identify and disentangle shared and private components. It includes finite sample analysis and introduces a minimax regularizer. However, the empirical validation is limited, primarily relying on synthetic datasets.","['Can the authors provide more details on the practical implications of their theoretical findings?', 'What are the potential limitations of their approach when applied to real-world datasets?']","['The theoretical insights may not translate well into practical applications without further empirical validation.', 'The reliance on synthetic data raises concerns about the applicability of the findings in more complex, real-world scenarios.']",False,3,2,3,5,4,"['The theoretical contributions address a significant gap in understanding latent correlation maximization in multiview learning.', 'The finite-sample analysis is a valuable addition to the literature.', 'The use of a generative model provides a solid foundation for the proposed methods.']","['The clarity of the writing could be improved, particularly in articulating the implications of the theoretical results.', 'Empirical evaluations rely heavily on synthetic datasets, which may not generalize well to real-world scenarios.', 'The explanations of the proposed regularization techniques and their justifications are not sufficiently detailed.']",3,2,2,3,Reject
Py8WbvKH_wv,"The paper proposes DRIBO, a method leveraging a Multi-View Information Bottleneck (MIB) to enhance the robustness of deep reinforcement learning (DRL) agents against visual distractions and improve generalization in unseen environments. It claims state-of-the-art performance on various benchmarks, including the DeepMind Control Suite and Procgen.","['How does the proposed MIB differ fundamentally from existing representation learning techniques in the context of DRL?', 'Can the authors provide more insights into the failure cases of DRIBO in certain environments?', 'What specific architecture and hyperparameters were used in the experiments, and how were they chosen?']","['The paper does not adequately address potential limitations or failure modes of the proposed approach.', 'The clarity of the methodology and theoretical background is insufficient, which may lead to misunderstandings.']",False,2,2,3,5,4,"['Addresses a significant challenge in DRL related to robustness and generalization.', 'Introduces a novel Multi-View Information Bottleneck approach that contextualizes the sequential nature of reinforcement learning.', 'Demonstrates promising empirical results across diverse visual control tasks.']","['The originality of the contribution is questionable, with overlaps to existing techniques in representation learning.', 'The clarity of the presentation is lacking, making it difficult for readers to grasp the methodology and contributions.', 'The experimental section lacks depth, particularly in comparative analysis and ablation studies.']",3,3,2,3,Reject
R11xJsRjA-W,"The paper investigates the relationship between out-of-distribution (OOD) generalization and privacy in machine learning models, particularly through membership inference (MI) attacks. It claims that better OOD generalization does not imply better membership privacy and emphasizes the importance of stable feature learning. The authors conduct extensive empirical evaluations across various datasets, providing insights relevant to both domain generalization and privacy communities.","['Could the authors clarify how they define stable features in the context of OOD generalization?', 'What specific metrics were used to evaluate the stability of features, and how were these metrics validated?', 'Can the authors provide more detailed explanations regarding the implications of their findings for practitioners?']","['The paper lacks sufficient clarity and depth in theoretical explanations, which may hinder understanding.', 'The results would benefit from additional qualitative analysis and more detailed ablation studies to substantiate claims.']",False,3,3,3,5,4,"['Addresses a critical intersection of topics in machine learning: OOD generalization and privacy.', 'Extensive empirical evaluations across multiple datasets enhance the credibility of the claims.', 'Provides important insights that challenge existing assumptions about the relationship between generalization and privacy.']","['The clarity of the writing is lacking; several sections are dense and difficult to navigate.', 'The theoretical foundations and assumptions are not clearly articulated, leading to confusion about the applicability of findings.', 'Empirical results lack depth in analysis and interpretation, and some experimental setups appear underexplored.']",3,3,3,4,Reject
5xEgrl_5FAJ,"The paper proposes BiBERT, a fully binarized version of BERT aimed at reducing computational and memory overhead while maintaining performance. It identifies two key issues affecting performance: information degradation in the attention mechanism and optimization direction mismatch during training. Solutions include a Bi-Attention structure and Direction-Matching Distillation (DMD) scheme.","['Can the authors clarify how BiBERT compares to the latest advancements in BERT quantization?', 'Could additional experiments be conducted to benchmark against other recent models?', 'How do the authors justify the claimed improvements in performance given the limitations of the proposed methods?']","['Original contributions may not significantly advance the field given existing literature on quantization.', 'Insufficient experimentation on recent models limits the credibility of performance claims.']",False,2,2,2,4,4,"['Addresses a relevant problem of model efficiency in NLP with promising claims.', 'Introduces a clear analysis of the issues faced by fully binarized BERT models.', 'Provides extensive experimental results demonstrating significant reductions in FLOPs and model size.']","['Lacks sufficient novelty; while the approach is interesting, the concepts of quantization and binarization are well-established.', 'Inadequate comparison with state-of-the-art quantization methods raises concerns about the claimed performance improvements.', 'The clarity of mathematical formulations and experimental design could be significantly improved.']",3,2,2,3,Reject
iGffRQ9jQpQ,"The paper introduces a novel framework called Self-interested Coalitional Learning (SCL) aimed at enhancing semi-supervised learning by integrating a companion task that infers label observability. This joint approach seeks to leverage both labeled and unlabeled data more effectively, potentially reducing reliance on labeled data and mitigating error accumulation issues. The framework is theoretically grounded and empirically evaluated across various tasks.","['Could you clarify the specific advantages of SCL over existing semi-supervised learning methods?', 'What are the implications of using the proposed method in scenarios with highly noisy labels?', 'Can the authors provide more details on the practical implementation of SCL and how it quantitatively compares with other frameworks?', 'What specific ablation studies can be conducted to further assess the impact of the various components of SCL?']","['The complexity of the proposed framework may limit its practical applicability.', 'Lack of thorough empirical validation against a broader set of benchmarks undermines the claims of effectiveness.', 'The clarity of the paper is a significant concern, particularly in explaining the theoretical aspects of SCL.']",True,2,2,2,4,4,"['Addresses the critical challenge of over-reliance on labeled data in semi-supervised learning.', 'Integrates a companion task to enhance information extraction from unlabeled data.', 'Theoretical insights connecting self-interested learning to loss reweighting on noisy labels are noteworthy.']","['The conceptual framework is complex and convoluted, making it challenging to follow the proposed methodology.', 'Empirical evaluations lack comprehensive comparisons with state-of-the-art methods, failing to convincingly demonstrate the superiority of SCL.', 'The writing lacks clarity, which may lead to misunderstandings of the proposed method and its contributions.', 'The significance of the results is questionable, as performance improvements are not substantial compared to existing methods.', 'The paper does not adequately address ethical considerations regarding the use of pseudo-labels in sensitive applications.']",2,2,2,3,Reject
bVT5w39X0a,"The paper introduces a novel method called multi-modal Relational Neural Process (mRNP), aimed at improving generative modeling for multi-modal data. The authors propose a stochastic process that learns dependencies between samples across different modalities while providing robust uncertainty estimates. The method utilizes mixture-of-graphs to address the limitations of existing generative models in multi-modal settings. Experimental results demonstrate advantages in prediction accuracy and uncertainty quantification compared to baseline methods.","['Could the authors provide more details on the specific hyperparameters used in the experiments?', 'Will the authors consider including additional ablation studies to strengthen the validation of their model?', 'Can the authors clarify the relationship between mRNP and existing generative models, particularly in terms of novelty?', 'What specific improvements in uncertainty estimation does mRNP achieve over existing methods, and how are these measured?']","['The theoretical underpinnings of the proposed method need clearer articulation to ensure that readers can fully grasp the concepts being presented.', ""More extensive experimental validation is required to demonstrate the model's performance across various scenarios and data distributions."", 'The paper does not adequately explore the limitations of the proposed approach or provide a robust discussion on potential negative societal impacts.']",False,2,2,3,5,4,"['The proposed mRNP framework effectively addresses key limitations of existing multi-modal generative models, particularly regarding uncertainty estimation and computational efficiency.', ""The introduction of mixture-of-graphs (MoG) is a novel approach that enhances the model's ability to handle diverse data types."", 'The experimental results indicate that mRNP outperforms state-of-the-art methods in both predictive accuracy and uncertainty quantification.']","['The paper lacks clarity in presenting the theoretical foundations of mRNP, making it difficult to follow the rationale behind certain design choices.', 'Experimental validation could be improved with more comprehensive ablation studies to test the robustness of the proposed methods under various conditions.', ""The description of the model's implementation details is somewhat superficial, lacking specific information on hyperparameters and training protocols."", 'The connection between the proposed method and existing works is not clearly articulated, leading to potential confusion about its novelty.']",3,2,2,4,Reject
I2Hw58KHp8O,"The paper proposes the Conditional Masked Language Model with Correction (CMLMC), which addresses shortcomings in existing non-autoregressive (NAR) translation models, specifically focusing on token distinguishability and training-inference alignment. CMLMC demonstrates state-of-the-art performance on multiple translation datasets without the need for distillation, making it a significant advancement in non-autoregressive machine translation.","['Can the authors elaborate on the specific hyperparameters used and how they were selected during the experiments?', 'Could the authors provide additional qualitative examples to better illustrate the performance improvements?', 'What specific challenges did the authors face when implementing the proposed corrections in practice?']","['The clarity of the explanations around architectural modifications and training procedures could be improved.', ""More context on the empirical results would strengthen the understanding of the model's performance."", 'The paper does not sufficiently address potential limitations of the proposed model, such as scalability or performance on low-resource languages.']",False,3,3,4,7,4,"['Significant contribution to the non-autoregressive machine translation field by addressing key performance issues without relying on distillation.', 'Empirical results demonstrate that CMLMC achieves state-of-the-art performance on multiple datasets, which is an important advancement.', 'The proposed model effectively integrates architectural modifications and a correction loss, showing a comprehensive understanding of the challenges in NAR translation.']","['Some sections lack clarity, particularly the detailed explanation of the proposed modifications and how they were implemented.', 'The paper could provide more context around the empirical results, such as how the choice of hyperparameters affected performance.', 'The organization of the paper could be improved for better clarity, as some sections are dense and can be challenging to follow.']",4,3,3,4,Accept
bilHNPhT6-,"The paper proposes a multi-objective reinforcement learning (MORL) approach called DiME, which aims to improve policy optimization in deep reinforcement learning by replacing linear scalarization with a more effective method. The authors apply this perspective to offline RL and finetuning case studies, claiming enhanced performance over state-of-the-art methods. They provide theoretical backing and experimental results to support their claims.","['Could the authors clarify the robustness of their experimental results and address potential overfitting?', 'Can the authors provide additional details on the comparative performance of DiME versus other methods across a wider range of tasks?', 'Can the authors clarify how DiME improves upon existing MORL methods in a way that is practically applicable?']","['The paper does not sufficiently address limitations regarding the generalizability of the results to other RL scenarios outside of the studied case studies.', 'The clarity and reproducibility of the results could be significantly improved.', 'The limitations of the experimental results need to be addressed, particularly in terms of diversity and comprehensiveness of the benchmarks used.']",False,3,3,3,5,4,"['The approach of interpreting RL challenges through the lens of multi-objective optimization is innovative and provides a fresh perspective to existing problems.', 'DiME is theoretically grounded and offers a promising alternative to linear scalarization in multi-objective RL settings.', 'The experimental results demonstrate that DiME outperforms state-of-the-art methods in specific tasks, indicating its potential effectiveness.']","['The paper lacks sufficient detail in the experimental methodology, making it difficult to assess the robustness of the results.', 'There are potential concerns regarding overfitting, particularly in the finetuning experiments, which may have influenced the reported performance metrics.', 'Some sections of the paper, particularly the theoretical derivations, could be clearer to enhance understanding and reproducibility.', 'The experimental evaluation is limited and lacks comprehensive comparisons across a broad set of benchmarks, which raises questions about the generalizability of the results.']",4,3,3,4,Reject
LQCUmLgFlR,"The paper investigates the relationship between optimal early stopping time and model dimension/sample size in neural networks, distinguishing between overparameterized and underparameterized settings. It provides theoretical results and empirical evidence to support its claims, particularly regarding the mitigation of the 'double descent' phenomenon.","['Can the authors provide clearer definitions and explanations for the concepts presented, particularly regarding the implications of overparameterization?', 'What additional experiments could strengthen the validation of the theoretical claims, especially in real-world applications?']","['The theoretical contributions are not well-articulated, making it challenging to appreciate their significance in the broader context of machine learning.', 'The experiments do not sufficiently explore the implications of the findings, particularly in relation to different model architectures.']",False,3,2,3,4,4,"['Addresses a significant and timely topic in deep learning related to early stopping and generalization, which is crucial for practical applications.', 'The distinction between overparameterization and underparameterization offers valuable theoretical insights, enhancing our understanding of model behavior in different contexts.', ""Includes experimental validation that demonstrates the applicability of the theoretical results across various datasets, reinforcing the paper's claims.""]","['The theoretical exposition is convoluted and lacks clarity, making it difficult for readers to grasp key findings and their implications for practice.', 'The experimental section could be more comprehensive, potentially including additional datasets or scenarios to convincingly validate the theoretical claims.', ""Some figures lack sufficient explanation, which hinders the reader's understanding of their significance and relevance to the findings.""]",3,2,2,3,Reject
rbFPSQHlllm,"The paper proposes AutoMO-Mixer, an automated multi-objective model for medical image diagnosis that aims to balance sensitivity and specificity through a multi-objective optimization approach. It utilizes a modified MLP-Mixer architecture and Bayesian optimization for hyperparameter tuning, claiming improved performance over conventional CNNs.","['How does AutoMO-Mixer significantly improve upon existing models beyond the multi-objective aspect?', 'What measures have been taken to ensure the findings are generalizable across different medical imaging datasets?', 'Can the authors elaborate on the limitations of their study and potential ethical implications?']","['The paper does not adequately address the limitations and potential societal impact of using automated models in medical diagnostics.', 'The reliance on a small number of datasets for validation may not reflect real-world applications effectively.']",True,2,2,2,3,4,"['Addresses the important challenge of balancing sensitivity and specificity in medical diagnostics.', 'Incorporates Bayesian optimization for hyperparameter tuning, which can enhance model performance.', ""Experimental validation on public datasets demonstrates the model's effectiveness.""]","['The novelty of AutoMO-Mixer compared to existing models is not clearly established, as many concepts appear derivative.', 'The methodology lacks clarity, making it difficult to fully understand the proposed approach.', 'Results are limited to two datasets, raising concerns about the generalizability of the findings.', 'The discussion on limitations and ethical implications of automated models in medical diagnostics is insufficient.']",2,2,2,3,Reject
ms7xJWbf8Ku,"The paper presents packing algorithms designed to enhance the efficiency of BERT pre-training by reducing padding overhead, achieving up to 2x speed-up without loss of accuracy. It details two algorithms and provides empirical results based on the Wikipedia dataset.","['Can the authors clarify how their packing methods differ from existing solutions?', 'What limitations might their approach face when applied to different datasets or architectures?', 'Could the authors provide more extensive results on the performance of packing algorithms across various datasets?']","['The paper does not adequately address the practical limitations and implications of the proposed methods in diverse real-world scenarios.', 'The reliance on specific characteristics of the Wikipedia dataset may limit the generalizability of the findings.']",False,3,3,3,5,4,"['Addresses a significant issue in NLP model training related to padding tokens.', 'Introduces efficient algorithms with linear time complexity suitable for large datasets.', 'Demonstrates substantial performance improvements in training time without sacrificing model quality.']","['The originality of the methods is limited as they adapt existing strategies rather than introducing novel approaches.', 'Experimental validation is primarily focused on the Wikipedia dataset, raising concerns about generalizability.', 'The clarity of the presentation could be improved, making it challenging for readers to implement or replicate the methods.']",2,3,3,4,Reject
nwKXyFvaUm,"The paper presents DivFL, a method for selecting a diverse subset of clients in federated learning using submodular maximization. This approach aims to enhance learning efficiency, convergence speed, and fairness among clients. The authors provide theoretical convergence analysis and empirical results on synthetic and real datasets supporting their claims.","['Can the authors clarify the methodology for client selection, particularly the optimization of the submodular function?', 'Would the authors consider conducting additional ablation studies to demonstrate the robustness of their approach?']","['Clarity in some sections could be improved for better reader understanding.', 'While empirical results are promising, a more comprehensive evaluation of the proposed method is needed.']",False,3,3,3,7,4,"['Addresses a critical issue in federated learning related to client selection and redundancy.', 'Innovative use of submodular maximization to improve client diversity.', 'Includes theoretical convergence analysis, adding value to the understanding of the method.', 'Empirical results demonstrate improvements in convergence speed and fairness across clients.']","['The presentation is dense; some concepts could be explained more clearly.', 'Empirical evaluations could be more comprehensive, with detailed comparisons to baseline methods.', 'Insufficient ablation studies to isolate the effects of different components of the proposed method.', 'Some claims regarding fairness and efficiency would benefit from additional quantitative analysis.']",3,3,3,4,Reject
anbBFlX1tJ1,"The paper introduces Boosted Curriculum Reinforcement Learning (BCRL), which enhances action-value function approximation by modeling it as a sum of residuals learned from previous tasks. The method aims to improve the representativeness of the functional space as tasks become more complex, supported by theoretical analysis and empirical results demonstrating its advantages over traditional methods.","['Could the authors provide additional clarity on how BCRL integrates boosting into the curriculum learning framework?', 'What measures were taken to ensure that the experimental results are robust and not overly reliant on specific environments?']","['The complexity of the mathematical formulations may hinder understanding, suggesting a need for clearer explanations.', 'The experimental results, while promising, could benefit from more diverse testing conditions to validate the generalizability of BCRL.']",False,3,3,3,6,4,"['The introduction of boosting concepts into curriculum learning is innovative and offers a fresh perspective on improving action-value function approximations.', 'The theoretical framework provided for BCRL is sound and offers insights into its convergence properties and advantages over traditional methods.', 'Empirical results indicate that BCRL outperforms standard curriculum RL methods in various experimental settings, showcasing its practical relevance.']","['The paper lacks clarity in explaining key concepts and methodology, particularly in how the boosting mechanism integrates with the curriculum learning framework.', 'The experimental validation, while promising, could be strengthened with additional environments and tasks to robustly demonstrate the efficacy of BCRL.', 'Some sections contain dense mathematical formulations that may benefit from simplification and more intuitive explanations.']",3,3,3,4,Reject
JVWB8QRUOi-,"The paper proposes a novel approach to promote cooperation among self-interested agents in sequential social dilemmas using homophilic incentives. It identifies the issue of second-order social dilemmas caused by incentivizing mechanisms that lead to unstable cooperation. The proposed method encourages agents with similar behaviors to adopt similar incentivizing behaviors, resulting in improved cooperation dynamics. The method is evaluated empirically across multiple scenarios, demonstrating its effectiveness in achieving stable cooperation.","['Can the authors clarify the theoretical rationale behind the homophily mechanism and how it specifically addresses second-order social dilemmas?', 'What additional analyses can be conducted to validate the stability of cooperation under the proposed framework?']","['The paper could benefit from a stronger discussion on the limitations of the proposed approach, including potential scenarios where homophily might not be effective.', 'The reliance on specific parameters without extensive sensitivity analysis may limit generalizability.']",False,3,2,3,6,4,"['Addresses a significant problem in multi-agent reinforcement learning regarding cooperation in sequential social dilemmas.', 'Introduces the concept of homophily as a mechanism to stabilize cooperation, which is innovative and relevant.', 'Comprehensive empirical evaluations across different scenarios, showing the effectiveness of the proposed method.']","['The clarity of the writing could be improved; some sections are dense and may confuse readers unfamiliar with certain concepts, particularly in the explanation of second-order social dilemmas.', 'The experimental results lack sufficient rigor and statistical analysis to validate the effectiveness of the proposed method, raising concerns about the robustness of the findings.', 'The analysis of oscillations in cooperation levels and the claimed resolutions are not thoroughly substantiated, leading to doubts about the reliability of the findings.']",3,3,2,4,Reject
dEelotBE6e2,The paper proposes a method to defend deep learning models against backdoor attacks using an ensemble of weak learners and an Inverse Self-Paced Learning (ISPL) algorithm. The proposed approach aims to identify and remove poisoned data from the training set by leveraging self-expansion properties. The authors claim that their method significantly outperforms existing defenses in empirical evaluations on CIFAR-10.,"['Could the authors clarify the specific assumptions required for the self-expansion property to hold?', 'What are the potential limitations of the proposed method when faced with more sophisticated backdoor attacks?', 'Can the authors provide additional details on the experimental setup and parameters used in the evaluations?', 'Can the authors clarify the theoretical foundations of their approach, particularly regarding the bootstrapped measure of generalization?']","['The paper does not thoroughly address the limitations of the proposed method, particularly in terms of its applicability to different types of backdoor attacks.', ""A more detailed analysis of the performance across varying levels of noise and different architectures would provide a better understanding of the method's robustness."", 'The paper does not sufficiently address the potential limitations or failure cases of the proposed method.']",False,3,3,4,5,4,"['Addresses a critical issue in deep learning security, specifically backdoor attacks.', 'Introduces a novel approach combining weak learners and self-expansion techniques.', 'Empirical results suggest the proposed method outperforms existing defenses across various scenarios.']","['The paper lacks clarity in several sections, making it difficult to follow the proposed methods and their theoretical underpinnings.', 'The experimental evaluation could be strengthened by including more diverse attack scenarios and comparisons with a broader range of defenses.', 'Some theoretical claims lack rigorous proof or clear justification, particularly regarding the assumptions made for the self-expansion property.', 'The originality of the proposed approach seems limited as it combines existing techniques without sufficiently distinguishing itself from previous works.']",3,3,4,4,Reject
FndDxSz3LxQ,"The paper presents a distributed training algorithm for Graph Neural Networks (GNNs) named Learn Locally, Correct Globally (LLCG). It aims to reduce communication and memory overhead while maintaining performance through local training and global server corrections. The paper provides theoretical analysis of convergence and performance degradation in existing methods, demonstrating that LLCG overcomes these issues.","['How do you plan to validate the effectiveness of LLCG across more datasets and settings?', 'Can you provide more clarity on the implementation details and how they impact the performance of LLCG?', 'Can the authors clarify how LLCG performs in scenarios with highly heterogeneous data distributions?', 'What are the implications of the proposed method in terms of privacy concerns, especially when dealing with sensitive data?']","['The clarity of the paper could limit its accessibility to the audience, which may hinder the understanding of the proposed method.', 'The assumptions made in the theoretical analysis should be more thoroughly justified with practical examples.', 'The paper does not adequately address the limitations of the proposed approach, particularly regarding its scalability and applicability to various types of graphs.']",True,3,3,3,6,4,"['The proposed algorithm effectively addresses the challenges of distributed GNN training, particularly the issues of communication and memory overhead.', 'The theoretical analysis provided is rigorous and explains the limitations of existing methods, as well as the advantages of the proposed approach.', 'Extensive experimental results are presented, showing that LLCG can achieve competitive performance while reducing communication costs.']","[""The paper's clarity could be improved, especially in explaining the nuances of the algorithm and its components."", 'The experimental evaluation is somewhat limited; more diverse datasets and settings would strengthen the claims made.', 'The practical implications of the proposed method in real-world scenarios could be better highlighted.', 'The paper primarily compares LLCG with only a few baseline methods; additional comparisons with other state-of-the-art techniques would strengthen the evaluation.', 'There is insufficient discussion regarding the limitations of the proposed approach and potential societal impacts.']",3,3,3,4,Reject
HRL6el2SBQ,"The paper proposes intra-class mixup supplemented with angular margin to improve out-of-distribution (OoD) detection in deep learning models. It claims that this method enhances the separability of in-distribution and OoD data by reducing angular spread in latent representations, leading to performance improvements in existing OoD detection techniques.","['Can the authors clarify the differences between their approach and existing methods like inter-class mixup?', 'What specific metrics were used to evaluate the impact of angular margin, and how were they computed?', 'Could the authors provide more detailed ablation studies to support their claims of improvement?']","['The paper does not sufficiently discuss the potential limitations of the intra-class mixup approach.', 'There is a risk of overfitting to the specific datasets used in experiments, which may limit generalizability.']",False,3,3,2,4,4,"['Addresses a relevant problem in deep learning: the detection of OoD samples.', 'Proposes a novel approach (intra-class mixup with angular margin) that is theoretically interesting.', 'Presents empirical results demonstrating improvements in OoD detection performance.']","['The novelty of the intra-class mixup approach may not be sufficiently distinct from existing methods, particularly inter-class mixup.', 'Methodology lacks clarity, particularly in how the angular margin is computed and its implications for model training.', 'Experimental validation needs to be more robust, with additional ablation studies and comparisons to a wider range of baselines.', 'Limited discussion on the limitations and potential drawbacks of the proposed method.']",3,4,4,3,Reject
t1QXzSGwr9,"The paper proposes a quantum machine learning framework for classifying larger images (up to 16x16 pixels) using a novel encoding mechanism that requires fewer qubits than previous work. The authors claim that their method achieves comparable accuracy to classical neural networks while requiring fewer qubits. However, the methodology and experimental results raise concerns regarding clarity, soundness, and significance.","['Can the authors provide more detailed experimental results comparing the quantum approach directly with leading classical models?', 'What specific advantages does the quantum approach present over classical methods, beyond comparable accuracy?', 'Can the authors elaborate on potential limitations and the practical implications of using their framework in real-world scenarios?']","['The results presented do not convincingly demonstrate that the quantum approach provides significant advantages over classical techniques.', 'The authors need to address the feasibility of implementing their QNN on current quantum hardware and the effects of noise, which could significantly influence performance.']",False,2,2,2,4,4,"['The idea of using quantum machine learning to handle larger image classification tasks is innovative.', 'The proposed encoding scheme, which utilizes fewer qubits, could potentially make practical quantum image classification more feasible.', 'The work addresses a significant problem in quantum machine learning by attempting to upscale image classification beyond prior limitations.']","['The experimental results show modest performance and do not consistently outperform classical models, raising questions about the practical benefits of quantum methods for image classification.', 'The methodology lacks sufficient detail, particularly in the construction and training of the quantum neural network, making replication challenging.', 'The paper does not provide thorough comparisons with state-of-the-art classical methods, which is crucial for evaluating the effectiveness of the quantum approach.', 'Many claims regarding the advantages of quantum over classical approaches are not convincingly supported by comprehensive experiments.', 'The paper does not adequately address potential limitations and challenges of implementing quantum neural networks for practical image classification tasks.']",3,2,2,4,Reject
e0uknAgETh,This paper investigates the vulnerability of spiking neural networks (SNNs) to adversarial attacks in the context of event-based vision systems. The authors adapt existing white-box attack algorithms to the discrete and sparse nature of event-based data and demonstrate the effectiveness of these perturbations on neuromorphic hardware using datasets such as N-MNIST and IBM Gestures.,"['What are the specific implications of the findings for the design and deployment of SNNs in real-world applications?', 'Can the authors elaborate on the limitations of their approach and suggest potential defensive strategies against the identified attacks?']","['The paper does not thoroughly address the broader implications of adversarial attacks on SNNs in practical applications.', 'The lack of clarity in the explanation of key concepts may hinder the understanding of the proposed methods.']",True,3,3,4,6,4,"['Addresses the critical and timely issue of adversarial attacks on neuromorphic systems, which is increasingly relevant as these technologies are deployed in real-world applications.', 'Demonstrates a novel application of adversarial techniques in the context of event-based vision, contributing to the understanding of SNN vulnerabilities.', 'Provides comprehensive experimental results that quantify the effectiveness of various adversarial attack strategies on SNNs and validates them on neuromorphic hardware.']","['The discussion on the implications of the results and potential future research directions is somewhat superficial and could be expanded.', 'The clarity of the presentation is hindered by excessive jargon and insufficient explanations of key concepts, making it challenging for readers who are not specialists in the field.', 'While the experiments yield valuable insights, the adaptation of existing algorithms to SNNs could be enhanced with more innovative approaches or novel attack strategies.', 'A more thorough analysis of the limitations of the proposed methods and potential countermeasures against adversarial attacks would strengthen the paper.']",4,3,3,4,Reject
8XM-AXMnAk_,"The paper proposes dynamicAL, a theory-driven deep active learning method that utilizes training dynamics to maximize generalization performance. The authors establish a theoretical framework correlating training dynamics with convergence and generalization, and provide empirical results demonstrating the method's effectiveness in various settings.","['Can the authors clarify the implications of the relaxations introduced, particularly in terms of their impact on the results?', 'What steps could be taken to enhance the experimental validation of dynamicAL against a wider range of baselines?', ""Can the authors provide clearer definitions for key concepts like 'training dynamics' and 'alignment'?""]","['The paper does not sufficiently address the limitations associated with using pseudo-labels in active learning, particularly their potential impact on performance.', 'The clarity of the theoretical analysis and certain experimental aspects need improvement.']",False,3,3,4,6,4,"['The theoretical foundation linking training dynamics to generalization performance is novel and insightful.', 'Empirical results demonstrate that dynamicAL consistently outperforms various baseline methods across several datasets.', 'The method is scalable and shows promise for practical applications in active learning.']","[""The paper lacks clarity in defining key concepts, such as 'training dynamics' and 'alignment', making it difficult for readers to fully grasp the proposed concepts."", 'The experimental evaluation is not comprehensive enough, lacking a broad comparison with a diverse set of contemporary active learning methods.', 'The reliance on pseudo-labeling raises concerns regarding the robustness of dynamicAL in real-world scenarios.']",3,3,2,3,Reject
qZNw8Ao_BIC,"This paper investigates the robustness of Vision Transformers (ViTs) by examining their reliance on non-robust features exposed through patch-based transformations. The authors propose a novel approach called patch-based negative augmentation, which aims to reduce the model's reliance on these non-robust features to enhance its robustness against out-of-distribution data. They show that this method consistently improves ViT performance across various robustness benchmarks, indicating its potential for enhancing ViT training.","['Could you clarify the implementation details for the negative augmentation strategy and how it compares with existing augmentation approaches?', 'What specific measures have been taken to ensure that the transformations used do not overlap with corruption types in existing benchmarks?']","['The clarity of the methodology and results could be improved to ensure that the contributions are fully understood and reproducible.', 'The paper does not sufficiently address potential limitations or downsides of using negative augmentations, especially in terms of computational efficiency and model complexity.']",False,3,3,3,7,4,"['Addresses a significant challenge in the robustness of ViTs and provides empirical evidence of their reliance on non-robust features.', 'Introduces a novel negative augmentation strategy that shows potential for enhancing the robustness of ViTs.', 'Comprehensive experiments demonstrate the effectiveness of the proposed methods across various benchmarks.']","['The explanations of the methodologies, particularly around negative augmentations and their combinations with existing methods, lack clarity.', 'Some experimental comparisons could be more comprehensive to strengthen the claims (e.g., comparisons with more diverse augmentation strategies).', 'The paper could better contextualize the results within existing literature on robustness and augmentation techniques.']",3,3,3,4,Reject
RLtqs6pzj1-,"The paper introduces FreeTickets, an ensemble learning framework that utilizes dynamic sparse training to create efficient subnetworks for improved performance in predictive accuracy, uncertainty estimation, and out-of-distribution robustness. The authors claim that FreeTickets can achieve better results than traditional dense ensembles with significantly lower computational costs.","['Could the authors clarify the specific innovations in the training process that distinguish FreeTickets from existing ensemble methods?', 'What measures have been taken to ensure the reproducibility of experimental results, especially regarding different architectures?', 'How do the authors envision the application of FreeTickets in real-world scenarios considering potential computational constraints?']","['The paper does not sufficiently address the trade-offs between sparsity and model expressiveness in practical applications.', 'There is a lack of a thorough comparative analysis with other state-of-the-art methods beyond just ensemble comparisons.']",False,3,2,3,6,4,"['The proposed FreeTickets framework presents an innovative connection between sparse neural network training and deep ensemble methods.', 'The empirical evaluations demonstrate significant improvements in predictive accuracy, uncertainty estimation, and efficiency.', 'The analysis of diversity among subnetworks generated by the proposed methods adds depth to the findings.']","['The writing lacks clarity in some sections, making it difficult to follow the methodology.', 'The paper could benefit from a more structured presentation of experiments and results to enhance readability.', 'There is limited discussion on the potential limitations and generalizability of the proposed methods across different datasets and architectures.']",3,3,2,4,Reject
kHNKTO2sYH,"The paper introduces Clean Subspace Variational Autoencoder (CLSVAE), a semi-supervised model designed to detect and repair systematic outliers in datasets by partitioning the latent space into clean and dirty subspaces. The method aims to leverage less labeled data for effective outlier management, with experiments demonstrating superior performance compared to existing models across three image datasets with varying levels of corruption.","[""Can the authors provide more details on the model's limitations and potential scenarios where it might fail?"", 'Could the authors clarify the rationale behind the choice of hyperparameters and how they were determined experimentally?', 'Can the authors discuss more extensively how their results compare to existing state-of-the-art methods beyond the selected baselines?']","[""The paper does not address the potential impact of the model's assumptions on its performance, particularly in varying levels of systematic error."", 'More comprehensive baselines and comparisons against state-of-the-art methods in anomaly detection and data repair are needed for a robust evaluation.']",False,3,2,3,5,4,"['Addresses a relevant issue in data preprocessing—systematic outliers—and proposes an innovative solution using variational autoencoders.', 'Demonstrates significant improvements in repair quality with minimal labeled data, which is a valuable contribution.', ""The model's architecture, focusing on the separation of clean and dirty patterns, is theoretically sound and well-motivated.""]","['The presentation lacks clarity in several sections, particularly in the explanation of the model architecture and the training process, making it difficult for readers to grasp the full implications of the proposed methods.', 'The evaluation is somewhat limited in scope and does not include a diverse range of baseline comparisons across various settings, which could strengthen the claims of superiority.', 'The paper does not sufficiently discuss limitations or potential failure modes of the proposed model, which is critical for practical applications.']",3,3,2,4,Reject
izj68lUcBpt,"The paper presents Temporally-Adaptive Convolutions (TAdaConv), a method that adaptively calibrates convolution weights based on temporal context to enhance video understanding. The authors claim improved performance on various benchmarks and suggest that TAdaConv can be integrated into existing models with low computational overhead.","['Can the authors clarify how TAdaConv fundamentally differs from existing dynamic convolution methods?', 'Could the authors provide more detailed ablation studies to better support the claims made about the effectiveness of different components?', 'What are the limitations of TAdaConv in scenarios with less available training data or more complex temporal dynamics?']","['The paper does not adequately address potential limitations of the proposed method, particularly in terms of generalizability and performance on unseen datasets.', 'The clarity of the technical exposition could be improved, particularly in explaining the methodology and results of the ablation studies.']",False,3,2,3,6,4,"['The concept of adapting convolution weights based on temporal context is innovative and addresses limitations in traditional convolutional approaches for video analysis.', 'Experimental results indicate competitive performance improvements across multiple datasets, showcasing the potential of TAdaConv.', 'The proposed method can be integrated into existing architectures, enhancing its applicability.']","['The paper lacks clarity in technical details, particularly regarding the calibration process and the results of the ablation studies.', 'The originality of the contribution is diminished by similarities to existing dynamic filtering methods, and the paper does not sufficiently position itself against these.', 'The experimental validation is limited, and broader evaluations across diverse tasks are needed to substantiate the claims.']",3,3,3,4,Reject
dzZQEvQ6dRK,"This paper investigates the use of self-supervised contrastive learning methods, particularly BYOL, for learning disentangled representations. The authors propose that contrastive methods can achieve a 'group disentanglement' property, which is a relaxed version of traditional disentanglement. They provide empirical evidence demonstrating that contrastive learning methods perform well on several benchmarks, including both synthetic and real-world datasets.","['What are the implications of the findings for future research in disentangled representation learning?', 'How do the authors justify the choice of metrics used for evaluating disentanglement, given existing criticisms?', ""Could you clarify what is meant by 'group disentanglement' and how it differs from traditional disentanglement?"", 'What specific modifications were made to the BYOL framework to achieve these results?']","['The paper does not adequately address the limitations of the proposed approach and the contexts in which it may fail.', ""Clarity of definitions and claims regarding 'group disentanglement' needs improvement."", 'Authors do not sufficiently address limitations of their study, particularly regarding scalability to more complex datasets beyond CelebA.']",False,3,3,3,6,4,"['Addresses an important topic in representation learning.', 'Empirical results show that contrastive methods, particularly BYOL, achieve competitive performance on disentanglement benchmarks.', ""Introduces the 'group disentanglement' concept, offering a new perspective on disentangled representations.""]","[""The theoretical basis for the claims about 'group disentanglement' is weak and lacks rigor."", 'Reliance on specific metrics for evaluating disentanglement raises questions about robustness.', 'Discussion does not adequately address implications of using contrastive methods compared to traditional generative models.', ""Definition of 'group disentanglement' is not sufficiently clear or justified, leading to ambiguity."", 'Methodology lacks clarity, particularly regarding experimental design and interpretation of results.']",3,3,3,4,Reject
bgAS1ZvveZ,"The paper proposes a method for improving reinforcement learning through value target lower bounding, which enhances the Bellman value target and aims for faster convergence to the optimal value. The authors provide theoretical guarantees for convergence in tabular settings and demonstrate empirical improvements in sample efficiency over established methods like TD3 and SAC across various tasks.","['How do the authors plan to extend their theoretical results to more complex cases beyond the tabular setting?', 'Could the authors provide more details on the experimental setups to enhance reproducibility?']","['The reliance on theoretical results that only apply to tabular cases limits the applicability of the method to more realistic RL problems.', 'The presentation could benefit from clearer explanations of the theoretical constructs and experimental methodologies.']",False,3,3,3,6,4,"['The theoretical analysis provides a solid foundation for the proposed method, demonstrating convergence in the tabular case.', 'Empirical results show significant performance improvements across a variety of tasks, indicating practical effectiveness.', 'The approach requires minimal additional computation and hyperparameter tuning, making it user-friendly.']","['The theoretical results are limited to tabular cases, which may not generalize well to more complex or stochastic environments.', 'The clarity of the paper suffers from dense theoretical sections that could be better articulated for a broader audience.', 'The paper lacks comprehensive comparisons with more recent reinforcement learning algorithms, which would help contextualize its contributions.']",3,3,3,4,Reject
biyvmQe5jM,"The paper investigates the effects of learning rate schedules and their relationship with weight norm bouncing in deep learning. It proposes ABEL, an automatic learning rate scheduler that adjusts the learning rate based on the weight norm dynamics. The authors provide empirical evidence showing that complex schedules are beneficial primarily when weight norm bouncing occurs, and suggest a simplified approach when bouncing is absent.","['Can the authors clarify the novelty of the ABEL scheduler in comparison to existing methods?', 'Are there additional experiments that can be conducted to strengthen the claims about the robustness of ABEL?', 'Can the authors provide a clearer theoretical explanation of why weight bouncing is crucial for learning rate schedules?']","['The paper could be more explicit about the limitations of the proposed method and under what conditions it may fail.', 'More clarity in the theoretical underpinnings behind weight norm bouncing and its impact on learning rate schedules would enhance understanding.']",False,3,2,3,6,4,"['The empirical analysis is thorough, covering various domains and architectures.', 'The proposal of ABEL offers a novel perspective on learning rate scheduling, particularly in relation to weight norm behaviors.', 'The study provides practical insights that could help practitioners in tuning their models more effectively.']","['The clarity of the explanations around the dynamics of weight norm bouncing and its implications could be improved.', 'The novelty of ABEL compared to existing learning rate schedules is not sufficiently highlighted; a more explicit comparison would strengthen the paper.', 'Some experimental setups lacked detailed descriptions, making it difficult to fully assess the robustness of the results.']",3,3,2,4,Reject
nkaba3ND7B5,"The paper introduces a framework for Autonomous Reinforcement Learning (ARL), focusing on learning in non-episodic environments without human supervision for resets. It presents the EARL benchmark, which includes diverse tasks reflective of real-world challenges in autonomous learning. The authors argue that existing RL methods struggle in these settings and emphasize the need for new algorithms tailored for autonomy.","['Can the authors provide a clearer explanation of the evaluation protocols?', 'How do the proposed benchmarks compare quantitatively against existing benchmarks in the literature?', 'What specific improvements do the authors expect to see in ARL algorithms when applied to the EARL benchmark?']","['The clarity of the evaluation methods and their significance in the context of existing RL methods need further elaboration.', 'The evaluation is somewhat limited in scope, potentially undermining the robustness of the conclusions drawn.']",False,2,2,3,5,4,"['The paper addresses a significant gap in reinforcement learning research by focusing on autonomy in RL algorithms, a crucial aspect for real-world applications.', 'The introduction of the EARL benchmark is a valuable contribution that can facilitate further research in autonomous RL.', 'The problem formulation and definition of two distinct evaluation settings (deployment and continuing) is a solid contribution.']","['The presentation lacks clarity; the formal definitions and framework are complicated and may not be easily understood by the reader.', 'The experimental evaluation is insufficient; the paper could benefit from more extensive benchmarking against state-of-the-art methods.', 'Some sections lack clarity and depth, particularly around the implications of the proposed framework and how it differs from existing approaches.', 'The results presented do not offer enough compelling evidence to support the claims made about the need for new algorithms for ARL.']",3,2,2,4,Reject
OqlohL9sVO,The paper proposes a method called UGALR for image retrieval that combines global and attention-based local features in a single-stage pipeline. It claims to improve efficiency and accuracy by removing the re-ranking process and using CNNs for local feature matching instead of traditional methods. Experimental results on benchmark datasets suggest state-of-the-art performance.,"['What specific advantages does UGALR have over existing methods, beyond the removal of the re-ranking step?', 'Can the authors provide more detailed experimental validation, including ablation studies on different components of UGALR?']","['The lack of clarity in certain sections may hinder reproducibility.', 'The paper does not adequately address potential limitations in real-world applications, such as computational efficiency and scalability.']",False,2,2,2,4,4,"['The method aims to unify local and global features, addressing a relevant issue in image retrieval.', 'The experimental results indicate competitive performance against existing methods on popular datasets.', 'The introduction of intermediate supervision is a novel approach that could enhance attention learning.']","['The methodology lacks clarity and detailed explanation of the LALM and CNN-based transformation processes.', 'The paper does not adequately justify the novelty of the approach relative to existing methods.', 'The significance of the experimental results is undermined by the lack of a comprehensive comparison with state-of-the-art techniques and insufficient ablation studies.', 'The re-ranking process is omitted, but there is little discussion on how this impacts the overall retrieval effectiveness.']",2,2,2,3,Reject
cLcLdwOfhoe,"The paper introduces FEDLITE, a scalable federated learning method designed for resource-constrained clients. It proposes a novel vector quantization scheme and a gradient correction method to reduce communication costs associated with split learning while maintaining model accuracy. The empirical results indicate significant communication savings, but the details lack sufficient depth.","['Can the authors provide more comprehensive experiments to validate the claimed performance improvements?', 'Could the authors clarify the mechanisms behind the proposed gradient correction method?', 'What specific conditions optimize the performance of the quantization scheme?']","['The methodology lacks clarity and rigor, which may hinder understanding and reproducibility.', 'Insufficient depth in experimental results raises concerns about the reliability of the findings.']",False,2,2,3,4,4,"['Addresses a significant challenge in federated learning related to resource limitations on clients.', 'The vector quantization scheme is a novel contribution that effectively reduces communication overhead.', 'Empirical evaluations suggest substantial potential for communication cost reduction.']","['Lacks clarity in explaining the proposed methods, particularly the quantization process.', 'Experimental results are insufficiently detailed to assess reproducibility and reliability.', 'The theoretical analysis does not robustly support the claims regarding performance and convergence.', ""Limited comparisons with existing federated learning methods hinder the evaluation of the proposed approach's effectiveness.""]",3,2,2,3,Reject
FZoZ7a31GCW,"This paper introduces Draupnir, a deep generative model for ancestral protein sequence reconstruction that incorporates a tree-structured Ornstein-Uhlenbeck process to represent the evolutionary process. The model is evaluated through several experiments and shows promising results in reconstructing ancestral sequences compared to existing methods.","['Can the authors elaborate on the limitations of their approach and how they might address them in future work?', 'What are the potential ethical implications of using this model in biological research and application?']","['The paper does not adequately address the limitations of the proposed model, particularly in terms of its applicability to other sequence families or larger genomic data sets.', 'The discussion on ethical considerations regarding the reconstruction of ancestral sequences and their implications for biological research is lacking.']",True,3,2,3,5,4,"['The approach addresses a significant issue in ancestral sequence reconstruction by incorporating evolutionary information explicitly.', 'The model shows good performance on benchmark data sets, suggesting its practical utility.', 'The use of a novel tree-structured Ornstein-Uhlenbeck process as a prior is a unique contribution that enhances the representation of biological sequences.']","['The clarity of the paper is hindered by complex explanations and a lack of detailed breakdown of certain methodologies.', 'There is insufficient discussion on the limitations and potential ethical implications of the method in biological research.', 'While the results are promising, the authors could provide more context on how these findings could impact real-world applications.']",3,3,2,3,Reject
8rCMq0yJMG,The paper proposes Source-Target Unified Knowledge Distillation (STU-KD) for adapting compact models on edge devices while addressing privacy concerns. It introduces a memory-efficient adaptation method called Lite Residual Hypothesis Transfer and a collaborative knowledge distillation method to maintain knowledge of source data. The framework aims to improve inference accuracy on target data while protecting user privacy.,"['Could the authors clarify the empirical support for the memory efficiency claims?', 'How do the proposed methods compare with existing techniques in terms of performance across various datasets?', 'Can the authors provide more detailed explanations of the lite residual hypothesis transfer and how it minimizes memory consumption?']","['The clarity of the paper is a significant concern, as the complex methods are inadequately explained.', 'The experimental results, while appearing strong, lack a thorough comparative analysis against a wider range of existing methods.']",False,2,2,2,5,4,"['Addresses a significant problem of adapting models to new environments while preserving user privacy.', 'Proposes novel components like memory-efficient adaptation and collaborative knowledge distillation.', 'Extensive experiments demonstrate improvements in inference accuracy across multiple datasets.']","['Lacks clarity in the description of methodologies, making it difficult to follow the proposed approach.', 'The experimental evaluation lacks depth and robustness, primarily focusing on accuracy without exploring implications of memory efficiency.', 'Insufficient discussion on limitations and potential risks associated with the proposed methods.']",3,2,2,3,Reject
So6YAqnqgMj,"The paper proposes µ-EigenGame, an unbiased version of the EigenGame algorithm which allows for more effective parallelism and improved convergence properties. It addresses the limitations of the original EigenGame, particularly in the context of using minibatches of data. The authors claim that µ-EigenGame outperforms EigenGame in empirical experiments related to dimensionality reduction and spectral clustering.","['Can the authors clarify the limitations observed in the original EigenGame more explicitly?', 'What specific improvements in convergence speed can be expected in practical scenarios?', 'Could the authors provide additional experimental results to support the claims more convincingly?']","['The paper does not adequately address potential limitations and scenarios where µ-EigenGame might not outperform EigenGame.', 'The clarity issues could lead to misunderstandings of the proposed method and its benefits.']",False,3,2,3,6,4,"['The introduction of an unbiased update for the EigenGame algorithm addresses a significant limitation of the original method.', 'The proposed method allows for increased parallelism, which is advantageous for handling large datasets.', 'The theoretical analysis is well-founded, providing a solid basis for the proposed updates.']","[""The paper lacks clarity in several sections, particularly in the explanation of the algorithm's mechanics and its implications, such as the details of the unbiased update process."", 'Theoretical contributions are not rigorously justified; the paper relies heavily on existing literature without providing substantial new insights.', 'Experimental results are limited in scope, lacking diversity in datasets and benchmarks to fully validate the robustness of µ-EigenGame compared to other state-of-the-art methods.']",3,3,2,4,Reject
Zca3NK3X8G,"The paper presents WaveCorr, a novel deep reinforcement learning architecture for portfolio management that incorporates a permutation invariance property to capture cross-asset dependencies. The authors claim significant improvements in portfolio performance metrics compared to existing architectures, supported by empirical results from various datasets.","['Can the authors provide more details on the theoretical implications of the permutation invariance property?', 'What specific steps were taken to ensure that the model does not overfit to the training data?', 'Could the authors enhance the clarity of the architecture description with visual aids or examples?']","['The paper does not adequately address potential risks associated with using reinforcement learning models in financial applications.', 'The experimental results lack robustness and depth, with limited evaluation on different market conditions or asset classes.']",False,3,4,3,6,4,"['The introduction of asset permutation invariance is a novel contribution that addresses a critical aspect of portfolio management.', 'WaveCorr demonstrates strong empirical performance improvements over existing methods, indicating its potential applicability in real-world scenarios.', 'The paper tackles a relevant and challenging problem in finance, appealing to both academic and industry audiences.']","['The theoretical foundation for the permutation invariance property is not clearly articulated, leaving questions about its implications.', 'The clarity of the presentation is lacking; key concepts are dense and poorly explained, making it difficult for readers to follow.', 'The evaluation methodology lacks a comprehensive comparison with a wider range of existing methods, limiting the substantiation of performance claims.', 'There is insufficient discussion on the limitations of the proposed architecture, particularly regarding overfitting and robustness under varying market conditions.']",3,3,4,4,Reject
YfFWrndRGQx,"This paper presents a systematic study of multi-objective online learning, introducing a framework of Multi-Objective Online Convex Optimization (MO-OCO) and the Online Mirror Multiple Descent (OMMD) algorithm. It derives theoretical bounds for the proposed algorithms and demonstrates their effectiveness through extensive experiments.","['Can the authors clarify the implications of their findings in practical applications?', 'Could more comparative experiments with other state-of-the-art methods be included to strengthen the experimental validation?', 'What specific changes could enhance the experimental analysis to better support the claims?']","['The paper does not sufficiently address how the proposed methods can be generalized to other domains beyond the studied applications.', 'The clarity and organization of the theoretical sections could hinder reader understanding.', 'The paper lacks clarity in some theoretical explanations and algorithmic details, which could hinder reproducibility.']",False,3,3,3,6,4,"['The paper addresses a significant problem in multi-objective optimization, which is highly relevant in practical applications.', 'The introduction of the Online Mirror Multiple Descent algorithm is innovative, providing a new perspective on gradient-based methods in an online setting.', 'The theoretical analysis provides valuable insights into the performance bounds of the proposed algorithms.', 'Extensive experiments validate the effectiveness of the algorithms, showing superiority over existing methods.']","['The clarity of the presentation could be improved; some definitions and concepts are presented in a convoluted manner, making them hard to follow.', 'While the theoretical contributions are robust, the experimental section lacks sufficient comparative analysis across a broader set of benchmarks and scenarios.', 'The implications of the findings in practical terms need to be elaborated further to enhance the significance of the results.']",3,3,3,4,Reject
Oh1r2wApbPv,"The paper introduces the Imagine-and-Verbalize (I&V) method aimed at enhancing generative commonsense reasoning (GCSR) through the construction of a relational scene knowledge graph (SKG). The approach leverages diverse knowledge resources to improve text generation based on input concepts and context. The authors present experimental results that claim to show effectiveness in two GCSR tasks, indicating better performance compared to existing methods.","['Could the authors clarify how the SKG is constructed and the role of different knowledge sources?', 'Can they provide more statistical analysis to support the claimed performance improvements?', 'What specific advantages does the proposed method have over previous knowledge graph integration approaches?', 'How do the authors justify the choice of evaluation metrics, and would they consider adding qualitative assessments to complement the quantitative results?']","['The clarity of the paper could be significantly improved to better convey the methodology and findings.', 'The experimental setup and results need more rigorous validation to ensure the robustness of claims.', 'The paper does not adequately address potential limitations of the proposed method in handling ambiguous or conflicting commonsense knowledge.']",False,2,2,3,5,4,"['The proposed method addresses a relevant problem in generative commonsense reasoning, aiming to produce more plausible scene descriptions.', 'The use of a relational scene knowledge graph (SKG) as a constraint in text generation is an interesting and potentially valuable contribution.', 'The experimental results suggest improvements over state-of-the-art models, indicating the potential effectiveness of the proposed approach.']","['The presentation of the method is somewhat unclear, making it difficult to fully grasp the proposed framework and its components.', 'There is a lack of detailed explanation on how the SKG is constructed and how the different knowledge sources are harmonized.', 'Some experimental results lack sufficient statistical analysis to validate claims of improvement over baselines.', 'The novelty of the approach may be limited, as the use of knowledge graphs for enhancing text generation is not entirely new.', 'The evaluation metrics used are primarily quantitative and do not include qualitative assessments, which limits the understanding of the generated content.']",3,2,2,3,Reject
youe3QQepVB,"The paper proposes a Multi-task Oriented Generative Modeling (MGM) framework that integrates generative models with discriminative networks to enhance performance across various visual perception tasks using weak annotations. The framework aims to synthesize images that facilitate learning in multiple tasks, demonstrating improvements on benchmarks like NYUv2 and Taskonomy.","['What specific advances does this work offer beyond existing methods in the field of generative modeling for multi-task learning?', 'Can the authors clarify how the generative and discriminative networks effectively collaborate within the proposed framework?', 'What specific steps were taken to ensure the reproducibility of the experimental results?']","['The paper does not adequately address the limitations of using weakly labeled data or the potential biases that may arise from the generative model.', 'There is insufficient experimental validation of the claims made regarding the effectiveness of the framework.']",False,2,3,3,5,4,"['Addresses a significant challenge in multi-task visual learning.', 'Innovative approach combining generative and discriminative modeling.', 'Experimental results indicate improvements over state-of-the-art methods, particularly in low-data scenarios.']","['The originality of the work could be questioned as it relies on existing architectures without substantial novel contributions.', 'The clarity of the paper could be improved, particularly in explaining the interaction between the generative and discriminative components.', 'The experimental evaluation lacks depth, with insufficient ablation studies and a limited range of comparative baselines.']",3,3,3,4,Reject
8Py-W8lSUgy,"The paper introduces MetaLink, a framework for relational multi-task learning that utilizes auxiliary task labels to enhance predictions on new tasks by building a knowledge graph connecting data points and tasks. The proposed method aims to leverage relationships between tasks to improve learning efficiency and performance on tasks.","['Can the authors provide more detailed explanations of the knowledge graph construction and its implications for task relationships?', 'What specific advantages does the heterogeneous GNN architecture provide over traditional GNNs in this context?', 'Could the authors conduct additional ablation studies to clarify the contributions of various components of MetaLink?']","['The paper does not sufficiently address when auxiliary task labels may not be correlated or relevant, which could limit the effectiveness of the method.', ""Further exploration of potential biases in the datasets used for evaluation would strengthen the understanding of the method's applicability.""]",True,2,2,3,4,4,"['The framework addresses a significant gap in multi-task learning by considering auxiliary task labels, providing a novel approach to knowledge transfer.', 'Empirical results demonstrate improvements over existing state-of-the-art methods across multiple datasets, highlighting the potential effectiveness of the proposed method.', 'The use of a knowledge graph structure is innovative and allows for flexible modeling of relationships between tasks and data points.']","['The methodology lacks clarity in several areas, particularly regarding the construction and utilization of the knowledge graph.', 'There is insufficient detail on how the GNN architecture is specifically tailored for this application, which limits the reproducibility of the results.', 'The evaluation focuses on a limited number of datasets, and the paper does not adequately explore the robustness of the proposed method across diverse tasks and domains.', 'The paper does not include enough ablation studies to support the claims about the effectiveness of using a heterogeneous GNN and knowledge graph.']",3,2,2,3,Reject
fVu3o-YUGQK,This paper investigates techniques for developing efficient self-supervised vision transformers (EsViT) for visual representation learning. It highlights the use of multi-stage architectures with sparse self-attentions to reduce modeling complexity and proposes a new pre-training task of region matching to enhance fine-grained learning. The results show that EsViT achieves high accuracy and efficiency compared to prior works.,"['Can the authors clarify the rationale behind the specific choice of parameters for the region-matching task?', 'Could additional comparisons with other architectures further substantiate the claims of efficiency?', 'Could the authors provide more details on the implementation of the proposed methods to enhance reproducibility?', 'Can the authors elaborate on how the proposed region-matching task was developed and its advantages over traditional methods?']","['The paper does not fully address potential limitations or negative societal impacts of deploying such self-supervised systems.', ""The clarity of the architecture's description and the implementation of the region matching task may hinder reproducibility and understanding."", 'The paper could benefit from a clearer presentation of methods and results, as well as a more rigorous exploration of the implications of the proposed techniques.']",False,3,3,4,7,4,"['Proposes a novel architecture and pre-training task for efficient self-supervised representation learning.', 'Demonstrates significant improvements in throughput and accuracy on ImageNet and downstream tasks.', 'Comprehensive experiments with clear comparisons to state-of-the-art methods.']","['The clarity of the presentation could be improved; some sections are dense and difficult to follow.', 'Some methodological choices, such as the specific implementation of the region-matching task, could benefit from more detailed justification and analysis.', 'The paper could provide more visualizations or case studies to demonstrate the learned representations and attention mechanisms.']",4,3,3,4,Accept
N0uJGWDw21d,"The paper presents BINGO, a novel self-supervised distillation method that aggregates similar instances to enhance the performance of small-scale models. The authors claim that BINGO achieves state-of-the-art results on ImageNet, significantly outperforming previous methods for small models.","['Can the authors provide a more thorough explanation of the theoretical foundations of BINGO?', 'What specific advantages does BINGO offer over other recent methods in terms of model performance and efficiency?', 'Could the authors elaborate on the bagging strategy and discuss its potential limitations?']","['The paper does not adequately address the shortcomings of the proposed method, particularly in terms of computational complexity.', 'The potential increase in computational complexity due to the bagging strategy is not sufficiently discussed, which could impact practical applications.']",False,3,2,3,5,4,"['BINGO demonstrates substantial performance improvements over existing methods, achieving 65.5% and 68.9% top-1 accuracies with ResNet-18 and ResNet-34, respectively, which is a notable advancement for small models.', 'The method of aggregating related instances provides a practical and innovative approach to knowledge distillation, potentially benefiting various applications in self-supervised learning.', 'The empirical results are robust, supported by comprehensive experiments that validate the effectiveness of the proposed method across different tasks, including KNN classification and semi-supervised learning.']","['The originality of BINGO is not clearly articulated; it appears to be an incremental improvement on existing methods without a strong theoretical foundation or novel insights.', 'There are clarity issues in the methodology, particularly regarding the bagging strategy, which could be better explained to enhance understanding and reproducibility.', 'The comparison with other distillation methods could be more comprehensive, and additional ablation studies are needed to fully understand the impact of different components on performance.']",3,3,2,3,Reject
q79uMSC6ZBT,"The paper introduces GRAMMFORMER, a Transformer-based model for code completion that generates code with 'holes' to indicate uncertainty in predictions. It leverages programming language grammar to guide the generation process and claims improved accuracy over traditional generative models. The model is evaluated on C# and Python, introducing a new evaluation metric, REGEXACC, alongside traditional metrics.","['Can the authors provide more details on the training process and the reasoning behind the chosen evaluation metrics?', 'What other state-of-the-art models were considered for comparison, and why were they excluded from the experiments?', 'Could additional ablation studies be conducted to isolate the effects of individual components of the model?']","['The lack of clarity in the model training and evaluation metrics could hinder reproducibility and understanding of the results.', 'The paper does not adequately address how it significantly advances the state of the art in code generation.']",False,2,2,3,4,4,"[""The concept of using 'holes' for uncertain predictions is innovative and addresses a real challenge in code generation."", 'The integration of programming language grammar can lead to more structured and correct code completions.', 'The empirical results suggest that GRAMMFORMER outperforms traditional models in terms of accuracy.']","['The paper lacks clarity in the training procedure and implementation details, making it difficult to reproduce the results.', 'The experimental evaluation is limited, primarily comparing against only a few baseline models without thorough exploration of the state-of-the-art.', 'The new evaluation metric REGEXACC needs more justification and validation to establish its reliability and relevance.', 'The contribution does not demonstrate a substantial advancement over current state-of-the-art models.']",3,2,2,3,Reject
-9ffJ9NQmal,"The paper introduces Variational Inference for Concept Embeddings (VICE), a method for learning object concept embeddings from human behavior in an odd-one-out task. It employs variational inference to achieve sparse, non-negative solutions while providing uncertainty information. VICE claims to outperform existing methods, particularly SPoSE, in various aspects, especially with smaller datasets, which are significant in cognitive science contexts.","['Can the authors clarify the theoretical justification for using the spike-and-slab prior over other alternatives?', 'What specific measures were taken to ensure that the results are reproducible across different experiments?', 'Could the authors provide more detailed information on the implementation and evaluation process for VICE, particularly regarding the training and validation procedures?']","['The clarity of the paper needs improvement, especially in the explanation of methods and results.', 'The evaluation of VICE against SPoSE lacks rigorous quantification of performance differences.']",False,3,2,3,5,4,"['The approach addresses a relevant problem in cognitive science by improving how object concept embeddings are learned from human behavior.', 'The use of variational inference and a spike-and-slab prior is an innovative attempt to enhance sparsity and interpretability.', 'The empirical results show that VICE performs well, especially with small datasets, which is crucial in cognitive science research.']","['The presentation lacks clarity in several sections, particularly in the methodology and rationale behind the choices made, such as the implementation details.', 'Comparative evaluations with SPoSE are not adequately quantified, making it difficult to assess the improvements offered by VICE; specific metrics or statistical tests should be included.', 'The paper does not provide sufficient detail on the implementation, which could hinder reproducibility and understanding of the method.']",3,3,2,3,Reject
UvNXZgJAOAP,"The paper proposes a sharp attention mechanism for sequence-to-sequence learning that improves alignment between input images and target outputs through a sharpener module. This module focuses on refining the representation of relevant regions in the input, aiming for clearer and more interpretable attention. Experimental results demonstrate that this approach outperforms traditional soft and hard attention mechanisms on both synthetic and real-world datasets.","['Can the authors clarify the design and functioning of the sharpener module?', 'What are the implications of the results for future work in attention mechanisms?', ""Can the authors provide a more detailed explanation of the sharpener module's architecture and its interaction with existing attention mechanisms?""]","['The paper could benefit from a more thorough discussion of the limitations of the proposed approach, particularly in relation to the computational complexity of the sharpener module.', 'The clarity of the proposed methodology is not sufficient for reproducibility, which is a significant concern.']",False,3,4,3,5,4,"['The introduction of the sharpener module represents a novel approach to enhancing attention mechanisms in visual sequence learning.', 'The paper provides thorough experimental validation on both synthetic and real-world datasets, showing significant performance improvements.', 'The focus on clear alignment in attention mechanisms addresses a critical limitation in existing approaches.']","['The explanation of the sharpener module and its components lacks clarity, making it difficult to fully understand how it operates.', 'While the experimental results are compelling, the paper does not adequately discuss the implications of the findings or the potential limitations of the approach.', 'The connection between the sharpener and existing attention mechanisms could be articulated more clearly, particularly in the related work section.']",3,4,4,3,Reject
2yITmG7YIFT,"The paper proposes HD-COS networks, which utilize cosine activation functions and Hadamard-Diagonal transformations to enhance the efficiency of neural networks in secure multi-party computation (MPC) settings. The authors claim that these methods reduce communication overhead while maintaining performance, but the novelty and practical implications of the approach require further clarity.","['Can the authors provide more detailed explanations on the theoretical framework supporting the use of cosine activation in MPC?', 'What specific benefits does the Hadamard-Diagonal transformation provide compared to standard dense layers in practical scenarios?', 'Could the authors elaborate on the selection process for datasets and the implications for generalizability of results?']","['The paper does not sufficiently explore limitations and potential drawbacks of the proposed methods in real-world applications.', ""There's insufficient discussion on how the proposed techniques compare with other MPC approaches and existing neural network architectures.""]",False,3,3,4,4,4,"['Addresses a significant challenge in privacy-preserving machine learning through MPC.', 'Introduces innovative techniques that theoretically reduce computational costs in MPC.', 'Empirical results suggest that the proposed method performs comparably to traditional methods while being more efficient.']","['Lacks clarity in the explanation of the proposed methods, particularly regarding the implementation of cosine activation and Hadamard-Diagonal structures.', 'Insufficient theoretical justification for the chosen methods compared to existing approaches.', 'Experimental validation is limited, lacking comprehensive ablation studies and comparisons with a broader range of existing methods.', 'The paper does not adequately address limitations or potential drawbacks of the proposed methods.']",4,3,3,4,Reject
kUGYDTJUcuc,"The paper proposes a unified recurrent attention model that combines top-down and bottom-up attention mechanisms for visual recognition tasks. It aims to enhance the exploration and decision-making process in visual tasks by utilizing a global context through image pyramids and reinforcement learning. The experimental results claim improvements over conventional CNNs and existing attention models on datasets like MNIST, CIFAR-10, and SVHN.","['Can the authors provide additional details on how the proposed model compares to existing attention models?', 'What specific advantages does the proposed method have in terms of computational efficiency and stability?', 'Could the authors clarify the rationale behind the entropy and context constraints in the model?', ""What specific metrics or benchmarks were used to evaluate the model's performance, and why were these chosen?""]","['The lack of detailed comparisons with existing methods raises questions about the claims of superiority.', 'The methodology is not clearly articulated, which may hinder reproducibility.', 'The paper does not adequately discuss potential limitations or the scalability of the model.']",False,2,2,2,4,4,"['The integration of top-down and bottom-up attention mechanisms is an interesting approach that could enhance visual recognition tasks.', 'The motivation to improve exploration strategies in attention mechanisms is relevant and timely.', 'The experimental evaluation includes multiple datasets, demonstrating a broad applicability of the proposed approach.']","['The paper lacks clarity in its presentation, making it difficult to fully understand the proposed methodology.', 'The experimental results are limited and do not provide a comprehensive comparison against a broader range of state-of-the-art models.', 'There is insufficient theoretical justification for the proposed approach, particularly regarding the choice of constraints and their impact on performance.', 'The novelty of the approach is questionable as it does not provide a clear differentiation from existing attention models.']",2,2,2,3,Reject
F2r3wYar3Py,"The paper proposes a novel approach to few-shot learning using a 'distortable canvas' to model human-like learning abilities. It claims to achieve competitive performance on character recognition tasks with minimal training examples, without pre-training. However, the complexity of the model and its evaluation raises concerns about clarity and reproducibility.","[""Can the authors provide clearer explanations of the optimization process and the role of the 'distortable canvas'?"", 'What specific experimental setups were used to compare against other state-of-the-art models, and were all hyperparameters optimized for fair comparison?', 'How can the model be applied or adapted to more complex real-world tasks beyond simple character recognition?']","['The complexity of the model may hinder practical application and understanding.', 'The clarity of the paper could be significantly improved to aid comprehension and reproducibility.']",False,2,2,3,4,4,"['The concept of modeling human-like learning capabilities is innovative and addresses a significant gap in current machine learning practices.', 'The model achieves impressive results on standard benchmarks like MNIST and Omniglot, showcasing its potential in low-data scenarios.', 'The paper attempts to offer human-interpretable outputs, which is valuable for understanding model behavior.']","[""The methodology is complex and lacks sufficient clarity, particularly in explaining the 'distortable canvas' and the optimization process."", ""Comparative results against state-of-the-art models are limited, and it's unclear how the proposed method consistently outperforms existing approaches."", 'The paper does not provide enough detail on the implementation, making it difficult for others to reproduce the results.']",3,3,3,4,Reject
36SHWj0Gp1,"The paper presents GenTAL, an unsupervised generative denoising skip-gram Transformer model for binary code similarity detection. It aims to learn compact representations of assembly code semantics while addressing challenges like obfuscation and varying compilation options. The model combines a Transformer architecture with a skip-gram style loss for reconstructing masked instructions and evaluates its performance across multiple scenarios.","['Can the authors clarify how GenTAL differs fundamentally from existing BERT-based models?', 'What specific improvements in performance can GenTAL demonstrate over each of the baselines?', 'Could the authors provide more detail on the experimental setup, particularly the training process and how the evaluation datasets were generated?', 'How does GenTAL perform with different types of obfuscation techniques not covered in the experiments?', 'Can the authors provide more detail on the preprocessing and masking strategies used for assembly code?']","['The paper does not adequately address limitations or potential drawbacks of the proposed approach, particularly in regard to the out-of-vocabulary (OOV) issue mentioned.', 'There is a lack of discussion on how the model might perform on other obfuscation techniques or with varying types of binary code.']",False,2,2,2,4,4,"['The paper addresses a significant problem in cybersecurity, specifically in binary code similarity detection, which is crucial for malware analysis.', 'The proposed GenTAL model offers a novel unsupervised approach, potentially improving generalizability and robustness against various transformations of assembly code.', 'The experimental results demonstrate that GenTAL outperforms several baselines in various code similarity tasks, indicating potential effectiveness in real-world applications.']","['The originality of the work is questionable as it builds heavily on existing models like BERT without sufficiently distinguishing itself from them.', 'The clarity of the writing is poor, with many complex sentences and jargon that may hinder understanding for readers not deeply familiar with the topic.', 'The evaluation metrics are not comprehensive enough; additional metrics and more detailed comparisons against state-of-the-art methods are needed to substantiate the claims.', 'The experimental results lack sufficient detail regarding the training and evaluation processes, making it difficult to assess reproducibility.']",2,2,2,3,Reject
n6Bc3YElODq,"The paper proposes Model-Based Opponent Modeling (MBOM), a method for adapting to various types of opponents in multi-agent reinforcement learning through recursive reasoning and Bayesian mixing. It claims to improve performance in competitive environments against fixed, naïve, and reasoning learners, with empirical results suggesting superiority over existing methods.","['Can the authors provide clearer explanations of the recursive reasoning and Bayesian mixing processes?', 'What specific advantages does MBOM offer over existing methods in opponent modeling?', 'Could the experimental methodology be presented in more detail to facilitate replication?']","['The clarity of the methodology is lacking, which might hinder reproducibility.', 'Insufficient exploration of the assumptions regarding opponent behavior and the computational costs associated with the proposed approach.']",False,3,3,3,5,4,"['Addresses a significant challenge in multi-agent reinforcement learning by proposing a framework for opponent modeling.', 'Innovative use of recursive reasoning combined with Bayesian mixing to adapt to learning opponents.', 'Empirical results demonstrate that MBOM outperforms several strong baselines in competitive environments, particularly against naïve and reasoning learners.']","['Lacks clarity in explaining the implementation details of recursive reasoning and Bayesian mixing, particularly in sections 3 and 4, which may hinder understanding.', 'Insufficient detail in the experimental setup and hyperparameter choices, making it difficult to replicate the results.', 'The novelty of the approach compared to existing methods is not clearly articulated, which may lead to questions about its contribution to the field.']",3,3,3,4,Reject
Ti2i204vZON,"The paper investigates representation learning methods for pixel-based control in reinforcement learning, particularly in environments with background distractions. It proposes a baseline method that incorporates reward and transition prediction and analyzes the performance of various existing methods. The authors argue for a data-centric evaluation approach and suggest that finer categorizations of benchmarks are crucial for meaningful evaluation.","['Could the authors provide more detailed empirical evidence to support the claims about the comparative performance of different methods?', 'What specific contributions make the proposed method superior to existing benchmarks?']","['The paper does not adequately address the limitations of the proposed baseline, particularly in more complex environments.', 'The clarity of presentation is a major concern that should be addressed in a revision.']",False,2,2,3,5,4,"['Addresses a significant challenge in reinforcement learning: learning from pixel inputs in complex environments.', 'Proposes a simple baseline methodology that could serve as a foundation for future research.', 'Highlights the need for a data-centric view in evaluating representation learning methods.']","[""The writing lacks clarity and organization, making it difficult to follow the authors' arguments."", 'Insufficient empirical evidence to substantiate claims about the performance of methods under distractions.', 'The novelty of the proposed method is not convincingly justified against existing literature.']",3,2,2,4,Reject
lvM693mon8q,"The paper introduces Compressed Vertical Federated Learning (C-VFL), a framework aimed at enhancing communication efficiency in vertically partitioned federated learning. It includes a theoretical analysis of convergence rates under various compression schemes and presents experimental results indicating significant communication reduction without notable accuracy loss.","['Could the authors clarify their theoretical claims and provide additional experimental comparisons with baseline methods?', 'What specific steps do the authors take to ensure the robustness of their experimental results across different datasets and conditions?', 'Can the authors elaborate on the implications of their assumptions in the theoretical analysis?']","['The paper does not sufficiently address the limitations of the proposed method, particularly regarding its assumptions and potential vulnerabilities related to compression errors.']",False,3,2,3,5,4,"['Addresses a critical challenge in federated learning, particularly in scenarios involving vertically partitioned data.', 'The theoretical analysis provides valuable insights into the effects of message compression on convergence.', 'Demonstrates substantial potential for reducing communication costs through experimental results.']","['The clarity of the paper is lacking in several areas, particularly in the theoretical arguments and proofs, making it difficult to follow.', 'The experimental validation is limited, lacking comprehensive comparisons with existing state-of-the-art methods, which would provide better context for the results.', 'The assumptions made in the theoretical analysis are not adequately justified, which may affect the perceived robustness of the findings.']",3,3,2,3,Reject
f4c4JtbHJ7B,"The paper proposes Pixab-CAM, a new class activation mapping method that utilizes pixel-wise weights instead of channel-wise weights to improve the interpretability of CNNs. The authors also eliminate dependency on the activation tensor and introduce novel evaluation metrics utilizing adversarial attacks to assess the quality of explanation maps. The paper demonstrates the qualitative and quantitative superiority of Pixab-CAM over existing CAM-based methods.","['Could the authors clarify the methodology for calculating pixel-wise weights?', 'Can more diverse baseline comparisons be included to better contextualize the performance of Pixab-CAM?', 'What specific quantitative comparisons support the claim of superiority of Pixab-CAM over other methods?']","['The clarity of the proposed methods and their implementations could be improved.', 'The evaluation may not cover all existing CAM-based methods, limiting the robustness of the claims.']",False,3,2,3,5,4,"['The introduction of pixel-wise weights addresses key limitations of traditional channel-wise weight approaches in CAM methods.', 'The elimination of dependency on the activation tensor is a significant advancement, potentially leading to more accurate explanations.', 'The proposed evaluation metrics using adversarial attacks are innovative and provide a new perspective for assessing explanation quality.']","['The paper lacks clarity in certain methodological details, especially regarding how pixel-wise weights are computed and utilized.', ""More thorough comparisons with a wider range of baseline methods would strengthen the evaluation of Pixab-CAM's effectiveness."", ""The results, while promising, could be enhanced with additional experiments or case studies to provide deeper insights into the method's performance.""]",3,2,2,3,Reject
rGg-Qcyplgq,"The paper proposes Perturbed Quantile Regression (PQR) for distributional reinforcement learning, aiming to improve exploration efficiency by randomizing risk criteria. It provides theoretical guarantees for convergence and optimality and demonstrates empirical superiority over existing algorithms in various environments, including Atari games.","['Can the authors clarify the conditions under which the convergence proofs hold?', 'Could the authors provide additional empirical comparisons with other established exploration methods?', 'What specific limitations do the authors foresee in their approach, and how do they plan to address them?']","['The paper lacks clarity in some sections, which may confuse readers regarding the theoretical contributions.', 'Limited experimental evaluations may not fully capture the effectiveness of the proposed method across diverse scenarios.']",False,3,2,2,3,4,"['The proposed method introduces a novel approach to exploration in distributional reinforcement learning by randomizing risk criteria.', 'Theoretical proofs of convergence and optimality are provided, which adds rigor to the claims.', 'Empirical results show that PQR outperforms baseline methods in several environments, indicating practical applicability.']","['The clarity of the presentation is lacking, making it difficult to follow the theoretical developments, particularly in the proofs and definitions.', 'The experimental evaluation could be more comprehensive; additional environments and comparisons would strengthen the claims.', 'The paper does not adequately address limitations or potential negative societal impacts of the proposed methods.']",3,3,2,3,Reject
bE239PSGIGZ,"The paper introduces the Speech Synthesising based Attack (SSA), a method for generating adversarial audio examples for Automatic Speech Recognition (ASR) systems from scratch without relying on existing benign audio. It employs a Conditional Variational Autoencoder (CVAE) and an adaptive sign gradient descent algorithm. The experiments demonstrate that SSA can effectively mislead ASR models while aiming to maintain natural sound.","['Can the authors clarify how their approach significantly differs from previous adversarial attack methods?', 'What specific steps can be taken to improve the naturalness of the synthesized audio examples?', 'Could the authors provide additional details on the training process of the CVAE and the specific metrics used to evaluate success?']","['The clarity of the methodology and experiments needs improvement, particularly in how the CVAE is trained and utilized.', 'The low quality of synthesized audio raises concerns about the practical effectiveness of the approach.']",False,3,2,3,5,4,"['The introduction of an audio-independent attack model is innovative and addresses a significant gap in adversarial attack methodologies.', 'The use of a Conditional Variational Autoencoder (CVAE) for adversarial audio synthesis is a relevant application of generative models.', 'The experimental results show that the proposed method achieves high success rates in deceiving ASR models across multiple datasets.']","['The clarity of the methodology is lacking, particularly in explaining the CVAE design, optimization process, and the adaptive learning rate mechanism.', 'The quality of the synthesized audio is a concern, as it reportedly lacks naturalness compared to original audio, which could limit practical applications.', 'Experimental comparisons with existing methods are limited, and more rigorous validation is needed to assess the true impact of the proposed approach.']",3,3,2,3,Reject
SHbhHHfePhP,"The paper proposes Graph Mechanics Networks (GMN) for modeling constrained dynamical systems using equivariant graph neural networks. It addresses challenges related to combinatorial complexity and geometric constraints, demonstrating improvements over state-of-the-art methods through extensive experiments on both simulated and real-world datasets.","['Can the authors clarify the implications of their theoretical findings in simpler terms?', ""Could the authors provide additional comparative results to strengthen the claims about GMN's advantages?"", 'How generalizable is GMN to other types of constrained systems not covered in the experiments?']","['The clarity and organization of the paper could be improved.', 'The experimental validation lacks depth in terms of comparisons with additional baseline models.']",False,3,3,3,6,4,"['Addresses significant challenges in modeling constrained dynamical systems.', 'Introduces a novel approach using generalized coordinates and equivariant functions.', 'Demonstrates strong empirical performance across various datasets.']","['Lacks clarity in explaining the methodology and theoretical concepts.', 'Presentation is dense and difficult to follow, impacting accessibility.', 'Insufficient experimental comparisons with a broader range of baseline methods.']",3,3,3,4,Reject
xaTensJtCP5,"The paper introduces Ab Initio objective functions for optimizing MCMC proposal distributions, addressing limitations of existing methods that rely on strict architectural constraints. It demonstrates the effectiveness of these new objective functions through experimental results, showing better performance compared to traditional objectives.","['Can the authors clarify the fitting procedures for the Ab Initio objectives?', 'What steps will the authors take to validate their objectives on a broader range of tasks?', 'How does this approach compare to classical MCMC methods in practical applications?']","['The clarity of the explanation regarding the construction of the new objective functions needs improvement.', 'The experimental validation is limited; further experiments on real-world datasets or more complex models are necessary.']",False,3,3,4,5,4,"['The proposed Ab Initio objective functions offer a novel approach to MCMC proposal optimization, filling a significant gap in the literature.', 'The paper is based on solid theoretical foundations regarding MCMC efficiency and sampling performance.', 'Experimental results indicate the effectiveness of the proposed methods across various optimization tasks, suggesting practical utility.']","['Some methodological explanations lack clarity, particularly regarding the construction and fitting of the objectives, which may hinder reproducibility.', 'The experimental scope is somewhat narrow; including more diverse datasets and metrics would strengthen the claims.', 'Certain sections are overly technical and could be simplified for better readability.']",4,3,3,4,Reject
TXqemS7XEH,"The paper proposes a training strategy called 'Pseudo-to-Real' aimed at efficiently training extremely large models, specifically a 10-trillion-parameter model, using limited computational resources. The approach involves a two-stage training process with parameter sharing followed by delinked parameters, claiming significant efficiency improvements and reduced carbon footprint.","[""Can the authors provide more detailed insights into the implementation of the 'Pseudo-to-Real' method and how it differs from existing methods?"", ""What specific benchmarks were used to evaluate the model's performance in downstream tasks, and how did the results compare to existing models?"", 'What ethical considerations have been taken into account in the development and potential release of such large models?']","['The lack of clarity in presenting the methodology makes it challenging to evaluate the validity of the results.', 'Insufficient exploration of the environmental and ethical implications of training and deploying immense models.']",True,2,2,2,4,4,"['Addresses a significant challenge in deep learning regarding the efficient training of extremely large models.', 'The ability to train a 10-trillion-parameter model within 10 days on 512 GPUs is a notable achievement, showcasing the potential for more sustainable AI practices.', 'The proposed method has the potential to significantly reduce resource consumption and training time, which is crucial for the future of large-scale AI.']","[""The clarity of the presentation is poor, making it challenging to understand the proposed methodology and results, particularly the specifics of the 'Pseudo-to-Real' strategy."", 'Experimental validation is limited, particularly in terms of comparisons with existing state-of-the-art methods, which could strengthen the claims made and provide context for the results.', ""The novelty of the 'Pseudo-to-Real' strategy is questionable, as it builds on established concepts without sufficient justification of its uniqueness."", 'The paper does not adequately engage with the ethical implications of training large models, despite mentioning greener AI.']",3,2,2,3,Reject
iaxWbVx-CG_,"The paper proposes Hierarchical Cross Contrastive Learning (HCCL), a method for self-supervised learning that utilizes multiple layers of a projection head for contrastive learning. By applying cross-level contrastive learning, HCCL aims to improve the generalization of learned visual representations. The method shows competitive results across various benchmarks, claiming to outperform several existing methods while requiring fewer training epochs.","['Can the authors clarify the rationale behind the hierarchical projection head setup?', 'What specific advantages does HCCL offer over other recent self-supervised methods in practical applications?']","['The contributions of the paper are presented in a way that may not fully convey their significance due to unclear writing and organization.', 'More comprehensive experiments comparing HCCL to a wider variety of self-supervised learning methods would strengthen the claims made.']",False,2,2,3,5,4,"['The introduction of a hierarchical projection head and cross-level contrastive learning is a novel approach that addresses the limitations of conventional contrastive learning methods.', 'The experimental results demonstrate that HCCL achieves competitive performance on multiple benchmarks, indicating its potential effectiveness.', 'The method is designed to be flexible and applicable across various self-supervised learning frameworks.']","['The paper lacks clarity and organization, making it challenging to follow the rationale behind the proposed method and its contributions.', 'Some experimental results lack sufficient context and comparison with a broader range of existing methods, which diminishes their impact.', 'Numerous grammatical errors and awkward phrasings detract from the overall quality of the writing.']",3,2,2,3,Reject
EMLJ_mTz_z,The paper proposes a novel framework for analyzing the learning dynamics of neural networks by representing the training process as a time-evolving graph. It aims to predict neural network performance based on early training dynamics by analyzing structural changes over a few epochs. The authors introduce a compact graph representation for convolutional layers and utilize graph statistics to make performance predictions across different neural architectures.,"['Can the authors elaborate on the advantages of the rolled representation compared to previous methods?', 'How do the authors address the potential limitations of their approach when applied to more complex or diverse tasks?', 'Could the authors provide more detailed comparisons between the performance of different architectures and the effectiveness of their method?']","[""The model's effectiveness in real-world scenarios or larger architectures is not adequately addressed, limiting its practical applicability."", 'The paper does not sufficiently discuss the implications of the findings or how they might influence future research directions.']",False,2,2,3,5,4,"['The approach of using a graph-based perspective to analyze neural network dynamics is innovative and can provide new insights into NN behavior.', 'The proposed framework demonstrates effectiveness in predicting NN performance using only a few training epochs, suggesting potential for early stopping and more efficient training.', 'The empirical analysis includes multiple well-known datasets and architectures, showcasing the applicability of the method.']","['The clarity of the presentation is lacking, making it difficult to fully understand the methodology and the significance of the results.', 'The theoretical foundation for the graph representation, especially the justification for the new rolled representation over previous methods, is inadequately addressed.', 'Empirical evaluations, while promising, lack sufficient depth; particularly, there is little discussion on the limitations of their predictions or the generalizability across different datasets and architectures.']",3,2,2,4,Reject
kO-wQWwqnO,"The paper presents L2BGAN, an image enhancement model designed to translate low-light images to brighter images without requiring paired supervision. It introduces geometric and illumination consistency constraints along with contextual loss criteria, supplemented by multiscale discriminators. The authors perform extensive experiments on benchmark datasets, claiming competitive performance in image enhancement and subsequent image analysis tasks.","['Could the authors provide more details on the specific architecture of the model and the training process?', 'How do the results compare to existing methods in a more rigorous way, with a clearer focus on metrics and visual comparisons?', 'What are the implications of using unpaired data in terms of model generalizability and performance?']","['The paper does not adequately address potential limitations of the proposed method, such as the reliance on unpaired data and how that may affect performance in diverse scenarios.', 'The lack of clarity in the methodology makes it difficult to fully understand the proposed approach.']",False,2,2,3,4,4,"['Addresses a significant challenge in image processing—enhancing low-light images without requiring paired supervision.', 'Innovative use of geometric and illumination consistency, as well as contextual loss to improve image enhancement.', 'Conducts extensive experiments on benchmark datasets, providing both visual and quantitative evaluations.']","['The methodology lacks sufficient detail, particularly in explaining the architecture and training process, making it difficult to fully understand how the proposed model operates.', 'The experimental results, while extensive, do not provide clear comparisons against state-of-the-art methods; the significance of the improvements is not convincingly articulated.', 'The clarity of the writing is subpar, leading to confusion regarding the core contributions and implementations of the paper.']",3,2,2,4,Reject
fJIrkNKGBNI,"The paper proposes a piece-wise polynomial filtering approach for Graph Neural Networks (GNNs) aimed at improving performance on heterophilic graphs. It introduces multiple adaptive polynomial filters based on graph spectrum decomposition and claims significant performance gains over state-of-the-art models. However, the theoretical justifications and empirical validations are not adequately detailed.","['Can the authors provide clearer theoretical justifications for the piece-wise polynomial approach?', 'Could additional ablation studies be included to clarify the contribution of various components in the proposed model?', 'How generalizable are the results across different datasets, particularly in practical scenarios?']","['Insufficient theoretical grounding for claims made about the effectiveness of the proposed method.', 'Lack of comprehensive experiments to validate the robustness of the model across various types of graphs.']",False,2,2,2,3,4,"['Addresses a significant issue in GNNs related to their performance on heterophilic graphs.', 'Introduces a novel concept of using multiple adaptive polynomial filters.', 'Empirical results indicate performance improvements over existing methods.']","['Theoretical framework lacks rigorous proofs to support claims.', 'Clarity of the presentation is undermined by complex notations and jargon.', 'Experimental validation is insufficient, lacking comprehensive comparisons and ablation studies.']",3,2,2,3,Reject

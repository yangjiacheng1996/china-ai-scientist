# china-ai-scientist
æœ¬é¡¹ç›®åŸºäºgithubä¸Šçš„ä¸€ä¸ªå¼€æºé¡¹ç›®AI-Scientistï¼ˆAIç§‘å­¦å®¶ï¼‰åšäºŒæ¬¡ä¿®æ”¹ï¼Œæ›´é€‚åˆä¸­å›½å®å®ä½“è´¨ã€‚
åœ¨ä¸­å›½ï¼Œç”±äºå¤§é™†å¢™ï¼Œæˆ‘ä»¬æ— æ³•è®¿é—®å›½å¤–AIå¤§æ¨¡å‹å®˜ç½‘ï¼Œæ— æ³•ç›´æ¥ä½¿ç”¨API Keyã€‚å¹¶ä¸”åœ¨ä½¿ç”¨åŸé¡¹ç›®è¸©åˆ°çš„ä¸€äº›å‘éƒ½ä¼šå†™å…¥è¿™ç¯‡æ–‡æ¡£ï¼Œå¸®åŠ©è¯»è€…å¿«é€Ÿä½¿ç”¨ã€‚

<h1 align="center">
  <a href="https://github.com/SakanaAI/AI-Scientist/blob/main/docs/logo_2.png">
    <img src="docs/logo_2.png" width="215" /></a><br>
  <b>AIç§‘å­¦å®¶: æ‹¥æŠ±å…¨è‡ªåŠ¨åŒ–</b><br>
  <b>å°†ç§‘å­¦å‘ç°å¼€æºåˆ°åº• ğŸ§‘â€ğŸ”¬</b><br>
</h1>

<p align="center">
  ğŸ“š <a href="https://arxiv.org/abs/2408.06292">[è®ºæ–‡]</a> |
  ğŸ“ <a href="https://sakana.ai/ai-scientist/">[å®˜ç½‘]</a> |
  ğŸ“‚ <a href="https://drive.google.com/drive/folders/1G7A0wTqfXVa-cpexjk0oaXakaSJwffEt">[é©±åŠ¨æ–‡ä»¶å¤¹]</a>
</p>

äººå·¥æ™ºèƒ½çš„ä¸€å¤§æŒ‘æˆ˜æ˜¯å¼€å‘èƒ½å¤Ÿè¿›è¡Œç§‘å­¦ç ”ç©¶å’Œå‘ç°æ–°çŸ¥è¯†çš„æ™ºèƒ½ä½“ã€‚è™½ç„¶å‰æ²¿æ¨¡å‹å·²ç»è¢«ç”¨æ¥è¾…åŠ©äººç±»ç§‘å­¦å®¶ï¼Œ
ä¾‹å¦‚ç”¨äºå¤´è„‘é£æš´æˆ–ç¼–å†™ä»£ç ï¼Œä½†å®ƒä»¬ä»ç„¶éœ€è¦å¹¿æ³›çš„äººå·¥ç›‘ç£ï¼Œæˆ–è€…å—é™äºç‰¹å®šçš„ä»»åŠ¡ã€‚

æˆ‘ä»¬å¾ˆé«˜å…´åœ°ä»‹ç»AIç§‘å­¦å®¶ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¨é¢çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿå®ç°å®Œå…¨è‡ªåŠ¨åŒ–çš„ç§‘å­¦å‘ç°ï¼Œä½¿å¾—åŸºç¡€æ¨¡å‹å¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿç‹¬ç«‹è¿›è¡Œç ”ç©¶ã€‚

æˆ‘ä»¬è¿›ä¸€æ­¥æä¾›äº†æˆ‘ä»¬è®ºæ–‡ä¸­çš„æ‰€æœ‰è¿è¡Œå’Œæ•°æ®ï¼Œæ‚¨å¯ä»¥åœ¨
[è¿™é‡Œ](https://drive.google.com/drive/folders/1G7A0wTqfXVa-cpexjk0oaXakaSJwffEt?usp=sharing)
æ‰¾åˆ°ã€‚æˆ‘ä»¬å¯¹æ¯ä¸ªåŸºç¡€æ¨¡å‹åœ¨æ¯ä¸ªæ¨¡æ¿ä¸Šè¿è¡Œäº†å¤§çº¦50ä¸ªåˆ›æ„ã€‚æˆ‘ä»¬å¼ºçƒˆå»ºè®®é˜…è¯»ä¸€äº›
[Claudeè®ºæ–‡](https://drive.google.com/drive/folders/1Mmpz6M1FK4q8e-SewgZcUzdeD0Q2zC39?usp=sharing)
ï¼ˆç‰¹åˆ«æ˜¯æ‰©æ•£ç›¸å…³çš„ï¼‰ï¼Œä»¥äº†è§£å…¶ä¼˜ç¼ºç‚¹ã€‚ä»¥ä¸‹æ˜¯AIç§‘å­¦å®¶ç”Ÿæˆçš„ä¸€äº›ç¤ºä¾‹è®ºæ–‡ğŸ“ï¼š

1. [DualScale Diffusion: Adaptive Feature Balancing for Low-Dimensional Generative Models](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/adaptive_dual_scale_denoising.pdf)
2. [Multi-scale Grid Noise Adaptation: Enhancing Diffusion Models For Low-dimensional Data](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/grid_based_noise_adaptation.pdf)
3. [GAN-Enhanced Diffusion: Boosting Sample Quality and Diversity](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/gan_diffusion.pdf)
4. [DualDiff: Enhancing Mode Capture in Low-dimensional Diffusion Models via Dual-expert Denoising](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/dual_expert_denoiser.pdf) 
5. [StyleFusion: Adaptive Multi-style Generation in Character-Level Language Models](https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/multi_style_adapter.pdf)
6. [Adaptive Learning Rates for Transformers via Q-Learning](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/rl_lr_adaptation.pdf)
8. [Unlocking Grokking: A Comparative Study of Weight Initialization Strategies in Transformer Models](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/weight_initialization_grokking.pdf)
9. [Grokking Accelerated: Layer-wise Learning Rates for Transformer Generalization](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/layerwise_lr_grokking.pdf)
10. [Grokking Through Compression: Unveiling Sudden Generalization via Minimal Description Length](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/mdl_grokking_correlation.pdf)
11. [Accelerating Mathematical Insight: Boosting Grokking Through Strategic Data Augmentation](https://github.com/SakanaAI/AI-Scientist/tree/main/example_papers/data_augmentation_grokking.pdf)

**å°ç¬”è®°**: æ³¨æ„ï¼æ­¤ä»£ç åº“å°†æ‰§è¡Œç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç¼–å†™çš„ä»£ç ã€‚è¿™ç§è‡ªä¸»æ€§ä¼´éšæœ‰å„ç§é£é™©å’ŒæŒ‘æˆ˜ã€‚
è¿™åŒ…æ‹¬ä¾‹å¦‚ä½¿ç”¨æ½œåœ¨å±é™©çš„è½¯ä»¶åŒ…ã€ç½‘ç»œè®¿é—®ä»¥åŠå¯èƒ½äº§ç”Ÿè¿›ç¨‹ã€‚è¯·è‡ªè¡Œåˆ¤æ–­ä½¿ç”¨ã€‚è¯·ç¡®ä¿é€‚å½“è¿›è¡Œ[å®¹å™¨åŒ–](#containerization)å¹¶é™åˆ¶ç½‘ç»œè®¿é—®ã€‚

<p align="center">
  <a href="https://github.com/SakanaAI/AI-Scientist/blob/main/example_papers/adaptive_dual_scale_denoising/adaptive_dual_scale_denoising.pdf"><img src="https://github.com/SakanaAI/AI-Scientist/blob/main/docs/anim-ai-scientist.gif" alt="Adaptive Dual Scale Denoising" width="80%" />
</p>

# ç›®å½•

1. [ææ–™å‡†å¤‡](#ææ–™å‡†å¤‡)
2. [è®ºæ–‡é€‰é¢˜](#è®ºæ–‡é€‰é¢˜)
3. [è®ºæ–‡è¯„å®¡](#è®ºæ–‡è¯„å®¡)
4. [è®ºæ–‡æ¨¡æ¿](#è®ºæ–‡æ¨¡æ¿)
5. [FQA](#faq)
6. [å¼•ç”¨AIç§‘å­¦å®¶](#citing-the-ai-scientist)
8. [å®¹å™¨åŒ–](#containerization)

# ææ–™å‡†å¤‡
## ç®—åŠ›å‡†å¤‡
ä¸ºäº†å‡å°‘æ‚¨çš„èµ„é‡‘æ¶ˆè€—ï¼Œæœ¬é¡¹ç›®è®¡åˆ’åœ¨ä¸¤ç§ç¯å¢ƒï¼ˆå®¶ä¸­ã€äº‘ä¸Šï¼‰å¼€å±•AIç ”ç©¶ï¼Œè¯·æ ¹æ®è‡ªå·±çš„æ¡ä»¶é€‰æ‹©åˆé€‚çš„å®éªŒç¯å¢ƒï¼š
#### åœ¨å®¶ä¸­å¼€å±•è¯•éªŒ
1. ä¸€å°å¸¦æœ‰è‹±ä¼Ÿè¾¾æ˜¾å¡çš„ç”µè„‘ï¼Œæ˜¾å¡è¦æ±‚ï¼šGeforce RTX30ç³»åˆ—åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œä¾‹å¦‚RTX3050ã€RTX4060ã€RTX5080ã€‚åŸå› æ˜¯é¡¹ç›®éœ€è¦è¿›è¡Œbfloat16è®¡ç®—ï¼Œ 
éœ€è¦æ”¯æŒsm_80æ¶æ„çš„æ˜¾å¡ã€‚Teslaæ˜¾å¡ä¸­ï¼ŒTç³»åˆ—å’ŒPç³»åˆ—ä¸æ”¯æŒsm_80ï¼Œè¯·ä¸è¦è´­ä¹°ï¼Œæ¨èTesla Aç³»åˆ—å’ŒHç³»åˆ—ï¼Œä¾‹å¦‚A10ã€A100ã€H800ã€‚
2. é­”æ³•ç½‘ç»œï¼šç”±äºæœ¬é¡¹ç›®ä¼šè®¿é—®ä¸€äº›è¢«å¢™çš„ç½‘å€ï¼Œä¸ºäº†é¿å…è¯•éªŒä¸­æ–­ï¼Œè¯·ç»™å®¶é‡Œå®‰è£…è½¯è·¯ç”±ã€‚æ¯”å¦‚æ·˜å®è´­ä¹°R2Sã€åç¡•æ¢…æ—è·¯ç”±å™¨ç­‰ç­‰ï¼Œè¯·å‚è€ƒ
[æˆ‘çš„åšå®¢](https://blog.csdn.net/qq_43626147/article/details/142746627)
#### äº‘ä¸Šç¯å¢ƒ
1. æµ·å¤–GPUæœåŠ¡å™¨ï¼šæƒ³è¦ä¸è¢«å¢™ã€ä¸”æœ‰æ˜¾å¡ï¼Œåªèƒ½è´­ä¹°æµ·å¤–GPUæœåŠ¡å™¨ã€‚æ–‡æœ¬æµ‹è¯•è¿‡é˜¿é‡Œäº‘å›½å¤–GPUæœåŠ¡å™¨ï¼Œæ˜¾å¡å‹å·A10ï¼Œregioné¦–å°”ï¼Œ
ç³»ç»ŸAlibaba cloud linuxï¼Œé©±åŠ¨driver550ï¼Œcuda12.4ï¼Œcudnn9.2ï¼Œä»·æ ¼11.66å…ƒ/å°æ—¶ï¼Œç³»ç»Ÿç›˜è°ƒæˆ100GBã€‚

## API key å‡†å¤‡
ä»¥ä¸‹çš„æ¯ä¸ªkeyéƒ½å¿…é¡»åˆ›å»ºï¼Œå¦åˆ™AIæ— æ³•è¿è¡Œã€‚
1. ç”³è¯·ä¸€å¼ ç¾å›½é“¶è¡Œå¡ï¼šä¸­å›½å¤§é™†å¯ä»¥ç™»å½• bewildcard.com ï¼ŒèŠ±ä¸€ç‚¹é’±æ³¨å†Œä¸€ä¸ªç¾å›½è™šæ‹Ÿé“¶è¡Œå¡ï¼Œå°±èƒ½æ„‰å¿«çš„ä½¿ç”¨æ‰€æœ‰ç¾å›½çš„æœåŠ¡ï¼ŒåŒ…æ‹¬AIå’Œäº‘è®¡ç®—ç­‰ç­‰ã€‚
2. å®˜æ–¹chatGPT4 keyï¼šchatGPTä¸å…è®¸å¤§é™†å’Œé¦™æ¸¯ç™»å½•ï¼Œè€Œä¸”éœ€è¦ç¾å›½é“¶è¡Œå¡æ‰èƒ½å……å€¼ã€‚å»https://platform.openai.comä¸Šåˆ›å»ºä¸€ä¸ªkeyï¼Œ
å¹¶ç»‘å®šé“¶è¡Œå¡ä½œä¸ºæ”¯ä»˜æ–¹å¼ï¼Œè®¾ç½®è‡ªåŠ¨å……å€¼ï¼Œå¹¶é¢„å­˜20ç¾åˆ€ä¼šå‘˜ã€‚
[è¯¦ç»†æ“ä½œè§†é¢‘](https://www.bilibili.com/video/BV1ax42197uA/?share_source=copy_web&vd_source=4cee0005e63af504f1a4e5f79e975468)
3. Semantic Scholarï¼š ç®€ç§°S2 keyï¼Œç›®å‰å®˜æ–¹keyå·²ç»æ‹¿ä¸åˆ°äº†ï¼Œæˆ‘ç”¨ä¼ä¸šé‚®ç®±å»å®˜ç½‘å¡«äº†ç”³è¯·è¡¨ï¼Œç¾å›½ä½¬ä¸æ‰¹çš„ï¼Œå›å¤è¯´ç”³è¯·å•ç§¯å‹ï¼ŒåŠå¹´åå†æ¥ã€‚
ç›®å‰å›½å†…åšS2 keyä¸­è½¬çš„åªæœ‰ä¸€ä½å«é˜¿æ°çš„å¤§å“¥ã€‚æ–‡æ¡£åœ°å€æ˜¯ https://api.ominiai.cn/ ï¼Œ éœ€è¦å…ˆåŠ é˜¿æ°çš„å¾®ä¿¡ï¼Œä»˜æ¬¾ï¼Œå¯¹æ–¹ä¼šç»™ä½ ä¸€ä¸ªå…‘æ¢å¡ï¼Œç„¶åå»
æ§åˆ¶å°---å……å€¼---å…‘æ¢ç é‡Œä½¿ç”¨åˆšæ‰æ‹¿åˆ°çš„å…‘æ¢å¡ã€‚æœ€ååœ¨æ§åˆ¶å°---ä»¤ç‰Œè¿™é‡Œåˆ›å»ºä¸€ä¸ªkeyï¼Œè¿™ä¸ªå°±æ˜¯æˆ‘ä»¬éœ€è¦çš„S2 api keyã€‚æ§åˆ¶å°åœ°å€æ˜¯
 https://api.ominiai.cn/panel


# è¿è¡Œç¯å¢ƒå‡†å¤‡

### æ“ä½œç³»ç»Ÿå‡†å¤‡
AIç§‘å­¦å®¶éœ€è¦åœ¨Linuxç³»ç»Ÿä¸Šè¿è¡Œï¼Œæœ¬é¡¹ç›®åœ¨å¦‚ä¸‹å‘è¡Œç‰ˆä¸Šæµ‹è¯•è¿‡ï¼š Debian 11ï¼ŒDebian 12ï¼ŒUbuntu 24.04ï¼ŒRockyLinux 9.xï¼ŒCentOS Steam 9.xã€‚

æœ¬æ–‡ä½¿ç”¨ç¯å¢ƒï¼š Debian 12.7ã€‚ä»¥ä¸‹æ“ä½œå›´ç»•Debian 12.7ç»™å‡ºã€‚

### ç³»ç»ŸåŒ…å®‰è£…
```bash
# ä¸æ˜¾å¡å®‰è£…æœ‰å…³çš„åŒ…
apt update && apt upgrade -y
apt -y install gcc make vim git
apt -y install linux-headers-$(uname -r) build-essential libglvnd-dev pkg-config

# ä¸AIç§‘å­¦å®¶ç›¸å…³çš„åŒ…
apt install -y texlive-full
```

### æ˜¾å¡é©±åŠ¨å®‰è£…
NVIDIAæ˜¾å¡é©±åŠ¨å®˜ç½‘ä¸‹è½½åœ°å€ï¼š  https://www.nvidia.cn/drivers/lookup/

æˆ‘çš„è¯•éªŒç¯å¢ƒæ˜¯NVIDIA RTX 4070 laptopï¼Œå®‰è£…è¿‡ç¨‹å¦‚ä¸‹ï¼š
```bash
# ç¦ç”¨ nouveau
vim /etc/modprobe.d/blacklist-nouveau.conf
blacklist nouveau               
options nouveau modeset=0 

# æ›´æ–°ç³»ç»Ÿé©±åŠ¨
update-initramfs -u
# é‡å¯
reboot

# æŸ¥çœ‹æ˜¾å¡å‹å·
lspci|grep NVIDIA

# RTX 4070
cd /tmp && wget https://cn.download.nvidia.com/XFree86/Linux-x86_64/550.120/NVIDIA-Linux-x86_64-550.120.run
bash NVIDIA-Linux-x86_64-550.120.run

# éªŒè¯é©±åŠ¨æ˜¯å¦å®‰è£…æˆåŠŸï¼ŒæŸ¥çœ‹driverå’Œcudaç‰ˆæœ¬ã€‚
nvidia-smi

```

### Anaconda3å®‰è£…
å®˜ç½‘åœ°å€ https://www.anaconda.com/ ï¼Œä¸‹è½½æœ€æ–°ç‰ˆå¹¶å®‰è£…ï¼ŒAnacondaå¯ä»¥ç®¡ç†å¤šä¸ªç‰ˆæœ¬çš„pythonå’Œä¸‰æ–¹åŒ…ï¼Œæ‰€ä»¥æ”¾å¿ƒå®‰è£…æœ€æ–°ç‰ˆã€‚
å®‰è£…è¿‡ç¨‹æ¼”ç¤ºï¼›
```bash
# å°†/optä½œä¸ºå·¥ä½œç›®å½•
cd /opt

# ä¸‹è½½Anaconda3ï¼ˆå›½å†…ä»ä¸­ç§‘å¤§æºä¸‹è½½é€Ÿåº¦å¿«ï¼‰
wget https://mirrors.ustc.edu.cn/anaconda/archive/Anaconda3-2024.06-1-Linux-x86_64.sh

# å®‰è£…Anaconda3
bash Anaconda3-2024.06-1-Linux-x86_64.sh

ç¬¬ä¸€æ­¥ï¼Œé˜…è¯»åè®®ï¼Œä¸€ç›´æŒ‰ç©ºæ ¼ï¼Œæœ€åè¾“å…¥yes
ç¬¬äºŒæ­¥ï¼Œè¾“å…¥å®‰è£…ä½ç½®ï¼Œ/opt/anaconda3
ç¬¬ä¸‰æ­¥ï¼Œå¼€æœºè‡ªå¯åŠ¨ï¼Œè¾“å…¥no

```

### å…‹éš†é¡¹ç›®
```bash
cd /opt
git clone https://github.com/yangjiacheng1996/china-ai-scientist.git
git clone https://github.com/gregversteeg/NPEET.git
```

### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºä¸€ä¸ªcondaè™šæ‹Ÿç¯å¢ƒï¼ˆcondaè™šæ‹Ÿç¯å¢ƒåªä¿å­˜åœ¨Anacondaå®‰è£…ç›®å½•ä¸‹ï¼Œå’Œvenvä¸ä¸€æ ·ï¼‰
# å¯åŠ¨conda
cd /opt/china-ai-scientist
source /opt/anaconda3/bin/activate

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n ai_scientist python=3.11

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
conda activate ai_scientist

# Install pypi requirements
pip install -r requirements.txt
```



### è®­ç»ƒæ‰€éœ€æ•°æ®ä¸‹è½½
```bash
# Prepare NanoGPT data
cd /opt/china-ai-scientist
python data/enwik8/prepare.py
python data/shakespeare_char/prepare.py
python data/text8/prepare.py
```

#### è®­ç»ƒæ¨¡å‹
æ—¢ç„¶æ˜¯AIç§‘å­¦å®¶ï¼Œé‚£ä¹ˆå°±éœ€è¦åœ¨æœ¬åœ°è®­ç»ƒä¸€ä¸ªå°çš„AIæ¨¡å‹æ¥å……å½“ä¸€ä¸ªâ€œäººâ€ã€‚è¿è¡Œä¸‹æ–¹å‘½ä»¤è®­ç»ƒNanoGPTã€‚
```bash
# Set up NanoGPT baseline run
cd /opt/china-ai-scientist
cd templates/nanoGPT && python experiment.py --out_dir run_0 && python plot.py
```
è®­ç»ƒè½»é‡NanoGPT
```bash
# NOTE: YOU MUST FIRST RUN THE PREPARE SCRIPTS ABOVE!
cd /opt/china-ai-scientist
cd templates/nanoGPT_lite && python experiment.py --out_dir run_0 && python plot.py
```
è®­ç»ƒ2D Diffusion
```bash
# Set up 2D Diffusion
cd /opt/NPEET
pip install .
pip install scikit-learn

# Set up 2D Diffusion baseline run
cd /opt/china-ai-scientist
cd templates/2d_diffusion && python experiment.py --out_dir run_0 && python plot.py
```

è®­ç»ƒGrokking
```bash
# Set up Grokking
pip install einops

# Set up Grokking baseline run
cd /opt/china-ai-scientist
cd templates/grokking && python experiment.py --out_dir run_0 && python plot.py
```
å…¨éƒ¨è®­ç»ƒå®Œæˆåï¼Œè®°å¾—å¤‡ä»½ä½ çš„AIç§‘å­¦å®¶ã€‚å¦‚æœåœ¨åç»­ä½¿ç”¨è¿‡ç¨‹ä¸­å‡ºç°æ„å¤–ï¼Œå¯ä»¥é‡å¤´å†æ¥ã€‚
```bash
cp -R /opt/china-ai-scientist  /opt/china-ai-scientist-bak
zip -r china-ai-scientist.zip /opt/china-ai-scientist-bak
```
å°†zipåŒ…æ”¾åˆ°ç™¾åº¦ç½‘ç›˜é‡Œï¼Œæˆ–è€…NASé‡Œã€‚

# è®ºæ–‡é€‰é¢˜
### è®¾ç½®Semantic Scholar api keyç¯å¢ƒå˜é‡ï¼ˆä»¥ä¸‹ç®€ç§°S2 keyï¼‰
å¦‚æœä½ æœ‰Semantic Scholarå®˜æ–¹çš„keyï¼Œé‚£ä¹ˆè®¾ç½®æ¯”è¾ƒç®€å•ï¼Œåªéœ€è¦ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼š
```bash
export S2_API_KEY="sk-xFDp6Ec9Y50q07r1C563F991Dd324bE1A45c5d2a4bC65602"
```
å¦‚æœä½ é‡‡ç”¨å›½å†…çš„S2ä¸­è½¬ç«™çš„api keyï¼Œåˆ™è¿˜éœ€è¦ç»™å‡ºä¸­è½¬ç«™çš„åœ°å€ã€‚å¦‚ä¸‹æˆ‘ç»™å‡ºäº†é˜¿æ°çš„ominiç«™ç‚¹çš„åœ°å€å’Œkeyã€‚
AI-ScientiståŸé¡¹ç›®è®¿é—®çš„S2å®˜ç½‘åœ°å€æ˜¯ https://api.semanticscholar.org/graph/v1/paper/search

æˆ‘ä»¬éœ€è¦æŠŠ https://api.semanticscholar.org æ›¿æ¢æˆå›½å†… https://api.ominiai.cn/generalProxy/
å¦‚æœä½ èƒ½è´­ä¹°åˆ°å…¶ä»–ç«™ç‚¹çš„S2 apiï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µæ›¿æ¢ã€‚
```bash
# Semantic Scholar api key
export S2_API_URL="https://api.ominiai.cn/generalProxy/graph/v1/paper/search"
export S2_API_KEY="sk-xFDp6Ec9Y50q07r1C563F991Dd324bE1A45c5d2a4bC65602"

```

### è®¾ç½®OpenRouterå®˜æ–¹api key
æœ¬é¡¹ç›®å…¨ç¨‹ä½¿ç”¨Openaiå®˜æ–¹keyï¼Œå¦‚æœä½ é‡‡ç”¨å…¶ä»–keyï¼Œä¾‹å¦‚Claudeã€OpenRouterï¼Œåˆ™åªèƒ½è¿›è¡Œé€‰é¢˜ï¼Œæ— æ³•è·‘å®Œå…¨éƒ¨æµç¨‹ã€‚
è¯·æ ¹æ®è‡ªå·±çš„å®é™…keyï¼Œè®¾ç½®å¦‚ä¸‹ç¯å¢ƒå˜é‡
```bash
# openai api key
export OPENAI_API_KEY="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"
```

### å¼€å§‹è®ºæ–‡é€‰é¢˜
```bash
source /opt/anaconda3/bin/activate
conda activate ai_scientist
# Run the paper generation.
cd /opt/china-ai-scientist
python launch_scientist.py --model "gpt-4o-2024-05-13" --experiment nanoGPT --num-ideas 1
```
æƒ³è¦æŸ¥çœ‹AIç§‘å­¦å®¶æ”¯æŒå“ªäº›æ¨¡å‹ï¼Œå¯ä»¥æŸ¥çœ‹å¸®åŠ©å‘½ä»¤
```bash
python launch_scientist.py --help
```
ä¸åŒçš„æ¨¡å‹éœ€è¦è®¾ç½®ä¸åŒçš„keyç¯å¢ƒå˜é‡ï¼Œè¯¦æƒ…è¯·çœ‹AI-ScientiståŸé¡¹ç›®æ–‡æ¡£ã€‚

å¦‚æœä½ æœ‰è¶…è¿‡ 1 ä¸ª GPUï¼Œè¯·ä½¿ç”¨ `parallel` é€‰é¡¹åœ¨å¤šä¸ª GPU ä¸Šå¹¶è¡Œç”Ÿæˆé€‰é¢˜ã€‚

è¿™ä¸ªé€‰é¢˜å‘½ä»¤ä¸€æ¬¡è¿è¡Œä¸ä¸€å®šèƒ½äº§ç”Ÿä¸€ä¸ªåˆé€‚çš„é€‰é¢˜ï¼Œæ‰€ä»¥éœ€è¦å¤šè¿è¡Œå‡ æ¬¡ã€‚å¦‚æœé‡åˆ°å¦‚ä¸‹è¾“å‡ºè¡¨ç¤ºç”Ÿæˆé€‰é¢˜å¤±è´¥:
```bash
Completed idea: adaptive_block_size, Success: False
All ideas evaluated.
```
é€‰é¢˜å¤±è´¥å°±é‡æ–°æ‰§è¡Œé€‰é¢˜å‘½ä»¤ï¼Œç›´åˆ°å‡ºç°å¦‚ä¸‹å­—æ ·è¡¨ç¤ºé€‰é¢˜æˆåŠŸï¼Œç¨‹åºä¼šç»§ç»­è¿è¡Œæ¥ä¸‹æ¥çš„è¯•éªŒéƒ¨åˆ†ã€‚
```bash
*Starting Experiments*
Based on the experiment description, I plan to run the following experiments: 
```
é€‰é¢˜æˆåŠŸè‡ªåŠ¨è¿›å…¥è®ºæ–‡å†™ä½œå’Œè¯•éªŒç¯èŠ‚ï¼Œæ— éœ€äººå·¥å¹²é¢„ï¼Œè€å¿ƒç­‰å¾…ã€‚

ç»è¿‡å®æµ‹ï¼Œ4070æ˜¾å¡ç”Ÿæˆä¸€ç¯‡è®ºæ–‡pdfæ–‡ä»¶ï¼Œå¹³å‡èŠ±è´¹15ç¾å…ƒï¼ˆ100å…ƒäººæ°‘å¸ï¼‰ã€‚ç”¨æ—¶23å°æ—¶ã€‚

### è®ºæ–‡è¯„å®¡
ç›¸å½“äºé¢„ç­”è¾©ï¼Œæˆ–è€…æœŸåˆŠè¯„å§”é—®ç­”ã€‚

é€‰é¢˜å‘½ä»¤æ‰§è¡Œç»“æŸåï¼Œä¼šäº§ç”Ÿä¸€ä¸ªè®ºæ–‡pdfåˆç¨¿ï¼Œå·²ç»å¯ä»¥æ‹¿å»æ¶¦è‰²æ¶¦è‰²å‘è¡¨æœŸåˆŠäº†ã€‚
å¦‚æœä¸æ”¾å¿ƒï¼Œå¯ä»¥ç»§ç»­è®©aiè¯„å®¡ä¸€ä¸‹ã€‚ä½¿ç”¨å¦‚ä¸‹è„šæœ¬è¿›è¡Œè¯„å®¡ã€‚
pdfçš„æ–‡ä»¶è·¯å¾„åœ¨/opt/china-ai-scientist/results/nanoGPTä¸­ï¼Œè¿›å…¥å¯¹åº”æ—¶é—´æˆ³ç›®å½•ä¸­æœ‰ä¸€ä¸ª
initialization_lr_interplay.pdfæ–‡ä»¶ã€‚å°†pdfç»å¯¹è·¯å¾„æ›¿æ¢è„šæœ¬ä¸­çš„report.pdfï¼Œå¹¶è¿è¡Œè„šæœ¬ã€‚

```python
import openai
from ai_scientist.perform_review import load_paper, perform_review

client = openai.OpenAI()
model = "gpt-4o-2024-05-13"

# Load paper from pdf file (raw text)
paper_txt = load_paper("report.pdf")
# Get the review dict of the review
review = perform_review(
    paper_txt,
    model,
    client,
    num_reflections=5,
    num_fs_examples=1,
    num_reviews_ensemble=5,
    temperature=0.1,
)

# Inspect review results
review["Overall"]  # overall score 1-10
review["Decision"]  # ['Accept', 'Reject']
review["Weaknesses"]  # List of weaknesses (str)
```

è¿è¡Œæ‰¹é‡åˆ†æï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ã€‚

```bash
cd review_iclr_bench
python iclr_analysis.py --num_reviews 500  --batch_size 100 --num_fs_examples 1 --num_reflections 5 --temperature 0.1 --num_reviews_ensemble 5
```

## è®ºæ–‡æ¨¡æ¿

If there is an area of study you would like **The AI Scientist** to explore, it should be very easy to create your own templates. In general, follow the structure of the existing templates, which consists of:

- `experiment.py` -- This is a single file where the 'meat' of the content is. It takes in an argument for `out_dir`, which is where it should create the folder and save the relevant information from the run.
- `plot.py` -- This should take in the information from the `run` folders and create plots. The code should be clear and easy to edit.
- `prompt.json` -- Put information about your template here.
- `seed_ideas.json` -- Put example ideas here. You can also try to generate ideas without any examples, and then pick the best one or two to put here.
- `latex/template.tex` -- We recommend using our latex folder, but be sure to replace the pre-loaded citations with ones that you would expect to be more relevant.
   
## Template Resources

We provide 3 templates, which heavily use code from other repositories, which we credit below. (Normally, we would do this in the files themselves, but it's unclear how this would affect The AI Scientist since it would be visible).

The NanoGPT template used code from [NanoGPT](https://github.com/karpathy/nanoGPT) and this [PR](https://github.com/karpathy/nanoGPT/pull/254).

The 2D Diffusion template used code from [tiny-diffusion](https://github.com/tanelp/tiny-diffusion), [ema-pytorch](https://github.com/lucidrains/ema-pytorch), and [Datasaur](https://www.research.autodesk.com/publications/same-stats-different-graphs/).

The Grokking template used code from [Sea-Snell/grokking](https://github.com/Sea-Snell/grokking) and [danielmamay/grokking](https://github.com/danielmamay/grokking).

We would like to thank the developers of the open-source models and packages for their contributions and for making their work available.

## Citing The AI Scientist

If you use **The AI Scientist** in your research, please cite it as follows:

```
@article{lu2024aiscientist,
  title={The {AI} {S}cientist: Towards Fully Automated Open-Ended Scientific Discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}
```

### FAQ

We recommend reading our paper in the first instance for any questions you have on The AI Scientist.

### Why am I missing files when running The AI Scientist?
Make sure you have completed all the setup and preparation steps before the main experiment script.

### Why has a PDF or a review not been generated?
The AI Scientist finishes an idea with a success rate that depends on both the template, the base foundation model, and the complexity of the idea. We advise referring to our main paper. The highest success rates are observed with Claude Sonnet 3.5.
Reviews are best done with GPT-4o, all other models have issues with positivity bias or failure to conform to required outputs.

### What is the cost of each idea generated?
Typically less than $15 per paper with Claude Sonnet 3.5. We recommend DeepSeek Coder V2 for a much more cost-effective approach. A good place to look for new models is the [Aider leaderboard](https://aider.chat/docs/leaderboards/).

### How do I change the base conference format associated with the write-ups?
Change the base `template.tex` files contained within each template.

### How do I run The AI Scientist for different subject fields?
Please refer to the instructions for different templates. In this current iteration, this is restricted to ideas that can be expressed in code. However, lifting this restriction would represent exciting future work! :)

### How do I add support for a new foundation model?
Please see this [PR](https://github.com/SakanaAI/AI-Scientist/pull/7) for an example of how to add a new model, e.g. this time for Claude via Bedrock.
We do not advise any model that is significantly weaker than GPT-4 level for The AI Scientist.

### Why do I need to run the baseline runs myself?
These appear as `run_0` and should be run per machine you execute The AI Scientist on for accurate run-time comparisons due to hardware differences.

### What if I have problems accessing the Semantic Scholar API?
We use the Semantic Scholar API to check ideas for novelty and collect citations for the paper write-up. You may be able to skip these phases in case you don't have an API key or the API is slow to access.

## Containerization

We include a [community-contributed](https://github.com/SakanaAI/AI-Scientist/pull/21) Docker image that may assist with your containerization efforts in `experimental/Dockerfile`.

You can use this image like this:

```bash
# Endpoint Script
docker run -e OPENAI_API_KEY=$OPENAI_API_KEY -v `pwd`/templates:/app/AI-Scientist/templates <AI_SCIENTIST_IMAGE> \
  --model gpt-4o-2024-05-13 \
  --experiment 2d_diffusion \
  --num-ideas 2
```

```bash
# Interactive
docker run -it -e OPENAI_API_KEY=$OPENAI_API_KEY \
  --entrypoint /bin/bash \
  <AI_SCIENTIST_IMAGE>
```

